{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda944ca-9e18-403d-ba60-8e7f2ab724c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef56eca5-0597-4530-9b5b-34acd53aa93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea12bd-b40f-44e5-83f0-9de77430c498",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Do wizualizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36dccf41-3316-4739-a159-ed07db6acdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_to_color(bias, vmin, vmax):\n",
    "    \"\"\"Funkcja pomocniczna do liczenia koloru node\"\"\"\n",
    "\n",
    "    if vmin < 0 and vmax > 0:\n",
    "        # Przypadek 1: mamy biasy ujemne i dodatnie, wówczas używamy red yellow green color mapy\n",
    "        norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "        cmap = plt.get_cmap(\"RdYlGn\") \n",
    "    elif vmin >= 0:\n",
    "        # Przypadek 2: Wszystkie biasy >= 0, wówczas używamy yellow green color mapy\n",
    "        norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "        cmap = plt.get_cmap(\"YlGn\")\n",
    "    else:\n",
    "        # Przypadek 3: Wszystkie biasy <= 0, wówczas używamy yellow orange red mapy (reversed, bo jest od yellow do red, a chcemy, żeby vmax był yellow dla ujemnych)\n",
    "        norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "        cmap = plt.get_cmap(\"YlOrRd_r\")\n",
    "\n",
    "    return cmap(norm(bias))\n",
    "\n",
    "def draw_network_networkx(mlp):\n",
    "    \"\"\"Wizualizuje stan wag i biasów w sieci:\n",
    "        - kolor neuronu zależy od wartości biasu (w danej wartwie)\n",
    "        - kolor krawędzi zależy od znaku odpowiadającej wagi\n",
    "        - grubość krawędzi zależy od wartości odpowiadającej wagi (tylko dana warstwa)\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Zczytaj ilość neuronów\n",
    "    layers_sizes = []\n",
    "    input_size = mlp.layers[0].weights.shape[0]\n",
    "    layers_sizes.append(input_size)\n",
    "    for layer in mlp.layers:\n",
    "        layers_sizes.append(layer.weights.shape[1])\n",
    "    n_layers = len(layers_sizes)\n",
    "\n",
    "    # Ustal pozycje\n",
    "    pos = {}\n",
    "    node_colors = {}\n",
    "    h_spacing = 2.0  # Odległość horyzontalna między warstwami\n",
    "    v_spacing = 1.5  # Odległość wertykalna między neuronami tej samej warstwy\n",
    "\n",
    "    # Ustalamy pozycje i color neuronów\n",
    "    for i, n_neurons in enumerate(layers_sizes): # dla i-tej warstwy\n",
    "        x = i * h_spacing\n",
    "        # Neurony oddzielamy równomiernie w warstwie\n",
    "        if n_neurons > 1:\n",
    "            y_positions = np.linspace(0, (n_neurons - 1) * v_spacing, n_neurons)\n",
    "            y_positions = y_positions - np.max(y_positions) / 2\n",
    "        else:\n",
    "            y_positions = np.array([0])\n",
    "        \n",
    "        for j, y in enumerate(y_positions): # dla j-tego neuronu w i-tej warstwie\n",
    "            node_id = (i, j)\n",
    "            pos[node_id] = (x, y) # ustalamy pozycje neuronu\n",
    "            if i == 0:\n",
    "                # Dla input layer ustawiamy kolor neutralny\n",
    "                node_colors[node_id] = 'lightblue'\n",
    "            else: # Dla innej niż input layer\n",
    "                bias = mlp.layers[i-1].biases[j]\n",
    "                biases_layer = mlp.layers[i-1].biases\n",
    "                # Normalizujemy kolor funkcją pomociczą\n",
    "                if len(biases_layer) > 1: # Jeśli mamy > jeden neuron w wartstwie\n",
    "                    vmin, vmax = np.min(biases_layer), np.max(biases_layer)\n",
    "                    node_colors[node_id] = bias_to_color(bias, vmin, vmax)\n",
    "                else: # Jeśli jest jeden nauron\n",
    "                    node_colors[node_id] = \"red\" if bias < 0 else \"green\"\n",
    "                    \n",
    "            G.add_node(node_id)\n",
    "\n",
    "    # Ustalamy grubość połączeń między neuronami na podstawie wag\n",
    "    for i, layer in enumerate(mlp.layers): # DLa i-tej wastwy\n",
    "        weights = layer.weights  # połączenie i-tej oraz (i+1)-tej warstwy\n",
    "        max_weight = np.max(np.abs(weights))\n",
    "        # Unkamy dzielenia przez 0\n",
    "        if max_weight == 0:\n",
    "            max_weight = 1\n",
    "        for j in range(weights.shape[0]): # DLa j-tego neuronu z i-tej warstwy\n",
    "            for k in range(weights.shape[1]): # Dla k-tego neurony z (i+1)-tej warstwy\n",
    "                source = (i, j) # Od j tego neuronu z i-tej warstwy\n",
    "                target = (i+1, k) # Do k-tego z i+1\n",
    "                weight = weights[j, k]\n",
    "                # Skalujemy grubość połączenia (w danej warstwie)\n",
    "                lw = 0.5 + 5 * (abs(weight) / max_weight)\n",
    "                color = \"red\" if weight < 0 else \"green\"\n",
    "                G.add_edge(source, target, weight=weight, width=lw, color = color)\n",
    "\n",
    "    # Rysujemy graf\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    # Rysujemy neurony z kolorami\n",
    "    node_color_list = [node_colors[node] for node in G.nodes()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_color_list, node_size=800, ax=ax)\n",
    "    \n",
    "    # Rysujemy połączenia z grubością i kolorami\n",
    "    edge_widths = [d['width'] for (_, _, d) in G.edges(data=True)]\n",
    "    edge_colors = [d['color'] for (_, _, d) in G.edges(data=True)]\n",
    "    nx.draw_networkx_edges(G, pos, ax=ax, width=edge_widths, edge_color=edge_colors)\n",
    "    \n",
    "    # Labelujemy neurony za pomocą indexu w warstwie\n",
    "    labels = {node: f\"{node[1]}\" for node in G.nodes()}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=10, ax=ax)\n",
    "\n",
    "    ax.set_title(\"Neural Net Visualization\")\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_loss(epoch_arr, loss_arr):\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.plot(epoch_arr, loss_arr)\n",
    "    plt.title(\"Loss vs epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "def eval_2d(network, x, y):\n",
    "    y_pred = network.predict(x)\n",
    "    plt.scatter(x, y, s = 1, label = \"True\")\n",
    "    plt.scatter(x, y_pred, s=1, label = \"Predicted\")\n",
    "    plt.title(f\"How fun is fitting desired y\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2716b3f5-2453-4119-9979-bb72fce979f3",
   "metadata": {},
   "source": [
    "# Definicja sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837624b-188e-4cb3-a107-36e4ed6e8264",
   "metadata": {},
   "source": [
    "Zmiany:\n",
    "- dodana możliwość ustawienia Dropout\n",
    "- dodana możliwość wcześniejszego stopu\n",
    "- wyrzucenie funkcji train_to_visualize, bo niepotrzeba jest (przerzucam funkcjonalność do po prost train)\n",
    "- dodanie l1 i l2 regularyzacji (jednak używam dopiero od Testy2 w multimodal-sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927b224e-08af-4103-a0fb-0b66a8f37cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def update(self, layer, dW, db):\n",
    "        raise NotImplementedError(\"This method should be overridden\")\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, lr=0.05):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, layer, dW, db):\n",
    "        layer.weights -= self.lr * dW\n",
    "        layer.biases  -= self.lr * db\n",
    "\n",
    "class Momentum(Optimizer):\n",
    "    def __init__(self, lr=0.05, lamb=0.9):\n",
    "        self.lr = lr\n",
    "        self.lamb = lamb\n",
    "        self.momentum = {}\n",
    "\n",
    "    def update(self, layer, dW, db):\n",
    "        # Inicjujemy momentum\n",
    "        if layer not in self.momentum:\n",
    "            self.momentum[layer] = {'dW': np.zeros_like(dW), 'db': np.zeros_like(db)}\n",
    "\n",
    "        ## Version 1\n",
    "        # # Update sredniej\n",
    "        # self.momentum[layer]['dW'] = self.lamb * self.momentum[layer]['dW'] - self.lr * dW\n",
    "        # self.momentum[layer]['db'] = self.lamb * self.momentum[layer]['db'] - self.lr * db\n",
    "        # # Update parametrow\n",
    "        # layer.weights += self.momentum[layer]['dW']\n",
    "        # layer.biases  += self.momentum[layer]['db']\n",
    "        \n",
    "        ## Version 2\n",
    "        # Update momentum\n",
    "        self.momentum[layer]['dW'] = self.lamb * self.momentum[layer]['dW'] - dW\n",
    "        self.momentum[layer]['db'] = self.lamb * self.momentum[layer]['db'] - db\n",
    "        \n",
    "        # Update parameters using the momentum\n",
    "        layer.weights += self.lr * self.momentum[layer]['dW']\n",
    "        layer.biases  += self.lr * self.momentum[layer]['db']\n",
    "\n",
    "class RMSProp(Optimizer):\n",
    "    def __init__(self, lr=0.05, beta = 0.9):\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.mean_sq_grad = {}\n",
    "    \n",
    "    def update(self, layer, dW, db):\n",
    "        # Inicjujemy\n",
    "        if layer not in self.mean_sq_grad:\n",
    "            self.mean_sq_grad[layer] = {'dW': np.zeros_like(dW), 'db': np.zeros_like(db)}\n",
    "        # Update sredniej\n",
    "        self.mean_sq_grad[layer]['dW'] = self.beta * self.mean_sq_grad[layer]['dW'] + (1 - self.beta) * dW ** 2\n",
    "        self.mean_sq_grad[layer]['db'] = self.beta * self.mean_sq_grad[layer]['db'] + (1 - self.beta) * db ** 2\n",
    "\n",
    "        # Update parametrow\n",
    "        layer.weights -= self.lr * dW / np.sqrt(self.mean_sq_grad[layer]['dW'] + np.finfo(float).eps)\n",
    "        layer.biases  -= self.lr * db / np.sqrt(self.mean_sq_grad[layer]['db'] + np.finfo(float).eps)\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, lr=0.01, beta1 = 0.9, beta2 = 0.999, epsilon = np.finfo(float).eps):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.m = {}\n",
    "        self.v = {}\n",
    "        self.t = {}\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def update(self, layer, dW, db):\n",
    "        # Inicjujemy\n",
    "        if layer not in self.m:\n",
    "            self.m[layer] = {'dW': np.zeros_like(dW), 'db': np.zeros_like(db)}\n",
    "            self.v[layer] = {'dW': np.zeros_like(dW), 'db': np.zeros_like(db)}\n",
    "            self.t[layer] = 0\n",
    "\n",
    "        # Set t\n",
    "        self.t[layer] += 1\n",
    "        \n",
    "        # Update weights\n",
    "        self.m[layer][\"dW\"] = self.beta1 * self.m[layer][\"dW\"] + (1 - self.beta1) * dW\n",
    "        self.v[layer][\"dW\"] = self.beta2 * self.v[layer][\"dW\"] + (1 - self.beta2) * dW**2\n",
    "        m_hat = self.m[layer][\"dW\"] / (1 - self.beta1**self.t[layer])\n",
    "        v_hat = self.v[layer][\"dW\"] / (1 - self.beta2**self.t[layer])\n",
    "        layer.weights -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "\n",
    "        # Update bias\n",
    "        self.m[layer][\"db\"] = self.beta1 * self.m[layer][\"db\"] + (1 - self.beta1) * db\n",
    "        self.v[layer][\"db\"] = self.beta2 * self.v[layer][\"db\"] + (1 - self.beta2) * db**2\n",
    "        m_hat = self.m[layer][\"db\"] / (1 - self.beta1**self.t[layer])\n",
    "        v_hat = self.v[layer][\"db\"] / (1 - self.beta2**self.t[layer])\n",
    "        layer.biases -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bbe447e-eaaf-4fa0-9bdc-2821b5d34eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_deriv(output):\n",
    "    # Zakłada, że wejściem jest \"a\", a nie \"z\" (czyli, że jest to już po zastosowaniu sigmoid(a))\n",
    "    return output * (1 - output)\n",
    "def linear(x):\n",
    "    return x\n",
    "def linear_deriv(x):\n",
    "    return 1.0\n",
    "def softmax(z):\n",
    "    d = -np.max(z, axis=1, keepdims=True)\n",
    "    return np.exp(z + d) / np.sum(np.exp(z + d), axis=1, keepdims=True)\n",
    "    \n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-12\n",
    "    return -np.mean(np.sum(y_true*np.log(y_pred + epsilon), axis=1))\n",
    "def cross_entropy_from_logits(y_true, logits):\n",
    "    y_pred = softmax(logits)    \n",
    "    return cross_entropy(y_true, y_pred)\n",
    "def one_hot(x):\n",
    "    result = np.int64(np.zeros((x.size, x.max() + 1)))\n",
    "    result[np.arange(x.size), x] = 1\n",
    "    return result\n",
    "def one_hot_from_probabilities(y_pred):\n",
    "    return one_hot(y_pred.argmax(axis=1))\n",
    "def from_one_hot_to_label(x):\n",
    "    return x.argmax(axis=1)\n",
    "def f1_score(y_true, y_pred): # Zakładamy, że są to predykcje trybie \"labelled\", czyli wektor [0, 1, 2, 1, ..]\n",
    "    classes = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    f1_arr = []\n",
    "    for cls in classes:\n",
    "        tp = np.sum((y_true == cls) & (y_pred == cls))\n",
    "        fp = np.sum((y_true != cls) & (y_pred == cls))\n",
    "        fn = np.sum((y_true == cls) & (y_pred != cls))\n",
    "        if tp == 0:\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1_arr.append(f1)\n",
    "    return np.mean(f1_arr)\n",
    "\n",
    "# Nowe funkcje aktywacji\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(output):\n",
    "    # Zakłada, że wejściem jest \"a\", a nie \"z\" (czyli, że jest to już po zastosowaniu tanh(a))\n",
    "    return 1 - np.power(output, 2)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_deriv(a_out):\n",
    "    # Zakłada, że wejściem jest \"a\", a nie \"z\" (czyli, że jest to już po zastosowaniu relu(a))\n",
    "    return np.where(a_out > 0, 1.0, 0.0)\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "def leaky_relu_deriv(a_out, alpha=0.01):\n",
    "    # Zakłada, że wejściem jest \"a\", a nie \"z\" (czyli, że jest to już po zastosowaniu leaky_relu(a))\n",
    "    return np.where(a_out > 0, 1.0, alpha)\n",
    "    \n",
    "\n",
    "class Layer: # Warstwa sieci\n",
    "    def __init__(self, input_size, output_size, act_fun, act_derivative, init_type = 'random', dropout_rate=0.0):\n",
    "        if init_type == \"random\":\n",
    "            self.weights = np.random.random((input_size, output_size))\n",
    "            self.biases = np.random.random(output_size)\n",
    "        elif init_type == \"xavier\":\n",
    "            limit = np.sqrt(2 / (input_size + output_size))\n",
    "            self.weights = np.random.randn(input_size, output_size) * limit\n",
    "            self.biases = np.zeros(output_size)\n",
    "        elif init_type == \"he\":\n",
    "            self.weights = np.random.randn(input_size, output_size) * np.sqrt(2 / input_size)\n",
    "            self.biases = np.zeros(output_size)\n",
    "        self.act_fun = act_fun\n",
    "        self.act_derivative = act_derivative\n",
    "        self.a_in = None\n",
    "        self.z = None\n",
    "        self.a_out = None\n",
    "        self.dropout_rate = dropout_rate  #  (0.0 oznacza brak dropout)\n",
    "        self.dropout_mask = None\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        self.a_in = x\n",
    "        z = np.dot(x, self.weights) + self.biases\n",
    "        self.z = z\n",
    "        z = self.act_fun(z)\n",
    "        self.a_out = z\n",
    "        # Tylko podczas treningu, kiedy chcemy mieć jakikolwiek dropout\n",
    "        if training and self.dropout_rate > 0.0:\n",
    "            self.dropout_mask = (np.random.rand(*self.a_out.shape) > self.dropout_rate) / (1 - self.dropout_rate)\n",
    "            self.a_out *= self.dropout_mask\n",
    "        else:\n",
    "            self.dropout_mask = None\n",
    "        return z\n",
    "\n",
    "    def backward(self, dA):\n",
    "        # IJeśli ustawiony jest dropout to dropout_mask nie jest None i zmieniamy wtedy gradient zgodnie z maską\n",
    "        if self.dropout_mask is not None:\n",
    "            dA *= self.dropout_mask\n",
    "        # dC / dz\n",
    "        dZ = self.act_derivative(self.a_out) * dA # zakładamy, że używamy act_derivative na \"a\", a nie na \"z\". W przypadku ostatniej warstwy nie ma to znaczenia, o ile zakładamy, że wyjście jest funkcją liniową, a zatem ma stałą pochodną\n",
    "        # Zmiana na wagach (L)\n",
    "        dW = np.dot(self.a_in.T, dZ)\n",
    "        # Zmiana na bias (L)\n",
    "        db = np.sum(dZ, axis=0)\n",
    "        # Zmiana dA (L-1)\n",
    "        dA_in = np.dot(dZ, self.weights.T)\n",
    "        return dA_in, dW, db\n",
    "    \n",
    "    def show_params(self):\n",
    "        print(\"Weights\")\n",
    "        print(self.weights)\n",
    "        print(\"Biases\")\n",
    "        print(self.biases)\n",
    "\n",
    "class MLP: # Cała sieć\n",
    "    def __init__(self, neural_arr, act_fun, act_derivative, out_fun, out_derivative, init_type = \"random\", dropout_rate=0.0):\n",
    "        self.layers = []\n",
    "        for i in range(len(neural_arr) - 2):\n",
    "            self.layers.append(Layer(neural_arr[i], neural_arr[i+1], act_fun, act_derivative, init_type, dropout_rate))  # Dodajemy dropout w wewnętrznych warstwach\n",
    "        self.layers.append(Layer(neural_arr[-2], neural_arr[-1], out_fun, out_derivative, init_type, dropout_rate=0.0))\n",
    "\n",
    "        # Do standaryzacji potem\n",
    "        self.input_mean = None\n",
    "        self.input_std = None\n",
    "        self.output_mean = None\n",
    "        self.output_std = None\n",
    "\n",
    "    def standarize_input(self, x):\n",
    "        return (x - self.input_mean) / self.input_std\n",
    "    def standarize_output(self, y):\n",
    "        return (y - self.output_mean) / self.output_std\n",
    "    def destandarize_output(self, y_std):\n",
    "        return y_std * self.output_std + self.output_mean\n",
    "\n",
    "    def forward(self, x, training=False): # Dodajemy flagę training\n",
    "        z = x.copy()\n",
    "        for i in range(len(self.layers)):\n",
    "            z = self.layers[i].forward(z, training)\n",
    "        return z\n",
    "        \n",
    "    def predict(self, x):\n",
    "        x_std = self.standarize_input(x)\n",
    "        y_std = self.forward(x_std)\n",
    "        return self.destandarize_output(y_std)\n",
    "\n",
    "    def backward(self, dA, optimizer, l1_lambda, l2_lambda):\n",
    "        for layer in reversed(self.layers):\n",
    "            dA, dW, db = layer.backward(dA)\n",
    "            dW += l1_lambda * np.sign(layer.weights) + l2_lambda * layer.weights  # DODANIE REGULARYZACJI\n",
    "            optimizer.update(layer, dW, db)\n",
    "\n",
    "    def train(self, x, y, epochs = 100, loss_fun = mse, optimizer = None, batch_size = None, early_stopping_patience=0, val_x=None, val_y=None, l1_lambda=0, l2_lambda=0):  # Dodajemy możliwość early_stopu i regularyzacji\n",
    "        \"\"\"Batch Gradient Descent by default\"\"\"\n",
    "        # Zapisuje średnie i odchylenia inputu i outputu\n",
    "        self.input_mean = np.mean(x, axis=0)\n",
    "        self.input_std = np.std(x, axis=0)\n",
    "        self.output_mean = np.mean(y, axis=0)\n",
    "        self.output_std = np.std(y, axis=0)\n",
    "\n",
    "        # standaryzuje x i y zanim zaczne uczyc\n",
    "        x_std = self.standarize_input(x)\n",
    "        y_std = self.standarize_output(y)\n",
    "\n",
    "        if batch_size == None: # Zapewnia, że jest to batch gradient descent by default\n",
    "            batch_size = y.shape[0]\n",
    "        optimizer = optimizer if optimizer is not None else SGD(lr=0.05) # Zapewnia, że istnieje optimizer\n",
    "\n",
    "        # Do early stopu\n",
    "        best_val_loss = np.inf\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Trenujemy\n",
    "        loss_history = np.zeros(epochs)\n",
    "        for epoch in range(epochs):\n",
    "            loss = 0\n",
    "\n",
    "            if batch_size != 1:\n",
    "                # tworze batche\n",
    "                order = np.arange(y.shape[0])\n",
    "                np.random.shuffle(order)\n",
    "                batches = np.array_split(order, len(order) // batch_size + (len(order) % batch_size != 0) )\n",
    "            else: # Znacznie polepsza czas gdy chcemy brac jedna probke na raz (sgd)\n",
    "                batches = np.arange(y.shape[0]).reshape(-1, 1)\n",
    "            \n",
    "            for batch in batches:\n",
    "                x_tmp = x_std[batch, :]\n",
    "                y_tmp = y_std[batch, :]\n",
    "                # Forward\n",
    "                y_pred_std = self.forward(x_tmp, training=True)\n",
    "                loss += loss_fun(y_tmp, y_pred_std)\n",
    "                # Backward\n",
    "                # Trzeba podzielić jeszcze przez wielkość próby, bo gradient \"na raz\" chcę się za dużo poprawić / batch_size\n",
    "                dA = (y_pred_std - y_tmp) / batch_size\n",
    "                self.backward(dA, optimizer, l1_lambda=l1_lambda, l2_lambda=l2_lambda)\n",
    "\n",
    "            loss = loss / len(batches)\n",
    "            loss_history[epoch] = loss\n",
    "            if epoch % int(epochs / 20) == 0:\n",
    "                print(f\"Epoch: {epoch+1}, Loss (standarized): {loss}\")\n",
    "\n",
    "            # Jeśli podaliśmy dane walidacyje to sprawdzamy (pod early stopping)\n",
    "            if val_x is not None and val_y is not None and early_stopping_patience!=0:\n",
    "                x_val_std = self.standarize_input(val_x)\n",
    "                y_val_std = self.standarize_output(val_y)\n",
    "                y_val_pred = self.forward(x_val_std, training=False)\n",
    "                val_loss = loss_fun(y_val_std, y_val_pred)\n",
    "                if epoch % int(epochs / 20) == 0:\n",
    "                    print(f\"          Validation Loss (standardized): {val_loss}\")\n",
    "                \n",
    "                # Sprawdzamy czy błąd na walidacyjnych danych się zwiększył\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if early_stopping_patience > 0 and patience_counter >= early_stopping_patience:\n",
    "                        print(f\"Early stopping triggered. No improvement in validation loss for {early_stopping_patience} epochs.\")\n",
    "                        break\n",
    "        \n",
    "        print(f\"Final epoch: {epoch+1}, Final loss (standarized): {loss}\")\n",
    "\n",
    "        return loss_history   \n",
    "\n",
    "    def train_classify(self, x, y, epochs = 100, loss_fun = cross_entropy, optimizer = None, batch_size = None, early_stopping_patience=0, val_x=None, val_y=None, l1_lambda=0, l2_lambda=0):\n",
    "        # Zapisuje średnie i odchylenia inputu i outputu\n",
    "        self.input_mean = np.mean(x, axis=0)\n",
    "        self.input_std = np.std(x, axis=0)\n",
    "        self.output_mean = 0\n",
    "        self.output_std = 1\n",
    "\n",
    "        # standaryzuje x zanim zaczne uczyc\n",
    "        x_std = self.standarize_input(x)\n",
    "        y_std = y\n",
    "\n",
    "        if batch_size == None: # Zapewnia, że jest to batch gradient descent by default\n",
    "            batch_size = y.shape[0]\n",
    "        optimizer = optimizer if optimizer is not None else SGD(lr=0.05) # Zapewnia, że istnieje optimizer\n",
    "\n",
    "        # Do early stopu\n",
    "        best_val_loss = np.inf\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Trenujemy\n",
    "        loss_history = np.zeros(epochs)\n",
    "        for epoch in range(epochs):\n",
    "            loss = 0\n",
    "\n",
    "            if batch_size != 1:\n",
    "                # tworze batche\n",
    "                order = np.arange(y.shape[0])\n",
    "                np.random.shuffle(order)\n",
    "                batches = np.array_split(order, len(order) // batch_size + (len(order) % batch_size != 0) )\n",
    "            else: # Znacznie polepsza czas gdy chcemy brac jedna probke na raz (sgd)\n",
    "                batches = np.arange(y.shape[0]).reshape(-1, 1)\n",
    "            \n",
    "            for batch in batches:\n",
    "                x_tmp = x_std[batch, :]\n",
    "                y_tmp = y_std[batch, :]\n",
    "                # Forward\n",
    "                y_pred_std = self.forward(x_tmp, training=True)\n",
    "                loss += loss_fun(y_tmp, y_pred_std)\n",
    "                # Backward\n",
    "                # Trzeba podzielić jeszcze przez wielkość próby, bo gradient \"na raz\" chcę się za dużo poprawić / batch_size\n",
    "                dA = (y_pred_std - y_tmp) / batch_size\n",
    "                self.backward(dA, optimizer, l1_lambda=l1_lambda, l2_lambda=l2_lambda)\n",
    "\n",
    "            loss = loss / len(batches)\n",
    "            loss_history[epoch] = loss\n",
    "            if epoch % int(epochs / 20) == 0:\n",
    "                print(f\"Epoch: {epoch+1}, Loss (standarized): {loss}\")\n",
    "\n",
    "            # Jeśli podaliśmy dane walidacyje to sprawdzamy (pod early stopping)\n",
    "            if val_x is not None and val_y is not None and early_stopping_patience!=0:\n",
    "                x_val_std = self.standarize_input(val_x)\n",
    "                y_val_std = self.standarize_output(val_y)\n",
    "                y_val_pred = self.forward(x_val_std, training=False)\n",
    "                val_loss = loss_fun(y_val_std, y_val_pred)\n",
    "\n",
    "                if epoch % int(epochs / 20) == 0:\n",
    "                    print(f\"          Validation Loss (standardized): {val_loss}\")\n",
    "                \n",
    "                # Sprawdzamy czy błąd na walidacyjnych danych się zwiększył\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if early_stopping_patience > 0 and patience_counter >= early_stopping_patience:\n",
    "                        print(f\"Early stopping triggered. No improvement in validation loss for {early_stopping_patience} epochs.\")\n",
    "        \n",
    "        print(f\"Final epoch: {epoch+1}, Final loss (standarized): {loss}\")\n",
    "        return loss_history\n",
    "\n",
    "    def show_params(self):\n",
    "        for i in range(len(self.layers)):\n",
    "            print(\"Layer: \", i)\n",
    "            self.layers[i].show_params()\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d391fc0-ab9b-4bb7-87fd-d83c088c707b",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89556af3-685c-44ab-a6b2-d165c4667da4",
   "metadata": {},
   "source": [
    "## Dane multimodal sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb440fee-351e-47dd-95eb-68f4ce35bb43",
   "metadata": {},
   "source": [
    "### Pobranie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0ff5bef8-967b-42e6-b417-2195f53140d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobieramy dane\n",
    "data_train = pd.read_csv(\"../Data/regression/multimodal-sparse-training.csv\").to_numpy()\n",
    "x_train = data_train[:, 0].reshape(-1, 1)\n",
    "y_train = data_train[:, 1].reshape(-1, 1)\n",
    "\n",
    "data_test = pd.read_csv(\"../Data/regression/multimodal-sparse-test.csv\").to_numpy()\n",
    "x_test = data_test[:, 0].reshape(-1, 1)\n",
    "y_test = data_test[:, 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "daf6991e-0b0d-4d51-b4a1-1e32b3cfb16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train, y_train, s = 1, label = \"train data\")\n",
    "plt.scatter(x_test, y_test, s = 1, label = \"test_data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde721b6-1da2-4870-801d-4f1f5f8decdd",
   "metadata": {},
   "source": [
    "### Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1cf475d-f841-44f3-9f03-8312b8cb13c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss (standarized): 1.063931000001304\n",
      "Epoch: 501, Loss (standarized): 0.1685767134873671\n",
      "Epoch: 1001, Loss (standarized): 0.044159124203801955\n",
      "Epoch: 1501, Loss (standarized): 0.04297051916525435\n",
      "Epoch: 2001, Loss (standarized): 0.04016256746055278\n",
      "Epoch: 2501, Loss (standarized): 0.03496096230863868\n",
      "Epoch: 3001, Loss (standarized): 0.03146724891046668\n",
      "Epoch: 3501, Loss (standarized): 0.021765388585397838\n",
      "Epoch: 4001, Loss (standarized): 0.0021298726887495367\n",
      "Epoch: 4501, Loss (standarized): 0.001902258954216967\n",
      "Epoch: 5001, Loss (standarized): 0.0015201933968525302\n",
      "Epoch: 5501, Loss (standarized): 0.0017950133609690908\n",
      "Epoch: 6001, Loss (standarized): 0.0027416519672504563\n",
      "Epoch: 6501, Loss (standarized): 0.001308105917687176\n",
      "Epoch: 7001, Loss (standarized): 0.0011083528348514496\n",
      "Epoch: 7501, Loss (standarized): 0.001330521953002473\n",
      "Epoch: 8001, Loss (standarized): 0.0008071107967213305\n",
      "Epoch: 8501, Loss (standarized): 0.0018611012074934007\n",
      "Epoch: 9001, Loss (standarized): 0.0016910673284326063\n",
      "Epoch: 9501, Loss (standarized): 0.0006482912069681868\n",
      "Final epoch: 10000, Final loss (standarized): 0.0006441335802600504\n",
      "Epoch: 1, Loss (standarized): 1.2749000051945263\n",
      "          Validation Loss (standardized): 0.9729421735258716\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 118, Final loss (standarized): 0.42356917116951653\n",
      "Epoch: 1, Loss (standarized): 1.171914424493657\n",
      "          Validation Loss (standardized): 0.9170808536173596\n",
      "Epoch: 501, Loss (standarized): 0.06472152418452128\n",
      "          Validation Loss (standardized): 0.138413551194152\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 729, Final loss (standarized): 0.0430345698897799\n",
      "Epoch: 1, Loss (standarized): 1.0791727875985888\n",
      "          Validation Loss (standardized): 0.9240264188879178\n",
      "Epoch: 501, Loss (standarized): 0.23066244991980672\n",
      "          Validation Loss (standardized): 0.27941448816215286\n",
      "Epoch: 1001, Loss (standarized): 0.042138611725958446\n",
      "          Validation Loss (standardized): 0.08795846199311712\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 1371, Final loss (standarized): 0.04029794310572008\n",
      "Epoch: 1, Loss (standarized): 1.0746086325292568\n",
      "          Validation Loss (standardized): 0.9243452111778282\n",
      "Epoch: 501, Loss (standarized): 0.14389739257795636\n",
      "          Validation Loss (standardized): 0.19504885580633627\n",
      "Epoch: 1001, Loss (standarized): 0.042251574910091794\n",
      "          Validation Loss (standardized): 0.08851692525386262\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 1003, Final loss (standarized): 0.040739400230319085\n",
      "Epoch: 1, Loss (standarized): 1.056133560949073\n",
      "          Validation Loss (standardized): 0.9594432904895319\n",
      "Epoch: 501, Loss (standarized): 0.0549942717993668\n",
      "          Validation Loss (standardized): 0.11675968934423636\n",
      "Epoch: 1001, Loss (standarized): 0.04178607332989374\n",
      "          Validation Loss (standardized): 0.08782841172199028\n",
      "Epoch: 1501, Loss (standarized): 0.041125904863726206\n",
      "          Validation Loss (standardized): 0.0892793191398113\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 1948, Final loss (standarized): 0.04239564671732903\n",
      "Epoch: 1, Loss (standarized): 1.0333549132751818\n",
      "          Validation Loss (standardized): 0.9512186251882653\n",
      "Epoch: 501, Loss (standarized): 0.20256274934030027\n",
      "          Validation Loss (standardized): 0.260148043925915\n",
      "Epoch: 1001, Loss (standarized): 0.04199655521184813\n",
      "          Validation Loss (standardized): 0.08883079926256546\n",
      "Epoch: 1501, Loss (standarized): 0.04167559226470161\n",
      "          Validation Loss (standardized): 0.09032974375423691\n",
      "Epoch: 2001, Loss (standarized): 0.04140216862848768\n",
      "          Validation Loss (standardized): 0.08679838554532524\n",
      "Epoch: 2501, Loss (standarized): 0.043527592631611774\n",
      "          Validation Loss (standardized): 0.08223818538139976\n",
      "Epoch: 3001, Loss (standarized): 0.037193820759125404\n",
      "          Validation Loss (standardized): 0.0689120513581304\n",
      "Epoch: 3501, Loss (standarized): 0.03529063055274162\n",
      "          Validation Loss (standardized): 0.05671057983687188\n",
      "Epoch: 4001, Loss (standarized): 0.027785863769601807\n",
      "          Validation Loss (standardized): 0.05047583773478905\n",
      "Epoch: 4501, Loss (standarized): 0.026641229520601085\n",
      "          Validation Loss (standardized): 0.04986391589861758\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 4915, Final loss (standarized): 0.022796031629510452\n",
      "Epoch: 1, Loss (standarized): 1.011318061969491\n",
      "Epoch: 501, Loss (standarized): 0.3262991820087111\n",
      "Epoch: 1001, Loss (standarized): 0.19017908481883308\n",
      "Epoch: 1501, Loss (standarized): 0.20647886195806517\n",
      "Epoch: 2001, Loss (standarized): 0.1925026325090809\n",
      "Epoch: 2501, Loss (standarized): 0.16738971024472754\n",
      "Epoch: 3001, Loss (standarized): 0.13362243121709785\n",
      "Epoch: 3501, Loss (standarized): 0.10762202741994903\n",
      "Epoch: 4001, Loss (standarized): 0.12027666792082817\n",
      "Epoch: 4501, Loss (standarized): 0.14263859815199403\n",
      "Epoch: 5001, Loss (standarized): 0.12992000139580331\n",
      "Epoch: 5501, Loss (standarized): 0.15183956871410104\n",
      "Epoch: 6001, Loss (standarized): 0.13564337138099491\n",
      "Epoch: 6501, Loss (standarized): 0.08131295355073612\n",
      "Epoch: 7001, Loss (standarized): 0.08145943356663937\n",
      "Epoch: 7501, Loss (standarized): 0.09254530504977052\n",
      "Epoch: 8001, Loss (standarized): 0.11629036523691555\n",
      "Epoch: 8501, Loss (standarized): 0.08502948643247742\n",
      "Epoch: 9001, Loss (standarized): 0.06102519144851532\n",
      "Epoch: 9501, Loss (standarized): 0.07045501996314261\n",
      "Final epoch: 10000, Final loss (standarized): 0.08662121441664383\n",
      "Epoch: 1, Loss (standarized): 1.0862059150067074\n",
      "          Validation Loss (standardized): 1.0184260646868608\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 198, Final loss (standarized): 0.34430528376758945\n",
      "Epoch: 1, Loss (standarized): 1.8385242907756023\n",
      "          Validation Loss (standardized): 0.9356435106076637\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 395, Final loss (standarized): 0.3285782306196554\n",
      "Epoch: 1, Loss (standarized): 0.9932184737943553\n",
      "          Validation Loss (standardized): 0.9096080345827547\n",
      "Epoch: 501, Loss (standarized): 0.2546457557733792\n",
      "          Validation Loss (standardized): 0.28626392265035244\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 718, Final loss (standarized): 0.2753977166407444\n",
      "Epoch: 1, Loss (standarized): 1.2119951850068065\n",
      "          Validation Loss (standardized): 0.9140220514753125\n",
      "Epoch: 501, Loss (standarized): 0.29240553404239844\n",
      "          Validation Loss (standardized): 0.30739261362950837\n",
      "Epoch: 1001, Loss (standarized): 0.22818844769396027\n",
      "          Validation Loss (standardized): 0.16691112279677303\n",
      "Epoch: 1501, Loss (standarized): 0.12503138045917367\n",
      "          Validation Loss (standardized): 0.1579905770972873\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 1546, Final loss (standarized): 0.2658166304419649\n",
      "Epoch: 1, Loss (standarized): 1.554949382651846\n",
      "          Validation Loss (standardized): 0.9381140766469475\n",
      "Epoch: 501, Loss (standarized): 0.4034382869797111\n",
      "          Validation Loss (standardized): 0.29830040104301786\n",
      "Epoch: 1001, Loss (standarized): 0.21438012038891174\n",
      "          Validation Loss (standardized): 0.1769374661012243\n",
      "Epoch: 1501, Loss (standarized): 0.16674866102451805\n",
      "          Validation Loss (standardized): 0.14865778696761298\n",
      "Epoch: 2001, Loss (standarized): 0.10792440558204418\n",
      "          Validation Loss (standardized): 0.13776138216761877\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 2225, Final loss (standarized): 0.16094342480582274\n",
      "Epoch: 1, Loss (standarized): 1.0938275141485685\n",
      "          Validation Loss (standardized): 0.9967030421025065\n",
      "Epoch: 501, Loss (standarized): 0.3119768512281995\n",
      "          Validation Loss (standardized): 0.29803068831134644\n",
      "Epoch: 1001, Loss (standarized): 0.22115015712105468\n",
      "          Validation Loss (standardized): 0.17930110129392154\n",
      "Epoch: 1501, Loss (standarized): 0.16823792822176187\n",
      "          Validation Loss (standardized): 0.1564299775436024\n",
      "Epoch: 2001, Loss (standarized): 0.11880029761644526\n",
      "          Validation Loss (standardized): 0.14678226406890282\n",
      "Epoch: 2501, Loss (standarized): 0.11709334801982153\n",
      "          Validation Loss (standardized): 0.15996834578697094\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 2669, Final loss (standarized): 0.09935414860393536\n",
      "Epoch: 1, Loss (standarized): 1.4981756536406245\n",
      "Epoch: 501, Loss (standarized): 0.41659896237839045\n",
      "Epoch: 1001, Loss (standarized): 0.3627370957235114\n",
      "Epoch: 1501, Loss (standarized): 0.320324905572283\n",
      "Epoch: 2001, Loss (standarized): 0.33054437133994236\n",
      "Epoch: 2501, Loss (standarized): 0.31452784711771137\n",
      "Epoch: 3001, Loss (standarized): 0.7548808960797865\n",
      "Epoch: 3501, Loss (standarized): 0.37871685964047574\n",
      "Epoch: 4001, Loss (standarized): 0.4355444663918898\n",
      "Epoch: 4501, Loss (standarized): 0.48894968217995366\n",
      "Epoch: 5001, Loss (standarized): 0.33362852547301075\n",
      "Epoch: 5501, Loss (standarized): 0.4353090245201842\n",
      "Epoch: 6001, Loss (standarized): 0.5242866308103612\n",
      "Epoch: 6501, Loss (standarized): 0.36547025158712687\n",
      "Epoch: 7001, Loss (standarized): 0.2662395352801136\n",
      "Epoch: 7501, Loss (standarized): 0.5052830399890749\n",
      "Epoch: 8001, Loss (standarized): 0.4533784862053626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_33460\\525374464.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8501, Loss (standarized): 0.5083368770581925\n",
      "Epoch: 9001, Loss (standarized): 0.9512662342448786\n",
      "Epoch: 9501, Loss (standarized): 0.9588423326117085\n",
      "Final epoch: 10000, Final loss (standarized): 0.9940408795674607\n",
      "Epoch: 1, Loss (standarized): 1.0249105142712152\n",
      "          Validation Loss (standardized): 1.0246838905105309\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 75, Final loss (standarized): 0.7397809885547824\n",
      "Epoch: 1, Loss (standarized): 1.514933278214602\n",
      "          Validation Loss (standardized): 1.0236188029521802\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 107, Final loss (standarized): 0.7467111465395508\n",
      "Epoch: 1, Loss (standarized): 1.296247735161058\n",
      "          Validation Loss (standardized): 0.9317635522374493\n",
      "Epoch: 501, Loss (standarized): 0.43959434453720403\n",
      "          Validation Loss (standardized): 0.4384682446252927\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 847, Final loss (standarized): 0.3990688014286008\n",
      "Epoch: 1, Loss (standarized): 2.012905557779002\n",
      "          Validation Loss (standardized): 0.9783087610214867\n",
      "Epoch: 501, Loss (standarized): 0.5331428274151773\n",
      "          Validation Loss (standardized): 0.39397055267922654\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 922, Final loss (standarized): 0.45777418378578993\n",
      "Epoch: 1, Loss (standarized): 1.2633149113515576\n",
      "          Validation Loss (standardized): 0.9443312153074044\n",
      "Epoch: 501, Loss (standarized): 0.5477937476107768\n",
      "          Validation Loss (standardized): 0.41362588002233563\n",
      "Epoch: 1001, Loss (standarized): 0.36968257692355744\n",
      "          Validation Loss (standardized): 0.3501783038152145\n",
      "Epoch: 1501, Loss (standarized): 0.3022697461249454\n",
      "          Validation Loss (standardized): 0.32774073957159133\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 1857, Final loss (standarized): 0.6674314847970321\n",
      "Epoch: 1, Loss (standarized): 1.2793615123218702\n",
      "          Validation Loss (standardized): 0.9608845900885185\n",
      "Epoch: 501, Loss (standarized): 0.544881354546435\n",
      "          Validation Loss (standardized): 0.44129212283308006\n",
      "Epoch: 1001, Loss (standarized): 0.4234566451369183\n",
      "          Validation Loss (standardized): 0.3495928902516522\n",
      "Epoch: 1501, Loss (standarized): 0.4456200156148372\n",
      "          Validation Loss (standardized): 0.35228840294397024\n",
      "Epoch: 2001, Loss (standarized): 0.4201754880991259\n",
      "          Validation Loss (standardized): 0.3218904903454389\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 2428, Final loss (standarized): 0.4069022662698312\n",
      "Epoch: 1, Loss (standarized): 2.510918848510401\n",
      "Epoch: 501, Loss (standarized): 0.9354976489009721\n",
      "Epoch: 1001, Loss (standarized): 0.9596887001375433\n",
      "Epoch: 1501, Loss (standarized): 1.0398932504245864\n",
      "Epoch: 2001, Loss (standarized): 0.9973242498436958\n",
      "Epoch: 2501, Loss (standarized): 0.9511222945553702\n",
      "Epoch: 3001, Loss (standarized): 0.9034244811708713\n",
      "Epoch: 3501, Loss (standarized): 0.9159682514401419\n",
      "Epoch: 4001, Loss (standarized): 0.880141158042599\n",
      "Epoch: 4501, Loss (standarized): 0.887720496943786\n",
      "Epoch: 5001, Loss (standarized): 0.9796048761045276\n",
      "Epoch: 5501, Loss (standarized): 0.9467993535865993\n",
      "Epoch: 6001, Loss (standarized): 0.8986996375204815\n",
      "Epoch: 6501, Loss (standarized): 1.0037972424768928\n",
      "Epoch: 7001, Loss (standarized): 0.8982188887560985\n",
      "Epoch: 7501, Loss (standarized): 0.8625317724626225\n",
      "Epoch: 8001, Loss (standarized): 1.0158426659548707\n",
      "Epoch: 8501, Loss (standarized): 0.9736143160886838\n",
      "Epoch: 9001, Loss (standarized): 1.0679893737086241\n",
      "Epoch: 9501, Loss (standarized): 0.997934587532143\n",
      "Final epoch: 10000, Final loss (standarized): 0.9416491495887285\n",
      "Epoch: 1, Loss (standarized): 1.8768258447531931\n",
      "          Validation Loss (standardized): 0.9366031020838309\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 12, Final loss (standarized): 0.9532754742296434\n",
      "Epoch: 1, Loss (standarized): 1.7982413174777379\n",
      "          Validation Loss (standardized): 0.9679106600431387\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 125, Final loss (standarized): 0.9336666828244582\n",
      "Epoch: 1, Loss (standarized): 1.953555860827319\n",
      "          Validation Loss (standardized): 1.0502098130554764\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 77, Final loss (standarized): 1.025054376163403\n",
      "Epoch: 1, Loss (standarized): 1.6637142248274677\n",
      "          Validation Loss (standardized): 0.9382923733334323\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 428, Final loss (standarized): 0.9712725624786449\n",
      "Epoch: 1, Loss (standarized): 2.0137518799312617\n",
      "          Validation Loss (standardized): 1.0021636348635716\n",
      "Epoch: 501, Loss (standarized): 0.812481689452923\n",
      "          Validation Loss (standardized): 0.7518250231110517\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 660, Final loss (standarized): 0.8663192355959438\n",
      "Epoch: 1, Loss (standarized): 2.1377297952387773\n",
      "          Validation Loss (standardized): 0.9363140447398283\n",
      "Epoch: 501, Loss (standarized): 0.9859626182640409\n",
      "          Validation Loss (standardized): 0.7673688600079838\n",
      "Epoch: 1001, Loss (standarized): 0.9483343532342545\n",
      "          Validation Loss (standardized): 0.9845230018243037\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 1072, Final loss (standarized): 1.045838646808364\n",
      "Epoch: 1, Loss (standarized): 0.8900049666602092\n",
      "Epoch: 501, Loss (standarized): 0.004909600827473147\n",
      "Epoch: 1001, Loss (standarized): 0.003888749447581194\n",
      "Epoch: 1501, Loss (standarized): 0.015876179972204515\n",
      "Epoch: 2001, Loss (standarized): 0.003656760330282491\n",
      "Epoch: 2501, Loss (standarized): 0.006267606531307495\n",
      "Epoch: 3001, Loss (standarized): 0.0022918911738514544\n",
      "Epoch: 3501, Loss (standarized): 0.004010933372326035\n",
      "Epoch: 4001, Loss (standarized): 0.0015396868298691339\n",
      "Epoch: 4501, Loss (standarized): 0.002924413178857806\n",
      "Epoch: 5001, Loss (standarized): 0.001679004122333794\n",
      "Epoch: 5501, Loss (standarized): 0.0031008498909647457\n",
      "Epoch: 6001, Loss (standarized): 0.0014171592856537837\n",
      "Epoch: 6501, Loss (standarized): 0.001159698457409477\n",
      "Epoch: 7001, Loss (standarized): 0.0017788722953201834\n",
      "Epoch: 7501, Loss (standarized): 0.0008804260330890866\n",
      "Epoch: 8001, Loss (standarized): 0.00550775962733035\n",
      "Epoch: 8501, Loss (standarized): 0.005686986677917783\n",
      "Epoch: 9001, Loss (standarized): 0.006685329918598873\n",
      "Epoch: 9501, Loss (standarized): 0.002847229043517278\n",
      "Final epoch: 10000, Final loss (standarized): 0.0011968523865138903\n",
      "Epoch: 1, Loss (standarized): 0.9665691292579062\n",
      "          Validation Loss (standardized): 0.7166344781095799\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 123, Final loss (standarized): 0.30270406849973674\n",
      "Epoch: 1, Loss (standarized): 0.9563383400750558\n",
      "          Validation Loss (standardized): 0.7548039888158908\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 348, Final loss (standarized): 0.039165411962691195\n",
      "Epoch: 1, Loss (standarized): 1.0089228945235529\n",
      "          Validation Loss (standardized): 0.7333629957168728\n",
      "Epoch: 501, Loss (standarized): 0.024219506394716532\n",
      "          Validation Loss (standardized): 0.04042820529776279\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 876, Final loss (standarized): 0.0022500635208210244\n",
      "Epoch: 1, Loss (standarized): 0.8566611299078528\n",
      "          Validation Loss (standardized): 0.6817996545284356\n",
      "Epoch: 501, Loss (standarized): 0.026064901904360758\n",
      "          Validation Loss (standardized): 0.0517277743118353\n",
      "Epoch: 1001, Loss (standarized): 0.0046093315312754676\n",
      "          Validation Loss (standardized): 0.014082076880826265\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 1339, Final loss (standarized): 0.0034547696128574014\n",
      "Epoch: 1, Loss (standarized): 0.8711691626730702\n",
      "          Validation Loss (standardized): 0.7862952482678887\n",
      "Epoch: 501, Loss (standarized): 0.03875517552211514\n",
      "          Validation Loss (standardized): 0.06903714280486258\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 947, Final loss (standarized): 0.0030562275123757134\n",
      "Epoch: 1, Loss (standarized): 0.8695641773504779\n",
      "          Validation Loss (standardized): 0.7542483674575352\n",
      "Epoch: 501, Loss (standarized): 0.04103407290827078\n",
      "          Validation Loss (standardized): 0.08284550889158153\n",
      "Epoch: 1001, Loss (standarized): 0.004087624770157382\n",
      "          Validation Loss (standardized): 0.020301977858313745\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 1437, Final loss (standarized): 0.003531515443576485\n",
      "Epoch: 1, Loss (standarized): 1.384635217770942\n",
      "Epoch: 501, Loss (standarized): 0.22252133233416443\n",
      "Epoch: 1001, Loss (standarized): 0.15759031376005295\n",
      "Epoch: 1501, Loss (standarized): 0.24351319072823374\n",
      "Epoch: 2001, Loss (standarized): 0.14753815490375408\n",
      "Epoch: 2501, Loss (standarized): 0.4043596710995425\n",
      "Epoch: 3001, Loss (standarized): 0.7909793825347783\n",
      "Epoch: 3501, Loss (standarized): 1.015294655941412\n",
      "Epoch: 4001, Loss (standarized): 1.1306970111208612\n",
      "Epoch: 4501, Loss (standarized): 1.080063359418872\n",
      "Epoch: 5001, Loss (standarized): 1.059735019367596\n",
      "Epoch: 5501, Loss (standarized): 0.9253652851020195\n",
      "Epoch: 6001, Loss (standarized): 0.9022068731918689\n",
      "Epoch: 6501, Loss (standarized): 1.0086799048344877\n",
      "Epoch: 7001, Loss (standarized): 1.0004254518302007\n",
      "Epoch: 7501, Loss (standarized): 1.0229926587505573\n",
      "Epoch: 8001, Loss (standarized): 0.9869490320408585\n",
      "Epoch: 8501, Loss (standarized): 1.0447265248366815\n",
      "Epoch: 9001, Loss (standarized): 0.9824405983746103\n",
      "Epoch: 9501, Loss (standarized): 0.9957404908032943\n",
      "Final epoch: 10000, Final loss (standarized): 1.0057886220873355\n",
      "Epoch: 1, Loss (standarized): 0.9053441579018922\n",
      "          Validation Loss (standardized): 0.759876365056104\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 58, Final loss (standarized): 0.412623132468771\n",
      "Epoch: 1, Loss (standarized): 0.7423282320257039\n",
      "          Validation Loss (standardized): 0.8227226343740671\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 132, Final loss (standarized): 0.3743928846644763\n",
      "Epoch: 1, Loss (standarized): 1.209204577267628\n",
      "          Validation Loss (standardized): 0.7530154127550418\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 153, Final loss (standarized): 0.410616132648407\n",
      "Epoch: 1, Loss (standarized): 1.01679207523307\n",
      "          Validation Loss (standardized): 0.7840222637805442\n",
      "Epoch: 501, Loss (standarized): 0.17290944140501752\n",
      "          Validation Loss (standardized): 0.17457688654965822\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 848, Final loss (standarized): 0.1964810854618519\n",
      "Epoch: 1, Loss (standarized): 0.9212085355985127\n",
      "          Validation Loss (standardized): 0.719765473085099\n",
      "Epoch: 501, Loss (standarized): 0.26854398958584663\n",
      "          Validation Loss (standardized): 0.2269090058858268\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 977, Final loss (standarized): 0.17333205004467617\n",
      "Epoch: 1, Loss (standarized): 0.9261895841440375\n",
      "          Validation Loss (standardized): 0.7828825812794158\n",
      "Epoch: 501, Loss (standarized): 0.1837085027455766\n",
      "          Validation Loss (standardized): 0.16024619374372284\n",
      "Epoch: 1001, Loss (standarized): 0.1710786426045135\n",
      "          Validation Loss (standardized): 0.17204656816470476\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 1189, Final loss (standarized): 0.21905442839948286\n",
      "Epoch: 1, Loss (standarized): 0.9757602216839917\n",
      "Epoch: 501, Loss (standarized): 0.8609990501287774\n",
      "Epoch: 1001, Loss (standarized): 1.0382951824712472\n",
      "Epoch: 1501, Loss (standarized): 1.0122656814008968\n",
      "Epoch: 2001, Loss (standarized): 0.9767205680155658\n",
      "Epoch: 2501, Loss (standarized): 1.0871721037269355\n",
      "Epoch: 3001, Loss (standarized): 1.0287587165502354\n",
      "Epoch: 3501, Loss (standarized): 1.0525208413438594\n",
      "Epoch: 4001, Loss (standarized): 1.025904480243373\n",
      "Epoch: 4501, Loss (standarized): 1.0246358585207056\n",
      "Epoch: 5001, Loss (standarized): 1.0075850407249674\n",
      "Epoch: 5501, Loss (standarized): 1.0358240767229245\n",
      "Epoch: 6001, Loss (standarized): 0.9888662122293376\n",
      "Epoch: 6501, Loss (standarized): 1.0304879766661519\n",
      "Epoch: 7001, Loss (standarized): 0.9930083535499996\n",
      "Epoch: 7501, Loss (standarized): 1.0522124004269613\n",
      "Epoch: 8001, Loss (standarized): 1.027744916387544\n",
      "Epoch: 8501, Loss (standarized): 1.0549446396802034\n",
      "Epoch: 9001, Loss (standarized): 1.0258042566366061\n",
      "Epoch: 9501, Loss (standarized): 1.0001177790380784\n",
      "Final epoch: 10000, Final loss (standarized): 1.0010618474833186\n",
      "Epoch: 1, Loss (standarized): 0.9918132586177129\n",
      "          Validation Loss (standardized): 0.7584073132803496\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 43, Final loss (standarized): 0.7327409838171477\n",
      "Epoch: 1, Loss (standarized): 1.265382512225468\n",
      "          Validation Loss (standardized): 0.8160659598207778\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 85, Final loss (standarized): 0.6056988351137071\n",
      "Epoch: 1, Loss (standarized): 0.91237404291037\n",
      "          Validation Loss (standardized): 0.7762266162535261\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 126, Final loss (standarized): 0.7614088842983198\n",
      "Epoch: 1, Loss (standarized): 1.2069795159603232\n",
      "          Validation Loss (standardized): 0.7190233715826909\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 248, Final loss (standarized): 0.5716573826366326\n",
      "Epoch: 1, Loss (standarized): 1.0398402174011334\n",
      "          Validation Loss (standardized): 0.7567287989951926\n",
      "Epoch: 501, Loss (standarized): 0.6248143335520573\n",
      "          Validation Loss (standardized): 0.5353643175168115\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 599, Final loss (standarized): 0.8777047521767036\n",
      "Epoch: 1, Loss (standarized): 1.236718692861034\n",
      "          Validation Loss (standardized): 0.7293181064403634\n",
      "Epoch: 501, Loss (standarized): 0.7003605960347473\n",
      "          Validation Loss (standardized): 0.5281873894719091\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 835, Final loss (standarized): 0.9933445994679333\n",
      "Epoch: 1, Loss (standarized): 1.6219897896143083\n",
      "Epoch: 501, Loss (standarized): 1.2090006627735286\n",
      "Epoch: 1001, Loss (standarized): 0.9712895106598378\n",
      "Epoch: 1501, Loss (standarized): 1.0315231118980355\n",
      "Epoch: 2001, Loss (standarized): 1.085056989981722\n",
      "Epoch: 2501, Loss (standarized): 1.012043066919246\n",
      "Epoch: 3001, Loss (standarized): 1.0442405918456397\n",
      "Epoch: 3501, Loss (standarized): 1.0015874388880104\n",
      "Epoch: 4001, Loss (standarized): 1.030112003853003\n",
      "Epoch: 4501, Loss (standarized): 1.041479269663691\n",
      "Epoch: 5001, Loss (standarized): 1.0469670486907734\n",
      "Epoch: 5501, Loss (standarized): 0.9720696842693488\n",
      "Epoch: 6001, Loss (standarized): 1.0203444426558017\n",
      "Epoch: 6501, Loss (standarized): 0.9929701453557944\n",
      "Epoch: 7001, Loss (standarized): 1.021674312476611\n",
      "Epoch: 7501, Loss (standarized): 1.082886831498445\n",
      "Epoch: 8001, Loss (standarized): 1.128981589095959\n",
      "Epoch: 8501, Loss (standarized): 1.0926644550216298\n",
      "Epoch: 9001, Loss (standarized): 1.0160703102749533\n",
      "Epoch: 9501, Loss (standarized): 1.026940113349889\n",
      "Final epoch: 10000, Final loss (standarized): 1.1444940184248127\n",
      "Epoch: 1, Loss (standarized): 0.9816968741021203\n",
      "          Validation Loss (standardized): 0.7614630037071421\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 68, Final loss (standarized): 0.6729335894382765\n",
      "Epoch: 1, Loss (standarized): 1.1965320980026477\n",
      "          Validation Loss (standardized): 0.7260486077580319\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 38, Final loss (standarized): 0.7549927393477509\n",
      "Epoch: 1, Loss (standarized): 1.0457654165031531\n",
      "          Validation Loss (standardized): 0.7817662037464658\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 120, Final loss (standarized): 0.7173666540688789\n",
      "Epoch: 1, Loss (standarized): 0.9847117221751631\n",
      "          Validation Loss (standardized): 0.761782795780006\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 269, Final loss (standarized): 0.9039281403384354\n",
      "Epoch: 1, Loss (standarized): 1.2460065571308916\n",
      "          Validation Loss (standardized): 0.7439420286448407\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 330, Final loss (standarized): 1.0167392186214852\n",
      "Epoch: 1, Loss (standarized): 1.2438988623434828\n",
      "          Validation Loss (standardized): 0.7535629102534513\n",
      "Epoch: 501, Loss (standarized): 0.9474629498125078\n",
      "          Validation Loss (standardized): 0.968977687111255\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 680, Final loss (standarized): 1.0676291050990425\n",
      "Epoch: 1, Loss (standarized): 3.1848926863906164\n",
      "Epoch: 501, Loss (standarized): 0.03158753519111384\n",
      "Epoch: 1001, Loss (standarized): 0.02477375993032107\n",
      "Epoch: 1501, Loss (standarized): 0.0069323640238799465\n",
      "Epoch: 2001, Loss (standarized): 0.004292460785393583\n",
      "Epoch: 2501, Loss (standarized): 0.0026489137486038926\n",
      "Epoch: 3001, Loss (standarized): 0.0030397396517808997\n",
      "Epoch: 3501, Loss (standarized): 0.004826131185848374\n",
      "Epoch: 4001, Loss (standarized): 0.003167416886974626\n",
      "Epoch: 4501, Loss (standarized): 0.0019898926098853567\n",
      "Epoch: 5001, Loss (standarized): 0.0036761855702251195\n",
      "Epoch: 5501, Loss (standarized): 0.004144848621643518\n",
      "Epoch: 6001, Loss (standarized): 0.0048479882713185745\n",
      "Epoch: 6501, Loss (standarized): 0.003542117676613026\n",
      "Epoch: 7001, Loss (standarized): 0.0020680790489710386\n",
      "Epoch: 7501, Loss (standarized): 0.0021616026497926536\n",
      "Epoch: 8001, Loss (standarized): 0.00265934465609355\n",
      "Epoch: 8501, Loss (standarized): 0.005144257838928087\n",
      "Epoch: 9001, Loss (standarized): 0.0018278500633878356\n",
      "Epoch: 9501, Loss (standarized): 0.003588346604350935\n",
      "Final epoch: 10000, Final loss (standarized): 0.002825671797831447\n",
      "Epoch: 1, Loss (standarized): 1.969954405273485\n",
      "          Validation Loss (standardized): 0.9367519504391839\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 97, Final loss (standarized): 0.2810702077683259\n",
      "Epoch: 1, Loss (standarized): 3.3703876675121567\n",
      "          Validation Loss (standardized): 1.9147007001659693\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 148, Final loss (standarized): 0.04590846116422284\n",
      "Epoch: 1, Loss (standarized): 2.1852290134646997\n",
      "          Validation Loss (standardized): 1.106313183326733\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 120, Final loss (standarized): 0.2768293646837768\n",
      "Epoch: 1, Loss (standarized): 2.2167873011150534\n",
      "          Validation Loss (standardized): 0.7111388528102935\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 295, Final loss (standarized): 0.2766864372199297\n",
      "Epoch: 1, Loss (standarized): 1.8933900535830124\n",
      "          Validation Loss (standardized): 0.7876664436084754\n",
      "Epoch: 501, Loss (standarized): 0.04143299342513783\n",
      "          Validation Loss (standardized): 0.07915412020449905\n",
      "Epoch: 1001, Loss (standarized): 0.027965669806741693\n",
      "          Validation Loss (standardized): 0.05809485808066686\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 1070, Final loss (standarized): 0.026116745353715283\n",
      "Epoch: 1, Loss (standarized): 1.4875553199530445\n",
      "          Validation Loss (standardized): 0.7392745183762883\n",
      "Epoch: 501, Loss (standarized): 0.056371986729179945\n",
      "          Validation Loss (standardized): 0.10996309792326318\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 808, Final loss (standarized): 0.047906125583093345\n",
      "Epoch: 1, Loss (standarized): 1.7869004408038816\n",
      "Epoch: 501, Loss (standarized): 0.13479727118595464\n",
      "Epoch: 1001, Loss (standarized): 0.08900399074735352\n",
      "Epoch: 1501, Loss (standarized): 0.08880711702799349\n",
      "Epoch: 2001, Loss (standarized): 0.07010952708531654\n",
      "Epoch: 2501, Loss (standarized): 0.08428036848558518\n",
      "Epoch: 3001, Loss (standarized): 0.09398732672835114\n",
      "Epoch: 3501, Loss (standarized): 0.09140138058952074\n",
      "Epoch: 4001, Loss (standarized): 0.06599408594779338\n",
      "Epoch: 4501, Loss (standarized): 0.06514620909852151\n",
      "Epoch: 5001, Loss (standarized): 0.0803566102267064\n",
      "Epoch: 5501, Loss (standarized): 0.06371410415891174\n",
      "Epoch: 6001, Loss (standarized): 0.06251865235056364\n",
      "Epoch: 6501, Loss (standarized): 0.06631893277529555\n",
      "Epoch: 7001, Loss (standarized): 0.05402648611631447\n",
      "Epoch: 7501, Loss (standarized): 0.09230878569553048\n",
      "Epoch: 8001, Loss (standarized): 0.09175224548372753\n",
      "Epoch: 8501, Loss (standarized): 0.06888215051850033\n",
      "Epoch: 9001, Loss (standarized): 0.06298545118218805\n",
      "Epoch: 9501, Loss (standarized): 0.06832821794539679\n",
      "Final epoch: 10000, Final loss (standarized): 0.055679908790885246\n",
      "Epoch: 1, Loss (standarized): 1.5032401033810534\n",
      "          Validation Loss (standardized): 0.7437057321291656\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 156, Final loss (standarized): 0.18720929967835434\n",
      "Epoch: 1, Loss (standarized): 2.9334388696850353\n",
      "          Validation Loss (standardized): 0.9634182387502159\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 239, Final loss (standarized): 0.174296661980961\n",
      "Epoch: 1, Loss (standarized): 2.2071386574544603\n",
      "          Validation Loss (standardized): 0.7916301729893168\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 265, Final loss (standarized): 0.122264753717681\n",
      "Epoch: 1, Loss (standarized): 4.693162346385378\n",
      "          Validation Loss (standardized): 0.8164393010703128\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 455, Final loss (standarized): 0.14760564934045498\n",
      "Epoch: 1, Loss (standarized): 2.223040481016961\n",
      "          Validation Loss (standardized): 2.223974057580547\n",
      "Epoch: 501, Loss (standarized): 0.08865861190156944\n",
      "          Validation Loss (standardized): 0.10909691616673975\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 752, Final loss (standarized): 0.16667404818383907\n",
      "Epoch: 1, Loss (standarized): 0.9913948294454458\n",
      "          Validation Loss (standardized): 0.8735842511016441\n",
      "Epoch: 501, Loss (standarized): 0.10718363812408772\n",
      "          Validation Loss (standardized): 0.09193960200169066\n",
      "Epoch: 1001, Loss (standarized): 0.11239285506833706\n",
      "          Validation Loss (standardized): 0.09519416938719125\n",
      "Epoch: 1501, Loss (standarized): 0.07601215355043242\n",
      "          Validation Loss (standardized): 0.06863283704706052\n",
      "Epoch: 2001, Loss (standarized): 0.18955240510484916\n",
      "          Validation Loss (standardized): 0.07221740023817878\n",
      "Epoch: 2501, Loss (standarized): 0.11944446273022327\n",
      "          Validation Loss (standardized): 0.06719664051371267\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 2545, Final loss (standarized): 0.17836680288936985\n",
      "Epoch: 1, Loss (standarized): 1.7202275964934886\n",
      "Epoch: 501, Loss (standarized): 0.3132833208623057\n",
      "Epoch: 1001, Loss (standarized): 0.2824567786754839\n",
      "Epoch: 1501, Loss (standarized): 0.19676375746506827\n",
      "Epoch: 2001, Loss (standarized): 0.2588917209889531\n",
      "Epoch: 2501, Loss (standarized): 0.1747770120887044\n",
      "Epoch: 3001, Loss (standarized): 0.18461258296091823\n",
      "Epoch: 3501, Loss (standarized): 0.33409769793263433\n",
      "Epoch: 4001, Loss (standarized): 0.22439191165214545\n",
      "Epoch: 4501, Loss (standarized): 0.19993633039815095\n",
      "Epoch: 5001, Loss (standarized): 0.24054345289159917\n",
      "Epoch: 5501, Loss (standarized): 0.26479479229218983\n",
      "Epoch: 6001, Loss (standarized): 0.20938621051164766\n",
      "Epoch: 6501, Loss (standarized): 0.2577609884006752\n",
      "Epoch: 7001, Loss (standarized): 0.40461469286310775\n",
      "Epoch: 7501, Loss (standarized): 0.20291876760888397\n",
      "Epoch: 8001, Loss (standarized): 0.269311370483562\n",
      "Epoch: 8501, Loss (standarized): 0.2843709540292883\n",
      "Epoch: 9001, Loss (standarized): 0.2818939241841562\n",
      "Epoch: 9501, Loss (standarized): 0.32436136223227746\n",
      "Final epoch: 10000, Final loss (standarized): 0.20394633055987993\n",
      "Epoch: 1, Loss (standarized): 2.595457285083065\n",
      "          Validation Loss (standardized): 0.9004003794014243\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 54, Final loss (standarized): 0.5718211574393745\n",
      "Epoch: 1, Loss (standarized): 3.911649924891618\n",
      "          Validation Loss (standardized): 1.3151086895182593\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 235, Final loss (standarized): 0.31988154531853313\n",
      "Epoch: 1, Loss (standarized): 3.1526692571192863\n",
      "          Validation Loss (standardized): 0.7167583397811716\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 494, Final loss (standarized): 0.2603720172548684\n",
      "Epoch: 1, Loss (standarized): 1.711893234701513\n",
      "          Validation Loss (standardized): 0.9412437311320154\n",
      "Epoch: 501, Loss (standarized): 0.24732711889713632\n",
      "          Validation Loss (standardized): 0.2790371656553221\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 638, Final loss (standarized): 0.2330386778054162\n",
      "Epoch: 1, Loss (standarized): 2.110501463065509\n",
      "          Validation Loss (standardized): 0.7948399883543084\n",
      "Epoch: 501, Loss (standarized): 0.40317566023885776\n",
      "          Validation Loss (standardized): 0.20843376565456836\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 996, Final loss (standarized): 0.24643447050924847\n",
      "Epoch: 1, Loss (standarized): 1.4068972256829086\n",
      "          Validation Loss (standardized): 0.8309826665159057\n",
      "Epoch: 501, Loss (standarized): 0.26819738398533616\n",
      "          Validation Loss (standardized): 0.2644737943876667\n",
      "Epoch: 1001, Loss (standarized): 0.2658030091588111\n",
      "          Validation Loss (standardized): 0.27300002030566584\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 1157, Final loss (standarized): 0.32625532270877805\n",
      "Epoch: 1, Loss (standarized): 2.1661707352238415\n",
      "Epoch: 501, Loss (standarized): 0.4007578840441839\n",
      "Epoch: 1001, Loss (standarized): 0.5940571421965531\n",
      "Epoch: 1501, Loss (standarized): 0.49332182068984876\n",
      "Epoch: 2001, Loss (standarized): 0.3788549357351815\n",
      "Epoch: 2501, Loss (standarized): 0.42272044202643205\n",
      "Epoch: 3001, Loss (standarized): 0.5031429930107858\n",
      "Epoch: 3501, Loss (standarized): 0.5493026770213949\n",
      "Epoch: 4001, Loss (standarized): 0.5021995246071549\n",
      "Epoch: 4501, Loss (standarized): 0.5633127409451358\n",
      "Epoch: 5001, Loss (standarized): 0.480216896428195\n",
      "Epoch: 5501, Loss (standarized): 0.4085143368305003\n",
      "Epoch: 6001, Loss (standarized): 0.47215985750766276\n",
      "Epoch: 6501, Loss (standarized): 0.6161548707101215\n",
      "Epoch: 7001, Loss (standarized): 0.6305304106725281\n",
      "Epoch: 7501, Loss (standarized): 0.3773599668566543\n",
      "Epoch: 8001, Loss (standarized): 0.5216072452374602\n",
      "Epoch: 8501, Loss (standarized): 0.3290379206910107\n",
      "Epoch: 9001, Loss (standarized): 0.3301049734474158\n",
      "Epoch: 9501, Loss (standarized): 0.33019581148694227\n",
      "Final epoch: 10000, Final loss (standarized): 0.44306064308223336\n",
      "Epoch: 1, Loss (standarized): 12.488185428791843\n",
      "          Validation Loss (standardized): 1.9845737074145384\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 23, Final loss (standarized): 0.9975452909060571\n",
      "Epoch: 1, Loss (standarized): 5.522097145797423\n",
      "          Validation Loss (standardized): 0.7778722180557507\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 67, Final loss (standarized): 0.6729604738445324\n",
      "Epoch: 1, Loss (standarized): 4.301574762653811\n",
      "          Validation Loss (standardized): 1.3065797714977083\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 322, Final loss (standarized): 0.46439120870325173\n",
      "Epoch: 1, Loss (standarized): 15.469084551650774\n",
      "          Validation Loss (standardized): 0.9751025185185626\n",
      "Epoch: 501, Loss (standarized): 0.5242373727622186\n",
      "          Validation Loss (standardized): 0.3969018592955667\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 556, Final loss (standarized): 0.6536309821647046\n",
      "Epoch: 1, Loss (standarized): 13.906053603654206\n",
      "          Validation Loss (standardized): 1.2717814220581027\n",
      "Epoch: 501, Loss (standarized): 0.664802223523056\n",
      "          Validation Loss (standardized): 0.44322163577717677\n",
      "Epoch: 1001, Loss (standarized): 0.40033280003491495\n",
      "          Validation Loss (standardized): 0.4350457980150982\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 1212, Final loss (standarized): 0.3797519387791366\n",
      "Epoch: 1, Loss (standarized): 12.218500038606464\n",
      "          Validation Loss (standardized): 2.575062563206968\n",
      "Epoch: 501, Loss (standarized): 0.4159533477005444\n",
      "          Validation Loss (standardized): 0.34770657636828645\n",
      "Epoch: 1001, Loss (standarized): 0.4290456539873922\n",
      "          Validation Loss (standardized): 0.2638472753526044\n",
      "Epoch: 1501, Loss (standarized): 0.3616655136151475\n",
      "          Validation Loss (standardized): 0.25464601833252426\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 1527, Final loss (standarized): 0.37773512538161436\n",
      "Epoch: 1, Loss (standarized): 1.676049143833711\n",
      "Epoch: 501, Loss (standarized): 0.0587595016455493\n",
      "Epoch: 1001, Loss (standarized): 0.0056646155989466505\n",
      "Epoch: 1501, Loss (standarized): 0.004898801874163177\n",
      "Epoch: 2001, Loss (standarized): 0.0034682698804935543\n",
      "Epoch: 2501, Loss (standarized): 0.005366968353593216\n",
      "Epoch: 3001, Loss (standarized): 0.0019137602767984071\n",
      "Epoch: 3501, Loss (standarized): 0.002589842344191586\n",
      "Epoch: 4001, Loss (standarized): 0.013299642457635492\n",
      "Epoch: 4501, Loss (standarized): 0.0031419174050222078\n",
      "Epoch: 5001, Loss (standarized): 0.002618594989385688\n",
      "Epoch: 5501, Loss (standarized): 0.00369770128393542\n",
      "Epoch: 6001, Loss (standarized): 0.0024433074226114858\n",
      "Epoch: 6501, Loss (standarized): 0.003980142156881012\n",
      "Epoch: 7001, Loss (standarized): 0.002286166856653258\n",
      "Epoch: 7501, Loss (standarized): 0.0038358108407451795\n",
      "Epoch: 8001, Loss (standarized): 0.0019367058986518107\n",
      "Epoch: 8501, Loss (standarized): 0.0023847973115224703\n",
      "Epoch: 9001, Loss (standarized): 0.0032614792954241824\n",
      "Epoch: 9501, Loss (standarized): 0.0015867333403380539\n",
      "Final epoch: 10000, Final loss (standarized): 0.0015838698970089208\n",
      "Epoch: 1, Loss (standarized): 1.716647198410974\n",
      "          Validation Loss (standardized): 0.7357199753696807\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 145, Final loss (standarized): 0.06399325131381688\n",
      "Epoch: 1, Loss (standarized): 0.7743542144594056\n",
      "          Validation Loss (standardized): 0.6937981700479351\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 192, Final loss (standarized): 0.05019705070558237\n",
      "Epoch: 1, Loss (standarized): 4.187200410038233\n",
      "          Validation Loss (standardized): 1.303352967212806\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 223, Final loss (standarized): 0.30053456823327124\n",
      "Epoch: 1, Loss (standarized): 1.527961007690646\n",
      "          Validation Loss (standardized): 0.9459772598934977\n",
      "Epoch: 501, Loss (standarized): 0.026630248937266877\n",
      "          Validation Loss (standardized): 0.055310447605182944\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 971, Final loss (standarized): 0.02395476600127713\n",
      "Epoch: 1, Loss (standarized): 1.0453611718455302\n",
      "          Validation Loss (standardized): 0.8570382367075191\n",
      "Epoch: 501, Loss (standarized): 0.027600236268328533\n",
      "          Validation Loss (standardized): 0.060784385073289045\n",
      "Epoch: 1001, Loss (standarized): 0.01455668550994994\n",
      "          Validation Loss (standardized): 0.03345213547739051\n",
      "Epoch: 1501, Loss (standarized): 0.00530982027208666\n",
      "          Validation Loss (standardized): 0.021747283409119376\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 1505, Final loss (standarized): 0.0052905936322664385\n",
      "Epoch: 1, Loss (standarized): 1.5458414325023155\n",
      "          Validation Loss (standardized): 0.7069118374690391\n",
      "Epoch: 501, Loss (standarized): 0.03289813128161008\n",
      "          Validation Loss (standardized): 0.06667222520007327\n",
      "Epoch: 1001, Loss (standarized): 0.0294365363799892\n",
      "          Validation Loss (standardized): 0.06021101593306514\n",
      "Epoch: 1501, Loss (standarized): 0.010326452712358804\n",
      "          Validation Loss (standardized): 0.036850801571768156\n",
      "Epoch: 2001, Loss (standarized): 0.00794991327686266\n",
      "          Validation Loss (standardized): 0.03385127460520332\n",
      "Epoch: 2501, Loss (standarized): 0.003433405365884414\n",
      "          Validation Loss (standardized): 0.021424434299123253\n",
      "Epoch: 3001, Loss (standarized): 0.002423678682593076\n",
      "          Validation Loss (standardized): 0.019339174925833064\n",
      "Epoch: 3501, Loss (standarized): 0.0038554885193019055\n",
      "          Validation Loss (standardized): 0.01713631817020525\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 3865, Final loss (standarized): 0.003206545263499122\n",
      "Epoch: 1, Loss (standarized): 1.0200164542730186\n",
      "Epoch: 501, Loss (standarized): 0.13194180302892564\n",
      "Epoch: 1001, Loss (standarized): 0.12069513294534784\n",
      "Epoch: 1501, Loss (standarized): 0.18972514004942267\n",
      "Epoch: 2001, Loss (standarized): 0.07533049708407241\n",
      "Epoch: 2501, Loss (standarized): 0.07374307598973226\n",
      "Epoch: 3001, Loss (standarized): 0.07230215461826572\n",
      "Epoch: 3501, Loss (standarized): 0.06408831129536863\n",
      "Epoch: 4001, Loss (standarized): 0.07748593879722941\n",
      "Epoch: 4501, Loss (standarized): 0.09315454217774163\n",
      "Epoch: 5001, Loss (standarized): 0.09746140184115405\n",
      "Epoch: 5501, Loss (standarized): 0.06646414958748177\n",
      "Epoch: 6001, Loss (standarized): 0.05774601562509088\n",
      "Epoch: 6501, Loss (standarized): 0.10584493052858163\n",
      "Epoch: 7001, Loss (standarized): 0.07747479979313637\n",
      "Epoch: 7501, Loss (standarized): 0.06100189871587457\n",
      "Epoch: 8001, Loss (standarized): 0.06680080441036035\n",
      "Epoch: 8501, Loss (standarized): 0.07174396520437346\n",
      "Epoch: 9001, Loss (standarized): 0.05518092200944482\n",
      "Epoch: 9501, Loss (standarized): 0.06422276813100912\n",
      "Final epoch: 10000, Final loss (standarized): 0.056586286708193066\n",
      "Epoch: 1, Loss (standarized): 1.361431266636803\n",
      "          Validation Loss (standardized): 0.9774542532512706\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 130, Final loss (standarized): 0.19565679205494818\n",
      "Epoch: 1, Loss (standarized): 3.4395598317019087\n",
      "          Validation Loss (standardized): 0.9859448048277695\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 214, Final loss (standarized): 0.20941859982795075\n",
      "Epoch: 1, Loss (standarized): 0.7324128022143026\n",
      "          Validation Loss (standardized): 0.7585350493084939\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 364, Final loss (standarized): 0.1706412511086005\n",
      "Epoch: 1, Loss (standarized): 1.4604472109049473\n",
      "          Validation Loss (standardized): 0.7755281175251028\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 488, Final loss (standarized): 0.09797980815278833\n",
      "Epoch: 1, Loss (standarized): 3.1333022574205676\n",
      "          Validation Loss (standardized): 0.9526723086681435\n",
      "Epoch: 501, Loss (standarized): 0.18253040512344026\n",
      "          Validation Loss (standardized): 0.14156144736738546\n",
      "Epoch: 1001, Loss (standarized): 0.11717522030432123\n",
      "          Validation Loss (standardized): 0.10313441676607804\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 1017, Final loss (standarized): 0.10557531495391095\n",
      "Epoch: 1, Loss (standarized): 2.9511054889077175\n",
      "          Validation Loss (standardized): 1.508711777224582\n",
      "Epoch: 501, Loss (standarized): 0.18175008252202968\n",
      "          Validation Loss (standardized): 0.09957402290187804\n",
      "Epoch: 1001, Loss (standarized): 0.11560243249963446\n",
      "          Validation Loss (standardized): 0.07080505926615191\n",
      "Epoch: 1501, Loss (standarized): 0.09375700358336084\n",
      "          Validation Loss (standardized): 0.06824771838694979\n",
      "Epoch: 2001, Loss (standarized): 0.12448240393990877\n",
      "          Validation Loss (standardized): 0.06564694687950567\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 2073, Final loss (standarized): 0.0833600696455053\n",
      "Epoch: 1, Loss (standarized): 1.8475054598258116\n",
      "Epoch: 501, Loss (standarized): 0.17153525899967587\n",
      "Epoch: 1001, Loss (standarized): 0.2207856665602961\n",
      "Epoch: 1501, Loss (standarized): 0.21414145386018735\n",
      "Epoch: 2001, Loss (standarized): 0.2273918419961405\n",
      "Epoch: 2501, Loss (standarized): 0.2040288455851801\n",
      "Epoch: 3001, Loss (standarized): 0.19839556016122684\n",
      "Epoch: 3501, Loss (standarized): 0.24325247279879475\n",
      "Epoch: 4001, Loss (standarized): 0.17032608003050725\n",
      "Epoch: 4501, Loss (standarized): 0.17106855970418178\n",
      "Epoch: 5001, Loss (standarized): 0.2327837929133823\n",
      "Epoch: 5501, Loss (standarized): 0.14608775795641332\n",
      "Epoch: 6001, Loss (standarized): 0.2501130184939302\n",
      "Epoch: 6501, Loss (standarized): 0.1748196463004882\n",
      "Epoch: 7001, Loss (standarized): 0.2394303912239142\n",
      "Epoch: 7501, Loss (standarized): 0.11328752884022843\n",
      "Epoch: 8001, Loss (standarized): 0.15295822915150356\n",
      "Epoch: 8501, Loss (standarized): 0.16876940697811812\n",
      "Epoch: 9001, Loss (standarized): 0.24227115451626402\n",
      "Epoch: 9501, Loss (standarized): 0.20038901418120375\n",
      "Final epoch: 10000, Final loss (standarized): 0.17604705200137555\n",
      "Epoch: 1, Loss (standarized): 3.4100671614736244\n",
      "          Validation Loss (standardized): 1.9409257668570268\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 21, Final loss (standarized): 0.8887846196742526\n",
      "Epoch: 1, Loss (standarized): 3.6252798458393225\n",
      "          Validation Loss (standardized): 1.0200886380689933\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 116, Final loss (standarized): 0.543787994430099\n",
      "Epoch: 1, Loss (standarized): 1.0206990680103893\n",
      "          Validation Loss (standardized): 0.7035235340714078\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 334, Final loss (standarized): 0.21066761225451794\n",
      "Epoch: 1, Loss (standarized): 1.584297923706086\n",
      "          Validation Loss (standardized): 0.7259857270080432\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 407, Final loss (standarized): 0.21140618557973545\n",
      "Epoch: 1, Loss (standarized): 2.1152867805758153\n",
      "          Validation Loss (standardized): 1.1785959699183999\n",
      "Epoch: 501, Loss (standarized): 0.232343517096749\n",
      "          Validation Loss (standardized): 0.20035713779583017\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 955, Final loss (standarized): 0.22002530138945725\n",
      "Epoch: 1, Loss (standarized): 2.8857758056025973\n",
      "          Validation Loss (standardized): 0.9147661655666309\n",
      "Epoch: 501, Loss (standarized): 0.281415074364764\n",
      "          Validation Loss (standardized): 0.20783953909138703\n",
      "Epoch: 1001, Loss (standarized): 0.2585872513513209\n",
      "          Validation Loss (standardized): 0.24142698233821225\n",
      "Epoch: 1501, Loss (standarized): 0.16607145223493197\n",
      "          Validation Loss (standardized): 0.228021855437025\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 1690, Final loss (standarized): 0.2663345307893316\n",
      "Epoch: 1, Loss (standarized): 3.9826974176461953\n",
      "Epoch: 501, Loss (standarized): 0.3818339500860536\n",
      "Epoch: 1001, Loss (standarized): 0.2954454696636747\n",
      "Epoch: 1501, Loss (standarized): 0.33283415457433985\n",
      "Epoch: 2001, Loss (standarized): 0.30682269488194475\n",
      "Epoch: 2501, Loss (standarized): 0.5314188142189696\n",
      "Epoch: 3001, Loss (standarized): 0.5378005710849217\n",
      "Epoch: 3501, Loss (standarized): 0.4054516282994827\n",
      "Epoch: 4001, Loss (standarized): 0.4683608209074189\n",
      "Epoch: 4501, Loss (standarized): 0.3937184010029357\n",
      "Epoch: 5001, Loss (standarized): 0.4273620242194882\n",
      "Epoch: 5501, Loss (standarized): 0.4948721152238872\n",
      "Epoch: 6001, Loss (standarized): 0.4629652665669403\n",
      "Epoch: 6501, Loss (standarized): 0.4183836295792473\n",
      "Epoch: 7001, Loss (standarized): 0.4421138510646672\n",
      "Epoch: 7501, Loss (standarized): 0.47849837892168945\n",
      "Epoch: 8001, Loss (standarized): 0.36842402729830326\n",
      "Epoch: 8501, Loss (standarized): 0.4380429032072293\n",
      "Epoch: 9001, Loss (standarized): 0.5259790731751276\n",
      "Epoch: 9501, Loss (standarized): 0.5364399326367514\n",
      "Final epoch: 10000, Final loss (standarized): 0.31847391641594736\n",
      "Epoch: 1, Loss (standarized): 2.0162607707066\n",
      "          Validation Loss (standardized): 0.8023723704150929\n",
      "Early stopping triggered. No improvement in validation loss for 10 epochs.\n",
      "Final epoch: 12, Final loss (standarized): 0.7631013488335573\n",
      "Epoch: 1, Loss (standarized): 10.97857462333237\n",
      "          Validation Loss (standardized): 1.6988388474181153\n",
      "Early stopping triggered. No improvement in validation loss for 20 epochs.\n",
      "Final epoch: 74, Final loss (standarized): 0.8425921880014704\n",
      "Epoch: 1, Loss (standarized): 7.381846300424089\n",
      "          Validation Loss (standardized): 0.8008308251987372\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 228, Final loss (standarized): 0.6525314535457891\n",
      "Epoch: 1, Loss (standarized): 26.05297540612634\n",
      "          Validation Loss (standardized): 3.8627718961079553\n",
      "Epoch: 501, Loss (standarized): 0.5611955522255047\n",
      "          Validation Loss (standardized): 0.4692853416940785\n",
      "Epoch: 1001, Loss (standarized): 0.6171271868730981\n",
      "          Validation Loss (standardized): 0.33047347420133233\n",
      "Early stopping triggered. No improvement in validation loss for 100 epochs.\n",
      "Final epoch: 1181, Final loss (standarized): 0.48810907880644083\n",
      "Epoch: 1, Loss (standarized): 2.623892362801384\n",
      "          Validation Loss (standardized): 0.9579531760398392\n",
      "Epoch: 501, Loss (standarized): 0.42516283718362813\n",
      "          Validation Loss (standardized): 0.3416436479657176\n",
      "Early stopping triggered. No improvement in validation loss for 200 epochs.\n",
      "Final epoch: 547, Final loss (standarized): 0.3844818581361691\n",
      "Epoch: 1, Loss (standarized): 3.728648341394322\n",
      "          Validation Loss (standardized): 0.7998267523153578\n",
      "Epoch: 501, Loss (standarized): 0.539921097508877\n",
      "          Validation Loss (standardized): 0.3720455179678403\n",
      "Epoch: 1001, Loss (standarized): 0.4971504651138773\n",
      "          Validation Loss (standardized): 0.3198066881380569\n",
      "Epoch: 1501, Loss (standarized): 0.4055990763404285\n",
      "          Validation Loss (standardized): 0.30158718628665454\n",
      "Early stopping triggered. No improvement in validation loss for 500 epochs.\n",
      "Final epoch: 1978, Final loss (standarized): 0.29979101324682433\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "archs = [[1, 20, 20, 1]]\n",
    "funs = [sigmoid, tanh, relu, leaky_relu]  # Testy pokazują, że leaky_relu tutaj średnio sobie radził, więc usunąłem, żeby lepiej działało\n",
    "fun_derivs = [sigmoid_deriv, tanh_deriv, relu_deriv, leaky_relu_deriv]\n",
    "dropouts = [0, 0.1, 0.3, 0.5]\n",
    "early_stops = [0, 10, 20, 50, 100, 200, 500]  # Patience = 1 jest za mały tak samo = 5, więc usunąłem\n",
    "initialization = [\"xavier\", \"xavier\", \"he\", \"he\"]\n",
    "results = { \"Arch\": [],\n",
    "            \"Fun\": [],\n",
    "            \"Test_loss\": [],\n",
    "            \"Train_results\": [], \n",
    "            \"Dropout\": [],\n",
    "            \"Patience\": [],\n",
    "            \"Net\": []}\n",
    "\n",
    "for arch in archs:\n",
    "    for i in range(len(funs)):\n",
    "        for dropout in dropouts:\n",
    "            for early_stop in early_stops:\n",
    "                net = MLP(arch, act_fun=funs[i], act_derivative=fun_derivs[i], out_fun=linear, out_derivative=linear_deriv, init_type=initialization[i], dropout_rate=dropout)\n",
    "                curr_result = net.train(x = x_train, y = y_train, epochs = 5000, optimizer=Adam(), batch_size=10, early_stopping_patience=early_stop, val_x=x_test, val_y=y_test)\n",
    "                y_pred = net.predict(x_test)\n",
    "                test_loss = mse(y_pred, y_test)\n",
    "                results[\"Arch\"].append(arch)\n",
    "                results[\"Fun\"].append(funs[i])\n",
    "                results[\"Test_loss\"].append(test_loss)\n",
    "                results[\"Train_results\"].append(curr_result)\n",
    "                results[\"Dropout\"].append(dropout)\n",
    "                results[\"Patience\"].append(early_stop)\n",
    "                results[\"Net\"].append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bd1cac-72d5-4b02-b0f2-8720a62a56b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Test_loss</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E79E2C7C0&gt;</td>\n",
       "      <td>77.685665</td>\n",
       "      <td>[1.5458414325023155, 1.152613822473693, 0.8876...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F1AC60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>83.211048</td>\n",
       "      <td>[0.8566611299078528, 0.9421270328243416, 0.849...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E3AEA0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>107.560954</td>\n",
       "      <td>[0.8695641773504779, 0.8206667752586556, 0.802...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79ECB1A0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function relu at 0x0000029E79E2C5E0&gt;</td>\n",
       "      <td>116.231826</td>\n",
       "      <td>[3.1848926863906164, 1.099435969906802, 0.8974...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E587F0C20&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E79E2C7C0&gt;</td>\n",
       "      <td>119.761218</td>\n",
       "      <td>[1.676049143833711, 0.7446093420303619, 0.8395...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E92570&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>5389.200397</td>\n",
       "      <td>[1.953555860827319, 2.506714114523655, 1.61486...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79AA9DC0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>5425.187882</td>\n",
       "      <td>[0.9757602216839917, 0.9112673432452337, 0.899...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E86870&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>5546.047291</td>\n",
       "      <td>[1.6219897896143083, 1.1228872399874557, 0.818...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F1B320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>5566.776762</td>\n",
       "      <td>[2.1377297952387773, 1.0949012671349838, 1.591...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E924B0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>5656.456851</td>\n",
       "      <td>[1.8768258447531931, 1.6612239739730874, 1.681...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79EF8650&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Arch                                          Fun    Test_loss  \\\n",
       "90  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E79E2C7C0>    77.685665   \n",
       "32  [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>    83.211048   \n",
       "34  [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>   107.560954   \n",
       "56  [1, 20, 20, 1]        <function relu at 0x0000029E79E2C5E0>   116.231826   \n",
       "84  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E79E2C7C0>   119.761218   \n",
       "..             ...                                          ...          ...   \n",
       "24  [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  5389.200397   \n",
       "42  [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  5425.187882   \n",
       "49  [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  5546.047291   \n",
       "27  [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  5566.776762   \n",
       "22  [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  5656.456851   \n",
       "\n",
       "                                        Train_results  Dropout  Patience  \\\n",
       "90  [1.5458414325023155, 1.152613822473693, 0.8876...      0.0       500   \n",
       "32  [0.8566611299078528, 0.9421270328243416, 0.849...      0.0       100   \n",
       "34  [0.8695641773504779, 0.8206667752586556, 0.802...      0.0       500   \n",
       "56  [3.1848926863906164, 1.099435969906802, 0.8974...      0.0         0   \n",
       "84  [1.676049143833711, 0.7446093420303619, 0.8395...      0.0         0   \n",
       "..                                                ...      ...       ...   \n",
       "24  [1.953555860827319, 2.506714114523655, 1.61486...      0.5        50   \n",
       "42  [0.9757602216839917, 0.9112673432452337, 0.899...      0.3         0   \n",
       "49  [1.6219897896143083, 1.1228872399874557, 0.818...      0.5         0   \n",
       "27  [2.1377297952387773, 1.0949012671349838, 1.591...      0.5       500   \n",
       "22  [1.8768258447531931, 1.6612239739730874, 1.681...      0.5        10   \n",
       "\n",
       "                                            Net  \n",
       "90  <__main__.MLP object at 0x0000029E79F1AC60>  \n",
       "32  <__main__.MLP object at 0x0000029E79E3AEA0>  \n",
       "34  <__main__.MLP object at 0x0000029E79ECB1A0>  \n",
       "56  <__main__.MLP object at 0x0000029E587F0C20>  \n",
       "84  <__main__.MLP object at 0x0000029E79E92570>  \n",
       "..                                          ...  \n",
       "24  <__main__.MLP object at 0x0000029E79AA9DC0>  \n",
       "42  <__main__.MLP object at 0x0000029E79E86870>  \n",
       "49  <__main__.MLP object at 0x0000029E79F1B320>  \n",
       "27  <__main__.MLP object at 0x0000029E79E924B0>  \n",
       "22  <__main__.MLP object at 0x0000029E79EF8650>  \n",
       "\n",
       "[112 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(\"Test_loss\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b396b-d1c3-4096-84c0-2f7bd9488dae",
   "metadata": {},
   "source": [
    "Dropout = 0.5 wydaje się być za duży"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5749095-747a-4dff-abe9-9e7d2d7a4500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Test_loss</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>3676.934431</td>\n",
       "      <td>[1.2633149113515576, 0.9829090148257399, 1.275...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E86900&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>3712.178226</td>\n",
       "      <td>[0.9847117221751631, 1.3320180258767575, 1.008...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E907D0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E79E2C7C0&gt;</td>\n",
       "      <td>3730.410710</td>\n",
       "      <td>[10.97857462333237, 5.58901305173068, 2.800666...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F59700&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function relu at 0x0000029E79E2C5E0&gt;</td>\n",
       "      <td>4210.320111</td>\n",
       "      <td>[12.488185428791843, 3.904650791883166, 6.2615...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E92600&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>4287.917406</td>\n",
       "      <td>[2.0137518799312617, 1.0705136986809018, 1.149...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79EF9910&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>4444.048425</td>\n",
       "      <td>[1.7982413174777379, 1.5405850511770907, 1.413...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E3B440&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>4671.701493</td>\n",
       "      <td>[1.2460065571308916, 1.4986830401483948, 0.786...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79EF8E60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>4733.458945</td>\n",
       "      <td>[1.6637142248274677, 2.200724499011219, 1.7131...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F1A390&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>4915.093763</td>\n",
       "      <td>[1.4981756536406245, 1.088392451662432, 1.1208...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79CFBD40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>4919.823876</td>\n",
       "      <td>[1.236718692861034, 0.8990143117181587, 1.0177...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79EF8290&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E79E2C7C0&gt;</td>\n",
       "      <td>4962.646984</td>\n",
       "      <td>[2.0162607707066, 1.3215822245610642, 0.996677...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F1B4A0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>5064.871540</td>\n",
       "      <td>[2.510918848510401, 1.8174431357042837, 1.5581...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E87200&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>5125.884638</td>\n",
       "      <td>[1.0398402174011334, 0.8650729871372145, 0.919...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E901A0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>5311.586859</td>\n",
       "      <td>[1.2438988623434828, 1.283442867289226, 1.0182...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79CB0AD0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>5383.077214</td>\n",
       "      <td>[1.384635217770942, 0.9072875209817594, 1.1739...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E3B2F0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>5389.200397</td>\n",
       "      <td>[1.953555860827319, 2.506714114523655, 1.61486...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79AA9DC0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>5425.187882</td>\n",
       "      <td>[0.9757602216839917, 0.9112673432452337, 0.899...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E86870&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E79E2C4A0&gt;</td>\n",
       "      <td>5546.047291</td>\n",
       "      <td>[1.6219897896143083, 1.1228872399874557, 0.818...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F1B320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>5566.776762</td>\n",
       "      <td>[2.1377297952387773, 1.0949012671349838, 1.591...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79E924B0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E79DB3A60&gt;</td>\n",
       "      <td>5656.456851</td>\n",
       "      <td>[1.8768258447531931, 1.6612239739730874, 1.681...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79EF8650&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Arch                                          Fun    Test_loss  \\\n",
       "19   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  3676.934431   \n",
       "53   [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  3712.178226   \n",
       "107  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E79E2C7C0>  3730.410710   \n",
       "78   [1, 20, 20, 1]        <function relu at 0x0000029E79E2C5E0>  4210.320111   \n",
       "26   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  4287.917406   \n",
       "23   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  4444.048425   \n",
       "54   [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  4671.701493   \n",
       "25   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  4733.458945   \n",
       "14   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  4915.093763   \n",
       "48   [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  4919.823876   \n",
       "106  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E79E2C7C0>  4962.646984   \n",
       "21   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  5064.871540   \n",
       "47   [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  5125.884638   \n",
       "55   [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  5311.586859   \n",
       "35   [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  5383.077214   \n",
       "24   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  5389.200397   \n",
       "42   [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  5425.187882   \n",
       "49   [1, 20, 20, 1]        <function tanh at 0x0000029E79E2C4A0>  5546.047291   \n",
       "27   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  5566.776762   \n",
       "22   [1, 20, 20, 1]     <function sigmoid at 0x0000029E79DB3A60>  5656.456851   \n",
       "\n",
       "                                         Train_results  Dropout  Patience  \\\n",
       "19   [1.2633149113515576, 0.9829090148257399, 1.275...      0.3       200   \n",
       "53   [0.9847117221751631, 1.3320180258767575, 1.008...      0.5       100   \n",
       "107  [10.97857462333237, 5.58901305173068, 2.800666...      0.5        20   \n",
       "78   [12.488185428791843, 3.904650791883166, 6.2615...      0.5        10   \n",
       "26   [2.0137518799312617, 1.0705136986809018, 1.149...      0.5       200   \n",
       "23   [1.7982413174777379, 1.5405850511770907, 1.413...      0.5        20   \n",
       "54   [1.2460065571308916, 1.4986830401483948, 0.786...      0.5       200   \n",
       "25   [1.6637142248274677, 2.200724499011219, 1.7131...      0.5       100   \n",
       "14   [1.4981756536406245, 1.088392451662432, 1.1208...      0.3         0   \n",
       "48   [1.236718692861034, 0.8990143117181587, 1.0177...      0.3       500   \n",
       "106  [2.0162607707066, 1.3215822245610642, 0.996677...      0.5        10   \n",
       "21   [2.510918848510401, 1.8174431357042837, 1.5581...      0.5         0   \n",
       "47   [1.0398402174011334, 0.8650729871372145, 0.919...      0.3       200   \n",
       "55   [1.2438988623434828, 1.283442867289226, 1.0182...      0.5       500   \n",
       "35   [1.384635217770942, 0.9072875209817594, 1.1739...      0.1         0   \n",
       "24   [1.953555860827319, 2.506714114523655, 1.61486...      0.5        50   \n",
       "42   [0.9757602216839917, 0.9112673432452337, 0.899...      0.3         0   \n",
       "49   [1.6219897896143083, 1.1228872399874557, 0.818...      0.5         0   \n",
       "27   [2.1377297952387773, 1.0949012671349838, 1.591...      0.5       500   \n",
       "22   [1.8768258447531931, 1.6612239739730874, 1.681...      0.5        10   \n",
       "\n",
       "                                             Net  \n",
       "19   <__main__.MLP object at 0x0000029E79E86900>  \n",
       "53   <__main__.MLP object at 0x0000029E79E907D0>  \n",
       "107  <__main__.MLP object at 0x0000029E79F59700>  \n",
       "78   <__main__.MLP object at 0x0000029E79E92600>  \n",
       "26   <__main__.MLP object at 0x0000029E79EF9910>  \n",
       "23   <__main__.MLP object at 0x0000029E79E3B440>  \n",
       "54   <__main__.MLP object at 0x0000029E79EF8E60>  \n",
       "25   <__main__.MLP object at 0x0000029E79F1A390>  \n",
       "14   <__main__.MLP object at 0x0000029E79CFBD40>  \n",
       "48   <__main__.MLP object at 0x0000029E79EF8290>  \n",
       "106  <__main__.MLP object at 0x0000029E79F1B4A0>  \n",
       "21   <__main__.MLP object at 0x0000029E79E87200>  \n",
       "47   <__main__.MLP object at 0x0000029E79E901A0>  \n",
       "55   <__main__.MLP object at 0x0000029E79CB0AD0>  \n",
       "35   <__main__.MLP object at 0x0000029E79E3B2F0>  \n",
       "24   <__main__.MLP object at 0x0000029E79AA9DC0>  \n",
       "42   <__main__.MLP object at 0x0000029E79E86870>  \n",
       "49   <__main__.MLP object at 0x0000029E79F1B320>  \n",
       "27   <__main__.MLP object at 0x0000029E79E924B0>  \n",
       "22   <__main__.MLP object at 0x0000029E79EF8650>  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e15e11b-555e-44fe-8188-3d966168334f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fr = 100\n",
    "to = 10000\n",
    "for arch in archs:\n",
    "    y = results_df[pd.concat([results_df[\"Patience\"].apply(lambda x: x==0),results_df[\"Dropout\"].apply(lambda x: x==0), results_df[\"Fun\"].apply(lambda x: x==relu)], axis=1).all(axis=1)].reset_index()[\"Train_results\"][0]\n",
    "    plt.plot(np.arange(len(y[fr:to])) + fr, y[fr:to], label = f\"Arch: {arch}\")\n",
    "plt.legend()\n",
    "plt.title(f\"Loss to epochs for diffrent architectures for {relu}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe61d5af-fbd2-4a95-bf29-40b0346bbc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DLA ZBIORU TESTOWEGO\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGzCAYAAADaCpaHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABOaUlEQVR4nO3deVxU9f4/8NcwwIAg4IJsIiKWu6lIiEuikpjk1mYqLoU3I68mbmH355a30PSblRlaWVouaXU1r1TmRqkhmWnuXEXFDdRSQJSdz++PkRPDOsDMnDkzr+fjMY/jnDnnzHvO4Jz3+awqIYQAERERkULZyB0AERERUX0wmSEiIiJFYzJDREREisZkhoiIiBSNyQwREREpGpMZIiIiUjQmM0RERKRoTGaIiIhI0ZjMEBERkaIxmSFSmKKiIsyePRu+vr6wsbHB8OHDTfr+oaGhCA0NNcixbty4gWeeeQZNmjSBSqXCu+++i8TERKhUKiQmJtbr2BMmTEDLli0NEqehtGzZEhMmTDDKsQ113vSlUqmwYMECk7wXUU2YzBA9sHbtWqhUKvz222+Vvh4aGoqOHTuaOKqKPv30UyxduhTPPPMM1q1bh5iYGLlDqrOYmBjs3LkTc+bMwRdffIFBgwZVut3GjRvx7rvvVlh//fp1LFiwAMeOHTNuoERk1mzlDoCIamfv3r3w8fHB8uXLZXn/H3/80WDH2rt3L4YNG4aZM2dK6x5++GHk5ubC3t5eWrdx40acPHkS06ZN09n/+vXrWLhwIVq2bIkuXbrovPbxxx+jpKTEYLGau8cee6zCeSOyFkxmiBTm5s2bcHNzk+39DXmxrOyz2NjYwMHBod7HtrOzq/cxlETf83b//n00aNDABBERmQ6rmYjqoaioCIsWLUJAQAA0Gg1atmyJ119/Hfn5+dI206dPR5MmTVB2gvopU6ZApVLh/fffl9bduHEDKpUK8fHxlb7XpUuXoFKpsG/fPpw6dQoqlUpqI1FVe4nSfdauXSutmzBhApydnXHt2jUMHz4czs7OcHd3x8yZM1FcXFzjZ66szcyKFSvQoUMHNGjQAI0aNUL37t2xcePGKo9RWqUnhMDKlSulzwJUbPsRGhqKhIQEpKWlSdu1bNkSiYmJCAoKAgC88MIL0muln7V8m5nSc7Fs2TJ89NFH0ncWFBSEw4cPV4jxq6++Qvv27eHg4ICOHTti69aterfDEULg3//+N5o3b44GDRqgX79+OHXqVKXbZmZmYtq0afD19YVGo0Hr1q2xZMmSCqVKX375JQIDA9GwYUO4uLigU6dOeO+996TXK/sbKK0aPXLkCB577DE0aNAAr7/+OgAgPz8f8+fPR+vWraHRaODr64vZs2fr/O2WbhcTEwN3d3c0bNgQQ4cOxdWrV2s8Bzk5OXBycsKrr75a4bWrV69CrVYjLi6uxuMQ6YMlM0TlZGVl4c8//6ywvrCwsMK6iRMnYt26dXjmmWcwY8YMJCcnIy4uDmfOnMHWrVsBAH369MHy5ctx6tQpqc3N/v37YWNjg/3792Pq1KnSOkBbXVAZd3d3fPHFF3jzzTeRk5MjXQjatWuHM2fO1OozFhcXIzw8HMHBwVi2bBl2796N//u//0NAQACio6NrdayPP/4YU6dOxTPPPINXX30VeXl5OH78OJKTkzF69OhK93nsscfwxRdfYOzYsXj88ccxbty4Ko//r3/9C1lZWbh69apUtebs7Ix27drhjTfewLx58/DSSy+hT58+AICePXtWG+/GjRtx9+5dTJo0CSqVCm+//TaeeuopXLhwQSrNSUhIwMiRI9GpUyfExcXhzp07iIqKgo+Pj17nZN68efj3v/+NwYMHY/Dgwfj9998xcOBAFBQU6Gx3//599O3bF9euXcOkSZPQokUL/PLLL5gzZw7S09OldkK7du3CqFGjMGDAACxZsgQAcObMGRw8eLDSZKGsv/76C0888QSef/55REZGwsPDAyUlJRg6dCgOHDiAl156Ce3atcOJEyewfPly/O9//8O2bduk/SdOnIj169dj9OjR6NmzJ/bu3YuIiIgaz4GzszNGjBiBzZs345133oFarZZe27RpE4QQGDNmjF7nk6hGgoiEEEJ89tlnAkC1jw4dOkjbHzt2TAAQEydO1DnOzJkzBQCxd+9eIYQQN2/eFADEhx9+KIQQIjMzU9jY2Ihnn31WeHh4SPtNnTpVNG7cWJSUlFQbZ9++fXXiEEKIffv2CQBi3759OusvXrwoAIjPPvtMWjd+/HgBQLzxxhs623bt2lUEBgZWf5IevH/fvn2l58OGDasQj74AiMmTJ+usq+yzRERECD8/vwr7Hz58uMLnKzV+/HidfUrPRZMmTcTt27el9d9++60AIP773/9K6zp16iSaN28u7t69K61LTEwUACqNo6ybN28Ke3t7ERERofNdvv766wKAGD9+vLRu0aJFwsnJSfzvf//TOUZsbKxQq9Xi8uXLQgghXn31VeHi4iKKioqqfN/Kzlvfvn0FALFq1Sqdbb/44gthY2Mj9u/fr7N+1apVAoA4ePCgEOLvv/FXXnlFZ7vRo0cLAGL+/PnVnoudO3cKAOL777/XWd+5c2edvyGi+mI1E1E5K1euxK5duyo8OnfurLPdd999B0BbjVTWjBkzAGjv7gFtiUrbtm3x888/AwAOHjwItVqNWbNm4caNGzh37hwAbclM7969peoWY3v55Zd1nvfp0wcXLlyo9XHc3Nxw9erVSqtqzNHIkSPRqFEj6XlpiU7pZ79+/TpOnDiBcePGwdnZWdqub9++6NSpU43H3717NwoKCqSqxFLlGy8D2qqsPn36oFGjRvjzzz+lR1hYGIqLi6W/GTc3N9y7dw+7du2q9efVaDR44YUXKrxvu3bt0LZtW5337d+/PwBg3759AP7+Gy8tPazus1QmLCwM3t7e2LBhg7Tu5MmTOH78OCIjI2v9WYiqwmomonIeffRRdO/evcL60gtOqbS0NNjY2KB169Y623l6esLNzQ1paWnSuj59+kgXhv3796N79+7o3r07GjdujP3798PDwwN//PFHldUyhubg4AB3d3eddY0aNcKdO3dqfazXXnsNu3fvxqOPPorWrVtj4MCBGD16NHr16mWocA2qRYsWOs9LE5vSz176vZX/XkvX/f7779Uev3T/hx56SGe9u7u7ThIFAOfOncPx48crfBelbt68CQB45ZVXsGXLFjzxxBPw8fHBwIED8dxzz1XZlb0sHx+fCo22z507hzNnztT4vqV/4wEBATqvt2nTpsb3BbSNkseMGYP4+Hip4fGGDRvg4OCAZ599Vq9jEOmDyQxRPelTktK7d298/PHHuHDhAvbv348+ffpApVKhd+/e2L9/P7y9vVFSUiKVEhgqhqoa9JZtv1Bf7dq1Q0pKCnbs2IEffvgB33zzDT788EPMmzcPCxcuNNj7GEpVn12UaaBtKiUlJXj88ccxe/bsSl9/+OGHAQDNmjXDsWPHsHPnTnz//ff4/vvv8dlnn2HcuHFYt25dte/h6OhY6ft26tQJ77zzTqX7+Pr61vKTVG3cuHFYunQptm3bhlGjRmHjxo148skn4erqarD3IGIyQ1RHfn5+KCkpwblz59CuXTtp/Y0bN5CZmQk/Pz9pXWmSsmvXLhw+fBixsbEAtA1h4+Pj4e3tDScnJwQGBtYpltI7/szMTJ31ZUuHjMnJyQkjR47EyJEjUVBQgKeeegpvvvkm5syZY5Bu1lUla8aokiv93s6fP1/htcrWVbX/uXPn0KpVK2n9rVu3KpR8BQQEICcnB2FhYTUe197eHkOGDMGQIUNQUlKCV155BatXr8bcuXMrLUWqTkBAAP744w8MGDCg2nNY+jeempqqUxqTkpKi93t17NgRXbt2xYYNG9C8eXNcvnwZK1asqFW8RDVhmxmiOho8eDAAVBiZtvRut2yPD39/f2mgu8LCQqkKpk+fPkhNTcXXX3+NHj16wNa2bvcXfn5+UKvVUhuLUh9++GGdjlcbf/31l85ze3t7tG/fHkKISnuA1YWTkxOysrIqXQ9UTOLqw9vbGx07dsTnn3+OnJwcaf1PP/2EEydO1Lh/WFgY7OzssGLFCp3SnspGMH7uueeQlJSEnTt3VngtMzMTRUVFACqeYxsbG6kNV/mu1Pp47rnncO3aNXz88ccVXsvNzcW9e/cAAE888QQA6AwhUNVnqc7YsWPx448/4t1330WTJk2k4xIZCktmiOrokUcewfjx4/HRRx8hMzMTffv2xa+//op169Zh+PDh6Nevn872ffr0wZdffolOnTpJJSndunWDk5MT/ve//9WrvYyrqyueffZZrFixAiqVCgEBAdixY4fU9sGYBg4cCE9PT/Tq1QseHh44c+YMPvjgA0RERKBhw4YGeY/AwEBs3rwZ06dPR1BQEJydnTFkyBAEBATAzc0Nq1atQsOGDeHk5ITg4GD4+/vX6/3eeustDBs2DL169cILL7yAO3fu4IMPPkDHjh11EpzKlI7ZExcXhyeffBKDBw/G0aNH8f3336Np06Y6286aNQvbt2/Hk08+iQkTJiAwMBD37t3DiRMn8PXXX+PSpUto2rQpJk6ciNu3b6N///5o3rw50tLSsGLFCnTp0kWnVFBfY8eOxZYtW/Dyyy9j37596NWrF4qLi3H27Fls2bIFO3fuRPfu3dGlSxeMGjUKH374IbKystCzZ0/s2bNHrxKqskaPHo3Zs2dj69atiI6OtroBDckEZO5NRWQ2SrtmHz58uNLXK+sSXVhYKBYuXCj8/f2FnZ2d8PX1FXPmzBF5eXkV9l+5cqUAIKKjo3XWh4WFCQBiz549esVZWRxCCHHr1i3x9NNPiwYNGohGjRqJSZMmiZMnT1baNdvJyanC/vPnzxf6/CSU75q9evVq8dhjj4kmTZoIjUYjAgICxKxZs0RWVlaNx4KeXbNzcnLE6NGjhZubW4Xu0d9++61o3769sLW11fmsVXXNXrp0aaVxlO9m/OWXX4q2bdsKjUYjOnbsKLZv3y6efvpp0bZt2xo/V3FxsVi4cKHw8vISjo6OIjQ0VJw8eVL4+fnpdM0WQoi7d++KOXPmiNatWwt7e3vRtGlT0bNnT7Fs2TJRUFAghBDi66+/FgMHDhTNmjUT9vb2okWLFmLSpEkiPT292vNW1d+KEEIUFBSIJUuWiA4dOgiNRiMaNWokAgMDxcKFC3W+u9zcXDF16lTRpEkT4eTkJIYMGSKuXLmiV9fssgYPHiwAiF9++UXvfYj0pRJChlZvREQK1KVLF7i7u9epi7S1GzFiBE6cOFHrUh0ifbDNDBFROYWFhVJ7lVKJiYn4448/KkzlQDVLT09HQkICxo4dK3coZKFYMkNEVM6lS5cQFhaGyMhIeHt74+zZs1i1ahVcXV1x8uRJNGnSRO4QFeHixYs4ePAgPvnkExw+fBipqanw9PSUOyyyQGwATERUTqNGjRAYGIhPPvkEt27dgpOTEyIiIrB48WImMrXw008/4YUXXkCLFi2wbt06JjJkNCyZISIiIkVjmxkiIiJSNCYzREREpGhW0WampKQE169fR8OGDU02IzERERHVjxACd+/ehbe3N2xsqi5/sYpk5vr16wadOI2IiIhM58qVK2jevHmVr1tFMlM6pPqVK1fg4uIiczRERESkj+zsbPj6+tY4NYpVJDOlVUsuLi5MZoiIiBSmpiYibABMREREisZkhoiIiBSNyQwREREpGpMZIiIiUjQmM0RERKRoTGaIiIhI0ZjMEBERkaIxmSEiIiJFYzJDREREisZkhoiIiBSNyQwREREpGpMZIiIiUjQmM/VxeA2wvKN2SURERLJgMlMfB5YDWVe0SyIiIpIFk5n66B0DuPpql0RERCQLW7kDULSgKO2DiIiIZMOSGSIiIlI0JjOGwIbAREREsmEyYwhsCExERCQbJjOGwIbAREREsmEDYENgQ2AiIiLZsGSGiIiIFI3JDBERESkakxkiIiJSNCYzREREpGhMZoiIiEjRmMwYEgfPIyIiMjkmM4a0d5F28Ly9i+SOhIiIyGowmTEkUW5JRERERsdkxpAGzNWOBDxgrtyREBERWQ2OAGxIHAmYiIjI5FgyYwxsCExERGQyTGaMgbNoExERmQyTGWPgLNpEREQmwzYzxsC2M0RERCbDkhkiIiJSNCYzREREpGhMZoiIyHjYu5NMgG1miIjI8L6OAk5tBdQaoOi+tncn2xKSkbBkhoiIDO/UVkAUA0W5f/fuZCkNGQmTGSIiMrwOIwCVGuj4NBBzUlsqwzG4yEiYzBARkeE9swaYf1u7LFV+DC6W1JCBqIQQFj/Hc3Z2NlxdXZGVlQUXFxe5wyEiIkCbyGRdARwbAfbO2iSH7WqoDH2v30Ytmfn5558xZMgQeHt7Q6VSYdu2bTqvCyEwb948eHl5wdHREWFhYTh37pzONrdv38aYMWPg4uICNzc3REVFIScnx5hhExFRZQxdklJaUiPA6qf6KPu9lP+OrKT0y6jJzL179/DII49g5cqVlb7+9ttv4/3338eqVauQnJwMJycnhIeHIy8vT9pmzJgxOHXqFHbt2oUdO3bg559/xksvvWTMsImIqLzDa4DvZhk26QiK0ranGTCXU8DURWmisnfR399L+XZJpc+/m2XRCY3JqplUKhW2bt2K4cOHA9CWynh7e2PGjBmYOXMmACArKwseHh5Yu3Ytnn/+eZw5cwbt27fH4cOH0b17dwDADz/8gMGDB+Pq1avw9vbW672NVc20/lAa4hNTEejXCEfS7qCJkz1OXc9CB29X/HWvANGhAYjs4Wew9yMiksXhNUDCDGiLUFRAxP8Zvzro8BrthZhVTzqStyxFi9Orcbn9JHS4sAbOeem4Z9MQ2SUOuNx+EgBIrwc/NwvJW5Yi8PRbsEUJchy84Bx7Fr/93wh0y94LAMiDBouLx2C73ROYGd4GkT38pGtb+WtY2fUApOvfz/+7BQDS/oak7/VbtnFmLl68iIyMDISFhUnrXF1dERwcjKSkJDz//PNISkqCm5ublMgAQFhYGGxsbJCcnIwRI0ZUeuz8/Hzk5+dLz7Ozs43yGeITU3EtMxcZWbkoFsC1zFwAwPFrWdLrTGaISEmmbjqKhOPXEdHZG++P6goAyNmzFM7Q3vdmCifsKA5DpJ7HKXtzB0DnIln+hrDsxTNnz1I456Vrl0FRVV5grUHylqVoc/pd2IkCdEch1CoBnF6NeNunMEp8g1X5Q7G+OAw+FxwBANfy3oPPBUccBDD9QiBCCycg2nY7NhUNxSwAXbITYaPSHrsB8rFA/SliSjbjk92RQI+3pWtb+WtY2fUAdK5/APBmwmnZvhvZejNlZGQAADw8PHTWe3h4SK9lZGSgWbNmOq/b2tqicePG0jaViYuLg6urq/Tw9fU1cPRa0aEB8HFzRERnb/i4OaKzjyvUKqCzjyt83Byl/7xEROZs/aE0dFn4Ix7613fY/sd1FAsg4fh16fX4oqG4I5xwRzhhadFz0sWsOgnHtcc5fi1LugCWvxiWPk84fl1nfel7XhVNEV80FACQvnslNuf+A5d+WIFei/di/aE0A58F89Xi9Gq4IQdOqgKoVQJFwgaX20+CV9hkjHT8GNkdx0nXnNLrUun1Jzo0AAn2T+BJm3h4hU0GABxzCUWJAErrZWxUQCPVPUTbbpf2qewaVnZ92etfqbzCEhOcjcpZ5AjAc+bMwfTp06Xn2dnZRkloInv4Wd0dAhFZlvWH0jD/25PS3fV7dh8gwuYQjrmEAogAAHiFTUbPhH7ILSyBo50N/qXHjVpEZ+9qS2YA7cWxfMlMKa+wyRiZOOjvbW23w7noT/wTGzEhdys27X4a6PG24U6EGbvcfhIcH5TMFKrskdJhGoKfm4VgoNJrUNl1lV2nus/Yqv3H4TXa9jaF+YCdBs79Z2n3Ue9GpGY5oI4BEFXlscr+u7Q0Ty6ytZm5cOECAgICcPToUXTp0kXarm/fvujSpQvee+89fPrpp5gxYwbu3LkjvV5UVAQHBwd89dVXVVYzlceu2UREleu1eC+uZeZCBeA9+w8wRPULVCpoB7ybf1vu8P72oA1N/v1saAqzpPYfFsVc2gmVdpl39dU20JaRWXTNro6/vz88PT2xZ88eaV12djaSk5MREhICAAgJCUFmZiaOHDkibbN3716UlJQgODjY5DETEVmC9YfSpKqa0uqCL7udxlCbB4kMoB3B15w86PmkGTgfcPWF84BZckdkeOYyQnL5wQ0VwKglMzk5OTh//jwAoGvXrnjnnXfQr18/NG7cGC1atMCSJUuwePFirFu3Dv7+/pg7dy6OHz+O06dPw8HBAQDwxBNP4MaNG1i1ahUKCwvxwgsvoHv37ti4caPecbBkhojob6WlMT5ujjg44CKwZxGQlwk8aOSLjs/ojtxLpmEuJTNmxCxKZn777Td07doVXbtqW8RPnz4dXbt2xbx58wAAs2fPxpQpU/DSSy8hKCgIOTk5+OGHH6REBgA2bNiAtm3bYsCAARg8eDB69+6Njz76yJhhG13ZuyIiIlPTaeB5YDmQdweA0FYtRbyj6ERGyb+v64vD0Cv/fawvDqt5YzmY8QB8nM5ABjp3RbH95Q6HiKxN2RIAQFsyowLQf67iSwSW/ns2RhV+g012T2PW/1NWA2GzvzbI0JbGLEpmqHJVdXsjIjKJsm0zgqKA2EvAa5cUn8gA2l5PzVV/St2MlcTsrw1m3JaGJTNERNbGkttmWPJnMycmOs/6Xr+ZzBARkUWy5lGDjc5EVU6sZiIiIgDKbhRbH+VHHCYDKq1y8g02i0bBTGaIiCyctV7Uzb4NipKVznh+JVlbQpMwHfgoVLZwmMwQEVk4a72oR/bww8HY/qxiMqayjYGvH5UtDCYzREQWzpov6tZaxWYyQVGAt3YsOWkpAyYzRESWzowHOzO2ZTtTcC0zF8t2psgdiuV6KRFYkKVdyoTJjBys+IeFiGRgLnP+EBkJkxk58IeFiEzJjAc7M7aZ4W3g4+aImeFt5A6FjIjjzMiBgzoRERHViOPMmLPSLm1MZIjISNjwlawJkxkiIgtkrWPL6GD7RKvBZIaIyAJZ69gyOtg+0WowmTEDLA4mIjKCMg2f+Ttr2ZjMmAEWBxORofF3BTrtE3k+LBuTGTPA4mAiMjT+ruji+bBs7JpNREREZolds4mIrBl78pAVYTJDRGSJ2JOHrAiTGSIiS2TFUxiQ9WEyYw5YHExERFRnTGbMAYuDicjQ+LuixZtFq8Bkxhz0jkGOgxeW3hvMAZ2IyDBYzaRVLqnj4HmWicmMOQiKQjg+xMqcvhzQiYgMgxPaavkGAyq1dgkOJmipmMyYiXdaHUGSw6t4p9URuUMhIrIcV5IBUaxdAgj0awS1Srsky8FkxkwEX1sHL9xC8LV1codCRGQ5ylW3HUm7g2KhXZLlYDJjLli/TURkeOWq2zitgWXidAZERERkljidAREREVkFJjNERESkaExmiIiISNGYzBARWQgOCEfWiskMEZGF4IBwZK2YzJgbziNCRHXEbsdkrZjMmBtODkdEdRSp3o2DmqmIVO+WOxQik2IyY244eB4R1RVvhshK2codAJUTFMWJ4YiobnrHaBMZ3gyRlWHJjLli2xkiqi3OlK0I7HVmeExmzBWLi4mIDMeMbhDZ68zwmMyYK99gQKXWLomIqH7M6AaRvc4Mj21mzNWVZEAUa5dERFQ/ZtSeKLKHHyJ7+MkdhkVhMmOuzOg/HhGR4rFzhUVjMmOu+B+PiIhIL2wzQ0REZEpm1BjZUjCZISIiMiUzaoxsKZjMmBmOP0BEZOE40rvBMZkxMxx/gIjIwnFwQ4NjMmNmOP4AERFR7aiEEELuIIwtOzsbrq6uyMrKgouLi9zhEBERkR70vX6zZIaIiIgUjckMERERKRqTGSIish4c48UiMZkhIiLrwTFeLBKTGSIish6+wYBKrV2SxWAyQ0RE1uNKMiCKtUuyGExmiIjIenD0XYvEZIaISME4BUotcfRdi8RkxkzxB4qI9MEpUIiYzJgt/kARkT44BQoRkxmzVeUPFMdIIKIyInv44WBsf0T28JM7FCLZcG4mpVnSEsi9Azg2Al67JHc0RERERsO5mSyVKLckIiKyckxmzFSVDYAHzNV2KxwwV57AiMi8sOqZSP5kZsGCBVCpVDqPtm3bSq/n5eVh8uTJaNKkCZydnfH000/jxo0bMkZsGlU2AGa3QiIqi8PzE8mfzABAhw4dkJ6eLj0OHDggvRYTE4P//ve/+Oqrr/DTTz/h+vXreOqpp2SM1jSq7aHAOzEiKsVB4IjkbwC8YMECbNu2DceOHavwWlZWFtzd3bFx40Y888wzAICzZ8+iXbt2SEpKQo8ePfR6D4tqAAxoE5msK9ofsJiTckdDRERkFIpqAHzu3Dl4e3ujVatWGDNmDC5fvgwAOHLkCAoLCxEWFiZt27ZtW7Ro0QJJSUlVHi8/Px/Z2dk6D4vCOzEiIiKJ7MlMcHAw1q5dix9++AHx8fG4ePEi+vTpg7t37yIjIwP29vZwc3PT2cfDwwMZGRlVHjMuLg6urq7Sw9fX18ifwsTYboaIiEhiK3cATzzxhPTvzp07Izg4GH5+ftiyZQscHR3rdMw5c+Zg+vTp0vPs7GzLS2iIiIgIgBmUzJTn5uaGhx9+GOfPn4enpycKCgqQmZmps82NGzfg6elZ5TE0Gg1cXFx0HkRERLJhxw2jMrtkJicnB6mpqfDy8kJgYCDs7OywZ88e6fWUlBRcvnwZISEhMkZJRERUC+xCb1SyVzPNnDkTQ4YMgZ+fH65fv4758+dDrVZj1KhRcHV1RVRUFKZPn47GjRvDxcUFU6ZMQUhIiN49mYiIiOSW7DMeLbJW47LPeATLHYwFkj2ZuXr1KkaNGoW//voL7u7u6N27Nw4dOgR3d3cAwPLly2FjY4Onn34a+fn5CA8Px4cffihz1EQKcHiN9i7QqSmQfhzoMAJ4pkwR99dRwKmtFdcTkcFNvxCIa3nvweeCIw7KHYwFkn2cGVOwuHFmiPTxYDwiAUAFoBg2UC+4I71cvKAR1CipsJ6UY/2hNMQnpiI6NICzZps5fld1o6hxZojICB6MR3S8pBWKhA12FOtWze4o7lHpelKOKqc9IbMT2cMPB2P7M5ExEtmrmYjIgEqrlnrHYH1xGOLz/dHE3R6nrmchorM3hpXZdE/7tzD9+PUK60k5okMDpLt9ImvGaiYiS1Jmqote+e/jWmYufNwccTC2v9yRERHVGquZiKxRmakuqp2slIjIgrBkhoiIiMwSS2aIiIjMAUf/NTomM0SW4vAa5Cxui6X/no31h9LkjoaISnH0X6NjMkNkKQ4sh3NeOkYVfsOuutaCd/zKUKYtGxkHkxkiS9E7BjkOXthk9zQb/VoL3vErQ1AUEHNSuySjYDJDZCHWF4chHB/CK2wyB+ayFrzjJwLAZIbIYnA0WCvEO34iAExmiCwGx5UhImvFcWaIiIiMiJNM1h3HmSGiOlt/KA29Fu9lF2+i+jq8BgN+GIDQu/9lFbARMZkhUrLDa4DFLYElLQ3aPZftb4gM5MByeOEW/mn3X1YBGxGTGSIFy9mzFMi7A+Te0f7bQNj+hqyVwUslH/Q484qYwyomI2IyQ6Rg8UVDcUc44Y5wQnzRUIMdN7KHHw7G9uePL1kdg5dKsseZSTCZsUQcFdRqeIVNRj+btehnsxZeYZPlDodI8VgqqUzszWSJlnfUjgrq6qu9IyAiIlIg9mayZhwV1Cokb1mK9AWtkbzFcG1liIiUyFbuAMgIgqJYP2sFWpxeDS/cAk6vBjBL7nCIiGTDkhlLxrYzFmv9oTQcKXkIRcIG1xp2kjscIqoCx2wyDSYzlowz6lqs9N0rMUh1CLaqEvjcPSF3OERUBY7ZZBpMZiwZ285YrGjb7bBVlaAINrjcfpJR34t3lkR1x95RpsHeTERKdHiNtsStd4zR20f1WrwX1zJz4ePmiIOx/Y36XkREZel7/WYDYCIlMmEj7+jQAGmSPCIic8SSGSIiIjJLHGeGiOqOPeGISEGYzBBRRewJR0QKwmSGiCpiTzgiUhAmM0RUUbmZftk9m4jMGZMZIgWRaz6m0oG/5n97kgkNEZkdJjNEClI6H1OL06tN+r7RoQFQq4BiAY5kSkRmh8kMkYJcbj8J6XA3+qi/5UX28MPCYR05kikRmSWOM0NERFTKhKNrU804zgwREVFtcVgCRWIyQ0REVIrDEigSkxlrxNFdiYgqV25YAlIGJjPWqLQY9btZTGiIiEjxmMxYo94xgEoNiGLWC1OtcPA8IjJHTGYUxiAXk6AoYPBS1gtTrZUOnsexZojInDCZURiDXUxYL0z6KtPGKjo0gGPNEJHZYTKjMIF+jaBWaZdkJeRusF2mq2pkDz8cjO2PyB5+8sRCRFQJJjMKcyTtDoqFdmkQcl8oqWZyj3vBrqpkpdhGTDmYzCiMwYv55b5QUo2SfcYjHe5I9hkvTwCskiQrVedqfd4kmhyTGYUxeDE/77rN3vQLgQjJew/TLwTKHQoA3q2S9ajzzePeRdqbxL2LjBMYVWArdwAks6Ao3nGbuejQAMQnpppNo9uyd6tsO0OWLLKHX93+xkW5JRkdS2aIzJy5NbpljyaiGgyYqy3xHjBX7kisBmfNJqKacSZhIpIBZ80mIsPhFBhEZMaYzBBRzTgFBhGZMSYzCsTeJGRynAKDiMwYkxkF4vw4JAuON0NEZorJjAKxNwkREdHf2JuJiIiIzBJ7MxEREdUHpyVQDCYzRERElanj3HXspGF6TGaIiIgqU8e565btTMG1zFws25lipMCoPCYzRKQ/FruTNWEPPsVgMkNE+qtjsTuRNZkZ3gY+bo6YGd5G7lCsBpMZItJfuWJ3tg0gqsjcJoe1BkxmiEh/5YrdOYAjEZkDJjNEVDtl2s1wAEeiMtimTDYcNI/0sv5QGuITUxEdGsCiU2u3vKO23Yyrr7aUhoi0+H/D4Cxu0LyVK1eiZcuWcHBwQHBwMH799Ve5Q7IqrE4gSR27qxJZPP7fkI0iSmY2b96McePGYdWqVQgODsa7776Lr776CikpKWjWrFmN+7Nkpv7KlswAYCkNEREZnb7Xb0UkM8HBwQgKCsIHH3wAACgpKYGvry+mTJmC2NjYGvdnMmNYXRb+iMzcQrg52uHY/IFyh2NZDq/RdnvuHcOxLYjI6llMNVNBQQGOHDmCsLAwaZ2NjQ3CwsKQlJRU6T75+fnIzs7WeRApAsdxISKqNbNPZv78808UFxfDw8NDZ72HhwcyMjIq3ScuLg6urq7Sw9fX1xShWg0OCGVErHMnIqo1s09m6mLOnDnIysqSHleuXJE7JLNVl0HPyg4IxUHTDIzDp1M1+P/NvPH7kY/ZJzNNmzaFWq3GjRs3dNbfuHEDnp6ele6j0Wjg4uKi86DK6d1LqYrxE9jLich0+P9NZjWMI8PvRz5mn8zY29sjMDAQe/bskdaVlJRgz549CAkJkTEyZSu9gwj0a6TfoGdVtOXgoGmGxTs7qg7/v8ms/O/gR6HAAldtgrO8I95pdYTfj0wU0Ztp8+bNGD9+PFavXo1HH30U7777LrZs2YKzZ89WaEtTGfZm0rX+UBrmf3sSxQLwcXPEwdj+Ne/EXjYm0WvxXlzLzNX/eyEi0yn/O7jAVfd1DpZncPpev21NGFOdjRw5Erdu3cK8efOQkZGBLl264IcfftArkaGK4hNTUSwAtQr630EERTGJMYHo0ACd8XyIdPCmQlbri8MQn++P6OIARAKAd1fg+lFtEgOw4b6MFFEyU18smdHFqQmIFIrD5cuKJaemZzHjzJDhGWt6erb3sEKcWM+02HVfVmyzZL5YMmOBSkteAv0a4UjaHZOVwPCuxQo9KCnIcfBCOD5kaR8RGRRLZqxYaffAhOPXjdNNsIq7cd61WKEHJQXxRUPZJZWIZMNkxgKVJhURnb2Nk1xU0U3bWNVXZMYeDPJ3JWAU1Cog0K+R3BERmRyr2OWniN5MVDuRPfyMm1D4BgPZ17VLIgBH0u6gWGiXRNam7GB5vJmTB0tmqPauJAOiWLskAqsYybrx719+LJmh2usd8/dYF0QwQWkgkRkauuIAjl/LQmcfV3Z6kBmTGao9DqBHRITj17J0liQfVjMRERHVQWcfV50lyYclM0RERHWwfUpvuUOgB1gyQ/XDEWCJiEhmTGaofqoYc4asDJNaIpIRkxmqH84VQwCTWiKSFdvMUP2wZxMBHEiRiGTFkhkiqj8OpEhEMmIyQ0T1x+pGIpIRq5mIqP5Y3UhEMmLJDJFc2AOIiMggmMyQ4fDiXDvsAUREZBBMZshweHGuHbYzISIyCLaZIcPhbNq1w3YmREQGwZIZMpygKCDmJC/QVm79oTT0WrwX6w+lyR0KEVkJJjNEMrHUi358YiquZeYiPjFV7lCIyEowmSGSiaVe9KNDA+Dj5ojo0AC5QyEiK8E2M0QyiQ4NQHxiqsVd9CN7+CGyh5/cYRCRFVEJIYTcQRhbdnY2XF1dkZWVBRcXF7nDISIiIj3oe/1mNRMREREpGpMZIiIiUjQmM0RERKRoTGbIpCy1OzKVwWktiMjEmMyQSVlqd2Qqg9NaEJGJMZkhk+IYJLD8kgvOOUVEJsau2USmtryjtuTC1Vc7/QMREVWKXbOJzBVLLoiIDIrJDJGJrS8OQ6/897G+OEzuUIiILAKTGSITYyNoIiLDYjJDspi66SgC5iRg6qajcodicmwETURkWGwATLIImJOAYgGoVUBqXITc4RARkRliA2AyaxGdvaFWaZdERET1wZIZIiIiMkssmSEiIiKrwGSGyFQsfeRfIiKZMJkh07LmCzrnLCIiMgomM2Ra1nxB9w0GVGrtkoiIDIbJDJmWFQ/ln3P+ICCKtUsiIjIYJjNkWkFR2skVg6LkjsTk3s17EldFU7yb96TcoRARWRRbuQMgshZfqwbik7x+cHO0w/+TOxgiIgvCkhmSx9dRwMLG2qU1OLwGBzRTMdn5J8wMbyN3NEREFoXJDMnj1FZAFGuX1mDvIjjnpWOW3RZE9vCTOxoiIovCZIbk0WGEtmdPhxFyR2ISeYXFOksiIjIcJjMkj2fWAPNva5dWYFnRSFwVTbGsaKTcoRARWRw2ACYyATb+JSIyHpbMEJnAzPA28HFzZONfIiIj4KzZREREZJY4azYRERFZBSYzREREpGhMZojIqKZuOoqAOQmYuumo3KEQkYViMkNERuVy8nP8ZD8VLic/lzsUIrJQTGaIyKjmaL5Cc9WfmKP5Su5QiMhCMZkhIqNystcOZ1VUIrD+UJrM0RCRJWIyQ2Zl/aE09Fq8lxc9SzJgLrLgjBIhkL57pdzREJEFYjJDZmXZzhRcy8zFsp0pcodChhIUBbVDQzRS3UO07Xa5oyEiC8RkhoiMznnALMDVV7skIjIwJjNkVjjsv2VaXxyGXvnvY31xmNyhEJEFkjWZadmyJVQqlc5j8eLFOtscP34cffr0gYODA3x9ffH222/LFC2ZQqR6Nw5qpiJSvVvuUOqN7X/+lr57JTbn/oNtZojIKGQvmXnjjTeQnp4uPaZMmSK9lp2djYEDB8LPzw9HjhzB0qVLsWDBAnz00UcyRkxGtWcRkHVFu1S4+MRUXMvMRXxiqtyhyC7adjuaq/7EmKJvmNzpickwkf5kT2YaNmwIT09P6eHk5CS9tmHDBhQUFODTTz9Fhw4d8Pzzz2Pq1Kl45513ZIyYjEpVbqlg77Q6giSHV/FOqyNyhyI75wGzkAVnOIpcls7oickwkf5kT2YWL16MJk2aoGvXrli6dCmKioqk15KSkvDYY4/B3t5eWhceHo6UlBTcuXOnymPm5+cjOztb50EK0X8u4OqrXSpc8LV18MItBF9bJ3co8mOPplqLDg2Aj5sjokMD5A6FyOzZyvnmU6dORbdu3dC4cWP88ssvmDNnDtLT06WSl4yMDPj7++vs4+HhIb3WqFGjSo8bFxeHhQsXGjd4Mo6gKO3DEvSOAQ4s1y5J25PpwHI483zoJbKHHyJ7+MkdBpEiqIQQwpAHjI2NxZIlS6rd5syZM2jbtm2F9Z9++ikmTZqEnJwcaDQaDBw4EP7+/li9erW0zenTp9GhQwecPn0a7dq1q/T4+fn5yM/Pl55nZ2fD19cXWVlZcHFxqeMnIyIiIlPKzs6Gq6trjddvg5fMzJgxAxMmTKh2m1atWlW6Pjg4GEVFRbh06RLatGkDT09P3LhxQ2eb0ueenp5VHl+j0UCj0dQucDI76w+lIT4xFdGhAbxDJetzeM3fJXuWUlpJZCQGT2bc3d3h7u5ep32PHTsGGxsbNGvWDAAQEhKCf/3rXygsLISdnR0AYNeuXWjTpk2VVUxkOdJ3r8Tmwm+waffTQA92yScrc2C5tmffgeVMZohqIFsD4KSkJLz77rv4448/cOHCBWzYsAExMTGIjIyUEpXRo0fD3t4eUVFROHXqFDZv3oz33nsP06dPlytsMqHS7rxsMEpWqXeMtjE82xgR1cjgbWb09fvvv+OVV17B2bNnkZ+fD39/f4wdOxbTp0/XqSI6fvw4Jk+ejMOHD6Np06aYMmUKXnvttVq9l751bmRmWMxORGTV9L1+y5bMmBKTGSIiIuXR9/ot+zgzRERERPXBZIaIiIgUjckMERERKRqTGSID4cSARETyYDJDipC8ZSnSF7RG8palcodSJU4MSEQkDyYzpAgtTq+GF26hxenVNW8sE04MSEQkD1knmiTS1+X2k4DTq3G5/SR4yR1MFTgxIBGRPDjODBGZVPKWpWjxIDENfm6W3OEQkRnjODNEJsKGv7WjhCpDIlIWJjNE9cSGv7Vzuf0kpMNdW3VIRGQAbDNDVA/rD6XhXn4R3Bzt2PBXT9qqpVlm2/aJiJSHJTNE9RCfmIrM3EI4aWzZ+JeISCZMZojqQac79uE1wPKO2iUREZkMezMRGcryjkDWFcDVF4g5KXc0RESKx95MZNHMsgdR7xhtItM7Ru5IiIisCpMZUqT03SuxOfcfSN+9Uu5Q/hYUpS2RCYqSOxIiIqvCZIYUKdp2O5qr/kS07XZZ3n/qpqMImJOAqZuOyvL+RET0NyYzpEjOA2YBrr7apQwSjl9HsdAuiYhIXkxmSJkeVOmsLw6Tpe1MRGdvqFXaJRERyYu9mUjRuiz8EZm5hXBztMOx+QPlDoeIiAyIvZnIqmTlFppXzyYiIjIZJjOkaFs9PsV5TSTetfuAcyMREVkpJjOkaP43foStqgQR6kO4l19k1NIZsxzbhoiImMyQwnUYAUCFQtghouB7o5XOrD+Uhvnfnqx8dmxOY0BEJCsmM6Rsz6wBXJvDEfn4p91/jTZzdXxiKooFoFah4nscWK6dxuDAcqO8NxERVY/JDCnfg2kEvCLmGGXm6vWH0nAvvwhujnZYOKxjxffgNAZkIByMkahubOUOgKjeSqcPeFAyMvV8NyQcv46Izt54f1TXeh8+PjEVmbmF8HFz/DuR+ToKOLUV8OoM3PtTm8hwGgOqp7KDMRrib5fIWrBkhixDmaqe0gvC9j+uG6SxbnRoACY7/4S9xROAxS21bWNObQVEMXD9KKuYyGA4GCNR3XDQPLIMh9doE4reMZh6vhu2/6GdZkCtQuVVQ7U99neztMkLoK1S8g1myQwRkZHpe/1mMkMWqbT3UbEAfNwccTC2f807PUiILjp2hEPGb7jcfhKCn5ul7amUdQWACnBwAwbMZeJCxlFafdlhhLZxO5GVYzJTBpMZ67T+UBriE1PRxMkep65n/d2G5vAaYO8iID8HKCkCbB2B8H8jZ89SOOelowg2sEUJ0uEOrwXndUp9mMSQUS1srC0BVKmB+bfljoZIdpzOgKzb4TWI/KkvDuJFLLo1BSn2kRhw+nUAQM6epUDuHaCkEIAAiu4jZ89SxBcNxVXRFD8iBOlwx+X2k7THejCpJRMZ4+GAhA90GKFNZDqMkDsSIkVhbyayPF9HASe/lp52trkDFYAn1YcAAPFFQzFRrEcD5MEOxciFPeKLhsIrbDJGJg5CdGgAvHr4wUum8K3Rsp0pyMwtxLKdKUbpXq8Yz6xh9RJRHTCZeaCkpAQFBQVyh0F1ZGdnB7VarX1yauvfLzg0gqpxSyD9ONQP7na9wiaj384w3MsvQmGJgKOdDf4V1h6RPfys+0JKRKRQTGYAFBQU4OLFiygpKZE7FKoHNzc3eHp6QtVhRLWNKJm0mJ+Z4W0Qn5hqtBGciciyWX0DYCEELl++jMLCQnh7e8PGhs2IlEYIgfv37+PmzZtwc3ODlxcriIiILIG+DYCtvmSmqKgI9+/fh7e3Nxo0aCB3OFRHjo6OAICbN2+iWbNmf1c5ERGRxbP6YojiYu1AaPb29jJHQvVVmowWFhbKHAnV2oOZx5O3LGWvJiKqNatPZkqpVCq5Q6B64neoYA+mo2hxejWuZeYiPjFV7oiISEGYzBCR/HyDAZUa1xp2gloFBPo1kjsiIlIQJjNEJL8ryYAohs/dEygWwJG0O3JHREQKwmRGgVQqVbWPBQsWyB0iUe30jgFcfXG5/ST4uDlaVRdtjn5MVH9W35tJidLT06V/b968GfPmzUNKSoq0ztnZWfq3EALFxcWwteVXTWYsKAoIikIwgINyx2Ji8YmpUjshjn9EVDcsmVEgT09P6eHq6gqVSiU9P3v2LBo2bIjvv/8egYGB0Gg0OHDgACZMmIDhw4frHGfatGkIDQ2VnpeUlCAuLg7+/v5wdHTEI488gq+//hpEpjR0xQG0jE3A0BUH5A7FJKJDA6yuNIrI0Hi7bqFiY2OxbNkytGrVCo0a6deYMi4uDuvXr8eqVavw0EMP4eeff0ZkZCTc3d3Rt29fI0dMpHX8WpbO0tJxRGqi+mMyY6HeeOMNPP7443pvn5+fj7feegu7d+9GSEgIAKBVq1Y4cOAAVq9ezWSGTKazjyuOX8tCZx9XuUMhIoVgMmNA6w+lSfPLyH2n1b1791ptf/78edy/f79CAlRQUICuXbsaMjSiqh1eg+1Fy4GnY4CgCLmjMTpz+s0gUjImMwZkTg35nJycdJ7b2Nig/DRcZUfKzcnJAQAkJCTAx8dHZzuNRmOkKInK2bsIyL2jXQZFyR2N0ZnTbwaRkrEBsAGZc0M+d3d3nV5QAHDs2DHp3+3bt4dGo8Hly5fRunVrnYevr6+JoyWrJf5eWkOX5ejQAEx2/gk78Yp2SgciqhMmMwYU2cMPB2P7m+UdVv/+/fHbb7/h888/x7lz5zB//nycPHlSer1hw4aYOXMmYmJisG7dOqSmpuL333/HihUrsG7dOhkjJ6syYC5gYwfk3UG3nU9Z9NQGUhWT7XY456Vrp3QgojphMmMlwsPDMXfuXMyePRtBQUG4e/cuxo0bp7PNokWLMHfuXMTFxaFdu3YYNGgQEhIS4O/vL1PUZHWCooASbfVnO3HebEs6DUGqYioaCrj6agcOJKI6UYnyDSksUHZ2NlxdXZGVlQUXFxed1/Ly8nDx4kX4+/vDwcFBpgjJEPhdWoiPQoHrRwHvrsBLiXJHYzRs/EtUs+qu32WxATARmZfSBObwGmB5R22JhQU2Bub4MkSGw2omIjJPB5YDWVfYloSIasRkhojM04PJJ9mWhIhqwmomIjJPDyafJCKqCUtmiIiISNGYzBAREZGiMZkhIkWZuukoAuYkYOqmo3KHUn+lPbY4+i9RvTCZISJFSTh+HcVCu1SKKhMw9tgiMggmM0SkKBGdvaFWaZdKUWUCxh5bRAbBZIaqNWHCBAwfPlx6HhoaimnTppk8jsTERKhUKmRmZpr8vcm8vG/3AVIdxuJ9uw/kDqVGpZNldvB2rTwBC4oCYk6y1xZRPTGZUagJEyZApVJBpVLB3t4erVu3xhtvvIGioiKjvu9//vMfLFq0SK9tmYCQUZzaCohi7fIBc51hu3T+pb/uFSA1LgLvj+oqd0hEFonJjIINGjQI6enpOHfuHGbMmIEFCxZg6dKlFbYrKCgw2Hs2btwYDRs2NNjxiGqtwwhApdYuH5AmbTSDGbbXH0pDl4U/osvCHxHo16jqyTLZ+JfIYIyWzLz55pvo2bMnGjRoADc3t0q3uXz5MiIiItCgQQM0a9YMs2bNqlCykJiYiG7dukGj0aB169ZYu3atsUJWHI1GA09PT/j5+SE6OhphYWHYvn27VDX05ptvwtvbG23atAEAXLlyBc899xzc3NzQuHFjDBs2DJcuXZKOV1xcjOnTp8PNzQ1NmjTB7NmzUX4e0vLVTPn5+Xjttdfg6+srfUdr1qzBpUuX0K9fPwBAo0aNoFKpMGHCBABASUkJ4uLi4O/vD0dHRzzyyCP4+uuvdd7nu+++w8MPPwxHR0f069dPJ06ycs+sAebf1i4fiA4N0Eka5CypiU9MRWZuITJzC3Ek7Q4OxvavfA4mNv4lMhijJTMFBQV49tlnER0dXenrxcXFiIiIQEFBAX755ResW7cOa9euxbx586RtLl68iIiICPTr1w/Hjh3DtGnTMHHiROzcudNYYSuao6OjVAqzZ88epKSkYNeuXdixYwcKCwsRHh6Ohg0bYv/+/Th48CCcnZ0xaNAgaZ//+7//w9q1a/Hpp5/iwIEDuH37NrZu3VrdW2LcuHHYtGkT3n//fZw5cwarV6+Gs7MzfH198c033wAAUlJSkJ6ejvfeew8AEBcXh88//xyrVq3CqVOnEBMTg8jISPz0008AtEnXU089hSFDhuDYsWOYOHEiYmNjjXXayAJE9vDTSRrKltQMXXEALWMTMHTFAYMkOTUdIzo0AG6OdnBztKu8RKYUG/8SGY4wss8++0y4urpWWP/dd98JGxsbkZGRIa2Lj48XLi4uIj8/XwghxOzZs0WHDh109hs5cqQIDw+vVQxZWVkCgMjKyqrwWm5urjh9+rTIzc2t1THlNn78eDFs2DAhhBAlJSVi165dQqPRiJkzZ4rx48cLDw8P6TwKIcQXX3wh2rRpI0pKSqR1+fn5wtHRUezcuVMIIYSXl5d4++23pdcLCwtF8+bNpfcRQoi+ffuKV199VQghREpKigAgdu3aVWmM+/btEwDEnTt3pHV5eXmiQYMG4pdfftHZNioqSowaNUoIIcScOXNE+/btdV5/7bXXKhyrPKV+l2R4XyRdEj3j9ogvki4Jv9d2SI+ecXukpT77T9n4u3Sc0nWPLNip1zGIqP6qu36XJVubmaSkJHTq1AkeHh7SuvDwcGRnZ+PUqVPSNmFhYTr7hYeHIykpqdpj5+fnIzs7W+dhEiauA9+xYwecnZ3h4OCAJ554AiNHjsSCBQsAAJ06dYK9vb207R9//IHz58+jYcOGcHZ2hrOzMxo3boy8vDykpqYiKysL6enpCA4OlvaxtbVF9+7dq3z/Y8eOQa1Wo2/fvnrHfP78edy/fx+PP/64FIezszM+//xzpKZq2zucOXNGJw4ACAkJ0fs9iMqW1HT2cQUAdPZxrVAdVZXSkp2E49elEp7SdQD0OgYRmY5sE01mZGToJDIApOcZGRnVbpOdnY3c3Fw4OjpWeuy4uDgsXLjQCFHXoGwduAm6Wvbr1w/x8fGwt7eHt7c3bG3//jqdnJx0ts3JyUFgYCA2bNhQ4Tju7u51ev+qzn91cnJyAAAJCQnw8fHReU2j0dQpDiIcXqP9f9c7Rvt/r8zz7ZovAIejgKYroB6LSM1yQB0DoOr/o9GhAYhPTEWgXyMcSbsjJS7xiamIDg2ovA0MEcmmViUzsbGxUnfgqh5nz541Vqx6mzNnDrKysqTHlStXTPPGJq4Dd3JyQuvWrdGiRQudRKYy3bp1w7lz59CsWTO0bt1a5+Hq6gpXV1d4eXkhOTlZ2qeoqAhHjhyp8pidOnVCSUmJ1NalvNKSoeLiYmld+/btodFocPny5Qpx+Pr6AgDatWuHX3/9VedYhw4dqv5kkHUr35i27PPrD0bdvX5U70a3kerdOKiZivftPsBBzVREqndL6yKvvlF9CezhNcCSlsDilsDXUdptPwoFFjbWPicig6tVMjNjxgycOXOm2kerVq30Opanpydu3Lihs670uaenZ7XbuLi4VFsqoNFo4OLiovMwCTMeAGvMmDFo2rQphg0bhv379+PixYtITEzE1KlTcfXqVQDAq6++isWLF2Pbtm04e/YsXnnllWrHiGnZsiXGjx+PF198Edu2bZOOuWXLFgCAn58fVCoVduzYgVu3biEnJwcNGzbEzJkzERMTg3Xr1iE1NRW///47VqxYgXXr1gEAXn75ZZw7dw6zZs1CSkoKNm7cyF5sVL3yNxJln3s/GNvFu6v+NxylSc+prX8nP5Wtq2rf3DtA3p2/t71+tMLYOERkOLWqZnJ3d69zlUR5ISEhePPNN3Hz5k00a9YMALBr1y64uLigffv20jbfffedzn67du1i+4k6aNCgAX7++We89tpreOqpp3D37l34+PhgwIABUrI3Y8YMpKenY/z48bCxscGLL76IESNGICsrq8rjxsfH4/XXX8crr7yCv/76Cy1atMDrr78OAPDx8cHChQsRGxuLF154AePGjcPatWuxaNEiuLu7Iy4uDhcuXICbmxu6desm7deiRQt88803iImJwYoVK/Doo4/irbfewosvvmj8E0XKFBSlexNR9nn5mwt9bjZ6x2iTEt9g4Ery38lPZesq23fvIkAAaD1Au61TUyD9uM7YOERkOCohyg0kYiCXL1/G7du3sX37dixduhT79+8HALRu3RrOzs4oLi5Gly5d4O3tjbfffhsZGRkYO3YsJk6ciLfeeguAtmt2x44dMXnyZLz44ovYu3cvpk6dioSEBISHh+sdS3Z2NlxdXZGVlVWhlCYvLw8XL16Ev78/HBwcDHcCyOT4XRIRWZbqrt9lGa0B8Lx586RqAwDo2lVb1Ltv3z6EhoZCrVZjx44diI6ORkhICJycnDB+/Hi88cYb0j7+/v5ISEhATEwM3nvvPTRv3hyffPJJrRIZIiIismxGK5kxJyyZsQ78LomILIu+JTOcm4mIiIgUjckMERERKRqTGSIiIlI0JjMPWEHTIYtXUlIidwhERCQD2aYzMBd2dnZQqVS4desW3N3doVKp5A6JakkIgYKCAty6dQs2NjY6c1IREZHls/pkRq1Wo3nz5rh69SouXbokdzhUDw0aNECLFi1gY8MCRyIia2L1yQwAODs746GHHkJhYaHcoVAdqdVq2NrasmSNiMgKMZl5QK1WQ61Wyx0GERER1RLL44mIiEjRmMwQERGRojGZISIiIkWzijYzpWPIZGdnyxwJERER6av0ul3TWHBWkczcvXsXAODr6ytzJERERFRbd+/ehaura5WvW8Ws2SUlJbh+/ToaNmxokK672dnZ8PX1xZUrV6qdxdPS8TzwHAA8BwDPAcBzAPAcAIY/B0II3L17F97e3tWOIWYVJTM2NjZo3ry5wY/r4uJitX+wZfE88BwAPAcAzwHAcwDwHACGPQfVlciUYgNgIiIiUjQmM0RERKRoTGbqQKPRYP78+dBoNHKHIiueB54DgOcA4DkAeA4AngNAvnNgFQ2AiYiIyHKxZIaIiIgUjckMERERKRqTGSIiIlI0JjNERESkaExmiIiISNGYzOjpzTffRM+ePdGgQQO4ubnptc+ECROgUql0HoMGDTJuoEZUl3MghMC8efPg5eUFR0dHhIWF4dy5c8YN1Ihu376NMWPGwMXFBW5uboiKikJOTk61+4SGhlb4O3j55ZdNFLFhrFy5Ei1btoSDgwOCg4Px66+/Vrv9V199hbZt28LBwQGdOnXCd999Z6JIjac252Dt2rUVvnMHBwcTRmt4P//8M4YMGQJvb2+oVCps27atxn0SExPRrVs3aDQatG7dGmvXrjV6nMZU23OQmJhY4e9ApVIhIyPDNAEbWFxcHIKCgtCwYUM0a9YMw4cPR0pKSo37meL3gMmMngoKCvDss88iOjq6VvsNGjQI6enp0mPTpk1GitD46nIO3n77bbz//vtYtWoVkpOT4eTkhPDwcOTl5RkxUuMZM2YMTp06hV27dmHHjh34+eef8dJLL9W43z/+8Q+dv4O3337bBNEaxubNmzF9+nTMnz8fv//+Ox555BGEh4fj5s2blW7/yy+/YNSoUYiKisLRo0cxfPhwDB8+HCdPnjRx5IZT23MAaIdzL/udp6WlmTBiw7t37x4eeeQRrFy5Uq/tL168iIiICPTr1w/Hjh3DtGnTMHHiROzcudPIkRpPbc9BqZSUFJ2/hWbNmhkpQuP66aefMHnyZBw6dAi7du1CYWEhBg4ciHv37lW5j8l+DwTVymeffSZcXV312nb8+PFi2LBhRo1HDvqeg5KSEuHp6SmWLl0qrcvMzBQajUZs2rTJiBEax+nTpwUAcfjwYWnd999/L1Qqlbh27VqV+/Xt21e8+uqrJojQOB599FExefJk6XlxcbHw9vYWcXFxlW7/3HPPiYiICJ11wcHBYtKkSUaN05hqew5q8zuhRADE1q1bq91m9uzZokOHDjrrRo4cKcLDw40Ymenocw727dsnAIg7d+6YJCZTu3nzpgAgfvrppyq3MdXvAUtmjCwxMRHNmjVDmzZtEB0djb/++kvukEzm4sWLyMjIQFhYmLTO1dUVwcHBSEpKkjGyuklKSoKbmxu6d+8urQsLC4ONjQ2Sk5Or3XfDhg1o2rQpOnbsiDlz5uD+/fvGDtcgCgoKcOTIEZ3v0MbGBmFhYVV+h0lJSTrbA0B4eLgiv3OgbucAAHJycuDn5wdfX18MGzYMp06dMkW4ZsPS/g7qo0uXLvDy8sLjjz+OgwcPyh2OwWRlZQEAGjduXOU2pvo7sIpZs+UyaNAgPPXUU/D390dqaipef/11PPHEE0hKSoJarZY7PKMrrRf28PDQWe/h4aHIOuOMjIwKxcO2trZo3LhxtZ9n9OjR8PPzg7e3N44fP47XXnsNKSkp+M9//mPskOvtzz//RHFxcaXf4dmzZyvdJyMjw2K+c6Bu56BNmzb49NNP0blzZ2RlZWHZsmXo2bMnTp06hebNm5sibNlV9XeQnZ2N3NxcODo6yhSZ6Xh5eWHVqlXo3r078vPz8cknnyA0NBTJycno1q2b3OHVS0lJCaZNm4ZevXqhY8eOVW5nqt8Dq05mYmNjsWTJkmq3OXPmDNq2bVun4z///PPSvzt16oTOnTsjICAAiYmJGDBgQJ2OaWjGPgdKoO85qKuybWo6deoELy8vDBgwAKmpqQgICKjzccl8hYSEICQkRHres2dPtGvXDqtXr8aiRYtkjIxMqU2bNmjTpo30vGfPnkhNTcXy5cvxxRdfyBhZ/U2ePBknT57EgQMH5A4FgJUnMzNmzMCECROq3aZVq1YGe79WrVqhadOmOH/+vNkkM8Y8B56engCAGzduwMvLS1p/48YNdOnSpU7HNAZ9z4Gnp2eFBp9FRUW4ffu29Fn1ERwcDAA4f/682SczTZs2hVqtxo0bN3TW37hxo8rP7OnpWavtzV1dzkF5dnZ26Nq1K86fP2+MEM1SVX8HLi4uVlEqU5VHH33UbBKAuvrnP/8pdYCoqaTRVL8HVp3MuLu7w93d3WTvd/XqVfz11186F3a5GfMc+Pv7w9PTE3v27JGSl+zsbCQnJ9e6V5gx6XsOQkJCkJmZiSNHjiAwMBAAsHfvXpSUlEgJij6OHTsGAGb1d1AVe3t7BAYGYs+ePRg+fDgAbfHynj178M9//rPSfUJCQrBnzx5MmzZNWrdr1y6dkgolqcs5KK+4uBgnTpzA4MGDjRipeQkJCanQBVfJfweGcuzYMUX836+MEAJTpkzB1q1bkZiYCH9//xr3MdnvgUGbE1uwtLQ0cfToUbFw4ULh7Owsjh49Ko4ePSru3r0rbdOmTRvxn//8RwghxN27d8XMmTNFUlKSuHjxoti9e7fo1q2beOihh0ReXp5cH6NeansOhBBi8eLFws3NTXz77bfi+PHjYtiwYcLf31/k5ubK8RHqbdCgQaJr164iOTlZHDhwQDz00ENi1KhR0utXr14Vbdq0EcnJyUIIIc6fPy/eeOMN8dtvv4mLFy+Kb7/9VrRq1Uo89thjcn2EWvvyyy+FRqMRa9euFadPnxYvvfSScHNzExkZGUIIIcaOHStiY2Ol7Q8ePChsbW3FsmXLxJkzZ8T8+fOFnZ2dOHHihFwfod5qew4WLlwodu7cKVJTU8WRI0fE888/LxwcHMSpU6fk+gj1dvfuXen/PADxzjvviKNHj4q0tDQhhBCxsbFi7Nix0vYXLlwQDRo0ELNmzRJnzpwRK1euFGq1Wvzwww9yfYR6q+05WL58udi2bZs4d+6cOHHihHj11VeFjY2N2L17t1wfoV6io6OFq6urSExMFOnp6dLj/v370jZy/R4wmdHT+PHjBYAKj3379knbABCfffaZEEKI+/fvi4EDBwp3d3dhZ2cn/Pz8xD/+8Q/px0+JansOhNB2z547d67w8PAQGo1GDBgwQKSkpJg+eAP566+/xKhRo4Szs7NwcXERL7zwgk4yd/HiRZ1zcvnyZfHYY4+Jxo0bC41GI1q3bi1mzZolsrKyZPoEdbNixQrRokULYW9vLx599FFx6NAh6bW+ffuK8ePH62y/ZcsW8fDDDwt7e3vRoUMHkZCQYOKIDa8252DatGnSth4eHmLw4MHi999/lyFqwyntZlz+Ufq5x48fL/r27Vthny5dugh7e3vRqlUrnd8GJartOViyZIkICAgQDg4OonHjxiI0NFTs3btXnuANoLLPXv43X67fA9WDAImIiIgUiePMEBERkaIxmSEiIiJFYzJDREREisZkhoiIiBSNyQwREREpGpMZIiIiUjQmM0RERKRoTGaIiIhI0ZjMEBERkaIxmSEiIiJFYzJDREREivb/AeLk969Jfc7IAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nDLA ZBIORU TESTOWEGO\")\n",
    "eval_2d(results_df[pd.concat([results_df[\"Patience\"].apply(lambda x: x==500),results_df[\"Dropout\"].apply(lambda x: x==0), results_df[\"Fun\"].apply(lambda x: x==leaky_relu)], axis=1).all(axis=1)].reset_index()[\"Net\"][0], x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383ba21-ed02-4900-b3b9-b911978c1e2c",
   "metadata": {},
   "source": [
    "### Testy2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949cbaeb-8314-48a1-892b-f36a2ab75ab0",
   "metadata": {},
   "source": [
    "Uwagi:\n",
    "- Zwiększyłem też batch_size dla szybszego uczenia do testów\n",
    "- Dropout nie działa dobrze (więc go już nie testuje ze względu na czas)\n",
    "- Tutaj testuję też regularyzację"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f46ecd0c-a6ae-40af-94c8-f1b6152e5c85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss (standarized): 1.022888334421633\n",
      "Epoch: 6, Loss (standarized): 0.9340298990805163\n",
      "Epoch: 11, Loss (standarized): 0.8667098113282673\n",
      "Epoch: 16, Loss (standarized): 0.829769189750135\n",
      "Epoch: 21, Loss (standarized): 0.826218139643822\n",
      "Epoch: 26, Loss (standarized): 0.8130277997908859\n",
      "Epoch: 31, Loss (standarized): 0.7958962038815534\n",
      "Epoch: 36, Loss (standarized): 0.7868710974754152\n",
      "Epoch: 41, Loss (standarized): 0.7723726660289445\n",
      "Epoch: 46, Loss (standarized): 0.7555256298495102\n",
      "Epoch: 51, Loss (standarized): 0.7397438611056311\n",
      "Epoch: 56, Loss (standarized): 0.7230366298570676\n",
      "Epoch: 61, Loss (standarized): 0.7087283793143284\n",
      "Epoch: 66, Loss (standarized): 0.6959915967480835\n",
      "Epoch: 71, Loss (standarized): 0.6836885745708636\n",
      "Epoch: 76, Loss (standarized): 0.6689142789323397\n",
      "Epoch: 81, Loss (standarized): 0.6491062534315928\n",
      "Epoch: 86, Loss (standarized): 0.621439425459472\n",
      "Epoch: 91, Loss (standarized): 0.5839943942864643\n",
      "Epoch: 96, Loss (standarized): 0.5387018530627362\n",
      "Final epoch: 100, Final loss (standarized): 0.5009445189957903\n",
      "Epoch: 1, Loss (standarized): 1.2216219876606784\n",
      "Epoch: 6, Loss (standarized): 1.0571583920573737\n",
      "Epoch: 11, Loss (standarized): 0.9856505563175532\n",
      "Epoch: 16, Loss (standarized): 0.9566335301810092\n",
      "Epoch: 21, Loss (standarized): 0.9479891378474647\n",
      "Epoch: 26, Loss (standarized): 0.919772910951164\n",
      "Epoch: 31, Loss (standarized): 0.9020842019851546\n",
      "Epoch: 36, Loss (standarized): 0.8858734029533647\n",
      "Epoch: 41, Loss (standarized): 0.8672735489979473\n",
      "Epoch: 46, Loss (standarized): 0.8523109950053452\n",
      "Epoch: 51, Loss (standarized): 0.8410869830838192\n",
      "Epoch: 56, Loss (standarized): 0.8322742734037536\n",
      "Epoch: 61, Loss (standarized): 0.8257271265771685\n",
      "Epoch: 66, Loss (standarized): 0.8209660201448173\n",
      "Epoch: 71, Loss (standarized): 0.8173645670069046\n",
      "Epoch: 76, Loss (standarized): 0.8142238965294691\n",
      "Epoch: 81, Loss (standarized): 0.8109978670631847\n",
      "Epoch: 86, Loss (standarized): 0.8074275274453363\n",
      "Epoch: 91, Loss (standarized): 0.8034654795064273\n",
      "Epoch: 96, Loss (standarized): 0.7992500339733034\n",
      "Final epoch: 100, Final loss (standarized): 0.7958119256737174\n",
      "Epoch: 1, Loss (standarized): 1.4126587134292479\n",
      "Epoch: 6, Loss (standarized): 1.0825103161378706\n",
      "Epoch: 11, Loss (standarized): 0.9751185874091547\n",
      "Epoch: 16, Loss (standarized): 0.9877458042797368\n",
      "Epoch: 21, Loss (standarized): 0.9320917784743681\n",
      "Epoch: 26, Loss (standarized): 0.9273282860760569\n",
      "Epoch: 31, Loss (standarized): 0.8940160072692714\n",
      "Epoch: 36, Loss (standarized): 0.8796448699528024\n",
      "Epoch: 41, Loss (standarized): 0.8570895291153514\n",
      "Epoch: 46, Loss (standarized): 0.8412440910332389\n",
      "Epoch: 51, Loss (standarized): 0.8286082295690644\n",
      "Epoch: 56, Loss (standarized): 0.8183655310100043\n",
      "Epoch: 61, Loss (standarized): 0.8118368324369409\n",
      "Epoch: 66, Loss (standarized): 0.8056573233647532\n",
      "Epoch: 71, Loss (standarized): 0.7991698541819494\n",
      "Epoch: 76, Loss (standarized): 0.7924645453179333\n",
      "Epoch: 81, Loss (standarized): 0.7854984171582607\n",
      "Epoch: 86, Loss (standarized): 0.7784682510209109\n",
      "Epoch: 91, Loss (standarized): 0.7714608022705973\n",
      "Epoch: 96, Loss (standarized): 0.7643397215810226\n",
      "Final epoch: 100, Final loss (standarized): 0.7585072073316976\n",
      "Epoch: 1, Loss (standarized): 1.2701463977585639\n",
      "Epoch: 6, Loss (standarized): 1.060005233705642\n",
      "Epoch: 11, Loss (standarized): 0.9584325715143688\n",
      "Epoch: 16, Loss (standarized): 0.9645501212156603\n",
      "Epoch: 21, Loss (standarized): 0.9172829329372407\n",
      "Epoch: 26, Loss (standarized): 0.8965656979482267\n",
      "Epoch: 31, Loss (standarized): 0.8683200097426393\n",
      "Epoch: 36, Loss (standarized): 0.8411102632201661\n",
      "Epoch: 41, Loss (standarized): 0.8217928191434968\n",
      "Epoch: 46, Loss (standarized): 0.8032970500347375\n",
      "Epoch: 51, Loss (standarized): 0.7908702903485814\n",
      "Epoch: 56, Loss (standarized): 0.7812665266747266\n",
      "Epoch: 61, Loss (standarized): 0.7714741091419585\n",
      "Epoch: 66, Loss (standarized): 0.7617630400853809\n",
      "Epoch: 71, Loss (standarized): 0.7525278618346605\n",
      "Epoch: 76, Loss (standarized): 0.7440931396390568\n",
      "Epoch: 81, Loss (standarized): 0.7363046560025159\n",
      "Epoch: 86, Loss (standarized): 0.7288952179979944\n",
      "Epoch: 91, Loss (standarized): 0.7216792860061537\n",
      "Epoch: 96, Loss (standarized): 0.7146693812637309\n",
      "Final epoch: 100, Final loss (standarized): 0.7092240759878516\n",
      "Epoch: 1, Loss (standarized): 1.170419046108669\n",
      "Epoch: 6, Loss (standarized): 1.0362565274703357\n",
      "Epoch: 11, Loss (standarized): 0.9952814743255345\n",
      "Epoch: 16, Loss (standarized): 0.9811587366685222\n",
      "Epoch: 21, Loss (standarized): 0.9775530037770812\n",
      "Epoch: 26, Loss (standarized): 0.9725246879738151\n",
      "Epoch: 31, Loss (standarized): 0.9724704421865663\n",
      "Epoch: 36, Loss (standarized): 0.9718279482506954\n",
      "Epoch: 41, Loss (standarized): 0.9714815018198731\n",
      "Epoch: 46, Loss (standarized): 0.9708362250475598\n",
      "Epoch: 51, Loss (standarized): 0.9703555223008932\n",
      "Epoch: 56, Loss (standarized): 0.9701521802660276\n",
      "Epoch: 61, Loss (standarized): 0.9696963621437206\n",
      "Epoch: 66, Loss (standarized): 0.967829885660785\n",
      "Epoch: 71, Loss (standarized): 0.965636391721679\n",
      "Epoch: 76, Loss (standarized): 0.9630061361269263\n",
      "Epoch: 81, Loss (standarized): 0.9596522755679977\n",
      "Epoch: 86, Loss (standarized): 0.9557183661191754\n",
      "Epoch: 91, Loss (standarized): 0.9513049272078087\n",
      "Epoch: 96, Loss (standarized): 0.9463035407526897\n",
      "Final epoch: 100, Final loss (standarized): 0.9417631190779755\n",
      "Epoch: 1, Loss (standarized): 1.1322393150551189\n",
      "Epoch: 6, Loss (standarized): 1.0267538150856796\n",
      "Epoch: 11, Loss (standarized): 0.9910674053006495\n",
      "Epoch: 16, Loss (standarized): 0.9914621120809954\n",
      "Epoch: 21, Loss (standarized): 0.9939610393476961\n",
      "Epoch: 26, Loss (standarized): 0.9932359745451226\n",
      "Epoch: 31, Loss (standarized): 0.9959567139241832\n",
      "Epoch: 36, Loss (standarized): 0.9980345573541834\n",
      "Epoch: 41, Loss (standarized): 0.9985928272998047\n",
      "Epoch: 46, Loss (standarized): 0.9992100279858434\n",
      "Epoch: 51, Loss (standarized): 0.999610196057558\n",
      "Epoch: 56, Loss (standarized): 1.000011043616075\n",
      "Epoch: 61, Loss (standarized): 1.0000842813330713\n",
      "Epoch: 66, Loss (standarized): 1.0001929668192404\n",
      "Epoch: 71, Loss (standarized): 1.0000038042162818\n",
      "Epoch: 76, Loss (standarized): 1.0000072375508742\n",
      "Epoch: 81, Loss (standarized): 1.0000084347772593\n",
      "Epoch: 86, Loss (standarized): 0.9999981488860648\n",
      "Epoch: 91, Loss (standarized): 1.0000243594555802\n",
      "Epoch: 96, Loss (standarized): 1.0000021581128835\n",
      "Final epoch: 100, Final loss (standarized): 1.0000211599164306\n",
      "Epoch: 1, Loss (standarized): 1.0955578609145067\n",
      "Epoch: 6, Loss (standarized): 1.0147267599385488\n",
      "Epoch: 11, Loss (standarized): 0.986825621172627\n",
      "Epoch: 16, Loss (standarized): 0.9862121865752226\n",
      "Epoch: 21, Loss (standarized): 0.9885288610993884\n",
      "Epoch: 26, Loss (standarized): 0.9880431340869684\n",
      "Epoch: 31, Loss (standarized): 0.990943327914452\n",
      "Epoch: 36, Loss (standarized): 0.9938462776954793\n",
      "Epoch: 41, Loss (standarized): 0.9969149046221452\n",
      "Epoch: 46, Loss (standarized): 0.9991084842896545\n",
      "Epoch: 51, Loss (standarized): 1.0002539588150616\n",
      "Epoch: 56, Loss (standarized): 1.0000608929500678\n",
      "Epoch: 61, Loss (standarized): 0.999937764407065\n",
      "Epoch: 66, Loss (standarized): 0.9999692068468266\n",
      "Epoch: 71, Loss (standarized): 0.9999952217609451\n",
      "Epoch: 76, Loss (standarized): 1.0000194884981188\n",
      "Epoch: 81, Loss (standarized): 0.9999966245111616\n",
      "Epoch: 86, Loss (standarized): 1.0000042390662809\n",
      "Epoch: 91, Loss (standarized): 1.0000023648049567\n",
      "Epoch: 96, Loss (standarized): 1.0000261977297726\n",
      "Final epoch: 100, Final loss (standarized): 1.0000338196803005\n",
      "Epoch: 1, Loss (standarized): 1.5305145896157515\n",
      "Epoch: 6, Loss (standarized): 1.0225521065499037\n",
      "Epoch: 11, Loss (standarized): 1.0449322111150117\n",
      "Epoch: 16, Loss (standarized): 0.992439336758283\n",
      "Epoch: 21, Loss (standarized): 1.0123264451742098\n",
      "Epoch: 26, Loss (standarized): 0.9897011462363897\n",
      "Epoch: 31, Loss (standarized): 0.9950604131588238\n",
      "Epoch: 36, Loss (standarized): 0.9926811280753908\n",
      "Epoch: 41, Loss (standarized): 0.9960673679924061\n",
      "Epoch: 46, Loss (standarized): 0.9964432333900912\n",
      "Epoch: 51, Loss (standarized): 0.9979977891194082\n",
      "Epoch: 56, Loss (standarized): 0.9990113490164017\n",
      "Epoch: 61, Loss (standarized): 0.9996055659115637\n",
      "Epoch: 66, Loss (standarized): 1.000024627305385\n",
      "Epoch: 71, Loss (standarized): 1.000110456091845\n",
      "Epoch: 76, Loss (standarized): 0.9999806950513754\n",
      "Epoch: 81, Loss (standarized): 1.0000725965155564\n",
      "Epoch: 86, Loss (standarized): 1.0000019136331193\n",
      "Epoch: 91, Loss (standarized): 1.0000626556745345\n",
      "Epoch: 96, Loss (standarized): 1.0000003312934513\n",
      "Final epoch: 100, Final loss (standarized): 0.999999898190222\n",
      "Epoch: 1, Loss (standarized): 1.4277735719030968\n",
      "Epoch: 6, Loss (standarized): 1.0559368960473496\n",
      "Epoch: 11, Loss (standarized): 1.017013415076454\n",
      "Epoch: 16, Loss (standarized): 0.9860061218893593\n",
      "Epoch: 21, Loss (standarized): 0.9685560212489633\n",
      "Epoch: 26, Loss (standarized): 0.9433021731497881\n",
      "Epoch: 31, Loss (standarized): 0.9291032086511939\n",
      "Epoch: 36, Loss (standarized): 0.9087008103955807\n",
      "Epoch: 41, Loss (standarized): 0.8908000950579537\n",
      "Epoch: 46, Loss (standarized): 0.8715164782982686\n",
      "Epoch: 51, Loss (standarized): 0.8517188695810208\n",
      "Epoch: 56, Loss (standarized): 0.8339686695444595\n",
      "Epoch: 61, Loss (standarized): 0.8165921222849596\n",
      "Epoch: 66, Loss (standarized): 0.8018565431081836\n",
      "Epoch: 71, Loss (standarized): 0.7889075864747513\n",
      "Epoch: 76, Loss (standarized): 0.777597701992604\n",
      "Epoch: 81, Loss (standarized): 0.7676201877380419\n",
      "Epoch: 86, Loss (standarized): 0.7586022125932043\n",
      "Epoch: 91, Loss (standarized): 0.7504006438116975\n",
      "Epoch: 96, Loss (standarized): 0.7429380811860863\n",
      "Final epoch: 100, Final loss (standarized): 0.7375023826497005\n",
      "Epoch: 1, Loss (standarized): 1.0819724357859828\n",
      "Epoch: 6, Loss (standarized): 0.996294676837476\n",
      "Epoch: 11, Loss (standarized): 0.9810144259913318\n",
      "Epoch: 16, Loss (standarized): 0.9578508054730934\n",
      "Epoch: 21, Loss (standarized): 0.938497138462188\n",
      "Epoch: 26, Loss (standarized): 0.9231400964257988\n",
      "Epoch: 31, Loss (standarized): 0.9101434995987627\n",
      "Epoch: 36, Loss (standarized): 0.8982223565073838\n",
      "Epoch: 41, Loss (standarized): 0.8862436507946606\n",
      "Epoch: 46, Loss (standarized): 0.8760716955938361\n",
      "Epoch: 51, Loss (standarized): 0.8663103035377496\n",
      "Epoch: 56, Loss (standarized): 0.8578052954093632\n",
      "Epoch: 61, Loss (standarized): 0.8494942870344119\n",
      "Epoch: 66, Loss (standarized): 0.8414714536085874\n",
      "Epoch: 71, Loss (standarized): 0.8332909102366001\n",
      "Epoch: 76, Loss (standarized): 0.8250164116546733\n",
      "Epoch: 81, Loss (standarized): 0.8165402649042971\n",
      "Epoch: 86, Loss (standarized): 0.8080306768347318\n",
      "Epoch: 91, Loss (standarized): 0.7995116217033985\n",
      "Epoch: 96, Loss (standarized): 0.7910046125907146\n",
      "Final epoch: 100, Final loss (standarized): 0.7844342654213151\n",
      "Epoch: 1, Loss (standarized): 1.0817148036398418\n",
      "Epoch: 6, Loss (standarized): 0.9871524313516236\n",
      "Epoch: 11, Loss (standarized): 0.9606087536649139\n",
      "Epoch: 16, Loss (standarized): 0.9249663211515093\n",
      "Epoch: 21, Loss (standarized): 0.9021636273562705\n",
      "Epoch: 26, Loss (standarized): 0.883692903943371\n",
      "Epoch: 31, Loss (standarized): 0.8628301380704574\n",
      "Epoch: 36, Loss (standarized): 0.8438716827852492\n",
      "Epoch: 41, Loss (standarized): 0.8284755675210527\n",
      "Epoch: 46, Loss (standarized): 0.8154335148269384\n",
      "Epoch: 51, Loss (standarized): 0.8036267690592499\n",
      "Epoch: 56, Loss (standarized): 0.7923886255481997\n",
      "Epoch: 61, Loss (standarized): 0.7815354163923459\n",
      "Epoch: 66, Loss (standarized): 0.7710379971845587\n",
      "Epoch: 71, Loss (standarized): 0.761116211677659\n",
      "Epoch: 76, Loss (standarized): 0.7516496107054144\n",
      "Epoch: 81, Loss (standarized): 0.7427491377132821\n",
      "Epoch: 86, Loss (standarized): 0.734450001215669\n",
      "Epoch: 91, Loss (standarized): 0.7269816109703585\n",
      "Epoch: 96, Loss (standarized): 0.7205881054826644\n",
      "Final epoch: 100, Final loss (standarized): 0.7162871173448393\n",
      "Epoch: 1, Loss (standarized): 1.4384564152422095\n",
      "Epoch: 6, Loss (standarized): 1.0712464178442616\n",
      "Epoch: 11, Loss (standarized): 0.9669162475257291\n",
      "Epoch: 16, Loss (standarized): 0.9795428545374527\n",
      "Epoch: 21, Loss (standarized): 0.9218489526090426\n",
      "Epoch: 26, Loss (standarized): 0.917677362374819\n",
      "Epoch: 31, Loss (standarized): 0.8830838233812649\n",
      "Epoch: 36, Loss (standarized): 0.8706131010136353\n",
      "Epoch: 41, Loss (standarized): 0.849013962944223\n",
      "Epoch: 46, Loss (standarized): 0.8351261953313024\n",
      "Epoch: 51, Loss (standarized): 0.8239362055295306\n",
      "Epoch: 56, Loss (standarized): 0.8135452979652161\n",
      "Epoch: 61, Loss (standarized): 0.8058737576098359\n",
      "Epoch: 66, Loss (standarized): 0.7983082656159013\n",
      "Epoch: 71, Loss (standarized): 0.7908190636571643\n",
      "Epoch: 76, Loss (standarized): 0.7836633100152575\n",
      "Epoch: 81, Loss (standarized): 0.7765746936664051\n",
      "Epoch: 86, Loss (standarized): 0.769601107931277\n",
      "Epoch: 91, Loss (standarized): 0.7626972363115462\n",
      "Epoch: 96, Loss (standarized): 0.7558111829280169\n",
      "Final epoch: 100, Final loss (standarized): 0.7502947254767969\n",
      "Epoch: 1, Loss (standarized): 1.7910677441759986\n",
      "Epoch: 6, Loss (standarized): 1.0585745333485086\n",
      "Epoch: 11, Loss (standarized): 1.1077432051587963\n",
      "Epoch: 16, Loss (standarized): 0.9787688578145886\n",
      "Epoch: 21, Loss (standarized): 1.0007494221241082\n",
      "Epoch: 26, Loss (standarized): 0.9407996517827911\n",
      "Epoch: 31, Loss (standarized): 0.9318292747607536\n",
      "Epoch: 36, Loss (standarized): 0.9018460446458036\n",
      "Epoch: 41, Loss (standarized): 0.8807158569967299\n",
      "Epoch: 46, Loss (standarized): 0.8580342590776248\n",
      "Epoch: 51, Loss (standarized): 0.8374369704525841\n",
      "Epoch: 56, Loss (standarized): 0.8194996844404535\n",
      "Epoch: 61, Loss (standarized): 0.8050503933273788\n",
      "Epoch: 66, Loss (standarized): 0.7934164177514743\n",
      "Epoch: 71, Loss (standarized): 0.7844516508132549\n",
      "Epoch: 76, Loss (standarized): 0.7759414173597468\n",
      "Epoch: 81, Loss (standarized): 0.7677817262983625\n",
      "Epoch: 86, Loss (standarized): 0.75922555420614\n",
      "Epoch: 91, Loss (standarized): 0.7507896434272716\n",
      "Epoch: 96, Loss (standarized): 0.7426522025012069\n",
      "Final epoch: 100, Final loss (standarized): 0.7364535474767441\n",
      "Epoch: 1, Loss (standarized): 0.9997509340818066\n",
      "Epoch: 6, Loss (standarized): 0.9692070422983029\n",
      "Epoch: 11, Loss (standarized): 0.9531198415706761\n",
      "Epoch: 16, Loss (standarized): 0.9375644919363093\n",
      "Epoch: 21, Loss (standarized): 0.9212731750287351\n",
      "Epoch: 26, Loss (standarized): 0.9036663480807157\n",
      "Epoch: 31, Loss (standarized): 0.8843520731736427\n",
      "Epoch: 36, Loss (standarized): 0.8647385114346978\n",
      "Epoch: 41, Loss (standarized): 0.8463363085245532\n",
      "Epoch: 46, Loss (standarized): 0.8311536303792945\n",
      "Epoch: 51, Loss (standarized): 0.8198224609541891\n",
      "Epoch: 56, Loss (standarized): 0.8117193119550491\n",
      "Epoch: 61, Loss (standarized): 0.8055626560305622\n",
      "Epoch: 66, Loss (standarized): 0.7998661330544803\n",
      "Epoch: 71, Loss (standarized): 0.7936704905024841\n",
      "Epoch: 76, Loss (standarized): 0.7872795067195316\n",
      "Epoch: 81, Loss (standarized): 0.7814089350458068\n",
      "Epoch: 86, Loss (standarized): 0.776451087339355\n",
      "Epoch: 91, Loss (standarized): 0.7722246656477892\n",
      "Epoch: 96, Loss (standarized): 0.7682711544509715\n",
      "Final epoch: 100, Final loss (standarized): 0.7650520138302553\n",
      "Epoch: 1, Loss (standarized): 1.4187090204997668\n",
      "Epoch: 6, Loss (standarized): 1.0700761947733988\n",
      "Epoch: 11, Loss (standarized): 0.9986437276631304\n",
      "Epoch: 16, Loss (standarized): 0.9868893079067689\n",
      "Epoch: 21, Loss (standarized): 0.9482958952003067\n",
      "Epoch: 26, Loss (standarized): 0.9309427125821774\n",
      "Epoch: 31, Loss (standarized): 0.90356471247669\n",
      "Epoch: 36, Loss (standarized): 0.8834828241052352\n",
      "Epoch: 41, Loss (standarized): 0.8582565084567279\n",
      "Epoch: 46, Loss (standarized): 0.8394498524917692\n",
      "Epoch: 51, Loss (standarized): 0.8203073704149102\n",
      "Epoch: 56, Loss (standarized): 0.8071497840553239\n",
      "Epoch: 61, Loss (standarized): 0.796206093298667\n",
      "Epoch: 66, Loss (standarized): 0.7872536114238163\n",
      "Epoch: 71, Loss (standarized): 0.7791895979321455\n",
      "Epoch: 76, Loss (standarized): 0.7709352321343937\n",
      "Epoch: 81, Loss (standarized): 0.7630279363521338\n",
      "Epoch: 86, Loss (standarized): 0.7556582833515687\n",
      "Epoch: 91, Loss (standarized): 0.7487091178362136\n",
      "Epoch: 96, Loss (standarized): 0.7421643064399939\n",
      "Final epoch: 100, Final loss (standarized): 0.7371603811704401\n",
      "Epoch: 1, Loss (standarized): 1.0772477096980062\n",
      "Epoch: 6, Loss (standarized): 1.0052243616621541\n",
      "Epoch: 11, Loss (standarized): 0.9442039271777357\n",
      "Epoch: 16, Loss (standarized): 0.8950149275785451\n",
      "Epoch: 21, Loss (standarized): 0.8574292662778751\n",
      "Epoch: 26, Loss (standarized): 0.8339224363524778\n",
      "Epoch: 31, Loss (standarized): 0.8238851384092826\n",
      "Epoch: 36, Loss (standarized): 0.8199860514609121\n",
      "Epoch: 41, Loss (standarized): 0.8136185347647477\n",
      "Epoch: 46, Loss (standarized): 0.8049115854970832\n",
      "Epoch: 51, Loss (standarized): 0.7971296783249008\n",
      "Epoch: 56, Loss (standarized): 0.7902571114145098\n",
      "Epoch: 61, Loss (standarized): 0.7827170441561135\n",
      "Epoch: 66, Loss (standarized): 0.7741467366941228\n",
      "Epoch: 71, Loss (standarized): 0.7650832386145666\n",
      "Epoch: 76, Loss (standarized): 0.7558326979000703\n",
      "Epoch: 81, Loss (standarized): 0.7463301069673878\n",
      "Epoch: 86, Loss (standarized): 0.736658724634797\n",
      "Epoch: 91, Loss (standarized): 0.726992787038604\n",
      "Epoch: 96, Loss (standarized): 0.7173137725068223\n",
      "Final epoch: 100, Final loss (standarized): 0.7095010316480849\n",
      "Epoch: 1, Loss (standarized): 1.0104573571703315\n",
      "          Validation Loss (standardized): 0.9929056813746032\n",
      "Epoch: 6, Loss (standarized): 0.9782848455557012\n",
      "          Validation Loss (standardized): 0.8976780547618555\n",
      "Epoch: 11, Loss (standarized): 0.9462982619878059\n",
      "          Validation Loss (standardized): 0.9049000024899434\n",
      "Epoch: 16, Loss (standarized): 0.912263651400373\n",
      "          Validation Loss (standardized): 0.8336324049026379\n",
      "Epoch: 21, Loss (standarized): 0.8764919871008885\n",
      "          Validation Loss (standardized): 0.812326977015687\n",
      "Epoch: 26, Loss (standarized): 0.8441672106019951\n",
      "          Validation Loss (standardized): 0.7587452393933796\n",
      "Epoch: 31, Loss (standarized): 0.8222583068178917\n",
      "          Validation Loss (standardized): 0.7389184106432108\n",
      "Epoch: 36, Loss (standarized): 0.8126027436915528\n",
      "          Validation Loss (standardized): 0.7251000382511416\n",
      "Epoch: 41, Loss (standarized): 0.8045679985331209\n",
      "          Validation Loss (standardized): 0.7126271427070512\n",
      "Epoch: 46, Loss (standarized): 0.791123824767408\n",
      "          Validation Loss (standardized): 0.7075554335985257\n",
      "Epoch: 51, Loss (standarized): 0.7775105869935448\n",
      "          Validation Loss (standardized): 0.695575275338628\n",
      "Epoch: 56, Loss (standarized): 0.7663819721148084\n",
      "          Validation Loss (standardized): 0.6908811726727396\n",
      "Epoch: 61, Loss (standarized): 0.7546073639866823\n",
      "          Validation Loss (standardized): 0.6799203218757411\n",
      "Epoch: 66, Loss (standarized): 0.7415971935310277\n",
      "          Validation Loss (standardized): 0.6662752842747857\n",
      "Epoch: 71, Loss (standarized): 0.7296496887111376\n",
      "          Validation Loss (standardized): 0.6557798584007088\n",
      "Epoch: 76, Loss (standarized): 0.7190026729517439\n",
      "          Validation Loss (standardized): 0.6454987145530611\n",
      "Epoch: 81, Loss (standarized): 0.7093715080363785\n",
      "          Validation Loss (standardized): 0.6385969655957132\n",
      "Epoch: 86, Loss (standarized): 0.7004337018023196\n",
      "          Validation Loss (standardized): 0.6315399854315811\n",
      "Epoch: 91, Loss (standarized): 0.6901483070707772\n",
      "          Validation Loss (standardized): 0.6221389798442201\n",
      "Epoch: 96, Loss (standarized): 0.6772704165651733\n",
      "          Validation Loss (standardized): 0.6123890077139477\n",
      "Final epoch: 100, Final loss (standarized): 0.6637182648779142\n",
      "Epoch: 1, Loss (standarized): 1.1669536148729107\n",
      "          Validation Loss (standardized): 1.085565993726012\n",
      "Epoch: 6, Loss (standarized): 1.0357805264127706\n",
      "          Validation Loss (standardized): 0.9210602841443137\n",
      "Epoch: 11, Loss (standarized): 0.9778079359262293\n",
      "          Validation Loss (standardized): 0.9561033569537818\n",
      "Epoch: 16, Loss (standarized): 0.9792986588369207\n",
      "          Validation Loss (standardized): 0.95664352331761\n",
      "Epoch: 21, Loss (standarized): 0.9556038927237793\n",
      "          Validation Loss (standardized): 0.8859473272970735\n",
      "Epoch: 26, Loss (standarized): 0.9437527558979848\n",
      "          Validation Loss (standardized): 0.8851021560210199\n",
      "Epoch: 31, Loss (standarized): 0.9335305769348257\n",
      "          Validation Loss (standardized): 0.8978724383591192\n",
      "Epoch: 36, Loss (standarized): 0.9177561460242594\n",
      "          Validation Loss (standardized): 0.8548704982896129\n",
      "Epoch: 41, Loss (standarized): 0.9047525275569562\n",
      "          Validation Loss (standardized): 0.8438246170011251\n",
      "Epoch: 46, Loss (standarized): 0.8908676720949387\n",
      "          Validation Loss (standardized): 0.8377758209020791\n",
      "Epoch: 51, Loss (standarized): 0.8751757559794318\n",
      "          Validation Loss (standardized): 0.8065405797926732\n",
      "Epoch: 56, Loss (standarized): 0.8602130678269901\n",
      "          Validation Loss (standardized): 0.7980899430074766\n",
      "Epoch: 61, Loss (standarized): 0.8463922379709686\n",
      "          Validation Loss (standardized): 0.7786172418729908\n",
      "Epoch: 66, Loss (standarized): 0.8342756591928191\n",
      "          Validation Loss (standardized): 0.764987631661429\n",
      "Epoch: 71, Loss (standarized): 0.8244284034551015\n",
      "          Validation Loss (standardized): 0.7561644715664076\n",
      "Epoch: 76, Loss (standarized): 0.8165442026487911\n",
      "          Validation Loss (standardized): 0.7459187552103941\n",
      "Epoch: 81, Loss (standarized): 0.8104154953216739\n",
      "          Validation Loss (standardized): 0.7419568271414169\n",
      "Epoch: 86, Loss (standarized): 0.805205346813134\n",
      "          Validation Loss (standardized): 0.7354597714991198\n",
      "Epoch: 91, Loss (standarized): 0.8005097995648871\n",
      "          Validation Loss (standardized): 0.7321526278903089\n",
      "Epoch: 96, Loss (standarized): 0.7958833110571936\n",
      "          Validation Loss (standardized): 0.7271113576034101\n",
      "Final epoch: 100, Final loss (standarized): 0.7922824115431146\n",
      "Epoch: 1, Loss (standarized): 1.608699352545909\n",
      "          Validation Loss (standardized): 1.0378021261476134\n",
      "Epoch: 6, Loss (standarized): 1.0821824200124541\n",
      "          Validation Loss (standardized): 1.208493393460351\n",
      "Epoch: 11, Loss (standarized): 0.9960699631688377\n",
      "          Validation Loss (standardized): 0.9500050508110056\n",
      "Epoch: 16, Loss (standarized): 0.9845888981468562\n",
      "          Validation Loss (standardized): 0.8707980703648255\n",
      "Epoch: 21, Loss (standarized): 0.938598338419013\n",
      "          Validation Loss (standardized): 0.8572756012135013\n",
      "Epoch: 26, Loss (standarized): 0.9240739238787972\n",
      "          Validation Loss (standardized): 0.9105043529008222\n",
      "Epoch: 31, Loss (standarized): 0.8961404461728145\n",
      "          Validation Loss (standardized): 0.8382826320838526\n",
      "Epoch: 36, Loss (standarized): 0.8825526532075262\n",
      "          Validation Loss (standardized): 0.7916798630601306\n",
      "Epoch: 41, Loss (standarized): 0.8612697350190143\n",
      "          Validation Loss (standardized): 0.7901542076707102\n",
      "Epoch: 46, Loss (standarized): 0.8500396998362095\n",
      "          Validation Loss (standardized): 0.789196302845453\n",
      "Epoch: 51, Loss (standarized): 0.8361061928590449\n",
      "          Validation Loss (standardized): 0.7535624504277962\n",
      "Epoch: 56, Loss (standarized): 0.8282573503463613\n",
      "          Validation Loss (standardized): 0.7419185789452518\n",
      "Epoch: 61, Loss (standarized): 0.8203787469677701\n",
      "          Validation Loss (standardized): 0.7449730660740254\n",
      "Epoch: 66, Loss (standarized): 0.8136706029657125\n",
      "          Validation Loss (standardized): 0.731487874024184\n",
      "Epoch: 71, Loss (standarized): 0.8074947582585544\n",
      "          Validation Loss (standardized): 0.7223431628896033\n",
      "Epoch: 76, Loss (standarized): 0.8006192727790407\n",
      "          Validation Loss (standardized): 0.7222919166792203\n",
      "Epoch: 81, Loss (standarized): 0.793743582783472\n",
      "          Validation Loss (standardized): 0.7142200510148713\n",
      "Epoch: 86, Loss (standarized): 0.7868390795510242\n",
      "          Validation Loss (standardized): 0.7071389780122308\n",
      "Epoch: 91, Loss (standarized): 0.7797845945631118\n",
      "          Validation Loss (standardized): 0.7042165034515412\n",
      "Epoch: 96, Loss (standarized): 0.7727077335561191\n",
      "          Validation Loss (standardized): 0.6968215393910215\n",
      "Final epoch: 100, Final loss (standarized): 0.7670281042343955\n",
      "Epoch: 1, Loss (standarized): 1.4889351932836619\n",
      "          Validation Loss (standardized): 1.3262096001232837\n",
      "Epoch: 6, Loss (standarized): 1.0497821773031175\n",
      "          Validation Loss (standardized): 0.9379173413652169\n",
      "Epoch: 11, Loss (standarized): 1.0128165572763612\n",
      "          Validation Loss (standardized): 0.8971771572060874\n",
      "Epoch: 16, Loss (standarized): 0.9766879815319218\n",
      "          Validation Loss (standardized): 0.9961729642220383\n",
      "Epoch: 21, Loss (standarized): 0.9592973596310429\n",
      "          Validation Loss (standardized): 0.9282819299202144\n",
      "Epoch: 26, Loss (standarized): 0.9290222719349824\n",
      "          Validation Loss (standardized): 0.8473991214065183\n",
      "Epoch: 31, Loss (standarized): 0.9126634629857147\n",
      "          Validation Loss (standardized): 0.829776552954697\n",
      "Epoch: 36, Loss (standarized): 0.8860742036992463\n",
      "          Validation Loss (standardized): 0.841647499312827\n",
      "Epoch: 41, Loss (standarized): 0.8653633770852773\n",
      "          Validation Loss (standardized): 0.8054259753826944\n",
      "Epoch: 46, Loss (standarized): 0.8433520110053934\n",
      "          Validation Loss (standardized): 0.7592262830734497\n",
      "Epoch: 51, Loss (standarized): 0.8249465223372466\n",
      "          Validation Loss (standardized): 0.7451803058039762\n",
      "Epoch: 56, Loss (standarized): 0.8116942929143403\n",
      "          Validation Loss (standardized): 0.7389349575656248\n",
      "Epoch: 61, Loss (standarized): 0.8013619143827512\n",
      "          Validation Loss (standardized): 0.7170122238100015\n",
      "Epoch: 66, Loss (standarized): 0.7944155996627151\n",
      "          Validation Loss (standardized): 0.7075219194470163\n",
      "Epoch: 71, Loss (standarized): 0.7871676907646001\n",
      "          Validation Loss (standardized): 0.7066374100691414\n",
      "Epoch: 76, Loss (standarized): 0.7791728160240782\n",
      "          Validation Loss (standardized): 0.6968639160619358\n",
      "Epoch: 81, Loss (standarized): 0.7705552433630634\n",
      "          Validation Loss (standardized): 0.6885827472747471\n",
      "Epoch: 86, Loss (standarized): 0.7618015236513407\n",
      "          Validation Loss (standardized): 0.6852447781454306\n",
      "Epoch: 91, Loss (standarized): 0.7534501707403924\n",
      "          Validation Loss (standardized): 0.6782386817207745\n",
      "Epoch: 96, Loss (standarized): 0.7454430237288475\n",
      "          Validation Loss (standardized): 0.6710324846434571\n",
      "Final epoch: 100, Final loss (standarized): 0.7392002807076655\n",
      "Epoch: 1, Loss (standarized): 1.0238334203009334\n",
      "          Validation Loss (standardized): 0.9622084901891662\n",
      "Epoch: 6, Loss (standarized): 0.9920340962597345\n",
      "          Validation Loss (standardized): 0.9420154981310254\n",
      "Epoch: 11, Loss (standarized): 0.9929097642914948\n",
      "          Validation Loss (standardized): 0.9641523181573354\n",
      "Epoch: 16, Loss (standarized): 0.9933839320247566\n",
      "          Validation Loss (standardized): 0.9383089086082883\n",
      "Epoch: 21, Loss (standarized): 0.9939708459762822\n",
      "          Validation Loss (standardized): 0.9641028295776399\n",
      "Epoch: 26, Loss (standarized): 0.9958369112944505\n",
      "          Validation Loss (standardized): 0.9540708988035687\n",
      "Epoch: 31, Loss (standarized): 0.9973872476675094\n",
      "          Validation Loss (standardized): 0.9573800662535474\n",
      "Epoch: 36, Loss (standarized): 0.9987064860000231\n",
      "          Validation Loss (standardized): 0.9607993848517655\n",
      "Epoch: 41, Loss (standarized): 0.9996205517779486\n",
      "          Validation Loss (standardized): 0.9603714738301121\n",
      "Epoch: 46, Loss (standarized): 1.0001372872261136\n",
      "          Validation Loss (standardized): 0.9645454349414158\n",
      "Epoch: 51, Loss (standarized): 1.0000608293989977\n",
      "          Validation Loss (standardized): 0.9628720794032303\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 53, Final loss (standarized): 1.000079470564065\n",
      "Epoch: 1, Loss (standarized): 1.007936265797161\n",
      "          Validation Loss (standardized): 0.9807911477262391\n",
      "Epoch: 6, Loss (standarized): 0.9976400316415862\n",
      "          Validation Loss (standardized): 0.9616591822826684\n",
      "Epoch: 11, Loss (standarized): 0.9947212089400223\n",
      "          Validation Loss (standardized): 0.9519736341357254\n",
      "Epoch: 16, Loss (standarized): 0.9942453470148873\n",
      "          Validation Loss (standardized): 0.9556782826572418\n",
      "Epoch: 21, Loss (standarized): 0.9955403992339331\n",
      "          Validation Loss (standardized): 0.9588935461746598\n",
      "Epoch: 26, Loss (standarized): 0.9975488812711747\n",
      "          Validation Loss (standardized): 0.9576459317132326\n",
      "Epoch: 31, Loss (standarized): 0.9989520960929656\n",
      "          Validation Loss (standardized): 0.960315439793218\n",
      "Epoch: 36, Loss (standarized): 0.9996711158981875\n",
      "          Validation Loss (standardized): 0.9595561098057631\n",
      "Epoch: 41, Loss (standarized): 1.0000005577057443\n",
      "          Validation Loss (standardized): 0.9630211801037127\n",
      "Epoch: 46, Loss (standarized): 0.9999781912672463\n",
      "          Validation Loss (standardized): 0.9615658905440182\n",
      "Epoch: 51, Loss (standarized): 0.9999622271228183\n",
      "          Validation Loss (standardized): 0.961634019486215\n",
      "Epoch: 56, Loss (standarized): 1.0000044619195196\n",
      "          Validation Loss (standardized): 0.9617887800023566\n",
      "Epoch: 61, Loss (standarized): 1.0001249414808264\n",
      "          Validation Loss (standardized): 0.9569021040766459\n",
      "Epoch: 66, Loss (standarized): 1.000002280878991\n",
      "          Validation Loss (standardized): 0.9600492388096916\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 68, Final loss (standarized): 1.0000146672121786\n",
      "Epoch: 1, Loss (standarized): 1.2326851896068933\n",
      "          Validation Loss (standardized): 1.091894104784643\n",
      "Epoch: 6, Loss (standarized): 1.020262089058217\n",
      "          Validation Loss (standardized): 0.90186856867652\n",
      "Epoch: 11, Loss (standarized): 0.9723792030944004\n",
      "          Validation Loss (standardized): 0.9476154953259049\n",
      "Epoch: 16, Loss (standarized): 0.9942468411253437\n",
      "          Validation Loss (standardized): 0.9845766948599877\n",
      "Epoch: 21, Loss (standarized): 0.9815156538258604\n",
      "          Validation Loss (standardized): 0.927171862214315\n",
      "Epoch: 26, Loss (standarized): 0.9888833677350067\n",
      "          Validation Loss (standardized): 0.9359428911513288\n",
      "Epoch: 31, Loss (standarized): 0.9922374111656268\n",
      "          Validation Loss (standardized): 0.9683580023667269\n",
      "Epoch: 36, Loss (standarized): 0.9942648729677241\n",
      "          Validation Loss (standardized): 0.9584425481522356\n",
      "Epoch: 41, Loss (standarized): 0.9966008378225645\n",
      "          Validation Loss (standardized): 0.9551269900738165\n",
      "Epoch: 46, Loss (standarized): 0.9984827292279537\n",
      "          Validation Loss (standardized): 0.9622696350384083\n",
      "Epoch: 51, Loss (standarized): 0.9991089888067078\n",
      "          Validation Loss (standardized): 0.9595928505788229\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 54, Final loss (standarized): 0.9993739500785044\n",
      "Epoch: 1, Loss (standarized): 1.090975787751296\n",
      "          Validation Loss (standardized): 1.0051278839826951\n",
      "Epoch: 6, Loss (standarized): 1.0162191989279008\n",
      "          Validation Loss (standardized): 0.9309209551988704\n",
      "Epoch: 11, Loss (standarized): 1.002860189717614\n",
      "          Validation Loss (standardized): 0.9966804583131318\n",
      "Epoch: 16, Loss (standarized): 0.9984171001258038\n",
      "          Validation Loss (standardized): 0.952680272201075\n",
      "Epoch: 21, Loss (standarized): 1.0008169242916545\n",
      "          Validation Loss (standardized): 0.9480506007007421\n",
      "Epoch: 26, Loss (standarized): 0.999472974024884\n",
      "          Validation Loss (standardized): 0.9719294181886343\n",
      "Epoch: 31, Loss (standarized): 0.9990461833917819\n",
      "          Validation Loss (standardized): 0.9559699655485383\n",
      "Epoch: 36, Loss (standarized): 0.9997211877961902\n",
      "          Validation Loss (standardized): 0.9549605073596009\n",
      "Epoch: 41, Loss (standarized): 0.999312241069658\n",
      "          Validation Loss (standardized): 0.9637191438941538\n",
      "Epoch: 46, Loss (standarized): 0.9994890448265874\n",
      "          Validation Loss (standardized): 0.959655370284465\n",
      "Epoch: 51, Loss (standarized): 0.9998218331105703\n",
      "          Validation Loss (standardized): 0.9610016414724494\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 54, Final loss (standarized): 0.9999179758098162\n",
      "Epoch: 1, Loss (standarized): 1.1203019012718496\n",
      "          Validation Loss (standardized): 0.9968014176912321\n",
      "Epoch: 6, Loss (standarized): 1.0009454180208237\n",
      "          Validation Loss (standardized): 0.9146563923411142\n",
      "Epoch: 11, Loss (standarized): 0.9725704007273753\n",
      "          Validation Loss (standardized): 0.9491299833197837\n",
      "Epoch: 16, Loss (standarized): 0.9309353665743838\n",
      "          Validation Loss (standardized): 0.844816301503277\n",
      "Epoch: 21, Loss (standarized): 0.8985682054870658\n",
      "          Validation Loss (standardized): 0.8506380076311365\n",
      "Epoch: 26, Loss (standarized): 0.8759641547055402\n",
      "          Validation Loss (standardized): 0.8116830285052717\n",
      "Epoch: 31, Loss (standarized): 0.8539679843904893\n",
      "          Validation Loss (standardized): 0.7714708026422664\n",
      "Epoch: 36, Loss (standarized): 0.8342585635562078\n",
      "          Validation Loss (standardized): 0.7701223970187536\n",
      "Epoch: 41, Loss (standarized): 0.8185290737818717\n",
      "          Validation Loss (standardized): 0.7338519398451376\n",
      "Epoch: 46, Loss (standarized): 0.8074841189895736\n",
      "          Validation Loss (standardized): 0.7337974341813162\n",
      "Epoch: 51, Loss (standarized): 0.7988941263471064\n",
      "          Validation Loss (standardized): 0.7169152785084785\n",
      "Epoch: 56, Loss (standarized): 0.7911394994318203\n",
      "          Validation Loss (standardized): 0.7145188420172268\n",
      "Epoch: 61, Loss (standarized): 0.7835727542025693\n",
      "          Validation Loss (standardized): 0.7057539295853951\n",
      "Epoch: 66, Loss (standarized): 0.7761020719439818\n",
      "          Validation Loss (standardized): 0.7012496677954217\n",
      "Epoch: 71, Loss (standarized): 0.7688154713246977\n",
      "          Validation Loss (standardized): 0.6945251247520876\n",
      "Epoch: 76, Loss (standarized): 0.7614666144524435\n",
      "          Validation Loss (standardized): 0.6890399780161885\n",
      "Epoch: 81, Loss (standarized): 0.754024330766826\n",
      "          Validation Loss (standardized): 0.682399099929205\n",
      "Epoch: 86, Loss (standarized): 0.74666964557866\n",
      "          Validation Loss (standardized): 0.6758802311031117\n",
      "Epoch: 91, Loss (standarized): 0.739667680209255\n",
      "          Validation Loss (standardized): 0.6690766272412185\n",
      "Epoch: 96, Loss (standarized): 0.7331499788315522\n",
      "          Validation Loss (standardized): 0.6640398725783992\n",
      "Final epoch: 100, Final loss (standarized): 0.7282782452752203\n",
      "Epoch: 1, Loss (standarized): 1.645976276280344\n",
      "          Validation Loss (standardized): 1.065583209032426\n",
      "Epoch: 6, Loss (standarized): 1.0448339533311188\n",
      "          Validation Loss (standardized): 1.1629989782575307\n",
      "Epoch: 11, Loss (standarized): 1.030307479246438\n",
      "          Validation Loss (standardized): 1.0063420390445676\n",
      "Epoch: 16, Loss (standarized): 0.9709037126186228\n",
      "          Validation Loss (standardized): 0.8789414726234339\n",
      "Epoch: 21, Loss (standarized): 0.974725380702169\n",
      "          Validation Loss (standardized): 0.8680825814654003\n",
      "Epoch: 26, Loss (standarized): 0.9358547098284908\n",
      "          Validation Loss (standardized): 0.9146550328988096\n",
      "Epoch: 31, Loss (standarized): 0.9362903505862586\n",
      "          Validation Loss (standardized): 0.9063093304820491\n",
      "Epoch: 36, Loss (standarized): 0.9192321138582059\n",
      "          Validation Loss (standardized): 0.8508815972806864\n",
      "Epoch: 41, Loss (standarized): 0.9160476492546629\n",
      "          Validation Loss (standardized): 0.8424847757890808\n",
      "Epoch: 46, Loss (standarized): 0.9046072930008193\n",
      "          Validation Loss (standardized): 0.8589105112388669\n",
      "Epoch: 51, Loss (standarized): 0.8986125517426821\n",
      "          Validation Loss (standardized): 0.8463964138874331\n",
      "Epoch: 56, Loss (standarized): 0.8925524418619197\n",
      "          Validation Loss (standardized): 0.8248631115556151\n",
      "Epoch: 61, Loss (standarized): 0.8861425647437692\n",
      "          Validation Loss (standardized): 0.8248618235811577\n",
      "Epoch: 66, Loss (standarized): 0.8805031672447026\n",
      "          Validation Loss (standardized): 0.8243894389799373\n",
      "Epoch: 71, Loss (standarized): 0.8751982568124502\n",
      "          Validation Loss (standardized): 0.8113163097854792\n",
      "Epoch: 76, Loss (standarized): 0.8705169992681977\n",
      "          Validation Loss (standardized): 0.8066364862529027\n",
      "Epoch: 81, Loss (standarized): 0.8658967220851498\n",
      "          Validation Loss (standardized): 0.8050580418407304\n",
      "Epoch: 86, Loss (standarized): 0.8616744612763277\n",
      "          Validation Loss (standardized): 0.7981282746077832\n",
      "Epoch: 91, Loss (standarized): 0.8576546551860229\n",
      "          Validation Loss (standardized): 0.7936784112547377\n",
      "Epoch: 96, Loss (standarized): 0.8536099241840441\n",
      "          Validation Loss (standardized): 0.7906709708986256\n",
      "Final epoch: 100, Final loss (standarized): 0.8504119896978427\n",
      "Epoch: 1, Loss (standarized): 1.0260843947243539\n",
      "          Validation Loss (standardized): 0.9368061898681662\n",
      "Epoch: 6, Loss (standarized): 0.9746608448102261\n",
      "          Validation Loss (standardized): 0.9567587307655353\n",
      "Epoch: 11, Loss (standarized): 0.9368799028115259\n",
      "          Validation Loss (standardized): 0.8586708638640194\n",
      "Epoch: 16, Loss (standarized): 0.9029415288006877\n",
      "          Validation Loss (standardized): 0.8558530371434253\n",
      "Epoch: 21, Loss (standarized): 0.8732526457537144\n",
      "          Validation Loss (standardized): 0.7927906922348368\n",
      "Epoch: 26, Loss (standarized): 0.8486903685540238\n",
      "          Validation Loss (standardized): 0.7821824190016626\n",
      "Epoch: 31, Loss (standarized): 0.8301984839807008\n",
      "          Validation Loss (standardized): 0.7461911611532517\n",
      "Epoch: 36, Loss (standarized): 0.8172230694433382\n",
      "          Validation Loss (standardized): 0.7386494761778283\n",
      "Epoch: 41, Loss (standarized): 0.8069980445583746\n",
      "          Validation Loss (standardized): 0.7254473685053904\n",
      "Epoch: 46, Loss (standarized): 0.7973867544230623\n",
      "          Validation Loss (standardized): 0.7161116560362304\n",
      "Epoch: 51, Loss (standarized): 0.7881225276563504\n",
      "          Validation Loss (standardized): 0.7127753319968957\n",
      "Epoch: 56, Loss (standarized): 0.779085575220848\n",
      "          Validation Loss (standardized): 0.7027937483612716\n",
      "Epoch: 61, Loss (standarized): 0.7696028593195915\n",
      "          Validation Loss (standardized): 0.6960071146963017\n",
      "Epoch: 66, Loss (standarized): 0.7594600139123353\n",
      "          Validation Loss (standardized): 0.6872261869122892\n",
      "Epoch: 71, Loss (standarized): 0.7492816093261886\n",
      "          Validation Loss (standardized): 0.6758761386799463\n",
      "Epoch: 76, Loss (standarized): 0.739852947491576\n",
      "          Validation Loss (standardized): 0.6678956680488031\n",
      "Epoch: 81, Loss (standarized): 0.7316222064855674\n",
      "          Validation Loss (standardized): 0.6609614653862088\n",
      "Epoch: 86, Loss (standarized): 0.7246435940207623\n",
      "          Validation Loss (standardized): 0.6546282584425529\n",
      "Epoch: 91, Loss (standarized): 0.7189572316772181\n",
      "          Validation Loss (standardized): 0.6495476174283422\n",
      "Epoch: 96, Loss (standarized): 0.7144455094488394\n",
      "          Validation Loss (standardized): 0.6458228375548265\n",
      "Final epoch: 100, Final loss (standarized): 0.7114322945883051\n",
      "Epoch: 1, Loss (standarized): 1.0523287209396972\n",
      "          Validation Loss (standardized): 1.049287403176016\n",
      "Epoch: 6, Loss (standarized): 0.996221241054146\n",
      "          Validation Loss (standardized): 0.9422211753943784\n",
      "Epoch: 11, Loss (standarized): 0.952224615337635\n",
      "          Validation Loss (standardized): 0.8905246515017184\n",
      "Epoch: 16, Loss (standarized): 0.917319381686373\n",
      "          Validation Loss (standardized): 0.8674798858991762\n",
      "Epoch: 21, Loss (standarized): 0.8848864604657368\n",
      "          Validation Loss (standardized): 0.8127491052953707\n",
      "Epoch: 26, Loss (standarized): 0.8539963591807085\n",
      "          Validation Loss (standardized): 0.7876971221148247\n",
      "Epoch: 31, Loss (standarized): 0.8268176142022357\n",
      "          Validation Loss (standardized): 0.7529531386637487\n",
      "Epoch: 36, Loss (standarized): 0.8063076693756239\n",
      "          Validation Loss (standardized): 0.7267611639121747\n",
      "Epoch: 41, Loss (standarized): 0.7919375127086175\n",
      "          Validation Loss (standardized): 0.715056540376932\n",
      "Epoch: 46, Loss (standarized): 0.7803858114971259\n",
      "          Validation Loss (standardized): 0.7050474683738464\n",
      "Epoch: 51, Loss (standarized): 0.7700054727915283\n",
      "          Validation Loss (standardized): 0.6953978704195103\n",
      "Epoch: 56, Loss (standarized): 0.7606645280003502\n",
      "          Validation Loss (standardized): 0.6873670080652654\n",
      "Epoch: 61, Loss (standarized): 0.7522570992667157\n",
      "          Validation Loss (standardized): 0.6808673500093456\n",
      "Epoch: 66, Loss (standarized): 0.7443579101958261\n",
      "          Validation Loss (standardized): 0.6741295024677495\n",
      "Epoch: 71, Loss (standarized): 0.73676718178191\n",
      "          Validation Loss (standardized): 0.667548323086717\n",
      "Epoch: 76, Loss (standarized): 0.7296297940422163\n",
      "          Validation Loss (standardized): 0.6612871960661784\n",
      "Epoch: 81, Loss (standarized): 0.7230622566700242\n",
      "          Validation Loss (standardized): 0.6561723009231849\n",
      "Epoch: 86, Loss (standarized): 0.7172450839871523\n",
      "          Validation Loss (standardized): 0.651329394663676\n",
      "Epoch: 91, Loss (standarized): 0.7120247362499608\n",
      "          Validation Loss (standardized): 0.6465143935353602\n",
      "Epoch: 96, Loss (standarized): 0.7073554523750845\n",
      "          Validation Loss (standardized): 0.6426852228857239\n",
      "Final epoch: 100, Final loss (standarized): 0.7039635863798979\n",
      "Epoch: 1, Loss (standarized): 1.0290762202497705\n",
      "          Validation Loss (standardized): 0.9298311708353845\n",
      "Epoch: 6, Loss (standarized): 0.9646953490504359\n",
      "          Validation Loss (standardized): 0.9494903993135043\n",
      "Epoch: 11, Loss (standarized): 0.9437286612630686\n",
      "          Validation Loss (standardized): 0.878508132117895\n",
      "Epoch: 16, Loss (standarized): 0.9204560055062301\n",
      "          Validation Loss (standardized): 0.8606863562991779\n",
      "Epoch: 21, Loss (standarized): 0.8942069266480903\n",
      "          Validation Loss (standardized): 0.8317857544514891\n",
      "Epoch: 26, Loss (standarized): 0.8670182313232566\n",
      "          Validation Loss (standardized): 0.7849727403231269\n",
      "Epoch: 31, Loss (standarized): 0.8440772546376888\n",
      "          Validation Loss (standardized): 0.7707548278369842\n",
      "Epoch: 36, Loss (standarized): 0.8297965664164998\n",
      "          Validation Loss (standardized): 0.7393574179457864\n",
      "Epoch: 41, Loss (standarized): 0.8224864642224613\n",
      "          Validation Loss (standardized): 0.7382132251134692\n",
      "Epoch: 46, Loss (standarized): 0.8157400750896141\n",
      "          Validation Loss (standardized): 0.7244786780203859\n",
      "Epoch: 51, Loss (standarized): 0.8059265954619207\n",
      "          Validation Loss (standardized): 0.7206069366646785\n",
      "Epoch: 56, Loss (standarized): 0.7952753853001994\n",
      "          Validation Loss (standardized): 0.7124984560815038\n",
      "Epoch: 61, Loss (standarized): 0.7856833443165219\n",
      "          Validation Loss (standardized): 0.7062968480343089\n",
      "Epoch: 66, Loss (standarized): 0.7759851888296673\n",
      "          Validation Loss (standardized): 0.6999742320189069\n",
      "Epoch: 71, Loss (standarized): 0.7650098241797958\n",
      "          Validation Loss (standardized): 0.68781571886789\n",
      "Epoch: 76, Loss (standarized): 0.7531542729710219\n",
      "          Validation Loss (standardized): 0.6783894617497715\n",
      "Epoch: 81, Loss (standarized): 0.7413541012888031\n",
      "          Validation Loss (standardized): 0.6660539317537711\n",
      "Epoch: 86, Loss (standarized): 0.730008511149807\n",
      "          Validation Loss (standardized): 0.6568061237936269\n",
      "Epoch: 91, Loss (standarized): 0.7194038673735917\n",
      "          Validation Loss (standardized): 0.648316997513448\n",
      "Epoch: 96, Loss (standarized): 0.7098947166009951\n",
      "          Validation Loss (standardized): 0.640067709177766\n",
      "Final epoch: 100, Final loss (standarized): 0.7030070024564241\n",
      "Epoch: 1, Loss (standarized): 2.1404230177211114\n",
      "          Validation Loss (standardized): 1.366987576853964\n",
      "Epoch: 6, Loss (standarized): 1.0013710145780286\n",
      "          Validation Loss (standardized): 1.0368208348055146\n",
      "Epoch: 11, Loss (standarized): 1.161552178243613\n",
      "          Validation Loss (standardized): 1.2432374131704238\n",
      "Epoch: 16, Loss (standarized): 1.0172622040961783\n",
      "          Validation Loss (standardized): 0.9910669178258851\n",
      "Epoch: 21, Loss (standarized): 0.9776238577606371\n",
      "          Validation Loss (standardized): 0.8896665295420633\n",
      "Epoch: 26, Loss (standarized): 0.9955304252327594\n",
      "          Validation Loss (standardized): 0.8802247518461752\n",
      "Epoch: 31, Loss (standarized): 0.9488584744203532\n",
      "          Validation Loss (standardized): 0.891623820430727\n",
      "Epoch: 36, Loss (standarized): 0.9464379435739408\n",
      "          Validation Loss (standardized): 0.9289098399594315\n",
      "Epoch: 41, Loss (standarized): 0.9356481290677028\n",
      "          Validation Loss (standardized): 0.8969359513655517\n",
      "Epoch: 46, Loss (standarized): 0.9244376944681203\n",
      "          Validation Loss (standardized): 0.8571759242766462\n",
      "Epoch: 51, Loss (standarized): 0.9200654033810831\n",
      "          Validation Loss (standardized): 0.847567662797144\n",
      "Epoch: 56, Loss (standarized): 0.909420581283657\n",
      "          Validation Loss (standardized): 0.8556447006058652\n",
      "Epoch: 61, Loss (standarized): 0.9035811374808638\n",
      "          Validation Loss (standardized): 0.8541960959698965\n",
      "Epoch: 66, Loss (standarized): 0.8962443148771093\n",
      "          Validation Loss (standardized): 0.8348372782295538\n",
      "Epoch: 71, Loss (standarized): 0.890716168580483\n",
      "          Validation Loss (standardized): 0.823102160881197\n",
      "Epoch: 76, Loss (standarized): 0.8843096767126987\n",
      "          Validation Loss (standardized): 0.8221104712284898\n",
      "Epoch: 81, Loss (standarized): 0.8788459659480008\n",
      "          Validation Loss (standardized): 0.8184559620568025\n",
      "Epoch: 86, Loss (standarized): 0.8737003948759167\n",
      "          Validation Loss (standardized): 0.808077168796111\n",
      "Epoch: 91, Loss (standarized): 0.8690960394221436\n",
      "          Validation Loss (standardized): 0.8014676303210447\n",
      "Epoch: 96, Loss (standarized): 0.8645535866390623\n",
      "          Validation Loss (standardized): 0.7991282611213064\n",
      "Final epoch: 100, Final loss (standarized): 0.8612273218992661\n",
      "Epoch: 1, Loss (standarized): 2.620099455806659\n",
      "          Validation Loss (standardized): 1.6929898907070902\n",
      "Epoch: 6, Loss (standarized): 1.0365083521577472\n",
      "          Validation Loss (standardized): 0.9294341688230493\n",
      "Epoch: 11, Loss (standarized): 1.115164423433539\n",
      "          Validation Loss (standardized): 1.238254408487404\n",
      "Epoch: 16, Loss (standarized): 1.1124425775751954\n",
      "          Validation Loss (standardized): 1.1460543305049486\n",
      "Epoch: 21, Loss (standarized): 0.9686130430612451\n",
      "          Validation Loss (standardized): 0.9301065860556568\n",
      "Epoch: 26, Loss (standarized): 0.9543741953355213\n",
      "          Validation Loss (standardized): 0.864984473661414\n",
      "Epoch: 31, Loss (standarized): 0.9622352577971359\n",
      "          Validation Loss (standardized): 0.8517865153714774\n",
      "Epoch: 36, Loss (standarized): 0.9271874314812425\n",
      "          Validation Loss (standardized): 0.8463215113520277\n",
      "Epoch: 41, Loss (standarized): 0.9078356653482771\n",
      "          Validation Loss (standardized): 0.8645516809319506\n",
      "Epoch: 46, Loss (standarized): 0.9009439770523917\n",
      "          Validation Loss (standardized): 0.8622414798380618\n",
      "Epoch: 51, Loss (standarized): 0.8838342114769138\n",
      "          Validation Loss (standardized): 0.8268071955436482\n",
      "Epoch: 56, Loss (standarized): 0.8700070223757894\n",
      "          Validation Loss (standardized): 0.7943025183770169\n",
      "Epoch: 61, Loss (standarized): 0.859564814333066\n",
      "          Validation Loss (standardized): 0.7775222481489075\n",
      "Epoch: 66, Loss (standarized): 0.8470959550722658\n",
      "          Validation Loss (standardized): 0.7714907745436012\n",
      "Epoch: 71, Loss (standarized): 0.8370628393149779\n",
      "          Validation Loss (standardized): 0.7668897208604174\n",
      "Epoch: 76, Loss (standarized): 0.828138521734046\n",
      "          Validation Loss (standardized): 0.7545932502862709\n",
      "Epoch: 81, Loss (standarized): 0.819939706067317\n",
      "          Validation Loss (standardized): 0.7401713193025253\n",
      "Epoch: 86, Loss (standarized): 0.8128133698807819\n",
      "          Validation Loss (standardized): 0.7311426299102584\n",
      "Epoch: 91, Loss (standarized): 0.8057866904760742\n",
      "          Validation Loss (standardized): 0.7268342341132842\n",
      "Epoch: 96, Loss (standarized): 0.7990964094076909\n",
      "          Validation Loss (standardized): 0.7221644278080542\n",
      "Final epoch: 100, Final loss (standarized): 0.7937561434497704\n",
      "Epoch: 1, Loss (standarized): 1.1312903725709378\n",
      "          Validation Loss (standardized): 1.0114333685774597\n",
      "Epoch: 6, Loss (standarized): 1.018541328774244\n",
      "          Validation Loss (standardized): 0.9396080680479681\n",
      "Epoch: 11, Loss (standarized): 0.996874983370889\n",
      "          Validation Loss (standardized): 0.9771947912530987\n",
      "Epoch: 16, Loss (standarized): 0.961933620421673\n",
      "          Validation Loss (standardized): 0.8799329642194794\n",
      "Epoch: 21, Loss (standarized): 0.9321441608381882\n",
      "          Validation Loss (standardized): 0.890068740367673\n",
      "Epoch: 26, Loss (standarized): 0.9098663271048097\n",
      "          Validation Loss (standardized): 0.8511480569836988\n",
      "Epoch: 31, Loss (standarized): 0.8849408225569595\n",
      "          Validation Loss (standardized): 0.8043452158055285\n",
      "Epoch: 36, Loss (standarized): 0.8586467318970665\n",
      "          Validation Loss (standardized): 0.7964327824440623\n",
      "Epoch: 41, Loss (standarized): 0.8364276826179701\n",
      "          Validation Loss (standardized): 0.75074307042613\n",
      "Epoch: 46, Loss (standarized): 0.8209912528377125\n",
      "          Validation Loss (standardized): 0.7428087160257535\n",
      "Epoch: 51, Loss (standarized): 0.8111688509475903\n",
      "          Validation Loss (standardized): 0.7237715878713759\n",
      "Epoch: 56, Loss (standarized): 0.8029220881302838\n",
      "          Validation Loss (standardized): 0.7181164046160685\n",
      "Epoch: 61, Loss (standarized): 0.7932123709137334\n",
      "          Validation Loss (standardized): 0.7080590489314466\n",
      "Epoch: 66, Loss (standarized): 0.782445994151806\n",
      "          Validation Loss (standardized): 0.7011510740885322\n",
      "Epoch: 71, Loss (standarized): 0.7723531195365657\n",
      "          Validation Loss (standardized): 0.6939340837298186\n",
      "Epoch: 76, Loss (standarized): 0.7631243796558301\n",
      "          Validation Loss (standardized): 0.6872802597478257\n",
      "Epoch: 81, Loss (standarized): 0.7539671391795624\n",
      "          Validation Loss (standardized): 0.6791697642412424\n",
      "Epoch: 86, Loss (standarized): 0.7446517572187573\n",
      "          Validation Loss (standardized): 0.6707789541233395\n",
      "Epoch: 91, Loss (standarized): 0.735708188859726\n",
      "          Validation Loss (standardized): 0.6618863531966653\n",
      "Epoch: 96, Loss (standarized): 0.727404165794586\n",
      "          Validation Loss (standardized): 0.6548480934302102\n",
      "Final epoch: 100, Final loss (standarized): 0.7211067452611545\n",
      "Epoch: 1, Loss (standarized): 1.781158891088428\n",
      "          Validation Loss (standardized): 1.603077940368823\n",
      "Epoch: 6, Loss (standarized): 1.008908801488842\n",
      "          Validation Loss (standardized): 0.9271924653609662\n",
      "Epoch: 11, Loss (standarized): 1.1030639345031479\n",
      "          Validation Loss (standardized): 0.9223517883847407\n",
      "Epoch: 16, Loss (standarized): 0.96096257199872\n",
      "          Validation Loss (standardized): 0.9224333307953259\n",
      "Epoch: 21, Loss (standarized): 0.9814778136598269\n",
      "          Validation Loss (standardized): 0.993686912294809\n",
      "Epoch: 26, Loss (standarized): 0.938776891020329\n",
      "          Validation Loss (standardized): 0.8969326218820837\n",
      "Epoch: 31, Loss (standarized): 0.9157581919749628\n",
      "          Validation Loss (standardized): 0.830873123040372\n",
      "Epoch: 36, Loss (standarized): 0.9002819494130098\n",
      "          Validation Loss (standardized): 0.8117703360759482\n",
      "Epoch: 41, Loss (standarized): 0.8732276129969095\n",
      "          Validation Loss (standardized): 0.8171800655721778\n",
      "Epoch: 46, Loss (standarized): 0.8576307670837796\n",
      "          Validation Loss (standardized): 0.801430621857136\n",
      "Epoch: 51, Loss (standarized): 0.8364072177456563\n",
      "          Validation Loss (standardized): 0.7585614856324152\n",
      "Epoch: 56, Loss (standarized): 0.8223682438519159\n",
      "          Validation Loss (standardized): 0.7354224303223091\n",
      "Epoch: 61, Loss (standarized): 0.8086506898954913\n",
      "          Validation Loss (standardized): 0.7306191760822404\n",
      "Epoch: 66, Loss (standarized): 0.7995560657287719\n",
      "          Validation Loss (standardized): 0.7227622263828044\n",
      "Epoch: 71, Loss (standarized): 0.7914500909526583\n",
      "          Validation Loss (standardized): 0.7070706715488076\n",
      "Epoch: 76, Loss (standarized): 0.7846954625151247\n",
      "          Validation Loss (standardized): 0.6994303301001823\n",
      "Epoch: 81, Loss (standarized): 0.7774946095704444\n",
      "          Validation Loss (standardized): 0.6972171188344722\n",
      "Epoch: 86, Loss (standarized): 0.7700862356538187\n",
      "          Validation Loss (standardized): 0.6903350381831674\n",
      "Epoch: 91, Loss (standarized): 0.7624390042107085\n",
      "          Validation Loss (standardized): 0.6819774771071251\n",
      "Epoch: 96, Loss (standarized): 0.7549178860313642\n",
      "          Validation Loss (standardized): 0.6773342509872953\n",
      "Final epoch: 100, Final loss (standarized): 0.7491287003280969\n",
      "Epoch: 1, Loss (standarized): 1.4314063815927853\n",
      "          Validation Loss (standardized): 1.002317489851919\n",
      "Epoch: 6, Loss (standarized): 1.1103106448566233\n",
      "          Validation Loss (standardized): 1.187206585077688\n",
      "Epoch: 11, Loss (standarized): 0.9980291891622783\n",
      "          Validation Loss (standardized): 0.9410026653631625\n",
      "Epoch: 16, Loss (standarized): 1.012223318947598\n",
      "          Validation Loss (standardized): 0.8984830950094149\n",
      "Epoch: 21, Loss (standarized): 0.9562691307293992\n",
      "          Validation Loss (standardized): 0.9201802902526892\n",
      "Epoch: 26, Loss (standarized): 0.9522859138884868\n",
      "          Validation Loss (standardized): 0.9260647278817585\n",
      "Epoch: 31, Loss (standarized): 0.9237701680469026\n",
      "          Validation Loss (standardized): 0.8525445111944275\n",
      "Epoch: 36, Loss (standarized): 0.911229523583569\n",
      "          Validation Loss (standardized): 0.8357434331803713\n",
      "Epoch: 41, Loss (standarized): 0.893471030403066\n",
      "          Validation Loss (standardized): 0.845670352600728\n",
      "Epoch: 46, Loss (standarized): 0.8780028845160635\n",
      "          Validation Loss (standardized): 0.8122315749702591\n",
      "Epoch: 51, Loss (standarized): 0.8661334289467973\n",
      "          Validation Loss (standardized): 0.789059694914207\n",
      "Epoch: 56, Loss (standarized): 0.854066032993796\n",
      "          Validation Loss (standardized): 0.7897550360104236\n",
      "Epoch: 61, Loss (standarized): 0.845000866749739\n",
      "          Validation Loss (standardized): 0.7743682470542664\n",
      "Epoch: 66, Loss (standarized): 0.8379588222418732\n",
      "          Validation Loss (standardized): 0.7622290734529612\n",
      "Epoch: 71, Loss (standarized): 0.8319328657884428\n",
      "          Validation Loss (standardized): 0.7628567389105042\n",
      "Epoch: 76, Loss (standarized): 0.8271088628055858\n",
      "          Validation Loss (standardized): 0.7543732260485534\n",
      "Epoch: 81, Loss (standarized): 0.8229535767832781\n",
      "          Validation Loss (standardized): 0.7503370342065964\n",
      "Epoch: 86, Loss (standarized): 0.8189071130334231\n",
      "          Validation Loss (standardized): 0.7489457472514022\n",
      "Epoch: 91, Loss (standarized): 0.8147863325579507\n",
      "          Validation Loss (standardized): 0.742611173199534\n",
      "Epoch: 96, Loss (standarized): 0.8104625286715479\n",
      "          Validation Loss (standardized): 0.740185069869477\n",
      "Final epoch: 100, Final loss (standarized): 0.8068825164557829\n",
      "Epoch: 1, Loss (standarized): 1.3695598146834627\n",
      "          Validation Loss (standardized): 0.9623862967849945\n",
      "Epoch: 6, Loss (standarized): 1.0895808041910209\n",
      "          Validation Loss (standardized): 1.1544221380059079\n",
      "Epoch: 11, Loss (standarized): 0.9719017983489863\n",
      "          Validation Loss (standardized): 0.9078352369179002\n",
      "Epoch: 16, Loss (standarized): 0.9891086975923331\n",
      "          Validation Loss (standardized): 0.8740007279508984\n",
      "Epoch: 21, Loss (standarized): 0.9333150113759183\n",
      "          Validation Loss (standardized): 0.9041829461099136\n",
      "Epoch: 26, Loss (standarized): 0.923053931624324\n",
      "          Validation Loss (standardized): 0.8835897618535395\n",
      "Epoch: 31, Loss (standarized): 0.8923488502387833\n",
      "          Validation Loss (standardized): 0.8088102359567465\n",
      "Epoch: 36, Loss (standarized): 0.8711120537442902\n",
      "          Validation Loss (standardized): 0.7922678684323001\n",
      "Epoch: 41, Loss (standarized): 0.8520646931430405\n",
      "          Validation Loss (standardized): 0.7920796920040768\n",
      "Epoch: 46, Loss (standarized): 0.8340119341852843\n",
      "          Validation Loss (standardized): 0.7513687888724883\n",
      "Epoch: 51, Loss (standarized): 0.8234307791448223\n",
      "          Validation Loss (standardized): 0.7361474471917859\n",
      "Epoch: 56, Loss (standarized): 0.8144634315105371\n",
      "          Validation Loss (standardized): 0.737891317994274\n",
      "Epoch: 61, Loss (standarized): 0.806792821240526\n",
      "          Validation Loss (standardized): 0.7213943869037975\n",
      "Epoch: 66, Loss (standarized): 0.7994862379488746\n",
      "          Validation Loss (standardized): 0.714968265214668\n",
      "Epoch: 71, Loss (standarized): 0.7914673085954869\n",
      "          Validation Loss (standardized): 0.7131704653578721\n",
      "Epoch: 76, Loss (standarized): 0.7832205896813892\n",
      "          Validation Loss (standardized): 0.7022087812020962\n",
      "Epoch: 81, Loss (standarized): 0.7751942056148214\n",
      "          Validation Loss (standardized): 0.6981762379200963\n",
      "Epoch: 86, Loss (standarized): 0.7672730137039583\n",
      "          Validation Loss (standardized): 0.6923482360159053\n",
      "Epoch: 91, Loss (standarized): 0.7592479335461616\n",
      "          Validation Loss (standardized): 0.6838415424193209\n",
      "Epoch: 96, Loss (standarized): 0.7511148238518064\n",
      "          Validation Loss (standardized): 0.6786085115386422\n",
      "Final epoch: 100, Final loss (standarized): 0.7446338116068241\n",
      "Epoch: 1, Loss (standarized): 1.0096619914275093\n",
      "          Validation Loss (standardized): 0.9555823516988508\n",
      "Epoch: 6, Loss (standarized): 0.9456158191616494\n",
      "          Validation Loss (standardized): 0.8611136647040891\n",
      "Epoch: 11, Loss (standarized): 0.9077168318677604\n",
      "          Validation Loss (standardized): 0.8714527638482431\n",
      "Epoch: 16, Loss (standarized): 0.8721014026585593\n",
      "          Validation Loss (standardized): 0.785500355044621\n",
      "Epoch: 21, Loss (standarized): 0.8444371727629285\n",
      "          Validation Loss (standardized): 0.7793710917542305\n",
      "Epoch: 26, Loss (standarized): 0.8286990285079632\n",
      "          Validation Loss (standardized): 0.7362558695126061\n",
      "Epoch: 31, Loss (standarized): 0.8229136151712064\n",
      "          Validation Loss (standardized): 0.7429753250700806\n",
      "Epoch: 36, Loss (standarized): 0.8179300994795327\n",
      "          Validation Loss (standardized): 0.7230083010037706\n",
      "Epoch: 41, Loss (standarized): 0.8081536919892015\n",
      "          Validation Loss (standardized): 0.7253266043778237\n",
      "Epoch: 46, Loss (standarized): 0.7968023128778697\n",
      "          Validation Loss (standardized): 0.7118022818114476\n",
      "Epoch: 51, Loss (standarized): 0.7864934258703336\n",
      "          Validation Loss (standardized): 0.7085451137648165\n",
      "Epoch: 56, Loss (standarized): 0.77565855113979\n",
      "          Validation Loss (standardized): 0.699602647606131\n",
      "Epoch: 61, Loss (standarized): 0.7630020053329897\n",
      "          Validation Loss (standardized): 0.6859483802608634\n",
      "Epoch: 66, Loss (standarized): 0.749228011352474\n",
      "          Validation Loss (standardized): 0.6754226217348384\n",
      "Epoch: 71, Loss (standarized): 0.7353511727066524\n",
      "          Validation Loss (standardized): 0.6607520162645367\n",
      "Epoch: 76, Loss (standarized): 0.7215540576266624\n",
      "          Validation Loss (standardized): 0.6499710710457839\n",
      "Epoch: 81, Loss (standarized): 0.7082282722106747\n",
      "          Validation Loss (standardized): 0.6398550998059958\n",
      "Epoch: 86, Loss (standarized): 0.6953355835226643\n",
      "          Validation Loss (standardized): 0.6284630018782829\n",
      "Epoch: 91, Loss (standarized): 0.6820367510530578\n",
      "          Validation Loss (standardized): 0.6182369598183385\n",
      "Epoch: 96, Loss (standarized): 0.6676483604991811\n",
      "          Validation Loss (standardized): 0.6070516756775273\n",
      "Final epoch: 100, Final loss (standarized): 0.6546412677048787\n",
      "Epoch: 1, Loss (standarized): 1.0125881431304793\n",
      "          Validation Loss (standardized): 0.9437362089688222\n",
      "Epoch: 6, Loss (standarized): 0.9796751474724925\n",
      "          Validation Loss (standardized): 0.9373714188304683\n",
      "Epoch: 11, Loss (standarized): 0.9804836366735843\n",
      "          Validation Loss (standardized): 0.9407221117691361\n",
      "Epoch: 16, Loss (standarized): 0.9854582153734146\n",
      "          Validation Loss (standardized): 0.9341965631001703\n",
      "Epoch: 21, Loss (standarized): 0.9894914502052513\n",
      "          Validation Loss (standardized): 0.9570121079754804\n",
      "Epoch: 26, Loss (standarized): 0.9933854982688907\n",
      "          Validation Loss (standardized): 0.9455099066028738\n",
      "Epoch: 31, Loss (standarized): 0.9958106794761103\n",
      "          Validation Loss (standardized): 0.9599953505078352\n",
      "Epoch: 36, Loss (standarized): 0.9981751995351409\n",
      "          Validation Loss (standardized): 0.9561432070199517\n",
      "Epoch: 41, Loss (standarized): 0.9989551663928162\n",
      "          Validation Loss (standardized): 0.9597419647849986\n",
      "Epoch: 46, Loss (standarized): 0.9993417141483597\n",
      "          Validation Loss (standardized): 0.9588587838741822\n",
      "Epoch: 51, Loss (standarized): 0.9996787191018752\n",
      "          Validation Loss (standardized): 0.9621550264424777\n",
      "Epoch: 56, Loss (standarized): 0.9998559196738522\n",
      "          Validation Loss (standardized): 0.9604967414240667\n",
      "Epoch: 61, Loss (standarized): 0.9999999076939886\n",
      "          Validation Loss (standardized): 0.9619058338040858\n",
      "Epoch: 66, Loss (standarized): 1.0000163486731597\n",
      "          Validation Loss (standardized): 0.9604229042377693\n",
      "Epoch: 71, Loss (standarized): 1.0000022609106314\n",
      "          Validation Loss (standardized): 0.962611180264057\n",
      "Epoch: 76, Loss (standarized): 1.0000077141295818\n",
      "          Validation Loss (standardized): 0.9594075308499842\n",
      "Epoch: 81, Loss (standarized): 1.0000619161845334\n",
      "          Validation Loss (standardized): 0.9575070117766399\n",
      "Epoch: 86, Loss (standarized): 1.0000748785056517\n",
      "          Validation Loss (standardized): 0.9583960314112437\n",
      "Epoch: 91, Loss (standarized): 1.0000108124578546\n",
      "          Validation Loss (standardized): 0.960041739861862\n",
      "Epoch: 96, Loss (standarized): 1.0000140087458398\n",
      "          Validation Loss (standardized): 0.9588990178290621\n",
      "Final epoch: 100, Final loss (standarized): 1.0000316623407968\n",
      "Epoch: 1, Loss (standarized): 1.0298406219598029\n",
      "          Validation Loss (standardized): 0.9698131222552562\n",
      "Epoch: 6, Loss (standarized): 1.0171402213328207\n",
      "          Validation Loss (standardized): 0.9875521911402707\n",
      "Epoch: 11, Loss (standarized): 1.0078502382051984\n",
      "          Validation Loss (standardized): 0.9588202827409407\n",
      "Epoch: 16, Loss (standarized): 1.00239615411378\n",
      "          Validation Loss (standardized): 0.9660249660299914\n",
      "Epoch: 21, Loss (standarized): 1.0001591881957292\n",
      "          Validation Loss (standardized): 0.95531054505749\n",
      "Epoch: 26, Loss (standarized): 0.9992448115956712\n",
      "          Validation Loss (standardized): 0.9591299187387929\n",
      "Epoch: 31, Loss (standarized): 0.9994895280751207\n",
      "          Validation Loss (standardized): 0.9610569444537437\n",
      "Epoch: 36, Loss (standarized): 0.9998400561038269\n",
      "          Validation Loss (standardized): 0.9649298367868724\n",
      "Epoch: 41, Loss (standarized): 0.9997593590479612\n",
      "          Validation Loss (standardized): 0.962718101360271\n",
      "Epoch: 46, Loss (standarized): 1.0000128003450666\n",
      "          Validation Loss (standardized): 0.9616434560185949\n",
      "Epoch: 51, Loss (standarized): 1.0000214007318504\n",
      "          Validation Loss (standardized): 0.9607216338859882\n",
      "Epoch: 56, Loss (standarized): 1.0000098895143714\n",
      "          Validation Loss (standardized): 0.9594856332105307\n",
      "Epoch: 61, Loss (standarized): 0.9999986484483955\n",
      "          Validation Loss (standardized): 0.9622408008312638\n",
      "Epoch: 66, Loss (standarized): 1.0000339710649755\n",
      "          Validation Loss (standardized): 0.9617402323542983\n",
      "Epoch: 71, Loss (standarized): 1.0000024045259885\n",
      "          Validation Loss (standardized): 0.9623663332917058\n",
      "Epoch: 76, Loss (standarized): 1.0001098450791706\n",
      "          Validation Loss (standardized): 0.956466578476749\n",
      "Epoch: 81, Loss (standarized): 1.0000055019253815\n",
      "          Validation Loss (standardized): 0.9606555220583605\n",
      "Epoch: 86, Loss (standarized): 1.000003327427065\n",
      "          Validation Loss (standardized): 0.962380963937685\n",
      "Epoch: 91, Loss (standarized): 1.0000012989784168\n",
      "          Validation Loss (standardized): 0.9616837885449059\n",
      "Epoch: 96, Loss (standarized): 1.0000007005925011\n",
      "          Validation Loss (standardized): 0.9598471249226983\n",
      "Final epoch: 100, Final loss (standarized): 1.0000000191416603\n",
      "Epoch: 1, Loss (standarized): 1.5792068699180553\n",
      "          Validation Loss (standardized): 1.0822073523109046\n",
      "Epoch: 6, Loss (standarized): 0.9821740409797488\n",
      "          Validation Loss (standardized): 0.997234089504295\n",
      "Epoch: 11, Loss (standarized): 1.0426153655141348\n",
      "          Validation Loss (standardized): 1.0677128209372742\n",
      "Epoch: 16, Loss (standarized): 0.9877049334228047\n",
      "          Validation Loss (standardized): 0.947761173333746\n",
      "Epoch: 21, Loss (standarized): 1.003949778824851\n",
      "          Validation Loss (standardized): 0.9205881412396333\n",
      "Epoch: 26, Loss (standarized): 1.0030373403584427\n",
      "          Validation Loss (standardized): 0.9305253193384004\n",
      "Epoch: 31, Loss (standarized): 0.994245991276129\n",
      "          Validation Loss (standardized): 0.9645403505893237\n",
      "Epoch: 36, Loss (standarized): 0.998151487397182\n",
      "          Validation Loss (standardized): 0.969915335699264\n",
      "Epoch: 41, Loss (standarized): 0.9983101337630103\n",
      "          Validation Loss (standardized): 0.9542412650933975\n",
      "Epoch: 46, Loss (standarized): 0.999626075308434\n",
      "          Validation Loss (standardized): 0.9561164015049308\n",
      "Epoch: 51, Loss (standarized): 0.9999804222982103\n",
      "          Validation Loss (standardized): 0.9652826540311434\n",
      "Epoch: 56, Loss (standarized): 1.0001411870803856\n",
      "          Validation Loss (standardized): 0.9644193892411366\n",
      "Epoch: 61, Loss (standarized): 0.999991070696702\n",
      "          Validation Loss (standardized): 0.9607979236712875\n",
      "Epoch: 66, Loss (standarized): 1.000024100986907\n",
      "          Validation Loss (standardized): 0.9611401540282742\n",
      "Epoch: 71, Loss (standarized): 1.0000319673838332\n",
      "          Validation Loss (standardized): 0.963034786229353\n",
      "Epoch: 76, Loss (standarized): 1.0000493327814663\n",
      "          Validation Loss (standardized): 0.962427307504139\n",
      "Epoch: 81, Loss (standarized): 1.0000032806080665\n",
      "          Validation Loss (standardized): 0.960878732700783\n",
      "Epoch: 86, Loss (standarized): 1.0000173372431196\n",
      "          Validation Loss (standardized): 0.962349577616701\n",
      "Epoch: 91, Loss (standarized): 1.0000374607614764\n",
      "          Validation Loss (standardized): 0.9628226690114736\n",
      "Epoch: 96, Loss (standarized): 1.000017604815202\n",
      "          Validation Loss (standardized): 0.9620083755931151\n",
      "Final epoch: 100, Final loss (standarized): 1.0000068713777732\n",
      "Epoch: 1, Loss (standarized): 1.1857173814767594\n",
      "          Validation Loss (standardized): 0.9441582156617369\n",
      "Epoch: 6, Loss (standarized): 1.0295702935365099\n",
      "          Validation Loss (standardized): 1.0597697796853698\n",
      "Epoch: 11, Loss (standarized): 1.0015333841167222\n",
      "          Validation Loss (standardized): 0.9622182086484773\n",
      "Epoch: 16, Loss (standarized): 1.0066318515940675\n",
      "          Validation Loss (standardized): 0.9339339505743348\n",
      "Epoch: 21, Loss (standarized): 0.9975334957689338\n",
      "          Validation Loss (standardized): 0.9640029259750479\n",
      "Epoch: 26, Loss (standarized): 1.00140342267771\n",
      "          Validation Loss (standardized): 0.976707230295944\n",
      "Epoch: 31, Loss (standarized): 0.9992481904648965\n",
      "          Validation Loss (standardized): 0.9532872512494848\n",
      "Epoch: 36, Loss (standarized): 0.9998049333849561\n",
      "          Validation Loss (standardized): 0.9567503530145381\n",
      "Epoch: 41, Loss (standarized): 1.0000099493640247\n",
      "          Validation Loss (standardized): 0.966221204919347\n",
      "Epoch: 46, Loss (standarized): 0.9999196513915194\n",
      "          Validation Loss (standardized): 0.9588314657428214\n",
      "Epoch: 51, Loss (standarized): 1.0000017027993562\n",
      "          Validation Loss (standardized): 0.9619800731376513\n",
      "Epoch: 56, Loss (standarized): 1.0001554860531896\n",
      "          Validation Loss (standardized): 0.9653691092884727\n",
      "Epoch: 61, Loss (standarized): 1.0000363922876783\n",
      "          Validation Loss (standardized): 0.9620934766796168\n",
      "Epoch: 66, Loss (standarized): 1.0000031429873295\n",
      "          Validation Loss (standardized): 0.9611956820153941\n",
      "Epoch: 71, Loss (standarized): 1.0000508867404048\n",
      "          Validation Loss (standardized): 0.9634181304669349\n",
      "Epoch: 76, Loss (standarized): 1.000023057777044\n",
      "          Validation Loss (standardized): 0.9623981954995261\n",
      "Epoch: 81, Loss (standarized): 1.000080359610669\n",
      "          Validation Loss (standardized): 0.9639823678264201\n",
      "Epoch: 86, Loss (standarized): 1.0000914006481803\n",
      "          Validation Loss (standardized): 0.9638058513925684\n",
      "Epoch: 91, Loss (standarized): 1.0000771947491742\n",
      "          Validation Loss (standardized): 0.964098520284939\n",
      "Epoch: 96, Loss (standarized): 1.0000433904003372\n",
      "          Validation Loss (standardized): 0.9622819905315144\n",
      "Final epoch: 100, Final loss (standarized): 1.0000173457001662\n",
      "Epoch: 1, Loss (standarized): 1.1367175313189612\n",
      "          Validation Loss (standardized): 1.021341558724844\n",
      "Epoch: 6, Loss (standarized): 1.028453265247845\n",
      "          Validation Loss (standardized): 0.9268356630683592\n",
      "Epoch: 11, Loss (standarized): 0.9966224955363433\n",
      "          Validation Loss (standardized): 0.9925108208366855\n",
      "Epoch: 16, Loss (standarized): 0.9574988565408408\n",
      "          Validation Loss (standardized): 0.885534211366873\n",
      "Epoch: 21, Loss (standarized): 0.9369240645494517\n",
      "          Validation Loss (standardized): 0.8754883684750324\n",
      "Epoch: 26, Loss (standarized): 0.9167111118455964\n",
      "          Validation Loss (standardized): 0.8718746752570808\n",
      "Epoch: 31, Loss (standarized): 0.8911228247389061\n",
      "          Validation Loss (standardized): 0.8126389084028048\n",
      "Epoch: 36, Loss (standarized): 0.8671627043889995\n",
      "          Validation Loss (standardized): 0.8038361256055331\n",
      "Epoch: 41, Loss (standarized): 0.8467836286144894\n",
      "          Validation Loss (standardized): 0.7737546217548296\n",
      "Epoch: 46, Loss (standarized): 0.8293661803331357\n",
      "          Validation Loss (standardized): 0.7489046704772381\n",
      "Epoch: 51, Loss (standarized): 0.8146334544394407\n",
      "          Validation Loss (standardized): 0.7398155067249352\n",
      "Epoch: 56, Loss (standarized): 0.8026486569821003\n",
      "          Validation Loss (standardized): 0.7201508737368809\n",
      "Epoch: 61, Loss (standarized): 0.7920604506101041\n",
      "          Validation Loss (standardized): 0.7157436936835395\n",
      "Epoch: 66, Loss (standarized): 0.7822670593275458\n",
      "          Validation Loss (standardized): 0.7034944187042299\n",
      "Epoch: 71, Loss (standarized): 0.772994017117975\n",
      "          Validation Loss (standardized): 0.6984073923691756\n",
      "Epoch: 76, Loss (standarized): 0.7642488070213107\n",
      "          Validation Loss (standardized): 0.6898555266579219\n",
      "Epoch: 81, Loss (standarized): 0.7558265047594744\n",
      "          Validation Loss (standardized): 0.6840625235433542\n",
      "Epoch: 86, Loss (standarized): 0.7475731076403659\n",
      "          Validation Loss (standardized): 0.6761582493970753\n",
      "Epoch: 91, Loss (standarized): 0.7396405707310278\n",
      "          Validation Loss (standardized): 0.6694866781794022\n",
      "Epoch: 96, Loss (standarized): 0.732337013258814\n",
      "          Validation Loss (standardized): 0.662425309569806\n",
      "Final epoch: 100, Final loss (standarized): 0.7270195833467807\n",
      "Epoch: 1, Loss (standarized): 1.047840470319665\n",
      "          Validation Loss (standardized): 1.0058906340851679\n",
      "Epoch: 6, Loss (standarized): 0.9892977386551938\n",
      "          Validation Loss (standardized): 0.9192590398613079\n",
      "Epoch: 11, Loss (standarized): 0.9553361876574791\n",
      "          Validation Loss (standardized): 0.9200473692409754\n",
      "Epoch: 16, Loss (standarized): 0.9300108918050018\n",
      "          Validation Loss (standardized): 0.8642871755677558\n",
      "Epoch: 21, Loss (standarized): 0.9098378257127274\n",
      "          Validation Loss (standardized): 0.8613880651299456\n",
      "Epoch: 26, Loss (standarized): 0.8913536154330794\n",
      "          Validation Loss (standardized): 0.8246106694159837\n",
      "Epoch: 31, Loss (standarized): 0.8739885223287803\n",
      "          Validation Loss (standardized): 0.8165556117434767\n",
      "Epoch: 36, Loss (standarized): 0.8569902193235148\n",
      "          Validation Loss (standardized): 0.788896986662501\n",
      "Epoch: 41, Loss (standarized): 0.840938794037088\n",
      "          Validation Loss (standardized): 0.7753313987586589\n",
      "Epoch: 46, Loss (standarized): 0.82598394822464\n",
      "          Validation Loss (standardized): 0.7597604292747762\n",
      "Epoch: 51, Loss (standarized): 0.8127619427818352\n",
      "          Validation Loss (standardized): 0.7432549197013704\n",
      "Epoch: 56, Loss (standarized): 0.8012966856644432\n",
      "          Validation Loss (standardized): 0.7341956420613074\n",
      "Epoch: 61, Loss (standarized): 0.7913343573838413\n",
      "          Validation Loss (standardized): 0.7240850050917564\n",
      "Epoch: 66, Loss (standarized): 0.7830236435053192\n",
      "          Validation Loss (standardized): 0.7159027776364926\n",
      "Epoch: 71, Loss (standarized): 0.7761393842058745\n",
      "          Validation Loss (standardized): 0.7095479016343208\n",
      "Epoch: 76, Loss (standarized): 0.770401640320532\n",
      "          Validation Loss (standardized): 0.7047400794601573\n",
      "Epoch: 81, Loss (standarized): 0.7656029503936932\n",
      "          Validation Loss (standardized): 0.7006051777176645\n",
      "Epoch: 86, Loss (standarized): 0.7615076855084572\n",
      "          Validation Loss (standardized): 0.6968633454969843\n",
      "Epoch: 91, Loss (standarized): 0.7580438925717102\n",
      "          Validation Loss (standardized): 0.6933800620748543\n",
      "Epoch: 96, Loss (standarized): 0.7551938144877081\n",
      "          Validation Loss (standardized): 0.69070768804564\n",
      "Final epoch: 100, Final loss (standarized): 0.7531914015133301\n",
      "Epoch: 1, Loss (standarized): 1.068522843137239\n",
      "          Validation Loss (standardized): 0.9708957566592332\n",
      "Epoch: 6, Loss (standarized): 0.9993875931033378\n",
      "          Validation Loss (standardized): 0.9497765654112003\n",
      "Epoch: 11, Loss (standarized): 0.9822539533227299\n",
      "          Validation Loss (standardized): 0.9160055461390104\n",
      "Epoch: 16, Loss (standarized): 0.9625877736717335\n",
      "          Validation Loss (standardized): 0.931168650181005\n",
      "Epoch: 21, Loss (standarized): 0.9443585640082677\n",
      "          Validation Loss (standardized): 0.8756848271902408\n",
      "Epoch: 26, Loss (standarized): 0.9259874838179772\n",
      "          Validation Loss (standardized): 0.8775368081739946\n",
      "Epoch: 31, Loss (standarized): 0.9085663608338976\n",
      "          Validation Loss (standardized): 0.844593682319202\n",
      "Epoch: 36, Loss (standarized): 0.8904561949318517\n",
      "          Validation Loss (standardized): 0.8238852353254674\n",
      "Epoch: 41, Loss (standarized): 0.8712739880033613\n",
      "          Validation Loss (standardized): 0.8019435927252507\n",
      "Epoch: 46, Loss (standarized): 0.8537851736523706\n",
      "          Validation Loss (standardized): 0.7783997182665684\n",
      "Epoch: 51, Loss (standarized): 0.8379988507642537\n",
      "          Validation Loss (standardized): 0.7607784704140014\n",
      "Epoch: 56, Loss (standarized): 0.8250445683906051\n",
      "          Validation Loss (standardized): 0.7476707868697584\n",
      "Epoch: 61, Loss (standarized): 0.8137774164519881\n",
      "          Validation Loss (standardized): 0.7340673906813714\n",
      "Epoch: 66, Loss (standarized): 0.8033640679524726\n",
      "          Validation Loss (standardized): 0.7275081636589431\n",
      "Epoch: 71, Loss (standarized): 0.7932629318721388\n",
      "          Validation Loss (standardized): 0.7178827241157407\n",
      "Epoch: 76, Loss (standarized): 0.7828633507354509\n",
      "          Validation Loss (standardized): 0.7092701067406773\n",
      "Epoch: 81, Loss (standarized): 0.7718012111471906\n",
      "          Validation Loss (standardized): 0.6984249331568202\n",
      "Epoch: 86, Loss (standarized): 0.7603248505807149\n",
      "          Validation Loss (standardized): 0.6880485781809955\n",
      "Epoch: 91, Loss (standarized): 0.7493368467725958\n",
      "          Validation Loss (standardized): 0.6777868558587579\n",
      "Epoch: 96, Loss (standarized): 0.7392434953164851\n",
      "          Validation Loss (standardized): 0.669279528650347\n",
      "Final epoch: 100, Final loss (standarized): 0.7319615872367473\n",
      "Epoch: 1, Loss (standarized): 1.1677176484328973\n",
      "          Validation Loss (standardized): 1.0670645355266677\n",
      "Epoch: 6, Loss (standarized): 1.0189254013051958\n",
      "          Validation Loss (standardized): 0.893358528486176\n",
      "Epoch: 11, Loss (standarized): 0.9446907159463747\n",
      "          Validation Loss (standardized): 0.9241364081851745\n",
      "Epoch: 16, Loss (standarized): 0.9389686663730394\n",
      "          Validation Loss (standardized): 0.9056618043637503\n",
      "Epoch: 21, Loss (standarized): 0.9076780094968244\n",
      "          Validation Loss (standardized): 0.8264677274331786\n",
      "Epoch: 26, Loss (standarized): 0.8863728457310686\n",
      "          Validation Loss (standardized): 0.8159687446951185\n",
      "Epoch: 31, Loss (standarized): 0.8681094501672622\n",
      "          Validation Loss (standardized): 0.8172791625525696\n",
      "Epoch: 36, Loss (standarized): 0.8460191018452136\n",
      "          Validation Loss (standardized): 0.7685366864862395\n",
      "Epoch: 41, Loss (standarized): 0.8290338113554959\n",
      "          Validation Loss (standardized): 0.7514922043271131\n",
      "Epoch: 46, Loss (standarized): 0.8128862411286066\n",
      "          Validation Loss (standardized): 0.7441669960698728\n",
      "Epoch: 51, Loss (standarized): 0.7978693852611416\n",
      "          Validation Loss (standardized): 0.7174688154234998\n",
      "Epoch: 56, Loss (standarized): 0.784508916681474\n",
      "          Validation Loss (standardized): 0.7097993183639175\n",
      "Epoch: 61, Loss (standarized): 0.7723722943948887\n",
      "          Validation Loss (standardized): 0.6974471344100632\n",
      "Epoch: 66, Loss (standarized): 0.7611336931580134\n",
      "          Validation Loss (standardized): 0.6868587513786066\n",
      "Epoch: 71, Loss (standarized): 0.7508086185835384\n",
      "          Validation Loss (standardized): 0.6801950518576717\n",
      "Epoch: 76, Loss (standarized): 0.7414495039320761\n",
      "          Validation Loss (standardized): 0.6713573868025249\n",
      "Epoch: 81, Loss (standarized): 0.7328777814062718\n",
      "          Validation Loss (standardized): 0.6647587039639302\n",
      "Epoch: 86, Loss (standarized): 0.7249993440243822\n",
      "          Validation Loss (standardized): 0.6576859761118667\n",
      "Epoch: 91, Loss (standarized): 0.7178413230160718\n",
      "          Validation Loss (standardized): 0.6517093342107233\n",
      "Epoch: 96, Loss (standarized): 0.7113489938346227\n",
      "          Validation Loss (standardized): 0.6462805366487747\n",
      "Final epoch: 100, Final loss (standarized): 0.7066389761593042\n",
      "Epoch: 1, Loss (standarized): 1.055675916891143\n",
      "          Validation Loss (standardized): 0.9498157765905221\n",
      "Epoch: 6, Loss (standarized): 0.9728679687019597\n",
      "          Validation Loss (standardized): 0.9075624806049768\n",
      "Epoch: 11, Loss (standarized): 0.942943518542339\n",
      "          Validation Loss (standardized): 0.8752539214617814\n",
      "Epoch: 16, Loss (standarized): 0.9121340743361419\n",
      "          Validation Loss (standardized): 0.8609097901747699\n",
      "Epoch: 21, Loss (standarized): 0.879390516325744\n",
      "          Validation Loss (standardized): 0.7927085585335198\n",
      "Epoch: 26, Loss (standarized): 0.8493776163117464\n",
      "          Validation Loss (standardized): 0.7872465720814339\n",
      "Epoch: 31, Loss (standarized): 0.8267091833357758\n",
      "          Validation Loss (standardized): 0.7389353231362185\n",
      "Epoch: 36, Loss (standarized): 0.8123238911324094\n",
      "          Validation Loss (standardized): 0.7344477536763963\n",
      "Epoch: 41, Loss (standarized): 0.8033899771364876\n",
      "          Validation Loss (standardized): 0.7151709517197906\n",
      "Epoch: 46, Loss (standarized): 0.7947093653285633\n",
      "          Validation Loss (standardized): 0.712533881340166\n",
      "Epoch: 51, Loss (standarized): 0.7842651665486728\n",
      "          Validation Loss (standardized): 0.7000941204557898\n",
      "Epoch: 56, Loss (standarized): 0.773860352520958\n",
      "          Validation Loss (standardized): 0.6965708202936315\n",
      "Epoch: 61, Loss (standarized): 0.7646940640430767\n",
      "          Validation Loss (standardized): 0.6874689276094499\n",
      "Epoch: 66, Loss (standarized): 0.7559168946323717\n",
      "          Validation Loss (standardized): 0.6828665342790932\n",
      "Epoch: 71, Loss (standarized): 0.7467721615917864\n",
      "          Validation Loss (standardized): 0.6724043679613717\n",
      "Epoch: 76, Loss (standarized): 0.7376567462668463\n",
      "          Validation Loss (standardized): 0.6657012988632967\n",
      "Epoch: 81, Loss (standarized): 0.7290875257293558\n",
      "          Validation Loss (standardized): 0.6563737144171066\n",
      "Epoch: 86, Loss (standarized): 0.7210187684104951\n",
      "          Validation Loss (standardized): 0.6507555832811909\n",
      "Epoch: 91, Loss (standarized): 0.7132902360939828\n",
      "          Validation Loss (standardized): 0.6438067585731079\n",
      "Epoch: 96, Loss (standarized): 0.7058483529194884\n",
      "          Validation Loss (standardized): 0.6385296523840098\n",
      "Final epoch: 100, Final loss (standarized): 0.6999128957014582\n",
      "Epoch: 1, Loss (standarized): 1.294540002183379\n",
      "          Validation Loss (standardized): 0.9374358590954383\n",
      "Epoch: 6, Loss (standarized): 1.0505092973066\n",
      "          Validation Loss (standardized): 1.0994759075750113\n",
      "Epoch: 11, Loss (standarized): 0.9534119752097006\n",
      "          Validation Loss (standardized): 0.8895994649380283\n",
      "Epoch: 16, Loss (standarized): 0.9671132955866917\n",
      "          Validation Loss (standardized): 0.8595138844935383\n",
      "Epoch: 21, Loss (standarized): 0.923180526150254\n",
      "          Validation Loss (standardized): 0.8914187750350622\n",
      "Epoch: 26, Loss (standarized): 0.9174707295350164\n",
      "          Validation Loss (standardized): 0.8763964762932369\n",
      "Epoch: 31, Loss (standarized): 0.8997860450579409\n",
      "          Validation Loss (standardized): 0.8208099587561832\n",
      "Epoch: 36, Loss (standarized): 0.8878082836043667\n",
      "          Validation Loss (standardized): 0.8186592039404386\n",
      "Epoch: 41, Loss (standarized): 0.8786894403418511\n",
      "          Validation Loss (standardized): 0.8261590283663719\n",
      "Epoch: 46, Loss (standarized): 0.8688338154311612\n",
      "          Validation Loss (standardized): 0.7958709559145811\n",
      "Epoch: 51, Loss (standarized): 0.8627431689074857\n",
      "          Validation Loss (standardized): 0.7899177958180849\n",
      "Epoch: 56, Loss (standarized): 0.8568879676599053\n",
      "          Validation Loss (standardized): 0.7933325582789729\n",
      "Epoch: 61, Loss (standarized): 0.8518877432439069\n",
      "          Validation Loss (standardized): 0.7782243353649185\n",
      "Epoch: 66, Loss (standarized): 0.8475854279130679\n",
      "          Validation Loss (standardized): 0.7764191684118561\n",
      "Epoch: 71, Loss (standarized): 0.8433246318380467\n",
      "          Validation Loss (standardized): 0.7743329933604431\n",
      "Epoch: 76, Loss (standarized): 0.8391340530686904\n",
      "          Validation Loss (standardized): 0.7655572074455944\n",
      "Epoch: 81, Loss (standarized): 0.834663385826072\n",
      "          Validation Loss (standardized): 0.764517634928053\n",
      "Epoch: 86, Loss (standarized): 0.8302187879604436\n",
      "          Validation Loss (standardized): 0.7582302599307649\n",
      "Epoch: 91, Loss (standarized): 0.8257411128538887\n",
      "          Validation Loss (standardized): 0.7539190429548001\n",
      "Epoch: 96, Loss (standarized): 0.8211843584282199\n",
      "          Validation Loss (standardized): 0.75012207102713\n",
      "Final epoch: 100, Final loss (standarized): 0.817587878753818\n",
      "Epoch: 1, Loss (standarized): 1.0775027812434823\n",
      "          Validation Loss (standardized): 0.9716110507271577\n",
      "Epoch: 6, Loss (standarized): 0.9747141122584028\n",
      "          Validation Loss (standardized): 0.9150890689155216\n",
      "Epoch: 11, Loss (standarized): 0.9350778963652466\n",
      "          Validation Loss (standardized): 0.8829506338813186\n",
      "Epoch: 16, Loss (standarized): 0.8944657253247108\n",
      "          Validation Loss (standardized): 0.8016868044716571\n",
      "Epoch: 21, Loss (standarized): 0.85611686132699\n",
      "          Validation Loss (standardized): 0.8004445454084214\n",
      "Epoch: 26, Loss (standarized): 0.8281840426330686\n",
      "          Validation Loss (standardized): 0.7399762793842999\n",
      "Epoch: 31, Loss (standarized): 0.8114990096999346\n",
      "          Validation Loss (standardized): 0.7323981550904846\n",
      "Epoch: 36, Loss (standarized): 0.8015818778844686\n",
      "          Validation Loss (standardized): 0.7166129246041509\n",
      "Epoch: 41, Loss (standarized): 0.7926152772287317\n",
      "          Validation Loss (standardized): 0.706740946181269\n",
      "Epoch: 46, Loss (standarized): 0.7821386372115285\n",
      "          Validation Loss (standardized): 0.702013521118766\n",
      "Epoch: 51, Loss (standarized): 0.7717428295066279\n",
      "          Validation Loss (standardized): 0.6913724563712901\n",
      "Epoch: 56, Loss (standarized): 0.7627557227886742\n",
      "          Validation Loss (standardized): 0.6889307384794108\n",
      "Epoch: 61, Loss (standarized): 0.754178068494906\n",
      "          Validation Loss (standardized): 0.6790896044742556\n",
      "Epoch: 66, Loss (standarized): 0.7452418494649826\n",
      "          Validation Loss (standardized): 0.673173334793885\n",
      "Epoch: 71, Loss (standarized): 0.7363193690265932\n",
      "          Validation Loss (standardized): 0.6633125924784855\n",
      "Epoch: 76, Loss (standarized): 0.7280426293144596\n",
      "          Validation Loss (standardized): 0.6565529764759738\n",
      "Epoch: 81, Loss (standarized): 0.7204112830194561\n",
      "          Validation Loss (standardized): 0.6497594537165068\n",
      "Epoch: 86, Loss (standarized): 0.7132910816360554\n",
      "          Validation Loss (standardized): 0.6440169429960467\n",
      "Epoch: 91, Loss (standarized): 0.7066746696156038\n",
      "          Validation Loss (standardized): 0.6392650335881187\n",
      "Epoch: 96, Loss (standarized): 0.700427660246236\n",
      "          Validation Loss (standardized): 0.633814558921442\n",
      "Final epoch: 100, Final loss (standarized): 0.695547313283581\n",
      "Epoch: 1, Loss (standarized): 1.2278636822598064\n",
      "          Validation Loss (standardized): 1.0063544188042186\n",
      "Epoch: 6, Loss (standarized): 1.0821252057184485\n",
      "          Validation Loss (standardized): 1.0578197180459263\n",
      "Epoch: 11, Loss (standarized): 1.023203396369627\n",
      "          Validation Loss (standardized): 0.9243454773081197\n",
      "Epoch: 16, Loss (standarized): 0.9663873905760969\n",
      "          Validation Loss (standardized): 0.9365592173809708\n",
      "Epoch: 21, Loss (standarized): 0.9394285712091699\n",
      "          Validation Loss (standardized): 0.8899991251566348\n",
      "Epoch: 26, Loss (standarized): 0.9096991189345409\n",
      "          Validation Loss (standardized): 0.8248151029987154\n",
      "Epoch: 31, Loss (standarized): 0.8779263744062641\n",
      "          Validation Loss (standardized): 0.8222435202412072\n",
      "Epoch: 36, Loss (standarized): 0.8542020556278984\n",
      "          Validation Loss (standardized): 0.7784166555637654\n",
      "Epoch: 41, Loss (standarized): 0.8371068069596458\n",
      "          Validation Loss (standardized): 0.7514303475300125\n",
      "Epoch: 46, Loss (standarized): 0.8252895282526949\n",
      "          Validation Loss (standardized): 0.74810714990923\n",
      "Epoch: 51, Loss (standarized): 0.8176474434896583\n",
      "          Validation Loss (standardized): 0.7269317687029206\n",
      "Epoch: 56, Loss (standarized): 0.8102701201500748\n",
      "          Validation Loss (standardized): 0.7274722317667485\n",
      "Epoch: 61, Loss (standarized): 0.8010624066202678\n",
      "          Validation Loss (standardized): 0.7148090331187592\n",
      "Epoch: 66, Loss (standarized): 0.7905283902797876\n",
      "          Validation Loss (standardized): 0.7093647738661005\n",
      "Epoch: 71, Loss (standarized): 0.7798259440735718\n",
      "          Validation Loss (standardized): 0.701458269303136\n",
      "Epoch: 76, Loss (standarized): 0.7689704960331192\n",
      "          Validation Loss (standardized): 0.692316825644616\n",
      "Epoch: 81, Loss (standarized): 0.7574940634758078\n",
      "          Validation Loss (standardized): 0.6838883861976883\n",
      "Epoch: 86, Loss (standarized): 0.7454081845653967\n",
      "          Validation Loss (standardized): 0.6716906724224964\n",
      "Epoch: 91, Loss (standarized): 0.7333078411078785\n",
      "          Validation Loss (standardized): 0.6619928723755124\n",
      "Epoch: 96, Loss (standarized): 0.7216857638136327\n",
      "          Validation Loss (standardized): 0.6507285150625699\n",
      "Final epoch: 100, Final loss (standarized): 0.7128463866742882\n",
      "Epoch: 1, Loss (standarized): 1.1389090124658938\n",
      "          Validation Loss (standardized): 0.9189853048246448\n",
      "Epoch: 6, Loss (standarized): 1.0210912362827052\n",
      "          Validation Loss (standardized): 0.9971177303225298\n",
      "Epoch: 11, Loss (standarized): 0.9776096696740453\n",
      "          Validation Loss (standardized): 0.880524137837775\n",
      "Epoch: 16, Loss (standarized): 0.9376427977289632\n",
      "          Validation Loss (standardized): 0.8986059151899906\n",
      "Epoch: 21, Loss (standarized): 0.9216465137357235\n",
      "          Validation Loss (standardized): 0.8741085446517158\n",
      "Epoch: 26, Loss (standarized): 0.8942609316974963\n",
      "          Validation Loss (standardized): 0.8074031647412148\n",
      "Epoch: 31, Loss (standarized): 0.8652603651451678\n",
      "          Validation Loss (standardized): 0.8025933112430351\n",
      "Epoch: 36, Loss (standarized): 0.8441805090742541\n",
      "          Validation Loss (standardized): 0.768439179123039\n",
      "Epoch: 41, Loss (standarized): 0.8288440765219114\n",
      "          Validation Loss (standardized): 0.7385379447818815\n",
      "Epoch: 46, Loss (standarized): 0.8186866742826118\n",
      "          Validation Loss (standardized): 0.7399170573993976\n",
      "Epoch: 51, Loss (standarized): 0.8116070248072195\n",
      "          Validation Loss (standardized): 0.7202077785730665\n",
      "Epoch: 56, Loss (standarized): 0.8035284813175447\n",
      "          Validation Loss (standardized): 0.718783419927639\n",
      "Epoch: 61, Loss (standarized): 0.7936489693621611\n",
      "          Validation Loss (standardized): 0.7088058478524252\n",
      "Epoch: 66, Loss (standarized): 0.783357792428642\n",
      "          Validation Loss (standardized): 0.7009495723469605\n",
      "Epoch: 71, Loss (standarized): 0.7734878320577067\n",
      "          Validation Loss (standardized): 0.696131193162458\n",
      "Epoch: 76, Loss (standarized): 0.7637768503484329\n",
      "          Validation Loss (standardized): 0.6858928549479683\n",
      "Epoch: 81, Loss (standarized): 0.7539562727870521\n",
      "          Validation Loss (standardized): 0.6799238835783764\n",
      "Epoch: 86, Loss (standarized): 0.7441603939122903\n",
      "          Validation Loss (standardized): 0.6693867346327333\n",
      "Epoch: 91, Loss (standarized): 0.7347999207169404\n",
      "          Validation Loss (standardized): 0.6620518500514178\n",
      "Epoch: 96, Loss (standarized): 0.7261389097229818\n",
      "          Validation Loss (standardized): 0.6539312582595903\n",
      "Final epoch: 100, Final loss (standarized): 0.7197421146029784\n",
      "Epoch: 1, Loss (standarized): 1.2638364828059074\n",
      "          Validation Loss (standardized): 0.9487594816242805\n",
      "Epoch: 6, Loss (standarized): 1.06464172571469\n",
      "          Validation Loss (standardized): 1.1096459676787334\n",
      "Epoch: 11, Loss (standarized): 0.9854325487337483\n",
      "          Validation Loss (standardized): 0.9261391372719132\n",
      "Epoch: 16, Loss (standarized): 1.0011164664658876\n",
      "          Validation Loss (standardized): 0.9063645597195726\n",
      "Epoch: 21, Loss (standarized): 0.969784003283889\n",
      "          Validation Loss (standardized): 0.9492970498515976\n",
      "Epoch: 26, Loss (standarized): 0.9663709627310378\n",
      "          Validation Loss (standardized): 0.9341145592391737\n",
      "Epoch: 31, Loss (standarized): 0.9524518264418859\n",
      "          Validation Loss (standardized): 0.8844675057740434\n",
      "Epoch: 36, Loss (standarized): 0.9397921000848679\n",
      "          Validation Loss (standardized): 0.8840587196298725\n",
      "Epoch: 41, Loss (standarized): 0.9279878112860093\n",
      "          Validation Loss (standardized): 0.885853299300581\n",
      "Epoch: 46, Loss (standarized): 0.9121900501840493\n",
      "          Validation Loss (standardized): 0.8485692852128511\n",
      "Epoch: 51, Loss (standarized): 0.8975194700499234\n",
      "          Validation Loss (standardized): 0.8335849188201528\n",
      "Epoch: 56, Loss (standarized): 0.8823663067852305\n",
      "          Validation Loss (standardized): 0.8244038181264112\n",
      "Epoch: 61, Loss (standarized): 0.8676971727558843\n",
      "          Validation Loss (standardized): 0.7978209643450217\n",
      "Epoch: 66, Loss (standarized): 0.8549070111216217\n",
      "          Validation Loss (standardized): 0.787177569584675\n",
      "Epoch: 71, Loss (standarized): 0.8442346852109223\n",
      "          Validation Loss (standardized): 0.7761629919237822\n",
      "Epoch: 76, Loss (standarized): 0.8355588193164744\n",
      "          Validation Loss (standardized): 0.7635950264382639\n",
      "Epoch: 81, Loss (standarized): 0.8284027191004995\n",
      "          Validation Loss (standardized): 0.7599447077531594\n",
      "Epoch: 86, Loss (standarized): 0.8222739741762283\n",
      "          Validation Loss (standardized): 0.7513655689442733\n",
      "Epoch: 91, Loss (standarized): 0.8165734217756423\n",
      "          Validation Loss (standardized): 0.7475841217351318\n",
      "Epoch: 96, Loss (standarized): 0.8109048379043966\n",
      "          Validation Loss (standardized): 0.7414264951884636\n",
      "Final epoch: 100, Final loss (standarized): 0.8062873712847543\n",
      "Epoch: 1, Loss (standarized): 1.6706608459112053\n",
      "          Validation Loss (standardized): 1.1140777622501064\n",
      "Epoch: 6, Loss (standarized): 1.0227406956962832\n",
      "          Validation Loss (standardized): 1.1255269636620744\n",
      "Epoch: 11, Loss (standarized): 1.0736424307879224\n",
      "          Validation Loss (standardized): 1.0775245269693223\n",
      "Epoch: 16, Loss (standarized): 0.9596685004922048\n",
      "          Validation Loss (standardized): 0.8885570354330875\n",
      "Epoch: 21, Loss (standarized): 0.981212007106518\n",
      "          Validation Loss (standardized): 0.8677265293339014\n",
      "Epoch: 26, Loss (standarized): 0.931563063360937\n",
      "          Validation Loss (standardized): 0.8723198335233107\n",
      "Epoch: 31, Loss (standarized): 0.9240665309598193\n",
      "          Validation Loss (standardized): 0.9011660270503842\n",
      "Epoch: 36, Loss (standarized): 0.9014489429848872\n",
      "          Validation Loss (standardized): 0.8483934299919244\n",
      "Epoch: 41, Loss (standarized): 0.8843430678640442\n",
      "          Validation Loss (standardized): 0.8027196486357774\n",
      "Epoch: 46, Loss (standarized): 0.8675198729202591\n",
      "          Validation Loss (standardized): 0.7890654917349968\n",
      "Epoch: 51, Loss (standarized): 0.850922573539642\n",
      "          Validation Loss (standardized): 0.7880829504911702\n",
      "Epoch: 56, Loss (standarized): 0.836946344107008\n",
      "          Validation Loss (standardized): 0.7644298673118033\n",
      "Epoch: 61, Loss (standarized): 0.8250694448186373\n",
      "          Validation Loss (standardized): 0.7400096761146281\n",
      "Epoch: 66, Loss (standarized): 0.815043853113456\n",
      "          Validation Loss (standardized): 0.7329588478542257\n",
      "Epoch: 71, Loss (standarized): 0.8065713720794745\n",
      "          Validation Loss (standardized): 0.7289310882186743\n",
      "Epoch: 76, Loss (standarized): 0.7982826640182339\n",
      "          Validation Loss (standardized): 0.7162470603292317\n",
      "Epoch: 81, Loss (standarized): 0.7901000209640454\n",
      "          Validation Loss (standardized): 0.7074910135243317\n",
      "Epoch: 86, Loss (standarized): 0.7813900326969165\n",
      "          Validation Loss (standardized): 0.7035498621704455\n",
      "Epoch: 91, Loss (standarized): 0.772574819100853\n",
      "          Validation Loss (standardized): 0.6957952518313314\n",
      "Epoch: 96, Loss (standarized): 0.76369290892667\n",
      "          Validation Loss (standardized): 0.6871087000141497\n",
      "Final epoch: 100, Final loss (standarized): 0.7565780572192171\n",
      "Epoch: 1, Loss (standarized): 1.1389170406033262\n",
      "          Validation Loss (standardized): 0.8849513720123224\n",
      "Epoch: 6, Loss (standarized): 0.9700093003309906\n",
      "          Validation Loss (standardized): 0.9059293565557696\n",
      "Epoch: 11, Loss (standarized): 0.9378590241586725\n",
      "          Validation Loss (standardized): 0.8163808348489044\n",
      "Epoch: 16, Loss (standarized): 0.8863750698041942\n",
      "          Validation Loss (standardized): 0.8609746238040605\n",
      "Epoch: 21, Loss (standarized): 0.8509839020150316\n",
      "          Validation Loss (standardized): 0.7661296763158354\n",
      "Epoch: 26, Loss (standarized): 0.8354893597375967\n",
      "          Validation Loss (standardized): 0.7479106022415369\n",
      "Epoch: 31, Loss (standarized): 0.8238186387918564\n",
      "          Validation Loss (standardized): 0.7554750223523127\n",
      "Epoch: 36, Loss (standarized): 0.8144901184241391\n",
      "          Validation Loss (standardized): 0.7194182585231288\n",
      "Epoch: 41, Loss (standarized): 0.8079372742727958\n",
      "          Validation Loss (standardized): 0.7316707504547441\n",
      "Epoch: 46, Loss (standarized): 0.8016959659622536\n",
      "          Validation Loss (standardized): 0.7151119058015086\n",
      "Epoch: 51, Loss (standarized): 0.7941276633494107\n",
      "          Validation Loss (standardized): 0.7110929643120971\n",
      "Epoch: 56, Loss (standarized): 0.7857225759665039\n",
      "          Validation Loss (standardized): 0.7077923196659966\n",
      "Epoch: 61, Loss (standarized): 0.7770950726379404\n",
      "          Validation Loss (standardized): 0.6966991570037178\n",
      "Epoch: 66, Loss (standarized): 0.7683839999783937\n",
      "          Validation Loss (standardized): 0.6954271139657385\n",
      "Epoch: 71, Loss (standarized): 0.7593126663682265\n",
      "          Validation Loss (standardized): 0.6833607974578894\n",
      "Epoch: 76, Loss (standarized): 0.7498491188562986\n",
      "          Validation Loss (standardized): 0.6789154788722882\n",
      "Epoch: 81, Loss (standarized): 0.7401281863769293\n",
      "          Validation Loss (standardized): 0.6679063370394225\n",
      "Epoch: 86, Loss (standarized): 0.7303761532733548\n",
      "          Validation Loss (standardized): 0.661239751120099\n",
      "Epoch: 91, Loss (standarized): 0.7207467045698721\n",
      "          Validation Loss (standardized): 0.6520012319977471\n",
      "Epoch: 96, Loss (standarized): 0.7113230759499218\n",
      "          Validation Loss (standardized): 0.6448636547101282\n",
      "Final epoch: 100, Final loss (standarized): 0.7039754718055337\n",
      "Epoch: 1, Loss (standarized): 1.2535163667040912\n",
      "          Validation Loss (standardized): 1.126392344567108\n",
      "Epoch: 6, Loss (standarized): 1.0451585265935182\n",
      "          Validation Loss (standardized): 0.9322822106866535\n",
      "Epoch: 11, Loss (standarized): 0.9907360837265529\n",
      "          Validation Loss (standardized): 0.9671172629076306\n",
      "Epoch: 16, Loss (standarized): 1.0013341511495308\n",
      "          Validation Loss (standardized): 0.9885875903036601\n",
      "Epoch: 21, Loss (standarized): 0.9877700436173111\n",
      "          Validation Loss (standardized): 0.9323516915016379\n",
      "Epoch: 26, Loss (standarized): 0.9900983877384647\n",
      "          Validation Loss (standardized): 0.9398074430370003\n",
      "Epoch: 31, Loss (standarized): 0.990750037639135\n",
      "          Validation Loss (standardized): 0.963240028276957\n",
      "Epoch: 36, Loss (standarized): 0.9915352466777957\n",
      "          Validation Loss (standardized): 0.9514382833741968\n",
      "Epoch: 41, Loss (standarized): 0.993601459856964\n",
      "          Validation Loss (standardized): 0.9508715817802218\n",
      "Epoch: 46, Loss (standarized): 0.9957477173244511\n",
      "          Validation Loss (standardized): 0.9617253268521878\n",
      "Epoch: 51, Loss (standarized): 0.9973288558449458\n",
      "          Validation Loss (standardized): 0.9594599814831604\n",
      "Epoch: 56, Loss (standarized): 0.9991182974107031\n",
      "          Validation Loss (standardized): 0.9555890099865235\n",
      "Epoch: 61, Loss (standarized): 0.9999052483381471\n",
      "          Validation Loss (standardized): 0.960939477476287\n",
      "Epoch: 66, Loss (standarized): 1.0002981831224385\n",
      "          Validation Loss (standardized): 0.9616031975841419\n",
      "Epoch: 71, Loss (standarized): 1.000164398675365\n",
      "          Validation Loss (standardized): 0.9588585763075954\n",
      "Epoch: 76, Loss (standarized): 1.000067145380584\n",
      "          Validation Loss (standardized): 0.9586779466277531\n",
      "Epoch: 81, Loss (standarized): 1.0000205803375999\n",
      "          Validation Loss (standardized): 0.9624201721440303\n",
      "Epoch: 86, Loss (standarized): 1.0000003316340442\n",
      "          Validation Loss (standardized): 0.9594583013783128\n",
      "Epoch: 91, Loss (standarized): 1.0000029036774398\n",
      "          Validation Loss (standardized): 0.9605912265758942\n",
      "Epoch: 96, Loss (standarized): 1.0000194488102552\n",
      "          Validation Loss (standardized): 0.9625946150706461\n",
      "Final epoch: 100, Final loss (standarized): 1.0000049861627243\n",
      "Epoch: 1, Loss (standarized): 1.7047037348609149\n",
      "          Validation Loss (standardized): 1.1441177174334285\n",
      "Epoch: 6, Loss (standarized): 1.0166225550231673\n",
      "          Validation Loss (standardized): 1.074687744160699\n",
      "Epoch: 11, Loss (standarized): 1.0843248920988275\n",
      "          Validation Loss (standardized): 1.109858996322339\n",
      "Epoch: 16, Loss (standarized): 0.9988860526836094\n",
      "          Validation Loss (standardized): 0.9509093120142735\n",
      "Epoch: 21, Loss (standarized): 1.018045665008144\n",
      "          Validation Loss (standardized): 0.9290891002784929\n",
      "Epoch: 26, Loss (standarized): 0.9992616722103215\n",
      "          Validation Loss (standardized): 0.9446583851402238\n",
      "Epoch: 31, Loss (standarized): 0.9981709006752428\n",
      "          Validation Loss (standardized): 0.9815560086049203\n",
      "Epoch: 36, Loss (standarized): 0.9976823904510667\n",
      "          Validation Loss (standardized): 0.965990654213455\n",
      "Epoch: 41, Loss (standarized): 0.9982172138884993\n",
      "          Validation Loss (standardized): 0.9494742401490345\n",
      "Epoch: 46, Loss (standarized): 0.9991623391976759\n",
      "          Validation Loss (standardized): 0.9572275312455603\n",
      "Epoch: 51, Loss (standarized): 0.9998014571692513\n",
      "          Validation Loss (standardized): 0.9659804014471741\n",
      "Epoch: 56, Loss (standarized): 0.9999452540921844\n",
      "          Validation Loss (standardized): 0.9630504258024912\n",
      "Epoch: 61, Loss (standarized): 0.9998706510177726\n",
      "          Validation Loss (standardized): 0.9585406265860718\n",
      "Epoch: 66, Loss (standarized): 0.9999277258981145\n",
      "          Validation Loss (standardized): 0.9591966638302591\n",
      "Epoch: 71, Loss (standarized): 0.9999876690924779\n",
      "          Validation Loss (standardized): 0.9618409266015914\n",
      "Epoch: 76, Loss (standarized): 1.0000408768263236\n",
      "          Validation Loss (standardized): 0.9618417446954959\n",
      "Epoch: 81, Loss (standarized): 0.9999956651298575\n",
      "          Validation Loss (standardized): 0.9595024239882229\n",
      "Epoch: 86, Loss (standarized): 1.0000302433203025\n",
      "          Validation Loss (standardized): 0.9589615379318508\n",
      "Epoch: 91, Loss (standarized): 1.0000268062300584\n",
      "          Validation Loss (standardized): 0.9594628191409594\n",
      "Epoch: 96, Loss (standarized): 1.0000090226179423\n",
      "          Validation Loss (standardized): 0.9620182515410448\n",
      "Final epoch: 100, Final loss (standarized): 1.0000031549280906\n",
      "Epoch: 1, Loss (standarized): 0.9788815540937664\n",
      "          Validation Loss (standardized): 0.9441148310918156\n",
      "Epoch: 6, Loss (standarized): 0.9782099372073262\n",
      "          Validation Loss (standardized): 0.9401674152400139\n",
      "Epoch: 11, Loss (standarized): 0.9820677546840365\n",
      "          Validation Loss (standardized): 0.9445726258559758\n",
      "Epoch: 16, Loss (standarized): 0.9866028586565676\n",
      "          Validation Loss (standardized): 0.9462284744047841\n",
      "Epoch: 21, Loss (standarized): 0.9912589708887953\n",
      "          Validation Loss (standardized): 0.9522062614986218\n",
      "Epoch: 26, Loss (standarized): 0.9955505422417025\n",
      "          Validation Loss (standardized): 0.956338690508434\n",
      "Epoch: 31, Loss (standarized): 0.9985401699524037\n",
      "          Validation Loss (standardized): 0.9605018318745263\n",
      "Epoch: 36, Loss (standarized): 0.9995572407942463\n",
      "          Validation Loss (standardized): 0.9586539808785431\n",
      "Epoch: 41, Loss (standarized): 1.0000896757894\n",
      "          Validation Loss (standardized): 0.964963385369844\n",
      "Epoch: 46, Loss (standarized): 1.0000180964298437\n",
      "          Validation Loss (standardized): 0.9635366051378617\n",
      "Epoch: 51, Loss (standarized): 1.0000020203287043\n",
      "          Validation Loss (standardized): 0.958210032087581\n",
      "Epoch: 56, Loss (standarized): 1.0000893061314127\n",
      "          Validation Loss (standardized): 0.9573062318368705\n",
      "Epoch: 61, Loss (standarized): 1.0000027313223188\n",
      "          Validation Loss (standardized): 0.9611331734024597\n",
      "Epoch: 66, Loss (standarized): 1.000092866062821\n",
      "          Validation Loss (standardized): 0.9577487348621926\n",
      "Epoch: 71, Loss (standarized): 1.000037453227609\n",
      "          Validation Loss (standardized): 0.9586764559770664\n",
      "Epoch: 76, Loss (standarized): 1.0000005463569734\n",
      "          Validation Loss (standardized): 0.9603572676460268\n",
      "Epoch: 81, Loss (standarized): 1.0000167807504492\n",
      "          Validation Loss (standardized): 0.962180127526248\n",
      "Epoch: 86, Loss (standarized): 1.000003657926582\n",
      "          Validation Loss (standardized): 0.960431311985233\n",
      "Epoch: 91, Loss (standarized): 1.0000097363501284\n",
      "          Validation Loss (standardized): 0.9625690774751473\n",
      "Epoch: 96, Loss (standarized): 1.0000330759232954\n",
      "          Validation Loss (standardized): 0.9625612094451091\n",
      "Final epoch: 100, Final loss (standarized): 1.000002771969998\n",
      "Epoch: 1, Loss (standarized): 1.8278220700761303\n",
      "          Validation Loss (standardized): 1.6304642171214312\n",
      "Epoch: 6, Loss (standarized): 1.0503974565721208\n",
      "          Validation Loss (standardized): 0.9698586994536962\n",
      "Epoch: 11, Loss (standarized): 1.1021055396733677\n",
      "          Validation Loss (standardized): 0.9515523666416372\n",
      "Epoch: 16, Loss (standarized): 1.000843911079178\n",
      "          Validation Loss (standardized): 0.9937514807647942\n",
      "Epoch: 21, Loss (standarized): 1.027002309396017\n",
      "          Validation Loss (standardized): 1.039844422178652\n",
      "Epoch: 26, Loss (standarized): 0.9932569251019977\n",
      "          Validation Loss (standardized): 0.9535415912950804\n",
      "Epoch: 31, Loss (standarized): 0.9974536317728626\n",
      "          Validation Loss (standardized): 0.929673390501963\n",
      "Epoch: 36, Loss (standarized): 0.9923633057995394\n",
      "          Validation Loss (standardized): 0.9510915433924468\n",
      "Epoch: 41, Loss (standarized): 0.9958693854716643\n",
      "          Validation Loss (standardized): 0.9718633627388913\n",
      "Epoch: 46, Loss (standarized): 0.9953899343597907\n",
      "          Validation Loss (standardized): 0.9567006203004226\n",
      "Epoch: 51, Loss (standarized): 0.996412928897913\n",
      "          Validation Loss (standardized): 0.954762168807442\n",
      "Epoch: 56, Loss (standarized): 0.9974178338251743\n",
      "          Validation Loss (standardized): 0.9597815002916431\n",
      "Epoch: 61, Loss (standarized): 0.9981298855397973\n",
      "          Validation Loss (standardized): 0.9579600935304005\n",
      "Epoch: 66, Loss (standarized): 0.9986779735651791\n",
      "          Validation Loss (standardized): 0.9609682975835928\n",
      "Epoch: 71, Loss (standarized): 0.999152746194999\n",
      "          Validation Loss (standardized): 0.9644734368668556\n",
      "Epoch: 76, Loss (standarized): 0.9994360071871737\n",
      "          Validation Loss (standardized): 0.9609776695225968\n",
      "Epoch: 81, Loss (standarized): 0.9996206429777643\n",
      "          Validation Loss (standardized): 0.9592729481137943\n",
      "Epoch: 86, Loss (standarized): 0.999819155431871\n",
      "          Validation Loss (standardized): 0.9585177627072038\n",
      "Epoch: 91, Loss (standarized): 0.9999847068492018\n",
      "          Validation Loss (standardized): 0.9602607957186674\n",
      "Epoch: 96, Loss (standarized): 1.0001105747001466\n",
      "          Validation Loss (standardized): 0.9637791862994383\n",
      "Final epoch: 100, Final loss (standarized): 1.0000475835486213\n",
      "Epoch: 1, Loss (standarized): 1.1035223691910097\n",
      "          Validation Loss (standardized): 0.9902512882659525\n",
      "Epoch: 6, Loss (standarized): 1.004297770336065\n",
      "          Validation Loss (standardized): 0.9277014996411512\n",
      "Epoch: 11, Loss (standarized): 0.9820802503094896\n",
      "          Validation Loss (standardized): 0.9544226960614114\n",
      "Epoch: 16, Loss (standarized): 0.9479998690334742\n",
      "          Validation Loss (standardized): 0.8634725940980121\n",
      "Epoch: 21, Loss (standarized): 0.9170417544647588\n",
      "          Validation Loss (standardized): 0.8724661770135126\n",
      "Epoch: 26, Loss (standarized): 0.8931343480392142\n",
      "          Validation Loss (standardized): 0.8288089605538025\n",
      "Epoch: 31, Loss (standarized): 0.869228661607584\n",
      "          Validation Loss (standardized): 0.790049395696843\n",
      "Epoch: 36, Loss (standarized): 0.8464024221892605\n",
      "          Validation Loss (standardized): 0.782157603464343\n",
      "Epoch: 41, Loss (standarized): 0.8267577784269851\n",
      "          Validation Loss (standardized): 0.7431076653687672\n",
      "Epoch: 46, Loss (standarized): 0.8123440377556687\n",
      "          Validation Loss (standardized): 0.7382552695577356\n",
      "Epoch: 51, Loss (standarized): 0.8013751837989685\n",
      "          Validation Loss (standardized): 0.7185316600830851\n",
      "Epoch: 56, Loss (standarized): 0.7920417944173558\n",
      "          Validation Loss (standardized): 0.7149041980456059\n",
      "Epoch: 61, Loss (standarized): 0.7829813098505143\n",
      "          Validation Loss (standardized): 0.7036647255753821\n",
      "Epoch: 66, Loss (standarized): 0.7741678852380299\n",
      "          Validation Loss (standardized): 0.6997660338315483\n",
      "Epoch: 71, Loss (standarized): 0.7656172429411738\n",
      "          Validation Loss (standardized): 0.6907519910998963\n",
      "Epoch: 76, Loss (standarized): 0.7569385859689698\n",
      "          Validation Loss (standardized): 0.6846801092220349\n",
      "Epoch: 81, Loss (standarized): 0.7481927534187502\n",
      "          Validation Loss (standardized): 0.6762994701798024\n",
      "Epoch: 86, Loss (standarized): 0.7396849735266665\n",
      "          Validation Loss (standardized): 0.6693485851695968\n",
      "Epoch: 91, Loss (standarized): 0.731793278512537\n",
      "          Validation Loss (standardized): 0.6606179535352038\n",
      "Epoch: 96, Loss (standarized): 0.7250040058975845\n",
      "          Validation Loss (standardized): 0.6557644546939018\n",
      "Final epoch: 100, Final loss (standarized): 0.7202949323941448\n",
      "Epoch: 1, Loss (standarized): 1.0826090179036487\n",
      "          Validation Loss (standardized): 0.9741040325174967\n",
      "Epoch: 6, Loss (standarized): 0.9822524987604204\n",
      "          Validation Loss (standardized): 0.8816912507602792\n",
      "Epoch: 11, Loss (standarized): 0.9516770080556138\n",
      "          Validation Loss (standardized): 0.938886454300762\n",
      "Epoch: 16, Loss (standarized): 0.9222557086743388\n",
      "          Validation Loss (standardized): 0.8511783074169591\n",
      "Epoch: 21, Loss (standarized): 0.9110653306371119\n",
      "          Validation Loss (standardized): 0.8466792611476017\n",
      "Epoch: 26, Loss (standarized): 0.9003289340705234\n",
      "          Validation Loss (standardized): 0.8549134050393816\n",
      "Epoch: 31, Loss (standarized): 0.8880428259491117\n",
      "          Validation Loss (standardized): 0.8145186696148683\n",
      "Epoch: 36, Loss (standarized): 0.8769880638518337\n",
      "          Validation Loss (standardized): 0.8210031153893823\n",
      "Epoch: 41, Loss (standarized): 0.8681344852590017\n",
      "          Validation Loss (standardized): 0.8036807176300164\n",
      "Epoch: 46, Loss (standarized): 0.8600779592557531\n",
      "          Validation Loss (standardized): 0.7928275381379882\n",
      "Epoch: 51, Loss (standarized): 0.8520661079904247\n",
      "          Validation Loss (standardized): 0.7891970914316606\n",
      "Epoch: 56, Loss (standarized): 0.8444760561189385\n",
      "          Validation Loss (standardized): 0.7757035759967061\n",
      "Epoch: 61, Loss (standarized): 0.8368952867163522\n",
      "          Validation Loss (standardized): 0.7724433637770355\n",
      "Epoch: 66, Loss (standarized): 0.8294512523838797\n",
      "          Validation Loss (standardized): 0.7611473757841322\n",
      "Epoch: 71, Loss (standarized): 0.8219387236932697\n",
      "          Validation Loss (standardized): 0.7560279552551882\n",
      "Epoch: 76, Loss (standarized): 0.8145538968273935\n",
      "          Validation Loss (standardized): 0.7469439711360263\n",
      "Epoch: 81, Loss (standarized): 0.8072834606957479\n",
      "          Validation Loss (standardized): 0.7402497973019067\n",
      "Epoch: 86, Loss (standarized): 0.8004352766294979\n",
      "          Validation Loss (standardized): 0.7337711076861889\n",
      "Epoch: 91, Loss (standarized): 0.794166943584583\n",
      "          Validation Loss (standardized): 0.7267784262077602\n",
      "Epoch: 96, Loss (standarized): 0.7885793504851328\n",
      "          Validation Loss (standardized): 0.7218230022125408\n",
      "Final epoch: 100, Final loss (standarized): 0.7845518515091104\n",
      "Epoch: 1, Loss (standarized): 1.333374607373091\n",
      "          Validation Loss (standardized): 1.2003560331316285\n",
      "Epoch: 6, Loss (standarized): 1.043905803010441\n",
      "          Validation Loss (standardized): 0.9193112231561448\n",
      "Epoch: 11, Loss (standarized): 0.9791195771154166\n",
      "          Validation Loss (standardized): 0.9003433257657708\n",
      "Epoch: 16, Loss (standarized): 0.9767778100021707\n",
      "          Validation Loss (standardized): 0.9842708666776362\n",
      "Epoch: 21, Loss (standarized): 0.9403160717340622\n",
      "          Validation Loss (standardized): 0.8887353578740678\n",
      "Epoch: 26, Loss (standarized): 0.9308139189683284\n",
      "          Validation Loss (standardized): 0.8423181068815417\n",
      "Epoch: 31, Loss (standarized): 0.9054160092417586\n",
      "          Validation Loss (standardized): 0.8463148049702005\n",
      "Epoch: 36, Loss (standarized): 0.8922917635055694\n",
      "          Validation Loss (standardized): 0.84814859896431\n",
      "Epoch: 41, Loss (standarized): 0.8696345028715886\n",
      "          Validation Loss (standardized): 0.7982258798547569\n",
      "Epoch: 46, Loss (standarized): 0.8527329801676498\n",
      "          Validation Loss (standardized): 0.7758742345546711\n",
      "Epoch: 51, Loss (standarized): 0.8351049462683842\n",
      "          Validation Loss (standardized): 0.7712861350559976\n",
      "Epoch: 56, Loss (standarized): 0.8188959859493812\n",
      "          Validation Loss (standardized): 0.7446872835416433\n",
      "Epoch: 61, Loss (standarized): 0.8050827330319056\n",
      "          Validation Loss (standardized): 0.7268867348225245\n",
      "Epoch: 66, Loss (standarized): 0.7930427047555911\n",
      "          Validation Loss (standardized): 0.720754819290149\n",
      "Epoch: 71, Loss (standarized): 0.7822538864746067\n",
      "          Validation Loss (standardized): 0.7064341388559324\n",
      "Epoch: 76, Loss (standarized): 0.7725807455148876\n",
      "          Validation Loss (standardized): 0.6972229127077211\n",
      "Epoch: 81, Loss (standarized): 0.7637530148751839\n",
      "          Validation Loss (standardized): 0.6912581548162501\n",
      "Epoch: 86, Loss (standarized): 0.7555654050619716\n",
      "          Validation Loss (standardized): 0.6834159343043402\n",
      "Epoch: 91, Loss (standarized): 0.7479679314721814\n",
      "          Validation Loss (standardized): 0.6775387008144623\n",
      "Epoch: 96, Loss (standarized): 0.7408781473148738\n",
      "          Validation Loss (standardized): 0.6717522032455537\n",
      "Final epoch: 100, Final loss (standarized): 0.7355827913926968\n",
      "Epoch: 1, Loss (standarized): 1.0296374127879673\n",
      "          Validation Loss (standardized): 0.947404805299804\n",
      "Epoch: 6, Loss (standarized): 0.9890643622340622\n",
      "          Validation Loss (standardized): 0.9630068127755115\n",
      "Epoch: 11, Loss (standarized): 0.954106416367664\n",
      "          Validation Loss (standardized): 0.8814418163525527\n",
      "Epoch: 16, Loss (standarized): 0.9232715049894032\n",
      "          Validation Loss (standardized): 0.8732545909452598\n",
      "Epoch: 21, Loss (standarized): 0.8942617139539634\n",
      "          Validation Loss (standardized): 0.8206362421982805\n",
      "Epoch: 26, Loss (standarized): 0.8673627874304343\n",
      "          Validation Loss (standardized): 0.7993742064319025\n",
      "Epoch: 31, Loss (standarized): 0.8439537338383699\n",
      "          Validation Loss (standardized): 0.7670283526311751\n",
      "Epoch: 36, Loss (standarized): 0.8264084143013527\n",
      "          Validation Loss (standardized): 0.743877218912931\n",
      "Epoch: 41, Loss (standarized): 0.8142488700586357\n",
      "          Validation Loss (standardized): 0.7355606559256143\n",
      "Epoch: 46, Loss (standarized): 0.8041498890273846\n",
      "          Validation Loss (standardized): 0.7199892567534915\n",
      "Epoch: 51, Loss (standarized): 0.7942501375926858\n",
      "          Validation Loss (standardized): 0.7141893607005357\n",
      "Epoch: 56, Loss (standarized): 0.7849137081296249\n",
      "          Validation Loss (standardized): 0.7087862508635903\n",
      "Epoch: 61, Loss (standarized): 0.7760020521861024\n",
      "          Validation Loss (standardized): 0.7001542346701186\n",
      "Epoch: 66, Loss (standarized): 0.7667317237809913\n",
      "          Validation Loss (standardized): 0.6924636999966145\n",
      "Epoch: 71, Loss (standarized): 0.7571169015297724\n",
      "          Validation Loss (standardized): 0.6837321742997361\n",
      "Epoch: 76, Loss (standarized): 0.7479049277323032\n",
      "          Validation Loss (standardized): 0.6744530504453291\n",
      "Epoch: 81, Loss (standarized): 0.7395499545682338\n",
      "          Validation Loss (standardized): 0.6669920113454331\n",
      "Epoch: 86, Loss (standarized): 0.7321479543646008\n",
      "          Validation Loss (standardized): 0.6608528583848259\n",
      "Epoch: 91, Loss (standarized): 0.7257934439553769\n",
      "          Validation Loss (standardized): 0.6550947905955323\n",
      "Epoch: 96, Loss (standarized): 0.7202749944396516\n",
      "          Validation Loss (standardized): 0.6506739136771954\n",
      "Final epoch: 100, Final loss (standarized): 0.7164904042934367\n",
      "Epoch: 1, Loss (standarized): 1.4014357271386226\n",
      "          Validation Loss (standardized): 0.9934856005304394\n",
      "Epoch: 6, Loss (standarized): 1.0736959252976515\n",
      "          Validation Loss (standardized): 1.1567782524350514\n",
      "Epoch: 11, Loss (standarized): 0.9892038871480118\n",
      "          Validation Loss (standardized): 0.9392672475269904\n",
      "Epoch: 16, Loss (standarized): 0.9852547313293748\n",
      "          Validation Loss (standardized): 0.8756383566107173\n",
      "Epoch: 21, Loss (standarized): 0.9361819640787715\n",
      "          Validation Loss (standardized): 0.8723775480917589\n",
      "Epoch: 26, Loss (standarized): 0.9223646646379674\n",
      "          Validation Loss (standardized): 0.8968535176109126\n",
      "Epoch: 31, Loss (standarized): 0.8882655328951611\n",
      "          Validation Loss (standardized): 0.8211798249442807\n",
      "Epoch: 36, Loss (standarized): 0.8698781832061631\n",
      "          Validation Loss (standardized): 0.7810880756882771\n",
      "Epoch: 41, Loss (standarized): 0.8433195325439515\n",
      "          Validation Loss (standardized): 0.7772535442855597\n",
      "Epoch: 46, Loss (standarized): 0.8258851646868678\n",
      "          Validation Loss (standardized): 0.7556045294630455\n",
      "Epoch: 51, Loss (standarized): 0.8099352659141053\n",
      "          Validation Loss (standardized): 0.7222766421168919\n",
      "Epoch: 56, Loss (standarized): 0.7981033997938644\n",
      "          Validation Loss (standardized): 0.7161970367800727\n",
      "Epoch: 61, Loss (standarized): 0.7890089154608291\n",
      "          Validation Loss (standardized): 0.7104835885387791\n",
      "Epoch: 66, Loss (standarized): 0.7794651815455689\n",
      "          Validation Loss (standardized): 0.6945478198008889\n",
      "Epoch: 71, Loss (standarized): 0.7695657463672407\n",
      "          Validation Loss (standardized): 0.689693750972601\n",
      "Epoch: 76, Loss (standarized): 0.7596454851764662\n",
      "          Validation Loss (standardized): 0.6839495369758845\n",
      "Epoch: 81, Loss (standarized): 0.7499785676112106\n",
      "          Validation Loss (standardized): 0.6734576039055422\n",
      "Epoch: 86, Loss (standarized): 0.7409265207098985\n",
      "          Validation Loss (standardized): 0.6685420812017644\n",
      "Epoch: 91, Loss (standarized): 0.7322844440988063\n",
      "          Validation Loss (standardized): 0.6619182394876215\n",
      "Epoch: 96, Loss (standarized): 0.7238618290526225\n",
      "          Validation Loss (standardized): 0.6533818591174848\n",
      "Final epoch: 100, Final loss (standarized): 0.7173671381296518\n",
      "Epoch: 1, Loss (standarized): 1.4216251586204436\n",
      "          Validation Loss (standardized): 0.9993143445409111\n",
      "Epoch: 6, Loss (standarized): 1.015108474522169\n",
      "          Validation Loss (standardized): 1.0893567471970023\n",
      "Epoch: 11, Loss (standarized): 1.0077866840765524\n",
      "          Validation Loss (standardized): 0.986649272577067\n",
      "Epoch: 16, Loss (standarized): 0.9578926405784834\n",
      "          Validation Loss (standardized): 0.8736581147105573\n",
      "Epoch: 21, Loss (standarized): 0.9592879301165652\n",
      "          Validation Loss (standardized): 0.8611912564994759\n",
      "Epoch: 26, Loss (standarized): 0.9270376343899926\n",
      "          Validation Loss (standardized): 0.8921841475622846\n",
      "Epoch: 31, Loss (standarized): 0.9239330472460463\n",
      "          Validation Loss (standardized): 0.8889348389291937\n",
      "Epoch: 36, Loss (standarized): 0.9071049571718612\n",
      "          Validation Loss (standardized): 0.8392662957659394\n",
      "Epoch: 41, Loss (standarized): 0.9011385716728068\n",
      "          Validation Loss (standardized): 0.8261540704707722\n",
      "Epoch: 46, Loss (standarized): 0.8890610091428733\n",
      "          Validation Loss (standardized): 0.8364017240365009\n",
      "Epoch: 51, Loss (standarized): 0.8810449127095238\n",
      "          Validation Loss (standardized): 0.8235763671529108\n",
      "Epoch: 56, Loss (standarized): 0.8727809719276222\n",
      "          Validation Loss (standardized): 0.8017144028932338\n",
      "Epoch: 61, Loss (standarized): 0.8643485675175807\n",
      "          Validation Loss (standardized): 0.7994644138757977\n",
      "Epoch: 66, Loss (standarized): 0.8566283657652335\n",
      "          Validation Loss (standardized): 0.7949855366108881\n",
      "Epoch: 71, Loss (standarized): 0.8489409119509777\n",
      "          Validation Loss (standardized): 0.7797107079537875\n",
      "Epoch: 76, Loss (standarized): 0.8414469778537945\n",
      "          Validation Loss (standardized): 0.7744974837989673\n",
      "Epoch: 81, Loss (standarized): 0.8340881300239076\n",
      "          Validation Loss (standardized): 0.7686267274964945\n",
      "Epoch: 86, Loss (standarized): 0.8269144225092127\n",
      "          Validation Loss (standardized): 0.7580661714902044\n",
      "Epoch: 91, Loss (standarized): 0.8197855843926728\n",
      "          Validation Loss (standardized): 0.7531136663796666\n",
      "Epoch: 96, Loss (standarized): 0.8128230325854318\n",
      "          Validation Loss (standardized): 0.7456447480943159\n",
      "Final epoch: 100, Final loss (standarized): 0.8073724785538762\n",
      "Epoch: 1, Loss (standarized): 1.0897776931682237\n",
      "          Validation Loss (standardized): 0.9366696889757131\n",
      "Epoch: 6, Loss (standarized): 1.0152041068074191\n",
      "          Validation Loss (standardized): 0.9948775369076779\n",
      "Epoch: 11, Loss (standarized): 0.9852656667803412\n",
      "          Validation Loss (standardized): 0.9025477097103507\n",
      "Epoch: 16, Loss (standarized): 0.9578498107501474\n",
      "          Validation Loss (standardized): 0.9204531411085516\n",
      "Epoch: 21, Loss (standarized): 0.9439255988332758\n",
      "          Validation Loss (standardized): 0.9004774135743034\n",
      "Epoch: 26, Loss (standarized): 0.9219793151948895\n",
      "          Validation Loss (standardized): 0.8455539801443266\n",
      "Epoch: 31, Loss (standarized): 0.8963311115817898\n",
      "          Validation Loss (standardized): 0.8387587262692543\n",
      "Epoch: 36, Loss (standarized): 0.8725634248685296\n",
      "          Validation Loss (standardized): 0.800640221547161\n",
      "Epoch: 41, Loss (standarized): 0.851234765748357\n",
      "          Validation Loss (standardized): 0.7677165333660787\n",
      "Epoch: 46, Loss (standarized): 0.8345852889672823\n",
      "          Validation Loss (standardized): 0.7565819911187672\n",
      "Epoch: 51, Loss (standarized): 0.8235469153248097\n",
      "          Validation Loss (standardized): 0.7341085163363468\n",
      "Epoch: 56, Loss (standarized): 0.8138161973849177\n",
      "          Validation Loss (standardized): 0.7315376490638837\n",
      "Epoch: 61, Loss (standarized): 0.802978857730874\n",
      "          Validation Loss (standardized): 0.7169629511098569\n",
      "Epoch: 66, Loss (standarized): 0.7917248542105089\n",
      "          Validation Loss (standardized): 0.7134107527623109\n",
      "Epoch: 71, Loss (standarized): 0.7808811015995685\n",
      "          Validation Loss (standardized): 0.7020694919401634\n",
      "Epoch: 76, Loss (standarized): 0.769603308361193\n",
      "          Validation Loss (standardized): 0.6950946197775028\n",
      "Epoch: 81, Loss (standarized): 0.7574845790734956\n",
      "          Validation Loss (standardized): 0.6823361012826643\n",
      "Epoch: 86, Loss (standarized): 0.745351645215725\n",
      "          Validation Loss (standardized): 0.6719525441189205\n",
      "Epoch: 91, Loss (standarized): 0.7341031827654773\n",
      "          Validation Loss (standardized): 0.6616744015027622\n",
      "Epoch: 96, Loss (standarized): 0.7239593187720172\n",
      "          Validation Loss (standardized): 0.6528921160721365\n",
      "Final epoch: 100, Final loss (standarized): 0.7166785532020992\n",
      "Epoch: 1, Loss (standarized): 1.025228005843383\n",
      "          Validation Loss (standardized): 0.9443656804900733\n",
      "Epoch: 6, Loss (standarized): 0.9724311704806304\n",
      "          Validation Loss (standardized): 0.9253275913077406\n",
      "Epoch: 11, Loss (standarized): 0.9166892925329291\n",
      "          Validation Loss (standardized): 0.8481855536155778\n",
      "Epoch: 16, Loss (standarized): 0.8752770121914697\n",
      "          Validation Loss (standardized): 0.8012856734211337\n",
      "Epoch: 21, Loss (standarized): 0.8467288914979288\n",
      "          Validation Loss (standardized): 0.7738516305783902\n",
      "Epoch: 26, Loss (standarized): 0.8324032515765406\n",
      "          Validation Loss (standardized): 0.74174173351208\n",
      "Epoch: 31, Loss (standarized): 0.8281871507311456\n",
      "          Validation Loss (standardized): 0.7460882550699072\n",
      "Epoch: 36, Loss (standarized): 0.8239304894329724\n",
      "          Validation Loss (standardized): 0.7308070914038219\n",
      "Epoch: 41, Loss (standarized): 0.8153707550909169\n",
      "          Validation Loss (standardized): 0.7276450199262833\n",
      "Epoch: 46, Loss (standarized): 0.8064783673767062\n",
      "          Validation Loss (standardized): 0.7258777562055063\n",
      "Epoch: 51, Loss (standarized): 0.7991113354622988\n",
      "          Validation Loss (standardized): 0.7174074706813346\n",
      "Epoch: 56, Loss (standarized): 0.7915193614181316\n",
      "          Validation Loss (standardized): 0.7139462324594521\n",
      "Epoch: 61, Loss (standarized): 0.7825561530340248\n",
      "          Validation Loss (standardized): 0.7059064914622888\n",
      "Epoch: 66, Loss (standarized): 0.7727242907188163\n",
      "          Validation Loss (standardized): 0.6941561163863287\n",
      "Epoch: 71, Loss (standarized): 0.762607910173074\n",
      "          Validation Loss (standardized): 0.6853925585419143\n",
      "Epoch: 76, Loss (standarized): 0.7521941348715251\n",
      "          Validation Loss (standardized): 0.6769263256784529\n",
      "Epoch: 81, Loss (standarized): 0.7414522499165901\n",
      "          Validation Loss (standardized): 0.6674204355336214\n",
      "Epoch: 86, Loss (standarized): 0.7306179735889218\n",
      "          Validation Loss (standardized): 0.6586354379875127\n",
      "Epoch: 91, Loss (standarized): 0.719685447234671\n",
      "          Validation Loss (standardized): 0.6499907284915615\n",
      "Epoch: 96, Loss (standarized): 0.7085027058315502\n",
      "          Validation Loss (standardized): 0.640454746164082\n",
      "Final epoch: 100, Final loss (standarized): 0.6992319799823206\n",
      "Epoch: 1, Loss (standarized): 1.0869221561754447\n",
      "          Validation Loss (standardized): 0.943260431859803\n",
      "Epoch: 6, Loss (standarized): 1.007780940849149\n",
      "          Validation Loss (standardized): 0.9724604893864743\n",
      "Epoch: 11, Loss (standarized): 0.9831273233750817\n",
      "          Validation Loss (standardized): 0.8970001963045536\n",
      "Epoch: 16, Loss (standarized): 0.9505516271290777\n",
      "          Validation Loss (standardized): 0.9243356111885457\n",
      "Epoch: 21, Loss (standarized): 0.926776489700158\n",
      "          Validation Loss (standardized): 0.8689450856877826\n",
      "Epoch: 26, Loss (standarized): 0.9026996035204574\n",
      "          Validation Loss (standardized): 0.8272583360807572\n",
      "Epoch: 31, Loss (standarized): 0.872431134387164\n",
      "          Validation Loss (standardized): 0.8157070598110476\n",
      "Epoch: 36, Loss (standarized): 0.8422073020110981\n",
      "          Validation Loss (standardized): 0.7598169979374433\n",
      "Epoch: 41, Loss (standarized): 0.8178224735287009\n",
      "          Validation Loss (standardized): 0.7404054358747197\n",
      "Epoch: 46, Loss (standarized): 0.8019429637411823\n",
      "          Validation Loss (standardized): 0.7177080590658158\n",
      "Epoch: 51, Loss (standarized): 0.7916619462256044\n",
      "          Validation Loss (standardized): 0.706614792446044\n",
      "Epoch: 56, Loss (standarized): 0.7807933660767218\n",
      "          Validation Loss (standardized): 0.6981807309095857\n",
      "Epoch: 61, Loss (standarized): 0.7682639604364168\n",
      "          Validation Loss (standardized): 0.686719933411354\n",
      "Epoch: 66, Loss (standarized): 0.7560816151947625\n",
      "          Validation Loss (standardized): 0.6802183609193854\n",
      "Epoch: 71, Loss (standarized): 0.7446137882689579\n",
      "          Validation Loss (standardized): 0.6692299908862266\n",
      "Epoch: 76, Loss (standarized): 0.7335306592611872\n",
      "          Validation Loss (standardized): 0.661948294833739\n",
      "Epoch: 81, Loss (standarized): 0.7229984177608058\n",
      "          Validation Loss (standardized): 0.651139870678694\n",
      "Epoch: 86, Loss (standarized): 0.713071466700875\n",
      "          Validation Loss (standardized): 0.6440619846177362\n",
      "Epoch: 91, Loss (standarized): 0.7033787520080212\n",
      "          Validation Loss (standardized): 0.6351747433064591\n",
      "Epoch: 96, Loss (standarized): 0.6937536420366051\n",
      "          Validation Loss (standardized): 0.6281960209096827\n",
      "Final epoch: 100, Final loss (standarized): 0.6857277436116717\n",
      "Epoch: 1, Loss (standarized): 1.0358526569818847\n",
      "          Validation Loss (standardized): 0.9491604494956626\n",
      "Epoch: 6, Loss (standarized): 0.9865153719084233\n",
      "          Validation Loss (standardized): 0.9674864703329754\n",
      "Epoch: 11, Loss (standarized): 0.9537343110526187\n",
      "          Validation Loss (standardized): 0.8800697911857469\n",
      "Epoch: 16, Loss (standarized): 0.9258260802078901\n",
      "          Validation Loss (standardized): 0.8829298184500735\n",
      "Epoch: 21, Loss (standarized): 0.9003448002216597\n",
      "          Validation Loss (standardized): 0.8270170450979486\n",
      "Epoch: 26, Loss (standarized): 0.8775417798305002\n",
      "          Validation Loss (standardized): 0.8189500169715123\n",
      "Epoch: 31, Loss (standarized): 0.857058566350894\n",
      "          Validation Loss (standardized): 0.781776585795276\n",
      "Epoch: 36, Loss (standarized): 0.8405978830211829\n",
      "          Validation Loss (standardized): 0.7700005625653603\n",
      "Epoch: 41, Loss (standarized): 0.8280650582198206\n",
      "          Validation Loss (standardized): 0.7553071290085146\n",
      "Epoch: 46, Loss (standarized): 0.819400047273356\n",
      "          Validation Loss (standardized): 0.7435916389726777\n",
      "Epoch: 51, Loss (standarized): 0.813430009614051\n",
      "          Validation Loss (standardized): 0.74313571355577\n",
      "Epoch: 56, Loss (standarized): 0.8086600122259302\n",
      "          Validation Loss (standardized): 0.7370205221884245\n",
      "Epoch: 61, Loss (standarized): 0.8041919103837396\n",
      "          Validation Loss (standardized): 0.7321953300141257\n",
      "Epoch: 66, Loss (standarized): 0.7992201074740358\n",
      "          Validation Loss (standardized): 0.7293932426100369\n",
      "Epoch: 71, Loss (standarized): 0.7935837967792214\n",
      "          Validation Loss (standardized): 0.7238661840398609\n",
      "Epoch: 76, Loss (standarized): 0.7878890403767516\n",
      "          Validation Loss (standardized): 0.7172384391148477\n",
      "Epoch: 81, Loss (standarized): 0.7825815837248952\n",
      "          Validation Loss (standardized): 0.712144467661867\n",
      "Epoch: 86, Loss (standarized): 0.7778072349410665\n",
      "          Validation Loss (standardized): 0.7083572622707678\n",
      "Epoch: 91, Loss (standarized): 0.7734116535374083\n",
      "          Validation Loss (standardized): 0.7048046204189515\n",
      "Epoch: 96, Loss (standarized): 0.769171125501018\n",
      "          Validation Loss (standardized): 0.701029148628281\n",
      "Final epoch: 100, Final loss (standarized): 0.7657875108673478\n",
      "Epoch: 1, Loss (standarized): 1.1694068896777492\n",
      "          Validation Loss (standardized): 1.0569322173325362\n",
      "Epoch: 6, Loss (standarized): 1.0278520577093808\n",
      "          Validation Loss (standardized): 0.8966197119433846\n",
      "Epoch: 11, Loss (standarized): 0.951728095614109\n",
      "          Validation Loss (standardized): 0.9476360511229638\n",
      "Epoch: 16, Loss (standarized): 0.9332984118072851\n",
      "          Validation Loss (standardized): 0.8871637798494387\n",
      "Epoch: 21, Loss (standarized): 0.9072879062234298\n",
      "          Validation Loss (standardized): 0.8168866513035472\n",
      "Epoch: 26, Loss (standarized): 0.8744214267292968\n",
      "          Validation Loss (standardized): 0.8136013369054222\n",
      "Epoch: 31, Loss (standarized): 0.8543536827547941\n",
      "          Validation Loss (standardized): 0.7927636139764235\n",
      "Epoch: 36, Loss (standarized): 0.8319099245344466\n",
      "          Validation Loss (standardized): 0.7427113647399431\n",
      "Epoch: 41, Loss (standarized): 0.8158681492794099\n",
      "          Validation Loss (standardized): 0.7380715082348693\n",
      "Epoch: 46, Loss (standarized): 0.8069608302572415\n",
      "          Validation Loss (standardized): 0.726326735020793\n",
      "Epoch: 51, Loss (standarized): 0.7999840718869131\n",
      "          Validation Loss (standardized): 0.7101547539417412\n",
      "Epoch: 56, Loss (standarized): 0.7925476875416592\n",
      "          Validation Loss (standardized): 0.7129120555984138\n",
      "Epoch: 61, Loss (standarized): 0.7846840456584856\n",
      "          Validation Loss (standardized): 0.7010500422121221\n",
      "Epoch: 66, Loss (standarized): 0.7772015865990771\n",
      "          Validation Loss (standardized): 0.6977726003636096\n",
      "Epoch: 71, Loss (standarized): 0.770360443977132\n",
      "          Validation Loss (standardized): 0.6941618949872808\n",
      "Epoch: 76, Loss (standarized): 0.7636849715900575\n",
      "          Validation Loss (standardized): 0.6865067010352629\n",
      "Epoch: 81, Loss (standarized): 0.7569360484048604\n",
      "          Validation Loss (standardized): 0.6833036809487705\n",
      "Epoch: 86, Loss (standarized): 0.750132846815869\n",
      "          Validation Loss (standardized): 0.6750126912024362\n",
      "Epoch: 91, Loss (standarized): 0.7435755658916503\n",
      "          Validation Loss (standardized): 0.6704018482132426\n",
      "Epoch: 96, Loss (standarized): 0.7373960144623132\n",
      "          Validation Loss (standardized): 0.6641891272147334\n",
      "Final epoch: 100, Final loss (standarized): 0.7327216473709534\n",
      "Epoch: 1, Loss (standarized): 1.0903178661963224\n",
      "          Validation Loss (standardized): 1.000271033580204\n",
      "Epoch: 6, Loss (standarized): 0.9927426050080687\n",
      "          Validation Loss (standardized): 0.9267927210440852\n",
      "Epoch: 11, Loss (standarized): 0.9535120103225628\n",
      "          Validation Loss (standardized): 0.9007454005451275\n",
      "Epoch: 16, Loss (standarized): 0.9209834491715704\n",
      "          Validation Loss (standardized): 0.8655368411861272\n",
      "Epoch: 21, Loss (standarized): 0.8916110576193546\n",
      "          Validation Loss (standardized): 0.8093811981087465\n",
      "Epoch: 26, Loss (standarized): 0.8656889032081605\n",
      "          Validation Loss (standardized): 0.8038901341495941\n",
      "Epoch: 31, Loss (standarized): 0.8466407419271199\n",
      "          Validation Loss (standardized): 0.7575045585122905\n",
      "Epoch: 36, Loss (standarized): 0.8351914001040918\n",
      "          Validation Loss (standardized): 0.7586281180839591\n",
      "Epoch: 41, Loss (standarized): 0.829140465788275\n",
      "          Validation Loss (standardized): 0.7367327707024685\n",
      "Epoch: 46, Loss (standarized): 0.8234933183687783\n",
      "          Validation Loss (standardized): 0.7399092588247507\n",
      "Epoch: 51, Loss (standarized): 0.8158040670805896\n",
      "          Validation Loss (standardized): 0.7259972525840515\n",
      "Epoch: 56, Loss (standarized): 0.8071333531849161\n",
      "          Validation Loss (standardized): 0.7257226206331268\n",
      "Epoch: 61, Loss (standarized): 0.7989112640306391\n",
      "          Validation Loss (standardized): 0.7167971252914097\n",
      "Epoch: 66, Loss (standarized): 0.7909541151847869\n",
      "          Validation Loss (standardized): 0.7126504785997573\n",
      "Epoch: 71, Loss (standarized): 0.7824901488535397\n",
      "          Validation Loss (standardized): 0.7053284872035473\n",
      "Epoch: 76, Loss (standarized): 0.7733262568558652\n",
      "          Validation Loss (standardized): 0.6957210909216053\n",
      "Epoch: 81, Loss (standarized): 0.7637008199509345\n",
      "          Validation Loss (standardized): 0.6883511692606074\n",
      "Epoch: 86, Loss (standarized): 0.7537039705903785\n",
      "          Validation Loss (standardized): 0.6784675805908639\n",
      "Epoch: 91, Loss (standarized): 0.7432326111160095\n",
      "          Validation Loss (standardized): 0.6699552104776572\n",
      "Epoch: 96, Loss (standarized): 0.7322646479557628\n",
      "          Validation Loss (standardized): 0.6616975492638403\n",
      "Final epoch: 100, Final loss (standarized): 0.7231065141025284\n",
      "Epoch: 1, Loss (standarized): 2.412219205466239\n",
      "          Validation Loss (standardized): 1.6263693878018362\n",
      "Epoch: 6, Loss (standarized): 1.1228544374208334\n",
      "          Validation Loss (standardized): 0.9727135874942294\n",
      "Epoch: 11, Loss (standarized): 1.0851898531367952\n",
      "          Validation Loss (standardized): 1.1656254064381173\n",
      "Epoch: 16, Loss (standarized): 1.1107241319650119\n",
      "          Validation Loss (standardized): 1.1483140201094497\n",
      "Epoch: 21, Loss (standarized): 1.0252315756936425\n",
      "          Validation Loss (standardized): 0.9977438919868888\n",
      "Epoch: 26, Loss (standarized): 1.018806330339594\n",
      "          Validation Loss (standardized): 0.9449998877629028\n",
      "Epoch: 31, Loss (standarized): 1.024063424809301\n",
      "          Validation Loss (standardized): 0.9417409794550673\n",
      "Epoch: 36, Loss (standarized): 1.0060847442224983\n",
      "          Validation Loss (standardized): 0.9596442414616141\n",
      "Epoch: 41, Loss (standarized): 1.0038931353078344\n",
      "          Validation Loss (standardized): 0.9783631322993119\n",
      "Epoch: 46, Loss (standarized): 1.0010350166922237\n",
      "          Validation Loss (standardized): 0.9654915382988369\n",
      "Epoch: 51, Loss (standarized): 0.9997822605739064\n",
      "          Validation Loss (standardized): 0.9543289348760899\n",
      "Epoch: 56, Loss (standarized): 0.9996437580187705\n",
      "          Validation Loss (standardized): 0.9555931133297105\n",
      "Epoch: 61, Loss (standarized): 0.9994313747201172\n",
      "          Validation Loss (standardized): 0.9567859845511707\n",
      "Epoch: 66, Loss (standarized): 0.9995348550821708\n",
      "          Validation Loss (standardized): 0.9572737093940207\n",
      "Epoch: 71, Loss (standarized): 0.999515969818836\n",
      "          Validation Loss (standardized): 0.9597266456930227\n",
      "Epoch: 76, Loss (standarized): 0.9996315861825273\n",
      "          Validation Loss (standardized): 0.9608234655187669\n",
      "Epoch: 81, Loss (standarized): 0.999781533401191\n",
      "          Validation Loss (standardized): 0.9606377320112861\n",
      "Epoch: 86, Loss (standarized): 0.9998956592419657\n",
      "          Validation Loss (standardized): 0.9603560869153411\n",
      "Epoch: 91, Loss (standarized): 1.0000304096319301\n",
      "          Validation Loss (standardized): 0.9606008184556639\n",
      "Epoch: 96, Loss (standarized): 1.000022790273364\n",
      "          Validation Loss (standardized): 0.9616014884340517\n",
      "Final epoch: 100, Final loss (standarized): 0.9999997834413762\n",
      "Epoch: 1, Loss (standarized): 1.3582197003779097\n",
      "          Validation Loss (standardized): 1.0131477189300913\n",
      "Epoch: 6, Loss (standarized): 1.0073481178878128\n",
      "          Validation Loss (standardized): 1.0230607601981574\n",
      "Epoch: 11, Loss (standarized): 1.0439588958175123\n",
      "          Validation Loss (standardized): 1.0568860449014439\n",
      "Epoch: 16, Loss (standarized): 1.0005211600961639\n",
      "          Validation Loss (standardized): 0.9572875079226821\n",
      "Epoch: 21, Loss (standarized): 1.0083583181286389\n",
      "          Validation Loss (standardized): 0.9354827148083628\n",
      "Epoch: 26, Loss (standarized): 1.0010774700161318\n",
      "          Validation Loss (standardized): 0.951056401505594\n",
      "Epoch: 31, Loss (standarized): 1.0001464012423837\n",
      "          Validation Loss (standardized): 0.9746873096412025\n",
      "Epoch: 36, Loss (standarized): 0.999766465510503\n",
      "          Validation Loss (standardized): 0.9639400951194194\n",
      "Epoch: 41, Loss (standarized): 0.9999746604068299\n",
      "          Validation Loss (standardized): 0.9526254952347486\n",
      "Epoch: 46, Loss (standarized): 0.9998904246029682\n",
      "          Validation Loss (standardized): 0.9583933074030807\n",
      "Epoch: 51, Loss (standarized): 1.0000749159385647\n",
      "          Validation Loss (standardized): 0.9644224829586996\n",
      "Epoch: 56, Loss (standarized): 0.9999953299230093\n",
      "          Validation Loss (standardized): 0.9601129975422333\n",
      "Epoch: 61, Loss (standarized): 1.000092092776076\n",
      "          Validation Loss (standardized): 0.9578385581274896\n",
      "Epoch: 66, Loss (standarized): 1.0000098567939442\n",
      "          Validation Loss (standardized): 0.9599928068437849\n",
      "Epoch: 71, Loss (standarized): 0.9999851723315347\n",
      "          Validation Loss (standardized): 0.9611129406362093\n",
      "Epoch: 76, Loss (standarized): 1.0000138076416998\n",
      "          Validation Loss (standardized): 0.959428461889027\n",
      "Epoch: 81, Loss (standarized): 1.0000044757330173\n",
      "          Validation Loss (standardized): 0.9601980123925634\n",
      "Epoch: 86, Loss (standarized): 1.000001564984278\n",
      "          Validation Loss (standardized): 0.961423855002185\n",
      "Epoch: 91, Loss (standarized): 1.0000166954794192\n",
      "          Validation Loss (standardized): 0.9619477900975639\n",
      "Epoch: 96, Loss (standarized): 1.0000071570282596\n",
      "          Validation Loss (standardized): 0.9617035117721997\n",
      "Final epoch: 100, Final loss (standarized): 1.0000168555262745\n",
      "Epoch: 1, Loss (standarized): 1.0461595988265173\n",
      "          Validation Loss (standardized): 0.9875298916796852\n",
      "Epoch: 6, Loss (standarized): 1.0093381952083236\n",
      "          Validation Loss (standardized): 0.9743211224404925\n",
      "Epoch: 11, Loss (standarized): 1.0013803769909022\n",
      "          Validation Loss (standardized): 0.9606560410615521\n",
      "Epoch: 16, Loss (standarized): 0.9990022776411884\n",
      "          Validation Loss (standardized): 0.9541298957498909\n",
      "Epoch: 21, Loss (standarized): 0.9979932524875949\n",
      "          Validation Loss (standardized): 0.9624111493161849\n",
      "Epoch: 26, Loss (standarized): 0.9983863992405494\n",
      "          Validation Loss (standardized): 0.9532475470254029\n",
      "Epoch: 31, Loss (standarized): 0.9989623959246838\n",
      "          Validation Loss (standardized): 0.9617453180358477\n",
      "Epoch: 36, Loss (standarized): 0.9995688548710572\n",
      "          Validation Loss (standardized): 0.9556152942482709\n",
      "Epoch: 41, Loss (standarized): 0.9997986357006876\n",
      "          Validation Loss (standardized): 0.9591658766116221\n",
      "Epoch: 46, Loss (standarized): 0.9998807603956408\n",
      "          Validation Loss (standardized): 0.9580401899425027\n",
      "Epoch: 51, Loss (standarized): 1.000013698171158\n",
      "          Validation Loss (standardized): 0.9595261387289988\n",
      "Epoch: 56, Loss (standarized): 1.000002016437887\n",
      "          Validation Loss (standardized): 0.9601890578591596\n",
      "Epoch: 61, Loss (standarized): 1.000046689391691\n",
      "          Validation Loss (standardized): 0.9580555802460183\n",
      "Epoch: 66, Loss (standarized): 0.999997836614454\n",
      "          Validation Loss (standardized): 0.9600053806303405\n",
      "Epoch: 71, Loss (standarized): 1.0000961507412822\n",
      "          Validation Loss (standardized): 0.957895328051909\n",
      "Epoch: 76, Loss (standarized): 1.000090097724631\n",
      "          Validation Loss (standardized): 0.957359474116206\n",
      "Epoch: 81, Loss (standarized): 1.000016640229261\n",
      "          Validation Loss (standardized): 0.9604233729920187\n",
      "Epoch: 86, Loss (standarized): 1.000009492634784\n",
      "          Validation Loss (standardized): 0.9606021541761223\n",
      "Epoch: 91, Loss (standarized): 1.0000031692384477\n",
      "          Validation Loss (standardized): 0.9621159485100301\n",
      "Epoch: 96, Loss (standarized): 1.0000003482312805\n",
      "          Validation Loss (standardized): 0.960815070290422\n",
      "Final epoch: 100, Final loss (standarized): 1.000001454547143\n",
      "Epoch: 1, Loss (standarized): 1.2938240350005343\n",
      "          Validation Loss (standardized): 0.9397957889822922\n",
      "Epoch: 6, Loss (standarized): 1.001762871559654\n",
      "          Validation Loss (standardized): 1.0466158346915961\n",
      "Epoch: 11, Loss (standarized): 0.986961619922047\n",
      "          Validation Loss (standardized): 0.9578973604100538\n",
      "Epoch: 16, Loss (standarized): 0.9870970244545083\n",
      "          Validation Loss (standardized): 0.9072781128365327\n",
      "Epoch: 21, Loss (standarized): 0.98716100576636\n",
      "          Validation Loss (standardized): 0.9202206324501802\n",
      "Epoch: 26, Loss (standarized): 0.9842281883915259\n",
      "          Validation Loss (standardized): 0.9604346450899822\n",
      "Epoch: 31, Loss (standarized): 0.9895844818774592\n",
      "          Validation Loss (standardized): 0.9539202781811521\n",
      "Epoch: 36, Loss (standarized): 0.9944919118444375\n",
      "          Validation Loss (standardized): 0.9433631439219187\n",
      "Epoch: 41, Loss (standarized): 0.9964871221435201\n",
      "          Validation Loss (standardized): 0.9556775066233689\n",
      "Epoch: 46, Loss (standarized): 0.9985233345578404\n",
      "          Validation Loss (standardized): 0.9658062725194065\n",
      "Epoch: 51, Loss (standarized): 0.9992797582175139\n",
      "          Validation Loss (standardized): 0.9621389647084285\n",
      "Epoch: 56, Loss (standarized): 0.999807151209198\n",
      "          Validation Loss (standardized): 0.964438013764293\n",
      "Epoch: 61, Loss (standarized): 1.0001199447866538\n",
      "          Validation Loss (standardized): 0.9646026620592076\n",
      "Epoch: 66, Loss (standarized): 1.0000298602076936\n",
      "          Validation Loss (standardized): 0.9619450284524794\n",
      "Epoch: 71, Loss (standarized): 0.9999883087442049\n",
      "          Validation Loss (standardized): 0.9607251798101111\n",
      "Epoch: 76, Loss (standarized): 1.0000097926848461\n",
      "          Validation Loss (standardized): 0.9625589362562208\n",
      "Epoch: 81, Loss (standarized): 1.000055361892904\n",
      "          Validation Loss (standardized): 0.9628086936908509\n",
      "Epoch: 86, Loss (standarized): 1.0000126589318281\n",
      "          Validation Loss (standardized): 0.9618653761416007\n",
      "Epoch: 91, Loss (standarized): 1.0000003533550892\n",
      "          Validation Loss (standardized): 0.9609070399650134\n",
      "Epoch: 96, Loss (standarized): 1.000017166013555\n",
      "          Validation Loss (standardized): 0.962266843181228\n",
      "Final epoch: 100, Final loss (standarized): 1.000029904610047\n",
      "Epoch: 1, Loss (standarized): 1.2199402190416682\n",
      "          Validation Loss (standardized): 1.0951049879124386\n",
      "Epoch: 6, Loss (standarized): 1.0597916208139166\n",
      "          Validation Loss (standardized): 0.9220753161781465\n",
      "Epoch: 11, Loss (standarized): 0.9768709044997859\n",
      "          Validation Loss (standardized): 0.9785762502658892\n",
      "Epoch: 16, Loss (standarized): 0.9676547116116632\n",
      "          Validation Loss (standardized): 0.9298976742702212\n",
      "Epoch: 21, Loss (standarized): 0.9484405605434081\n",
      "          Validation Loss (standardized): 0.8636539255941535\n",
      "Epoch: 26, Loss (standarized): 0.9241014359220001\n",
      "          Validation Loss (standardized): 0.8715498639033947\n",
      "Epoch: 31, Loss (standarized): 0.9115060094599062\n",
      "          Validation Loss (standardized): 0.865936110789668\n",
      "Epoch: 36, Loss (standarized): 0.8909420204901014\n",
      "          Validation Loss (standardized): 0.8146488326965422\n",
      "Epoch: 41, Loss (standarized): 0.8722092797421865\n",
      "          Validation Loss (standardized): 0.8050682983850501\n",
      "Epoch: 46, Loss (standarized): 0.8551344027565981\n",
      "          Validation Loss (standardized): 0.7896376200160233\n",
      "Epoch: 51, Loss (standarized): 0.8381279589586889\n",
      "          Validation Loss (standardized): 0.7579861896877731\n",
      "Epoch: 56, Loss (standarized): 0.8227335251485659\n",
      "          Validation Loss (standardized): 0.7494369770787047\n",
      "Epoch: 61, Loss (standarized): 0.8093219589280384\n",
      "          Validation Loss (standardized): 0.7315467367074652\n",
      "Epoch: 66, Loss (standarized): 0.7972219921414527\n",
      "          Validation Loss (standardized): 0.7177538544661778\n",
      "Epoch: 71, Loss (standarized): 0.7859126047238998\n",
      "          Validation Loss (standardized): 0.7102533994870299\n",
      "Epoch: 76, Loss (standarized): 0.7753412454234431\n",
      "          Validation Loss (standardized): 0.6982337469218755\n",
      "Epoch: 81, Loss (standarized): 0.7653819074591984\n",
      "          Validation Loss (standardized): 0.6913347361333864\n",
      "Epoch: 86, Loss (standarized): 0.7561056254209882\n",
      "          Validation Loss (standardized): 0.6827631507664512\n",
      "Epoch: 91, Loss (standarized): 0.7473657732333507\n",
      "          Validation Loss (standardized): 0.6758513052554289\n",
      "Epoch: 96, Loss (standarized): 0.7391096303541278\n",
      "          Validation Loss (standardized): 0.6687041696935324\n",
      "Final epoch: 100, Final loss (standarized): 0.7328495994603611\n",
      "Epoch: 1, Loss (standarized): 1.036832417429702\n",
      "          Validation Loss (standardized): 0.9447109420894689\n",
      "Epoch: 6, Loss (standarized): 0.981227697622006\n",
      "          Validation Loss (standardized): 0.9672175980879169\n",
      "Epoch: 11, Loss (standarized): 0.9526363648833615\n",
      "          Validation Loss (standardized): 0.8821143303561415\n",
      "Epoch: 16, Loss (standarized): 0.9289565397748586\n",
      "          Validation Loss (standardized): 0.8881668687464412\n",
      "Epoch: 21, Loss (standarized): 0.9083911950770286\n",
      "          Validation Loss (standardized): 0.8418415256941572\n",
      "Epoch: 26, Loss (standarized): 0.8905561702355588\n",
      "          Validation Loss (standardized): 0.8354535010790058\n",
      "Epoch: 31, Loss (standarized): 0.8747832409265965\n",
      "          Validation Loss (standardized): 0.8071456538248379\n",
      "Epoch: 36, Loss (standarized): 0.8611749395478189\n",
      "          Validation Loss (standardized): 0.7997010687254434\n",
      "Epoch: 41, Loss (standarized): 0.8495539455346381\n",
      "          Validation Loss (standardized): 0.780319612996387\n",
      "Epoch: 46, Loss (standarized): 0.8398063365313557\n",
      "          Validation Loss (standardized): 0.7765171766763228\n",
      "Epoch: 51, Loss (standarized): 0.831046681924575\n",
      "          Validation Loss (standardized): 0.7621969344669054\n",
      "Epoch: 56, Loss (standarized): 0.8231744955647426\n",
      "          Validation Loss (standardized): 0.7579174147033165\n",
      "Epoch: 61, Loss (standarized): 0.8152896355051293\n",
      "          Validation Loss (standardized): 0.7486179235243199\n",
      "Epoch: 66, Loss (standarized): 0.8073554012516787\n",
      "          Validation Loss (standardized): 0.7405525156417473\n",
      "Epoch: 71, Loss (standarized): 0.7990576949527206\n",
      "          Validation Loss (standardized): 0.7334917168354993\n",
      "Epoch: 76, Loss (standarized): 0.7908488998426776\n",
      "          Validation Loss (standardized): 0.7245847013365786\n",
      "Epoch: 81, Loss (standarized): 0.7830120469256286\n",
      "          Validation Loss (standardized): 0.7172195714505167\n",
      "Epoch: 86, Loss (standarized): 0.7756351935896287\n",
      "          Validation Loss (standardized): 0.7109932427659781\n",
      "Epoch: 91, Loss (standarized): 0.7686933600484712\n",
      "          Validation Loss (standardized): 0.7039119923250113\n",
      "Epoch: 96, Loss (standarized): 0.7625583192873602\n",
      "          Validation Loss (standardized): 0.6984105054774407\n",
      "Final epoch: 100, Final loss (standarized): 0.758359670320042\n",
      "Epoch: 1, Loss (standarized): 1.1771499681776494\n",
      "          Validation Loss (standardized): 0.9322427949692763\n",
      "Epoch: 6, Loss (standarized): 1.0446311645026094\n",
      "          Validation Loss (standardized): 1.0538491447100864\n",
      "Epoch: 11, Loss (standarized): 0.9777245431841974\n",
      "          Validation Loss (standardized): 0.9012747871890591\n",
      "Epoch: 16, Loss (standarized): 0.9663363935158642\n",
      "          Validation Loss (standardized): 0.8936672164119639\n",
      "Epoch: 21, Loss (standarized): 0.9488258366725596\n",
      "          Validation Loss (standardized): 0.9267541512082519\n",
      "Epoch: 26, Loss (standarized): 0.9249632835034747\n",
      "          Validation Loss (standardized): 0.8632524990487787\n",
      "Epoch: 31, Loss (standarized): 0.9113656900823841\n",
      "          Validation Loss (standardized): 0.8369410805118267\n",
      "Epoch: 36, Loss (standarized): 0.8906903288611845\n",
      "          Validation Loss (standardized): 0.8405683987541821\n",
      "Epoch: 41, Loss (standarized): 0.8716416695086456\n",
      "          Validation Loss (standardized): 0.8026990627230284\n",
      "Epoch: 46, Loss (standarized): 0.8546065583602058\n",
      "          Validation Loss (standardized): 0.7796510863820129\n",
      "Epoch: 51, Loss (standarized): 0.8371599125522222\n",
      "          Validation Loss (standardized): 0.7696123187430272\n",
      "Epoch: 56, Loss (standarized): 0.8218065209624801\n",
      "          Validation Loss (standardized): 0.7443731113296113\n",
      "Epoch: 61, Loss (standarized): 0.8080863688890343\n",
      "          Validation Loss (standardized): 0.7341406679411128\n",
      "Epoch: 66, Loss (standarized): 0.7959008713409836\n",
      "          Validation Loss (standardized): 0.7204492503072716\n",
      "Epoch: 71, Loss (standarized): 0.7846604910328725\n",
      "          Validation Loss (standardized): 0.7102099156935994\n",
      "Epoch: 76, Loss (standarized): 0.7739787466594586\n",
      "          Validation Loss (standardized): 0.7008873662510579\n",
      "Epoch: 81, Loss (standarized): 0.7637670082024199\n",
      "          Validation Loss (standardized): 0.6919715166400997\n",
      "Epoch: 86, Loss (standarized): 0.7539459976142066\n",
      "          Validation Loss (standardized): 0.6836600676425374\n",
      "Epoch: 91, Loss (standarized): 0.7446067666605682\n",
      "          Validation Loss (standardized): 0.6758456921674076\n",
      "Epoch: 96, Loss (standarized): 0.7358462697763176\n",
      "          Validation Loss (standardized): 0.6680611232758263\n",
      "Final epoch: 100, Final loss (standarized): 0.7292852714485896\n",
      "Epoch: 1, Loss (standarized): 1.2631217056623527\n",
      "          Validation Loss (standardized): 0.931088763125159\n",
      "Epoch: 6, Loss (standarized): 1.0440475470233894\n",
      "          Validation Loss (standardized): 1.0900771703696193\n",
      "Epoch: 11, Loss (standarized): 0.9547634083089711\n",
      "          Validation Loss (standardized): 0.8914805177831947\n",
      "Epoch: 16, Loss (standarized): 0.9641351727051886\n",
      "          Validation Loss (standardized): 0.8578318005794984\n",
      "Epoch: 21, Loss (standarized): 0.9201811175417663\n",
      "          Validation Loss (standardized): 0.883383356807712\n",
      "Epoch: 26, Loss (standarized): 0.9109160776947576\n",
      "          Validation Loss (standardized): 0.8690371328296161\n",
      "Epoch: 31, Loss (standarized): 0.8867877495393433\n",
      "          Validation Loss (standardized): 0.807099132256898\n",
      "Epoch: 36, Loss (standarized): 0.8694438607400905\n",
      "          Validation Loss (standardized): 0.7948873243762784\n",
      "Epoch: 41, Loss (standarized): 0.8530809974407043\n",
      "          Validation Loss (standardized): 0.7939207239036113\n",
      "Epoch: 46, Loss (standarized): 0.8363260637382683\n",
      "          Validation Loss (standardized): 0.7572982500562392\n",
      "Epoch: 51, Loss (standarized): 0.8237432846806673\n",
      "          Validation Loss (standardized): 0.7432174108884858\n",
      "Epoch: 56, Loss (standarized): 0.8121955685730253\n",
      "          Validation Loss (standardized): 0.7394541756920597\n",
      "Epoch: 61, Loss (standarized): 0.8018807592199616\n",
      "          Validation Loss (standardized): 0.7210431027854131\n",
      "Epoch: 66, Loss (standarized): 0.7927200074719042\n",
      "          Validation Loss (standardized): 0.7149330269901077\n",
      "Epoch: 71, Loss (standarized): 0.7840799757077818\n",
      "          Validation Loss (standardized): 0.7081724377369693\n",
      "Epoch: 76, Loss (standarized): 0.7756715584252507\n",
      "          Validation Loss (standardized): 0.6986291481850802\n",
      "Epoch: 81, Loss (standarized): 0.7675509866724892\n",
      "          Validation Loss (standardized): 0.6946299896405635\n",
      "Epoch: 86, Loss (standarized): 0.7595879100496165\n",
      "          Validation Loss (standardized): 0.6863617340589042\n",
      "Epoch: 91, Loss (standarized): 0.7517730270839663\n",
      "          Validation Loss (standardized): 0.6799986340039595\n",
      "Epoch: 96, Loss (standarized): 0.7442001936256268\n",
      "          Validation Loss (standardized): 0.6738317119577317\n",
      "Final epoch: 100, Final loss (standarized): 0.7383518183228688\n",
      "Epoch: 1, Loss (standarized): 1.0094919218189335\n",
      "          Validation Loss (standardized): 1.0382456903248076\n",
      "Epoch: 6, Loss (standarized): 0.9729780328845024\n",
      "          Validation Loss (standardized): 0.9045596759599072\n",
      "Epoch: 11, Loss (standarized): 0.9268401443123988\n",
      "          Validation Loss (standardized): 0.8662535755293248\n",
      "Epoch: 16, Loss (standarized): 0.8864333308933989\n",
      "          Validation Loss (standardized): 0.8185128205885822\n",
      "Epoch: 21, Loss (standarized): 0.8528278324099527\n",
      "          Validation Loss (standardized): 0.7738046065653603\n",
      "Epoch: 26, Loss (standarized): 0.830717128500714\n",
      "          Validation Loss (standardized): 0.7538556271468024\n",
      "Epoch: 31, Loss (standarized): 0.821429384861122\n",
      "          Validation Loss (standardized): 0.7296279020508881\n",
      "Epoch: 36, Loss (standarized): 0.8165619901268568\n",
      "          Validation Loss (standardized): 0.7324345570562047\n",
      "Epoch: 41, Loss (standarized): 0.8073997608829291\n",
      "          Validation Loss (standardized): 0.7183162123534794\n",
      "Epoch: 46, Loss (standarized): 0.7958856492377795\n",
      "          Validation Loss (standardized): 0.7122146390021744\n",
      "Epoch: 51, Loss (standarized): 0.7861764025320326\n",
      "          Validation Loss (standardized): 0.7098103765341764\n",
      "Epoch: 56, Loss (standarized): 0.7770879603071984\n",
      "          Validation Loss (standardized): 0.6992337199887487\n",
      "Epoch: 61, Loss (standarized): 0.7665839254177026\n",
      "          Validation Loss (standardized): 0.6903723152452274\n",
      "Epoch: 66, Loss (standarized): 0.7553147552027654\n",
      "          Validation Loss (standardized): 0.6806340452064441\n",
      "Epoch: 71, Loss (standarized): 0.7442494978341674\n",
      "          Validation Loss (standardized): 0.6690234639779209\n",
      "Epoch: 76, Loss (standarized): 0.7331768648218822\n",
      "          Validation Loss (standardized): 0.6595223527268675\n",
      "Epoch: 81, Loss (standarized): 0.7222701288607031\n",
      "          Validation Loss (standardized): 0.6517118291196912\n",
      "Epoch: 86, Loss (standarized): 0.7118480750643922\n",
      "          Validation Loss (standardized): 0.6432581030075443\n",
      "Epoch: 91, Loss (standarized): 0.701689978565212\n",
      "          Validation Loss (standardized): 0.6340978823002937\n",
      "Epoch: 96, Loss (standarized): 0.6915277753033079\n",
      "          Validation Loss (standardized): 0.6255823649099213\n",
      "Final epoch: 100, Final loss (standarized): 0.6830384713051643\n",
      "Epoch: 1, Loss (standarized): 0.9870600050383509\n",
      "          Validation Loss (standardized): 0.8790170145239151\n",
      "Epoch: 6, Loss (standarized): 0.9212355190989807\n",
      "          Validation Loss (standardized): 0.8965685802374377\n",
      "Epoch: 11, Loss (standarized): 0.8998327041449274\n",
      "          Validation Loss (standardized): 0.8271113205114475\n",
      "Epoch: 16, Loss (standarized): 0.8807662687551023\n",
      "          Validation Loss (standardized): 0.8172292967843853\n",
      "Epoch: 21, Loss (standarized): 0.8634554663404831\n",
      "          Validation Loss (standardized): 0.7965235075728827\n",
      "Epoch: 26, Loss (standarized): 0.849051214219361\n",
      "          Validation Loss (standardized): 0.7707214396883163\n",
      "Epoch: 31, Loss (standarized): 0.8378502528228072\n",
      "          Validation Loss (standardized): 0.7703193805741557\n",
      "Epoch: 36, Loss (standarized): 0.8305762388305901\n",
      "          Validation Loss (standardized): 0.7521806907498373\n",
      "Epoch: 41, Loss (standarized): 0.825735065014167\n",
      "          Validation Loss (standardized): 0.7571493254871158\n",
      "Epoch: 46, Loss (standarized): 0.8222801938021345\n",
      "          Validation Loss (standardized): 0.7479771387785503\n",
      "Epoch: 51, Loss (standarized): 0.8186324948141672\n",
      "          Validation Loss (standardized): 0.749229119429855\n",
      "Epoch: 56, Loss (standarized): 0.8139752592712453\n",
      "          Validation Loss (standardized): 0.7431780425923129\n",
      "Epoch: 61, Loss (standarized): 0.808207369914642\n",
      "          Validation Loss (standardized): 0.7373490959598874\n",
      "Epoch: 66, Loss (standarized): 0.80179914730818\n",
      "          Validation Loss (standardized): 0.7330540189533872\n",
      "Epoch: 71, Loss (standarized): 0.7952917211787209\n",
      "          Validation Loss (standardized): 0.7246066176683056\n",
      "Epoch: 76, Loss (standarized): 0.7890046777722388\n",
      "          Validation Loss (standardized): 0.7207902800040015\n",
      "Epoch: 81, Loss (standarized): 0.7829140408123243\n",
      "          Validation Loss (standardized): 0.7148016997816375\n",
      "Epoch: 86, Loss (standarized): 0.776898571983322\n",
      "          Validation Loss (standardized): 0.7091431354784448\n",
      "Epoch: 91, Loss (standarized): 0.7707546612916287\n",
      "          Validation Loss (standardized): 0.7044818231129426\n",
      "Epoch: 96, Loss (standarized): 0.7643983434738347\n",
      "          Validation Loss (standardized): 0.6987814360627185\n",
      "Final epoch: 100, Final loss (standarized): 0.7592222382967714\n",
      "Epoch: 1, Loss (standarized): 0.988947013006868\n",
      "          Validation Loss (standardized): 0.9770615131140253\n",
      "Epoch: 6, Loss (standarized): 0.9472428513337562\n",
      "          Validation Loss (standardized): 0.8743529501806648\n",
      "Epoch: 11, Loss (standarized): 0.9035800567377807\n",
      "          Validation Loss (standardized): 0.837372333781288\n",
      "Epoch: 16, Loss (standarized): 0.8657387322274891\n",
      "          Validation Loss (standardized): 0.7941022231717818\n",
      "Epoch: 21, Loss (standarized): 0.8379182182488399\n",
      "          Validation Loss (standardized): 0.750810820747886\n",
      "Epoch: 26, Loss (standarized): 0.8241488998436871\n",
      "          Validation Loss (standardized): 0.7438769161599191\n",
      "Epoch: 31, Loss (standarized): 0.8164674424925895\n",
      "          Validation Loss (standardized): 0.7258712007843183\n",
      "Epoch: 36, Loss (standarized): 0.8051118467581319\n",
      "          Validation Loss (standardized): 0.7185693416814729\n",
      "Epoch: 41, Loss (standarized): 0.7931330499150714\n",
      "          Validation Loss (standardized): 0.7152777241436769\n",
      "Epoch: 46, Loss (standarized): 0.7829755861945893\n",
      "          Validation Loss (standardized): 0.7051063099352202\n",
      "Epoch: 51, Loss (standarized): 0.7717684874568954\n",
      "          Validation Loss (standardized): 0.6951378493367829\n",
      "Epoch: 56, Loss (standarized): 0.7589047410247047\n",
      "          Validation Loss (standardized): 0.6843217416485154\n",
      "Epoch: 61, Loss (standarized): 0.7464904774220853\n",
      "          Validation Loss (standardized): 0.6721232804474475\n",
      "Epoch: 66, Loss (standarized): 0.7350727758240726\n",
      "          Validation Loss (standardized): 0.6613038254680785\n",
      "Epoch: 71, Loss (standarized): 0.7245498930656318\n",
      "          Validation Loss (standardized): 0.6531941047162312\n",
      "Epoch: 76, Loss (standarized): 0.7152412837066857\n",
      "          Validation Loss (standardized): 0.6462188557419445\n",
      "Epoch: 81, Loss (standarized): 0.7067400492930229\n",
      "          Validation Loss (standardized): 0.6389612906616856\n",
      "Epoch: 86, Loss (standarized): 0.6988681983332384\n",
      "          Validation Loss (standardized): 0.6320893339480051\n",
      "Epoch: 91, Loss (standarized): 0.6911093952741926\n",
      "          Validation Loss (standardized): 0.6258821974872327\n",
      "Epoch: 96, Loss (standarized): 0.6828919062312597\n",
      "          Validation Loss (standardized): 0.6195808281223937\n",
      "Final epoch: 100, Final loss (standarized): 0.6755436362705023\n",
      "Epoch: 1, Loss (standarized): 1.4853654977154904\n",
      "          Validation Loss (standardized): 1.2973634864411363\n",
      "Epoch: 6, Loss (standarized): 1.0392326602947795\n",
      "          Validation Loss (standardized): 0.9168516157876263\n",
      "Epoch: 11, Loss (standarized): 0.9859495308659589\n",
      "          Validation Loss (standardized): 0.8649714194042372\n",
      "Epoch: 16, Loss (standarized): 0.946890371587835\n",
      "          Validation Loss (standardized): 0.9592390644961015\n",
      "Epoch: 21, Loss (standarized): 0.9194968566516513\n",
      "          Validation Loss (standardized): 0.8761151807484869\n",
      "Epoch: 26, Loss (standarized): 0.8866885238664487\n",
      "          Validation Loss (standardized): 0.7947404834039387\n",
      "Epoch: 31, Loss (standarized): 0.8654738552896205\n",
      "          Validation Loss (standardized): 0.7758802921774622\n",
      "Epoch: 36, Loss (standarized): 0.8405807375013907\n",
      "          Validation Loss (standardized): 0.7882816393854923\n",
      "Epoch: 41, Loss (standarized): 0.822655788263074\n",
      "          Validation Loss (standardized): 0.753662295350301\n",
      "Epoch: 46, Loss (standarized): 0.8076667694694774\n",
      "          Validation Loss (standardized): 0.7183525054575142\n",
      "Epoch: 51, Loss (standarized): 0.7962058444514781\n",
      "          Validation Loss (standardized): 0.7144174382105869\n",
      "Epoch: 56, Loss (standarized): 0.7891889972023655\n",
      "          Validation Loss (standardized): 0.7150201133630307\n",
      "Epoch: 61, Loss (standarized): 0.7821996453318197\n",
      "          Validation Loss (standardized): 0.6985600602959867\n",
      "Epoch: 66, Loss (standarized): 0.7763749024328017\n",
      "          Validation Loss (standardized): 0.6917407899979761\n",
      "Epoch: 71, Loss (standarized): 0.7695569005208887\n",
      "          Validation Loss (standardized): 0.6922990970716384\n",
      "Epoch: 76, Loss (standarized): 0.7625023112142109\n",
      "          Validation Loss (standardized): 0.6845660140490696\n",
      "Epoch: 81, Loss (standarized): 0.7554265774214685\n",
      "          Validation Loss (standardized): 0.6771100109523721\n",
      "Epoch: 86, Loss (standarized): 0.748448482499078\n",
      "          Validation Loss (standardized): 0.6748349304854014\n",
      "Epoch: 91, Loss (standarized): 0.7417029476794119\n",
      "          Validation Loss (standardized): 0.6695806362654576\n",
      "Epoch: 96, Loss (standarized): 0.7350121509451113\n",
      "          Validation Loss (standardized): 0.6627399187338138\n",
      "Final epoch: 100, Final loss (standarized): 0.7297230862508183\n",
      "Epoch: 1, Loss (standarized): 0.8111084947273852\n",
      "Epoch: 6, Loss (standarized): 0.746245939186178\n",
      "Epoch: 11, Loss (standarized): 0.6486578959969533\n",
      "Epoch: 16, Loss (standarized): 0.5503614153340075\n",
      "Epoch: 21, Loss (standarized): 0.47521596975516933\n",
      "Epoch: 26, Loss (standarized): 0.4204675455994803\n",
      "Epoch: 31, Loss (standarized): 0.4113486258576975\n",
      "Epoch: 36, Loss (standarized): 0.40937554334696513\n",
      "Epoch: 41, Loss (standarized): 0.3942651264398053\n",
      "Epoch: 46, Loss (standarized): 0.382493789866945\n",
      "Epoch: 51, Loss (standarized): 0.3750391959475655\n",
      "Epoch: 56, Loss (standarized): 0.3632373684424227\n",
      "Epoch: 61, Loss (standarized): 0.35120954749013694\n",
      "Epoch: 66, Loss (standarized): 0.3391136485515374\n",
      "Epoch: 71, Loss (standarized): 0.3248176053106307\n",
      "Epoch: 76, Loss (standarized): 0.3105410973636467\n",
      "Epoch: 81, Loss (standarized): 0.29624280593686303\n",
      "Epoch: 86, Loss (standarized): 0.28343844901089177\n",
      "Epoch: 91, Loss (standarized): 0.271416164752844\n",
      "Epoch: 96, Loss (standarized): 0.2568641317885229\n",
      "Final epoch: 100, Final loss (standarized): 0.24525580483186973\n",
      "Epoch: 1, Loss (standarized): 1.2218164912032532\n",
      "Epoch: 6, Loss (standarized): 0.9088267662724661\n",
      "Epoch: 11, Loss (standarized): 0.7838847469997126\n",
      "Epoch: 16, Loss (standarized): 0.7868825478300637\n",
      "Epoch: 21, Loss (standarized): 0.7252753177153697\n",
      "Epoch: 26, Loss (standarized): 0.6931679251973479\n",
      "Epoch: 31, Loss (standarized): 0.6444780681519339\n",
      "Epoch: 36, Loss (standarized): 0.6066289410588164\n",
      "Epoch: 41, Loss (standarized): 0.562688109484724\n",
      "Epoch: 46, Loss (standarized): 0.5196614859995781\n",
      "Epoch: 51, Loss (standarized): 0.486338906744904\n",
      "Epoch: 56, Loss (standarized): 0.4608579694519245\n",
      "Epoch: 61, Loss (standarized): 0.442857615050073\n",
      "Epoch: 66, Loss (standarized): 0.43234442347302127\n",
      "Epoch: 71, Loss (standarized): 0.4243468827498013\n",
      "Epoch: 76, Loss (standarized): 0.41941154329940494\n",
      "Epoch: 81, Loss (standarized): 0.4164908260803107\n",
      "Epoch: 86, Loss (standarized): 0.4138370563277419\n",
      "Epoch: 91, Loss (standarized): 0.4114415094409935\n",
      "Epoch: 96, Loss (standarized): 0.40959138691777747\n",
      "Final epoch: 100, Final loss (standarized): 0.408374901140237\n",
      "Epoch: 1, Loss (standarized): 1.0254730561165175\n",
      "Epoch: 6, Loss (standarized): 0.7827065265466899\n",
      "Epoch: 11, Loss (standarized): 0.7040827799119269\n",
      "Epoch: 16, Loss (standarized): 0.6044789627745815\n",
      "Epoch: 21, Loss (standarized): 0.5446452110826777\n",
      "Epoch: 26, Loss (standarized): 0.5026741158364805\n",
      "Epoch: 31, Loss (standarized): 0.460118435225141\n",
      "Epoch: 36, Loss (standarized): 0.4341991868912058\n",
      "Epoch: 41, Loss (standarized): 0.41760511618570273\n",
      "Epoch: 46, Loss (standarized): 0.4091485313719348\n",
      "Epoch: 51, Loss (standarized): 0.4020506025650981\n",
      "Epoch: 56, Loss (standarized): 0.3952166016519266\n",
      "Epoch: 61, Loss (standarized): 0.38847367981656217\n",
      "Epoch: 66, Loss (standarized): 0.38334603706174775\n",
      "Epoch: 71, Loss (standarized): 0.3780670923167059\n",
      "Epoch: 76, Loss (standarized): 0.37234809457130924\n",
      "Epoch: 81, Loss (standarized): 0.36654805773308524\n",
      "Epoch: 86, Loss (standarized): 0.3608041272983818\n",
      "Epoch: 91, Loss (standarized): 0.3550348753484692\n",
      "Epoch: 96, Loss (standarized): 0.3491865550987686\n",
      "Final epoch: 100, Final loss (standarized): 0.34446079013588526\n",
      "Epoch: 1, Loss (standarized): 0.9522581549685587\n",
      "Epoch: 6, Loss (standarized): 0.8029320859789749\n",
      "Epoch: 11, Loss (standarized): 0.7724464700590798\n",
      "Epoch: 16, Loss (standarized): 0.7150072988099426\n",
      "Epoch: 21, Loss (standarized): 0.6357839861332341\n",
      "Epoch: 26, Loss (standarized): 0.5581007085784102\n",
      "Epoch: 31, Loss (standarized): 0.4901860086740147\n",
      "Epoch: 36, Loss (standarized): 0.4401418587013054\n",
      "Epoch: 41, Loss (standarized): 0.4211843474367468\n",
      "Epoch: 46, Loss (standarized): 0.41537449724855674\n",
      "Epoch: 51, Loss (standarized): 0.403454665825249\n",
      "Epoch: 56, Loss (standarized): 0.3969353699067124\n",
      "Epoch: 61, Loss (standarized): 0.39226580306286163\n",
      "Epoch: 66, Loss (standarized): 0.38407853495440836\n",
      "Epoch: 71, Loss (standarized): 0.3766723270144808\n",
      "Epoch: 76, Loss (standarized): 0.36830164021075673\n",
      "Epoch: 81, Loss (standarized): 0.3592359726842405\n",
      "Epoch: 86, Loss (standarized): 0.3494976406235565\n",
      "Epoch: 91, Loss (standarized): 0.33810566589136765\n",
      "Epoch: 96, Loss (standarized): 0.32428484620754516\n",
      "Final epoch: 100, Final loss (standarized): 0.31096735171176076\n",
      "Epoch: 1, Loss (standarized): 1.0555384143510538\n",
      "Epoch: 6, Loss (standarized): 0.837897382389967\n",
      "Epoch: 11, Loss (standarized): 0.777026362600974\n",
      "Epoch: 16, Loss (standarized): 0.7668182368185381\n",
      "Epoch: 21, Loss (standarized): 0.7337949590657685\n",
      "Epoch: 26, Loss (standarized): 0.7169119436027592\n",
      "Epoch: 31, Loss (standarized): 0.7025120192082601\n",
      "Epoch: 36, Loss (standarized): 0.6926430899345094\n",
      "Epoch: 41, Loss (standarized): 0.6824465529250923\n",
      "Epoch: 46, Loss (standarized): 0.6740555531913339\n",
      "Epoch: 51, Loss (standarized): 0.666514854288945\n",
      "Epoch: 56, Loss (standarized): 0.6586728746480753\n",
      "Epoch: 61, Loss (standarized): 0.6485816669677107\n",
      "Epoch: 66, Loss (standarized): 0.6369672704571938\n",
      "Epoch: 71, Loss (standarized): 0.6266749400064203\n",
      "Epoch: 76, Loss (standarized): 0.6172062157081498\n",
      "Epoch: 81, Loss (standarized): 0.6070810698675582\n",
      "Epoch: 86, Loss (standarized): 0.5968702793381573\n",
      "Epoch: 91, Loss (standarized): 0.585550992721523\n",
      "Epoch: 96, Loss (standarized): 0.5725009352844597\n",
      "Final epoch: 100, Final loss (standarized): 0.5609928009998697\n",
      "Epoch: 1, Loss (standarized): 1.2529253943756777\n",
      "Epoch: 6, Loss (standarized): 0.8635923731551403\n",
      "Epoch: 11, Loss (standarized): 0.7967026339523263\n",
      "Epoch: 16, Loss (standarized): 0.7971987653119738\n",
      "Epoch: 21, Loss (standarized): 0.7793679376695508\n",
      "Epoch: 26, Loss (standarized): 0.7515098259211404\n",
      "Epoch: 31, Loss (standarized): 0.7352175490132403\n",
      "Epoch: 36, Loss (standarized): 0.7200912008972533\n",
      "Epoch: 41, Loss (standarized): 0.7065147618459111\n",
      "Epoch: 46, Loss (standarized): 0.6944434355516138\n",
      "Epoch: 51, Loss (standarized): 0.6828040070799997\n",
      "Epoch: 56, Loss (standarized): 0.670964293740862\n",
      "Epoch: 61, Loss (standarized): 0.6588637582598948\n",
      "Epoch: 66, Loss (standarized): 0.6475997701232796\n",
      "Epoch: 71, Loss (standarized): 0.6386667213008208\n",
      "Epoch: 76, Loss (standarized): 0.6319683633526731\n",
      "Epoch: 81, Loss (standarized): 0.6266659490281328\n",
      "Epoch: 86, Loss (standarized): 0.6221752486291919\n",
      "Epoch: 91, Loss (standarized): 0.6176965717279547\n",
      "Epoch: 96, Loss (standarized): 0.6128868583571416\n",
      "Final epoch: 100, Final loss (standarized): 0.6086174576298353\n",
      "Epoch: 1, Loss (standarized): 0.7978096959854317\n",
      "Epoch: 6, Loss (standarized): 0.7384708899463137\n",
      "Epoch: 11, Loss (standarized): 0.6875241648544167\n",
      "Epoch: 16, Loss (standarized): 0.6489356002079182\n",
      "Epoch: 21, Loss (standarized): 0.6187918700642835\n",
      "Epoch: 26, Loss (standarized): 0.5983232919532899\n",
      "Epoch: 31, Loss (standarized): 0.578883314791196\n",
      "Epoch: 36, Loss (standarized): 0.5617009639984473\n",
      "Epoch: 41, Loss (standarized): 0.5432269875936423\n",
      "Epoch: 46, Loss (standarized): 0.5250592643496503\n",
      "Epoch: 51, Loss (standarized): 0.5065772508704932\n",
      "Epoch: 56, Loss (standarized): 0.4870984813694168\n",
      "Epoch: 61, Loss (standarized): 0.4659384843124615\n",
      "Epoch: 66, Loss (standarized): 0.4457948876722163\n",
      "Epoch: 71, Loss (standarized): 0.42907647319515274\n",
      "Epoch: 76, Loss (standarized): 0.4153137810697548\n",
      "Epoch: 81, Loss (standarized): 0.4043425777267567\n",
      "Epoch: 86, Loss (standarized): 0.39580963507056866\n",
      "Epoch: 91, Loss (standarized): 0.3892386571660885\n",
      "Epoch: 96, Loss (standarized): 0.38286952687742176\n",
      "Final epoch: 100, Final loss (standarized): 0.37811524330200913\n",
      "Epoch: 1, Loss (standarized): 1.1433058813339687\n",
      "Epoch: 6, Loss (standarized): 0.838192224027563\n",
      "Epoch: 11, Loss (standarized): 0.8143681403314224\n",
      "Epoch: 16, Loss (standarized): 0.8005662321870279\n",
      "Epoch: 21, Loss (standarized): 0.7877787657536929\n",
      "Epoch: 26, Loss (standarized): 0.7596069165184401\n",
      "Epoch: 31, Loss (standarized): 0.7359109156475607\n",
      "Epoch: 36, Loss (standarized): 0.7158489420724379\n",
      "Epoch: 41, Loss (standarized): 0.6984814922727797\n",
      "Epoch: 46, Loss (standarized): 0.6829128024565639\n",
      "Epoch: 51, Loss (standarized): 0.6683288274861237\n",
      "Epoch: 56, Loss (standarized): 0.6560287768561454\n",
      "Epoch: 61, Loss (standarized): 0.6458211261234948\n",
      "Epoch: 66, Loss (standarized): 0.6368999259960594\n",
      "Epoch: 71, Loss (standarized): 0.628857178510076\n",
      "Epoch: 76, Loss (standarized): 0.6208817280413148\n",
      "Epoch: 81, Loss (standarized): 0.6124667483675953\n",
      "Epoch: 86, Loss (standarized): 0.603595805870766\n",
      "Epoch: 91, Loss (standarized): 0.5936812836036467\n",
      "Epoch: 96, Loss (standarized): 0.5828208116016389\n",
      "Final epoch: 100, Final loss (standarized): 0.5732338861568798\n",
      "Epoch: 1, Loss (standarized): 0.9172725540251541\n",
      "Epoch: 6, Loss (standarized): 0.7992199349162548\n",
      "Epoch: 11, Loss (standarized): 0.7503883935535945\n",
      "Epoch: 16, Loss (standarized): 0.6834154339609807\n",
      "Epoch: 21, Loss (standarized): 0.6303859620654386\n",
      "Epoch: 26, Loss (standarized): 0.5788602162842558\n",
      "Epoch: 31, Loss (standarized): 0.5210963691063146\n",
      "Epoch: 36, Loss (standarized): 0.4681927084280108\n",
      "Epoch: 41, Loss (standarized): 0.4258581779106757\n",
      "Epoch: 46, Loss (standarized): 0.39755005577644204\n",
      "Epoch: 51, Loss (standarized): 0.38640122658519493\n",
      "Epoch: 56, Loss (standarized): 0.3804320595509302\n",
      "Epoch: 61, Loss (standarized): 0.37336387149959693\n",
      "Epoch: 66, Loss (standarized): 0.3668026774343786\n",
      "Epoch: 71, Loss (standarized): 0.3616138805576833\n",
      "Epoch: 76, Loss (standarized): 0.3566064387479164\n",
      "Epoch: 81, Loss (standarized): 0.3512848437648564\n",
      "Epoch: 86, Loss (standarized): 0.34593393241781917\n",
      "Epoch: 91, Loss (standarized): 0.34077456267915723\n",
      "Epoch: 96, Loss (standarized): 0.3358051040718547\n",
      "Final epoch: 100, Final loss (standarized): 0.33198668807972964\n",
      "Epoch: 1, Loss (standarized): 1.0467205125080803\n",
      "Epoch: 6, Loss (standarized): 0.8445761076655003\n",
      "Epoch: 11, Loss (standarized): 0.7577734802022629\n",
      "Epoch: 16, Loss (standarized): 0.7305163891462978\n",
      "Epoch: 21, Loss (standarized): 0.6859463985872052\n",
      "Epoch: 26, Loss (standarized): 0.6496469751774925\n",
      "Epoch: 31, Loss (standarized): 0.6156473743658947\n",
      "Epoch: 36, Loss (standarized): 0.5778299212977525\n",
      "Epoch: 41, Loss (standarized): 0.5402536086631112\n",
      "Epoch: 46, Loss (standarized): 0.5029456258036187\n",
      "Epoch: 51, Loss (standarized): 0.4702339733229722\n",
      "Epoch: 56, Loss (standarized): 0.4434420729743186\n",
      "Epoch: 61, Loss (standarized): 0.4267494820161268\n",
      "Epoch: 66, Loss (standarized): 0.416466392298632\n",
      "Epoch: 71, Loss (standarized): 0.411427973834539\n",
      "Epoch: 76, Loss (standarized): 0.4087085134681142\n",
      "Epoch: 81, Loss (standarized): 0.4076427154610265\n",
      "Epoch: 86, Loss (standarized): 0.40665599120669127\n",
      "Epoch: 91, Loss (standarized): 0.4049871778981064\n",
      "Epoch: 96, Loss (standarized): 0.4027812066581335\n",
      "Final epoch: 100, Final loss (standarized): 0.4009162318050783\n",
      "Epoch: 1, Loss (standarized): 2.6219675997177747\n",
      "Epoch: 6, Loss (standarized): 0.8403486670697392\n",
      "Epoch: 11, Loss (standarized): 0.9944072686481336\n",
      "Epoch: 16, Loss (standarized): 0.7475039338329783\n",
      "Epoch: 21, Loss (standarized): 0.7841972617026303\n",
      "Epoch: 26, Loss (standarized): 0.7306165501086278\n",
      "Epoch: 31, Loss (standarized): 0.6798222671915075\n",
      "Epoch: 36, Loss (standarized): 0.6665451989820124\n",
      "Epoch: 41, Loss (standarized): 0.6282068711418559\n",
      "Epoch: 46, Loss (standarized): 0.6036801782850413\n",
      "Epoch: 51, Loss (standarized): 0.5788076590972985\n",
      "Epoch: 56, Loss (standarized): 0.552304534573981\n",
      "Epoch: 61, Loss (standarized): 0.5290068715667233\n",
      "Epoch: 66, Loss (standarized): 0.5054544749199178\n",
      "Epoch: 71, Loss (standarized): 0.4860514645046793\n",
      "Epoch: 76, Loss (standarized): 0.4698170061645321\n",
      "Epoch: 81, Loss (standarized): 0.4568179234660166\n",
      "Epoch: 86, Loss (standarized): 0.44717240859329505\n",
      "Epoch: 91, Loss (standarized): 0.4401463233914784\n",
      "Epoch: 96, Loss (standarized): 0.4348551894005211\n",
      "Final epoch: 100, Final loss (standarized): 0.4314638985071694\n",
      "Epoch: 1, Loss (standarized): 2.0609881479827212\n",
      "Epoch: 6, Loss (standarized): 0.888588001119077\n",
      "Epoch: 11, Loss (standarized): 0.9040186647308548\n",
      "Epoch: 16, Loss (standarized): 0.7702877118350988\n",
      "Epoch: 21, Loss (standarized): 0.7894349557862578\n",
      "Epoch: 26, Loss (standarized): 0.7140696388669665\n",
      "Epoch: 31, Loss (standarized): 0.695026070033629\n",
      "Epoch: 36, Loss (standarized): 0.6582231483575125\n",
      "Epoch: 41, Loss (standarized): 0.6279368431241552\n",
      "Epoch: 46, Loss (standarized): 0.5967762906397438\n",
      "Epoch: 51, Loss (standarized): 0.5615446157966228\n",
      "Epoch: 56, Loss (standarized): 0.5287610958786046\n",
      "Epoch: 61, Loss (standarized): 0.4993013740634843\n",
      "Epoch: 66, Loss (standarized): 0.4722755364832866\n",
      "Epoch: 71, Loss (standarized): 0.45210590358024233\n",
      "Epoch: 76, Loss (standarized): 0.4370208958405457\n",
      "Epoch: 81, Loss (standarized): 0.4261275163452498\n",
      "Epoch: 86, Loss (standarized): 0.4173252683186156\n",
      "Epoch: 91, Loss (standarized): 0.40956639060279676\n",
      "Epoch: 96, Loss (standarized): 0.402837128333333\n",
      "Final epoch: 100, Final loss (standarized): 0.3981063202877999\n",
      "Epoch: 1, Loss (standarized): 0.9096315331800631\n",
      "Epoch: 6, Loss (standarized): 0.7891770441611995\n",
      "Epoch: 11, Loss (standarized): 0.7244819655457999\n",
      "Epoch: 16, Loss (standarized): 0.6476272777597007\n",
      "Epoch: 21, Loss (standarized): 0.582548895137766\n",
      "Epoch: 26, Loss (standarized): 0.5270260307129518\n",
      "Epoch: 31, Loss (standarized): 0.47496010652777426\n",
      "Epoch: 36, Loss (standarized): 0.4384542875054356\n",
      "Epoch: 41, Loss (standarized): 0.40699576301136753\n",
      "Epoch: 46, Loss (standarized): 0.38949059922950535\n",
      "Epoch: 51, Loss (standarized): 0.37775661277594397\n",
      "Epoch: 56, Loss (standarized): 0.37080160198581325\n",
      "Epoch: 61, Loss (standarized): 0.3638717890636041\n",
      "Epoch: 66, Loss (standarized): 0.35660513475087363\n",
      "Epoch: 71, Loss (standarized): 0.3502161484009777\n",
      "Epoch: 76, Loss (standarized): 0.3437872241788392\n",
      "Epoch: 81, Loss (standarized): 0.336750937723205\n",
      "Epoch: 86, Loss (standarized): 0.3294486055102909\n",
      "Epoch: 91, Loss (standarized): 0.321828299249328\n",
      "Epoch: 96, Loss (standarized): 0.31375478348432057\n",
      "Final epoch: 100, Final loss (standarized): 0.3072003735984382\n",
      "Epoch: 1, Loss (standarized): 1.205899851996612\n",
      "Epoch: 6, Loss (standarized): 0.873840605604275\n",
      "Epoch: 11, Loss (standarized): 0.799586682515734\n",
      "Epoch: 16, Loss (standarized): 0.7911000778084878\n",
      "Epoch: 21, Loss (standarized): 0.7499928449631313\n",
      "Epoch: 26, Loss (standarized): 0.7163267181572232\n",
      "Epoch: 31, Loss (standarized): 0.6767976339018391\n",
      "Epoch: 36, Loss (standarized): 0.6448892025552991\n",
      "Epoch: 41, Loss (standarized): 0.6087231850228306\n",
      "Epoch: 46, Loss (standarized): 0.5685518977983969\n",
      "Epoch: 51, Loss (standarized): 0.5257922020066415\n",
      "Epoch: 56, Loss (standarized): 0.4901043773213859\n",
      "Epoch: 61, Loss (standarized): 0.4566573671395293\n",
      "Epoch: 66, Loss (standarized): 0.4345669808483601\n",
      "Epoch: 71, Loss (standarized): 0.42024386545934345\n",
      "Epoch: 76, Loss (standarized): 0.41318014963983724\n",
      "Epoch: 81, Loss (standarized): 0.40969715264732603\n",
      "Epoch: 86, Loss (standarized): 0.4087363599096318\n",
      "Epoch: 91, Loss (standarized): 0.4081612162194328\n",
      "Epoch: 96, Loss (standarized): 0.40740928801929693\n",
      "Final epoch: 100, Final loss (standarized): 0.4064698906358476\n",
      "Epoch: 1, Loss (standarized): 0.9322043699846077\n",
      "Epoch: 6, Loss (standarized): 0.7948918638988077\n",
      "Epoch: 11, Loss (standarized): 0.7540799943430446\n",
      "Epoch: 16, Loss (standarized): 0.6960732834612964\n",
      "Epoch: 21, Loss (standarized): 0.6221965430885751\n",
      "Epoch: 26, Loss (standarized): 0.5527438746806492\n",
      "Epoch: 31, Loss (standarized): 0.49572113364393733\n",
      "Epoch: 36, Loss (standarized): 0.45513350526578344\n",
      "Epoch: 41, Loss (standarized): 0.43333674050731685\n",
      "Epoch: 46, Loss (standarized): 0.4306016905840876\n",
      "Epoch: 51, Loss (standarized): 0.423026919303242\n",
      "Epoch: 56, Loss (standarized): 0.4189413522954598\n",
      "Epoch: 61, Loss (standarized): 0.4166561540716545\n",
      "Epoch: 66, Loss (standarized): 0.4140963252059624\n",
      "Epoch: 71, Loss (standarized): 0.41013475495920854\n",
      "Epoch: 76, Loss (standarized): 0.4074220327493979\n",
      "Epoch: 81, Loss (standarized): 0.4040354107823573\n",
      "Epoch: 86, Loss (standarized): 0.4005065282698368\n",
      "Epoch: 91, Loss (standarized): 0.39652917711347524\n",
      "Epoch: 96, Loss (standarized): 0.391951308610908\n",
      "Final epoch: 100, Final loss (standarized): 0.3878768512290566\n",
      "Epoch: 1, Loss (standarized): 1.1032995914660435\n",
      "Epoch: 6, Loss (standarized): 0.8208458140236864\n",
      "Epoch: 11, Loss (standarized): 0.7295109011088415\n",
      "Epoch: 16, Loss (standarized): 0.6990502977999405\n",
      "Epoch: 21, Loss (standarized): 0.63658977967591\n",
      "Epoch: 26, Loss (standarized): 0.5995780890874901\n",
      "Epoch: 31, Loss (standarized): 0.5466328884457542\n",
      "Epoch: 36, Loss (standarized): 0.4992652851109531\n",
      "Epoch: 41, Loss (standarized): 0.4577046138315173\n",
      "Epoch: 46, Loss (standarized): 0.4217934678558227\n",
      "Epoch: 51, Loss (standarized): 0.4002270587076562\n",
      "Epoch: 56, Loss (standarized): 0.3881393691598632\n",
      "Epoch: 61, Loss (standarized): 0.3807194519719235\n",
      "Epoch: 66, Loss (standarized): 0.37173663433309756\n",
      "Epoch: 71, Loss (standarized): 0.3628774711333147\n",
      "Epoch: 76, Loss (standarized): 0.3560440279170072\n",
      "Epoch: 81, Loss (standarized): 0.3488916924780511\n",
      "Epoch: 86, Loss (standarized): 0.3412041070536949\n",
      "Epoch: 91, Loss (standarized): 0.33378908842177357\n",
      "Epoch: 96, Loss (standarized): 0.32596709570980015\n",
      "Final epoch: 100, Final loss (standarized): 0.31946139070275237\n",
      "Epoch: 1, Loss (standarized): 1.2510459149947601\n",
      "          Validation Loss (standardized): 0.9266769019444561\n",
      "Epoch: 6, Loss (standarized): 0.8951167251479466\n",
      "          Validation Loss (standardized): 0.7935999560796345\n",
      "Epoch: 11, Loss (standarized): 0.7827496797758379\n",
      "          Validation Loss (standardized): 0.7035883750044689\n",
      "Epoch: 16, Loss (standarized): 0.7832161101690268\n",
      "          Validation Loss (standardized): 0.7203514433874468\n",
      "Epoch: 21, Loss (standarized): 0.73084663016995\n",
      "          Validation Loss (standardized): 0.6576928083461097\n",
      "Epoch: 26, Loss (standarized): 0.6990300997049225\n",
      "          Validation Loss (standardized): 0.6329644673901467\n",
      "Epoch: 31, Loss (standarized): 0.6541489680297928\n",
      "          Validation Loss (standardized): 0.5968137288645248\n",
      "Epoch: 36, Loss (standarized): 0.6134187300936763\n",
      "          Validation Loss (standardized): 0.5727152717098953\n",
      "Epoch: 41, Loss (standarized): 0.5656651450704373\n",
      "          Validation Loss (standardized): 0.5350456713274323\n",
      "Epoch: 46, Loss (standarized): 0.5186612073627739\n",
      "          Validation Loss (standardized): 0.5044488013607665\n",
      "Epoch: 51, Loss (standarized): 0.47315180762612546\n",
      "          Validation Loss (standardized): 0.48579131339221043\n",
      "Epoch: 56, Loss (standarized): 0.44039876567690184\n",
      "          Validation Loss (standardized): 0.4780705260890646\n",
      "Epoch: 61, Loss (standarized): 0.42338104103596164\n",
      "          Validation Loss (standardized): 0.4818366506256908\n",
      "Epoch: 66, Loss (standarized): 0.41763379638257775\n",
      "          Validation Loss (standardized): 0.49359818753321166\n",
      "Epoch: 71, Loss (standarized): 0.4174170112755545\n",
      "          Validation Loss (standardized): 0.4994936687968031\n",
      "Epoch: 76, Loss (standarized): 0.41427732836819936\n",
      "          Validation Loss (standardized): 0.49626852604447635\n",
      "Epoch: 81, Loss (standarized): 0.4094115382706186\n",
      "          Validation Loss (standardized): 0.48462424910942814\n",
      "Epoch: 86, Loss (standarized): 0.4054782296628419\n",
      "          Validation Loss (standardized): 0.4747998421826314\n",
      "Epoch: 91, Loss (standarized): 0.4029814155037713\n",
      "          Validation Loss (standardized): 0.4674686839600477\n",
      "Epoch: 96, Loss (standarized): 0.40002082693306207\n",
      "          Validation Loss (standardized): 0.4640694320146133\n",
      "Final epoch: 100, Final loss (standarized): 0.3969294166969302\n",
      "Epoch: 1, Loss (standarized): 0.8946290723378599\n",
      "          Validation Loss (standardized): 0.7274085951347239\n",
      "Epoch: 6, Loss (standarized): 0.7920953451787255\n",
      "          Validation Loss (standardized): 0.7080606043402768\n",
      "Epoch: 11, Loss (standarized): 0.7565903708858023\n",
      "          Validation Loss (standardized): 0.6725999825851673\n",
      "Epoch: 16, Loss (standarized): 0.7083405122354899\n",
      "          Validation Loss (standardized): 0.6333437983719196\n",
      "Epoch: 21, Loss (standarized): 0.6491037576401375\n",
      "          Validation Loss (standardized): 0.5942550710365306\n",
      "Epoch: 26, Loss (standarized): 0.5876602477449012\n",
      "          Validation Loss (standardized): 0.5463904028204007\n",
      "Epoch: 31, Loss (standarized): 0.5285496489971246\n",
      "          Validation Loss (standardized): 0.5083155014920188\n",
      "Epoch: 36, Loss (standarized): 0.47821526203981896\n",
      "          Validation Loss (standardized): 0.48816053631607786\n",
      "Epoch: 41, Loss (standarized): 0.4439502511650703\n",
      "          Validation Loss (standardized): 0.4773694052502314\n",
      "Epoch: 46, Loss (standarized): 0.4218884854111815\n",
      "          Validation Loss (standardized): 0.46901363857102646\n",
      "Epoch: 51, Loss (standarized): 0.4096639339068714\n",
      "          Validation Loss (standardized): 0.45965231669904627\n",
      "Epoch: 56, Loss (standarized): 0.4034967110193442\n",
      "          Validation Loss (standardized): 0.45530160058266456\n",
      "Epoch: 61, Loss (standarized): 0.39915470927022223\n",
      "          Validation Loss (standardized): 0.45574831263602683\n",
      "Epoch: 66, Loss (standarized): 0.39665375245344175\n",
      "          Validation Loss (standardized): 0.45490840177277236\n",
      "Epoch: 71, Loss (standarized): 0.39517364310123426\n",
      "          Validation Loss (standardized): 0.45050506356232134\n",
      "Epoch: 76, Loss (standarized): 0.39396336146981675\n",
      "          Validation Loss (standardized): 0.4472791373867983\n",
      "Epoch: 81, Loss (standarized): 0.3918950154353885\n",
      "          Validation Loss (standardized): 0.44567378655598766\n",
      "Epoch: 86, Loss (standarized): 0.38919287750174714\n",
      "          Validation Loss (standardized): 0.44305195478634646\n",
      "Epoch: 91, Loss (standarized): 0.3858921921866426\n",
      "          Validation Loss (standardized): 0.438729568055288\n",
      "Epoch: 96, Loss (standarized): 0.3819395090016675\n",
      "          Validation Loss (standardized): 0.4349085378347698\n",
      "Final epoch: 100, Final loss (standarized): 0.3784783838459464\n",
      "Epoch: 1, Loss (standarized): 0.8853249632048069\n",
      "          Validation Loss (standardized): 0.7204011921676539\n",
      "Epoch: 6, Loss (standarized): 0.7792429701721797\n",
      "          Validation Loss (standardized): 0.6936957656664343\n",
      "Epoch: 11, Loss (standarized): 0.710468447702266\n",
      "          Validation Loss (standardized): 0.6303943806715092\n",
      "Epoch: 16, Loss (standarized): 0.6319091567417233\n",
      "          Validation Loss (standardized): 0.5761418003495528\n",
      "Epoch: 21, Loss (standarized): 0.5690037776907868\n",
      "          Validation Loss (standardized): 0.5386969324303444\n",
      "Epoch: 26, Loss (standarized): 0.5018842955050415\n",
      "          Validation Loss (standardized): 0.48908245429694747\n",
      "Epoch: 31, Loss (standarized): 0.45482912859784647\n",
      "          Validation Loss (standardized): 0.4655249373230484\n",
      "Epoch: 36, Loss (standarized): 0.4188581535688519\n",
      "          Validation Loss (standardized): 0.44335213119015565\n",
      "Epoch: 41, Loss (standarized): 0.39610278127937926\n",
      "          Validation Loss (standardized): 0.44356275058793204\n",
      "Epoch: 46, Loss (standarized): 0.38153356337822186\n",
      "          Validation Loss (standardized): 0.4363101622927139\n",
      "Epoch: 51, Loss (standarized): 0.3753505734101732\n",
      "          Validation Loss (standardized): 0.43733399316460203\n",
      "Epoch: 56, Loss (standarized): 0.3690160904078804\n",
      "          Validation Loss (standardized): 0.4378103216648337\n",
      "Epoch: 61, Loss (standarized): 0.36109382638321097\n",
      "          Validation Loss (standardized): 0.4180662594366941\n",
      "Epoch: 66, Loss (standarized): 0.3536555601857726\n",
      "          Validation Loss (standardized): 0.4066252908425315\n",
      "Epoch: 71, Loss (standarized): 0.34724802800209187\n",
      "          Validation Loss (standardized): 0.3932990704874875\n",
      "Epoch: 76, Loss (standarized): 0.34039370629358345\n",
      "          Validation Loss (standardized): 0.38257924661292647\n",
      "Epoch: 81, Loss (standarized): 0.3327851069503279\n",
      "          Validation Loss (standardized): 0.3771252520556276\n",
      "Epoch: 86, Loss (standarized): 0.3251524476366269\n",
      "          Validation Loss (standardized): 0.37166278359741584\n",
      "Epoch: 91, Loss (standarized): 0.3178172683063397\n",
      "          Validation Loss (standardized): 0.36551159035162106\n",
      "Epoch: 96, Loss (standarized): 0.31053476613563646\n",
      "          Validation Loss (standardized): 0.3555203884743881\n",
      "Final epoch: 100, Final loss (standarized): 0.30489951072799326\n",
      "Epoch: 1, Loss (standarized): 0.8835620219306051\n",
      "          Validation Loss (standardized): 0.721979525329005\n",
      "Epoch: 6, Loss (standarized): 0.7764513242884108\n",
      "          Validation Loss (standardized): 0.7023019070353266\n",
      "Epoch: 11, Loss (standarized): 0.7014077991996546\n",
      "          Validation Loss (standardized): 0.634543016396197\n",
      "Epoch: 16, Loss (standarized): 0.6154712261089303\n",
      "          Validation Loss (standardized): 0.5631825158199111\n",
      "Epoch: 21, Loss (standarized): 0.53817053224318\n",
      "          Validation Loss (standardized): 0.5196129059212796\n",
      "Epoch: 26, Loss (standarized): 0.4783955585939241\n",
      "          Validation Loss (standardized): 0.47004876492104464\n",
      "Epoch: 31, Loss (standarized): 0.43196675251738437\n",
      "          Validation Loss (standardized): 0.46854391087960273\n",
      "Epoch: 36, Loss (standarized): 0.40781102237784006\n",
      "          Validation Loss (standardized): 0.4567037707844374\n",
      "Epoch: 41, Loss (standarized): 0.3927058347651489\n",
      "          Validation Loss (standardized): 0.4575541148097071\n",
      "Epoch: 46, Loss (standarized): 0.3876038779470947\n",
      "          Validation Loss (standardized): 0.4653890831475701\n",
      "Epoch: 51, Loss (standarized): 0.3830073606256593\n",
      "          Validation Loss (standardized): 0.454836361441491\n",
      "Epoch: 56, Loss (standarized): 0.37578004788509584\n",
      "          Validation Loss (standardized): 0.44960299089029576\n",
      "Epoch: 61, Loss (standarized): 0.36879752765484997\n",
      "          Validation Loss (standardized): 0.43384176412597725\n",
      "Epoch: 66, Loss (standarized): 0.3631365620763514\n",
      "          Validation Loss (standardized): 0.41963633437709835\n",
      "Epoch: 71, Loss (standarized): 0.3575120940456734\n",
      "          Validation Loss (standardized): 0.41408819743182873\n",
      "Epoch: 76, Loss (standarized): 0.35107560408677874\n",
      "          Validation Loss (standardized): 0.4049756965540564\n",
      "Epoch: 81, Loss (standarized): 0.344250476436345\n",
      "          Validation Loss (standardized): 0.398971940387337\n",
      "Epoch: 86, Loss (standarized): 0.33707176523083937\n",
      "          Validation Loss (standardized): 0.3912799768777972\n",
      "Epoch: 91, Loss (standarized): 0.3291528406522163\n",
      "          Validation Loss (standardized): 0.3799066586167798\n",
      "Epoch: 96, Loss (standarized): 0.32079022981741084\n",
      "          Validation Loss (standardized): 0.367657152149403\n",
      "Final epoch: 100, Final loss (standarized): 0.31399114892864394\n",
      "Epoch: 1, Loss (standarized): 0.9599173022652179\n",
      "          Validation Loss (standardized): 0.7301659270570636\n",
      "Epoch: 6, Loss (standarized): 0.782739372690546\n",
      "          Validation Loss (standardized): 0.6821385075126954\n",
      "Epoch: 11, Loss (standarized): 0.7186028293157779\n",
      "          Validation Loss (standardized): 0.6539773208444967\n",
      "Epoch: 16, Loss (standarized): 0.6755270052768275\n",
      "          Validation Loss (standardized): 0.6119381907008729\n",
      "Epoch: 21, Loss (standarized): 0.6383786546275512\n",
      "          Validation Loss (standardized): 0.5856398569732135\n",
      "Epoch: 26, Loss (standarized): 0.6129931234464496\n",
      "          Validation Loss (standardized): 0.5668932174962638\n",
      "Epoch: 31, Loss (standarized): 0.5956751229515096\n",
      "          Validation Loss (standardized): 0.555813482753446\n",
      "Epoch: 36, Loss (standarized): 0.5840023425903555\n",
      "          Validation Loss (standardized): 0.5497313559530271\n",
      "Epoch: 41, Loss (standarized): 0.5746847715299392\n",
      "          Validation Loss (standardized): 0.5420851094008176\n",
      "Epoch: 46, Loss (standarized): 0.5637510966232733\n",
      "          Validation Loss (standardized): 0.5324379482897033\n",
      "Epoch: 51, Loss (standarized): 0.551949611584251\n",
      "          Validation Loss (standardized): 0.5258634658709621\n",
      "Epoch: 56, Loss (standarized): 0.5408058933247564\n",
      "          Validation Loss (standardized): 0.5137386115832847\n",
      "Epoch: 61, Loss (standarized): 0.5277389994102772\n",
      "          Validation Loss (standardized): 0.503916818342889\n",
      "Epoch: 66, Loss (standarized): 0.5132598964692594\n",
      "          Validation Loss (standardized): 0.49337354584565857\n",
      "Epoch: 71, Loss (standarized): 0.4974475498287257\n",
      "          Validation Loss (standardized): 0.48159915166421496\n",
      "Epoch: 76, Loss (standarized): 0.4801467755606771\n",
      "          Validation Loss (standardized): 0.471007597271681\n",
      "Epoch: 81, Loss (standarized): 0.46143187540882813\n",
      "          Validation Loss (standardized): 0.4585644625312241\n",
      "Epoch: 86, Loss (standarized): 0.443629159508213\n",
      "          Validation Loss (standardized): 0.4475428685967448\n",
      "Epoch: 91, Loss (standarized): 0.4281844816121823\n",
      "          Validation Loss (standardized): 0.4400479619538784\n",
      "Epoch: 96, Loss (standarized): 0.4163684515579448\n",
      "          Validation Loss (standardized): 0.43574829309638624\n",
      "Final epoch: 100, Final loss (standarized): 0.40893239350035626\n",
      "Epoch: 1, Loss (standarized): 0.8095153471299348\n",
      "          Validation Loss (standardized): 0.7139510337059423\n",
      "Epoch: 6, Loss (standarized): 0.7936424769629937\n",
      "          Validation Loss (standardized): 0.7170527251712219\n",
      "Epoch: 11, Loss (standarized): 0.7800763607384745\n",
      "          Validation Loss (standardized): 0.6965204120295075\n",
      "Epoch: 16, Loss (standarized): 0.7685599864715972\n",
      "          Validation Loss (standardized): 0.6954654515408183\n",
      "Epoch: 21, Loss (standarized): 0.7543288442383245\n",
      "          Validation Loss (standardized): 0.6821316280877354\n",
      "Epoch: 26, Loss (standarized): 0.7367043223963098\n",
      "          Validation Loss (standardized): 0.6621881058949812\n",
      "Epoch: 31, Loss (standarized): 0.7145330963372636\n",
      "          Validation Loss (standardized): 0.6440263422859802\n",
      "Epoch: 36, Loss (standarized): 0.6937176841320546\n",
      "          Validation Loss (standardized): 0.6295034925702333\n",
      "Epoch: 41, Loss (standarized): 0.6782775272173727\n",
      "          Validation Loss (standardized): 0.6122950238328628\n",
      "Epoch: 46, Loss (standarized): 0.6680930153140574\n",
      "          Validation Loss (standardized): 0.6045862987291073\n",
      "Epoch: 51, Loss (standarized): 0.6604813835076403\n",
      "          Validation Loss (standardized): 0.6045205802442088\n",
      "Epoch: 56, Loss (standarized): 0.6561501393203837\n",
      "          Validation Loss (standardized): 0.602767653334375\n",
      "Epoch: 61, Loss (standarized): 0.6531199365126377\n",
      "          Validation Loss (standardized): 0.6011107131318272\n",
      "Epoch: 66, Loss (standarized): 0.6507818346211101\n",
      "          Validation Loss (standardized): 0.5967048821556017\n",
      "Epoch: 71, Loss (standarized): 0.6490393258393621\n",
      "          Validation Loss (standardized): 0.5962010464162557\n",
      "Epoch: 76, Loss (standarized): 0.6472327030044329\n",
      "          Validation Loss (standardized): 0.5975365917457502\n",
      "Epoch: 81, Loss (standarized): 0.6445948107681361\n",
      "          Validation Loss (standardized): 0.5921122024471869\n",
      "Epoch: 86, Loss (standarized): 0.6419560400199021\n",
      "          Validation Loss (standardized): 0.5889484981707404\n",
      "Epoch: 91, Loss (standarized): 0.6390694842895164\n",
      "          Validation Loss (standardized): 0.586854853429353\n",
      "Epoch: 96, Loss (standarized): 0.6359272187400717\n",
      "          Validation Loss (standardized): 0.5875597447045459\n",
      "Final epoch: 100, Final loss (standarized): 0.6332819074664708\n",
      "Epoch: 1, Loss (standarized): 0.8762987459701195\n",
      "          Validation Loss (standardized): 0.7153532081796145\n",
      "Epoch: 6, Loss (standarized): 0.7892018140630885\n",
      "          Validation Loss (standardized): 0.727676759276717\n",
      "Epoch: 11, Loss (standarized): 0.7558192001318359\n",
      "          Validation Loss (standardized): 0.6685853576177885\n",
      "Epoch: 16, Loss (standarized): 0.7289806604838974\n",
      "          Validation Loss (standardized): 0.6597308054223592\n",
      "Epoch: 21, Loss (standarized): 0.7064598332844519\n",
      "          Validation Loss (standardized): 0.6380271871949493\n",
      "Epoch: 26, Loss (standarized): 0.6817647675461748\n",
      "          Validation Loss (standardized): 0.6169648348263914\n",
      "Epoch: 31, Loss (standarized): 0.6637272569873537\n",
      "          Validation Loss (standardized): 0.6101720252332525\n",
      "Epoch: 36, Loss (standarized): 0.6515866927223009\n",
      "          Validation Loss (standardized): 0.5941612684011548\n",
      "Epoch: 41, Loss (standarized): 0.6418062750609053\n",
      "          Validation Loss (standardized): 0.5951310880200665\n",
      "Epoch: 46, Loss (standarized): 0.6324754311107662\n",
      "          Validation Loss (standardized): 0.5823010415510184\n",
      "Epoch: 51, Loss (standarized): 0.6222552974336204\n",
      "          Validation Loss (standardized): 0.578258796667874\n",
      "Epoch: 56, Loss (standarized): 0.6126855380979779\n",
      "          Validation Loss (standardized): 0.5692661756331074\n",
      "Epoch: 61, Loss (standarized): 0.6016332560532854\n",
      "          Validation Loss (standardized): 0.5613495561069136\n",
      "Epoch: 66, Loss (standarized): 0.5882694012402714\n",
      "          Validation Loss (standardized): 0.5489087052580465\n",
      "Epoch: 71, Loss (standarized): 0.5703583253169944\n",
      "          Validation Loss (standardized): 0.5364318509659758\n",
      "Epoch: 76, Loss (standarized): 0.5487712623162457\n",
      "          Validation Loss (standardized): 0.5171835089391414\n",
      "Epoch: 81, Loss (standarized): 0.5234289096803917\n",
      "          Validation Loss (standardized): 0.5027166922946352\n",
      "Epoch: 86, Loss (standarized): 0.4953314692336826\n",
      "          Validation Loss (standardized): 0.4795587585961455\n",
      "Epoch: 91, Loss (standarized): 0.4673055157703791\n",
      "          Validation Loss (standardized): 0.46527081260941805\n",
      "Epoch: 96, Loss (standarized): 0.4431247511552394\n",
      "          Validation Loss (standardized): 0.45299402432051317\n",
      "Final epoch: 100, Final loss (standarized): 0.42800743667484176\n",
      "Epoch: 1, Loss (standarized): 1.1247953298433209\n",
      "          Validation Loss (standardized): 0.7963272928389661\n",
      "Epoch: 6, Loss (standarized): 0.8746591830781221\n",
      "          Validation Loss (standardized): 0.7459110238521308\n",
      "Epoch: 11, Loss (standarized): 0.8018824175736544\n",
      "          Validation Loss (standardized): 0.7409133856957364\n",
      "Epoch: 16, Loss (standarized): 0.7826109222879616\n",
      "          Validation Loss (standardized): 0.7025985113786658\n",
      "Epoch: 21, Loss (standarized): 0.7504299692481776\n",
      "          Validation Loss (standardized): 0.6703032292069192\n",
      "Epoch: 26, Loss (standarized): 0.7293588090175729\n",
      "          Validation Loss (standardized): 0.659194211288413\n",
      "Epoch: 31, Loss (standarized): 0.7109091934525589\n",
      "          Validation Loss (standardized): 0.6453228269430952\n",
      "Epoch: 36, Loss (standarized): 0.692442330031567\n",
      "          Validation Loss (standardized): 0.6303428709517211\n",
      "Epoch: 41, Loss (standarized): 0.6758019430786141\n",
      "          Validation Loss (standardized): 0.6164069317056202\n",
      "Epoch: 46, Loss (standarized): 0.6607896060888263\n",
      "          Validation Loss (standardized): 0.6061052349491578\n",
      "Epoch: 51, Loss (standarized): 0.6464852724747032\n",
      "          Validation Loss (standardized): 0.5941511073496016\n",
      "Epoch: 56, Loss (standarized): 0.6322202503842028\n",
      "          Validation Loss (standardized): 0.5835342254554803\n",
      "Epoch: 61, Loss (standarized): 0.6181778904601075\n",
      "          Validation Loss (standardized): 0.5741265861110825\n",
      "Epoch: 66, Loss (standarized): 0.6032429010399788\n",
      "          Validation Loss (standardized): 0.5617224062745183\n",
      "Epoch: 71, Loss (standarized): 0.5869414930858807\n",
      "          Validation Loss (standardized): 0.5483319244553896\n",
      "Epoch: 76, Loss (standarized): 0.5705083033907911\n",
      "          Validation Loss (standardized): 0.5348197864065863\n",
      "Epoch: 81, Loss (standarized): 0.5527487127978216\n",
      "          Validation Loss (standardized): 0.5225670823654989\n",
      "Epoch: 86, Loss (standarized): 0.533612963367999\n",
      "          Validation Loss (standardized): 0.5062301593143068\n",
      "Epoch: 91, Loss (standarized): 0.5133692990494565\n",
      "          Validation Loss (standardized): 0.4914465560319212\n",
      "Epoch: 96, Loss (standarized): 0.49249528096865197\n",
      "          Validation Loss (standardized): 0.47697935284920917\n",
      "Final epoch: 100, Final loss (standarized): 0.47625454066805\n",
      "Epoch: 1, Loss (standarized): 1.032761077930727\n",
      "          Validation Loss (standardized): 0.7924246236470619\n",
      "Epoch: 6, Loss (standarized): 0.8462969776183147\n",
      "          Validation Loss (standardized): 0.730562224646414\n",
      "Epoch: 11, Loss (standarized): 0.751426398568276\n",
      "          Validation Loss (standardized): 0.6883933353567099\n",
      "Epoch: 16, Loss (standarized): 0.7205631093462014\n",
      "          Validation Loss (standardized): 0.6451106439765825\n",
      "Epoch: 21, Loss (standarized): 0.6670453607535284\n",
      "          Validation Loss (standardized): 0.604212110927017\n",
      "Epoch: 26, Loss (standarized): 0.6256729467102772\n",
      "          Validation Loss (standardized): 0.578292211299964\n",
      "Epoch: 31, Loss (standarized): 0.58448465065999\n",
      "          Validation Loss (standardized): 0.5424788823862259\n",
      "Epoch: 36, Loss (standarized): 0.5338449226682839\n",
      "          Validation Loss (standardized): 0.5133168177803945\n",
      "Epoch: 41, Loss (standarized): 0.48705579866964327\n",
      "          Validation Loss (standardized): 0.4835593399906534\n",
      "Epoch: 46, Loss (standarized): 0.44817164988080604\n",
      "          Validation Loss (standardized): 0.4630114422384432\n",
      "Epoch: 51, Loss (standarized): 0.4186977084804958\n",
      "          Validation Loss (standardized): 0.45448469556133647\n",
      "Epoch: 56, Loss (standarized): 0.4030577325459488\n",
      "          Validation Loss (standardized): 0.4511278636682768\n",
      "Epoch: 61, Loss (standarized): 0.3932055525778904\n",
      "          Validation Loss (standardized): 0.4495202388356709\n",
      "Epoch: 66, Loss (standarized): 0.3847618387253899\n",
      "          Validation Loss (standardized): 0.44148407489091573\n",
      "Epoch: 71, Loss (standarized): 0.37781033555604143\n",
      "          Validation Loss (standardized): 0.43086339276707375\n",
      "Epoch: 76, Loss (standarized): 0.3720263312516419\n",
      "          Validation Loss (standardized): 0.42275598541490583\n",
      "Epoch: 81, Loss (standarized): 0.3661762555233531\n",
      "          Validation Loss (standardized): 0.4179479612903795\n",
      "Epoch: 86, Loss (standarized): 0.3601201797474721\n",
      "          Validation Loss (standardized): 0.4131719804011959\n",
      "Epoch: 91, Loss (standarized): 0.3542970286110371\n",
      "          Validation Loss (standardized): 0.4075847826341845\n",
      "Epoch: 96, Loss (standarized): 0.34849273716524026\n",
      "          Validation Loss (standardized): 0.40002231922331766\n",
      "Final epoch: 100, Final loss (standarized): 0.34372874348060434\n",
      "Epoch: 1, Loss (standarized): 0.8194635820720155\n",
      "          Validation Loss (standardized): 0.7688438901417787\n",
      "Epoch: 6, Loss (standarized): 0.799202736636522\n",
      "          Validation Loss (standardized): 0.7082777845437149\n",
      "Epoch: 11, Loss (standarized): 0.7533321708067564\n",
      "          Validation Loss (standardized): 0.6684046331906224\n",
      "Epoch: 16, Loss (standarized): 0.6974728676975037\n",
      "          Validation Loss (standardized): 0.6318232645316784\n",
      "Epoch: 21, Loss (standarized): 0.6318725775126043\n",
      "          Validation Loss (standardized): 0.5791783835892123\n",
      "Epoch: 26, Loss (standarized): 0.5719428657805944\n",
      "          Validation Loss (standardized): 0.5384357331105405\n",
      "Epoch: 31, Loss (standarized): 0.5193708028822646\n",
      "          Validation Loss (standardized): 0.5014119306813761\n",
      "Epoch: 36, Loss (standarized): 0.4692666873011868\n",
      "          Validation Loss (standardized): 0.47602137811824674\n",
      "Epoch: 41, Loss (standarized): 0.4349642802911057\n",
      "          Validation Loss (standardized): 0.46109586358064847\n",
      "Epoch: 46, Loss (standarized): 0.41354376557062017\n",
      "          Validation Loss (standardized): 0.45661686407866403\n",
      "Epoch: 51, Loss (standarized): 0.40298151175962216\n",
      "          Validation Loss (standardized): 0.4500688833194345\n",
      "Epoch: 56, Loss (standarized): 0.39822904282703436\n",
      "          Validation Loss (standardized): 0.4500901063263372\n",
      "Epoch: 61, Loss (standarized): 0.39613894956268336\n",
      "          Validation Loss (standardized): 0.44809828077747765\n",
      "Epoch: 66, Loss (standarized): 0.39652052340879507\n",
      "          Validation Loss (standardized): 0.44279491835755935\n",
      "Epoch: 71, Loss (standarized): 0.39780986997260265\n",
      "          Validation Loss (standardized): 0.4406557808690478\n",
      "Epoch: 76, Loss (standarized): 0.39734594842434756\n",
      "          Validation Loss (standardized): 0.44048847317904416\n",
      "Epoch: 81, Loss (standarized): 0.39606507230266647\n",
      "          Validation Loss (standardized): 0.4399011071791798\n",
      "Epoch: 86, Loss (standarized): 0.39461041340717495\n",
      "          Validation Loss (standardized): 0.4386511320851156\n",
      "Epoch: 91, Loss (standarized): 0.3931097625148453\n",
      "          Validation Loss (standardized): 0.4378886954811579\n",
      "Epoch: 96, Loss (standarized): 0.39195767378474755\n",
      "          Validation Loss (standardized): 0.4372530827509024\n",
      "Final epoch: 100, Final loss (standarized): 0.39128854151652814\n",
      "Epoch: 1, Loss (standarized): 1.2989895342292854\n",
      "          Validation Loss (standardized): 1.0478959595088826\n",
      "Epoch: 6, Loss (standarized): 0.8169115665740023\n",
      "          Validation Loss (standardized): 0.7353118177213125\n",
      "Epoch: 11, Loss (standarized): 0.8357587190418234\n",
      "          Validation Loss (standardized): 0.7232781795654282\n",
      "Epoch: 16, Loss (standarized): 0.7853289081113239\n",
      "          Validation Loss (standardized): 0.7083790718733843\n",
      "Epoch: 21, Loss (standarized): 0.7804262603585591\n",
      "          Validation Loss (standardized): 0.7085772894490796\n",
      "Epoch: 26, Loss (standarized): 0.7515375983399781\n",
      "          Validation Loss (standardized): 0.6752975358446517\n",
      "Epoch: 31, Loss (standarized): 0.7198886716095293\n",
      "          Validation Loss (standardized): 0.6461790328588074\n",
      "Epoch: 36, Loss (standarized): 0.6917701326540794\n",
      "          Validation Loss (standardized): 0.6239071565037361\n",
      "Epoch: 41, Loss (standarized): 0.6610649761183695\n",
      "          Validation Loss (standardized): 0.605280820379965\n",
      "Epoch: 46, Loss (standarized): 0.6301475014503886\n",
      "          Validation Loss (standardized): 0.5775121283422752\n",
      "Epoch: 51, Loss (standarized): 0.5883252606692428\n",
      "          Validation Loss (standardized): 0.5472223213492841\n",
      "Epoch: 56, Loss (standarized): 0.5398286489620756\n",
      "          Validation Loss (standardized): 0.5144014867148003\n",
      "Epoch: 61, Loss (standarized): 0.4943796720040884\n",
      "          Validation Loss (standardized): 0.49079218738525526\n",
      "Epoch: 66, Loss (standarized): 0.45274763423031417\n",
      "          Validation Loss (standardized): 0.47322315970264944\n",
      "Epoch: 71, Loss (standarized): 0.426419624161644\n",
      "          Validation Loss (standardized): 0.4691376506368566\n",
      "Epoch: 76, Loss (standarized): 0.41271862152078154\n",
      "          Validation Loss (standardized): 0.4712774797879023\n",
      "Epoch: 81, Loss (standarized): 0.4042390040061249\n",
      "          Validation Loss (standardized): 0.4667143043489592\n",
      "Epoch: 86, Loss (standarized): 0.39702649561747966\n",
      "          Validation Loss (standardized): 0.4554571489749072\n",
      "Epoch: 91, Loss (standarized): 0.3909280096301545\n",
      "          Validation Loss (standardized): 0.44724619735651544\n",
      "Epoch: 96, Loss (standarized): 0.38493225941806836\n",
      "          Validation Loss (standardized): 0.44138427973133104\n",
      "Final epoch: 100, Final loss (standarized): 0.3806399749938184\n",
      "Epoch: 1, Loss (standarized): 1.6180821604800635\n",
      "          Validation Loss (standardized): 1.2154968606077614\n",
      "Epoch: 6, Loss (standarized): 0.8550928226667602\n",
      "          Validation Loss (standardized): 0.7985952394157991\n",
      "Epoch: 11, Loss (standarized): 0.8662851349374125\n",
      "          Validation Loss (standardized): 0.7231690488634382\n",
      "Epoch: 16, Loss (standarized): 0.7739102515269085\n",
      "          Validation Loss (standardized): 0.711293639810724\n",
      "Epoch: 21, Loss (standarized): 0.7739559109581101\n",
      "          Validation Loss (standardized): 0.7081034881038372\n",
      "Epoch: 26, Loss (standarized): 0.7137950991152072\n",
      "          Validation Loss (standardized): 0.6368155248843191\n",
      "Epoch: 31, Loss (standarized): 0.6812070160295229\n",
      "          Validation Loss (standardized): 0.6135971206143576\n",
      "Epoch: 36, Loss (standarized): 0.6351887505840244\n",
      "          Validation Loss (standardized): 0.581060352072952\n",
      "Epoch: 41, Loss (standarized): 0.5983226607254578\n",
      "          Validation Loss (standardized): 0.5613094125274857\n",
      "Epoch: 46, Loss (standarized): 0.5593098387029493\n",
      "          Validation Loss (standardized): 0.5318672954264361\n",
      "Epoch: 51, Loss (standarized): 0.525737611484196\n",
      "          Validation Loss (standardized): 0.5151044331085718\n",
      "Epoch: 56, Loss (standarized): 0.49447873388037983\n",
      "          Validation Loss (standardized): 0.4997999423115658\n",
      "Epoch: 61, Loss (standarized): 0.47171615433041614\n",
      "          Validation Loss (standardized): 0.4911625509120123\n",
      "Epoch: 66, Loss (standarized): 0.4533697630491698\n",
      "          Validation Loss (standardized): 0.48462486931398274\n",
      "Epoch: 71, Loss (standarized): 0.43806419949742487\n",
      "          Validation Loss (standardized): 0.47716110147899843\n",
      "Epoch: 76, Loss (standarized): 0.4258225015611135\n",
      "          Validation Loss (standardized): 0.4688897305729279\n",
      "Epoch: 81, Loss (standarized): 0.41599215615794927\n",
      "          Validation Loss (standardized): 0.4606100306437111\n",
      "Epoch: 86, Loss (standarized): 0.40766877759450004\n",
      "          Validation Loss (standardized): 0.45433205891679734\n",
      "Epoch: 91, Loss (standarized): 0.39983038591330616\n",
      "          Validation Loss (standardized): 0.449794504832112\n",
      "Epoch: 96, Loss (standarized): 0.3927146258075401\n",
      "          Validation Loss (standardized): 0.44371247547141535\n",
      "Final epoch: 100, Final loss (standarized): 0.3872545218847426\n",
      "Epoch: 1, Loss (standarized): 0.9799627224658582\n",
      "          Validation Loss (standardized): 0.7424014619100291\n",
      "Epoch: 6, Loss (standarized): 0.816024883301665\n",
      "          Validation Loss (standardized): 0.7002783774320211\n",
      "Epoch: 11, Loss (standarized): 0.7342278704940206\n",
      "          Validation Loss (standardized): 0.6739200138116601\n",
      "Epoch: 16, Loss (standarized): 0.660621645858728\n",
      "          Validation Loss (standardized): 0.5874947449289118\n",
      "Epoch: 21, Loss (standarized): 0.5983397268542817\n",
      "          Validation Loss (standardized): 0.5655380752032869\n",
      "Epoch: 26, Loss (standarized): 0.5366159671931394\n",
      "          Validation Loss (standardized): 0.5055825897067863\n",
      "Epoch: 31, Loss (standarized): 0.4812305213923363\n",
      "          Validation Loss (standardized): 0.49120520758931296\n",
      "Epoch: 36, Loss (standarized): 0.43933686200271793\n",
      "          Validation Loss (standardized): 0.4697452629538864\n",
      "Epoch: 41, Loss (standarized): 0.4221639381204397\n",
      "          Validation Loss (standardized): 0.4894472501344291\n",
      "Epoch: 46, Loss (standarized): 0.4150072894685531\n",
      "          Validation Loss (standardized): 0.4853292517539256\n",
      "Epoch: 51, Loss (standarized): 0.41091298399733384\n",
      "          Validation Loss (standardized): 0.49458702245923575\n",
      "Epoch: 56, Loss (standarized): 0.4015263951497916\n",
      "          Validation Loss (standardized): 0.467349223159266\n",
      "Epoch: 61, Loss (standarized): 0.39564874800634975\n",
      "          Validation Loss (standardized): 0.4525178576826481\n",
      "Epoch: 66, Loss (standarized): 0.3905099379547597\n",
      "          Validation Loss (standardized): 0.4492531955118166\n",
      "Epoch: 71, Loss (standarized): 0.3835759442298312\n",
      "          Validation Loss (standardized): 0.441362818645\n",
      "Epoch: 76, Loss (standarized): 0.3768750832049036\n",
      "          Validation Loss (standardized): 0.43825448846580284\n",
      "Epoch: 81, Loss (standarized): 0.36966406490695103\n",
      "          Validation Loss (standardized): 0.42995714834413223\n",
      "Epoch: 86, Loss (standarized): 0.36171516706834134\n",
      "          Validation Loss (standardized): 0.41453425203942873\n",
      "Epoch: 91, Loss (standarized): 0.35343550310346233\n",
      "          Validation Loss (standardized): 0.40149724592033564\n",
      "Epoch: 96, Loss (standarized): 0.34438441229143846\n",
      "          Validation Loss (standardized): 0.39262263115454615\n",
      "Final epoch: 100, Final loss (standarized): 0.3368026717607656\n",
      "Epoch: 1, Loss (standarized): 0.8828902630752505\n",
      "          Validation Loss (standardized): 0.7174491473036296\n",
      "Epoch: 6, Loss (standarized): 0.7975425002436756\n",
      "          Validation Loss (standardized): 0.7376796014144571\n",
      "Epoch: 11, Loss (standarized): 0.747878157698139\n",
      "          Validation Loss (standardized): 0.6564419907346805\n",
      "Epoch: 16, Loss (standarized): 0.6861193148652692\n",
      "          Validation Loss (standardized): 0.6320652653879827\n",
      "Epoch: 21, Loss (standarized): 0.6234560280445803\n",
      "          Validation Loss (standardized): 0.5644031815330974\n",
      "Epoch: 26, Loss (standarized): 0.5673986273235019\n",
      "          Validation Loss (standardized): 0.5434569400858098\n",
      "Epoch: 31, Loss (standarized): 0.5173814724853972\n",
      "          Validation Loss (standardized): 0.49980970442323697\n",
      "Epoch: 36, Loss (standarized): 0.4733624111177632\n",
      "          Validation Loss (standardized): 0.48206542128207813\n",
      "Epoch: 41, Loss (standarized): 0.44410337407268036\n",
      "          Validation Loss (standardized): 0.46417439004849703\n",
      "Epoch: 46, Loss (standarized): 0.4214743337023242\n",
      "          Validation Loss (standardized): 0.4555753214081847\n",
      "Epoch: 51, Loss (standarized): 0.4093418967016699\n",
      "          Validation Loss (standardized): 0.4567836592523325\n",
      "Epoch: 56, Loss (standarized): 0.4018380895726672\n",
      "          Validation Loss (standardized): 0.45451240194571585\n",
      "Epoch: 61, Loss (standarized): 0.39864360807405286\n",
      "          Validation Loss (standardized): 0.4516940940556654\n",
      "Epoch: 66, Loss (standarized): 0.39761344408266475\n",
      "          Validation Loss (standardized): 0.45323090984262576\n",
      "Epoch: 71, Loss (standarized): 0.39784550920256334\n",
      "          Validation Loss (standardized): 0.4490778353166103\n",
      "Epoch: 76, Loss (standarized): 0.3978982848705604\n",
      "          Validation Loss (standardized): 0.447156491958755\n",
      "Epoch: 81, Loss (standarized): 0.39781036623171545\n",
      "          Validation Loss (standardized): 0.44546523750710676\n",
      "Epoch: 86, Loss (standarized): 0.3970049032382601\n",
      "          Validation Loss (standardized): 0.44241838241286985\n",
      "Epoch: 91, Loss (standarized): 0.3951993651639682\n",
      "          Validation Loss (standardized): 0.4404021926708227\n",
      "Epoch: 96, Loss (standarized): 0.3928361920572502\n",
      "          Validation Loss (standardized): 0.4383026236822183\n",
      "Final epoch: 100, Final loss (standarized): 0.3908171667429766\n",
      "Epoch: 1, Loss (standarized): 0.9019983302856879\n",
      "          Validation Loss (standardized): 0.7294371463042224\n",
      "Epoch: 6, Loss (standarized): 0.8009025785007712\n",
      "          Validation Loss (standardized): 0.7296204911807422\n",
      "Epoch: 11, Loss (standarized): 0.7539985999247677\n",
      "          Validation Loss (standardized): 0.6614584761718619\n",
      "Epoch: 16, Loss (standarized): 0.6916709448929824\n",
      "          Validation Loss (standardized): 0.6267556779129012\n",
      "Epoch: 21, Loss (standarized): 0.616257935346594\n",
      "          Validation Loss (standardized): 0.5564014624098016\n",
      "Epoch: 26, Loss (standarized): 0.5409240830695359\n",
      "          Validation Loss (standardized): 0.5224287140596651\n",
      "Epoch: 31, Loss (standarized): 0.47375907353725316\n",
      "          Validation Loss (standardized): 0.470427727168653\n",
      "Epoch: 36, Loss (standarized): 0.42727037930002076\n",
      "          Validation Loss (standardized): 0.47297391585978416\n",
      "Epoch: 41, Loss (standarized): 0.4135582951811327\n",
      "          Validation Loss (standardized): 0.47814350498530334\n",
      "Epoch: 46, Loss (standarized): 0.40441507540663524\n",
      "          Validation Loss (standardized): 0.4884226182065376\n",
      "Epoch: 51, Loss (standarized): 0.4000810590530481\n",
      "          Validation Loss (standardized): 0.47414447650785696\n",
      "Epoch: 56, Loss (standarized): 0.3894733401461555\n",
      "          Validation Loss (standardized): 0.45719963735128494\n",
      "Epoch: 61, Loss (standarized): 0.3831673853355599\n",
      "          Validation Loss (standardized): 0.4405805016371801\n",
      "Epoch: 66, Loss (standarized): 0.37834988294585276\n",
      "          Validation Loss (standardized): 0.43011642313631093\n",
      "Epoch: 71, Loss (standarized): 0.37194314166144543\n",
      "          Validation Loss (standardized): 0.42457867739178773\n",
      "Epoch: 76, Loss (standarized): 0.36526646642291033\n",
      "          Validation Loss (standardized): 0.4183768415977609\n",
      "Epoch: 81, Loss (standarized): 0.358542636662742\n",
      "          Validation Loss (standardized): 0.4136806858932757\n",
      "Epoch: 86, Loss (standarized): 0.3512290484986482\n",
      "          Validation Loss (standardized): 0.40455690949368156\n",
      "Epoch: 91, Loss (standarized): 0.34337830025692034\n",
      "          Validation Loss (standardized): 0.39236194203799635\n",
      "Epoch: 96, Loss (standarized): 0.33514532197498664\n",
      "          Validation Loss (standardized): 0.3814277667755837\n",
      "Final epoch: 100, Final loss (standarized): 0.32806750907740334\n",
      "Epoch: 1, Loss (standarized): 1.2887293294529911\n",
      "          Validation Loss (standardized): 0.8465654137041112\n",
      "Epoch: 6, Loss (standarized): 0.9220540695104138\n",
      "          Validation Loss (standardized): 0.7739323812460454\n",
      "Epoch: 11, Loss (standarized): 0.7474070679191704\n",
      "          Validation Loss (standardized): 0.7015597917847449\n",
      "Epoch: 16, Loss (standarized): 0.7031532544997598\n",
      "          Validation Loss (standardized): 0.6219834633426441\n",
      "Epoch: 21, Loss (standarized): 0.6516537044071675\n",
      "          Validation Loss (standardized): 0.5941965701501173\n",
      "Epoch: 26, Loss (standarized): 0.5897634790818588\n",
      "          Validation Loss (standardized): 0.5502822882997183\n",
      "Epoch: 31, Loss (standarized): 0.5578750278778042\n",
      "          Validation Loss (standardized): 0.5266616233834729\n",
      "Epoch: 36, Loss (standarized): 0.5105934930893967\n",
      "          Validation Loss (standardized): 0.5054338228884028\n",
      "Epoch: 41, Loss (standarized): 0.4735406660577223\n",
      "          Validation Loss (standardized): 0.4838988438090405\n",
      "Epoch: 46, Loss (standarized): 0.4498904999259226\n",
      "          Validation Loss (standardized): 0.4810790267362042\n",
      "Epoch: 51, Loss (standarized): 0.4326748796133474\n",
      "          Validation Loss (standardized): 0.48335866429897156\n",
      "Epoch: 56, Loss (standarized): 0.42033642938283144\n",
      "          Validation Loss (standardized): 0.47913041565580383\n",
      "Epoch: 61, Loss (standarized): 0.4109884467823829\n",
      "          Validation Loss (standardized): 0.4757129015652376\n",
      "Epoch: 66, Loss (standarized): 0.40203267707557105\n",
      "          Validation Loss (standardized): 0.46219570008396005\n",
      "Epoch: 71, Loss (standarized): 0.39540518785657575\n",
      "          Validation Loss (standardized): 0.45328521656777454\n",
      "Epoch: 76, Loss (standarized): 0.38974755618988566\n",
      "          Validation Loss (standardized): 0.4464475150682905\n",
      "Epoch: 81, Loss (standarized): 0.3836798420064793\n",
      "          Validation Loss (standardized): 0.4418262019447753\n",
      "Epoch: 86, Loss (standarized): 0.37748596889819214\n",
      "          Validation Loss (standardized): 0.4370443119823759\n",
      "Epoch: 91, Loss (standarized): 0.37137972020158555\n",
      "          Validation Loss (standardized): 0.4317976793197547\n",
      "Epoch: 96, Loss (standarized): 0.3650549645352753\n",
      "          Validation Loss (standardized): 0.4229509761375493\n",
      "Final epoch: 100, Final loss (standarized): 0.35988386654136145\n",
      "Epoch: 1, Loss (standarized): 1.0329786046980844\n",
      "          Validation Loss (standardized): 0.7687833219979657\n",
      "Epoch: 6, Loss (standarized): 0.8479117417297217\n",
      "          Validation Loss (standardized): 0.716566820140325\n",
      "Epoch: 11, Loss (standarized): 0.7878167584131963\n",
      "          Validation Loss (standardized): 0.7200396241097715\n",
      "Epoch: 16, Loss (standarized): 0.7070215960818256\n",
      "          Validation Loss (standardized): 0.6318862655538255\n",
      "Epoch: 21, Loss (standarized): 0.6445134095082478\n",
      "          Validation Loss (standardized): 0.5884847663800322\n",
      "Epoch: 26, Loss (standarized): 0.5806124681881473\n",
      "          Validation Loss (standardized): 0.5424301077236113\n",
      "Epoch: 31, Loss (standarized): 0.5161407450229406\n",
      "          Validation Loss (standardized): 0.510065721227616\n",
      "Epoch: 36, Loss (standarized): 0.46110203082399026\n",
      "          Validation Loss (standardized): 0.48534005459649904\n",
      "Epoch: 41, Loss (standarized): 0.4345133498301301\n",
      "          Validation Loss (standardized): 0.4905763324951101\n",
      "Epoch: 46, Loss (standarized): 0.4223104220978572\n",
      "          Validation Loss (standardized): 0.49139462990221433\n",
      "Epoch: 51, Loss (standarized): 0.4121621691831582\n",
      "          Validation Loss (standardized): 0.485461797690842\n",
      "Epoch: 56, Loss (standarized): 0.39936943353875715\n",
      "          Validation Loss (standardized): 0.46394398414524496\n",
      "Epoch: 61, Loss (standarized): 0.394263191713654\n",
      "          Validation Loss (standardized): 0.45258341976682276\n",
      "Epoch: 66, Loss (standarized): 0.3877709882393332\n",
      "          Validation Loss (standardized): 0.45172602928180666\n",
      "Epoch: 71, Loss (standarized): 0.3805826761176018\n",
      "          Validation Loss (standardized): 0.4512011107204924\n",
      "Epoch: 76, Loss (standarized): 0.37470333677905143\n",
      "          Validation Loss (standardized): 0.4443318391317614\n",
      "Epoch: 81, Loss (standarized): 0.36747894164370754\n",
      "          Validation Loss (standardized): 0.43204013638980093\n",
      "Epoch: 86, Loss (standarized): 0.36049696242202095\n",
      "          Validation Loss (standardized): 0.42228212414337546\n",
      "Epoch: 91, Loss (standarized): 0.3525885797369722\n",
      "          Validation Loss (standardized): 0.415376378397713\n",
      "Epoch: 96, Loss (standarized): 0.3443733090718435\n",
      "          Validation Loss (standardized): 0.4051604379686108\n",
      "Final epoch: 100, Final loss (standarized): 0.33716721983040204\n",
      "Epoch: 1, Loss (standarized): 0.8032253176461863\n",
      "          Validation Loss (standardized): 0.7019920910310286\n",
      "Epoch: 6, Loss (standarized): 0.7442942814655715\n",
      "          Validation Loss (standardized): 0.6671928303692702\n",
      "Epoch: 11, Loss (standarized): 0.65406017030261\n",
      "          Validation Loss (standardized): 0.590710169338144\n",
      "Epoch: 16, Loss (standarized): 0.5511914603315281\n",
      "          Validation Loss (standardized): 0.5261891620883417\n",
      "Epoch: 21, Loss (standarized): 0.46948524133149017\n",
      "          Validation Loss (standardized): 0.4785949293473177\n",
      "Epoch: 26, Loss (standarized): 0.42516201470015363\n",
      "          Validation Loss (standardized): 0.47104061798584257\n",
      "Epoch: 31, Loss (standarized): 0.4061092739445936\n",
      "          Validation Loss (standardized): 0.4707258701649531\n",
      "Epoch: 36, Loss (standarized): 0.40272882841969804\n",
      "          Validation Loss (standardized): 0.4704284429056857\n",
      "Epoch: 41, Loss (standarized): 0.4034489884582021\n",
      "          Validation Loss (standardized): 0.4665401625515207\n",
      "Epoch: 46, Loss (standarized): 0.40633029516750324\n",
      "          Validation Loss (standardized): 0.46077278551237755\n",
      "Epoch: 51, Loss (standarized): 0.4098640785837893\n",
      "          Validation Loss (standardized): 0.4572155555504061\n",
      "Epoch: 56, Loss (standarized): 0.41120968802262076\n",
      "          Validation Loss (standardized): 0.45733877095437747\n",
      "Epoch: 61, Loss (standarized): 0.40958605175847324\n",
      "          Validation Loss (standardized): 0.459190503361145\n",
      "Epoch: 66, Loss (standarized): 0.40635789989619486\n",
      "          Validation Loss (standardized): 0.45979673315868425\n",
      "Epoch: 71, Loss (standarized): 0.4044002931024355\n",
      "          Validation Loss (standardized): 0.45952989812363454\n",
      "Epoch: 76, Loss (standarized): 0.4037292400030984\n",
      "          Validation Loss (standardized): 0.45768050819918515\n",
      "Epoch: 81, Loss (standarized): 0.40307227761942777\n",
      "          Validation Loss (standardized): 0.45486309822107146\n",
      "Epoch: 86, Loss (standarized): 0.40153032491018636\n",
      "          Validation Loss (standardized): 0.4517465303251679\n",
      "Epoch: 91, Loss (standarized): 0.3989232853343238\n",
      "          Validation Loss (standardized): 0.4488156427416516\n",
      "Epoch: 96, Loss (standarized): 0.39538812736951956\n",
      "          Validation Loss (standardized): 0.44575898714355844\n",
      "Final epoch: 100, Final loss (standarized): 0.39242935884106867\n",
      "Epoch: 1, Loss (standarized): 0.9174022622272172\n",
      "          Validation Loss (standardized): 0.7042275404445248\n",
      "Epoch: 6, Loss (standarized): 0.7808601302794076\n",
      "          Validation Loss (standardized): 0.7026218423061014\n",
      "Epoch: 11, Loss (standarized): 0.7443085917410068\n",
      "          Validation Loss (standardized): 0.655066398182006\n",
      "Epoch: 16, Loss (standarized): 0.6785511921806202\n",
      "          Validation Loss (standardized): 0.6223328228325845\n",
      "Epoch: 21, Loss (standarized): 0.5979237040360547\n",
      "          Validation Loss (standardized): 0.5551824365846351\n",
      "Epoch: 26, Loss (standarized): 0.5298939087890746\n",
      "          Validation Loss (standardized): 0.5212926373574136\n",
      "Epoch: 31, Loss (standarized): 0.47573974640055783\n",
      "          Validation Loss (standardized): 0.48143010233031286\n",
      "Epoch: 36, Loss (standarized): 0.4329653718060563\n",
      "          Validation Loss (standardized): 0.4857108894105559\n",
      "Epoch: 41, Loss (standarized): 0.42080473591339385\n",
      "          Validation Loss (standardized): 0.4869911692625725\n",
      "Epoch: 46, Loss (standarized): 0.41757302872763535\n",
      "          Validation Loss (standardized): 0.5090808295668322\n",
      "Epoch: 51, Loss (standarized): 0.4145953082969072\n",
      "          Validation Loss (standardized): 0.5045675913395928\n",
      "Epoch: 56, Loss (standarized): 0.4102373033552026\n",
      "          Validation Loss (standardized): 0.4889111388535787\n",
      "Epoch: 61, Loss (standarized): 0.40478375995631255\n",
      "          Validation Loss (standardized): 0.4838925865778014\n",
      "Epoch: 66, Loss (standarized): 0.4009620623365662\n",
      "          Validation Loss (standardized): 0.46943325563999166\n",
      "Epoch: 71, Loss (standarized): 0.3975486906203602\n",
      "          Validation Loss (standardized): 0.460096043063651\n",
      "Epoch: 76, Loss (standarized): 0.3935640515877341\n",
      "          Validation Loss (standardized): 0.45761272506022527\n",
      "Epoch: 81, Loss (standarized): 0.38878794778200343\n",
      "          Validation Loss (standardized): 0.4510575752802211\n",
      "Epoch: 86, Loss (standarized): 0.3835646656389217\n",
      "          Validation Loss (standardized): 0.447056325017225\n",
      "Epoch: 91, Loss (standarized): 0.37825502265980954\n",
      "          Validation Loss (standardized): 0.44264958789703696\n",
      "Epoch: 96, Loss (standarized): 0.3726278976778284\n",
      "          Validation Loss (standardized): 0.4344059123370965\n",
      "Final epoch: 100, Final loss (standarized): 0.36793787709264125\n",
      "Epoch: 1, Loss (standarized): 1.028138067525593\n",
      "          Validation Loss (standardized): 0.822530421278795\n",
      "Epoch: 6, Loss (standarized): 0.8304364214232113\n",
      "          Validation Loss (standardized): 0.7347763423745499\n",
      "Epoch: 11, Loss (standarized): 0.7476484928864563\n",
      "          Validation Loss (standardized): 0.6680416533905407\n",
      "Epoch: 16, Loss (standarized): 0.7104554625947871\n",
      "          Validation Loss (standardized): 0.6464405821319275\n",
      "Epoch: 21, Loss (standarized): 0.6467536119620889\n",
      "          Validation Loss (standardized): 0.5853734315775339\n",
      "Epoch: 26, Loss (standarized): 0.5972581818939403\n",
      "          Validation Loss (standardized): 0.5604840625303673\n",
      "Epoch: 31, Loss (standarized): 0.5369016276888297\n",
      "          Validation Loss (standardized): 0.5103411389937428\n",
      "Epoch: 36, Loss (standarized): 0.483793673297773\n",
      "          Validation Loss (standardized): 0.4763818638211522\n",
      "Epoch: 41, Loss (standarized): 0.44284606081192496\n",
      "          Validation Loss (standardized): 0.47020769655314076\n",
      "Epoch: 46, Loss (standarized): 0.40900453205628506\n",
      "          Validation Loss (standardized): 0.4470298023878746\n",
      "Epoch: 51, Loss (standarized): 0.39644044265051953\n",
      "          Validation Loss (standardized): 0.46176551764193563\n",
      "Epoch: 56, Loss (standarized): 0.39079193716028415\n",
      "          Validation Loss (standardized): 0.4706550644219684\n",
      "Epoch: 61, Loss (standarized): 0.38485663536145986\n",
      "          Validation Loss (standardized): 0.45521375579843715\n",
      "Epoch: 66, Loss (standarized): 0.37655437839036887\n",
      "          Validation Loss (standardized): 0.4433968663180247\n",
      "Epoch: 71, Loss (standarized): 0.36973467792245474\n",
      "          Validation Loss (standardized): 0.42860795690085174\n",
      "Epoch: 76, Loss (standarized): 0.36442981968998384\n",
      "          Validation Loss (standardized): 0.4153995873774562\n",
      "Epoch: 81, Loss (standarized): 0.357982551536811\n",
      "          Validation Loss (standardized): 0.410050130121641\n",
      "Epoch: 86, Loss (standarized): 0.3511596743774737\n",
      "          Validation Loss (standardized): 0.40611728915541667\n",
      "Epoch: 91, Loss (standarized): 0.34451881396982476\n",
      "          Validation Loss (standardized): 0.39754957105389904\n",
      "Epoch: 96, Loss (standarized): 0.337069989345366\n",
      "          Validation Loss (standardized): 0.38548004169898337\n",
      "Final epoch: 100, Final loss (standarized): 0.33055337112796457\n",
      "Epoch: 1, Loss (standarized): 1.170643341077198\n",
      "          Validation Loss (standardized): 0.8565819005058066\n",
      "Epoch: 6, Loss (standarized): 0.8401093441636975\n",
      "          Validation Loss (standardized): 0.7445761484111887\n",
      "Epoch: 11, Loss (standarized): 0.750366755574011\n",
      "          Validation Loss (standardized): 0.6702693675126679\n",
      "Epoch: 16, Loss (standarized): 0.7417239202828807\n",
      "          Validation Loss (standardized): 0.6781497280977312\n",
      "Epoch: 21, Loss (standarized): 0.7072116011952965\n",
      "          Validation Loss (standardized): 0.6393702511541687\n",
      "Epoch: 26, Loss (standarized): 0.6896699069627872\n",
      "          Validation Loss (standardized): 0.6252415959709536\n",
      "Epoch: 31, Loss (standarized): 0.672624566210749\n",
      "          Validation Loss (standardized): 0.609914836737617\n",
      "Epoch: 36, Loss (standarized): 0.6594866523274541\n",
      "          Validation Loss (standardized): 0.6050170220882339\n",
      "Epoch: 41, Loss (standarized): 0.6502582551459654\n",
      "          Validation Loss (standardized): 0.5968261844729585\n",
      "Epoch: 46, Loss (standarized): 0.6413208595915357\n",
      "          Validation Loss (standardized): 0.5913010965994252\n",
      "Epoch: 51, Loss (standarized): 0.63230483943217\n",
      "          Validation Loss (standardized): 0.5835942678379044\n",
      "Epoch: 56, Loss (standarized): 0.6234909429909191\n",
      "          Validation Loss (standardized): 0.5771695273599191\n",
      "Epoch: 61, Loss (standarized): 0.6145206296518133\n",
      "          Validation Loss (standardized): 0.571450069682774\n",
      "Epoch: 66, Loss (standarized): 0.6053696578341271\n",
      "          Validation Loss (standardized): 0.5620929162037391\n",
      "Epoch: 71, Loss (standarized): 0.5947588081077833\n",
      "          Validation Loss (standardized): 0.5551560938110914\n",
      "Epoch: 76, Loss (standarized): 0.5832599146004451\n",
      "          Validation Loss (standardized): 0.5474198053289985\n",
      "Epoch: 81, Loss (standarized): 0.5691445555307255\n",
      "          Validation Loss (standardized): 0.5379325302339538\n",
      "Epoch: 86, Loss (standarized): 0.5529257471411646\n",
      "          Validation Loss (standardized): 0.5268760778403777\n",
      "Epoch: 91, Loss (standarized): 0.5343186813908779\n",
      "          Validation Loss (standardized): 0.5128126522676036\n",
      "Epoch: 96, Loss (standarized): 0.5150469558843097\n",
      "          Validation Loss (standardized): 0.504775826071337\n",
      "Final epoch: 100, Final loss (standarized): 0.49939478298245793\n",
      "Epoch: 1, Loss (standarized): 1.2048164282484475\n",
      "          Validation Loss (standardized): 0.8657263142910849\n",
      "Epoch: 6, Loss (standarized): 0.8513754317497686\n",
      "          Validation Loss (standardized): 0.7587230482462851\n",
      "Epoch: 11, Loss (standarized): 0.7584482624117201\n",
      "          Validation Loss (standardized): 0.6720038227654634\n",
      "Epoch: 16, Loss (standarized): 0.7553537535933625\n",
      "          Validation Loss (standardized): 0.6973607533183005\n",
      "Epoch: 21, Loss (standarized): 0.7223809916821257\n",
      "          Validation Loss (standardized): 0.6521415551160604\n",
      "Epoch: 26, Loss (standarized): 0.7020292235746372\n",
      "          Validation Loss (standardized): 0.63334840011298\n",
      "Epoch: 31, Loss (standarized): 0.689252840836652\n",
      "          Validation Loss (standardized): 0.625965661502223\n",
      "Epoch: 36, Loss (standarized): 0.6779538234651108\n",
      "          Validation Loss (standardized): 0.6205186070912709\n",
      "Epoch: 41, Loss (standarized): 0.6712762683344828\n",
      "          Validation Loss (standardized): 0.6167451252798312\n",
      "Epoch: 46, Loss (standarized): 0.6643923293497581\n",
      "          Validation Loss (standardized): 0.6112743777218155\n",
      "Epoch: 51, Loss (standarized): 0.6582981742959794\n",
      "          Validation Loss (standardized): 0.6046290911430264\n",
      "Epoch: 56, Loss (standarized): 0.652679727759035\n",
      "          Validation Loss (standardized): 0.6000429150797143\n",
      "Epoch: 61, Loss (standarized): 0.6469661143347966\n",
      "          Validation Loss (standardized): 0.5958348460931792\n",
      "Epoch: 66, Loss (standarized): 0.6410275117328139\n",
      "          Validation Loss (standardized): 0.5936088521721773\n",
      "Epoch: 71, Loss (standarized): 0.6341427272085424\n",
      "          Validation Loss (standardized): 0.5867333847068508\n",
      "Epoch: 76, Loss (standarized): 0.6272564190042711\n",
      "          Validation Loss (standardized): 0.5818551018744917\n",
      "Epoch: 81, Loss (standarized): 0.6200715256912859\n",
      "          Validation Loss (standardized): 0.5758544718501262\n",
      "Epoch: 86, Loss (standarized): 0.6119893400342364\n",
      "          Validation Loss (standardized): 0.5721486418030268\n",
      "Epoch: 91, Loss (standarized): 0.6025285997785109\n",
      "          Validation Loss (standardized): 0.5634206304956763\n",
      "Epoch: 96, Loss (standarized): 0.5913133291258631\n",
      "          Validation Loss (standardized): 0.5552315279755988\n",
      "Final epoch: 100, Final loss (standarized): 0.5813798236913892\n",
      "Epoch: 1, Loss (standarized): 0.9860284665645598\n",
      "          Validation Loss (standardized): 0.7436854636012958\n",
      "Epoch: 6, Loss (standarized): 0.8295805228507833\n",
      "          Validation Loss (standardized): 0.7177338782302687\n",
      "Epoch: 11, Loss (standarized): 0.7948451653235841\n",
      "          Validation Loss (standardized): 0.7250634672997556\n",
      "Epoch: 16, Loss (standarized): 0.7646139693486663\n",
      "          Validation Loss (standardized): 0.686456820836812\n",
      "Epoch: 21, Loss (standarized): 0.7479314764468128\n",
      "          Validation Loss (standardized): 0.6687605486636882\n",
      "Epoch: 26, Loss (standarized): 0.7264137847887845\n",
      "          Validation Loss (standardized): 0.6619585866715731\n",
      "Epoch: 31, Loss (standarized): 0.7095840377321135\n",
      "          Validation Loss (standardized): 0.6438819328246774\n",
      "Epoch: 36, Loss (standarized): 0.6910753618950319\n",
      "          Validation Loss (standardized): 0.6302779455007088\n",
      "Epoch: 41, Loss (standarized): 0.6751239274953585\n",
      "          Validation Loss (standardized): 0.6161532845431138\n",
      "Epoch: 46, Loss (standarized): 0.6602953585972957\n",
      "          Validation Loss (standardized): 0.6042652277867042\n",
      "Epoch: 51, Loss (standarized): 0.6467386152890837\n",
      "          Validation Loss (standardized): 0.5971076281453833\n",
      "Epoch: 56, Loss (standarized): 0.6320801042983201\n",
      "          Validation Loss (standardized): 0.5833350430487504\n",
      "Epoch: 61, Loss (standarized): 0.6162229555131243\n",
      "          Validation Loss (standardized): 0.5717819018160805\n",
      "Epoch: 66, Loss (standarized): 0.5985689762505306\n",
      "          Validation Loss (standardized): 0.5580530386935613\n",
      "Epoch: 71, Loss (standarized): 0.5797614851154004\n",
      "          Validation Loss (standardized): 0.54306207783972\n",
      "Epoch: 76, Loss (standarized): 0.558943137577193\n",
      "          Validation Loss (standardized): 0.5284684738406772\n",
      "Epoch: 81, Loss (standarized): 0.5357563710579664\n",
      "          Validation Loss (standardized): 0.5092164297839266\n",
      "Epoch: 86, Loss (standarized): 0.5116827208525065\n",
      "          Validation Loss (standardized): 0.49145699173043444\n",
      "Epoch: 91, Loss (standarized): 0.4876787806031849\n",
      "          Validation Loss (standardized): 0.4765515369962878\n",
      "Epoch: 96, Loss (standarized): 0.4655340678044914\n",
      "          Validation Loss (standardized): 0.46227137388480144\n",
      "Final epoch: 100, Final loss (standarized): 0.4501231797551137\n",
      "Epoch: 1, Loss (standarized): 0.9298718463327621\n",
      "          Validation Loss (standardized): 0.7687533608549276\n",
      "Epoch: 6, Loss (standarized): 0.8255223956984636\n",
      "          Validation Loss (standardized): 0.7286268656700778\n",
      "Epoch: 11, Loss (standarized): 0.8091148286456097\n",
      "          Validation Loss (standardized): 0.7335254045993109\n",
      "Epoch: 16, Loss (standarized): 0.7974942985303279\n",
      "          Validation Loss (standardized): 0.7193401064645306\n",
      "Epoch: 21, Loss (standarized): 0.7752445480594783\n",
      "          Validation Loss (standardized): 0.6925173690790493\n",
      "Epoch: 26, Loss (standarized): 0.7564154531331065\n",
      "          Validation Loss (standardized): 0.678605036643844\n",
      "Epoch: 31, Loss (standarized): 0.738383787146809\n",
      "          Validation Loss (standardized): 0.6644548908578852\n",
      "Epoch: 36, Loss (standarized): 0.7210482051321062\n",
      "          Validation Loss (standardized): 0.6490197791359966\n",
      "Epoch: 41, Loss (standarized): 0.7053961028422945\n",
      "          Validation Loss (standardized): 0.6384087422694421\n",
      "Epoch: 46, Loss (standarized): 0.6918883921527421\n",
      "          Validation Loss (standardized): 0.6281794618415047\n",
      "Epoch: 51, Loss (standarized): 0.6809715918028332\n",
      "          Validation Loss (standardized): 0.6194936678185057\n",
      "Epoch: 56, Loss (standarized): 0.6721520536524299\n",
      "          Validation Loss (standardized): 0.6154772558702839\n",
      "Epoch: 61, Loss (standarized): 0.664137281858171\n",
      "          Validation Loss (standardized): 0.6071311920405722\n",
      "Epoch: 66, Loss (standarized): 0.6569955257709117\n",
      "          Validation Loss (standardized): 0.6035699864960149\n",
      "Epoch: 71, Loss (standarized): 0.6499185034355202\n",
      "          Validation Loss (standardized): 0.59781123885061\n",
      "Epoch: 76, Loss (standarized): 0.6421994723336579\n",
      "          Validation Loss (standardized): 0.5902443742840427\n",
      "Epoch: 81, Loss (standarized): 0.6336672567412915\n",
      "          Validation Loss (standardized): 0.5822447089782763\n",
      "Epoch: 86, Loss (standarized): 0.624371184266208\n",
      "          Validation Loss (standardized): 0.5751587743423403\n",
      "Epoch: 91, Loss (standarized): 0.6149867910764486\n",
      "          Validation Loss (standardized): 0.5668950983715751\n",
      "Epoch: 96, Loss (standarized): 0.6060970736497655\n",
      "          Validation Loss (standardized): 0.5599174713315945\n",
      "Final epoch: 100, Final loss (standarized): 0.5998236265061072\n",
      "Epoch: 1, Loss (standarized): 1.0222792545861676\n",
      "          Validation Loss (standardized): 0.812001345561079\n",
      "Epoch: 6, Loss (standarized): 0.8706609707222945\n",
      "          Validation Loss (standardized): 0.7624555956396617\n",
      "Epoch: 11, Loss (standarized): 0.8160269156521205\n",
      "          Validation Loss (standardized): 0.736447328813669\n",
      "Epoch: 16, Loss (standarized): 0.8162502678166085\n",
      "          Validation Loss (standardized): 0.7422486544863652\n",
      "Epoch: 21, Loss (standarized): 0.7840067459865897\n",
      "          Validation Loss (standardized): 0.6942060143062673\n",
      "Epoch: 26, Loss (standarized): 0.7562406250467504\n",
      "          Validation Loss (standardized): 0.6810256897427245\n",
      "Epoch: 31, Loss (standarized): 0.7152110129863813\n",
      "          Validation Loss (standardized): 0.641615504137025\n",
      "Epoch: 36, Loss (standarized): 0.677388660323064\n",
      "          Validation Loss (standardized): 0.6154360312807289\n",
      "Epoch: 41, Loss (standarized): 0.6372163103460673\n",
      "          Validation Loss (standardized): 0.5823846792763931\n",
      "Epoch: 46, Loss (standarized): 0.5879341877117742\n",
      "          Validation Loss (standardized): 0.549108671013375\n",
      "Epoch: 51, Loss (standarized): 0.5293080961823712\n",
      "          Validation Loss (standardized): 0.5034510692043608\n",
      "Epoch: 56, Loss (standarized): 0.4838556477196394\n",
      "          Validation Loss (standardized): 0.49205152358705656\n",
      "Epoch: 61, Loss (standarized): 0.43957621017215603\n",
      "          Validation Loss (standardized): 0.46044969145\n",
      "Epoch: 66, Loss (standarized): 0.4135563830323896\n",
      "          Validation Loss (standardized): 0.4612902451105196\n",
      "Epoch: 71, Loss (standarized): 0.3982026881609697\n",
      "          Validation Loss (standardized): 0.4578136401222501\n",
      "Epoch: 76, Loss (standarized): 0.3913058681229116\n",
      "          Validation Loss (standardized): 0.45470734231918036\n",
      "Epoch: 81, Loss (standarized): 0.3842957842249441\n",
      "          Validation Loss (standardized): 0.4489317643601673\n",
      "Epoch: 86, Loss (standarized): 0.3768409053837619\n",
      "          Validation Loss (standardized): 0.4340460799740648\n",
      "Epoch: 91, Loss (standarized): 0.37147972321970785\n",
      "          Validation Loss (standardized): 0.42288577776921954\n",
      "Epoch: 96, Loss (standarized): 0.3666472708820635\n",
      "          Validation Loss (standardized): 0.4167984068047531\n",
      "Final epoch: 100, Final loss (standarized): 0.3623085904622494\n",
      "Epoch: 1, Loss (standarized): 1.085929874091556\n",
      "          Validation Loss (standardized): 0.7793365421142618\n",
      "Epoch: 6, Loss (standarized): 0.8528269665575046\n",
      "          Validation Loss (standardized): 0.7187208253004177\n",
      "Epoch: 11, Loss (standarized): 0.7894925191210315\n",
      "          Validation Loss (standardized): 0.7331246484793451\n",
      "Epoch: 16, Loss (standarized): 0.7253165932727662\n",
      "          Validation Loss (standardized): 0.6481163420343401\n",
      "Epoch: 21, Loss (standarized): 0.694191842227408\n",
      "          Validation Loss (standardized): 0.6265931067262948\n",
      "Epoch: 26, Loss (standarized): 0.6490403435390923\n",
      "          Validation Loss (standardized): 0.5981653268028728\n",
      "Epoch: 31, Loss (standarized): 0.6180662803514825\n",
      "          Validation Loss (standardized): 0.5711433143123846\n",
      "Epoch: 36, Loss (standarized): 0.5835569073877874\n",
      "          Validation Loss (standardized): 0.5504100497493365\n",
      "Epoch: 41, Loss (standarized): 0.5475423304431024\n",
      "          Validation Loss (standardized): 0.5240817753292917\n",
      "Epoch: 46, Loss (standarized): 0.5152315792751443\n",
      "          Validation Loss (standardized): 0.5055741376051027\n",
      "Epoch: 51, Loss (standarized): 0.4855575789778069\n",
      "          Validation Loss (standardized): 0.49240896024691233\n",
      "Epoch: 56, Loss (standarized): 0.45913321079166813\n",
      "          Validation Loss (standardized): 0.47699819817478656\n",
      "Epoch: 61, Loss (standarized): 0.44081955629549385\n",
      "          Validation Loss (standardized): 0.47303088799414267\n",
      "Epoch: 66, Loss (standarized): 0.4291940708796112\n",
      "          Validation Loss (standardized): 0.469235739575638\n",
      "Epoch: 71, Loss (standarized): 0.4229546831620533\n",
      "          Validation Loss (standardized): 0.46982509343878576\n",
      "Epoch: 76, Loss (standarized): 0.4198892314039114\n",
      "          Validation Loss (standardized): 0.4676978105728628\n",
      "Epoch: 81, Loss (standarized): 0.4188861119335951\n",
      "          Validation Loss (standardized): 0.4673186018616171\n",
      "Epoch: 86, Loss (standarized): 0.4187519453701789\n",
      "          Validation Loss (standardized): 0.46482659582822505\n",
      "Epoch: 91, Loss (standarized): 0.41899671864639493\n",
      "          Validation Loss (standardized): 0.46382506908830345\n",
      "Epoch: 96, Loss (standarized): 0.41896934762285254\n",
      "          Validation Loss (standardized): 0.46185922987981703\n",
      "Final epoch: 100, Final loss (standarized): 0.41869156958992554\n",
      "Epoch: 1, Loss (standarized): 1.0332000164355057\n",
      "          Validation Loss (standardized): 0.7604242493747043\n",
      "Epoch: 6, Loss (standarized): 0.8233454616290778\n",
      "          Validation Loss (standardized): 0.7131080636429737\n",
      "Epoch: 11, Loss (standarized): 0.7204856192698004\n",
      "          Validation Loss (standardized): 0.6672324671681167\n",
      "Epoch: 16, Loss (standarized): 0.6688112742383496\n",
      "          Validation Loss (standardized): 0.6025433580673781\n",
      "Epoch: 21, Loss (standarized): 0.6224117830726927\n",
      "          Validation Loss (standardized): 0.576456900281195\n",
      "Epoch: 26, Loss (standarized): 0.5695956739912921\n",
      "          Validation Loss (standardized): 0.5365462617068414\n",
      "Epoch: 31, Loss (standarized): 0.528989149252199\n",
      "          Validation Loss (standardized): 0.5016231558667071\n",
      "Epoch: 36, Loss (standarized): 0.48356339579863156\n",
      "          Validation Loss (standardized): 0.4875075762989913\n",
      "Epoch: 41, Loss (standarized): 0.4489074597031536\n",
      "          Validation Loss (standardized): 0.46455538579968547\n",
      "Epoch: 46, Loss (standarized): 0.42465731644106197\n",
      "          Validation Loss (standardized): 0.4599398504275713\n",
      "Epoch: 51, Loss (standarized): 0.408965647994113\n",
      "          Validation Loss (standardized): 0.4550435531118755\n",
      "Epoch: 56, Loss (standarized): 0.4002315409256293\n",
      "          Validation Loss (standardized): 0.45605058127416265\n",
      "Epoch: 61, Loss (standarized): 0.39409576913449373\n",
      "          Validation Loss (standardized): 0.45111073116912936\n",
      "Epoch: 66, Loss (standarized): 0.38944826655129755\n",
      "          Validation Loss (standardized): 0.4490839419894309\n",
      "Epoch: 71, Loss (standarized): 0.3854431073408576\n",
      "          Validation Loss (standardized): 0.43988802935883464\n",
      "Epoch: 76, Loss (standarized): 0.38187124753592894\n",
      "          Validation Loss (standardized): 0.436855617450538\n",
      "Epoch: 81, Loss (standarized): 0.3782563965158038\n",
      "          Validation Loss (standardized): 0.4301145157118679\n",
      "Epoch: 86, Loss (standarized): 0.3746337412983928\n",
      "          Validation Loss (standardized): 0.4243776797049003\n",
      "Epoch: 91, Loss (standarized): 0.37085952674340517\n",
      "          Validation Loss (standardized): 0.4207180774086269\n",
      "Epoch: 96, Loss (standarized): 0.36677087798671115\n",
      "          Validation Loss (standardized): 0.41545498618224264\n",
      "Final epoch: 100, Final loss (standarized): 0.3634279086512112\n",
      "Epoch: 1, Loss (standarized): 1.0950858548476508\n",
      "          Validation Loss (standardized): 0.7509328633992243\n",
      "Epoch: 6, Loss (standarized): 0.8410289538649751\n",
      "          Validation Loss (standardized): 0.7184623699293243\n",
      "Epoch: 11, Loss (standarized): 0.7325644119662081\n",
      "          Validation Loss (standardized): 0.6841070892638891\n",
      "Epoch: 16, Loss (standarized): 0.6704252155013484\n",
      "          Validation Loss (standardized): 0.6116623270295621\n",
      "Epoch: 21, Loss (standarized): 0.6364905342967441\n",
      "          Validation Loss (standardized): 0.5875925334443959\n",
      "Epoch: 26, Loss (standarized): 0.5754867012308356\n",
      "          Validation Loss (standardized): 0.5483104014516023\n",
      "Epoch: 31, Loss (standarized): 0.5353324201744243\n",
      "          Validation Loss (standardized): 0.5161512016780034\n",
      "Epoch: 36, Loss (standarized): 0.49504658244963656\n",
      "          Validation Loss (standardized): 0.4960380957534746\n",
      "Epoch: 41, Loss (standarized): 0.4573407884798387\n",
      "          Validation Loss (standardized): 0.4810733908071939\n",
      "Epoch: 46, Loss (standarized): 0.4329333647649646\n",
      "          Validation Loss (standardized): 0.48195200217772965\n",
      "Epoch: 51, Loss (standarized): 0.4222462701422943\n",
      "          Validation Loss (standardized): 0.48435286440633335\n",
      "Epoch: 56, Loss (standarized): 0.4188423083221881\n",
      "          Validation Loss (standardized): 0.49334118096827256\n",
      "Epoch: 61, Loss (standarized): 0.41669078806577764\n",
      "          Validation Loss (standardized): 0.4914303361834081\n",
      "Epoch: 66, Loss (standarized): 0.4144186554737768\n",
      "          Validation Loss (standardized): 0.48912520691476147\n",
      "Epoch: 71, Loss (standarized): 0.411447996692457\n",
      "          Validation Loss (standardized): 0.48200352862422263\n",
      "Epoch: 76, Loss (standarized): 0.4094079066209927\n",
      "          Validation Loss (standardized): 0.47630782982122466\n",
      "Epoch: 81, Loss (standarized): 0.4076862730313988\n",
      "          Validation Loss (standardized): 0.472511941064803\n",
      "Epoch: 86, Loss (standarized): 0.4056587184028115\n",
      "          Validation Loss (standardized): 0.4683692594074708\n",
      "Epoch: 91, Loss (standarized): 0.40326234197094435\n",
      "          Validation Loss (standardized): 0.4664228995690344\n",
      "Epoch: 96, Loss (standarized): 0.4004268828047793\n",
      "          Validation Loss (standardized): 0.46388184216135725\n",
      "Final epoch: 100, Final loss (standarized): 0.39801554599195926\n",
      "Epoch: 1, Loss (standarized): 1.0347491476929063\n",
      "          Validation Loss (standardized): 0.7815999636349505\n",
      "Epoch: 6, Loss (standarized): 0.8685031510212118\n",
      "          Validation Loss (standardized): 0.7343990544466533\n",
      "Epoch: 11, Loss (standarized): 0.8174011401258572\n",
      "          Validation Loss (standardized): 0.7593311220750967\n",
      "Epoch: 16, Loss (standarized): 0.7723664307706102\n",
      "          Validation Loss (standardized): 0.6826088489209726\n",
      "Epoch: 21, Loss (standarized): 0.7399713215336859\n",
      "          Validation Loss (standardized): 0.6653292415703576\n",
      "Epoch: 26, Loss (standarized): 0.6835493983475327\n",
      "          Validation Loss (standardized): 0.6200656939880751\n",
      "Epoch: 31, Loss (standarized): 0.6313077015578694\n",
      "          Validation Loss (standardized): 0.5782871471754436\n",
      "Epoch: 36, Loss (standarized): 0.5738016281777325\n",
      "          Validation Loss (standardized): 0.5383389428509823\n",
      "Epoch: 41, Loss (standarized): 0.5065247238262282\n",
      "          Validation Loss (standardized): 0.4899465352216815\n",
      "Epoch: 46, Loss (standarized): 0.4560325656240993\n",
      "          Validation Loss (standardized): 0.48243440733092974\n",
      "Epoch: 51, Loss (standarized): 0.41894518427661886\n",
      "          Validation Loss (standardized): 0.473120238151442\n",
      "Epoch: 56, Loss (standarized): 0.40470689193630227\n",
      "          Validation Loss (standardized): 0.46895078831231246\n",
      "Epoch: 61, Loss (standarized): 0.39779246887881337\n",
      "          Validation Loss (standardized): 0.4785713429180759\n",
      "Epoch: 66, Loss (standarized): 0.3917751096826357\n",
      "          Validation Loss (standardized): 0.4744942424792613\n",
      "Epoch: 71, Loss (standarized): 0.38106563160237106\n",
      "          Validation Loss (standardized): 0.4512693092530638\n",
      "Epoch: 76, Loss (standarized): 0.37176041586955916\n",
      "          Validation Loss (standardized): 0.4294519198373126\n",
      "Epoch: 81, Loss (standarized): 0.36504369962146316\n",
      "          Validation Loss (standardized): 0.41737514460506925\n",
      "Epoch: 86, Loss (standarized): 0.35726950524151907\n",
      "          Validation Loss (standardized): 0.40888517194873086\n",
      "Epoch: 91, Loss (standarized): 0.34839498281347736\n",
      "          Validation Loss (standardized): 0.40041482733898304\n",
      "Epoch: 96, Loss (standarized): 0.3396234521436369\n",
      "          Validation Loss (standardized): 0.3929558280606865\n",
      "Final epoch: 100, Final loss (standarized): 0.3324927928295196\n",
      "Epoch: 1, Loss (standarized): 0.818249977512673\n",
      "          Validation Loss (standardized): 0.7206627950862722\n",
      "Epoch: 6, Loss (standarized): 0.7638641156245896\n",
      "          Validation Loss (standardized): 0.6872851651407684\n",
      "Epoch: 11, Loss (standarized): 0.6895173571971379\n",
      "          Validation Loss (standardized): 0.6187020072238764\n",
      "Epoch: 16, Loss (standarized): 0.6190582675157923\n",
      "          Validation Loss (standardized): 0.5693685682687933\n",
      "Epoch: 21, Loss (standarized): 0.5603912720305297\n",
      "          Validation Loss (standardized): 0.5307174027244076\n",
      "Epoch: 26, Loss (standarized): 0.5061910443828783\n",
      "          Validation Loss (standardized): 0.4820400091168517\n",
      "Epoch: 31, Loss (standarized): 0.45542125768773845\n",
      "          Validation Loss (standardized): 0.4632754971351343\n",
      "Epoch: 36, Loss (standarized): 0.42099557715187624\n",
      "          Validation Loss (standardized): 0.4443912553561285\n",
      "Epoch: 41, Loss (standarized): 0.3999932768059603\n",
      "          Validation Loss (standardized): 0.4425074360070343\n",
      "Epoch: 46, Loss (standarized): 0.3917420171082028\n",
      "          Validation Loss (standardized): 0.440657163410518\n",
      "Epoch: 51, Loss (standarized): 0.38690436419472884\n",
      "          Validation Loss (standardized): 0.4348924581305256\n",
      "Epoch: 56, Loss (standarized): 0.3858481063725506\n",
      "          Validation Loss (standardized): 0.4300573969110296\n",
      "Epoch: 61, Loss (standarized): 0.3860428304963769\n",
      "          Validation Loss (standardized): 0.4288952782070296\n",
      "Epoch: 66, Loss (standarized): 0.38426656024401223\n",
      "          Validation Loss (standardized): 0.42777460924338\n",
      "Epoch: 71, Loss (standarized): 0.38179542459514015\n",
      "          Validation Loss (standardized): 0.4265483079103899\n",
      "Epoch: 76, Loss (standarized): 0.3799322462732002\n",
      "          Validation Loss (standardized): 0.4253899011041982\n",
      "Epoch: 81, Loss (standarized): 0.37848385602756524\n",
      "          Validation Loss (standardized): 0.42278931953464716\n",
      "Epoch: 86, Loss (standarized): 0.37693748682117123\n",
      "          Validation Loss (standardized): 0.4197625217016021\n",
      "Epoch: 91, Loss (standarized): 0.37504222011830135\n",
      "          Validation Loss (standardized): 0.41695562156111043\n",
      "Epoch: 96, Loss (standarized): 0.37241943267178856\n",
      "          Validation Loss (standardized): 0.413934052549969\n",
      "Final epoch: 100, Final loss (standarized): 0.3701642303143101\n",
      "Epoch: 1, Loss (standarized): 1.4189214001447303\n",
      "          Validation Loss (standardized): 0.9808736906667117\n",
      "Epoch: 6, Loss (standarized): 0.9426957613487126\n",
      "          Validation Loss (standardized): 0.8264594553918019\n",
      "Epoch: 11, Loss (standarized): 0.7660839198120344\n",
      "          Validation Loss (standardized): 0.6887231947439238\n",
      "Epoch: 16, Loss (standarized): 0.7693054669783838\n",
      "          Validation Loss (standardized): 0.7048208316925464\n",
      "Epoch: 21, Loss (standarized): 0.6906528138381235\n",
      "          Validation Loss (standardized): 0.6216716277095613\n",
      "Epoch: 26, Loss (standarized): 0.66114515776389\n",
      "          Validation Loss (standardized): 0.6000330321355836\n",
      "Epoch: 31, Loss (standarized): 0.612313896769254\n",
      "          Validation Loss (standardized): 0.5675648363883314\n",
      "Epoch: 36, Loss (standarized): 0.5791106373771816\n",
      "          Validation Loss (standardized): 0.546635931315128\n",
      "Epoch: 41, Loss (standarized): 0.5319996519688622\n",
      "          Validation Loss (standardized): 0.5134136997398817\n",
      "Epoch: 46, Loss (standarized): 0.49327888852848434\n",
      "          Validation Loss (standardized): 0.49193735333594674\n",
      "Epoch: 51, Loss (standarized): 0.46037588717327854\n",
      "          Validation Loss (standardized): 0.4803098696480093\n",
      "Epoch: 56, Loss (standarized): 0.4339443200100176\n",
      "          Validation Loss (standardized): 0.46885455510816426\n",
      "Epoch: 61, Loss (standarized): 0.4172306780808145\n",
      "          Validation Loss (standardized): 0.46583768249687607\n",
      "Epoch: 66, Loss (standarized): 0.40480551524678027\n",
      "          Validation Loss (standardized): 0.4592189066152581\n",
      "Epoch: 71, Loss (standarized): 0.394057533965798\n",
      "          Validation Loss (standardized): 0.44977148078964235\n",
      "Epoch: 76, Loss (standarized): 0.38535875651058216\n",
      "          Validation Loss (standardized): 0.4398709514762497\n",
      "Epoch: 81, Loss (standarized): 0.3786683104294212\n",
      "          Validation Loss (standardized): 0.4324288780654871\n",
      "Epoch: 86, Loss (standarized): 0.37186532889282253\n",
      "          Validation Loss (standardized): 0.4269787816874326\n",
      "Epoch: 91, Loss (standarized): 0.3652567446772975\n",
      "          Validation Loss (standardized): 0.42226747239210694\n",
      "Epoch: 96, Loss (standarized): 0.35893164512942244\n",
      "          Validation Loss (standardized): 0.416215773241167\n",
      "Final epoch: 100, Final loss (standarized): 0.35383278910813526\n",
      "Epoch: 1, Loss (standarized): 1.018306837014375\n",
      "          Validation Loss (standardized): 0.7781290839326518\n",
      "Epoch: 6, Loss (standarized): 0.8438702537975397\n",
      "          Validation Loss (standardized): 0.7190598311842027\n",
      "Epoch: 11, Loss (standarized): 0.759122654885784\n",
      "          Validation Loss (standardized): 0.698384610930338\n",
      "Epoch: 16, Loss (standarized): 0.7040176491079477\n",
      "          Validation Loss (standardized): 0.6264211943031182\n",
      "Epoch: 21, Loss (standarized): 0.6544800543404616\n",
      "          Validation Loss (standardized): 0.5939741925514128\n",
      "Epoch: 26, Loss (standarized): 0.5981265769066875\n",
      "          Validation Loss (standardized): 0.5585971915205563\n",
      "Epoch: 31, Loss (standarized): 0.5468758561230225\n",
      "          Validation Loss (standardized): 0.5125067370359714\n",
      "Epoch: 36, Loss (standarized): 0.4922054915087008\n",
      "          Validation Loss (standardized): 0.493500027749575\n",
      "Epoch: 41, Loss (standarized): 0.45328913707367685\n",
      "          Validation Loss (standardized): 0.4674865411541347\n",
      "Epoch: 46, Loss (standarized): 0.4209694157938424\n",
      "          Validation Loss (standardized): 0.46856300867468276\n",
      "Epoch: 51, Loss (standarized): 0.40809904855099505\n",
      "          Validation Loss (standardized): 0.4652933239592942\n",
      "Epoch: 56, Loss (standarized): 0.4008412494230506\n",
      "          Validation Loss (standardized): 0.47436365749502485\n",
      "Epoch: 61, Loss (standarized): 0.3935863708953077\n",
      "          Validation Loss (standardized): 0.4590524176826291\n",
      "Epoch: 66, Loss (standarized): 0.3852834141916996\n",
      "          Validation Loss (standardized): 0.44831099048053735\n",
      "Epoch: 71, Loss (standarized): 0.3782996288376171\n",
      "          Validation Loss (standardized): 0.43127262788468357\n",
      "Epoch: 76, Loss (standarized): 0.37226531724563633\n",
      "          Validation Loss (standardized): 0.4214995650185523\n",
      "Epoch: 81, Loss (standarized): 0.36516067427838805\n",
      "          Validation Loss (standardized): 0.41626081352137106\n",
      "Epoch: 86, Loss (standarized): 0.35764362243100056\n",
      "          Validation Loss (standardized): 0.40844264837031674\n",
      "Epoch: 91, Loss (standarized): 0.3503062395988061\n",
      "          Validation Loss (standardized): 0.4016236087993594\n",
      "Epoch: 96, Loss (standarized): 0.3426777402716248\n",
      "          Validation Loss (standardized): 0.39176195246492534\n",
      "Final epoch: 100, Final loss (standarized): 0.3364001870019283\n",
      "Epoch: 1, Loss (standarized): 2.246187658825032\n",
      "          Validation Loss (standardized): 1.5560113584215294\n",
      "Epoch: 6, Loss (standarized): 0.8754148955420362\n",
      "          Validation Loss (standardized): 0.8767088325861766\n",
      "Epoch: 11, Loss (standarized): 0.8904003006936104\n",
      "          Validation Loss (standardized): 0.7295966506353097\n",
      "Epoch: 16, Loss (standarized): 0.7490316486510645\n",
      "          Validation Loss (standardized): 0.7129366983757802\n",
      "Epoch: 21, Loss (standarized): 0.760620184440962\n",
      "          Validation Loss (standardized): 0.6905657638250413\n",
      "Epoch: 26, Loss (standarized): 0.6716744469968495\n",
      "          Validation Loss (standardized): 0.610298347982073\n",
      "Epoch: 31, Loss (standarized): 0.6581410957895939\n",
      "          Validation Loss (standardized): 0.5977154923232664\n",
      "Epoch: 36, Loss (standarized): 0.6055475484578274\n",
      "          Validation Loss (standardized): 0.559637929597625\n",
      "Epoch: 41, Loss (standarized): 0.5758747039560472\n",
      "          Validation Loss (standardized): 0.5466390599203705\n",
      "Epoch: 46, Loss (standarized): 0.535864999557426\n",
      "          Validation Loss (standardized): 0.5149206329595948\n",
      "Epoch: 51, Loss (standarized): 0.5034931340735597\n",
      "          Validation Loss (standardized): 0.4998333149983719\n",
      "Epoch: 56, Loss (standarized): 0.47132311901780544\n",
      "          Validation Loss (standardized): 0.4862760104957556\n",
      "Epoch: 61, Loss (standarized): 0.4511866468956556\n",
      "          Validation Loss (standardized): 0.48215422317327394\n",
      "Epoch: 66, Loss (standarized): 0.4361770219064251\n",
      "          Validation Loss (standardized): 0.4844421677320237\n",
      "Epoch: 71, Loss (standarized): 0.4267731300781251\n",
      "          Validation Loss (standardized): 0.4838368312206138\n",
      "Epoch: 76, Loss (standarized): 0.4206753782198319\n",
      "          Validation Loss (standardized): 0.48346229715580336\n",
      "Epoch: 81, Loss (standarized): 0.41429625636037226\n",
      "          Validation Loss (standardized): 0.4777352194574931\n",
      "Epoch: 86, Loss (standarized): 0.407919704832245\n",
      "          Validation Loss (standardized): 0.46890435071032116\n",
      "Epoch: 91, Loss (standarized): 0.4022091354296652\n",
      "          Validation Loss (standardized): 0.46147776090963744\n",
      "Epoch: 96, Loss (standarized): 0.3968883774609057\n",
      "          Validation Loss (standardized): 0.45533515126791246\n",
      "Final epoch: 100, Final loss (standarized): 0.39262430865554365\n",
      "Epoch: 1, Loss (standarized): 0.9859247751916438\n",
      "          Validation Loss (standardized): 0.7979419310215928\n",
      "Epoch: 6, Loss (standarized): 0.8380283609171961\n",
      "          Validation Loss (standardized): 0.7318352368391229\n",
      "Epoch: 11, Loss (standarized): 0.7812282080823387\n",
      "          Validation Loss (standardized): 0.7022042925956095\n",
      "Epoch: 16, Loss (standarized): 0.7666791182520158\n",
      "          Validation Loss (standardized): 0.6938764905855064\n",
      "Epoch: 21, Loss (standarized): 0.7265863864624821\n",
      "          Validation Loss (standardized): 0.647301481036533\n",
      "Epoch: 26, Loss (standarized): 0.6933896464205818\n",
      "          Validation Loss (standardized): 0.628308766794191\n",
      "Epoch: 31, Loss (standarized): 0.6564491360150694\n",
      "          Validation Loss (standardized): 0.5986277827244474\n",
      "Epoch: 36, Loss (standarized): 0.6230025563895866\n",
      "          Validation Loss (standardized): 0.5734135134963453\n",
      "Epoch: 41, Loss (standarized): 0.5815232401610201\n",
      "          Validation Loss (standardized): 0.5436260683410836\n",
      "Epoch: 46, Loss (standarized): 0.5324067148043231\n",
      "          Validation Loss (standardized): 0.5096835706063385\n",
      "Epoch: 51, Loss (standarized): 0.4869267378175005\n",
      "          Validation Loss (standardized): 0.4922962068101226\n",
      "Epoch: 56, Loss (standarized): 0.44783920039976693\n",
      "          Validation Loss (standardized): 0.47222936883435546\n",
      "Epoch: 61, Loss (standarized): 0.4243792825487197\n",
      "          Validation Loss (standardized): 0.4720368860155509\n",
      "Epoch: 66, Loss (standarized): 0.41594237354823493\n",
      "          Validation Loss (standardized): 0.4781720930540098\n",
      "Epoch: 71, Loss (standarized): 0.412136592663306\n",
      "          Validation Loss (standardized): 0.47576891193878096\n",
      "Epoch: 76, Loss (standarized): 0.41148266722392124\n",
      "          Validation Loss (standardized): 0.468536089052888\n",
      "Epoch: 81, Loss (standarized): 0.41314872399572744\n",
      "          Validation Loss (standardized): 0.46394237377626196\n",
      "Epoch: 86, Loss (standarized): 0.4129034993148477\n",
      "          Validation Loss (standardized): 0.462364339549907\n",
      "Epoch: 91, Loss (standarized): 0.41079264973167184\n",
      "          Validation Loss (standardized): 0.4625712249189906\n",
      "Epoch: 96, Loss (standarized): 0.40852492392209605\n",
      "          Validation Loss (standardized): 0.46267048418231305\n",
      "Final epoch: 100, Final loss (standarized): 0.40702816451392837\n",
      "Epoch: 1, Loss (standarized): 0.9793201948951186\n",
      "          Validation Loss (standardized): 0.7373284947822131\n",
      "Epoch: 6, Loss (standarized): 0.8029276470118927\n",
      "          Validation Loss (standardized): 0.6966705596689308\n",
      "Epoch: 11, Loss (standarized): 0.7115119857114054\n",
      "          Validation Loss (standardized): 0.6620499542813707\n",
      "Epoch: 16, Loss (standarized): 0.6605253750634074\n",
      "          Validation Loss (standardized): 0.589780790529566\n",
      "Epoch: 21, Loss (standarized): 0.618631859913167\n",
      "          Validation Loss (standardized): 0.5778883590461764\n",
      "Epoch: 26, Loss (standarized): 0.5645150273537748\n",
      "          Validation Loss (standardized): 0.5281585700312892\n",
      "Epoch: 31, Loss (standarized): 0.5164965049828292\n",
      "          Validation Loss (standardized): 0.484092381195381\n",
      "Epoch: 36, Loss (standarized): 0.4713937089441293\n",
      "          Validation Loss (standardized): 0.47563142004962955\n",
      "Epoch: 41, Loss (standarized): 0.43270781302875355\n",
      "          Validation Loss (standardized): 0.438645477447732\n",
      "Epoch: 46, Loss (standarized): 0.40331669933342357\n",
      "          Validation Loss (standardized): 0.42970802305574984\n",
      "Epoch: 51, Loss (standarized): 0.38409003457179614\n",
      "          Validation Loss (standardized): 0.42421234440359323\n",
      "Epoch: 56, Loss (standarized): 0.3724676396226133\n",
      "          Validation Loss (standardized): 0.4227838496541908\n",
      "Epoch: 61, Loss (standarized): 0.3651459627988457\n",
      "          Validation Loss (standardized): 0.4252284586995579\n",
      "Epoch: 66, Loss (standarized): 0.3598872876667697\n",
      "          Validation Loss (standardized): 0.4248497421976715\n",
      "Epoch: 71, Loss (standarized): 0.35472692354963775\n",
      "          Validation Loss (standardized): 0.4157798328425163\n",
      "Epoch: 76, Loss (standarized): 0.3495152252504942\n",
      "          Validation Loss (standardized): 0.41174691688425313\n",
      "Epoch: 81, Loss (standarized): 0.34465904580285367\n",
      "          Validation Loss (standardized): 0.4007002014151415\n",
      "Epoch: 86, Loss (standarized): 0.34022607672293753\n",
      "          Validation Loss (standardized): 0.3944058502978854\n",
      "Epoch: 91, Loss (standarized): 0.3357992147909455\n",
      "          Validation Loss (standardized): 0.3902756961569333\n",
      "Epoch: 96, Loss (standarized): 0.3312767859532252\n",
      "          Validation Loss (standardized): 0.3859483254114018\n",
      "Final epoch: 100, Final loss (standarized): 0.3277168586157589\n",
      "Epoch: 1, Loss (standarized): 0.9776924711781791\n",
      "          Validation Loss (standardized): 0.7427992022120846\n",
      "Epoch: 6, Loss (standarized): 0.8192503649661841\n",
      "          Validation Loss (standardized): 0.7102777741544127\n",
      "Epoch: 11, Loss (standarized): 0.7840199673389714\n",
      "          Validation Loss (standardized): 0.6999278239334166\n",
      "Epoch: 16, Loss (standarized): 0.7193830692718762\n",
      "          Validation Loss (standardized): 0.6402396087791505\n",
      "Epoch: 21, Loss (standarized): 0.6498316117249694\n",
      "          Validation Loss (standardized): 0.5949732992519801\n",
      "Epoch: 26, Loss (standarized): 0.5894030844002431\n",
      "          Validation Loss (standardized): 0.5442069533243645\n",
      "Epoch: 31, Loss (standarized): 0.5286323332210244\n",
      "          Validation Loss (standardized): 0.5149632058860313\n",
      "Epoch: 36, Loss (standarized): 0.4746555264633875\n",
      "          Validation Loss (standardized): 0.4868137307698616\n",
      "Epoch: 41, Loss (standarized): 0.44040348726497475\n",
      "          Validation Loss (standardized): 0.485805451096755\n",
      "Epoch: 46, Loss (standarized): 0.4261732780118404\n",
      "          Validation Loss (standardized): 0.493737765567117\n",
      "Epoch: 51, Loss (standarized): 0.4175569802109605\n",
      "          Validation Loss (standardized): 0.4942594106579674\n",
      "Epoch: 56, Loss (standarized): 0.40747287907619684\n",
      "          Validation Loss (standardized): 0.47733356500455243\n",
      "Epoch: 61, Loss (standarized): 0.40178866231973914\n",
      "          Validation Loss (standardized): 0.46493236511268554\n",
      "Epoch: 66, Loss (standarized): 0.3957435963259237\n",
      "          Validation Loss (standardized): 0.4607513023507835\n",
      "Epoch: 71, Loss (standarized): 0.3879522889028219\n",
      "          Validation Loss (standardized): 0.45826078463949144\n",
      "Epoch: 76, Loss (standarized): 0.38082785858090984\n",
      "          Validation Loss (standardized): 0.45093372222076333\n",
      "Epoch: 81, Loss (standarized): 0.3721414330948036\n",
      "          Validation Loss (standardized): 0.43652880764074814\n",
      "Epoch: 86, Loss (standarized): 0.3631460360161343\n",
      "          Validation Loss (standardized): 0.42413303879865505\n",
      "Epoch: 91, Loss (standarized): 0.35281047478867233\n",
      "          Validation Loss (standardized): 0.4143766989971757\n",
      "Epoch: 96, Loss (standarized): 0.3414800661897789\n",
      "          Validation Loss (standardized): 0.39879130892430603\n",
      "Final epoch: 100, Final loss (standarized): 0.3316472387118058\n",
      "Epoch: 1, Loss (standarized): 1.0192100922404497\n",
      "          Validation Loss (standardized): 0.7224036779535331\n",
      "Epoch: 6, Loss (standarized): 0.7840703027288652\n",
      "          Validation Loss (standardized): 0.6698781167765455\n",
      "Epoch: 11, Loss (standarized): 0.7028677717731242\n",
      "          Validation Loss (standardized): 0.6492650207726319\n",
      "Epoch: 16, Loss (standarized): 0.6541768890182356\n",
      "          Validation Loss (standardized): 0.5887504515446095\n",
      "Epoch: 21, Loss (standarized): 0.6304568113901933\n",
      "          Validation Loss (standardized): 0.5791761969002928\n",
      "Epoch: 26, Loss (standarized): 0.599483879736091\n",
      "          Validation Loss (standardized): 0.5585530213104286\n",
      "Epoch: 31, Loss (standarized): 0.5796687951880406\n",
      "          Validation Loss (standardized): 0.5413618847131505\n",
      "Epoch: 36, Loss (standarized): 0.562136619523335\n",
      "          Validation Loss (standardized): 0.5356330287257495\n",
      "Epoch: 41, Loss (standarized): 0.5477390985263001\n",
      "          Validation Loss (standardized): 0.520773045106587\n",
      "Epoch: 46, Loss (standarized): 0.5346767867290713\n",
      "          Validation Loss (standardized): 0.5160780946466216\n",
      "Epoch: 51, Loss (standarized): 0.5234087710884194\n",
      "          Validation Loss (standardized): 0.5062232226778021\n",
      "Epoch: 56, Loss (standarized): 0.5119638519341754\n",
      "          Validation Loss (standardized): 0.4971681212902675\n",
      "Epoch: 61, Loss (standarized): 0.5013925006079\n",
      "          Validation Loss (standardized): 0.4923797101283156\n",
      "Epoch: 66, Loss (standarized): 0.49043896833290096\n",
      "          Validation Loss (standardized): 0.4823513143106997\n",
      "Epoch: 71, Loss (standarized): 0.4797930807815055\n",
      "          Validation Loss (standardized): 0.4757291459208314\n",
      "Epoch: 76, Loss (standarized): 0.469531750325086\n",
      "          Validation Loss (standardized): 0.46969341327996644\n",
      "Epoch: 81, Loss (standarized): 0.4593250467494661\n",
      "          Validation Loss (standardized): 0.4628880204724328\n",
      "Epoch: 86, Loss (standarized): 0.44896479341851575\n",
      "          Validation Loss (standardized): 0.4569333589689995\n",
      "Epoch: 91, Loss (standarized): 0.4396278888534268\n",
      "          Validation Loss (standardized): 0.4535907696368717\n",
      "Epoch: 96, Loss (standarized): 0.43159050029117535\n",
      "          Validation Loss (standardized): 0.44793829909289146\n",
      "Final epoch: 100, Final loss (standarized): 0.4262601212943638\n",
      "Epoch: 1, Loss (standarized): 0.8414170440955955\n",
      "          Validation Loss (standardized): 0.6791699011843768\n",
      "Epoch: 6, Loss (standarized): 0.7141794226722861\n",
      "          Validation Loss (standardized): 0.648722727637756\n",
      "Epoch: 11, Loss (standarized): 0.6743847471760409\n",
      "          Validation Loss (standardized): 0.6126347742264784\n",
      "Epoch: 16, Loss (standarized): 0.6436131557810103\n",
      "          Validation Loss (standardized): 0.592306915318124\n",
      "Epoch: 21, Loss (standarized): 0.6257319294122959\n",
      "          Validation Loss (standardized): 0.584789197750011\n",
      "Epoch: 26, Loss (standarized): 0.614245114787696\n",
      "          Validation Loss (standardized): 0.5711113449612651\n",
      "Epoch: 31, Loss (standarized): 0.6061743322907993\n",
      "          Validation Loss (standardized): 0.5625404335542706\n",
      "Epoch: 36, Loss (standarized): 0.6018177302914705\n",
      "          Validation Loss (standardized): 0.5644076630356826\n",
      "Epoch: 41, Loss (standarized): 0.5959976937959984\n",
      "          Validation Loss (standardized): 0.5560724186229521\n",
      "Epoch: 46, Loss (standarized): 0.58798997996609\n",
      "          Validation Loss (standardized): 0.5514295671707178\n",
      "Epoch: 51, Loss (standarized): 0.5798666896019729\n",
      "          Validation Loss (standardized): 0.5443137474200571\n",
      "Epoch: 56, Loss (standarized): 0.5706778143681783\n",
      "          Validation Loss (standardized): 0.5347973130415397\n",
      "Epoch: 61, Loss (standarized): 0.5589769624545078\n",
      "          Validation Loss (standardized): 0.5274717487567411\n",
      "Epoch: 66, Loss (standarized): 0.5462392457034345\n",
      "          Validation Loss (standardized): 0.518591255755355\n",
      "Epoch: 71, Loss (standarized): 0.5322921252953358\n",
      "          Validation Loss (standardized): 0.506858077655372\n",
      "Epoch: 76, Loss (standarized): 0.5173865219950053\n",
      "          Validation Loss (standardized): 0.49843110496961984\n",
      "Epoch: 81, Loss (standarized): 0.5020502027781741\n",
      "          Validation Loss (standardized): 0.48512730003765897\n",
      "Epoch: 86, Loss (standarized): 0.4869764787602307\n",
      "          Validation Loss (standardized): 0.47836138110375614\n",
      "Epoch: 91, Loss (standarized): 0.4725846892716872\n",
      "          Validation Loss (standardized): 0.46935100301066895\n",
      "Epoch: 96, Loss (standarized): 0.4597705605674457\n",
      "          Validation Loss (standardized): 0.462526072586339\n",
      "Final epoch: 100, Final loss (standarized): 0.45109038937434115\n",
      "Epoch: 1, Loss (standarized): 0.8652553115562032\n",
      "          Validation Loss (standardized): 0.7198870778884067\n",
      "Epoch: 6, Loss (standarized): 0.8064383549306783\n",
      "          Validation Loss (standardized): 0.7300208450718038\n",
      "Epoch: 11, Loss (standarized): 0.7877764454503267\n",
      "          Validation Loss (standardized): 0.7003804281956607\n",
      "Epoch: 16, Loss (standarized): 0.7625841992526866\n",
      "          Validation Loss (standardized): 0.6850852005514402\n",
      "Epoch: 21, Loss (standarized): 0.7425672548363711\n",
      "          Validation Loss (standardized): 0.6689065333640856\n",
      "Epoch: 26, Loss (standarized): 0.7248956879806342\n",
      "          Validation Loss (standardized): 0.6527812885801706\n",
      "Epoch: 31, Loss (standarized): 0.7098355505997798\n",
      "          Validation Loss (standardized): 0.6415176520161222\n",
      "Epoch: 36, Loss (standarized): 0.6969833111525894\n",
      "          Validation Loss (standardized): 0.6333589947781451\n",
      "Epoch: 41, Loss (standarized): 0.6860659811024201\n",
      "          Validation Loss (standardized): 0.6237583768338033\n",
      "Epoch: 46, Loss (standarized): 0.6771839647657923\n",
      "          Validation Loss (standardized): 0.6184955574813761\n",
      "Epoch: 51, Loss (standarized): 0.6701037007823186\n",
      "          Validation Loss (standardized): 0.6143233765062301\n",
      "Epoch: 56, Loss (standarized): 0.6637349569761944\n",
      "          Validation Loss (standardized): 0.6062317467165373\n",
      "Epoch: 61, Loss (standarized): 0.6579077462066618\n",
      "          Validation Loss (standardized): 0.603672676316754\n",
      "Epoch: 66, Loss (standarized): 0.6520638270283486\n",
      "          Validation Loss (standardized): 0.6007945918973528\n",
      "Epoch: 71, Loss (standarized): 0.6462527240736984\n",
      "          Validation Loss (standardized): 0.5948084063985334\n",
      "Epoch: 76, Loss (standarized): 0.6412726302428057\n",
      "          Validation Loss (standardized): 0.5899271762216053\n",
      "Epoch: 81, Loss (standarized): 0.6366366628316308\n",
      "          Validation Loss (standardized): 0.5874836778559898\n",
      "Epoch: 86, Loss (standarized): 0.6317043736518004\n",
      "          Validation Loss (standardized): 0.5830977915780815\n",
      "Epoch: 91, Loss (standarized): 0.625850272701789\n",
      "          Validation Loss (standardized): 0.5760352229834528\n",
      "Epoch: 96, Loss (standarized): 0.618915917501529\n",
      "          Validation Loss (standardized): 0.5726654695568266\n",
      "Final epoch: 100, Final loss (standarized): 0.6127241553605784\n",
      "Epoch: 1, Loss (standarized): 0.9395412032837328\n",
      "          Validation Loss (standardized): 0.7839490419675318\n",
      "Epoch: 6, Loss (standarized): 0.8313250530133661\n",
      "          Validation Loss (standardized): 0.7376238610664376\n",
      "Epoch: 11, Loss (standarized): 0.8195486429919339\n",
      "          Validation Loss (standardized): 0.7339320056800915\n",
      "Epoch: 16, Loss (standarized): 0.8204372648521894\n",
      "          Validation Loss (standardized): 0.7488681725348101\n",
      "Epoch: 21, Loss (standarized): 0.8050908013141014\n",
      "          Validation Loss (standardized): 0.7218071628515982\n",
      "Epoch: 26, Loss (standarized): 0.7861726361915196\n",
      "          Validation Loss (standardized): 0.704438496071945\n",
      "Epoch: 31, Loss (standarized): 0.7672373712248619\n",
      "          Validation Loss (standardized): 0.6938820520398434\n",
      "Epoch: 36, Loss (standarized): 0.7470918841476808\n",
      "          Validation Loss (standardized): 0.6724315460561071\n",
      "Epoch: 41, Loss (standarized): 0.7279428865916137\n",
      "          Validation Loss (standardized): 0.6542231967831207\n",
      "Epoch: 46, Loss (standarized): 0.711446570026357\n",
      "          Validation Loss (standardized): 0.6449371112217571\n",
      "Epoch: 51, Loss (standarized): 0.6982023151910207\n",
      "          Validation Loss (standardized): 0.6334948827372595\n",
      "Epoch: 56, Loss (standarized): 0.6882486396275087\n",
      "          Validation Loss (standardized): 0.6225588767223534\n",
      "Epoch: 61, Loss (standarized): 0.6813419994725274\n",
      "          Validation Loss (standardized): 0.6225601539218657\n",
      "Epoch: 66, Loss (standarized): 0.6761536568388895\n",
      "          Validation Loss (standardized): 0.6168319099928968\n",
      "Epoch: 71, Loss (standarized): 0.6714683465483716\n",
      "          Validation Loss (standardized): 0.6131927495478782\n",
      "Epoch: 76, Loss (standarized): 0.6667101367606663\n",
      "          Validation Loss (standardized): 0.6120591754250312\n",
      "Epoch: 81, Loss (standarized): 0.6613954691403517\n",
      "          Validation Loss (standardized): 0.6058430007741044\n",
      "Epoch: 86, Loss (standarized): 0.6565824176478845\n",
      "          Validation Loss (standardized): 0.6025485687184391\n",
      "Epoch: 91, Loss (standarized): 0.6523701564160518\n",
      "          Validation Loss (standardized): 0.5994982225253714\n",
      "Epoch: 96, Loss (standarized): 0.6485693547317293\n",
      "          Validation Loss (standardized): 0.5953234157475018\n",
      "Final epoch: 100, Final loss (standarized): 0.645627812861043\n",
      "Epoch: 1, Loss (standarized): 1.2569383634577398\n",
      "          Validation Loss (standardized): 0.9162591050372418\n",
      "Epoch: 6, Loss (standarized): 0.8830337267112771\n",
      "          Validation Loss (standardized): 0.7908942617863255\n",
      "Epoch: 11, Loss (standarized): 0.7853466192338295\n",
      "          Validation Loss (standardized): 0.6947825414366369\n",
      "Epoch: 16, Loss (standarized): 0.7730617562039102\n",
      "          Validation Loss (standardized): 0.7124049578390328\n",
      "Epoch: 21, Loss (standarized): 0.7266185705582041\n",
      "          Validation Loss (standardized): 0.648634735418362\n",
      "Epoch: 26, Loss (standarized): 0.6829431055300041\n",
      "          Validation Loss (standardized): 0.6214565425775495\n",
      "Epoch: 31, Loss (standarized): 0.6437493966387362\n",
      "          Validation Loss (standardized): 0.5865413739818454\n",
      "Epoch: 36, Loss (standarized): 0.6005541566051504\n",
      "          Validation Loss (standardized): 0.5566856363372651\n",
      "Epoch: 41, Loss (standarized): 0.5545163612986331\n",
      "          Validation Loss (standardized): 0.5215714351723773\n",
      "Epoch: 46, Loss (standarized): 0.5064477485588045\n",
      "          Validation Loss (standardized): 0.4971340702355506\n",
      "Epoch: 51, Loss (standarized): 0.4648379671285463\n",
      "          Validation Loss (standardized): 0.4719017968932437\n",
      "Epoch: 56, Loss (standarized): 0.4308420771632175\n",
      "          Validation Loss (standardized): 0.4566577488762922\n",
      "Epoch: 61, Loss (standarized): 0.409451920140987\n",
      "          Validation Loss (standardized): 0.45072247376528823\n",
      "Epoch: 66, Loss (standarized): 0.3964199157034711\n",
      "          Validation Loss (standardized): 0.44884345648034857\n",
      "Epoch: 71, Loss (standarized): 0.386808718295346\n",
      "          Validation Loss (standardized): 0.4425683037315439\n",
      "Epoch: 76, Loss (standarized): 0.3774427260299584\n",
      "          Validation Loss (standardized): 0.43128709841043006\n",
      "Epoch: 81, Loss (standarized): 0.3703091005692277\n",
      "          Validation Loss (standardized): 0.42033859314607225\n",
      "Epoch: 86, Loss (standarized): 0.3637428266458552\n",
      "          Validation Loss (standardized): 0.4132669644908444\n",
      "Epoch: 91, Loss (standarized): 0.35679860915188594\n",
      "          Validation Loss (standardized): 0.4079654263955009\n",
      "Epoch: 96, Loss (standarized): 0.3503313050613067\n",
      "          Validation Loss (standardized): 0.40324391601869025\n",
      "Final epoch: 100, Final loss (standarized): 0.3452078657734139\n",
      "Epoch: 1, Loss (standarized): 1.006672212894542\n",
      "          Validation Loss (standardized): 0.7786478428600441\n",
      "Epoch: 6, Loss (standarized): 0.856745912735903\n",
      "          Validation Loss (standardized): 0.7336545442161042\n",
      "Epoch: 11, Loss (standarized): 0.8115096159217468\n",
      "          Validation Loss (standardized): 0.7481821705454655\n",
      "Epoch: 16, Loss (standarized): 0.7839852007342202\n",
      "          Validation Loss (standardized): 0.6978830287130325\n",
      "Epoch: 21, Loss (standarized): 0.7593989441836271\n",
      "          Validation Loss (standardized): 0.6822229820391559\n",
      "Epoch: 26, Loss (standarized): 0.7286460275020346\n",
      "          Validation Loss (standardized): 0.6553235308461143\n",
      "Epoch: 31, Loss (standarized): 0.7005053234341826\n",
      "          Validation Loss (standardized): 0.6368497285567318\n",
      "Epoch: 36, Loss (standarized): 0.6658590812591829\n",
      "          Validation Loss (standardized): 0.6053157364055908\n",
      "Epoch: 41, Loss (standarized): 0.6308797744190031\n",
      "          Validation Loss (standardized): 0.5801504348245999\n",
      "Epoch: 46, Loss (standarized): 0.5912147587720586\n",
      "          Validation Loss (standardized): 0.5501994825872661\n",
      "Epoch: 51, Loss (standarized): 0.5480855054755296\n",
      "          Validation Loss (standardized): 0.5220413916563517\n",
      "Epoch: 56, Loss (standarized): 0.505592833513053\n",
      "          Validation Loss (standardized): 0.4980071207994732\n",
      "Epoch: 61, Loss (standarized): 0.4690077955392765\n",
      "          Validation Loss (standardized): 0.48163255741357497\n",
      "Epoch: 66, Loss (standarized): 0.4428638022399758\n",
      "          Validation Loss (standardized): 0.4732855873578049\n",
      "Epoch: 71, Loss (standarized): 0.4278633618218069\n",
      "          Validation Loss (standardized): 0.4704961041254226\n",
      "Epoch: 76, Loss (standarized): 0.4190985109816234\n",
      "          Validation Loss (standardized): 0.4660979011710339\n",
      "Epoch: 81, Loss (standarized): 0.4144510984954957\n",
      "          Validation Loss (standardized): 0.4600057338659043\n",
      "Epoch: 86, Loss (standarized): 0.41224669146128584\n",
      "          Validation Loss (standardized): 0.45547929020519007\n",
      "Epoch: 91, Loss (standarized): 0.4100575785541703\n",
      "          Validation Loss (standardized): 0.4526533230857109\n",
      "Epoch: 96, Loss (standarized): 0.40727038865925885\n",
      "          Validation Loss (standardized): 0.45012060798580394\n",
      "Final epoch: 100, Final loss (standarized): 0.40493778527042695\n",
      "Epoch: 1, Loss (standarized): 0.8203941774004526\n",
      "          Validation Loss (standardized): 0.7269381025156654\n",
      "Epoch: 6, Loss (standarized): 0.7562009053430961\n",
      "          Validation Loss (standardized): 0.6922942965829414\n",
      "Epoch: 11, Loss (standarized): 0.674050283725766\n",
      "          Validation Loss (standardized): 0.605106604747301\n",
      "Epoch: 16, Loss (standarized): 0.5824126212591839\n",
      "          Validation Loss (standardized): 0.5436630871042116\n",
      "Epoch: 21, Loss (standarized): 0.5079074256202717\n",
      "          Validation Loss (standardized): 0.4908711943152025\n",
      "Epoch: 26, Loss (standarized): 0.4449765757601952\n",
      "          Validation Loss (standardized): 0.4631949902392617\n",
      "Epoch: 31, Loss (standarized): 0.4020267456328878\n",
      "          Validation Loss (standardized): 0.4492970736037023\n",
      "Epoch: 36, Loss (standarized): 0.3872590339429263\n",
      "          Validation Loss (standardized): 0.45161276358942387\n",
      "Epoch: 41, Loss (standarized): 0.3816622973131695\n",
      "          Validation Loss (standardized): 0.4501197316003667\n",
      "Epoch: 46, Loss (standarized): 0.3732450304764595\n",
      "          Validation Loss (standardized): 0.43546228861749925\n",
      "Epoch: 51, Loss (standarized): 0.36680807780971697\n",
      "          Validation Loss (standardized): 0.41543624628087217\n",
      "Epoch: 56, Loss (standarized): 0.3626800344680202\n",
      "          Validation Loss (standardized): 0.4048753251856293\n",
      "Epoch: 61, Loss (standarized): 0.3571257372516538\n",
      "          Validation Loss (standardized): 0.39681489160329847\n",
      "Epoch: 66, Loss (standarized): 0.35046880369512284\n",
      "          Validation Loss (standardized): 0.39396942717849404\n",
      "Epoch: 71, Loss (standarized): 0.344472637439609\n",
      "          Validation Loss (standardized): 0.39115595842637063\n",
      "Epoch: 76, Loss (standarized): 0.33885576030086983\n",
      "          Validation Loss (standardized): 0.385365079694879\n",
      "Epoch: 81, Loss (standarized): 0.33361116894720844\n",
      "          Validation Loss (standardized): 0.37987880165463694\n",
      "Epoch: 86, Loss (standarized): 0.328519553533196\n",
      "          Validation Loss (standardized): 0.3751141546902491\n",
      "Epoch: 91, Loss (standarized): 0.32345925719922103\n",
      "          Validation Loss (standardized): 0.37076324233830066\n",
      "Epoch: 96, Loss (standarized): 0.31879768040713163\n",
      "          Validation Loss (standardized): 0.36320368446265017\n",
      "Final epoch: 100, Final loss (standarized): 0.315298671621944\n",
      "Epoch: 1, Loss (standarized): 0.8724031143441607\n",
      "          Validation Loss (standardized): 0.7120731759497444\n",
      "Epoch: 6, Loss (standarized): 0.7592320142725733\n",
      "          Validation Loss (standardized): 0.6824584061393242\n",
      "Epoch: 11, Loss (standarized): 0.6971247489032161\n",
      "          Validation Loss (standardized): 0.6290865827322126\n",
      "Epoch: 16, Loss (standarized): 0.6339441033593164\n",
      "          Validation Loss (standardized): 0.5708528690814789\n",
      "Epoch: 21, Loss (standarized): 0.5699934560550357\n",
      "          Validation Loss (standardized): 0.5386259971098335\n",
      "Epoch: 26, Loss (standarized): 0.5110332983530633\n",
      "          Validation Loss (standardized): 0.48576386877512884\n",
      "Epoch: 31, Loss (standarized): 0.45763926179175163\n",
      "          Validation Loss (standardized): 0.47420723388498287\n",
      "Epoch: 36, Loss (standarized): 0.4226252041492364\n",
      "          Validation Loss (standardized): 0.44667095500731263\n",
      "Epoch: 41, Loss (standarized): 0.40212303627014656\n",
      "          Validation Loss (standardized): 0.45447648762236414\n",
      "Epoch: 46, Loss (standarized): 0.38911816475757344\n",
      "          Validation Loss (standardized): 0.4424126232020221\n",
      "Epoch: 51, Loss (standarized): 0.3778468861169328\n",
      "          Validation Loss (standardized): 0.4330384025523499\n",
      "Epoch: 56, Loss (standarized): 0.36962438430811057\n",
      "          Validation Loss (standardized): 0.41857676185923687\n",
      "Epoch: 61, Loss (standarized): 0.36270272563505884\n",
      "          Validation Loss (standardized): 0.4115761891099999\n",
      "Epoch: 66, Loss (standarized): 0.3556817769513495\n",
      "          Validation Loss (standardized): 0.40861880175047555\n",
      "Epoch: 71, Loss (standarized): 0.3491529861801887\n",
      "          Validation Loss (standardized): 0.40158826289612903\n",
      "Epoch: 76, Loss (standarized): 0.34281232597972994\n",
      "          Validation Loss (standardized): 0.39248095232156566\n",
      "Epoch: 81, Loss (standarized): 0.3365178558781913\n",
      "          Validation Loss (standardized): 0.38361360657475724\n",
      "Epoch: 86, Loss (standarized): 0.3300037045501628\n",
      "          Validation Loss (standardized): 0.3773505830268573\n",
      "Epoch: 91, Loss (standarized): 0.323152891719065\n",
      "          Validation Loss (standardized): 0.37054540271159664\n",
      "Epoch: 96, Loss (standarized): 0.3158032179290605\n",
      "          Validation Loss (standardized): 0.3622504389300595\n",
      "Final epoch: 100, Final loss (standarized): 0.30950841311171096\n",
      "Epoch: 1, Loss (standarized): 1.0496111472431677\n",
      "          Validation Loss (standardized): 0.7991642367094164\n",
      "Epoch: 6, Loss (standarized): 0.8679393430100444\n",
      "          Validation Loss (standardized): 0.7387916498993886\n",
      "Epoch: 11, Loss (standarized): 0.7883058415665705\n",
      "          Validation Loss (standardized): 0.7324875693086692\n",
      "Epoch: 16, Loss (standarized): 0.7564514788840521\n",
      "          Validation Loss (standardized): 0.6734157342621886\n",
      "Epoch: 21, Loss (standarized): 0.7158842267078873\n",
      "          Validation Loss (standardized): 0.650671996906155\n",
      "Epoch: 26, Loss (standarized): 0.6695440327953046\n",
      "          Validation Loss (standardized): 0.607507509770238\n",
      "Epoch: 31, Loss (standarized): 0.6229361565083898\n",
      "          Validation Loss (standardized): 0.5711598731314496\n",
      "Epoch: 36, Loss (standarized): 0.5574472605182987\n",
      "          Validation Loss (standardized): 0.5247352719915068\n",
      "Epoch: 41, Loss (standarized): 0.49135884063027024\n",
      "          Validation Loss (standardized): 0.4815073079439676\n",
      "Epoch: 46, Loss (standarized): 0.4380250755998569\n",
      "          Validation Loss (standardized): 0.46348548495534553\n",
      "Epoch: 51, Loss (standarized): 0.40637658999848936\n",
      "          Validation Loss (standardized): 0.4580811912172605\n",
      "Epoch: 56, Loss (standarized): 0.39859213424990375\n",
      "          Validation Loss (standardized): 0.4744735642166374\n",
      "Epoch: 61, Loss (standarized): 0.3925572426342411\n",
      "          Validation Loss (standardized): 0.46987566603958586\n",
      "Epoch: 66, Loss (standarized): 0.38206554261867376\n",
      "          Validation Loss (standardized): 0.44800591678156393\n",
      "Epoch: 71, Loss (standarized): 0.37645697179654003\n",
      "          Validation Loss (standardized): 0.4343628043076558\n",
      "Epoch: 76, Loss (standarized): 0.3713768126989104\n",
      "          Validation Loss (standardized): 0.42769780788060996\n",
      "Epoch: 81, Loss (standarized): 0.3636959912148101\n",
      "          Validation Loss (standardized): 0.42302943005024857\n",
      "Epoch: 86, Loss (standarized): 0.3568874212905689\n",
      "          Validation Loss (standardized): 0.41844765281988083\n",
      "Epoch: 91, Loss (standarized): 0.3500835211147549\n",
      "          Validation Loss (standardized): 0.4092607694470995\n",
      "Epoch: 96, Loss (standarized): 0.34260369164775\n",
      "          Validation Loss (standardized): 0.39676676759887075\n",
      "Final epoch: 100, Final loss (standarized): 0.3366259253087307\n",
      "Epoch: 1, Loss (standarized): 0.8372030636546268\n",
      "          Validation Loss (standardized): 0.7490703655484117\n",
      "Epoch: 6, Loss (standarized): 0.7873406409840413\n",
      "          Validation Loss (standardized): 0.6920561837217833\n",
      "Epoch: 11, Loss (standarized): 0.7278379746645888\n",
      "          Validation Loss (standardized): 0.6463459732509859\n",
      "Epoch: 16, Loss (standarized): 0.6581039468083597\n",
      "          Validation Loss (standardized): 0.5960428041704009\n",
      "Epoch: 21, Loss (standarized): 0.5801669472160452\n",
      "          Validation Loss (standardized): 0.5373726696718066\n",
      "Epoch: 26, Loss (standarized): 0.5111211040285171\n",
      "          Validation Loss (standardized): 0.5062402909649322\n",
      "Epoch: 31, Loss (standarized): 0.4610693167354672\n",
      "          Validation Loss (standardized): 0.4686929841919222\n",
      "Epoch: 36, Loss (standarized): 0.4258926579676522\n",
      "          Validation Loss (standardized): 0.4676855647968533\n",
      "Epoch: 41, Loss (standarized): 0.4121186129875273\n",
      "          Validation Loss (standardized): 0.4690786266849335\n",
      "Epoch: 46, Loss (standarized): 0.40361472121055203\n",
      "          Validation Loss (standardized): 0.46039962385063915\n",
      "Epoch: 51, Loss (standarized): 0.39917188090348876\n",
      "          Validation Loss (standardized): 0.4523294942015926\n",
      "Epoch: 56, Loss (standarized): 0.39739956724569003\n",
      "          Validation Loss (standardized): 0.44687794243196544\n",
      "Epoch: 61, Loss (standarized): 0.39509925993884465\n",
      "          Validation Loss (standardized): 0.44408975810083823\n",
      "Epoch: 66, Loss (standarized): 0.39200435877060186\n",
      "          Validation Loss (standardized): 0.4426236557906421\n",
      "Epoch: 71, Loss (standarized): 0.3898292324050777\n",
      "          Validation Loss (standardized): 0.4411476283421959\n",
      "Epoch: 76, Loss (standarized): 0.3877575382153217\n",
      "          Validation Loss (standardized): 0.438104100559639\n",
      "Epoch: 81, Loss (standarized): 0.38589511733824156\n",
      "          Validation Loss (standardized): 0.4350486834252871\n",
      "Epoch: 86, Loss (standarized): 0.38377402232078256\n",
      "          Validation Loss (standardized): 0.4328743651956151\n",
      "Epoch: 91, Loss (standarized): 0.38121095748743344\n",
      "          Validation Loss (standardized): 0.43099701130444873\n",
      "Epoch: 96, Loss (standarized): 0.3788861081943697\n",
      "          Validation Loss (standardized): 0.42906074145240014\n",
      "Final epoch: 100, Final loss (standarized): 0.37734236792076087\n",
      "Epoch: 1, Loss (standarized): 0.9988972414797264\n",
      "          Validation Loss (standardized): 0.7040445657799939\n",
      "Epoch: 6, Loss (standarized): 0.7872538075266988\n",
      "          Validation Loss (standardized): 0.6944478399793635\n",
      "Epoch: 11, Loss (standarized): 0.7510716238529496\n",
      "          Validation Loss (standardized): 0.6570736759684986\n",
      "Epoch: 16, Loss (standarized): 0.6788631624092047\n",
      "          Validation Loss (standardized): 0.6228118198195487\n",
      "Epoch: 21, Loss (standarized): 0.6056760324221651\n",
      "          Validation Loss (standardized): 0.5678495880720661\n",
      "Epoch: 26, Loss (standarized): 0.5532874549090829\n",
      "          Validation Loss (standardized): 0.5145514604254029\n",
      "Epoch: 31, Loss (standarized): 0.5022758288238806\n",
      "          Validation Loss (standardized): 0.5070508383825032\n",
      "Epoch: 36, Loss (standarized): 0.45803258673807934\n",
      "          Validation Loss (standardized): 0.4677360211007256\n",
      "Epoch: 41, Loss (standarized): 0.4278403544463095\n",
      "          Validation Loss (standardized): 0.48439015232766924\n",
      "Epoch: 46, Loss (standarized): 0.41673179202126587\n",
      "          Validation Loss (standardized): 0.4823253695088416\n",
      "Epoch: 51, Loss (standarized): 0.41275001349246254\n",
      "          Validation Loss (standardized): 0.494628519900686\n",
      "Epoch: 56, Loss (standarized): 0.4105137001614111\n",
      "          Validation Loss (standardized): 0.495678103879342\n",
      "Epoch: 61, Loss (standarized): 0.406864776262127\n",
      "          Validation Loss (standardized): 0.4825629461597687\n",
      "Epoch: 66, Loss (standarized): 0.4020816990162981\n",
      "          Validation Loss (standardized): 0.47809580773759824\n",
      "Epoch: 71, Loss (standarized): 0.39836953416488863\n",
      "          Validation Loss (standardized): 0.46390321927898526\n",
      "Epoch: 76, Loss (standarized): 0.3950827625051071\n",
      "          Validation Loss (standardized): 0.45625413067567805\n",
      "Epoch: 81, Loss (standarized): 0.3916520807072377\n",
      "          Validation Loss (standardized): 0.4520089340924392\n",
      "Epoch: 86, Loss (standarized): 0.38754322497589844\n",
      "          Validation Loss (standardized): 0.4457886052932244\n",
      "Epoch: 91, Loss (standarized): 0.383118954609564\n",
      "          Validation Loss (standardized): 0.4437300382143829\n",
      "Epoch: 96, Loss (standarized): 0.37854017666579937\n",
      "          Validation Loss (standardized): 0.43893794770061545\n",
      "Final epoch: 100, Final loss (standarized): 0.37486082810446336\n",
      "Epoch: 1, Loss (standarized): 0.8870217429791009\n",
      "          Validation Loss (standardized): 0.6946577633660402\n",
      "Epoch: 6, Loss (standarized): 0.7522413554482054\n",
      "          Validation Loss (standardized): 0.6819803640234003\n",
      "Epoch: 11, Loss (standarized): 0.6989143304177882\n",
      "          Validation Loss (standardized): 0.6250838267876598\n",
      "Epoch: 16, Loss (standarized): 0.636435260280401\n",
      "          Validation Loss (standardized): 0.5763626118981116\n",
      "Epoch: 21, Loss (standarized): 0.5631720898907032\n",
      "          Validation Loss (standardized): 0.5333280701229356\n",
      "Epoch: 26, Loss (standarized): 0.5012175018393318\n",
      "          Validation Loss (standardized): 0.4881010151047977\n",
      "Epoch: 31, Loss (standarized): 0.45358412143090276\n",
      "          Validation Loss (standardized): 0.4857324029347492\n",
      "Epoch: 36, Loss (standarized): 0.42184148968313223\n",
      "          Validation Loss (standardized): 0.47842766317081115\n",
      "Epoch: 41, Loss (standarized): 0.4138913060315361\n",
      "          Validation Loss (standardized): 0.48581436353975277\n",
      "Epoch: 46, Loss (standarized): 0.41018222750617\n",
      "          Validation Loss (standardized): 0.4948478133089606\n",
      "Epoch: 51, Loss (standarized): 0.4020214116700783\n",
      "          Validation Loss (standardized): 0.48335409221196235\n",
      "Epoch: 56, Loss (standarized): 0.3953865422012982\n",
      "          Validation Loss (standardized): 0.4613697590847785\n",
      "Epoch: 61, Loss (standarized): 0.39125737724744086\n",
      "          Validation Loss (standardized): 0.4515301761105702\n",
      "Epoch: 66, Loss (standarized): 0.38560379942049977\n",
      "          Validation Loss (standardized): 0.4500956546434797\n",
      "Epoch: 71, Loss (standarized): 0.37912275554107044\n",
      "          Validation Loss (standardized): 0.4479118692606285\n",
      "Epoch: 76, Loss (standarized): 0.3732808095526496\n",
      "          Validation Loss (standardized): 0.44059342956413294\n",
      "Epoch: 81, Loss (standarized): 0.3668051217659363\n",
      "          Validation Loss (standardized): 0.42964675405633185\n",
      "Epoch: 86, Loss (standarized): 0.35987822937612723\n",
      "          Validation Loss (standardized): 0.4185708650508907\n",
      "Epoch: 91, Loss (standarized): 0.35248209712959977\n",
      "          Validation Loss (standardized): 0.4087991529876314\n",
      "Epoch: 96, Loss (standarized): 0.34425704840013027\n",
      "          Validation Loss (standardized): 0.39993884469209534\n",
      "Final epoch: 100, Final loss (standarized): 0.3373720061606771\n",
      "Epoch: 1, Loss (standarized): 1.5176194622195955\n",
      "          Validation Loss (standardized): 1.1226117775118736\n",
      "Epoch: 6, Loss (standarized): 0.845349993829496\n",
      "          Validation Loss (standardized): 0.7868453532074008\n",
      "Epoch: 11, Loss (standarized): 0.8116667272491249\n",
      "          Validation Loss (standardized): 0.6988695292638437\n",
      "Epoch: 16, Loss (standarized): 0.7607466512114286\n",
      "          Validation Loss (standardized): 0.7097514140867642\n",
      "Epoch: 21, Loss (standarized): 0.748697037391606\n",
      "          Validation Loss (standardized): 0.6828458544420037\n",
      "Epoch: 26, Loss (standarized): 0.6998471543160725\n",
      "          Validation Loss (standardized): 0.6332775194605778\n",
      "Epoch: 31, Loss (standarized): 0.6789528226799927\n",
      "          Validation Loss (standardized): 0.6146289651729482\n",
      "Epoch: 36, Loss (standarized): 0.6366360107658409\n",
      "          Validation Loss (standardized): 0.5873815196463158\n",
      "Epoch: 41, Loss (standarized): 0.6048924218339851\n",
      "          Validation Loss (standardized): 0.5629101647299106\n",
      "Epoch: 46, Loss (standarized): 0.5612070408060236\n",
      "          Validation Loss (standardized): 0.5298163145910735\n",
      "Epoch: 51, Loss (standarized): 0.5185290646460491\n",
      "          Validation Loss (standardized): 0.4992691694940913\n",
      "Epoch: 56, Loss (standarized): 0.477405854969925\n",
      "          Validation Loss (standardized): 0.47310325102603573\n",
      "Epoch: 61, Loss (standarized): 0.44012868686647877\n",
      "          Validation Loss (standardized): 0.45774535933497873\n",
      "Epoch: 66, Loss (standarized): 0.41293932607101913\n",
      "          Validation Loss (standardized): 0.4483006258838506\n",
      "Epoch: 71, Loss (standarized): 0.3960392938657927\n",
      "          Validation Loss (standardized): 0.446338891066614\n",
      "Epoch: 76, Loss (standarized): 0.38625778621303564\n",
      "          Validation Loss (standardized): 0.44317949105003734\n",
      "Epoch: 81, Loss (standarized): 0.3795828686607446\n",
      "          Validation Loss (standardized): 0.4394955316705247\n",
      "Epoch: 86, Loss (standarized): 0.3745688573945284\n",
      "          Validation Loss (standardized): 0.4349667247457684\n",
      "Epoch: 91, Loss (standarized): 0.3698528508025447\n",
      "          Validation Loss (standardized): 0.4291965431405061\n",
      "Epoch: 96, Loss (standarized): 0.36473720855936864\n",
      "          Validation Loss (standardized): 0.42484555522892625\n",
      "Final epoch: 100, Final loss (standarized): 0.36060586945655715\n",
      "Epoch: 1, Loss (standarized): 0.8316317608579638\n",
      "          Validation Loss (standardized): 0.7607566266767303\n",
      "Epoch: 6, Loss (standarized): 0.8146048631388976\n",
      "          Validation Loss (standardized): 0.7218225592350584\n",
      "Epoch: 11, Loss (standarized): 0.7705115520692261\n",
      "          Validation Loss (standardized): 0.6814148438452091\n",
      "Epoch: 16, Loss (standarized): 0.7250425224207998\n",
      "          Validation Loss (standardized): 0.6493328872358342\n",
      "Epoch: 21, Loss (standarized): 0.6701468187696333\n",
      "          Validation Loss (standardized): 0.6078515738984424\n",
      "Epoch: 26, Loss (standarized): 0.6106636517629442\n",
      "          Validation Loss (standardized): 0.5564893818150529\n",
      "Epoch: 31, Loss (standarized): 0.5498686138446824\n",
      "          Validation Loss (standardized): 0.5276582858870672\n",
      "Epoch: 36, Loss (standarized): 0.49004130293715376\n",
      "          Validation Loss (standardized): 0.47781471312291757\n",
      "Epoch: 41, Loss (standarized): 0.44434504250849416\n",
      "          Validation Loss (standardized): 0.47128881713114296\n",
      "Epoch: 46, Loss (standarized): 0.41719415275513294\n",
      "          Validation Loss (standardized): 0.4620253279513966\n",
      "Epoch: 51, Loss (standarized): 0.40467522324246585\n",
      "          Validation Loss (standardized): 0.46675195761165966\n",
      "Epoch: 56, Loss (standarized): 0.4009268932375085\n",
      "          Validation Loss (standardized): 0.466250214844403\n",
      "Epoch: 61, Loss (standarized): 0.3988856010851937\n",
      "          Validation Loss (standardized): 0.45987607976714556\n",
      "Epoch: 66, Loss (standarized): 0.3995109949128391\n",
      "          Validation Loss (standardized): 0.4568717473699344\n",
      "Epoch: 71, Loss (standarized): 0.4015280912733184\n",
      "          Validation Loss (standardized): 0.45381032277579264\n",
      "Epoch: 76, Loss (standarized): 0.4023735882283315\n",
      "          Validation Loss (standardized): 0.4506557933295865\n",
      "Epoch: 81, Loss (standarized): 0.40154222069594037\n",
      "          Validation Loss (standardized): 0.4503254417666102\n",
      "Epoch: 86, Loss (standarized): 0.39960707905389053\n",
      "          Validation Loss (standardized): 0.44959144887309543\n",
      "Epoch: 91, Loss (standarized): 0.39735083182940617\n",
      "          Validation Loss (standardized): 0.4483178630242328\n",
      "Epoch: 96, Loss (standarized): 0.39526722048818697\n",
      "          Validation Loss (standardized): 0.4474061818147\n",
      "Final epoch: 100, Final loss (standarized): 0.3940122823704545\n",
      "Epoch: 1, Loss (standarized): 0.9651317815826944\n",
      "          Validation Loss (standardized): 0.7462534240190186\n",
      "Epoch: 6, Loss (standarized): 0.842587522366529\n",
      "          Validation Loss (standardized): 0.7292674207180344\n",
      "Epoch: 11, Loss (standarized): 0.7998279291220263\n",
      "          Validation Loss (standardized): 0.7250868802965613\n",
      "Epoch: 16, Loss (standarized): 0.7462202133156408\n",
      "          Validation Loss (standardized): 0.6712183079063752\n",
      "Epoch: 21, Loss (standarized): 0.702184613861861\n",
      "          Validation Loss (standardized): 0.632858934934077\n",
      "Epoch: 26, Loss (standarized): 0.6406675384063438\n",
      "          Validation Loss (standardized): 0.5887140917536727\n",
      "Epoch: 31, Loss (standarized): 0.5804497321549593\n",
      "          Validation Loss (standardized): 0.545065117207141\n",
      "Epoch: 36, Loss (standarized): 0.5189614463000896\n",
      "          Validation Loss (standardized): 0.5032170237973785\n",
      "Epoch: 41, Loss (standarized): 0.46207314139219574\n",
      "          Validation Loss (standardized): 0.4763049720535766\n",
      "Epoch: 46, Loss (standarized): 0.42950809237207555\n",
      "          Validation Loss (standardized): 0.4854840330433351\n",
      "Epoch: 51, Loss (standarized): 0.413841956740434\n",
      "          Validation Loss (standardized): 0.48890796300410694\n",
      "Epoch: 56, Loss (standarized): 0.41075437251304975\n",
      "          Validation Loss (standardized): 0.49049611527305076\n",
      "Epoch: 61, Loss (standarized): 0.40803782203783856\n",
      "          Validation Loss (standardized): 0.49652986446079495\n",
      "Epoch: 66, Loss (standarized): 0.40223368010169125\n",
      "          Validation Loss (standardized): 0.48441202745422707\n",
      "Epoch: 71, Loss (standarized): 0.3955028781745534\n",
      "          Validation Loss (standardized): 0.4662327234062294\n",
      "Epoch: 76, Loss (standarized): 0.39102246735451174\n",
      "          Validation Loss (standardized): 0.4579650546045418\n",
      "Epoch: 81, Loss (standarized): 0.38663715385335906\n",
      "          Validation Loss (standardized): 0.4477934728580607\n",
      "Epoch: 86, Loss (standarized): 0.3816725386238877\n",
      "          Validation Loss (standardized): 0.44026896667645304\n",
      "Epoch: 91, Loss (standarized): 0.37603694833125834\n",
      "          Validation Loss (standardized): 0.4361667698348738\n",
      "Epoch: 96, Loss (standarized): 0.3701265275533244\n",
      "          Validation Loss (standardized): 0.4304144932314584\n",
      "Final epoch: 100, Final loss (standarized): 0.36542178921591206\n",
      "Epoch: 1, Loss (standarized): 1.135478722031463\n",
      "          Validation Loss (standardized): 0.8406065821477011\n",
      "Epoch: 6, Loss (standarized): 0.851564312143784\n",
      "          Validation Loss (standardized): 0.7567970923462164\n",
      "Epoch: 11, Loss (standarized): 0.7340864398434036\n",
      "          Validation Loss (standardized): 0.6556005177499568\n",
      "Epoch: 16, Loss (standarized): 0.7116211037606539\n",
      "          Validation Loss (standardized): 0.653353488895155\n",
      "Epoch: 21, Loss (standarized): 0.6494876888313171\n",
      "          Validation Loss (standardized): 0.5866144300171218\n",
      "Epoch: 26, Loss (standarized): 0.6113822978573438\n",
      "          Validation Loss (standardized): 0.5680098622306466\n",
      "Epoch: 31, Loss (standarized): 0.5645025501805735\n",
      "          Validation Loss (standardized): 0.5334920107983756\n",
      "Epoch: 36, Loss (standarized): 0.5213124915808226\n",
      "          Validation Loss (standardized): 0.4986283117489026\n",
      "Epoch: 41, Loss (standarized): 0.4733828055100956\n",
      "          Validation Loss (standardized): 0.4823348421030087\n",
      "Epoch: 46, Loss (standarized): 0.4407660195732646\n",
      "          Validation Loss (standardized): 0.4666042361777649\n",
      "Epoch: 51, Loss (standarized): 0.41467090073486756\n",
      "          Validation Loss (standardized): 0.45965398788037576\n",
      "Epoch: 56, Loss (standarized): 0.40228083658333247\n",
      "          Validation Loss (standardized): 0.463084599125015\n",
      "Epoch: 61, Loss (standarized): 0.3944344363392721\n",
      "          Validation Loss (standardized): 0.46286563622733723\n",
      "Epoch: 66, Loss (standarized): 0.3880965021163406\n",
      "          Validation Loss (standardized): 0.4559389901003846\n",
      "Epoch: 71, Loss (standarized): 0.3805764133758597\n",
      "          Validation Loss (standardized): 0.44686872549892626\n",
      "Epoch: 76, Loss (standarized): 0.3742076894842342\n",
      "          Validation Loss (standardized): 0.43328544645533085\n",
      "Epoch: 81, Loss (standarized): 0.36897212196848905\n",
      "          Validation Loss (standardized): 0.4249337283341916\n",
      "Epoch: 86, Loss (standarized): 0.36327697412565574\n",
      "          Validation Loss (standardized): 0.4178469677201841\n",
      "Epoch: 91, Loss (standarized): 0.35703382102660264\n",
      "          Validation Loss (standardized): 0.4117024806980195\n",
      "Epoch: 96, Loss (standarized): 0.35085331795420027\n",
      "          Validation Loss (standardized): 0.4077446903605831\n",
      "Final epoch: 100, Final loss (standarized): 0.3457696352295504\n",
      "Epoch: 1, Loss (standarized): 1.0452208061124417\n",
      "          Validation Loss (standardized): 0.7937870970170842\n",
      "Epoch: 6, Loss (standarized): 0.8013105224584767\n",
      "          Validation Loss (standardized): 0.7055644715243159\n",
      "Epoch: 11, Loss (standarized): 0.7356865455474136\n",
      "          Validation Loss (standardized): 0.6701260128883904\n",
      "Epoch: 16, Loss (standarized): 0.7240647296703439\n",
      "          Validation Loss (standardized): 0.6564160651236394\n",
      "Epoch: 21, Loss (standarized): 0.6882368698850027\n",
      "          Validation Loss (standardized): 0.6219658317427944\n",
      "Epoch: 26, Loss (standarized): 0.6693974998159568\n",
      "          Validation Loss (standardized): 0.6118239476858395\n",
      "Epoch: 31, Loss (standarized): 0.6512342362691056\n",
      "          Validation Loss (standardized): 0.5965920317774165\n",
      "Epoch: 36, Loss (standarized): 0.6368407653650776\n",
      "          Validation Loss (standardized): 0.5853666840034214\n",
      "Epoch: 41, Loss (standarized): 0.6230789705279896\n",
      "          Validation Loss (standardized): 0.5751618302571199\n",
      "Epoch: 46, Loss (standarized): 0.6103692964044084\n",
      "          Validation Loss (standardized): 0.5654763679050062\n",
      "Epoch: 51, Loss (standarized): 0.5987762335434039\n",
      "          Validation Loss (standardized): 0.5580761603446848\n",
      "Epoch: 56, Loss (standarized): 0.585614549251025\n",
      "          Validation Loss (standardized): 0.5501612794130356\n",
      "Epoch: 61, Loss (standarized): 0.5731319986527335\n",
      "          Validation Loss (standardized): 0.5368613174899379\n",
      "Epoch: 66, Loss (standarized): 0.5594339613469294\n",
      "          Validation Loss (standardized): 0.5248142211537873\n",
      "Epoch: 71, Loss (standarized): 0.5432921999137718\n",
      "          Validation Loss (standardized): 0.5157190939724409\n",
      "Epoch: 76, Loss (standarized): 0.5261639351714532\n",
      "          Validation Loss (standardized): 0.5008170879393059\n",
      "Epoch: 81, Loss (standarized): 0.5077840959177371\n",
      "          Validation Loss (standardized): 0.4882637429954892\n",
      "Epoch: 86, Loss (standarized): 0.4886698143985185\n",
      "          Validation Loss (standardized): 0.4755789665264837\n",
      "Epoch: 91, Loss (standarized): 0.4701683240096898\n",
      "          Validation Loss (standardized): 0.46447789381284593\n",
      "Epoch: 96, Loss (standarized): 0.45278239222835354\n",
      "          Validation Loss (standardized): 0.4546973565511554\n",
      "Final epoch: 100, Final loss (standarized): 0.4399264776565296\n",
      "Epoch: 1, Loss (standarized): 0.8084129100029485\n",
      "          Validation Loss (standardized): 0.7048313706487661\n",
      "Epoch: 6, Loss (standarized): 0.7569968253894732\n",
      "          Validation Loss (standardized): 0.6759087203505223\n",
      "Epoch: 11, Loss (standarized): 0.7234312721325098\n",
      "          Validation Loss (standardized): 0.6557536057033695\n",
      "Epoch: 16, Loss (standarized): 0.6956227517290758\n",
      "          Validation Loss (standardized): 0.6255260435787765\n",
      "Epoch: 21, Loss (standarized): 0.6755899821167695\n",
      "          Validation Loss (standardized): 0.6136829734368614\n",
      "Epoch: 26, Loss (standarized): 0.6623284886269823\n",
      "          Validation Loss (standardized): 0.6050464447708286\n",
      "Epoch: 31, Loss (standarized): 0.6554410320167208\n",
      "          Validation Loss (standardized): 0.5971572395170256\n",
      "Epoch: 36, Loss (standarized): 0.6556570313783912\n",
      "          Validation Loss (standardized): 0.6007212315888003\n",
      "Epoch: 41, Loss (standarized): 0.6571213544556576\n",
      "          Validation Loss (standardized): 0.60425762220331\n",
      "Epoch: 46, Loss (standarized): 0.6564728486594603\n",
      "          Validation Loss (standardized): 0.6015364968894119\n",
      "Epoch: 51, Loss (standarized): 0.6525199780412719\n",
      "          Validation Loss (standardized): 0.5986920689586555\n",
      "Epoch: 56, Loss (standarized): 0.6454718231794772\n",
      "          Validation Loss (standardized): 0.59287237244291\n",
      "Epoch: 61, Loss (standarized): 0.6385552132320076\n",
      "          Validation Loss (standardized): 0.5902688173842319\n",
      "Epoch: 66, Loss (standarized): 0.6349678266513046\n",
      "          Validation Loss (standardized): 0.5895874675976853\n",
      "Epoch: 71, Loss (standarized): 0.6336110022654887\n",
      "          Validation Loss (standardized): 0.5859194225136626\n",
      "Epoch: 76, Loss (standarized): 0.6323185931097994\n",
      "          Validation Loss (standardized): 0.5805439540299582\n",
      "Epoch: 81, Loss (standarized): 0.6293640889489157\n",
      "          Validation Loss (standardized): 0.5785506798529226\n",
      "Epoch: 86, Loss (standarized): 0.6251457680556893\n",
      "          Validation Loss (standardized): 0.5760436611398866\n",
      "Epoch: 91, Loss (standarized): 0.6213623133235787\n",
      "          Validation Loss (standardized): 0.5733295731190342\n",
      "Epoch: 96, Loss (standarized): 0.6184847868434502\n",
      "          Validation Loss (standardized): 0.5691954763437529\n",
      "Final epoch: 100, Final loss (standarized): 0.6164740404783687\n",
      "Epoch: 1, Loss (standarized): 1.3169474347913894\n",
      "          Validation Loss (standardized): 0.902805679806793\n",
      "Epoch: 6, Loss (standarized): 0.9087375999757278\n",
      "          Validation Loss (standardized): 0.7891083100575915\n",
      "Epoch: 11, Loss (standarized): 0.7725974230147925\n",
      "          Validation Loss (standardized): 0.690085092645831\n",
      "Epoch: 16, Loss (standarized): 0.7715398454512362\n",
      "          Validation Loss (standardized): 0.7003194603835684\n",
      "Epoch: 21, Loss (standarized): 0.7155328139637339\n",
      "          Validation Loss (standardized): 0.6400305788592009\n",
      "Epoch: 26, Loss (standarized): 0.6944089478886746\n",
      "          Validation Loss (standardized): 0.6228860801851569\n",
      "Epoch: 31, Loss (standarized): 0.6612899182979983\n",
      "          Validation Loss (standardized): 0.6025557469936677\n",
      "Epoch: 36, Loss (standarized): 0.6405148790291015\n",
      "          Validation Loss (standardized): 0.5889650677641659\n",
      "Epoch: 41, Loss (standarized): 0.6194562641941046\n",
      "          Validation Loss (standardized): 0.574347200164909\n",
      "Epoch: 46, Loss (standarized): 0.6020464686076012\n",
      "          Validation Loss (standardized): 0.5594960622475134\n",
      "Epoch: 51, Loss (standarized): 0.5836761402259516\n",
      "          Validation Loss (standardized): 0.5499722379572016\n",
      "Epoch: 56, Loss (standarized): 0.5662848175056553\n",
      "          Validation Loss (standardized): 0.5377050363488047\n",
      "Epoch: 61, Loss (standarized): 0.5497433491062579\n",
      "          Validation Loss (standardized): 0.5261460911372992\n",
      "Epoch: 66, Loss (standarized): 0.5335530332506324\n",
      "          Validation Loss (standardized): 0.5174146800632916\n",
      "Epoch: 71, Loss (standarized): 0.5184362548595687\n",
      "          Validation Loss (standardized): 0.5099149605728573\n",
      "Epoch: 76, Loss (standarized): 0.5052991757366739\n",
      "          Validation Loss (standardized): 0.5006398015300658\n",
      "Epoch: 81, Loss (standarized): 0.49379372177829756\n",
      "          Validation Loss (standardized): 0.4959092657130411\n",
      "Epoch: 86, Loss (standarized): 0.4835419416616998\n",
      "          Validation Loss (standardized): 0.48814932344387474\n",
      "Epoch: 91, Loss (standarized): 0.47473863331510663\n",
      "          Validation Loss (standardized): 0.48472511585805833\n",
      "Epoch: 96, Loss (standarized): 0.46735531971118405\n",
      "          Validation Loss (standardized): 0.4807173691188237\n",
      "Final epoch: 100, Final loss (standarized): 0.46204563324891784\n",
      "Epoch: 1, Loss (standarized): 1.0076932022700482\n",
      "          Validation Loss (standardized): 0.7719295895991181\n",
      "Epoch: 6, Loss (standarized): 0.8302527544985475\n",
      "          Validation Loss (standardized): 0.7238867573495589\n",
      "Epoch: 11, Loss (standarized): 0.7930220338040637\n",
      "          Validation Loss (standardized): 0.727205192059115\n",
      "Epoch: 16, Loss (standarized): 0.7751093890929688\n",
      "          Validation Loss (standardized): 0.6974213142990415\n",
      "Epoch: 21, Loss (standarized): 0.7527179671820561\n",
      "          Validation Loss (standardized): 0.6777893398584512\n",
      "Epoch: 26, Loss (standarized): 0.7383876891727147\n",
      "          Validation Loss (standardized): 0.6663938656820766\n",
      "Epoch: 31, Loss (standarized): 0.7260423261718147\n",
      "          Validation Loss (standardized): 0.6588139687257604\n",
      "Epoch: 36, Loss (standarized): 0.714175200796231\n",
      "          Validation Loss (standardized): 0.6462955349633698\n",
      "Epoch: 41, Loss (standarized): 0.7018578815646965\n",
      "          Validation Loss (standardized): 0.6374516609956952\n",
      "Epoch: 46, Loss (standarized): 0.6924173157743324\n",
      "          Validation Loss (standardized): 0.6295547990087297\n",
      "Epoch: 51, Loss (standarized): 0.6856814555802693\n",
      "          Validation Loss (standardized): 0.6245786281760184\n",
      "Epoch: 56, Loss (standarized): 0.6804348406049052\n",
      "          Validation Loss (standardized): 0.619931115692558\n",
      "Epoch: 61, Loss (standarized): 0.6749287566926789\n",
      "          Validation Loss (standardized): 0.6159947544601168\n",
      "Epoch: 66, Loss (standarized): 0.6687296082776354\n",
      "          Validation Loss (standardized): 0.612235805488666\n",
      "Epoch: 71, Loss (standarized): 0.6618116346205476\n",
      "          Validation Loss (standardized): 0.6066085523232255\n",
      "Epoch: 76, Loss (standarized): 0.6550744273672369\n",
      "          Validation Loss (standardized): 0.601513110159514\n",
      "Epoch: 81, Loss (standarized): 0.6472526126451805\n",
      "          Validation Loss (standardized): 0.5941859565666001\n",
      "Epoch: 86, Loss (standarized): 0.6386216680951042\n",
      "          Validation Loss (standardized): 0.5870563381894576\n",
      "Epoch: 91, Loss (standarized): 0.6287523293760571\n",
      "          Validation Loss (standardized): 0.5794019539484744\n",
      "Epoch: 96, Loss (standarized): 0.6180977648324629\n",
      "          Validation Loss (standardized): 0.5702724663043358\n",
      "Final epoch: 100, Final loss (standarized): 0.6084684148376439\n",
      "Epoch: 1, Loss (standarized): 1.765875445392075\n",
      "          Validation Loss (standardized): 1.2633699778352057\n",
      "Epoch: 6, Loss (standarized): 0.8463259355096507\n",
      "          Validation Loss (standardized): 0.805463775447839\n",
      "Epoch: 11, Loss (standarized): 0.8522228859551936\n",
      "          Validation Loss (standardized): 0.7188699291145106\n",
      "Epoch: 16, Loss (standarized): 0.7448083129571254\n",
      "          Validation Loss (standardized): 0.6954044322317499\n",
      "Epoch: 21, Loss (standarized): 0.75155880009345\n",
      "          Validation Loss (standardized): 0.6869453561317863\n",
      "Epoch: 26, Loss (standarized): 0.6942901421210741\n",
      "          Validation Loss (standardized): 0.6310972860297498\n",
      "Epoch: 31, Loss (standarized): 0.6730612977006952\n",
      "          Validation Loss (standardized): 0.6122872180271065\n",
      "Epoch: 36, Loss (standarized): 0.6450370873613375\n",
      "          Validation Loss (standardized): 0.5903977432392767\n",
      "Epoch: 41, Loss (standarized): 0.616544370775421\n",
      "          Validation Loss (standardized): 0.5736532966357129\n",
      "Epoch: 46, Loss (standarized): 0.5895484275280313\n",
      "          Validation Loss (standardized): 0.5507958292932505\n",
      "Epoch: 51, Loss (standarized): 0.5559603908007832\n",
      "          Validation Loss (standardized): 0.5314262996650851\n",
      "Epoch: 56, Loss (standarized): 0.5251125877932203\n",
      "          Validation Loss (standardized): 0.5115664128045407\n",
      "Epoch: 61, Loss (standarized): 0.49646885555095227\n",
      "          Validation Loss (standardized): 0.49798195664211575\n",
      "Epoch: 66, Loss (standarized): 0.47054111160886525\n",
      "          Validation Loss (standardized): 0.4857530413602656\n",
      "Epoch: 71, Loss (standarized): 0.4503696094411572\n",
      "          Validation Loss (standardized): 0.4795879921154642\n",
      "Epoch: 76, Loss (standarized): 0.43530725805438963\n",
      "          Validation Loss (standardized): 0.4749703892417358\n",
      "Epoch: 81, Loss (standarized): 0.4236891401208266\n",
      "          Validation Loss (standardized): 0.4712581418771532\n",
      "Epoch: 86, Loss (standarized): 0.41404349398117324\n",
      "          Validation Loss (standardized): 0.46552323054175415\n",
      "Epoch: 91, Loss (standarized): 0.4054885482640266\n",
      "          Validation Loss (standardized): 0.4571569303984496\n",
      "Epoch: 96, Loss (standarized): 0.398354931255808\n",
      "          Validation Loss (standardized): 0.44992136942405125\n",
      "Final epoch: 100, Final loss (standarized): 0.3930692377424564\n",
      "Epoch: 1, Loss (standarized): 1.5032840928796467\n",
      "          Validation Loss (standardized): 1.1103304406292582\n",
      "Epoch: 6, Loss (standarized): 0.8336720310914298\n",
      "          Validation Loss (standardized): 0.7731895066056625\n",
      "Epoch: 11, Loss (standarized): 0.8295049373458265\n",
      "          Validation Loss (standardized): 0.710772886812402\n",
      "Epoch: 16, Loss (standarized): 0.7601027562530429\n",
      "          Validation Loss (standardized): 0.7041395203120075\n",
      "Epoch: 21, Loss (standarized): 0.764386969705069\n",
      "          Validation Loss (standardized): 0.6948957271145776\n",
      "Epoch: 26, Loss (standarized): 0.7215368526614506\n",
      "          Validation Loss (standardized): 0.6531061097946912\n",
      "Epoch: 31, Loss (standarized): 0.7020126392286766\n",
      "          Validation Loss (standardized): 0.6323629541848264\n",
      "Epoch: 36, Loss (standarized): 0.6798024434077858\n",
      "          Validation Loss (standardized): 0.6174904029538294\n",
      "Epoch: 41, Loss (standarized): 0.6585198027576442\n",
      "          Validation Loss (standardized): 0.6038020753116793\n",
      "Epoch: 46, Loss (standarized): 0.6404890527044225\n",
      "          Validation Loss (standardized): 0.5895612411210938\n",
      "Epoch: 51, Loss (standarized): 0.6191407122114705\n",
      "          Validation Loss (standardized): 0.5724569165003439\n",
      "Epoch: 56, Loss (standarized): 0.5961985945514602\n",
      "          Validation Loss (standardized): 0.5566845930608824\n",
      "Epoch: 61, Loss (standarized): 0.5705708839197065\n",
      "          Validation Loss (standardized): 0.5383241260967241\n",
      "Epoch: 66, Loss (standarized): 0.5437943782311822\n",
      "          Validation Loss (standardized): 0.5224102814470853\n",
      "Epoch: 71, Loss (standarized): 0.5165157026446044\n",
      "          Validation Loss (standardized): 0.5052249744877472\n",
      "Epoch: 76, Loss (standarized): 0.48898221540825604\n",
      "          Validation Loss (standardized): 0.48998745804000315\n",
      "Epoch: 81, Loss (standarized): 0.4650556491571914\n",
      "          Validation Loss (standardized): 0.4800615543289922\n",
      "Epoch: 86, Loss (standarized): 0.4461179658219101\n",
      "          Validation Loss (standardized): 0.47315227912606805\n",
      "Epoch: 91, Loss (standarized): 0.433497963727736\n",
      "          Validation Loss (standardized): 0.4713458508081733\n",
      "Epoch: 96, Loss (standarized): 0.4256393549511056\n",
      "          Validation Loss (standardized): 0.47071149016189634\n",
      "Final epoch: 100, Final loss (standarized): 0.4222529094028614\n",
      "Epoch: 1, Loss (standarized): 1.0543854723182908\n",
      "          Validation Loss (standardized): 0.7568699708961703\n",
      "Epoch: 6, Loss (standarized): 0.8386223050732282\n",
      "          Validation Loss (standardized): 0.7185840110033042\n",
      "Epoch: 11, Loss (standarized): 0.7337019179649031\n",
      "          Validation Loss (standardized): 0.6760961580145366\n",
      "Epoch: 16, Loss (standarized): 0.6785519346741306\n",
      "          Validation Loss (standardized): 0.6117766246185212\n",
      "Epoch: 21, Loss (standarized): 0.6292861759217019\n",
      "          Validation Loss (standardized): 0.5766261709760343\n",
      "Epoch: 26, Loss (standarized): 0.576916168826914\n",
      "          Validation Loss (standardized): 0.547700841398365\n",
      "Epoch: 31, Loss (standarized): 0.5419361899972055\n",
      "          Validation Loss (standardized): 0.5157083208441994\n",
      "Epoch: 36, Loss (standarized): 0.498868038119389\n",
      "          Validation Loss (standardized): 0.5028030170642519\n",
      "Epoch: 41, Loss (standarized): 0.46437544301849376\n",
      "          Validation Loss (standardized): 0.4789992060756462\n",
      "Epoch: 46, Loss (standarized): 0.4429572580706048\n",
      "          Validation Loss (standardized): 0.4795672811243598\n",
      "Epoch: 51, Loss (standarized): 0.4254771969843107\n",
      "          Validation Loss (standardized): 0.4736278890390034\n",
      "Epoch: 56, Loss (standarized): 0.41739537766180207\n",
      "          Validation Loss (standardized): 0.4771441602116118\n",
      "Epoch: 61, Loss (standarized): 0.41254711936293587\n",
      "          Validation Loss (standardized): 0.4774644846833846\n",
      "Epoch: 66, Loss (standarized): 0.4100086295312284\n",
      "          Validation Loss (standardized): 0.4797564282705815\n",
      "Epoch: 71, Loss (standarized): 0.40727904625600464\n",
      "          Validation Loss (standardized): 0.4716165568295105\n",
      "Epoch: 76, Loss (standarized): 0.40516472709232065\n",
      "          Validation Loss (standardized): 0.46957988032284015\n",
      "Epoch: 81, Loss (standarized): 0.4027587257584832\n",
      "          Validation Loss (standardized): 0.46498413129150906\n",
      "Epoch: 86, Loss (standarized): 0.4006732042853365\n",
      "          Validation Loss (standardized): 0.4597668354727364\n",
      "Epoch: 91, Loss (standarized): 0.39851470484154594\n",
      "          Validation Loss (standardized): 0.4569027606581549\n",
      "Epoch: 96, Loss (standarized): 0.39607263424018535\n",
      "          Validation Loss (standardized): 0.45405889063235294\n",
      "Final epoch: 100, Final loss (standarized): 0.3940444867995643\n",
      "Epoch: 1, Loss (standarized): 1.1886836325975425\n",
      "          Validation Loss (standardized): 0.9118053198619684\n",
      "Epoch: 6, Loss (standarized): 0.891321142878601\n",
      "          Validation Loss (standardized): 0.7843489934494192\n",
      "Epoch: 11, Loss (standarized): 0.8027922176868968\n",
      "          Validation Loss (standardized): 0.7186597991439337\n",
      "Epoch: 16, Loss (standarized): 0.7987612988905731\n",
      "          Validation Loss (standardized): 0.7317395259419022\n",
      "Epoch: 21, Loss (standarized): 0.7571044997236858\n",
      "          Validation Loss (standardized): 0.6757849804877245\n",
      "Epoch: 26, Loss (standarized): 0.7228140147021043\n",
      "          Validation Loss (standardized): 0.6513746319995145\n",
      "Epoch: 31, Loss (standarized): 0.6903340456307367\n",
      "          Validation Loss (standardized): 0.6191015975094867\n",
      "Epoch: 36, Loss (standarized): 0.6544485260859275\n",
      "          Validation Loss (standardized): 0.6008590139161982\n",
      "Epoch: 41, Loss (standarized): 0.6154596617546998\n",
      "          Validation Loss (standardized): 0.5634149766296108\n",
      "Epoch: 46, Loss (standarized): 0.5714998903090805\n",
      "          Validation Loss (standardized): 0.5383665447400976\n",
      "Epoch: 51, Loss (standarized): 0.5277287650113056\n",
      "          Validation Loss (standardized): 0.5079400683726466\n",
      "Epoch: 56, Loss (standarized): 0.4840369554035103\n",
      "          Validation Loss (standardized): 0.48345005503732513\n",
      "Epoch: 61, Loss (standarized): 0.44657668254720184\n",
      "          Validation Loss (standardized): 0.4661465707322673\n",
      "Epoch: 66, Loss (standarized): 0.4191688061961266\n",
      "          Validation Loss (standardized): 0.45710547198688917\n",
      "Epoch: 71, Loss (standarized): 0.4039266493246222\n",
      "          Validation Loss (standardized): 0.4586859350014225\n",
      "Epoch: 76, Loss (standarized): 0.39470259654088286\n",
      "          Validation Loss (standardized): 0.45436217619433245\n",
      "Epoch: 81, Loss (standarized): 0.3878041617319013\n",
      "          Validation Loss (standardized): 0.4465020892339416\n",
      "Epoch: 86, Loss (standarized): 0.3823227188160536\n",
      "          Validation Loss (standardized): 0.4395307697732384\n",
      "Epoch: 91, Loss (standarized): 0.3777763877638317\n",
      "          Validation Loss (standardized): 0.43166062639842545\n",
      "Epoch: 96, Loss (standarized): 0.37329381248171145\n",
      "          Validation Loss (standardized): 0.42618002753647166\n",
      "Final epoch: 100, Final loss (standarized): 0.369721076786676\n",
      "Epoch: 1, Loss (standarized): 0.8359296293277219\n",
      "          Validation Loss (standardized): 0.7227679509381941\n",
      "Epoch: 6, Loss (standarized): 0.7894594929120864\n",
      "          Validation Loss (standardized): 0.7162836754903352\n",
      "Epoch: 11, Loss (standarized): 0.7355227965876074\n",
      "          Validation Loss (standardized): 0.6514120812183636\n",
      "Epoch: 16, Loss (standarized): 0.6646202928720317\n",
      "          Validation Loss (standardized): 0.6079164375164166\n",
      "Epoch: 21, Loss (standarized): 0.5848002532862375\n",
      "          Validation Loss (standardized): 0.5419578036953054\n",
      "Epoch: 26, Loss (standarized): 0.5037245524056534\n",
      "          Validation Loss (standardized): 0.485682895516388\n",
      "Epoch: 31, Loss (standarized): 0.43380561852140065\n",
      "          Validation Loss (standardized): 0.4651549260944843\n",
      "Epoch: 36, Loss (standarized): 0.41167959398671883\n",
      "          Validation Loss (standardized): 0.48727551311593226\n",
      "Epoch: 41, Loss (standarized): 0.4117200708356303\n",
      "          Validation Loss (standardized): 0.5008966831609392\n",
      "Epoch: 46, Loss (standarized): 0.40269621940007416\n",
      "          Validation Loss (standardized): 0.48154631400200726\n",
      "Epoch: 51, Loss (standarized): 0.38974448687033697\n",
      "          Validation Loss (standardized): 0.4536976589565643\n",
      "Epoch: 56, Loss (standarized): 0.38404991916766146\n",
      "          Validation Loss (standardized): 0.43649337130737\n",
      "Epoch: 61, Loss (standarized): 0.3756363229544427\n",
      "          Validation Loss (standardized): 0.4280657680732821\n",
      "Epoch: 66, Loss (standarized): 0.3650534632478616\n",
      "          Validation Loss (standardized): 0.4224458920182564\n",
      "Epoch: 71, Loss (standarized): 0.355683727559587\n",
      "          Validation Loss (standardized): 0.4150923858037862\n",
      "Epoch: 76, Loss (standarized): 0.3452871492004562\n",
      "          Validation Loss (standardized): 0.3994192390494855\n",
      "Epoch: 81, Loss (standarized): 0.3338597786903355\n",
      "          Validation Loss (standardized): 0.3804810973011681\n",
      "Epoch: 86, Loss (standarized): 0.3224167439673989\n",
      "          Validation Loss (standardized): 0.3661319370493171\n",
      "Epoch: 91, Loss (standarized): 0.3111370435084668\n",
      "          Validation Loss (standardized): 0.35281544960254296\n",
      "Epoch: 96, Loss (standarized): 0.3004404482515838\n",
      "          Validation Loss (standardized): 0.34420264189331007\n",
      "Final epoch: 100, Final loss (standarized): 0.29272075100718203\n",
      "Epoch: 1, Loss (standarized): 1.1658708330274572\n",
      "          Validation Loss (standardized): 0.8669672015802458\n",
      "Epoch: 6, Loss (standarized): 0.8225947618753182\n",
      "          Validation Loss (standardized): 0.750160935673194\n",
      "Epoch: 11, Loss (standarized): 0.7293833850366934\n",
      "          Validation Loss (standardized): 0.6551946786198868\n",
      "Epoch: 16, Loss (standarized): 0.7151936566551182\n",
      "          Validation Loss (standardized): 0.6621412521734149\n",
      "Epoch: 21, Loss (standarized): 0.6673882764663273\n",
      "          Validation Loss (standardized): 0.607027854378611\n",
      "Epoch: 26, Loss (standarized): 0.6302752005062748\n",
      "          Validation Loss (standardized): 0.5833944334855167\n",
      "Epoch: 31, Loss (standarized): 0.5909098451392797\n",
      "          Validation Loss (standardized): 0.5542799719176493\n",
      "Epoch: 36, Loss (standarized): 0.5541398987069148\n",
      "          Validation Loss (standardized): 0.5267576805289655\n",
      "Epoch: 41, Loss (standarized): 0.5152977424607018\n",
      "          Validation Loss (standardized): 0.5058188533246438\n",
      "Epoch: 46, Loss (standarized): 0.4834241305476096\n",
      "          Validation Loss (standardized): 0.4884437829233717\n",
      "Epoch: 51, Loss (standarized): 0.45715728682566964\n",
      "          Validation Loss (standardized): 0.47904462524133257\n",
      "Epoch: 56, Loss (standarized): 0.4393174085632193\n",
      "          Validation Loss (standardized): 0.4779953707800405\n",
      "Epoch: 61, Loss (standarized): 0.428427856270294\n",
      "          Validation Loss (standardized): 0.4756201322722148\n",
      "Epoch: 66, Loss (standarized): 0.42302165817468146\n",
      "          Validation Loss (standardized): 0.47616574021435853\n",
      "Epoch: 71, Loss (standarized): 0.41956801222861595\n",
      "          Validation Loss (standardized): 0.4732243946882421\n",
      "Epoch: 76, Loss (standarized): 0.4179428269722957\n",
      "          Validation Loss (standardized): 0.47016484549231186\n",
      "Epoch: 81, Loss (standarized): 0.4171200977345424\n",
      "          Validation Loss (standardized): 0.4677757635919182\n",
      "Epoch: 86, Loss (standarized): 0.4162970949662556\n",
      "          Validation Loss (standardized): 0.46498235702383633\n",
      "Epoch: 91, Loss (standarized): 0.4149642866487856\n",
      "          Validation Loss (standardized): 0.4638270027752223\n",
      "Epoch: 96, Loss (standarized): 0.41298435073935025\n",
      "          Validation Loss (standardized): 0.4627526632456282\n",
      "Final epoch: 100, Final loss (standarized): 0.4112543007613175\n",
      "Epoch: 1, Loss (standarized): 0.8356611336117787\n",
      "          Validation Loss (standardized): 0.7397239211552976\n",
      "Epoch: 6, Loss (standarized): 0.8058046364051222\n",
      "          Validation Loss (standardized): 0.7192743145324169\n",
      "Epoch: 11, Loss (standarized): 0.7466787150480346\n",
      "          Validation Loss (standardized): 0.6538681603491738\n",
      "Epoch: 16, Loss (standarized): 0.6694845917443493\n",
      "          Validation Loss (standardized): 0.6044187938146188\n",
      "Epoch: 21, Loss (standarized): 0.5820663820763835\n",
      "          Validation Loss (standardized): 0.5393776947452068\n",
      "Epoch: 26, Loss (standarized): 0.5023401300493588\n",
      "          Validation Loss (standardized): 0.4810118659226595\n",
      "Epoch: 31, Loss (standarized): 0.43708742716966975\n",
      "          Validation Loss (standardized): 0.46626815087821444\n",
      "Epoch: 36, Loss (standarized): 0.4060911747910631\n",
      "          Validation Loss (standardized): 0.46961527695543054\n",
      "Epoch: 41, Loss (standarized): 0.39661326099953437\n",
      "          Validation Loss (standardized): 0.47333009916673646\n",
      "Epoch: 46, Loss (standarized): 0.39121784188111847\n",
      "          Validation Loss (standardized): 0.46965496922849276\n",
      "Epoch: 51, Loss (standarized): 0.38022819218843085\n",
      "          Validation Loss (standardized): 0.4496226585932838\n",
      "Epoch: 56, Loss (standarized): 0.3727702849443856\n",
      "          Validation Loss (standardized): 0.4296584969211874\n",
      "Epoch: 61, Loss (standarized): 0.3669763228307544\n",
      "          Validation Loss (standardized): 0.4167456913531644\n",
      "Epoch: 66, Loss (standarized): 0.3593409543074622\n",
      "          Validation Loss (standardized): 0.41083024519917716\n",
      "Epoch: 71, Loss (standarized): 0.3522518844140914\n",
      "          Validation Loss (standardized): 0.40803603164162205\n",
      "Epoch: 76, Loss (standarized): 0.3460528026822835\n",
      "          Validation Loss (standardized): 0.4010243368500496\n",
      "Epoch: 81, Loss (standarized): 0.33978224247376615\n",
      "          Validation Loss (standardized): 0.3905367069408723\n",
      "Epoch: 86, Loss (standarized): 0.3336677296966094\n",
      "          Validation Loss (standardized): 0.38093411569654784\n",
      "Epoch: 91, Loss (standarized): 0.32740896913765655\n",
      "          Validation Loss (standardized): 0.3735675060318502\n",
      "Epoch: 96, Loss (standarized): 0.32067386496199374\n",
      "          Validation Loss (standardized): 0.36802489199846916\n",
      "Final epoch: 100, Final loss (standarized): 0.314959864856609\n",
      "Epoch: 1, Loss (standarized): 1.0073602942381563\n",
      "          Validation Loss (standardized): 0.7935768949708971\n",
      "Epoch: 6, Loss (standarized): 0.8642095024637552\n",
      "          Validation Loss (standardized): 0.7449765806959227\n",
      "Epoch: 11, Loss (standarized): 0.7980083373213904\n",
      "          Validation Loss (standardized): 0.7329876200387808\n",
      "Epoch: 16, Loss (standarized): 0.7643387856895967\n",
      "          Validation Loss (standardized): 0.6747988221006564\n",
      "Epoch: 21, Loss (standarized): 0.7160970054932898\n",
      "          Validation Loss (standardized): 0.6441716367195239\n",
      "Epoch: 26, Loss (standarized): 0.6602136074458704\n",
      "          Validation Loss (standardized): 0.6003637978313927\n",
      "Epoch: 31, Loss (standarized): 0.6087170537526227\n",
      "          Validation Loss (standardized): 0.5539572719202239\n",
      "Epoch: 36, Loss (standarized): 0.5390835783132844\n",
      "          Validation Loss (standardized): 0.514718560762623\n",
      "Epoch: 41, Loss (standarized): 0.47653647417977646\n",
      "          Validation Loss (standardized): 0.476285022479405\n",
      "Epoch: 46, Loss (standarized): 0.4363846323797631\n",
      "          Validation Loss (standardized): 0.46049176732718783\n",
      "Epoch: 51, Loss (standarized): 0.40566394494219987\n",
      "          Validation Loss (standardized): 0.45300274172484706\n",
      "Epoch: 56, Loss (standarized): 0.3941834332913006\n",
      "          Validation Loss (standardized): 0.4600983072281862\n",
      "Epoch: 61, Loss (standarized): 0.3890532282181384\n",
      "          Validation Loss (standardized): 0.45674635431425087\n",
      "Epoch: 66, Loss (standarized): 0.38114940375924167\n",
      "          Validation Loss (standardized): 0.45367462573244877\n",
      "Epoch: 71, Loss (standarized): 0.3716983480770172\n",
      "          Validation Loss (standardized): 0.43154953003618163\n",
      "Epoch: 76, Loss (standarized): 0.36361705622807505\n",
      "          Validation Loss (standardized): 0.4146679012477141\n",
      "Epoch: 81, Loss (standarized): 0.3565840070576918\n",
      "          Validation Loss (standardized): 0.40338751691915375\n",
      "Epoch: 86, Loss (standarized): 0.34921171204108803\n",
      "          Validation Loss (standardized): 0.3913597981329615\n",
      "Epoch: 91, Loss (standarized): 0.34150522439212316\n",
      "          Validation Loss (standardized): 0.38760196650615614\n",
      "Epoch: 96, Loss (standarized): 0.33377025849054665\n",
      "          Validation Loss (standardized): 0.38158908991453694\n",
      "Final epoch: 100, Final loss (standarized): 0.32756490724413634\n",
      "Epoch: 1, Loss (standarized): 1.457667487068435\n",
      "Epoch: 6, Loss (standarized): 0.7512793086663827\n",
      "Epoch: 11, Loss (standarized): 0.7137539402211359\n",
      "Epoch: 16, Loss (standarized): 0.6126509346736232\n",
      "Epoch: 21, Loss (standarized): 0.5997559123347417\n",
      "Epoch: 26, Loss (standarized): 0.5400012163360413\n",
      "Epoch: 31, Loss (standarized): 0.5230518012405285\n",
      "Epoch: 36, Loss (standarized): 0.48420779085024507\n",
      "Epoch: 41, Loss (standarized): 0.4641670140849616\n",
      "Epoch: 46, Loss (standarized): 0.43877093240261117\n",
      "Epoch: 51, Loss (standarized): 0.41769088814335315\n",
      "Epoch: 56, Loss (standarized): 0.39922400786449497\n",
      "Epoch: 61, Loss (standarized): 0.383516256331658\n",
      "Epoch: 66, Loss (standarized): 0.36933807597629753\n",
      "Epoch: 71, Loss (standarized): 0.3538745694354865\n",
      "Epoch: 76, Loss (standarized): 0.3366956315479638\n",
      "Epoch: 81, Loss (standarized): 0.318094215227512\n",
      "Epoch: 86, Loss (standarized): 0.2977415493478854\n",
      "Epoch: 91, Loss (standarized): 0.2762297427126292\n",
      "Epoch: 96, Loss (standarized): 0.25701431015643644\n",
      "Final epoch: 100, Final loss (standarized): 0.24100050196942976\n",
      "Epoch: 1, Loss (standarized): 2.3016624517852704\n",
      "Epoch: 6, Loss (standarized): 0.8035773989879408\n",
      "Epoch: 11, Loss (standarized): 0.8247641791669971\n",
      "Epoch: 16, Loss (standarized): 0.6555007817912321\n",
      "Epoch: 21, Loss (standarized): 0.5995309343180047\n",
      "Epoch: 26, Loss (standarized): 0.5106565827817062\n",
      "Epoch: 31, Loss (standarized): 0.4748557508893292\n",
      "Epoch: 36, Loss (standarized): 0.45706541490635333\n",
      "Epoch: 41, Loss (standarized): 0.44512707126038975\n",
      "Epoch: 46, Loss (standarized): 0.4317908570328367\n",
      "Epoch: 51, Loss (standarized): 0.42068123630139337\n",
      "Epoch: 56, Loss (standarized): 0.41351440963082997\n",
      "Epoch: 61, Loss (standarized): 0.4079823717825307\n",
      "Epoch: 66, Loss (standarized): 0.4035016196811562\n",
      "Epoch: 71, Loss (standarized): 0.39752798422892566\n",
      "Epoch: 76, Loss (standarized): 0.39218179051074553\n",
      "Epoch: 81, Loss (standarized): 0.38773743518049963\n",
      "Epoch: 86, Loss (standarized): 0.38450063577894805\n",
      "Epoch: 91, Loss (standarized): 0.3808283389159877\n",
      "Epoch: 96, Loss (standarized): 0.3776832199306905\n",
      "Final epoch: 100, Final loss (standarized): 0.3753375727630869\n",
      "Epoch: 1, Loss (standarized): 3.624279915693632\n",
      "Epoch: 6, Loss (standarized): 0.7231283049093538\n",
      "Epoch: 11, Loss (standarized): 1.0777557248828313\n",
      "Epoch: 16, Loss (standarized): 0.7279844086361522\n",
      "Epoch: 21, Loss (standarized): 0.682056503018016\n",
      "Epoch: 26, Loss (standarized): 0.6360725329570232\n",
      "Epoch: 31, Loss (standarized): 0.5797683911101308\n",
      "Epoch: 36, Loss (standarized): 0.53192244154867\n",
      "Epoch: 41, Loss (standarized): 0.4869924367677778\n",
      "Epoch: 46, Loss (standarized): 0.4501990776599133\n",
      "Epoch: 51, Loss (standarized): 0.4325411304209258\n",
      "Epoch: 56, Loss (standarized): 0.4172568954512985\n",
      "Epoch: 61, Loss (standarized): 0.4060066774582506\n",
      "Epoch: 66, Loss (standarized): 0.39682722536364295\n",
      "Epoch: 71, Loss (standarized): 0.3853717250326662\n",
      "Epoch: 76, Loss (standarized): 0.374666742204569\n",
      "Epoch: 81, Loss (standarized): 0.3646544222787777\n",
      "Epoch: 86, Loss (standarized): 0.3560996522046408\n",
      "Epoch: 91, Loss (standarized): 0.3488513032093322\n",
      "Epoch: 96, Loss (standarized): 0.3419327962339997\n",
      "Final epoch: 100, Final loss (standarized): 0.33633101205076804\n",
      "Epoch: 1, Loss (standarized): 1.2030872339196972\n",
      "Epoch: 6, Loss (standarized): 0.8488474332358649\n",
      "Epoch: 11, Loss (standarized): 0.674948676226036\n",
      "Epoch: 16, Loss (standarized): 0.6012756545179764\n",
      "Epoch: 21, Loss (standarized): 0.5191389632207659\n",
      "Epoch: 26, Loss (standarized): 0.4501020752129226\n",
      "Epoch: 31, Loss (standarized): 0.4402376700211508\n",
      "Epoch: 36, Loss (standarized): 0.4186936080237748\n",
      "Epoch: 41, Loss (standarized): 0.3938128025942612\n",
      "Epoch: 46, Loss (standarized): 0.383950076722375\n",
      "Epoch: 51, Loss (standarized): 0.3689712070153024\n",
      "Epoch: 56, Loss (standarized): 0.3563903350838099\n",
      "Epoch: 61, Loss (standarized): 0.3490329685179794\n",
      "Epoch: 66, Loss (standarized): 0.339157153025935\n",
      "Epoch: 71, Loss (standarized): 0.3295674740067841\n",
      "Epoch: 76, Loss (standarized): 0.3199717266093675\n",
      "Epoch: 81, Loss (standarized): 0.31091201393456946\n",
      "Epoch: 86, Loss (standarized): 0.3024580232007209\n",
      "Epoch: 91, Loss (standarized): 0.294892455967615\n",
      "Epoch: 96, Loss (standarized): 0.290065221859047\n",
      "Final epoch: 100, Final loss (standarized): 0.2865912709236641\n",
      "Epoch: 1, Loss (standarized): 4.898456021366357\n",
      "Epoch: 6, Loss (standarized): 0.7617531394206871\n",
      "Epoch: 11, Loss (standarized): 1.027110969490635\n",
      "Epoch: 16, Loss (standarized): 0.7849889560712338\n",
      "Epoch: 21, Loss (standarized): 0.5936261730984945\n",
      "Epoch: 26, Loss (standarized): 0.6283870553279456\n",
      "Epoch: 31, Loss (standarized): 0.5836317169619638\n",
      "Epoch: 36, Loss (standarized): 0.5356122411655372\n",
      "Epoch: 41, Loss (standarized): 0.5272225155157064\n",
      "Epoch: 46, Loss (standarized): 0.5061928670294829\n",
      "Epoch: 51, Loss (standarized): 0.49520422251992285\n",
      "Epoch: 56, Loss (standarized): 0.4868341258422594\n",
      "Epoch: 61, Loss (standarized): 0.48057375239317085\n",
      "Epoch: 66, Loss (standarized): 0.47396415151303845\n",
      "Epoch: 71, Loss (standarized): 0.4695504030254913\n",
      "Epoch: 76, Loss (standarized): 0.46675617589824825\n",
      "Epoch: 81, Loss (standarized): 0.4634813824209377\n",
      "Epoch: 86, Loss (standarized): 0.4607389257003313\n",
      "Epoch: 91, Loss (standarized): 0.45868028423184787\n",
      "Epoch: 96, Loss (standarized): 0.4561409007401645\n",
      "Final epoch: 100, Final loss (standarized): 0.4544340998793247\n",
      "Epoch: 1, Loss (standarized): 0.9273342655654137\n",
      "Epoch: 6, Loss (standarized): 0.6445119735350453\n",
      "Epoch: 11, Loss (standarized): 0.5726848909957887\n",
      "Epoch: 16, Loss (standarized): 0.5301937573666626\n",
      "Epoch: 21, Loss (standarized): 0.5022099956991894\n",
      "Epoch: 26, Loss (standarized): 0.4843820665459175\n",
      "Epoch: 31, Loss (standarized): 0.4765397319352907\n",
      "Epoch: 36, Loss (standarized): 0.4678143879741441\n",
      "Epoch: 41, Loss (standarized): 0.46441658006904446\n",
      "Epoch: 46, Loss (standarized): 0.46170569478119383\n",
      "Epoch: 51, Loss (standarized): 0.45121720408367877\n",
      "Epoch: 56, Loss (standarized): 0.4435931573753479\n",
      "Epoch: 61, Loss (standarized): 0.4353665799216834\n",
      "Epoch: 66, Loss (standarized): 0.43130969186523666\n",
      "Epoch: 71, Loss (standarized): 0.4289736272715506\n",
      "Epoch: 76, Loss (standarized): 0.4276998235362166\n",
      "Epoch: 81, Loss (standarized): 0.4266622384479085\n",
      "Epoch: 86, Loss (standarized): 0.4268360479358463\n",
      "Epoch: 91, Loss (standarized): 0.4275597529148879\n",
      "Epoch: 96, Loss (standarized): 0.427053894030923\n",
      "Final epoch: 100, Final loss (standarized): 0.4275738737529715\n",
      "Epoch: 1, Loss (standarized): 1.3187306716744733\n",
      "Epoch: 6, Loss (standarized): 0.7994982062626947\n",
      "Epoch: 11, Loss (standarized): 0.6770760561795668\n",
      "Epoch: 16, Loss (standarized): 0.6518197802386874\n",
      "Epoch: 21, Loss (standarized): 0.5962762982053088\n",
      "Epoch: 26, Loss (standarized): 0.5633164653611714\n",
      "Epoch: 31, Loss (standarized): 0.5351717621826934\n",
      "Epoch: 36, Loss (standarized): 0.5141397536770749\n",
      "Epoch: 41, Loss (standarized): 0.49620865316474533\n",
      "Epoch: 46, Loss (standarized): 0.4806369429617529\n",
      "Epoch: 51, Loss (standarized): 0.46787215475780125\n",
      "Epoch: 56, Loss (standarized): 0.45651462934020826\n",
      "Epoch: 61, Loss (standarized): 0.44327807131571023\n",
      "Epoch: 66, Loss (standarized): 0.4329538629063066\n",
      "Epoch: 71, Loss (standarized): 0.4240791262426953\n",
      "Epoch: 76, Loss (standarized): 0.4179573522822004\n",
      "Epoch: 81, Loss (standarized): 0.41322835371812205\n",
      "Epoch: 86, Loss (standarized): 0.40991808946576186\n",
      "Epoch: 91, Loss (standarized): 0.4075322421787428\n",
      "Epoch: 96, Loss (standarized): 0.40586079725057334\n",
      "Final epoch: 100, Final loss (standarized): 0.4044553756929112\n",
      "Epoch: 1, Loss (standarized): 0.9591063581862411\n",
      "Epoch: 6, Loss (standarized): 0.7520610975690264\n",
      "Epoch: 11, Loss (standarized): 0.6627789199909377\n",
      "Epoch: 16, Loss (standarized): 0.6305535290687105\n",
      "Epoch: 21, Loss (standarized): 0.5990793810147872\n",
      "Epoch: 26, Loss (standarized): 0.5707038449514462\n",
      "Epoch: 31, Loss (standarized): 0.5500375389088521\n",
      "Epoch: 36, Loss (standarized): 0.5262172076088352\n",
      "Epoch: 41, Loss (standarized): 0.5087059607352366\n",
      "Epoch: 46, Loss (standarized): 0.49708395643321424\n",
      "Epoch: 51, Loss (standarized): 0.4889958668312743\n",
      "Epoch: 56, Loss (standarized): 0.4825843576705496\n",
      "Epoch: 61, Loss (standarized): 0.4775578798648207\n",
      "Epoch: 66, Loss (standarized): 0.4734968153020553\n",
      "Epoch: 71, Loss (standarized): 0.4694659389289132\n",
      "Epoch: 76, Loss (standarized): 0.46513128217926025\n",
      "Epoch: 81, Loss (standarized): 0.4613194559475068\n",
      "Epoch: 86, Loss (standarized): 0.45777566245204343\n",
      "Epoch: 91, Loss (standarized): 0.4535819214369717\n",
      "Epoch: 96, Loss (standarized): 0.44986318272509396\n",
      "Final epoch: 100, Final loss (standarized): 0.4457452422780017\n",
      "Epoch: 1, Loss (standarized): 2.0059113526421624\n",
      "Epoch: 6, Loss (standarized): 0.7277653372585137\n",
      "Epoch: 11, Loss (standarized): 0.6948703800751685\n",
      "Epoch: 16, Loss (standarized): 0.495267921544208\n",
      "Epoch: 21, Loss (standarized): 0.4671523645335956\n",
      "Epoch: 26, Loss (standarized): 0.4347703171760955\n",
      "Epoch: 31, Loss (standarized): 0.4117570833300996\n",
      "Epoch: 36, Loss (standarized): 0.4023642720344733\n",
      "Epoch: 41, Loss (standarized): 0.3846493774573954\n",
      "Epoch: 46, Loss (standarized): 0.3691900812937183\n",
      "Epoch: 51, Loss (standarized): 0.3599725998107182\n",
      "Epoch: 56, Loss (standarized): 0.3490328147449102\n",
      "Epoch: 61, Loss (standarized): 0.33720306374307357\n",
      "Epoch: 66, Loss (standarized): 0.3264633879497821\n",
      "Epoch: 71, Loss (standarized): 0.3162198230736973\n",
      "Epoch: 76, Loss (standarized): 0.30617557931088407\n",
      "Epoch: 81, Loss (standarized): 0.2976741383592354\n",
      "Epoch: 86, Loss (standarized): 0.29025237390995573\n",
      "Epoch: 91, Loss (standarized): 0.28330129891641975\n",
      "Epoch: 96, Loss (standarized): 0.27754902476702364\n",
      "Final epoch: 100, Final loss (standarized): 0.2732737404063087\n",
      "Epoch: 1, Loss (standarized): 6.012342363178844\n",
      "Epoch: 6, Loss (standarized): 0.9473883495336665\n",
      "Epoch: 11, Loss (standarized): 0.9160026941317394\n",
      "Epoch: 16, Loss (standarized): 0.9975550567868854\n",
      "Epoch: 21, Loss (standarized): 0.6415969753701168\n",
      "Epoch: 26, Loss (standarized): 0.5958477527068444\n",
      "Epoch: 31, Loss (standarized): 0.5765840910861284\n",
      "Epoch: 36, Loss (standarized): 0.5251904388910297\n",
      "Epoch: 41, Loss (standarized): 0.5077160100894542\n",
      "Epoch: 46, Loss (standarized): 0.4777356569805399\n",
      "Epoch: 51, Loss (standarized): 0.459891853482438\n",
      "Epoch: 56, Loss (standarized): 0.4415454575625949\n",
      "Epoch: 61, Loss (standarized): 0.4285323846125686\n",
      "Epoch: 66, Loss (standarized): 0.42028863278778283\n",
      "Epoch: 71, Loss (standarized): 0.4125613015999983\n",
      "Epoch: 76, Loss (standarized): 0.4069089408677874\n",
      "Epoch: 81, Loss (standarized): 0.4030367757145855\n",
      "Epoch: 86, Loss (standarized): 0.3994301589788408\n",
      "Epoch: 91, Loss (standarized): 0.39676398246634853\n",
      "Epoch: 96, Loss (standarized): 0.39423646084797903\n",
      "Final epoch: 100, Final loss (standarized): 0.39237641532200057\n",
      "Epoch: 1, Loss (standarized): 1.926871296048681\n",
      "Epoch: 6, Loss (standarized): 0.8066973344666193\n",
      "Epoch: 11, Loss (standarized): 0.779550272284199\n",
      "Epoch: 16, Loss (standarized): 0.6995161411193977\n",
      "Epoch: 21, Loss (standarized): 0.5766845176996817\n",
      "Epoch: 26, Loss (standarized): 0.5306327117025607\n",
      "Epoch: 31, Loss (standarized): 0.4942031249697106\n",
      "Epoch: 36, Loss (standarized): 0.47501358314701686\n",
      "Epoch: 41, Loss (standarized): 0.456584424871724\n",
      "Epoch: 46, Loss (standarized): 0.44361166958134923\n",
      "Epoch: 51, Loss (standarized): 0.43641947041992796\n",
      "Epoch: 56, Loss (standarized): 0.43061279539773184\n",
      "Epoch: 61, Loss (standarized): 0.42702779808798363\n",
      "Epoch: 66, Loss (standarized): 0.42236959935010976\n",
      "Epoch: 71, Loss (standarized): 0.4176263513974499\n",
      "Epoch: 76, Loss (standarized): 0.413721470944174\n",
      "Epoch: 81, Loss (standarized): 0.41042912795656356\n",
      "Epoch: 86, Loss (standarized): 0.40716102897722184\n",
      "Epoch: 91, Loss (standarized): 0.40397000999274385\n",
      "Epoch: 96, Loss (standarized): 0.39963529241359363\n",
      "Final epoch: 100, Final loss (standarized): 0.395617562991167\n",
      "Epoch: 1, Loss (standarized): 1.7717304574861692\n",
      "Epoch: 6, Loss (standarized): 0.8407963597985842\n",
      "Epoch: 11, Loss (standarized): 0.789943134312673\n",
      "Epoch: 16, Loss (standarized): 0.6928065972443159\n",
      "Epoch: 21, Loss (standarized): 0.6492522392676602\n",
      "Epoch: 26, Loss (standarized): 0.5856140683617042\n",
      "Epoch: 31, Loss (standarized): 0.5357053000404808\n",
      "Epoch: 36, Loss (standarized): 0.49551272293274967\n",
      "Epoch: 41, Loss (standarized): 0.46630695354597657\n",
      "Epoch: 46, Loss (standarized): 0.4446771721497578\n",
      "Epoch: 51, Loss (standarized): 0.42657237290005534\n",
      "Epoch: 56, Loss (standarized): 0.4084263446225118\n",
      "Epoch: 61, Loss (standarized): 0.39211037441852264\n",
      "Epoch: 66, Loss (standarized): 0.37915086554925587\n",
      "Epoch: 71, Loss (standarized): 0.36822601785444065\n",
      "Epoch: 76, Loss (standarized): 0.3590407254187215\n",
      "Epoch: 81, Loss (standarized): 0.3487557333835575\n",
      "Epoch: 86, Loss (standarized): 0.33914036578741447\n",
      "Epoch: 91, Loss (standarized): 0.32948457519033064\n",
      "Epoch: 96, Loss (standarized): 0.3200026459090278\n",
      "Final epoch: 100, Final loss (standarized): 0.3127182446520201\n",
      "Epoch: 1, Loss (standarized): 1.9098838312077242\n",
      "Epoch: 6, Loss (standarized): 0.7837602986788539\n",
      "Epoch: 11, Loss (standarized): 0.7470692004934094\n",
      "Epoch: 16, Loss (standarized): 0.6066772805226208\n",
      "Epoch: 21, Loss (standarized): 0.591023296724728\n",
      "Epoch: 26, Loss (standarized): 0.5217554584247365\n",
      "Epoch: 31, Loss (standarized): 0.5016032818732142\n",
      "Epoch: 36, Loss (standarized): 0.46851057455911194\n",
      "Epoch: 41, Loss (standarized): 0.45145633432874543\n",
      "Epoch: 46, Loss (standarized): 0.4324606226289238\n",
      "Epoch: 51, Loss (standarized): 0.41878224878786535\n",
      "Epoch: 56, Loss (standarized): 0.4063960673639416\n",
      "Epoch: 61, Loss (standarized): 0.39567971864395357\n",
      "Epoch: 66, Loss (standarized): 0.3825749781693893\n",
      "Epoch: 71, Loss (standarized): 0.36759018666200427\n",
      "Epoch: 76, Loss (standarized): 0.35182258113069176\n",
      "Epoch: 81, Loss (standarized): 0.3353080084723509\n",
      "Epoch: 86, Loss (standarized): 0.3169314690704178\n",
      "Epoch: 91, Loss (standarized): 0.2973958873540492\n",
      "Epoch: 96, Loss (standarized): 0.2759855127671526\n",
      "Final epoch: 100, Final loss (standarized): 0.25803124204560574\n",
      "Epoch: 1, Loss (standarized): 1.3475602784535137\n",
      "Epoch: 6, Loss (standarized): 0.758066837339713\n",
      "Epoch: 11, Loss (standarized): 0.5962343554157611\n",
      "Epoch: 16, Loss (standarized): 0.5437054980754532\n",
      "Epoch: 21, Loss (standarized): 0.48915526140127125\n",
      "Epoch: 26, Loss (standarized): 0.4664403908529284\n",
      "Epoch: 31, Loss (standarized): 0.44431869921967576\n",
      "Epoch: 36, Loss (standarized): 0.4319033375196543\n",
      "Epoch: 41, Loss (standarized): 0.4252221155621846\n",
      "Epoch: 46, Loss (standarized): 0.41846442246488513\n",
      "Epoch: 51, Loss (standarized): 0.411591892501958\n",
      "Epoch: 56, Loss (standarized): 0.40448575067740505\n",
      "Epoch: 61, Loss (standarized): 0.3979832557883271\n",
      "Epoch: 66, Loss (standarized): 0.3913610406790301\n",
      "Epoch: 71, Loss (standarized): 0.384465876609127\n",
      "Epoch: 76, Loss (standarized): 0.3779299121194998\n",
      "Epoch: 81, Loss (standarized): 0.3722715175900154\n",
      "Epoch: 86, Loss (standarized): 0.3671344997384552\n",
      "Epoch: 91, Loss (standarized): 0.3627949985057664\n",
      "Epoch: 96, Loss (standarized): 0.35882378337632037\n",
      "Final epoch: 100, Final loss (standarized): 0.35578389583138015\n",
      "Epoch: 1, Loss (standarized): 3.895482739969873\n",
      "Epoch: 6, Loss (standarized): 1.2206237020155117\n",
      "Epoch: 11, Loss (standarized): 1.029854109534327\n",
      "Epoch: 16, Loss (standarized): 0.8251561983702809\n",
      "Epoch: 21, Loss (standarized): 0.667916277636462\n",
      "Epoch: 26, Loss (standarized): 0.6445011062767385\n",
      "Epoch: 31, Loss (standarized): 0.5683378887897728\n",
      "Epoch: 36, Loss (standarized): 0.5328683600019897\n",
      "Epoch: 41, Loss (standarized): 0.4959407251625409\n",
      "Epoch: 46, Loss (standarized): 0.47671204938055417\n",
      "Epoch: 51, Loss (standarized): 0.46004508612427947\n",
      "Epoch: 56, Loss (standarized): 0.44696872092039863\n",
      "Epoch: 61, Loss (standarized): 0.4388112174744695\n",
      "Epoch: 66, Loss (standarized): 0.4307398925582554\n",
      "Epoch: 71, Loss (standarized): 0.4212620906750536\n",
      "Epoch: 76, Loss (standarized): 0.40960008257841823\n",
      "Epoch: 81, Loss (standarized): 0.40088838337444077\n",
      "Epoch: 86, Loss (standarized): 0.39257097944775843\n",
      "Epoch: 91, Loss (standarized): 0.3847058991130881\n",
      "Epoch: 96, Loss (standarized): 0.37713676956499287\n",
      "Final epoch: 100, Final loss (standarized): 0.37123865487836555\n",
      "Epoch: 1, Loss (standarized): 1.774095381427458\n",
      "Epoch: 6, Loss (standarized): 0.7639411218494764\n",
      "Epoch: 11, Loss (standarized): 0.7453999628612964\n",
      "Epoch: 16, Loss (standarized): 0.5447986875628876\n",
      "Epoch: 21, Loss (standarized): 0.47777470025464536\n",
      "Epoch: 26, Loss (standarized): 0.40332761350745033\n",
      "Epoch: 31, Loss (standarized): 0.4215669950292088\n",
      "Epoch: 36, Loss (standarized): 0.39169385321646855\n",
      "Epoch: 41, Loss (standarized): 0.37756170527214516\n",
      "Epoch: 46, Loss (standarized): 0.3710487168421781\n",
      "Epoch: 51, Loss (standarized): 0.3576659065375196\n",
      "Epoch: 56, Loss (standarized): 0.3473113303807605\n",
      "Epoch: 61, Loss (standarized): 0.3352519451262324\n",
      "Epoch: 66, Loss (standarized): 0.3222284345382116\n",
      "Epoch: 71, Loss (standarized): 0.30702136996924223\n",
      "Epoch: 76, Loss (standarized): 0.2911734153916622\n",
      "Epoch: 81, Loss (standarized): 0.2758203207167679\n",
      "Epoch: 86, Loss (standarized): 0.25813132544848194\n",
      "Epoch: 91, Loss (standarized): 0.2423442388808657\n",
      "Epoch: 96, Loss (standarized): 0.228289540846281\n",
      "Final epoch: 100, Final loss (standarized): 0.21482522761339032\n",
      "Epoch: 1, Loss (standarized): 1.3841915196846946\n",
      "          Validation Loss (standardized): 0.936440539123102\n",
      "Epoch: 6, Loss (standarized): 0.811052035123975\n",
      "          Validation Loss (standardized): 0.8024725471005614\n",
      "Epoch: 11, Loss (standarized): 0.6974768764788234\n",
      "          Validation Loss (standardized): 0.746215403243653\n",
      "Epoch: 16, Loss (standarized): 0.6025862677174796\n",
      "          Validation Loss (standardized): 0.5869434372258637\n",
      "Epoch: 21, Loss (standarized): 0.5719613658452666\n",
      "          Validation Loss (standardized): 0.5310491759759526\n",
      "Epoch: 26, Loss (standarized): 0.5093951959362952\n",
      "          Validation Loss (standardized): 0.5385254433439228\n",
      "Epoch: 31, Loss (standarized): 0.48715417084531687\n",
      "          Validation Loss (standardized): 0.5227587075250624\n",
      "Epoch: 36, Loss (standarized): 0.44676840392054284\n",
      "          Validation Loss (standardized): 0.45942069618579545\n",
      "Epoch: 41, Loss (standarized): 0.42288117250335483\n",
      "          Validation Loss (standardized): 0.45461930671599754\n",
      "Epoch: 46, Loss (standarized): 0.3999146093281971\n",
      "          Validation Loss (standardized): 0.4456644890346623\n",
      "Epoch: 51, Loss (standarized): 0.3825274107272838\n",
      "          Validation Loss (standardized): 0.4254338867719808\n",
      "Epoch: 56, Loss (standarized): 0.369573873420212\n",
      "          Validation Loss (standardized): 0.4200030352919674\n",
      "Epoch: 61, Loss (standarized): 0.35534395789937107\n",
      "          Validation Loss (standardized): 0.4056176041921381\n",
      "Epoch: 66, Loss (standarized): 0.33896070331621553\n",
      "          Validation Loss (standardized): 0.3913336336576514\n",
      "Epoch: 71, Loss (standarized): 0.3225540933626232\n",
      "          Validation Loss (standardized): 0.37256550442179276\n",
      "Epoch: 76, Loss (standarized): 0.30466976589899597\n",
      "          Validation Loss (standardized): 0.35712835306981916\n",
      "Epoch: 81, Loss (standarized): 0.28809614885693147\n",
      "          Validation Loss (standardized): 0.336049660808087\n",
      "Epoch: 86, Loss (standarized): 0.2725845386078053\n",
      "          Validation Loss (standardized): 0.32506455447808535\n",
      "Epoch: 91, Loss (standarized): 0.25710677323826686\n",
      "          Validation Loss (standardized): 0.3072212570382646\n",
      "Epoch: 96, Loss (standarized): 0.241384705091051\n",
      "          Validation Loss (standardized): 0.29398688087527075\n",
      "Final epoch: 100, Final loss (standarized): 0.2289811875519796\n",
      "Epoch: 1, Loss (standarized): 3.0146452035150992\n",
      "          Validation Loss (standardized): 2.080410337871641\n",
      "Epoch: 6, Loss (standarized): 0.828519120693932\n",
      "          Validation Loss (standardized): 0.7507474163568034\n",
      "Epoch: 11, Loss (standarized): 0.793912923176441\n",
      "          Validation Loss (standardized): 0.8838300739263437\n",
      "Epoch: 16, Loss (standarized): 0.7081508241258149\n",
      "          Validation Loss (standardized): 0.7177482827114895\n",
      "Epoch: 21, Loss (standarized): 0.5498145380573929\n",
      "          Validation Loss (standardized): 0.5965463993468153\n",
      "Epoch: 26, Loss (standarized): 0.5348902016182551\n",
      "          Validation Loss (standardized): 0.5472340390684056\n",
      "Epoch: 31, Loss (standarized): 0.4747673123101176\n",
      "          Validation Loss (standardized): 0.5306554491669496\n",
      "Epoch: 36, Loss (standarized): 0.4494203515925081\n",
      "          Validation Loss (standardized): 0.5191291181427107\n",
      "Epoch: 41, Loss (standarized): 0.43445015480704335\n",
      "          Validation Loss (standardized): 0.49339007485298025\n",
      "Epoch: 46, Loss (standarized): 0.416304261651682\n",
      "          Validation Loss (standardized): 0.473933589471785\n",
      "Epoch: 51, Loss (standarized): 0.4051850017306139\n",
      "          Validation Loss (standardized): 0.4549580417931625\n",
      "Epoch: 56, Loss (standarized): 0.39302586523515604\n",
      "          Validation Loss (standardized): 0.4358974152759931\n",
      "Epoch: 61, Loss (standarized): 0.3767776972699875\n",
      "          Validation Loss (standardized): 0.42143192398573004\n",
      "Epoch: 66, Loss (standarized): 0.36343180856402\n",
      "          Validation Loss (standardized): 0.412355513111409\n",
      "Epoch: 71, Loss (standarized): 0.3520689266077046\n",
      "          Validation Loss (standardized): 0.40008709120861163\n",
      "Epoch: 76, Loss (standarized): 0.3403121205591004\n",
      "          Validation Loss (standardized): 0.38709011815748584\n",
      "Epoch: 81, Loss (standarized): 0.33068311654450305\n",
      "          Validation Loss (standardized): 0.3774514667046265\n",
      "Epoch: 86, Loss (standarized): 0.3226723352781228\n",
      "          Validation Loss (standardized): 0.3697708945251497\n",
      "Epoch: 91, Loss (standarized): 0.31517373520098435\n",
      "          Validation Loss (standardized): 0.36441765931593567\n",
      "Epoch: 96, Loss (standarized): 0.30872617383003675\n",
      "          Validation Loss (standardized): 0.3612490689779999\n",
      "Final epoch: 100, Final loss (standarized): 0.3041820135512272\n",
      "Epoch: 1, Loss (standarized): 1.1753846488651878\n",
      "          Validation Loss (standardized): 1.075742211261964\n",
      "Epoch: 6, Loss (standarized): 0.7251075666543298\n",
      "          Validation Loss (standardized): 0.6764262782830758\n",
      "Epoch: 11, Loss (standarized): 0.617980055570666\n",
      "          Validation Loss (standardized): 0.6591169621982522\n",
      "Epoch: 16, Loss (standarized): 0.5098840713969193\n",
      "          Validation Loss (standardized): 0.5252373266017597\n",
      "Epoch: 21, Loss (standarized): 0.4609791408688193\n",
      "          Validation Loss (standardized): 0.4919288779294695\n",
      "Epoch: 26, Loss (standarized): 0.43287868594672024\n",
      "          Validation Loss (standardized): 0.4911963249110323\n",
      "Epoch: 31, Loss (standarized): 0.4177001993557797\n",
      "          Validation Loss (standardized): 0.47094446492348174\n",
      "Epoch: 36, Loss (standarized): 0.4127803921043213\n",
      "          Validation Loss (standardized): 0.4893769025994287\n",
      "Epoch: 41, Loss (standarized): 0.39812897916832074\n",
      "          Validation Loss (standardized): 0.44629974746523343\n",
      "Epoch: 46, Loss (standarized): 0.38385923722856213\n",
      "          Validation Loss (standardized): 0.4256860896831354\n",
      "Epoch: 51, Loss (standarized): 0.37261240661389144\n",
      "          Validation Loss (standardized): 0.4265837835175791\n",
      "Epoch: 56, Loss (standarized): 0.3617340222201863\n",
      "          Validation Loss (standardized): 0.4091881727072832\n",
      "Epoch: 61, Loss (standarized): 0.35105906576348234\n",
      "          Validation Loss (standardized): 0.3888231931727866\n",
      "Epoch: 66, Loss (standarized): 0.33946583471670067\n",
      "          Validation Loss (standardized): 0.3772873211694096\n",
      "Epoch: 71, Loss (standarized): 0.32725848054291007\n",
      "          Validation Loss (standardized): 0.36832747709247754\n",
      "Epoch: 76, Loss (standarized): 0.3144928526200571\n",
      "          Validation Loss (standardized): 0.359215044946676\n",
      "Epoch: 81, Loss (standarized): 0.3027359796040793\n",
      "          Validation Loss (standardized): 0.3474662244133877\n",
      "Epoch: 86, Loss (standarized): 0.29286841040762723\n",
      "          Validation Loss (standardized): 0.339037058459061\n",
      "Epoch: 91, Loss (standarized): 0.28513370741748617\n",
      "          Validation Loss (standardized): 0.331108714171406\n",
      "Epoch: 96, Loss (standarized): 0.27916192245826527\n",
      "          Validation Loss (standardized): 0.3272005246775128\n",
      "Final epoch: 100, Final loss (standarized): 0.27610943052030407\n",
      "Epoch: 1, Loss (standarized): 2.0453017280071597\n",
      "          Validation Loss (standardized): 1.3182911034048381\n",
      "Epoch: 6, Loss (standarized): 0.82915826947133\n",
      "          Validation Loss (standardized): 0.9028464787855767\n",
      "Epoch: 11, Loss (standarized): 0.8668913767464599\n",
      "          Validation Loss (standardized): 0.9797457263777244\n",
      "Epoch: 16, Loss (standarized): 0.7116109049092525\n",
      "          Validation Loss (standardized): 0.7059913851527759\n",
      "Epoch: 21, Loss (standarized): 0.6857527492543802\n",
      "          Validation Loss (standardized): 0.656105159060607\n",
      "Epoch: 26, Loss (standarized): 0.6471110406697852\n",
      "          Validation Loss (standardized): 0.6223706820989513\n",
      "Epoch: 31, Loss (standarized): 0.6041175718384787\n",
      "          Validation Loss (standardized): 0.6292569477045332\n",
      "Epoch: 36, Loss (standarized): 0.5763287318837657\n",
      "          Validation Loss (standardized): 0.6156494100590436\n",
      "Epoch: 41, Loss (standarized): 0.5379879362370172\n",
      "          Validation Loss (standardized): 0.5547737893049651\n",
      "Epoch: 46, Loss (standarized): 0.5078502192213303\n",
      "          Validation Loss (standardized): 0.5210865280991878\n",
      "Epoch: 51, Loss (standarized): 0.473109406663057\n",
      "          Validation Loss (standardized): 0.5138714425973296\n",
      "Epoch: 56, Loss (standarized): 0.44865257710623485\n",
      "          Validation Loss (standardized): 0.4953131976554976\n",
      "Epoch: 61, Loss (standarized): 0.426140315396608\n",
      "          Validation Loss (standardized): 0.471508492510386\n",
      "Epoch: 66, Loss (standarized): 0.4064492976840751\n",
      "          Validation Loss (standardized): 0.46619627741455594\n",
      "Epoch: 71, Loss (standarized): 0.38954131174349527\n",
      "          Validation Loss (standardized): 0.4512451515708458\n",
      "Epoch: 76, Loss (standarized): 0.3740333482054248\n",
      "          Validation Loss (standardized): 0.44341401927841045\n",
      "Epoch: 81, Loss (standarized): 0.3565605343378424\n",
      "          Validation Loss (standardized): 0.42153334886989746\n",
      "Epoch: 86, Loss (standarized): 0.3419004720264526\n",
      "          Validation Loss (standardized): 0.405914689523862\n",
      "Epoch: 91, Loss (standarized): 0.32853630793455524\n",
      "          Validation Loss (standardized): 0.3883491346863307\n",
      "Epoch: 96, Loss (standarized): 0.31523026336033483\n",
      "          Validation Loss (standardized): 0.3704620944194679\n",
      "Final epoch: 100, Final loss (standarized): 0.30357328483216883\n",
      "Epoch: 1, Loss (standarized): 1.6440162739221051\n",
      "          Validation Loss (standardized): 1.1939365573729441\n",
      "Epoch: 6, Loss (standarized): 0.9235586015308573\n",
      "          Validation Loss (standardized): 0.7716202514560788\n",
      "Epoch: 11, Loss (standarized): 0.6368791481274994\n",
      "          Validation Loss (standardized): 0.6975748539734323\n",
      "Epoch: 16, Loss (standarized): 0.6453768138159341\n",
      "          Validation Loss (standardized): 0.7445022251111589\n",
      "Epoch: 21, Loss (standarized): 0.5471171146129836\n",
      "          Validation Loss (standardized): 0.5619979911067449\n",
      "Epoch: 26, Loss (standarized): 0.5264310735629212\n",
      "          Validation Loss (standardized): 0.5253525230444239\n",
      "Epoch: 31, Loss (standarized): 0.48232898182470973\n",
      "          Validation Loss (standardized): 0.544045171366979\n",
      "Epoch: 36, Loss (standarized): 0.4628910703003449\n",
      "          Validation Loss (standardized): 0.5095710390183401\n",
      "Epoch: 41, Loss (standarized): 0.44503572324703133\n",
      "          Validation Loss (standardized): 0.4778165009284621\n",
      "Epoch: 46, Loss (standarized): 0.4340201494636238\n",
      "          Validation Loss (standardized): 0.4797726243831042\n",
      "Epoch: 51, Loss (standarized): 0.4277544018530741\n",
      "          Validation Loss (standardized): 0.4862780715291345\n",
      "Epoch: 56, Loss (standarized): 0.4217914749828785\n",
      "          Validation Loss (standardized): 0.4742998757832952\n",
      "Epoch: 61, Loss (standarized): 0.4207940640193574\n",
      "          Validation Loss (standardized): 0.47272481045066717\n",
      "Epoch: 66, Loss (standarized): 0.4204484308007433\n",
      "          Validation Loss (standardized): 0.4703437514525302\n",
      "Epoch: 71, Loss (standarized): 0.41987757374643253\n",
      "          Validation Loss (standardized): 0.47243977478395516\n",
      "Epoch: 76, Loss (standarized): 0.4196765703907245\n",
      "          Validation Loss (standardized): 0.4732747585406528\n",
      "Epoch: 81, Loss (standarized): 0.41896487161679563\n",
      "          Validation Loss (standardized): 0.4689858461236558\n",
      "Epoch: 86, Loss (standarized): 0.41782385006457334\n",
      "          Validation Loss (standardized): 0.465797776330547\n",
      "Epoch: 91, Loss (standarized): 0.41649207586563497\n",
      "          Validation Loss (standardized): 0.4640812443329181\n",
      "Epoch: 96, Loss (standarized): 0.415904674580437\n",
      "          Validation Loss (standardized): 0.4633058690806301\n",
      "Final epoch: 100, Final loss (standarized): 0.414430520716639\n",
      "Epoch: 1, Loss (standarized): 1.5820221358055364\n",
      "          Validation Loss (standardized): 1.0196408527300365\n",
      "Epoch: 6, Loss (standarized): 0.7921957920205638\n",
      "          Validation Loss (standardized): 0.8993641234853982\n",
      "Epoch: 11, Loss (standarized): 0.7582972380432279\n",
      "          Validation Loss (standardized): 0.7744078273538048\n",
      "Epoch: 16, Loss (standarized): 0.6753059384154324\n",
      "          Validation Loss (standardized): 0.6613267671543528\n",
      "Epoch: 21, Loss (standarized): 0.6536747136021938\n",
      "          Validation Loss (standardized): 0.6370372820750323\n",
      "Epoch: 26, Loss (standarized): 0.6073078700426707\n",
      "          Validation Loss (standardized): 0.6225863874846642\n",
      "Epoch: 31, Loss (standarized): 0.5764047683495536\n",
      "          Validation Loss (standardized): 0.5898413213965958\n",
      "Epoch: 36, Loss (standarized): 0.5473054303388262\n",
      "          Validation Loss (standardized): 0.5438725331048054\n",
      "Epoch: 41, Loss (standarized): 0.5218084520650341\n",
      "          Validation Loss (standardized): 0.5234520625543402\n",
      "Epoch: 46, Loss (standarized): 0.49876434100045497\n",
      "          Validation Loss (standardized): 0.5129909505888584\n",
      "Epoch: 51, Loss (standarized): 0.47907250680478936\n",
      "          Validation Loss (standardized): 0.49179171304857705\n",
      "Epoch: 56, Loss (standarized): 0.4620658032076118\n",
      "          Validation Loss (standardized): 0.4840333463568033\n",
      "Epoch: 61, Loss (standarized): 0.4468148167004532\n",
      "          Validation Loss (standardized): 0.47361107954392195\n",
      "Epoch: 66, Loss (standarized): 0.43450097538422144\n",
      "          Validation Loss (standardized): 0.4636091242116311\n",
      "Epoch: 71, Loss (standarized): 0.42598342477901224\n",
      "          Validation Loss (standardized): 0.45464408801810907\n",
      "Epoch: 76, Loss (standarized): 0.41989882365633263\n",
      "          Validation Loss (standardized): 0.4531135953433626\n",
      "Epoch: 81, Loss (standarized): 0.41512539165544854\n",
      "          Validation Loss (standardized): 0.4508640532747297\n",
      "Epoch: 86, Loss (standarized): 0.4127617718221021\n",
      "          Validation Loss (standardized): 0.44861577786450596\n",
      "Epoch: 91, Loss (standarized): 0.4113597037279548\n",
      "          Validation Loss (standardized): 0.44510123992597345\n",
      "Epoch: 96, Loss (standarized): 0.41086576915822703\n",
      "          Validation Loss (standardized): 0.4451012447319032\n",
      "Final epoch: 100, Final loss (standarized): 0.41036639482154447\n",
      "Epoch: 1, Loss (standarized): 3.177525795356419\n",
      "          Validation Loss (standardized): 1.854372495409783\n",
      "Epoch: 6, Loss (standarized): 0.8572937728943509\n",
      "          Validation Loss (standardized): 0.8718313216104303\n",
      "Epoch: 11, Loss (standarized): 0.9123125958494727\n",
      "          Validation Loss (standardized): 1.0217191231898606\n",
      "Epoch: 16, Loss (standarized): 0.6865117519634936\n",
      "          Validation Loss (standardized): 0.6665161925138702\n",
      "Epoch: 21, Loss (standarized): 0.6712498692659065\n",
      "          Validation Loss (standardized): 0.6111511733525924\n",
      "Epoch: 26, Loss (standarized): 0.5812789294588646\n",
      "          Validation Loss (standardized): 0.6087827124757709\n",
      "Epoch: 31, Loss (standarized): 0.5354640073111043\n",
      "          Validation Loss (standardized): 0.5577239305288333\n",
      "Epoch: 36, Loss (standarized): 0.49688935188532657\n",
      "          Validation Loss (standardized): 0.4990776992797524\n",
      "Epoch: 41, Loss (standarized): 0.46227887769997694\n",
      "          Validation Loss (standardized): 0.4920742287264022\n",
      "Epoch: 46, Loss (standarized): 0.43808709256430856\n",
      "          Validation Loss (standardized): 0.4605607888549683\n",
      "Epoch: 51, Loss (standarized): 0.4224421440155151\n",
      "          Validation Loss (standardized): 0.4559825900479072\n",
      "Epoch: 56, Loss (standarized): 0.4136423386585368\n",
      "          Validation Loss (standardized): 0.45912853972407774\n",
      "Epoch: 61, Loss (standarized): 0.4058299584402528\n",
      "          Validation Loss (standardized): 0.4458741794804574\n",
      "Epoch: 66, Loss (standarized): 0.40070582050119563\n",
      "          Validation Loss (standardized): 0.43996188988578183\n",
      "Epoch: 71, Loss (standarized): 0.3967467711000615\n",
      "          Validation Loss (standardized): 0.4448754981832069\n",
      "Epoch: 76, Loss (standarized): 0.39491348637174645\n",
      "          Validation Loss (standardized): 0.4458835962408152\n",
      "Epoch: 81, Loss (standarized): 0.3926929660197954\n",
      "          Validation Loss (standardized): 0.4408049085699315\n",
      "Epoch: 86, Loss (standarized): 0.3919758635222526\n",
      "          Validation Loss (standardized): 0.4398881733372154\n",
      "Epoch: 91, Loss (standarized): 0.3905777134819704\n",
      "          Validation Loss (standardized): 0.4377799063663433\n",
      "Epoch: 96, Loss (standarized): 0.38874468701099063\n",
      "          Validation Loss (standardized): 0.44054901714779826\n",
      "Final epoch: 100, Final loss (standarized): 0.38773729141523505\n",
      "Epoch: 1, Loss (standarized): 2.883030613134516\n",
      "          Validation Loss (standardized): 1.7606452679999876\n",
      "Epoch: 6, Loss (standarized): 0.9954731806561725\n",
      "          Validation Loss (standardized): 1.0089702552883928\n",
      "Epoch: 11, Loss (standarized): 0.8162314732342211\n",
      "          Validation Loss (standardized): 0.868878539018702\n",
      "Epoch: 16, Loss (standarized): 0.8206092846055515\n",
      "          Validation Loss (standardized): 0.786864588229795\n",
      "Epoch: 21, Loss (standarized): 0.6760161472175912\n",
      "          Validation Loss (standardized): 0.6499768514138273\n",
      "Epoch: 26, Loss (standarized): 0.6411292530427753\n",
      "          Validation Loss (standardized): 0.6449348311223935\n",
      "Epoch: 31, Loss (standarized): 0.5918672004428119\n",
      "          Validation Loss (standardized): 0.5754774207516483\n",
      "Epoch: 36, Loss (standarized): 0.5553533098513108\n",
      "          Validation Loss (standardized): 0.5516549889561653\n",
      "Epoch: 41, Loss (standarized): 0.5319475229615456\n",
      "          Validation Loss (standardized): 0.5399895246403067\n",
      "Epoch: 46, Loss (standarized): 0.5083293454623032\n",
      "          Validation Loss (standardized): 0.5118847491948332\n",
      "Epoch: 51, Loss (standarized): 0.48971832168909674\n",
      "          Validation Loss (standardized): 0.4927814643560369\n",
      "Epoch: 56, Loss (standarized): 0.4742126746372358\n",
      "          Validation Loss (standardized): 0.48231347971030814\n",
      "Epoch: 61, Loss (standarized): 0.45858692302561754\n",
      "          Validation Loss (standardized): 0.4743044755998334\n",
      "Epoch: 66, Loss (standarized): 0.44647211941228315\n",
      "          Validation Loss (standardized): 0.46554700536753457\n",
      "Epoch: 71, Loss (standarized): 0.43749944339144137\n",
      "          Validation Loss (standardized): 0.4639218205702227\n",
      "Epoch: 76, Loss (standarized): 0.4297917142581088\n",
      "          Validation Loss (standardized): 0.4570536306482505\n",
      "Epoch: 81, Loss (standarized): 0.423998800684549\n",
      "          Validation Loss (standardized): 0.45410509736301896\n",
      "Epoch: 86, Loss (standarized): 0.41821884247558716\n",
      "          Validation Loss (standardized): 0.4478927285233538\n",
      "Epoch: 91, Loss (standarized): 0.4126169649358117\n",
      "          Validation Loss (standardized): 0.4483875188625677\n",
      "Epoch: 96, Loss (standarized): 0.4082335824086722\n",
      "          Validation Loss (standardized): 0.44402531391249\n",
      "Final epoch: 100, Final loss (standarized): 0.40534655983179013\n",
      "Epoch: 1, Loss (standarized): 2.5156530013091953\n",
      "          Validation Loss (standardized): 1.054184587037714\n",
      "Epoch: 6, Loss (standarized): 1.2822190311319352\n",
      "          Validation Loss (standardized): 1.2318053848398451\n",
      "Epoch: 11, Loss (standarized): 0.7222742298307068\n",
      "          Validation Loss (standardized): 0.7160597226727596\n",
      "Epoch: 16, Loss (standarized): 0.6514894303248682\n",
      "          Validation Loss (standardized): 0.5875487024744239\n",
      "Epoch: 21, Loss (standarized): 0.5486963934011838\n",
      "          Validation Loss (standardized): 0.556112842590944\n",
      "Epoch: 26, Loss (standarized): 0.4907050043960696\n",
      "          Validation Loss (standardized): 0.526203943909488\n",
      "Epoch: 31, Loss (standarized): 0.4685732819639938\n",
      "          Validation Loss (standardized): 0.4893761479004513\n",
      "Epoch: 36, Loss (standarized): 0.45758552395459545\n",
      "          Validation Loss (standardized): 0.4833431374048569\n",
      "Epoch: 41, Loss (standarized): 0.44504791614836064\n",
      "          Validation Loss (standardized): 0.4959155249839446\n",
      "Epoch: 46, Loss (standarized): 0.432270579942463\n",
      "          Validation Loss (standardized): 0.4830426472860397\n",
      "Epoch: 51, Loss (standarized): 0.4193116909157443\n",
      "          Validation Loss (standardized): 0.4683621378405289\n",
      "Epoch: 56, Loss (standarized): 0.4070150828017304\n",
      "          Validation Loss (standardized): 0.45936804985872004\n",
      "Epoch: 61, Loss (standarized): 0.398141586379593\n",
      "          Validation Loss (standardized): 0.4503183880027977\n",
      "Epoch: 66, Loss (standarized): 0.3906561976417281\n",
      "          Validation Loss (standardized): 0.44654305130456945\n",
      "Epoch: 71, Loss (standarized): 0.384341647574915\n",
      "          Validation Loss (standardized): 0.4424311989689384\n",
      "Epoch: 76, Loss (standarized): 0.37848423596027964\n",
      "          Validation Loss (standardized): 0.4364400339009227\n",
      "Epoch: 81, Loss (standarized): 0.37270825829699233\n",
      "          Validation Loss (standardized): 0.4341010007511962\n",
      "Epoch: 86, Loss (standarized): 0.3671129763823272\n",
      "          Validation Loss (standardized): 0.42731959794889035\n",
      "Epoch: 91, Loss (standarized): 0.3619493150903327\n",
      "          Validation Loss (standardized): 0.4221284033961086\n",
      "Epoch: 96, Loss (standarized): 0.3566445571421818\n",
      "          Validation Loss (standardized): 0.41408864798103473\n",
      "Final epoch: 100, Final loss (standarized): 0.35223398877107137\n",
      "Epoch: 1, Loss (standarized): 9.327800773728\n",
      "          Validation Loss (standardized): 7.81663742842749\n",
      "Epoch: 6, Loss (standarized): 2.3079005900728733\n",
      "          Validation Loss (standardized): 2.1285722262620883\n",
      "Epoch: 11, Loss (standarized): 0.7465639584147399\n",
      "          Validation Loss (standardized): 0.6413869211167406\n",
      "Epoch: 16, Loss (standarized): 0.9041156403450857\n",
      "          Validation Loss (standardized): 0.8579391256386215\n",
      "Epoch: 21, Loss (standarized): 0.8633027280913641\n",
      "          Validation Loss (standardized): 0.7237182233578355\n",
      "Epoch: 26, Loss (standarized): 0.7152169891577553\n",
      "          Validation Loss (standardized): 0.6088629346810082\n",
      "Epoch: 31, Loss (standarized): 0.6252974088288232\n",
      "          Validation Loss (standardized): 0.5896638533003005\n",
      "Epoch: 36, Loss (standarized): 0.580001078408593\n",
      "          Validation Loss (standardized): 0.6295861930343123\n",
      "Epoch: 41, Loss (standarized): 0.5674757208436494\n",
      "          Validation Loss (standardized): 0.6276671554695582\n",
      "Epoch: 46, Loss (standarized): 0.5249172926012353\n",
      "          Validation Loss (standardized): 0.5681578427460215\n",
      "Epoch: 51, Loss (standarized): 0.4566178282560706\n",
      "          Validation Loss (standardized): 0.4629909312913234\n",
      "Epoch: 56, Loss (standarized): 0.43453664969877626\n",
      "          Validation Loss (standardized): 0.4620453219089734\n",
      "Epoch: 61, Loss (standarized): 0.4172803069235852\n",
      "          Validation Loss (standardized): 0.4722103926771142\n",
      "Epoch: 66, Loss (standarized): 0.4043233869885232\n",
      "          Validation Loss (standardized): 0.43853522937920997\n",
      "Epoch: 71, Loss (standarized): 0.3922151957277175\n",
      "          Validation Loss (standardized): 0.46600600801433756\n",
      "Epoch: 76, Loss (standarized): 0.3833125855330706\n",
      "          Validation Loss (standardized): 0.4281620844161659\n",
      "Epoch: 81, Loss (standarized): 0.375959974758138\n",
      "          Validation Loss (standardized): 0.44217019050622014\n",
      "Epoch: 86, Loss (standarized): 0.3717898026558628\n",
      "          Validation Loss (standardized): 0.4232383161291095\n",
      "Epoch: 91, Loss (standarized): 0.36811711139129333\n",
      "          Validation Loss (standardized): 0.42099984710297833\n",
      "Epoch: 96, Loss (standarized): 0.36450765359402776\n",
      "          Validation Loss (standardized): 0.4186966008551718\n",
      "Final epoch: 100, Final loss (standarized): 0.36130516655503675\n",
      "Epoch: 1, Loss (standarized): 1.3546881306643765\n",
      "          Validation Loss (standardized): 1.1651256488960546\n",
      "Epoch: 6, Loss (standarized): 0.8234837143565045\n",
      "          Validation Loss (standardized): 0.7284245630801991\n",
      "Epoch: 11, Loss (standarized): 0.7134498749820757\n",
      "          Validation Loss (standardized): 0.6797837229257487\n",
      "Epoch: 16, Loss (standarized): 0.6839569726654047\n",
      "          Validation Loss (standardized): 0.7766130803278487\n",
      "Epoch: 21, Loss (standarized): 0.6477605097736733\n",
      "          Validation Loss (standardized): 0.6824856387902827\n",
      "Epoch: 26, Loss (standarized): 0.6143409261022136\n",
      "          Validation Loss (standardized): 0.6087993603336127\n",
      "Epoch: 31, Loss (standarized): 0.588224070199199\n",
      "          Validation Loss (standardized): 0.5959929594585717\n",
      "Epoch: 36, Loss (standarized): 0.5471986421159298\n",
      "          Validation Loss (standardized): 0.5905217150358649\n",
      "Epoch: 41, Loss (standarized): 0.5107731326724474\n",
      "          Validation Loss (standardized): 0.5307084697074274\n",
      "Epoch: 46, Loss (standarized): 0.4775957990689165\n",
      "          Validation Loss (standardized): 0.5188571633263089\n",
      "Epoch: 51, Loss (standarized): 0.4484360552927499\n",
      "          Validation Loss (standardized): 0.48150790666909843\n",
      "Epoch: 56, Loss (standarized): 0.42629834560974766\n",
      "          Validation Loss (standardized): 0.4783164840514507\n",
      "Epoch: 61, Loss (standarized): 0.4113831701869065\n",
      "          Validation Loss (standardized): 0.4624635909414615\n",
      "Epoch: 66, Loss (standarized): 0.4000729266029094\n",
      "          Validation Loss (standardized): 0.4530882989898869\n",
      "Epoch: 71, Loss (standarized): 0.38893937984758276\n",
      "          Validation Loss (standardized): 0.44776486172965785\n",
      "Epoch: 76, Loss (standarized): 0.3767362832973405\n",
      "          Validation Loss (standardized): 0.4373919281624859\n",
      "Epoch: 81, Loss (standarized): 0.3663348254147357\n",
      "          Validation Loss (standardized): 0.42308636680289835\n",
      "Epoch: 86, Loss (standarized): 0.3555278121606609\n",
      "          Validation Loss (standardized): 0.4066519292309252\n",
      "Epoch: 91, Loss (standarized): 0.34463895550766477\n",
      "          Validation Loss (standardized): 0.39537347279161467\n",
      "Epoch: 96, Loss (standarized): 0.3339032555138684\n",
      "          Validation Loss (standardized): 0.38200318901293345\n",
      "Final epoch: 100, Final loss (standarized): 0.3255923519494309\n",
      "Epoch: 1, Loss (standarized): 2.809042512331173\n",
      "          Validation Loss (standardized): 1.0492806599649267\n",
      "Epoch: 6, Loss (standarized): 1.110400708108919\n",
      "          Validation Loss (standardized): 0.7290171359337431\n",
      "Epoch: 11, Loss (standarized): 0.848657733857543\n",
      "          Validation Loss (standardized): 0.8898972199810464\n",
      "Epoch: 16, Loss (standarized): 0.5302711289550868\n",
      "          Validation Loss (standardized): 0.5639993210518698\n",
      "Epoch: 21, Loss (standarized): 0.5305236939984292\n",
      "          Validation Loss (standardized): 0.5094527641673394\n",
      "Epoch: 26, Loss (standarized): 0.5005705486853104\n",
      "          Validation Loss (standardized): 0.561046626934675\n",
      "Epoch: 31, Loss (standarized): 0.4397196296493691\n",
      "          Validation Loss (standardized): 0.48179914852068\n",
      "Epoch: 36, Loss (standarized): 0.4275925953398512\n",
      "          Validation Loss (standardized): 0.4736908041361716\n",
      "Epoch: 41, Loss (standarized): 0.4167039420402257\n",
      "          Validation Loss (standardized): 0.4721154259056524\n",
      "Epoch: 46, Loss (standarized): 0.3985270225194951\n",
      "          Validation Loss (standardized): 0.44262326438426597\n",
      "Epoch: 51, Loss (standarized): 0.3838202669285976\n",
      "          Validation Loss (standardized): 0.44028701304269774\n",
      "Epoch: 56, Loss (standarized): 0.37404881406901985\n",
      "          Validation Loss (standardized): 0.4217572941962963\n",
      "Epoch: 61, Loss (standarized): 0.3648908899333242\n",
      "          Validation Loss (standardized): 0.4149274997838509\n",
      "Epoch: 66, Loss (standarized): 0.35614974235388497\n",
      "          Validation Loss (standardized): 0.407922412622179\n",
      "Epoch: 71, Loss (standarized): 0.3464621127267498\n",
      "          Validation Loss (standardized): 0.39400731533424993\n",
      "Epoch: 76, Loss (standarized): 0.3370729711375943\n",
      "          Validation Loss (standardized): 0.386893627562482\n",
      "Epoch: 81, Loss (standarized): 0.32698755568983984\n",
      "          Validation Loss (standardized): 0.3776590495122985\n",
      "Epoch: 86, Loss (standarized): 0.3170905429417898\n",
      "          Validation Loss (standardized): 0.36312182257237763\n",
      "Epoch: 91, Loss (standarized): 0.30635823260049266\n",
      "          Validation Loss (standardized): 0.3524435434586718\n",
      "Epoch: 96, Loss (standarized): 0.294439150594105\n",
      "          Validation Loss (standardized): 0.3405922862432821\n",
      "Final epoch: 100, Final loss (standarized): 0.2841578624757858\n",
      "Epoch: 1, Loss (standarized): 0.9170522566668329\n",
      "          Validation Loss (standardized): 0.7970292369940444\n",
      "Epoch: 6, Loss (standarized): 0.6603927920858285\n",
      "          Validation Loss (standardized): 0.6408656328185457\n",
      "Epoch: 11, Loss (standarized): 0.5671252763973926\n",
      "          Validation Loss (standardized): 0.6400221804287909\n",
      "Epoch: 16, Loss (standarized): 0.49983292368444426\n",
      "          Validation Loss (standardized): 0.538546269339896\n",
      "Epoch: 21, Loss (standarized): 0.4664883987864953\n",
      "          Validation Loss (standardized): 0.5507028164695249\n",
      "Epoch: 26, Loss (standarized): 0.43957056503895153\n",
      "          Validation Loss (standardized): 0.47558697676087003\n",
      "Epoch: 31, Loss (standarized): 0.4229095319402851\n",
      "          Validation Loss (standardized): 0.47581364373475155\n",
      "Epoch: 36, Loss (standarized): 0.4047181642611385\n",
      "          Validation Loss (standardized): 0.4655127460928374\n",
      "Epoch: 41, Loss (standarized): 0.38944012569434183\n",
      "          Validation Loss (standardized): 0.430117494877165\n",
      "Epoch: 46, Loss (standarized): 0.3747199124912715\n",
      "          Validation Loss (standardized): 0.41840455213560135\n",
      "Epoch: 51, Loss (standarized): 0.35921962625077375\n",
      "          Validation Loss (standardized): 0.405423287262773\n",
      "Epoch: 56, Loss (standarized): 0.34547486085926865\n",
      "          Validation Loss (standardized): 0.3838606271022472\n",
      "Epoch: 61, Loss (standarized): 0.33386218272255724\n",
      "          Validation Loss (standardized): 0.36539071780128696\n",
      "Epoch: 66, Loss (standarized): 0.3220649740379353\n",
      "          Validation Loss (standardized): 0.35371469858773397\n",
      "Epoch: 71, Loss (standarized): 0.3113547057875073\n",
      "          Validation Loss (standardized): 0.34207170592856556\n",
      "Epoch: 76, Loss (standarized): 0.2933373960694808\n",
      "          Validation Loss (standardized): 0.34285563236071953\n",
      "Epoch: 81, Loss (standarized): 0.2900964154349448\n",
      "          Validation Loss (standardized): 0.31985074024317606\n",
      "Epoch: 86, Loss (standarized): 0.27843953923145426\n",
      "          Validation Loss (standardized): 0.31195103302027005\n",
      "Epoch: 91, Loss (standarized): 0.2664083727395547\n",
      "          Validation Loss (standardized): 0.3043989018405956\n",
      "Epoch: 96, Loss (standarized): 0.2551593755020103\n",
      "          Validation Loss (standardized): 0.29547273976203414\n",
      "Final epoch: 100, Final loss (standarized): 0.24554845700747432\n",
      "Epoch: 1, Loss (standarized): 2.215534322266466\n",
      "          Validation Loss (standardized): 2.0381757194369747\n",
      "Epoch: 6, Loss (standarized): 0.8260662132959717\n",
      "          Validation Loss (standardized): 0.7481105580604759\n",
      "Epoch: 11, Loss (standarized): 0.7494627179361649\n",
      "          Validation Loss (standardized): 0.7062035126982209\n",
      "Epoch: 16, Loss (standarized): 0.7296871603023914\n",
      "          Validation Loss (standardized): 0.6210108225209591\n",
      "Epoch: 21, Loss (standarized): 0.6056324301862873\n",
      "          Validation Loss (standardized): 0.5835637361109227\n",
      "Epoch: 26, Loss (standarized): 0.5598284151488462\n",
      "          Validation Loss (standardized): 0.5990877014749273\n",
      "Epoch: 31, Loss (standarized): 0.5105803996636586\n",
      "          Validation Loss (standardized): 0.523673804155554\n",
      "Epoch: 36, Loss (standarized): 0.47202481467552937\n",
      "          Validation Loss (standardized): 0.4866317784614179\n",
      "Epoch: 41, Loss (standarized): 0.4360436177236305\n",
      "          Validation Loss (standardized): 0.47554789066755176\n",
      "Epoch: 46, Loss (standarized): 0.4058124487687236\n",
      "          Validation Loss (standardized): 0.4397088386500911\n",
      "Epoch: 51, Loss (standarized): 0.3909923967946195\n",
      "          Validation Loss (standardized): 0.4302706460728154\n",
      "Epoch: 56, Loss (standarized): 0.3838076435473251\n",
      "          Validation Loss (standardized): 0.4324163094698259\n",
      "Epoch: 61, Loss (standarized): 0.37686677820840214\n",
      "          Validation Loss (standardized): 0.4218509719039048\n",
      "Epoch: 66, Loss (standarized): 0.3699748439240803\n",
      "          Validation Loss (standardized): 0.4209945775161941\n",
      "Epoch: 71, Loss (standarized): 0.3641847333247464\n",
      "          Validation Loss (standardized): 0.4141698772041697\n",
      "Epoch: 76, Loss (standarized): 0.3583934507035039\n",
      "          Validation Loss (standardized): 0.4110265151829465\n",
      "Epoch: 81, Loss (standarized): 0.3518571326370917\n",
      "          Validation Loss (standardized): 0.4056498999284595\n",
      "Epoch: 86, Loss (standarized): 0.3448002654470508\n",
      "          Validation Loss (standardized): 0.39588845471992684\n",
      "Epoch: 91, Loss (standarized): 0.3381743293200925\n",
      "          Validation Loss (standardized): 0.3890194588759111\n",
      "Epoch: 96, Loss (standarized): 0.32978372699308445\n",
      "          Validation Loss (standardized): 0.383094884498537\n",
      "Final epoch: 100, Final loss (standarized): 0.32252959335663345\n",
      "Epoch: 1, Loss (standarized): 5.645153211182992\n",
      "          Validation Loss (standardized): 4.719187162112956\n",
      "Epoch: 6, Loss (standarized): 1.04055368312014\n",
      "          Validation Loss (standardized): 0.9425413306297326\n",
      "Epoch: 11, Loss (standarized): 0.7648915769477146\n",
      "          Validation Loss (standardized): 0.6906350434764316\n",
      "Epoch: 16, Loss (standarized): 0.8296351025029175\n",
      "          Validation Loss (standardized): 0.7389109075343339\n",
      "Epoch: 21, Loss (standarized): 0.6970715702279483\n",
      "          Validation Loss (standardized): 0.64869460802579\n",
      "Epoch: 26, Loss (standarized): 0.6246586373372554\n",
      "          Validation Loss (standardized): 0.6665242016262615\n",
      "Epoch: 31, Loss (standarized): 0.5783449067581916\n",
      "          Validation Loss (standardized): 0.5861115792933754\n",
      "Epoch: 36, Loss (standarized): 0.5389202484542555\n",
      "          Validation Loss (standardized): 0.5436844745594734\n",
      "Epoch: 41, Loss (standarized): 0.4934529357516567\n",
      "          Validation Loss (standardized): 0.5461202831662274\n",
      "Epoch: 46, Loss (standarized): 0.4564406655523527\n",
      "          Validation Loss (standardized): 0.48447530245713105\n",
      "Epoch: 51, Loss (standarized): 0.4219559858567705\n",
      "          Validation Loss (standardized): 0.4573690755504042\n",
      "Epoch: 56, Loss (standarized): 0.4017076980566654\n",
      "          Validation Loss (standardized): 0.4467688820316178\n",
      "Epoch: 61, Loss (standarized): 0.3879010641199322\n",
      "          Validation Loss (standardized): 0.4267954088430772\n",
      "Epoch: 66, Loss (standarized): 0.37912406542422794\n",
      "          Validation Loss (standardized): 0.42389860746082625\n",
      "Epoch: 71, Loss (standarized): 0.3687554950713609\n",
      "          Validation Loss (standardized): 0.4110666202470055\n",
      "Epoch: 76, Loss (standarized): 0.35601555183655587\n",
      "          Validation Loss (standardized): 0.39873187849745806\n",
      "Epoch: 81, Loss (standarized): 0.34216407642511276\n",
      "          Validation Loss (standardized): 0.3825469246403951\n",
      "Epoch: 86, Loss (standarized): 0.3294297860809276\n",
      "          Validation Loss (standardized): 0.3622572834561098\n",
      "Epoch: 91, Loss (standarized): 0.3141812232872562\n",
      "          Validation Loss (standardized): 0.3489447666210409\n",
      "Epoch: 96, Loss (standarized): 0.30009781467788377\n",
      "          Validation Loss (standardized): 0.3352278323814164\n",
      "Final epoch: 100, Final loss (standarized): 0.2882050293060979\n",
      "Epoch: 1, Loss (standarized): 2.1632671263743353\n",
      "          Validation Loss (standardized): 1.1305947966068894\n",
      "Epoch: 6, Loss (standarized): 1.0710941724438432\n",
      "          Validation Loss (standardized): 1.2250589563998917\n",
      "Epoch: 11, Loss (standarized): 0.7134171029777583\n",
      "          Validation Loss (standardized): 0.7007785155778015\n",
      "Epoch: 16, Loss (standarized): 0.7383265912949585\n",
      "          Validation Loss (standardized): 0.6530007080050234\n",
      "Epoch: 21, Loss (standarized): 0.5940149860064661\n",
      "          Validation Loss (standardized): 0.6227653794319054\n",
      "Epoch: 26, Loss (standarized): 0.5694552649857563\n",
      "          Validation Loss (standardized): 0.622136726061378\n",
      "Epoch: 31, Loss (standarized): 0.5237973141245602\n",
      "          Validation Loss (standardized): 0.5277057926828143\n",
      "Epoch: 36, Loss (standarized): 0.48440196242038985\n",
      "          Validation Loss (standardized): 0.5526770136872126\n",
      "Epoch: 41, Loss (standarized): 0.4553583293722664\n",
      "          Validation Loss (standardized): 0.4909442329743435\n",
      "Epoch: 46, Loss (standarized): 0.4330070257189143\n",
      "          Validation Loss (standardized): 0.49949035784194207\n",
      "Epoch: 51, Loss (standarized): 0.41596068476068737\n",
      "          Validation Loss (standardized): 0.47235651914065047\n",
      "Epoch: 56, Loss (standarized): 0.40416082657125907\n",
      "          Validation Loss (standardized): 0.4800329465124753\n",
      "Epoch: 61, Loss (standarized): 0.393578977782813\n",
      "          Validation Loss (standardized): 0.45508833922556824\n",
      "Epoch: 66, Loss (standarized): 0.3835636576918189\n",
      "          Validation Loss (standardized): 0.4509129938698407\n",
      "Epoch: 71, Loss (standarized): 0.3713847525540984\n",
      "          Validation Loss (standardized): 0.4374491894009558\n",
      "Epoch: 76, Loss (standarized): 0.3545121981458559\n",
      "          Validation Loss (standardized): 0.41148521459165993\n",
      "Epoch: 81, Loss (standarized): 0.34372892992701753\n",
      "          Validation Loss (standardized): 0.3971544052745062\n",
      "Epoch: 86, Loss (standarized): 0.3339996809812691\n",
      "          Validation Loss (standardized): 0.3859639809545064\n",
      "Epoch: 91, Loss (standarized): 0.32382550210956956\n",
      "          Validation Loss (standardized): 0.3753606504310578\n",
      "Epoch: 96, Loss (standarized): 0.31275072169749063\n",
      "          Validation Loss (standardized): 0.36115248230431435\n",
      "Final epoch: 100, Final loss (standarized): 0.30433772101478357\n",
      "Epoch: 1, Loss (standarized): 2.1975594481605976\n",
      "          Validation Loss (standardized): 1.2916342935962941\n",
      "Epoch: 6, Loss (standarized): 0.8743400484956829\n",
      "          Validation Loss (standardized): 0.9275661084673297\n",
      "Epoch: 11, Loss (standarized): 0.8227582248665645\n",
      "          Validation Loss (standardized): 0.7750922228131799\n",
      "Epoch: 16, Loss (standarized): 0.6388926063460622\n",
      "          Validation Loss (standardized): 0.6308798709670992\n",
      "Epoch: 21, Loss (standarized): 0.626808322820534\n",
      "          Validation Loss (standardized): 0.6313749900843879\n",
      "Epoch: 26, Loss (standarized): 0.5350142129364139\n",
      "          Validation Loss (standardized): 0.5420676839801801\n",
      "Epoch: 31, Loss (standarized): 0.49687377981678954\n",
      "          Validation Loss (standardized): 0.4978495005293283\n",
      "Epoch: 36, Loss (standarized): 0.46190390772840395\n",
      "          Validation Loss (standardized): 0.47643338923853235\n",
      "Epoch: 41, Loss (standarized): 0.43481653861179553\n",
      "          Validation Loss (standardized): 0.465820663093034\n",
      "Epoch: 46, Loss (standarized): 0.42645276239423263\n",
      "          Validation Loss (standardized): 0.4627824235066535\n",
      "Epoch: 51, Loss (standarized): 0.4120441272995217\n",
      "          Validation Loss (standardized): 0.4504038843434013\n",
      "Epoch: 56, Loss (standarized): 0.3991525955459599\n",
      "          Validation Loss (standardized): 0.434709322356139\n",
      "Epoch: 61, Loss (standarized): 0.3820270614890112\n",
      "          Validation Loss (standardized): 0.41785989431426457\n",
      "Epoch: 66, Loss (standarized): 0.3645696014588367\n",
      "          Validation Loss (standardized): 0.40096951383185625\n",
      "Epoch: 71, Loss (standarized): 0.3439829390723653\n",
      "          Validation Loss (standardized): 0.3792334768617978\n",
      "Epoch: 76, Loss (standarized): 0.3295633995152264\n",
      "          Validation Loss (standardized): 0.3696424991938281\n",
      "Epoch: 81, Loss (standarized): 0.31457391450054806\n",
      "          Validation Loss (standardized): 0.35802110270494825\n",
      "Epoch: 86, Loss (standarized): 0.29898058520473647\n",
      "          Validation Loss (standardized): 0.3437236962220628\n",
      "Epoch: 91, Loss (standarized): 0.28320276464662947\n",
      "          Validation Loss (standardized): 0.3277357319773364\n",
      "Epoch: 96, Loss (standarized): 0.26612507540459124\n",
      "          Validation Loss (standardized): 0.310574339596015\n",
      "Final epoch: 100, Final loss (standarized): 0.2512400369696455\n",
      "Epoch: 1, Loss (standarized): 2.0307624826368724\n",
      "          Validation Loss (standardized): 1.4042700299730353\n",
      "Epoch: 6, Loss (standarized): 0.9271639933071579\n",
      "          Validation Loss (standardized): 0.8631375974609093\n",
      "Epoch: 11, Loss (standarized): 0.7058007565838242\n",
      "          Validation Loss (standardized): 0.6586150841404047\n",
      "Epoch: 16, Loss (standarized): 0.6806454317824063\n",
      "          Validation Loss (standardized): 0.7457913564189831\n",
      "Epoch: 21, Loss (standarized): 0.605305190810312\n",
      "          Validation Loss (standardized): 0.6224913605863808\n",
      "Epoch: 26, Loss (standarized): 0.5815212790104507\n",
      "          Validation Loss (standardized): 0.5577897358647833\n",
      "Epoch: 31, Loss (standarized): 0.5289333799365327\n",
      "          Validation Loss (standardized): 0.5472349924325415\n",
      "Epoch: 36, Loss (standarized): 0.5051997674474291\n",
      "          Validation Loss (standardized): 0.5373766434999463\n",
      "Epoch: 41, Loss (standarized): 0.47349620327526143\n",
      "          Validation Loss (standardized): 0.48507774833623896\n",
      "Epoch: 46, Loss (standarized): 0.4500275576884153\n",
      "          Validation Loss (standardized): 0.48056060417909635\n",
      "Epoch: 51, Loss (standarized): 0.4319520744750826\n",
      "          Validation Loss (standardized): 0.4747661133441224\n",
      "Epoch: 56, Loss (standarized): 0.4165175874909761\n",
      "          Validation Loss (standardized): 0.44782367248091276\n",
      "Epoch: 61, Loss (standarized): 0.4013362568862556\n",
      "          Validation Loss (standardized): 0.45028706448635397\n",
      "Epoch: 66, Loss (standarized): 0.39193364094691685\n",
      "          Validation Loss (standardized): 0.43631051914978286\n",
      "Epoch: 71, Loss (standarized): 0.3844515238125119\n",
      "          Validation Loss (standardized): 0.4335189941384728\n",
      "Epoch: 76, Loss (standarized): 0.3767129378983538\n",
      "          Validation Loss (standardized): 0.42828418052027073\n",
      "Epoch: 81, Loss (standarized): 0.3690540781319493\n",
      "          Validation Loss (standardized): 0.42282041596563585\n",
      "Epoch: 86, Loss (standarized): 0.3617206459893929\n",
      "          Validation Loss (standardized): 0.41296246931058567\n",
      "Epoch: 91, Loss (standarized): 0.3538670374896108\n",
      "          Validation Loss (standardized): 0.4036396745358839\n",
      "Epoch: 96, Loss (standarized): 0.34516526442914636\n",
      "          Validation Loss (standardized): 0.39694994592996097\n",
      "Final epoch: 100, Final loss (standarized): 0.33820087040092983\n",
      "Epoch: 1, Loss (standarized): 0.8393655662556828\n",
      "          Validation Loss (standardized): 0.7739464842942487\n",
      "Epoch: 6, Loss (standarized): 0.6770707433679608\n",
      "          Validation Loss (standardized): 0.6550093191259281\n",
      "Epoch: 11, Loss (standarized): 0.6039196104562303\n",
      "          Validation Loss (standardized): 0.6550757573527026\n",
      "Epoch: 16, Loss (standarized): 0.5335732781260601\n",
      "          Validation Loss (standardized): 0.5488098816278101\n",
      "Epoch: 21, Loss (standarized): 0.4856084373646897\n",
      "          Validation Loss (standardized): 0.5475834002219461\n",
      "Epoch: 26, Loss (standarized): 0.44706313676749937\n",
      "          Validation Loss (standardized): 0.505128184739757\n",
      "Epoch: 31, Loss (standarized): 0.43290664556359887\n",
      "          Validation Loss (standardized): 0.4868454340366943\n",
      "Epoch: 36, Loss (standarized): 0.40939722627307074\n",
      "          Validation Loss (standardized): 0.45552677493746\n",
      "Epoch: 41, Loss (standarized): 0.3822981063787063\n",
      "          Validation Loss (standardized): 0.4333069793447676\n",
      "Epoch: 46, Loss (standarized): 0.3612305370558934\n",
      "          Validation Loss (standardized): 0.41740079096385196\n",
      "Epoch: 51, Loss (standarized): 0.3413803188929346\n",
      "          Validation Loss (standardized): 0.3989731482549372\n",
      "Epoch: 56, Loss (standarized): 0.32190937013226223\n",
      "          Validation Loss (standardized): 0.3825904523364267\n",
      "Epoch: 61, Loss (standarized): 0.30165711696302855\n",
      "          Validation Loss (standardized): 0.35147075612681944\n",
      "Epoch: 66, Loss (standarized): 0.2806969684092916\n",
      "          Validation Loss (standardized): 0.329830291262012\n",
      "Epoch: 71, Loss (standarized): 0.25998591311007896\n",
      "          Validation Loss (standardized): 0.3027045444877466\n",
      "Epoch: 76, Loss (standarized): 0.23815722920561636\n",
      "          Validation Loss (standardized): 0.2849591194586598\n",
      "Epoch: 81, Loss (standarized): 0.21656515217290506\n",
      "          Validation Loss (standardized): 0.2672151732590129\n",
      "Epoch: 86, Loss (standarized): 0.19499276841608615\n",
      "          Validation Loss (standardized): 0.24686611776764134\n",
      "Epoch: 91, Loss (standarized): 0.17601773944795285\n",
      "          Validation Loss (standardized): 0.22785970361454416\n",
      "Epoch: 96, Loss (standarized): 0.15757092112493593\n",
      "          Validation Loss (standardized): 0.21242585790730764\n",
      "Final epoch: 100, Final loss (standarized): 0.1437958137011607\n",
      "Epoch: 1, Loss (standarized): 9.126646970015232\n",
      "          Validation Loss (standardized): 5.083972227470477\n",
      "Epoch: 6, Loss (standarized): 1.1088350894608385\n",
      "          Validation Loss (standardized): 1.7094478762981153\n",
      "Epoch: 11, Loss (standarized): 2.02743987253712\n",
      "          Validation Loss (standardized): 2.170142037622579\n",
      "Epoch: 16, Loss (standarized): 0.8904733720258248\n",
      "          Validation Loss (standardized): 0.8458328249479209\n",
      "Epoch: 21, Loss (standarized): 1.0456639983364957\n",
      "          Validation Loss (standardized): 0.8747549289001312\n",
      "Epoch: 26, Loss (standarized): 0.8205158146773208\n",
      "          Validation Loss (standardized): 0.7043894157232188\n",
      "Epoch: 31, Loss (standarized): 0.7133135874932542\n",
      "          Validation Loss (standardized): 0.8021285857243616\n",
      "Epoch: 36, Loss (standarized): 0.6909653149569529\n",
      "          Validation Loss (standardized): 0.7710270889522909\n",
      "Epoch: 41, Loss (standarized): 0.6074208287526007\n",
      "          Validation Loss (standardized): 0.6259958965060628\n",
      "Epoch: 46, Loss (standarized): 0.5896992286825823\n",
      "          Validation Loss (standardized): 0.5749671425036915\n",
      "Epoch: 51, Loss (standarized): 0.5484633830903223\n",
      "          Validation Loss (standardized): 0.5725732625115612\n",
      "Epoch: 56, Loss (standarized): 0.5303182233961259\n",
      "          Validation Loss (standardized): 0.5930605744262532\n",
      "Epoch: 61, Loss (standarized): 0.5097454846177099\n",
      "          Validation Loss (standardized): 0.5668915092980673\n",
      "Epoch: 66, Loss (standarized): 0.4953564436160317\n",
      "          Validation Loss (standardized): 0.5363671172256129\n",
      "Epoch: 71, Loss (standarized): 0.48274081173403954\n",
      "          Validation Loss (standardized): 0.5277665789756942\n",
      "Epoch: 76, Loss (standarized): 0.47197463620927876\n",
      "          Validation Loss (standardized): 0.5316083987955416\n",
      "Epoch: 81, Loss (standarized): 0.4612770895092021\n",
      "          Validation Loss (standardized): 0.5235204678201141\n",
      "Epoch: 86, Loss (standarized): 0.4527388344009123\n",
      "          Validation Loss (standardized): 0.5125393368921201\n",
      "Epoch: 91, Loss (standarized): 0.44383361206727534\n",
      "          Validation Loss (standardized): 0.5081410694400952\n",
      "Epoch: 96, Loss (standarized): 0.4362638316831499\n",
      "          Validation Loss (standardized): 0.5048141418955754\n",
      "Final epoch: 100, Final loss (standarized): 0.43195763547658234\n",
      "Epoch: 1, Loss (standarized): 1.750854358527739\n",
      "          Validation Loss (standardized): 1.107598517584987\n",
      "Epoch: 6, Loss (standarized): 0.7949059671361036\n",
      "          Validation Loss (standardized): 0.9343703818415099\n",
      "Epoch: 11, Loss (standarized): 0.6746483354859674\n",
      "          Validation Loss (standardized): 0.6578696323596486\n",
      "Epoch: 16, Loss (standarized): 0.5899522852770624\n",
      "          Validation Loss (standardized): 0.6122345948501342\n",
      "Epoch: 21, Loss (standarized): 0.5483026442110082\n",
      "          Validation Loss (standardized): 0.5543185022852315\n",
      "Epoch: 26, Loss (standarized): 0.49981689598208856\n",
      "          Validation Loss (standardized): 0.5364435610507319\n",
      "Epoch: 31, Loss (standarized): 0.48985346804707586\n",
      "          Validation Loss (standardized): 0.5332731587473822\n",
      "Epoch: 36, Loss (standarized): 0.4695826315516903\n",
      "          Validation Loss (standardized): 0.4929003786792545\n",
      "Epoch: 41, Loss (standarized): 0.4598356667206529\n",
      "          Validation Loss (standardized): 0.4938187517474998\n",
      "Epoch: 46, Loss (standarized): 0.44561727616504554\n",
      "          Validation Loss (standardized): 0.486564716365914\n",
      "Epoch: 51, Loss (standarized): 0.4421884577504075\n",
      "          Validation Loss (standardized): 0.4825975567580113\n",
      "Epoch: 56, Loss (standarized): 0.44117115534044\n",
      "          Validation Loss (standardized): 0.4805115331097157\n",
      "Epoch: 61, Loss (standarized): 0.438495773475151\n",
      "          Validation Loss (standardized): 0.4753948350871937\n",
      "Epoch: 66, Loss (standarized): 0.4353506519304823\n",
      "          Validation Loss (standardized): 0.48025598419388205\n",
      "Epoch: 71, Loss (standarized): 0.4342759267895252\n",
      "          Validation Loss (standardized): 0.48120262032821215\n",
      "Epoch: 76, Loss (standarized): 0.43282794219698867\n",
      "          Validation Loss (standardized): 0.4776435022689198\n",
      "Epoch: 81, Loss (standarized): 0.43109639568301805\n",
      "          Validation Loss (standardized): 0.4741427302284795\n",
      "Epoch: 86, Loss (standarized): 0.4293790500736959\n",
      "          Validation Loss (standardized): 0.47399059257541004\n",
      "Epoch: 91, Loss (standarized): 0.4269102760029792\n",
      "          Validation Loss (standardized): 0.4728223036607308\n",
      "Epoch: 96, Loss (standarized): 0.4236414879599998\n",
      "          Validation Loss (standardized): 0.4667347063572619\n",
      "Final epoch: 100, Final loss (standarized): 0.420714795226932\n",
      "Epoch: 1, Loss (standarized): 1.4325168803009611\n",
      "          Validation Loss (standardized): 0.9491508340457488\n",
      "Epoch: 6, Loss (standarized): 0.8164560495223462\n",
      "          Validation Loss (standardized): 0.9197831087977483\n",
      "Epoch: 11, Loss (standarized): 0.7073235420262485\n",
      "          Validation Loss (standardized): 0.686322418756995\n",
      "Epoch: 16, Loss (standarized): 0.6551555198112944\n",
      "          Validation Loss (standardized): 0.6325774125806415\n",
      "Epoch: 21, Loss (standarized): 0.6070491645845653\n",
      "          Validation Loss (standardized): 0.6076108755448835\n",
      "Epoch: 26, Loss (standarized): 0.5533488788910347\n",
      "          Validation Loss (standardized): 0.5650181777233041\n",
      "Epoch: 31, Loss (standarized): 0.5283632290270756\n",
      "          Validation Loss (standardized): 0.5371252629556299\n",
      "Epoch: 36, Loss (standarized): 0.4953711604250118\n",
      "          Validation Loss (standardized): 0.5098443715036203\n",
      "Epoch: 41, Loss (standarized): 0.4768882689488616\n",
      "          Validation Loss (standardized): 0.4839908762757696\n",
      "Epoch: 46, Loss (standarized): 0.4589964967812724\n",
      "          Validation Loss (standardized): 0.48543183965140657\n",
      "Epoch: 51, Loss (standarized): 0.4515225438009927\n",
      "          Validation Loss (standardized): 0.47680312294088234\n",
      "Epoch: 56, Loss (standarized): 0.447349456640211\n",
      "          Validation Loss (standardized): 0.47516589940190285\n",
      "Epoch: 61, Loss (standarized): 0.4446922426781594\n",
      "          Validation Loss (standardized): 0.4709425598227122\n",
      "Epoch: 66, Loss (standarized): 0.44248502848827653\n",
      "          Validation Loss (standardized): 0.4715028468567155\n",
      "Epoch: 71, Loss (standarized): 0.44020176446123144\n",
      "          Validation Loss (standardized): 0.47367831646609987\n",
      "Epoch: 76, Loss (standarized): 0.43764195940803025\n",
      "          Validation Loss (standardized): 0.46648327151077246\n",
      "Epoch: 81, Loss (standarized): 0.4345132979070859\n",
      "          Validation Loss (standardized): 0.4691387144204904\n",
      "Epoch: 86, Loss (standarized): 0.43087333798128824\n",
      "          Validation Loss (standardized): 0.4652263343488911\n",
      "Epoch: 91, Loss (standarized): 0.4273744478571603\n",
      "          Validation Loss (standardized): 0.4612766905544632\n",
      "Epoch: 96, Loss (standarized): 0.42391757036235395\n",
      "          Validation Loss (standardized): 0.45998980751124746\n",
      "Final epoch: 100, Final loss (standarized): 0.421018997580198\n",
      "Epoch: 1, Loss (standarized): 2.4490137492581474\n",
      "          Validation Loss (standardized): 1.1490252033411605\n",
      "Epoch: 6, Loss (standarized): 1.1537245720919067\n",
      "          Validation Loss (standardized): 1.2435796985872818\n",
      "Epoch: 11, Loss (standarized): 0.6796777013565187\n",
      "          Validation Loss (standardized): 0.6743145565614058\n",
      "Epoch: 16, Loss (standarized): 0.7087090829658208\n",
      "          Validation Loss (standardized): 0.7016547403840773\n",
      "Epoch: 21, Loss (standarized): 0.5909207019245108\n",
      "          Validation Loss (standardized): 0.6798208145954058\n",
      "Epoch: 26, Loss (standarized): 0.5459417255623771\n",
      "          Validation Loss (standardized): 0.5614786475871376\n",
      "Epoch: 31, Loss (standarized): 0.499501848253774\n",
      "          Validation Loss (standardized): 0.5390434705387883\n",
      "Epoch: 36, Loss (standarized): 0.4698391754714074\n",
      "          Validation Loss (standardized): 0.5238707652152849\n",
      "Epoch: 41, Loss (standarized): 0.4452114812849697\n",
      "          Validation Loss (standardized): 0.49741310199192723\n",
      "Epoch: 46, Loss (standarized): 0.4250311309154945\n",
      "          Validation Loss (standardized): 0.49271076866502256\n",
      "Epoch: 51, Loss (standarized): 0.41954150801528495\n",
      "          Validation Loss (standardized): 0.4782584310175067\n",
      "Epoch: 56, Loss (standarized): 0.4116444668711745\n",
      "          Validation Loss (standardized): 0.4731626566040812\n",
      "Epoch: 61, Loss (standarized): 0.4089459592126259\n",
      "          Validation Loss (standardized): 0.4737125985862476\n",
      "Epoch: 66, Loss (standarized): 0.4066116143304142\n",
      "          Validation Loss (standardized): 0.474964383499194\n",
      "Epoch: 71, Loss (standarized): 0.4047245790008752\n",
      "          Validation Loss (standardized): 0.4725485409067862\n",
      "Epoch: 76, Loss (standarized): 0.4037724096245981\n",
      "          Validation Loss (standardized): 0.46809984808486776\n",
      "Epoch: 81, Loss (standarized): 0.40287668378611013\n",
      "          Validation Loss (standardized): 0.46986832531247896\n",
      "Epoch: 86, Loss (standarized): 0.4021937469208831\n",
      "          Validation Loss (standardized): 0.4719582674671394\n",
      "Epoch: 91, Loss (standarized): 0.40115172234272\n",
      "          Validation Loss (standardized): 0.4634144319459824\n",
      "Epoch: 96, Loss (standarized): 0.39996346318881165\n",
      "          Validation Loss (standardized): 0.4636213993544812\n",
      "Final epoch: 100, Final loss (standarized): 0.39870498370107665\n",
      "Epoch: 1, Loss (standarized): 2.891119654344206\n",
      "          Validation Loss (standardized): 1.715985045407788\n",
      "Epoch: 6, Loss (standarized): 0.9777402177695631\n",
      "          Validation Loss (standardized): 1.137760751779675\n",
      "Epoch: 11, Loss (standarized): 0.7774790660426405\n",
      "          Validation Loss (standardized): 0.6901581074145643\n",
      "Epoch: 16, Loss (standarized): 0.724655890019911\n",
      "          Validation Loss (standardized): 0.7367229849233763\n",
      "Epoch: 21, Loss (standarized): 0.5758893717597457\n",
      "          Validation Loss (standardized): 0.5850330657797277\n",
      "Epoch: 26, Loss (standarized): 0.5639807267240554\n",
      "          Validation Loss (standardized): 0.5794368900734662\n",
      "Epoch: 31, Loss (standarized): 0.5048400947032509\n",
      "          Validation Loss (standardized): 0.5145520141879086\n",
      "Epoch: 36, Loss (standarized): 0.49918701627166095\n",
      "          Validation Loss (standardized): 0.5236531913553912\n",
      "Epoch: 41, Loss (standarized): 0.47005371741936\n",
      "          Validation Loss (standardized): 0.49816643377240327\n",
      "Epoch: 46, Loss (standarized): 0.45513441338152705\n",
      "          Validation Loss (standardized): 0.479224137637566\n",
      "Epoch: 51, Loss (standarized): 0.4468553112358563\n",
      "          Validation Loss (standardized): 0.483006555493138\n",
      "Epoch: 56, Loss (standarized): 0.4376236908666408\n",
      "          Validation Loss (standardized): 0.47041880871648717\n",
      "Epoch: 61, Loss (standarized): 0.43049541695240706\n",
      "          Validation Loss (standardized): 0.47400329612590025\n",
      "Epoch: 66, Loss (standarized): 0.42339493098500347\n",
      "          Validation Loss (standardized): 0.46713865320901715\n",
      "Epoch: 71, Loss (standarized): 0.41464590263446005\n",
      "          Validation Loss (standardized): 0.4636422355767735\n",
      "Epoch: 76, Loss (standarized): 0.40897233948858586\n",
      "          Validation Loss (standardized): 0.46135648339622404\n",
      "Epoch: 81, Loss (standarized): 0.40478731027091186\n",
      "          Validation Loss (standardized): 0.4612179971426319\n",
      "Epoch: 86, Loss (standarized): 0.40090438296585784\n",
      "          Validation Loss (standardized): 0.46047714848918075\n",
      "Epoch: 91, Loss (standarized): 0.3982853074707299\n",
      "          Validation Loss (standardized): 0.45733205363086477\n",
      "Epoch: 96, Loss (standarized): 0.3963244091081458\n",
      "          Validation Loss (standardized): 0.4546399505766411\n",
      "Final epoch: 100, Final loss (standarized): 0.3948540041092338\n",
      "Epoch: 1, Loss (standarized): 1.99693274173852\n",
      "          Validation Loss (standardized): 0.8591759503166361\n",
      "Epoch: 6, Loss (standarized): 1.026738501729271\n",
      "          Validation Loss (standardized): 1.077715487525637\n",
      "Epoch: 11, Loss (standarized): 0.8368528957793817\n",
      "          Validation Loss (standardized): 0.7261124132634902\n",
      "Epoch: 16, Loss (standarized): 0.7442534221887364\n",
      "          Validation Loss (standardized): 0.7432490349319067\n",
      "Epoch: 21, Loss (standarized): 0.6273780949141351\n",
      "          Validation Loss (standardized): 0.671005082003449\n",
      "Epoch: 26, Loss (standarized): 0.607181786191565\n",
      "          Validation Loss (standardized): 0.5929522252349515\n",
      "Epoch: 31, Loss (standarized): 0.555519872040563\n",
      "          Validation Loss (standardized): 0.5831666072666231\n",
      "Epoch: 36, Loss (standarized): 0.5095500114915762\n",
      "          Validation Loss (standardized): 0.530299573048679\n",
      "Epoch: 41, Loss (standarized): 0.48183955267392065\n",
      "          Validation Loss (standardized): 0.49934427100287765\n",
      "Epoch: 46, Loss (standarized): 0.4535142774681633\n",
      "          Validation Loss (standardized): 0.4912225702041772\n",
      "Epoch: 51, Loss (standarized): 0.43499807130674145\n",
      "          Validation Loss (standardized): 0.4784660987802411\n",
      "Epoch: 56, Loss (standarized): 0.41997916467089835\n",
      "          Validation Loss (standardized): 0.4706031516842586\n",
      "Epoch: 61, Loss (standarized): 0.41062843135467475\n",
      "          Validation Loss (standardized): 0.4652384899429697\n",
      "Epoch: 66, Loss (standarized): 0.40312691597231376\n",
      "          Validation Loss (standardized): 0.46205370875862156\n",
      "Epoch: 71, Loss (standarized): 0.3966259197676046\n",
      "          Validation Loss (standardized): 0.46009388137981305\n",
      "Epoch: 76, Loss (standarized): 0.39111074519978295\n",
      "          Validation Loss (standardized): 0.4567424151983196\n",
      "Epoch: 81, Loss (standarized): 0.3857047170462944\n",
      "          Validation Loss (standardized): 0.45084281111603103\n",
      "Epoch: 86, Loss (standarized): 0.37968704116014096\n",
      "          Validation Loss (standardized): 0.4419050965475513\n",
      "Epoch: 91, Loss (standarized): 0.373147528113157\n",
      "          Validation Loss (standardized): 0.4346623638501248\n",
      "Epoch: 96, Loss (standarized): 0.3669123296096144\n",
      "          Validation Loss (standardized): 0.42458620014460124\n",
      "Final epoch: 100, Final loss (standarized): 0.36050398463733935\n",
      "Epoch: 1, Loss (standarized): 2.7302241517610257\n",
      "          Validation Loss (standardized): 1.976957880207264\n",
      "Epoch: 6, Loss (standarized): 1.076194377452569\n",
      "          Validation Loss (standardized): 0.8678890142113486\n",
      "Epoch: 11, Loss (standarized): 0.6613034354517351\n",
      "          Validation Loss (standardized): 0.647390489477278\n",
      "Epoch: 16, Loss (standarized): 0.5177202800795634\n",
      "          Validation Loss (standardized): 0.6083323522823407\n",
      "Epoch: 21, Loss (standarized): 0.486426455225052\n",
      "          Validation Loss (standardized): 0.5610507841246436\n",
      "Epoch: 26, Loss (standarized): 0.45474625535737195\n",
      "          Validation Loss (standardized): 0.5480117775603165\n",
      "Epoch: 31, Loss (standarized): 0.4337745481492477\n",
      "          Validation Loss (standardized): 0.5078249646000625\n",
      "Epoch: 36, Loss (standarized): 0.4279376883753735\n",
      "          Validation Loss (standardized): 0.4892586382474613\n",
      "Epoch: 41, Loss (standarized): 0.4188393749780584\n",
      "          Validation Loss (standardized): 0.49413499507606323\n",
      "Epoch: 46, Loss (standarized): 0.4105205184675266\n",
      "          Validation Loss (standardized): 0.4771083956790838\n",
      "Epoch: 51, Loss (standarized): 0.40689891319083415\n",
      "          Validation Loss (standardized): 0.46739786298415525\n",
      "Epoch: 56, Loss (standarized): 0.4033501517563397\n",
      "          Validation Loss (standardized): 0.46559308748367856\n",
      "Epoch: 61, Loss (standarized): 0.39761380948699243\n",
      "          Validation Loss (standardized): 0.4587355391657323\n",
      "Epoch: 66, Loss (standarized): 0.39311785039654074\n",
      "          Validation Loss (standardized): 0.45211294263659324\n",
      "Epoch: 71, Loss (standarized): 0.3894534762055171\n",
      "          Validation Loss (standardized): 0.4491690031884657\n",
      "Epoch: 76, Loss (standarized): 0.38624831369213936\n",
      "          Validation Loss (standardized): 0.4454979144580844\n",
      "Epoch: 81, Loss (standarized): 0.38326023800705344\n",
      "          Validation Loss (standardized): 0.43964587850287873\n",
      "Epoch: 86, Loss (standarized): 0.38047175769863945\n",
      "          Validation Loss (standardized): 0.43439099787139057\n",
      "Epoch: 91, Loss (standarized): 0.378079440098123\n",
      "          Validation Loss (standardized): 0.43033233437248525\n",
      "Epoch: 96, Loss (standarized): 0.3757567173400148\n",
      "          Validation Loss (standardized): 0.4270064040849554\n",
      "Final epoch: 100, Final loss (standarized): 0.3740628874707385\n",
      "Epoch: 1, Loss (standarized): 2.466621497140855\n",
      "          Validation Loss (standardized): 1.4673903765084833\n",
      "Epoch: 6, Loss (standarized): 0.8825177032623042\n",
      "          Validation Loss (standardized): 1.0324202759165828\n",
      "Epoch: 11, Loss (standarized): 0.7354157059963861\n",
      "          Validation Loss (standardized): 0.6869296705504877\n",
      "Epoch: 16, Loss (standarized): 0.7129900803098896\n",
      "          Validation Loss (standardized): 0.6159807648334256\n",
      "Epoch: 21, Loss (standarized): 0.5962178846420119\n",
      "          Validation Loss (standardized): 0.6360956467742089\n",
      "Epoch: 26, Loss (standarized): 0.5784255270737502\n",
      "          Validation Loss (standardized): 0.6071421152600641\n",
      "Epoch: 31, Loss (standarized): 0.5520690529136651\n",
      "          Validation Loss (standardized): 0.5427861262347701\n",
      "Epoch: 36, Loss (standarized): 0.5164856436354105\n",
      "          Validation Loss (standardized): 0.5605372117084118\n",
      "Epoch: 41, Loss (standarized): 0.49466263881819295\n",
      "          Validation Loss (standardized): 0.5027613501440957\n",
      "Epoch: 46, Loss (standarized): 0.4774521970009486\n",
      "          Validation Loss (standardized): 0.5102801564121944\n",
      "Epoch: 51, Loss (standarized): 0.4610160636750778\n",
      "          Validation Loss (standardized): 0.48586682594761155\n",
      "Epoch: 56, Loss (standarized): 0.4499537862810958\n",
      "          Validation Loss (standardized): 0.501983128731513\n",
      "Epoch: 61, Loss (standarized): 0.43963328156414994\n",
      "          Validation Loss (standardized): 0.47750333540394324\n",
      "Epoch: 66, Loss (standarized): 0.4264096654875356\n",
      "          Validation Loss (standardized): 0.46147161091408195\n",
      "Epoch: 71, Loss (standarized): 0.4144574299281373\n",
      "          Validation Loss (standardized): 0.46033336415803205\n",
      "Epoch: 76, Loss (standarized): 0.3996390098861151\n",
      "          Validation Loss (standardized): 0.45258838264737894\n",
      "Epoch: 81, Loss (standarized): 0.384639797574693\n",
      "          Validation Loss (standardized): 0.4493788810414221\n",
      "Epoch: 86, Loss (standarized): 0.37206676043350423\n",
      "          Validation Loss (standardized): 0.4300851680055075\n",
      "Epoch: 91, Loss (standarized): 0.3613005546779206\n",
      "          Validation Loss (standardized): 0.41768371534424664\n",
      "Epoch: 96, Loss (standarized): 0.3528966443893916\n",
      "          Validation Loss (standardized): 0.41381989052975343\n",
      "Final epoch: 100, Final loss (standarized): 0.3468515568361236\n",
      "Epoch: 1, Loss (standarized): 1.764840085354726\n",
      "          Validation Loss (standardized): 1.0631319614595491\n",
      "Epoch: 6, Loss (standarized): 0.8709402894394692\n",
      "          Validation Loss (standardized): 0.916623418388952\n",
      "Epoch: 11, Loss (standarized): 0.7317795942986873\n",
      "          Validation Loss (standardized): 0.6724256434475879\n",
      "Epoch: 16, Loss (standarized): 0.6907429555330339\n",
      "          Validation Loss (standardized): 0.7359228789820341\n",
      "Epoch: 21, Loss (standarized): 0.5797617627836414\n",
      "          Validation Loss (standardized): 0.5537713786106457\n",
      "Epoch: 26, Loss (standarized): 0.5410988406387671\n",
      "          Validation Loss (standardized): 0.5757332261415207\n",
      "Epoch: 31, Loss (standarized): 0.4966128551782504\n",
      "          Validation Loss (standardized): 0.5144676391550306\n",
      "Epoch: 36, Loss (standarized): 0.48422336966678625\n",
      "          Validation Loss (standardized): 0.4915827275674317\n",
      "Epoch: 41, Loss (standarized): 0.46401303434542085\n",
      "          Validation Loss (standardized): 0.5013909961724936\n",
      "Epoch: 46, Loss (standarized): 0.4535795349459101\n",
      "          Validation Loss (standardized): 0.4872115449606753\n",
      "Epoch: 51, Loss (standarized): 0.43990920416465346\n",
      "          Validation Loss (standardized): 0.4856990828402746\n",
      "Epoch: 56, Loss (standarized): 0.431178776461784\n",
      "          Validation Loss (standardized): 0.47649674777258083\n",
      "Epoch: 61, Loss (standarized): 0.41983565585750443\n",
      "          Validation Loss (standardized): 0.4751620918143756\n",
      "Epoch: 66, Loss (standarized): 0.40747389715803906\n",
      "          Validation Loss (standardized): 0.46708156401184525\n",
      "Epoch: 71, Loss (standarized): 0.3953273268920537\n",
      "          Validation Loss (standardized): 0.45258834540677684\n",
      "Epoch: 76, Loss (standarized): 0.38406501817700994\n",
      "          Validation Loss (standardized): 0.44819702537876915\n",
      "Epoch: 81, Loss (standarized): 0.3752499764629604\n",
      "          Validation Loss (standardized): 0.4403362242579453\n",
      "Epoch: 86, Loss (standarized): 0.36875058642211606\n",
      "          Validation Loss (standardized): 0.4322097264396189\n",
      "Epoch: 91, Loss (standarized): 0.36353146463419983\n",
      "          Validation Loss (standardized): 0.4280050988054673\n",
      "Epoch: 96, Loss (standarized): 0.3588874354832896\n",
      "          Validation Loss (standardized): 0.42115388138976895\n",
      "Final epoch: 100, Final loss (standarized): 0.3555574632614563\n",
      "Epoch: 1, Loss (standarized): 2.933207159661708\n",
      "          Validation Loss (standardized): 1.9589223201512223\n",
      "Epoch: 6, Loss (standarized): 1.1265070584732717\n",
      "          Validation Loss (standardized): 1.0088038794321228\n",
      "Epoch: 11, Loss (standarized): 0.75169829695688\n",
      "          Validation Loss (standardized): 0.7721841800712014\n",
      "Epoch: 16, Loss (standarized): 0.77841758020491\n",
      "          Validation Loss (standardized): 0.8041184552936399\n",
      "Epoch: 21, Loss (standarized): 0.5937828108570798\n",
      "          Validation Loss (standardized): 0.6260274028443037\n",
      "Epoch: 26, Loss (standarized): 0.5814450243357869\n",
      "          Validation Loss (standardized): 0.551921008370135\n",
      "Epoch: 31, Loss (standarized): 0.4996357903352477\n",
      "          Validation Loss (standardized): 0.5360689805327141\n",
      "Epoch: 36, Loss (standarized): 0.48392032887541864\n",
      "          Validation Loss (standardized): 0.5223293009989955\n",
      "Epoch: 41, Loss (standarized): 0.45290805100334364\n",
      "          Validation Loss (standardized): 0.5020363143429084\n",
      "Epoch: 46, Loss (standarized): 0.4304931255975738\n",
      "          Validation Loss (standardized): 0.4687559162702321\n",
      "Epoch: 51, Loss (standarized): 0.4100763468297096\n",
      "          Validation Loss (standardized): 0.47399866714766115\n",
      "Epoch: 56, Loss (standarized): 0.4005751094616743\n",
      "          Validation Loss (standardized): 0.4640428564877216\n",
      "Epoch: 61, Loss (standarized): 0.38438625857837705\n",
      "          Validation Loss (standardized): 0.4413459930048689\n",
      "Epoch: 66, Loss (standarized): 0.3705208597902317\n",
      "          Validation Loss (standardized): 0.42337009484302895\n",
      "Epoch: 71, Loss (standarized): 0.35482148253461837\n",
      "          Validation Loss (standardized): 0.39993948067917856\n",
      "Epoch: 76, Loss (standarized): 0.34100127004375924\n",
      "          Validation Loss (standardized): 0.3801119695192536\n",
      "Epoch: 81, Loss (standarized): 0.32537161810973336\n",
      "          Validation Loss (standardized): 0.3651384525507522\n",
      "Epoch: 86, Loss (standarized): 0.30684137352135005\n",
      "          Validation Loss (standardized): 0.3419858758859336\n",
      "Epoch: 91, Loss (standarized): 0.2873692176318391\n",
      "          Validation Loss (standardized): 0.3266684640057305\n",
      "Epoch: 96, Loss (standarized): 0.26641533842632936\n",
      "          Validation Loss (standardized): 0.30340606125289793\n",
      "Final epoch: 100, Final loss (standarized): 0.2488804844689189\n",
      "Epoch: 1, Loss (standarized): 0.9762659481101806\n",
      "          Validation Loss (standardized): 0.8052162820909513\n",
      "Epoch: 6, Loss (standarized): 0.6783612283740282\n",
      "          Validation Loss (standardized): 0.6498259747282412\n",
      "Epoch: 11, Loss (standarized): 0.5841748563176484\n",
      "          Validation Loss (standardized): 0.6449437770205124\n",
      "Epoch: 16, Loss (standarized): 0.5153564371404473\n",
      "          Validation Loss (standardized): 0.5336113515434836\n",
      "Epoch: 21, Loss (standarized): 0.46980232012609235\n",
      "          Validation Loss (standardized): 0.5327309672703442\n",
      "Epoch: 26, Loss (standarized): 0.44707938008407266\n",
      "          Validation Loss (standardized): 0.5014313025810293\n",
      "Epoch: 31, Loss (standarized): 0.4382180191366808\n",
      "          Validation Loss (standardized): 0.519732971868129\n",
      "Epoch: 36, Loss (standarized): 0.43210281608263645\n",
      "          Validation Loss (standardized): 0.4953061224880911\n",
      "Epoch: 41, Loss (standarized): 0.4225000548283462\n",
      "          Validation Loss (standardized): 0.502931747233656\n",
      "Epoch: 46, Loss (standarized): 0.41510966105456004\n",
      "          Validation Loss (standardized): 0.48102741811332783\n",
      "Epoch: 51, Loss (standarized): 0.4084960245622854\n",
      "          Validation Loss (standardized): 0.4781244736193155\n",
      "Epoch: 56, Loss (standarized): 0.4032468759845452\n",
      "          Validation Loss (standardized): 0.4690856494199646\n",
      "Epoch: 61, Loss (standarized): 0.3953706221423635\n",
      "          Validation Loss (standardized): 0.4587589552693311\n",
      "Epoch: 66, Loss (standarized): 0.3871177440369248\n",
      "          Validation Loss (standardized): 0.44727269751425475\n",
      "Epoch: 71, Loss (standarized): 0.3767137121395453\n",
      "          Validation Loss (standardized): 0.43509361744854774\n",
      "Epoch: 76, Loss (standarized): 0.36615370964755944\n",
      "          Validation Loss (standardized): 0.42251007091786874\n",
      "Epoch: 81, Loss (standarized): 0.35531822950451375\n",
      "          Validation Loss (standardized): 0.41073373402080476\n",
      "Epoch: 86, Loss (standarized): 0.34413476194855364\n",
      "          Validation Loss (standardized): 0.3961496098066973\n",
      "Epoch: 91, Loss (standarized): 0.3335985594525819\n",
      "          Validation Loss (standardized): 0.38219422425594046\n",
      "Epoch: 96, Loss (standarized): 0.32312293368902073\n",
      "          Validation Loss (standardized): 0.36762084883598617\n",
      "Final epoch: 100, Final loss (standarized): 0.31498069043321186\n",
      "Epoch: 1, Loss (standarized): 1.2564697803350837\n",
      "          Validation Loss (standardized): 0.8544362548983097\n",
      "Epoch: 6, Loss (standarized): 0.8335436522286759\n",
      "          Validation Loss (standardized): 0.8854044412153758\n",
      "Epoch: 11, Loss (standarized): 0.7367716292260912\n",
      "          Validation Loss (standardized): 0.6874860093061819\n",
      "Epoch: 16, Loss (standarized): 0.6520645142111908\n",
      "          Validation Loss (standardized): 0.6671066405566836\n",
      "Epoch: 21, Loss (standarized): 0.6244481250914421\n",
      "          Validation Loss (standardized): 0.6581295160648415\n",
      "Epoch: 26, Loss (standarized): 0.5740291683049525\n",
      "          Validation Loss (standardized): 0.5704096333425559\n",
      "Epoch: 31, Loss (standarized): 0.5380325085512006\n",
      "          Validation Loss (standardized): 0.5671828483853196\n",
      "Epoch: 36, Loss (standarized): 0.5122209102214205\n",
      "          Validation Loss (standardized): 0.5504267289685901\n",
      "Epoch: 41, Loss (standarized): 0.49056457411725346\n",
      "          Validation Loss (standardized): 0.5126166208485988\n",
      "Epoch: 46, Loss (standarized): 0.47314315946653557\n",
      "          Validation Loss (standardized): 0.5291194162212735\n",
      "Epoch: 51, Loss (standarized): 0.459069043350258\n",
      "          Validation Loss (standardized): 0.4973481793772798\n",
      "Epoch: 56, Loss (standarized): 0.44787400935095345\n",
      "          Validation Loss (standardized): 0.5035712993719391\n",
      "Epoch: 61, Loss (standarized): 0.436034939600225\n",
      "          Validation Loss (standardized): 0.48508201967762415\n",
      "Epoch: 66, Loss (standarized): 0.42153387142790777\n",
      "          Validation Loss (standardized): 0.47931929462847933\n",
      "Epoch: 71, Loss (standarized): 0.40451882472326145\n",
      "          Validation Loss (standardized): 0.4554933922506542\n",
      "Epoch: 76, Loss (standarized): 0.38487935622156394\n",
      "          Validation Loss (standardized): 0.43951936137652053\n",
      "Epoch: 81, Loss (standarized): 0.3640880385078389\n",
      "          Validation Loss (standardized): 0.4140332134969965\n",
      "Epoch: 86, Loss (standarized): 0.34188380017574427\n",
      "          Validation Loss (standardized): 0.38710352936144865\n",
      "Epoch: 91, Loss (standarized): 0.32221940248519926\n",
      "          Validation Loss (standardized): 0.3628685899962252\n",
      "Epoch: 96, Loss (standarized): 0.3049869680200749\n",
      "          Validation Loss (standardized): 0.34176200855842653\n",
      "Final epoch: 100, Final loss (standarized): 0.29118267223991207\n",
      "Epoch: 1, Loss (standarized): 1.7630820211574427\n",
      "          Validation Loss (standardized): 1.4859511998200998\n",
      "Epoch: 6, Loss (standarized): 0.7446368345904577\n",
      "          Validation Loss (standardized): 0.7073599539615091\n",
      "Epoch: 11, Loss (standarized): 0.8334898202444899\n",
      "          Validation Loss (standardized): 0.6880590020116231\n",
      "Epoch: 16, Loss (standarized): 0.6494242963392438\n",
      "          Validation Loss (standardized): 0.6438498815433618\n",
      "Epoch: 21, Loss (standarized): 0.6117393844047063\n",
      "          Validation Loss (standardized): 0.6377653253193528\n",
      "Epoch: 26, Loss (standarized): 0.5515737207815056\n",
      "          Validation Loss (standardized): 0.5533686126806073\n",
      "Epoch: 31, Loss (standarized): 0.49175991039796774\n",
      "          Validation Loss (standardized): 0.4976117789523822\n",
      "Epoch: 36, Loss (standarized): 0.453583496178669\n",
      "          Validation Loss (standardized): 0.46510923821544203\n",
      "Epoch: 41, Loss (standarized): 0.42190982055833287\n",
      "          Validation Loss (standardized): 0.45449199467677787\n",
      "Epoch: 46, Loss (standarized): 0.40675321832341\n",
      "          Validation Loss (standardized): 0.4474328271574315\n",
      "Epoch: 51, Loss (standarized): 0.3959833176457851\n",
      "          Validation Loss (standardized): 0.43704235388521484\n",
      "Epoch: 56, Loss (standarized): 0.38476855551547356\n",
      "          Validation Loss (standardized): 0.430777426455802\n",
      "Epoch: 61, Loss (standarized): 0.37358322909458885\n",
      "          Validation Loss (standardized): 0.4258578967509935\n",
      "Epoch: 66, Loss (standarized): 0.36269180040040355\n",
      "          Validation Loss (standardized): 0.41056579739897414\n",
      "Epoch: 71, Loss (standarized): 0.35184097119873076\n",
      "          Validation Loss (standardized): 0.4013291087105673\n",
      "Epoch: 76, Loss (standarized): 0.3421249069678514\n",
      "          Validation Loss (standardized): 0.39289625519892935\n",
      "Epoch: 81, Loss (standarized): 0.33321760129623507\n",
      "          Validation Loss (standardized): 0.38536586047270865\n",
      "Epoch: 86, Loss (standarized): 0.32447930749119436\n",
      "          Validation Loss (standardized): 0.3739039348748031\n",
      "Epoch: 91, Loss (standarized): 0.3161523663078632\n",
      "          Validation Loss (standardized): 0.3647385041725637\n",
      "Epoch: 96, Loss (standarized): 0.30820119526527284\n",
      "          Validation Loss (standardized): 0.35775750599498224\n",
      "Final epoch: 100, Final loss (standarized): 0.30255349646884405\n",
      "Epoch: 1, Loss (standarized): 0.9541957638471956\n",
      "          Validation Loss (standardized): 0.79626503038212\n",
      "Epoch: 6, Loss (standarized): 0.7073917589078821\n",
      "          Validation Loss (standardized): 0.6926438086639114\n",
      "Epoch: 11, Loss (standarized): 0.6257468738101817\n",
      "          Validation Loss (standardized): 0.6939816631402373\n",
      "Epoch: 16, Loss (standarized): 0.5493924641105986\n",
      "          Validation Loss (standardized): 0.5525716798086464\n",
      "Epoch: 21, Loss (standarized): 0.5036097996720413\n",
      "          Validation Loss (standardized): 0.5719475929887002\n",
      "Epoch: 26, Loss (standarized): 0.47128046280421165\n",
      "          Validation Loss (standardized): 0.49821892140759916\n",
      "Epoch: 31, Loss (standarized): 0.4392435023119624\n",
      "          Validation Loss (standardized): 0.48392205563426016\n",
      "Epoch: 36, Loss (standarized): 0.425057320934615\n",
      "          Validation Loss (standardized): 0.49547625424511\n",
      "Epoch: 41, Loss (standarized): 0.4133557323087351\n",
      "          Validation Loss (standardized): 0.44992064532070475\n",
      "Epoch: 46, Loss (standarized): 0.3878864775962796\n",
      "          Validation Loss (standardized): 0.4232496397964402\n",
      "Epoch: 51, Loss (standarized): 0.3667315537360547\n",
      "          Validation Loss (standardized): 0.4017834951974714\n",
      "Epoch: 56, Loss (standarized): 0.33789043709731414\n",
      "          Validation Loss (standardized): 0.37279030780267375\n",
      "Epoch: 61, Loss (standarized): 0.32092393915796824\n",
      "          Validation Loss (standardized): 0.3480665952308716\n",
      "Epoch: 66, Loss (standarized): 0.30689433809922945\n",
      "          Validation Loss (standardized): 0.3330545351386438\n",
      "Epoch: 71, Loss (standarized): 0.2975632909046758\n",
      "          Validation Loss (standardized): 0.325179202883441\n",
      "Epoch: 76, Loss (standarized): 0.2893407457857592\n",
      "          Validation Loss (standardized): 0.31855885523429106\n",
      "Epoch: 81, Loss (standarized): 0.2832805034307021\n",
      "          Validation Loss (standardized): 0.3173892808430774\n",
      "Epoch: 86, Loss (standarized): 0.27820583220464357\n",
      "          Validation Loss (standardized): 0.3136764330954357\n",
      "Epoch: 91, Loss (standarized): 0.2736317658583582\n",
      "          Validation Loss (standardized): 0.3124690083637079\n",
      "Epoch: 96, Loss (standarized): 0.27040469833696\n",
      "          Validation Loss (standardized): 0.3105842312057912\n",
      "Final epoch: 100, Final loss (standarized): 0.26894358077953096\n",
      "Epoch: 1, Loss (standarized): 1.3550321935445173\n",
      "          Validation Loss (standardized): 0.9670705188468162\n",
      "Epoch: 6, Loss (standarized): 0.8352301219257938\n",
      "          Validation Loss (standardized): 0.8819364016404643\n",
      "Epoch: 11, Loss (standarized): 0.6623693472788497\n",
      "          Validation Loss (standardized): 0.6683916721878778\n",
      "Epoch: 16, Loss (standarized): 0.6257984091642461\n",
      "          Validation Loss (standardized): 0.5958937469845598\n",
      "Epoch: 21, Loss (standarized): 0.5160174490647005\n",
      "          Validation Loss (standardized): 0.550410525364362\n",
      "Epoch: 26, Loss (standarized): 0.4770141729202021\n",
      "          Validation Loss (standardized): 0.5169555764621259\n",
      "Epoch: 31, Loss (standarized): 0.4440988911372263\n",
      "          Validation Loss (standardized): 0.4765873421684574\n",
      "Epoch: 36, Loss (standarized): 0.42868603131684074\n",
      "          Validation Loss (standardized): 0.4677789606963141\n",
      "Epoch: 41, Loss (standarized): 0.4139730363648567\n",
      "          Validation Loss (standardized): 0.4580469409292655\n",
      "Epoch: 46, Loss (standarized): 0.40090603535992797\n",
      "          Validation Loss (standardized): 0.44270510527301665\n",
      "Epoch: 51, Loss (standarized): 0.39325869868638313\n",
      "          Validation Loss (standardized): 0.43336234739092655\n",
      "Epoch: 56, Loss (standarized): 0.38697094421100847\n",
      "          Validation Loss (standardized): 0.430324603675589\n",
      "Epoch: 61, Loss (standarized): 0.38062992854305033\n",
      "          Validation Loss (standardized): 0.42490411917678744\n",
      "Epoch: 66, Loss (standarized): 0.3750091012386154\n",
      "          Validation Loss (standardized): 0.4192724340403724\n",
      "Epoch: 71, Loss (standarized): 0.3691352843310756\n",
      "          Validation Loss (standardized): 0.4143715016375254\n",
      "Epoch: 76, Loss (standarized): 0.36368238204407377\n",
      "          Validation Loss (standardized): 0.40950177763582324\n",
      "Epoch: 81, Loss (standarized): 0.3571288880699445\n",
      "          Validation Loss (standardized): 0.4037290075125744\n",
      "Epoch: 86, Loss (standarized): 0.3501529789138841\n",
      "          Validation Loss (standardized): 0.39712383451822353\n",
      "Epoch: 91, Loss (standarized): 0.34236812479865747\n",
      "          Validation Loss (standardized): 0.3917520491360675\n",
      "Epoch: 96, Loss (standarized): 0.33244978696656574\n",
      "          Validation Loss (standardized): 0.3828308258145995\n",
      "Final epoch: 100, Final loss (standarized): 0.3257389324726428\n",
      "Epoch: 1, Loss (standarized): 2.302235495592843\n",
      "          Validation Loss (standardized): 1.2648434437662854\n",
      "Epoch: 6, Loss (standarized): 0.9312019614548932\n",
      "          Validation Loss (standardized): 1.202764940561439\n",
      "Epoch: 11, Loss (standarized): 0.8827886749654376\n",
      "          Validation Loss (standardized): 0.8855354753869991\n",
      "Epoch: 16, Loss (standarized): 0.7368071590551581\n",
      "          Validation Loss (standardized): 0.6849865404825104\n",
      "Epoch: 21, Loss (standarized): 0.7138113845419947\n",
      "          Validation Loss (standardized): 0.6620450274730478\n",
      "Epoch: 26, Loss (standarized): 0.6441943648868591\n",
      "          Validation Loss (standardized): 0.6723779902650083\n",
      "Epoch: 31, Loss (standarized): 0.6010829901729661\n",
      "          Validation Loss (standardized): 0.6381997002420442\n",
      "Epoch: 36, Loss (standarized): 0.5529234853181879\n",
      "          Validation Loss (standardized): 0.5467381171475444\n",
      "Epoch: 41, Loss (standarized): 0.5001588385093381\n",
      "          Validation Loss (standardized): 0.513849645069933\n",
      "Epoch: 46, Loss (standarized): 0.45973365470237615\n",
      "          Validation Loss (standardized): 0.4824459482983963\n",
      "Epoch: 51, Loss (standarized): 0.42822478132049324\n",
      "          Validation Loss (standardized): 0.4541882646732717\n",
      "Epoch: 56, Loss (standarized): 0.40372654607580305\n",
      "          Validation Loss (standardized): 0.44318418973693746\n",
      "Epoch: 61, Loss (standarized): 0.39077173765710205\n",
      "          Validation Loss (standardized): 0.4395816085134915\n",
      "Epoch: 66, Loss (standarized): 0.38404743469791675\n",
      "          Validation Loss (standardized): 0.4265011234801547\n",
      "Epoch: 71, Loss (standarized): 0.37456710208722044\n",
      "          Validation Loss (standardized): 0.42342286010479996\n",
      "Epoch: 76, Loss (standarized): 0.36376377945316163\n",
      "          Validation Loss (standardized): 0.413833691981833\n",
      "Epoch: 81, Loss (standarized): 0.35326069340861455\n",
      "          Validation Loss (standardized): 0.3987977908582598\n",
      "Epoch: 86, Loss (standarized): 0.3434857709314691\n",
      "          Validation Loss (standardized): 0.39106359108491967\n",
      "Epoch: 91, Loss (standarized): 0.3331748273662957\n",
      "          Validation Loss (standardized): 0.38631884466326255\n",
      "Epoch: 96, Loss (standarized): 0.3221300106608368\n",
      "          Validation Loss (standardized): 0.3771529592159025\n",
      "Final epoch: 100, Final loss (standarized): 0.31370854290155126\n",
      "Epoch: 1, Loss (standarized): 2.50267506466303\n",
      "          Validation Loss (standardized): 1.364792128387464\n",
      "Epoch: 6, Loss (standarized): 0.806881527478738\n",
      "          Validation Loss (standardized): 0.8875897732587654\n",
      "Epoch: 11, Loss (standarized): 0.8391121793370317\n",
      "          Validation Loss (standardized): 0.7979800938250626\n",
      "Epoch: 16, Loss (standarized): 0.5901153803680381\n",
      "          Validation Loss (standardized): 0.6763453948083895\n",
      "Epoch: 21, Loss (standarized): 0.5427635628754022\n",
      "          Validation Loss (standardized): 0.5562206558423743\n",
      "Epoch: 26, Loss (standarized): 0.5097492000029205\n",
      "          Validation Loss (standardized): 0.5284816478472864\n",
      "Epoch: 31, Loss (standarized): 0.45313272567722274\n",
      "          Validation Loss (standardized): 0.5078265563241863\n",
      "Epoch: 36, Loss (standarized): 0.44930029713076225\n",
      "          Validation Loss (standardized): 0.5025765538836385\n",
      "Epoch: 41, Loss (standarized): 0.43824143483947653\n",
      "          Validation Loss (standardized): 0.5052716252440662\n",
      "Epoch: 46, Loss (standarized): 0.4272150372372717\n",
      "          Validation Loss (standardized): 0.46995029247721953\n",
      "Epoch: 51, Loss (standarized): 0.41687079335768595\n",
      "          Validation Loss (standardized): 0.46601629556667595\n",
      "Epoch: 56, Loss (standarized): 0.4022483965443887\n",
      "          Validation Loss (standardized): 0.4462662647829433\n",
      "Epoch: 61, Loss (standarized): 0.39000542785796277\n",
      "          Validation Loss (standardized): 0.4401057736780713\n",
      "Epoch: 66, Loss (standarized): 0.3774019829851492\n",
      "          Validation Loss (standardized): 0.4177978377015809\n",
      "Epoch: 71, Loss (standarized): 0.36507458600938775\n",
      "          Validation Loss (standardized): 0.40626175983024027\n",
      "Epoch: 76, Loss (standarized): 0.3558435316642572\n",
      "          Validation Loss (standardized): 0.38798217033914495\n",
      "Epoch: 81, Loss (standarized): 0.34817802928741654\n",
      "          Validation Loss (standardized): 0.384252360609268\n",
      "Epoch: 86, Loss (standarized): 0.3411041416387228\n",
      "          Validation Loss (standardized): 0.372498909664084\n",
      "Epoch: 91, Loss (standarized): 0.3352313787098515\n",
      "          Validation Loss (standardized): 0.3643095996626511\n",
      "Epoch: 96, Loss (standarized): 0.3293826894867889\n",
      "          Validation Loss (standardized): 0.3605638120519538\n",
      "Final epoch: 100, Final loss (standarized): 0.3251493951070453\n",
      "Epoch: 1, Loss (standarized): 4.678891579069037\n",
      "          Validation Loss (standardized): 3.244788389058001\n",
      "Epoch: 6, Loss (standarized): 1.3071453006874818\n",
      "          Validation Loss (standardized): 0.9869490346959451\n",
      "Epoch: 11, Loss (standarized): 0.7880069935523434\n",
      "          Validation Loss (standardized): 0.8815641939584044\n",
      "Epoch: 16, Loss (standarized): 0.7657115892859568\n",
      "          Validation Loss (standardized): 0.7730535326494268\n",
      "Epoch: 21, Loss (standarized): 0.6376813661477329\n",
      "          Validation Loss (standardized): 0.6380776829394529\n",
      "Epoch: 26, Loss (standarized): 0.5871881173967398\n",
      "          Validation Loss (standardized): 0.5645818764708288\n",
      "Epoch: 31, Loss (standarized): 0.5177887049681436\n",
      "          Validation Loss (standardized): 0.5339616485856342\n",
      "Epoch: 36, Loss (standarized): 0.47873560116477637\n",
      "          Validation Loss (standardized): 0.49287775627628394\n",
      "Epoch: 41, Loss (standarized): 0.4347391367550754\n",
      "          Validation Loss (standardized): 0.4532400444871999\n",
      "Epoch: 46, Loss (standarized): 0.41872593666720814\n",
      "          Validation Loss (standardized): 0.4401610390555036\n",
      "Epoch: 51, Loss (standarized): 0.405308707571938\n",
      "          Validation Loss (standardized): 0.43778535173832184\n",
      "Epoch: 56, Loss (standarized): 0.4009033472834161\n",
      "          Validation Loss (standardized): 0.43534696247301186\n",
      "Epoch: 61, Loss (standarized): 0.3977928790689137\n",
      "          Validation Loss (standardized): 0.4257378516765894\n",
      "Epoch: 66, Loss (standarized): 0.39559962420649397\n",
      "          Validation Loss (standardized): 0.4250599693974908\n",
      "Epoch: 71, Loss (standarized): 0.39132571372584213\n",
      "          Validation Loss (standardized): 0.42027379796631775\n",
      "Epoch: 76, Loss (standarized): 0.38701687946907903\n",
      "          Validation Loss (standardized): 0.4201550936536061\n",
      "Epoch: 81, Loss (standarized): 0.3838604799476925\n",
      "          Validation Loss (standardized): 0.4209378269782883\n",
      "Epoch: 86, Loss (standarized): 0.3809988955177136\n",
      "          Validation Loss (standardized): 0.41782644505724426\n",
      "Epoch: 91, Loss (standarized): 0.3785847923255505\n",
      "          Validation Loss (standardized): 0.41475846442008674\n",
      "Epoch: 96, Loss (standarized): 0.3756959829025507\n",
      "          Validation Loss (standardized): 0.41433758182596464\n",
      "Final epoch: 100, Final loss (standarized): 0.37369478454297617\n",
      "Epoch: 1, Loss (standarized): 1.127675204120614\n",
      "          Validation Loss (standardized): 0.9970226741017165\n",
      "Epoch: 6, Loss (standarized): 0.7706455421306766\n",
      "          Validation Loss (standardized): 0.6871496450883984\n",
      "Epoch: 11, Loss (standarized): 0.6795552560245228\n",
      "          Validation Loss (standardized): 0.6647397061103861\n",
      "Epoch: 16, Loss (standarized): 0.6290477368039982\n",
      "          Validation Loss (standardized): 0.6641068295811646\n",
      "Epoch: 21, Loss (standarized): 0.5911795002994373\n",
      "          Validation Loss (standardized): 0.5820750337521674\n",
      "Epoch: 26, Loss (standarized): 0.5549148464266287\n",
      "          Validation Loss (standardized): 0.5633476689033262\n",
      "Epoch: 31, Loss (standarized): 0.5248318885447867\n",
      "          Validation Loss (standardized): 0.5433503677488969\n",
      "Epoch: 36, Loss (standarized): 0.4983095963963665\n",
      "          Validation Loss (standardized): 0.5087094270302503\n",
      "Epoch: 41, Loss (standarized): 0.47366487505135435\n",
      "          Validation Loss (standardized): 0.4989370236221251\n",
      "Epoch: 46, Loss (standarized): 0.46032663782217276\n",
      "          Validation Loss (standardized): 0.4782610079538467\n",
      "Epoch: 51, Loss (standarized): 0.4475443173127152\n",
      "          Validation Loss (standardized): 0.47903762474086065\n",
      "Epoch: 56, Loss (standarized): 0.4408174897094166\n",
      "          Validation Loss (standardized): 0.46971602268765544\n",
      "Epoch: 61, Loss (standarized): 0.43633393616788413\n",
      "          Validation Loss (standardized): 0.4681267160756481\n",
      "Epoch: 66, Loss (standarized): 0.43249086695942546\n",
      "          Validation Loss (standardized): 0.465677500951914\n",
      "Epoch: 71, Loss (standarized): 0.4288818993421136\n",
      "          Validation Loss (standardized): 0.462267963110275\n",
      "Epoch: 76, Loss (standarized): 0.4251748160581377\n",
      "          Validation Loss (standardized): 0.4553701971701194\n",
      "Epoch: 81, Loss (standarized): 0.42122995876225267\n",
      "          Validation Loss (standardized): 0.45192214691066823\n",
      "Epoch: 86, Loss (standarized): 0.4158259921964806\n",
      "          Validation Loss (standardized): 0.44919932210962377\n",
      "Epoch: 91, Loss (standarized): 0.41106086813417314\n",
      "          Validation Loss (standardized): 0.4459595467007048\n",
      "Epoch: 96, Loss (standarized): 0.4067800802890645\n",
      "          Validation Loss (standardized): 0.44363186044413416\n",
      "Final epoch: 100, Final loss (standarized): 0.4041537157585754\n",
      "Epoch: 1, Loss (standarized): 3.8418665484248002\n",
      "          Validation Loss (standardized): 3.4656056312722505\n",
      "Epoch: 6, Loss (standarized): 0.723453961067295\n",
      "          Validation Loss (standardized): 0.6660172181133833\n",
      "Epoch: 11, Loss (standarized): 0.9583439763935229\n",
      "          Validation Loss (standardized): 0.8542406033886542\n",
      "Epoch: 16, Loss (standarized): 0.7538328555445821\n",
      "          Validation Loss (standardized): 0.6253856427836106\n",
      "Epoch: 21, Loss (standarized): 0.5876772728317355\n",
      "          Validation Loss (standardized): 0.6537246757367495\n",
      "Epoch: 26, Loss (standarized): 0.6386790559195522\n",
      "          Validation Loss (standardized): 0.7426759406956063\n",
      "Epoch: 31, Loss (standarized): 0.5971164540936352\n",
      "          Validation Loss (standardized): 0.6485975650126359\n",
      "Epoch: 36, Loss (standarized): 0.536354238624954\n",
      "          Validation Loss (standardized): 0.546222287139537\n",
      "Epoch: 41, Loss (standarized): 0.5327658743583392\n",
      "          Validation Loss (standardized): 0.5260459524409093\n",
      "Epoch: 46, Loss (standarized): 0.5155550762588839\n",
      "          Validation Loss (standardized): 0.5286504805929404\n",
      "Epoch: 51, Loss (standarized): 0.5051927937935273\n",
      "          Validation Loss (standardized): 0.5387800823932922\n",
      "Epoch: 56, Loss (standarized): 0.49911579341657986\n",
      "          Validation Loss (standardized): 0.536000210534827\n",
      "Epoch: 61, Loss (standarized): 0.4885110483973727\n",
      "          Validation Loss (standardized): 0.5216863622125513\n",
      "Epoch: 66, Loss (standarized): 0.4796843443109672\n",
      "          Validation Loss (standardized): 0.5045828135508422\n",
      "Epoch: 71, Loss (standarized): 0.4699918667583165\n",
      "          Validation Loss (standardized): 0.49856854551657437\n",
      "Epoch: 76, Loss (standarized): 0.4623158937248533\n",
      "          Validation Loss (standardized): 0.4956201540465719\n",
      "Epoch: 81, Loss (standarized): 0.45837126688275037\n",
      "          Validation Loss (standardized): 0.49277972052391905\n",
      "Epoch: 86, Loss (standarized): 0.4528876602702395\n",
      "          Validation Loss (standardized): 0.4864176994658841\n",
      "Epoch: 91, Loss (standarized): 0.44890306159337595\n",
      "          Validation Loss (standardized): 0.4846483206685427\n",
      "Epoch: 96, Loss (standarized): 0.4463539332602796\n",
      "          Validation Loss (standardized): 0.48622265111514357\n",
      "Final epoch: 100, Final loss (standarized): 0.4447332721673673\n",
      "Epoch: 1, Loss (standarized): 2.8254736432734138\n",
      "          Validation Loss (standardized): 1.2728633614036107\n",
      "Epoch: 6, Loss (standarized): 1.1454458874708986\n",
      "          Validation Loss (standardized): 1.468115672328463\n",
      "Epoch: 11, Loss (standarized): 0.7965181946991583\n",
      "          Validation Loss (standardized): 0.7726514913197684\n",
      "Epoch: 16, Loss (standarized): 0.8071026724837385\n",
      "          Validation Loss (standardized): 0.7055349266689934\n",
      "Epoch: 21, Loss (standarized): 0.6553041886568208\n",
      "          Validation Loss (standardized): 0.6327127936215775\n",
      "Epoch: 26, Loss (standarized): 0.6168762638042274\n",
      "          Validation Loss (standardized): 0.7071927646859436\n",
      "Epoch: 31, Loss (standarized): 0.5574209494832317\n",
      "          Validation Loss (standardized): 0.589988920318492\n",
      "Epoch: 36, Loss (standarized): 0.5392833008927879\n",
      "          Validation Loss (standardized): 0.5299235810150198\n",
      "Epoch: 41, Loss (standarized): 0.5144948259499704\n",
      "          Validation Loss (standardized): 0.5255089319262929\n",
      "Epoch: 46, Loss (standarized): 0.4932494435719722\n",
      "          Validation Loss (standardized): 0.5414608277905417\n",
      "Epoch: 51, Loss (standarized): 0.4793083996242548\n",
      "          Validation Loss (standardized): 0.5105995540362082\n",
      "Epoch: 56, Loss (standarized): 0.469441897401875\n",
      "          Validation Loss (standardized): 0.4967548907316126\n",
      "Epoch: 61, Loss (standarized): 0.46100216566705887\n",
      "          Validation Loss (standardized): 0.5039053232717081\n",
      "Epoch: 66, Loss (standarized): 0.45654608857548223\n",
      "          Validation Loss (standardized): 0.5029221481796273\n",
      "Epoch: 71, Loss (standarized): 0.45268092165682255\n",
      "          Validation Loss (standardized): 0.49115132775623893\n",
      "Epoch: 76, Loss (standarized): 0.449009014213592\n",
      "          Validation Loss (standardized): 0.48973396685167486\n",
      "Epoch: 81, Loss (standarized): 0.4451000049341106\n",
      "          Validation Loss (standardized): 0.48929700698502077\n",
      "Epoch: 86, Loss (standarized): 0.44103078774582904\n",
      "          Validation Loss (standardized): 0.48446474817238794\n",
      "Epoch: 91, Loss (standarized): 0.43607997375957847\n",
      "          Validation Loss (standardized): 0.4799827283231943\n",
      "Epoch: 96, Loss (standarized): 0.43101342724825437\n",
      "          Validation Loss (standardized): 0.4748842053650182\n",
      "Final epoch: 100, Final loss (standarized): 0.42704814845084804\n",
      "Epoch: 1, Loss (standarized): 1.9270575837775243\n",
      "          Validation Loss (standardized): 1.5908739305771777\n",
      "Epoch: 6, Loss (standarized): 0.7177833946291777\n",
      "          Validation Loss (standardized): 0.7196037542559905\n",
      "Epoch: 11, Loss (standarized): 0.8160894161735393\n",
      "          Validation Loss (standardized): 0.7184192679193484\n",
      "Epoch: 16, Loss (standarized): 0.6330558576328746\n",
      "          Validation Loss (standardized): 0.6304788575763787\n",
      "Epoch: 21, Loss (standarized): 0.6270276984463117\n",
      "          Validation Loss (standardized): 0.6857270883143373\n",
      "Epoch: 26, Loss (standarized): 0.5699796787777677\n",
      "          Validation Loss (standardized): 0.576830230490441\n",
      "Epoch: 31, Loss (standarized): 0.5405723097940494\n",
      "          Validation Loss (standardized): 0.5367015645834301\n",
      "Epoch: 36, Loss (standarized): 0.5074265248551054\n",
      "          Validation Loss (standardized): 0.5421137722000796\n",
      "Epoch: 41, Loss (standarized): 0.4805443771003608\n",
      "          Validation Loss (standardized): 0.49889699581403624\n",
      "Epoch: 46, Loss (standarized): 0.4573595011936705\n",
      "          Validation Loss (standardized): 0.49116964347751024\n",
      "Epoch: 51, Loss (standarized): 0.4385880176008591\n",
      "          Validation Loss (standardized): 0.48205339983703405\n",
      "Epoch: 56, Loss (standarized): 0.4271733969002258\n",
      "          Validation Loss (standardized): 0.47507413427112594\n",
      "Epoch: 61, Loss (standarized): 0.4209857974605045\n",
      "          Validation Loss (standardized): 0.4712069284306043\n",
      "Epoch: 66, Loss (standarized): 0.41199341460816247\n",
      "          Validation Loss (standardized): 0.46880667783559216\n",
      "Epoch: 71, Loss (standarized): 0.40179643873654725\n",
      "          Validation Loss (standardized): 0.4542203368684598\n",
      "Epoch: 76, Loss (standarized): 0.39109617008532455\n",
      "          Validation Loss (standardized): 0.4373759801681718\n",
      "Epoch: 81, Loss (standarized): 0.37788335542133794\n",
      "          Validation Loss (standardized): 0.42879683438485316\n",
      "Epoch: 86, Loss (standarized): 0.3661615739209081\n",
      "          Validation Loss (standardized): 0.4261491822293172\n",
      "Epoch: 91, Loss (standarized): 0.3537105057183322\n",
      "          Validation Loss (standardized): 0.41602635606116367\n",
      "Epoch: 96, Loss (standarized): 0.3403337354985478\n",
      "          Validation Loss (standardized): 0.39620987393826496\n",
      "Final epoch: 100, Final loss (standarized): 0.32970481509545746\n",
      "Epoch: 1, Loss (standarized): 3.210192582203409\n",
      "          Validation Loss (standardized): 1.747319948850312\n",
      "Epoch: 6, Loss (standarized): 1.0837664507957565\n",
      "          Validation Loss (standardized): 1.2880304692569309\n",
      "Epoch: 11, Loss (standarized): 0.8289509945780911\n",
      "          Validation Loss (standardized): 0.7415113948852613\n",
      "Epoch: 16, Loss (standarized): 0.7292910799721195\n",
      "          Validation Loss (standardized): 0.7286561571559845\n",
      "Epoch: 21, Loss (standarized): 0.6690946245623717\n",
      "          Validation Loss (standardized): 0.6554250365458856\n",
      "Epoch: 26, Loss (standarized): 0.5507321108378107\n",
      "          Validation Loss (standardized): 0.6029633442559511\n",
      "Epoch: 31, Loss (standarized): 0.5441964386647593\n",
      "          Validation Loss (standardized): 0.5794722232358922\n",
      "Epoch: 36, Loss (standarized): 0.47565557857621493\n",
      "          Validation Loss (standardized): 0.5134209709353261\n",
      "Epoch: 41, Loss (standarized): 0.46360805652001247\n",
      "          Validation Loss (standardized): 0.48171503888150397\n",
      "Epoch: 46, Loss (standarized): 0.42468292357187193\n",
      "          Validation Loss (standardized): 0.4571195290766527\n",
      "Epoch: 51, Loss (standarized): 0.41343987794783155\n",
      "          Validation Loss (standardized): 0.4578789501369072\n",
      "Epoch: 56, Loss (standarized): 0.4016912526039144\n",
      "          Validation Loss (standardized): 0.44351275492227626\n",
      "Epoch: 61, Loss (standarized): 0.3957568651711195\n",
      "          Validation Loss (standardized): 0.4286349660031016\n",
      "Epoch: 66, Loss (standarized): 0.39152412438584455\n",
      "          Validation Loss (standardized): 0.4266757074461847\n",
      "Epoch: 71, Loss (standarized): 0.38547109806901425\n",
      "          Validation Loss (standardized): 0.42628896584618015\n",
      "Epoch: 76, Loss (standarized): 0.38000734554131566\n",
      "          Validation Loss (standardized): 0.41865352542421536\n",
      "Epoch: 81, Loss (standarized): 0.37382275424504685\n",
      "          Validation Loss (standardized): 0.418285777791658\n",
      "Epoch: 86, Loss (standarized): 0.368190291310741\n",
      "          Validation Loss (standardized): 0.41561352073640934\n",
      "Epoch: 91, Loss (standarized): 0.3633360003979605\n",
      "          Validation Loss (standardized): 0.41417560980437523\n",
      "Epoch: 96, Loss (standarized): 0.358773444007072\n",
      "          Validation Loss (standardized): 0.40883389918595237\n",
      "Final epoch: 100, Final loss (standarized): 0.35544087820957637\n",
      "Epoch: 1, Loss (standarized): 0.850356790532835\n",
      "          Validation Loss (standardized): 0.8057385575481121\n",
      "Epoch: 6, Loss (standarized): 0.6900726466896113\n",
      "          Validation Loss (standardized): 0.7392590754779803\n",
      "Epoch: 11, Loss (standarized): 0.5636810666173776\n",
      "          Validation Loss (standardized): 0.5435602457919595\n",
      "Epoch: 16, Loss (standarized): 0.48659744073943856\n",
      "          Validation Loss (standardized): 0.5419987663612722\n",
      "Epoch: 21, Loss (standarized): 0.4504407195944543\n",
      "          Validation Loss (standardized): 0.514864558090939\n",
      "Epoch: 26, Loss (standarized): 0.4354349296259345\n",
      "          Validation Loss (standardized): 0.501159712765553\n",
      "Epoch: 31, Loss (standarized): 0.4286131316797304\n",
      "          Validation Loss (standardized): 0.5236699241381852\n",
      "Epoch: 36, Loss (standarized): 0.41701849020375226\n",
      "          Validation Loss (standardized): 0.4827471964460912\n",
      "Epoch: 41, Loss (standarized): 0.4090636309011625\n",
      "          Validation Loss (standardized): 0.49310742317379214\n",
      "Epoch: 46, Loss (standarized): 0.40097288589535723\n",
      "          Validation Loss (standardized): 0.47705430179557573\n",
      "Epoch: 51, Loss (standarized): 0.3926316039951813\n",
      "          Validation Loss (standardized): 0.4646674954087344\n",
      "Epoch: 56, Loss (standarized): 0.3883698575595967\n",
      "          Validation Loss (standardized): 0.4673556476708383\n",
      "Epoch: 61, Loss (standarized): 0.3825475534298765\n",
      "          Validation Loss (standardized): 0.45438209552261294\n",
      "Epoch: 66, Loss (standarized): 0.37603837261564205\n",
      "          Validation Loss (standardized): 0.4439569090592195\n",
      "Epoch: 71, Loss (standarized): 0.3684446014955231\n",
      "          Validation Loss (standardized): 0.4360828493745853\n",
      "Epoch: 76, Loss (standarized): 0.360336886396439\n",
      "          Validation Loss (standardized): 0.42737706990293417\n",
      "Epoch: 81, Loss (standarized): 0.35121208283880934\n",
      "          Validation Loss (standardized): 0.41421936915334384\n",
      "Epoch: 86, Loss (standarized): 0.3409363403302562\n",
      "          Validation Loss (standardized): 0.40305789802034425\n",
      "Epoch: 91, Loss (standarized): 0.32969442688154016\n",
      "          Validation Loss (standardized): 0.3930353875697247\n",
      "Epoch: 96, Loss (standarized): 0.3176475734734683\n",
      "          Validation Loss (standardized): 0.3776753993682467\n",
      "Final epoch: 100, Final loss (standarized): 0.30735121488817707\n",
      "Epoch: 1, Loss (standarized): 1.7708853464698386\n",
      "          Validation Loss (standardized): 0.8584006678809384\n",
      "Epoch: 6, Loss (standarized): 0.8696797132037147\n",
      "          Validation Loss (standardized): 0.7865390724353337\n",
      "Epoch: 11, Loss (standarized): 0.7541037300711964\n",
      "          Validation Loss (standardized): 0.6663517275416393\n",
      "Epoch: 16, Loss (standarized): 0.61632749748231\n",
      "          Validation Loss (standardized): 0.7285347579805861\n",
      "Epoch: 21, Loss (standarized): 0.5396236645873269\n",
      "          Validation Loss (standardized): 0.5478800360722968\n",
      "Epoch: 26, Loss (standarized): 0.5206370654650819\n",
      "          Validation Loss (standardized): 0.5385141998580085\n",
      "Epoch: 31, Loss (standarized): 0.49684458968636475\n",
      "          Validation Loss (standardized): 0.5587473868900347\n",
      "Epoch: 36, Loss (standarized): 0.4697561964246423\n",
      "          Validation Loss (standardized): 0.4925244241529761\n",
      "Epoch: 41, Loss (standarized): 0.4510242157976182\n",
      "          Validation Loss (standardized): 0.5202365294768196\n",
      "Epoch: 46, Loss (standarized): 0.43642129362387455\n",
      "          Validation Loss (standardized): 0.4786294891381142\n",
      "Epoch: 51, Loss (standarized): 0.42426329431901416\n",
      "          Validation Loss (standardized): 0.48569322724023145\n",
      "Epoch: 56, Loss (standarized): 0.4131511887619803\n",
      "          Validation Loss (standardized): 0.4620505092834678\n",
      "Epoch: 61, Loss (standarized): 0.40124509541923564\n",
      "          Validation Loss (standardized): 0.4649001360972003\n",
      "Epoch: 66, Loss (standarized): 0.38898626264072644\n",
      "          Validation Loss (standardized): 0.44491593502232135\n",
      "Epoch: 71, Loss (standarized): 0.3768820611639535\n",
      "          Validation Loss (standardized): 0.43500867098647933\n",
      "Epoch: 76, Loss (standarized): 0.36605357680664835\n",
      "          Validation Loss (standardized): 0.41894534010358486\n",
      "Epoch: 81, Loss (standarized): 0.354469227262603\n",
      "          Validation Loss (standardized): 0.40861553577044746\n",
      "Epoch: 86, Loss (standarized): 0.34263162926444146\n",
      "          Validation Loss (standardized): 0.3950856303531519\n",
      "Epoch: 91, Loss (standarized): 0.32877453216357555\n",
      "          Validation Loss (standardized): 0.3853076040380202\n",
      "Epoch: 96, Loss (standarized): 0.31775394763979603\n",
      "          Validation Loss (standardized): 0.3660055687194278\n",
      "Final epoch: 100, Final loss (standarized): 0.3068304968682185\n",
      "Epoch: 1, Loss (standarized): 2.824084945254153\n",
      "          Validation Loss (standardized): 2.068522055413653\n",
      "Epoch: 6, Loss (standarized): 1.119277196939165\n",
      "          Validation Loss (standardized): 0.9275251002606555\n",
      "Epoch: 11, Loss (standarized): 0.7228504723706639\n",
      "          Validation Loss (standardized): 0.7429786206190083\n",
      "Epoch: 16, Loss (standarized): 0.6962294729276879\n",
      "          Validation Loss (standardized): 0.721662381930654\n",
      "Epoch: 21, Loss (standarized): 0.5499071032444898\n",
      "          Validation Loss (standardized): 0.5635173665442443\n",
      "Epoch: 26, Loss (standarized): 0.48524799231651555\n",
      "          Validation Loss (standardized): 0.49765146854213327\n",
      "Epoch: 31, Loss (standarized): 0.4340789892363738\n",
      "          Validation Loss (standardized): 0.4790488593289091\n",
      "Epoch: 36, Loss (standarized): 0.43167868457885283\n",
      "          Validation Loss (standardized): 0.4893564845604565\n",
      "Epoch: 41, Loss (standarized): 0.4112323776254212\n",
      "          Validation Loss (standardized): 0.4582663013442155\n",
      "Epoch: 46, Loss (standarized): 0.39826056567281565\n",
      "          Validation Loss (standardized): 0.43957166809218956\n",
      "Epoch: 51, Loss (standarized): 0.38040432140784664\n",
      "          Validation Loss (standardized): 0.42856723167953903\n",
      "Epoch: 56, Loss (standarized): 0.3707071854802006\n",
      "          Validation Loss (standardized): 0.4156885142581798\n",
      "Epoch: 61, Loss (standarized): 0.35578809273203965\n",
      "          Validation Loss (standardized): 0.4005099978084487\n",
      "Epoch: 66, Loss (standarized): 0.3423001040274385\n",
      "          Validation Loss (standardized): 0.38611422440709303\n",
      "Epoch: 71, Loss (standarized): 0.32712780070214936\n",
      "          Validation Loss (standardized): 0.36591602876769824\n",
      "Epoch: 76, Loss (standarized): 0.3116627311832791\n",
      "          Validation Loss (standardized): 0.3506712745463271\n",
      "Epoch: 81, Loss (standarized): 0.2939324003259808\n",
      "          Validation Loss (standardized): 0.3299907845819336\n",
      "Epoch: 86, Loss (standarized): 0.2749632206844216\n",
      "          Validation Loss (standardized): 0.3097763490838418\n",
      "Epoch: 91, Loss (standarized): 0.254937196036766\n",
      "          Validation Loss (standardized): 0.2907889931107542\n",
      "Epoch: 96, Loss (standarized): 0.2334535285501631\n",
      "          Validation Loss (standardized): 0.2671516948025974\n",
      "Final epoch: 100, Final loss (standarized): 0.21632885280764153\n",
      "Epoch: 1, Loss (standarized): 5.211408122325954\n",
      "          Validation Loss (standardized): 3.7947112411286947\n",
      "Epoch: 6, Loss (standarized): 0.8248225249470362\n",
      "          Validation Loss (standardized): 0.7263905571457502\n",
      "Epoch: 11, Loss (standarized): 1.114541504756374\n",
      "          Validation Loss (standardized): 1.0861804298107842\n",
      "Epoch: 16, Loss (standarized): 0.7532810323832905\n",
      "          Validation Loss (standardized): 0.6981074055737776\n",
      "Epoch: 21, Loss (standarized): 0.6300922615878786\n",
      "          Validation Loss (standardized): 0.7119522773439522\n",
      "Epoch: 26, Loss (standarized): 0.6556825083694724\n",
      "          Validation Loss (standardized): 0.699851755294687\n",
      "Epoch: 31, Loss (standarized): 0.5397785040789227\n",
      "          Validation Loss (standardized): 0.582419540237344\n",
      "Epoch: 36, Loss (standarized): 0.5370934004481088\n",
      "          Validation Loss (standardized): 0.5653829420358017\n",
      "Epoch: 41, Loss (standarized): 0.5130690991609544\n",
      "          Validation Loss (standardized): 0.5314510378060049\n",
      "Epoch: 46, Loss (standarized): 0.4872449176479966\n",
      "          Validation Loss (standardized): 0.5287837061845182\n",
      "Epoch: 51, Loss (standarized): 0.48001860785834616\n",
      "          Validation Loss (standardized): 0.5301387595038359\n",
      "Epoch: 56, Loss (standarized): 0.46355436121163074\n",
      "          Validation Loss (standardized): 0.5080093484474026\n",
      "Epoch: 61, Loss (standarized): 0.4554568230122129\n",
      "          Validation Loss (standardized): 0.49382187048818343\n",
      "Epoch: 66, Loss (standarized): 0.4473773141010692\n",
      "          Validation Loss (standardized): 0.487419168274465\n",
      "Epoch: 71, Loss (standarized): 0.4401855319977573\n",
      "          Validation Loss (standardized): 0.48428757185843124\n",
      "Epoch: 76, Loss (standarized): 0.43158163770814983\n",
      "          Validation Loss (standardized): 0.475428106379541\n",
      "Epoch: 81, Loss (standarized): 0.42113964344900634\n",
      "          Validation Loss (standardized): 0.4654720233412207\n",
      "Epoch: 86, Loss (standarized): 0.4083843492051864\n",
      "          Validation Loss (standardized): 0.45655481646557433\n",
      "Epoch: 91, Loss (standarized): 0.39418301728015137\n",
      "          Validation Loss (standardized): 0.4410163446879946\n",
      "Epoch: 96, Loss (standarized): 0.37925372043572253\n",
      "          Validation Loss (standardized): 0.4319558927965583\n",
      "Final epoch: 100, Final loss (standarized): 0.3691027125667799\n",
      "Epoch: 1, Loss (standarized): 3.152614951487517\n",
      "          Validation Loss (standardized): 2.0381813464806187\n",
      "Epoch: 6, Loss (standarized): 1.1312713119713669\n",
      "          Validation Loss (standardized): 1.0420811192985158\n",
      "Epoch: 11, Loss (standarized): 0.8035675427244344\n",
      "          Validation Loss (standardized): 0.8476614547617891\n",
      "Epoch: 16, Loss (standarized): 0.8083795434143812\n",
      "          Validation Loss (standardized): 0.8168309190753514\n",
      "Epoch: 21, Loss (standarized): 0.74610893907408\n",
      "          Validation Loss (standardized): 0.7227894205091835\n",
      "Epoch: 26, Loss (standarized): 0.6376127262180773\n",
      "          Validation Loss (standardized): 0.6414276133574865\n",
      "Epoch: 31, Loss (standarized): 0.5818140579845454\n",
      "          Validation Loss (standardized): 0.5838011629482872\n",
      "Epoch: 36, Loss (standarized): 0.5096069373078139\n",
      "          Validation Loss (standardized): 0.5136417725217339\n",
      "Epoch: 41, Loss (standarized): 0.45371184275286147\n",
      "          Validation Loss (standardized): 0.49230611011844116\n",
      "Epoch: 46, Loss (standarized): 0.42008244352823765\n",
      "          Validation Loss (standardized): 0.4518964965333359\n",
      "Epoch: 51, Loss (standarized): 0.4040185728051508\n",
      "          Validation Loss (standardized): 0.4502726834702882\n",
      "Epoch: 56, Loss (standarized): 0.39106603672112034\n",
      "          Validation Loss (standardized): 0.4300948972727436\n",
      "Epoch: 61, Loss (standarized): 0.37849070968882204\n",
      "          Validation Loss (standardized): 0.415746043024693\n",
      "Epoch: 66, Loss (standarized): 0.36816081054341815\n",
      "          Validation Loss (standardized): 0.40450183290764585\n",
      "Epoch: 71, Loss (standarized): 0.35951448107604767\n",
      "          Validation Loss (standardized): 0.39052558380038854\n",
      "Epoch: 76, Loss (standarized): 0.349724128949836\n",
      "          Validation Loss (standardized): 0.3788895808866367\n",
      "Epoch: 81, Loss (standarized): 0.34027198261742236\n",
      "          Validation Loss (standardized): 0.37460390087368867\n",
      "Epoch: 86, Loss (standarized): 0.3320074343592504\n",
      "          Validation Loss (standardized): 0.36985067786632053\n",
      "Epoch: 91, Loss (standarized): 0.32525749584961855\n",
      "          Validation Loss (standardized): 0.3635082595883883\n",
      "Epoch: 96, Loss (standarized): 0.31861338312007725\n",
      "          Validation Loss (standardized): 0.35568963371298745\n",
      "Final epoch: 100, Final loss (standarized): 0.3135325288524551\n",
      "Epoch: 1, Loss (standarized): 2.111108235194417\n",
      "          Validation Loss (standardized): 1.048108044319872\n",
      "Epoch: 6, Loss (standarized): 1.0971852544098568\n",
      "          Validation Loss (standardized): 1.1877087345666146\n",
      "Epoch: 11, Loss (standarized): 0.6593852809699261\n",
      "          Validation Loss (standardized): 0.6324149466445469\n",
      "Epoch: 16, Loss (standarized): 0.6722487205844926\n",
      "          Validation Loss (standardized): 0.5863885263980797\n",
      "Epoch: 21, Loss (standarized): 0.5186382559600294\n",
      "          Validation Loss (standardized): 0.5801302963017608\n",
      "Epoch: 26, Loss (standarized): 0.499368206847625\n",
      "          Validation Loss (standardized): 0.5117269416734892\n",
      "Epoch: 31, Loss (standarized): 0.46896174925658407\n",
      "          Validation Loss (standardized): 0.47526455096144743\n",
      "Epoch: 36, Loss (standarized): 0.45329203911296323\n",
      "          Validation Loss (standardized): 0.49222819169623305\n",
      "Epoch: 41, Loss (standarized): 0.43983917290587743\n",
      "          Validation Loss (standardized): 0.47387068906068663\n",
      "Epoch: 46, Loss (standarized): 0.4169557849727683\n",
      "          Validation Loss (standardized): 0.45068023036694876\n",
      "Epoch: 51, Loss (standarized): 0.39785054721415936\n",
      "          Validation Loss (standardized): 0.43854055173568945\n",
      "Epoch: 56, Loss (standarized): 0.3850090416329917\n",
      "          Validation Loss (standardized): 0.42110412636260436\n",
      "Epoch: 61, Loss (standarized): 0.36886850498532375\n",
      "          Validation Loss (standardized): 0.4132750369507475\n",
      "Epoch: 66, Loss (standarized): 0.3520918256742093\n",
      "          Validation Loss (standardized): 0.39878617984097126\n",
      "Epoch: 71, Loss (standarized): 0.33508082259591404\n",
      "          Validation Loss (standardized): 0.3797311406406935\n",
      "Epoch: 76, Loss (standarized): 0.3176223716729056\n",
      "          Validation Loss (standardized): 0.3675472522181049\n",
      "Epoch: 81, Loss (standarized): 0.30049941159956567\n",
      "          Validation Loss (standardized): 0.3549276128989983\n",
      "Epoch: 86, Loss (standarized): 0.28397504640752746\n",
      "          Validation Loss (standardized): 0.3405708429215605\n",
      "Epoch: 91, Loss (standarized): 0.2666816937440088\n",
      "          Validation Loss (standardized): 0.3225284036378165\n",
      "Epoch: 96, Loss (standarized): 0.2507892911510698\n",
      "          Validation Loss (standardized): 0.3065887268094059\n",
      "Final epoch: 100, Final loss (standarized): 0.23883360378939766\n",
      "Epoch: 1, Loss (standarized): 3.2888732237682596\n",
      "          Validation Loss (standardized): 2.3463940064929716\n",
      "Epoch: 6, Loss (standarized): 0.9013312516511698\n",
      "          Validation Loss (standardized): 0.7769007900085901\n",
      "Epoch: 11, Loss (standarized): 0.8170902486875502\n",
      "          Validation Loss (standardized): 0.9289391645897743\n",
      "Epoch: 16, Loss (standarized): 0.664547644570088\n",
      "          Validation Loss (standardized): 0.6796040543263265\n",
      "Epoch: 21, Loss (standarized): 0.49862520519103165\n",
      "          Validation Loss (standardized): 0.5399730363109455\n",
      "Epoch: 26, Loss (standarized): 0.49282932752007225\n",
      "          Validation Loss (standardized): 0.5310873392644917\n",
      "Epoch: 31, Loss (standarized): 0.4394625734391145\n",
      "          Validation Loss (standardized): 0.532713880471421\n",
      "Epoch: 36, Loss (standarized): 0.4425960260554976\n",
      "          Validation Loss (standardized): 0.527438923538512\n",
      "Epoch: 41, Loss (standarized): 0.41166982441426486\n",
      "          Validation Loss (standardized): 0.4747777250925625\n",
      "Epoch: 46, Loss (standarized): 0.4015899918108886\n",
      "          Validation Loss (standardized): 0.45581715109108933\n",
      "Epoch: 51, Loss (standarized): 0.385334659480023\n",
      "          Validation Loss (standardized): 0.4469266224871382\n",
      "Epoch: 56, Loss (standarized): 0.3727497635434849\n",
      "          Validation Loss (standardized): 0.4331899550239228\n",
      "Epoch: 61, Loss (standarized): 0.3571014089748087\n",
      "          Validation Loss (standardized): 0.4093735726171516\n",
      "Epoch: 66, Loss (standarized): 0.34068302861876315\n",
      "          Validation Loss (standardized): 0.386863855802316\n",
      "Epoch: 71, Loss (standarized): 0.32388893668438506\n",
      "          Validation Loss (standardized): 0.3702576537701853\n",
      "Epoch: 76, Loss (standarized): 0.3043166892995041\n",
      "          Validation Loss (standardized): 0.3532709758108017\n",
      "Epoch: 81, Loss (standarized): 0.2842037769918231\n",
      "          Validation Loss (standardized): 0.32937345635932647\n",
      "Epoch: 86, Loss (standarized): 0.26339271368521733\n",
      "          Validation Loss (standardized): 0.30602622370606697\n",
      "Epoch: 91, Loss (standarized): 0.2424697046438867\n",
      "          Validation Loss (standardized): 0.28229697049444974\n",
      "Epoch: 96, Loss (standarized): 0.22086807111701412\n",
      "          Validation Loss (standardized): 0.25957964894028246\n",
      "Final epoch: 100, Final loss (standarized): 0.2036315610354102\n",
      "Epoch: 1, Loss (standarized): 5.388830024233937\n",
      "          Validation Loss (standardized): 3.3320933948690707\n",
      "Epoch: 6, Loss (standarized): 1.433232558626874\n",
      "          Validation Loss (standardized): 1.1378611633025288\n",
      "Epoch: 11, Loss (standarized): 0.9877502148573107\n",
      "          Validation Loss (standardized): 1.0396007617988305\n",
      "Epoch: 16, Loss (standarized): 0.8775053192578351\n",
      "          Validation Loss (standardized): 0.9370329339492345\n",
      "Epoch: 21, Loss (standarized): 0.8124012806814406\n",
      "          Validation Loss (standardized): 0.8221906897422762\n",
      "Epoch: 26, Loss (standarized): 0.7712885322963015\n",
      "          Validation Loss (standardized): 0.7327074350455425\n",
      "Epoch: 31, Loss (standarized): 0.6966369094094491\n",
      "          Validation Loss (standardized): 0.6609452408926179\n",
      "Epoch: 36, Loss (standarized): 0.6157628523510102\n",
      "          Validation Loss (standardized): 0.6102746633415207\n",
      "Epoch: 41, Loss (standarized): 0.5490736041567138\n",
      "          Validation Loss (standardized): 0.5465590800127628\n",
      "Epoch: 46, Loss (standarized): 0.4860729529940622\n",
      "          Validation Loss (standardized): 0.49494045820573185\n",
      "Epoch: 51, Loss (standarized): 0.4316973130595036\n",
      "          Validation Loss (standardized): 0.44735957712135077\n",
      "Epoch: 56, Loss (standarized): 0.3997032874005694\n",
      "          Validation Loss (standardized): 0.43235986167713086\n",
      "Epoch: 61, Loss (standarized): 0.3873545657979364\n",
      "          Validation Loss (standardized): 0.42554173453386285\n",
      "Epoch: 66, Loss (standarized): 0.37979130710828723\n",
      "          Validation Loss (standardized): 0.4197634757115013\n",
      "Epoch: 71, Loss (standarized): 0.37343727168356916\n",
      "          Validation Loss (standardized): 0.41268354391100837\n",
      "Epoch: 76, Loss (standarized): 0.37068906127804074\n",
      "          Validation Loss (standardized): 0.4033215163069181\n",
      "Epoch: 81, Loss (standarized): 0.37023817888449895\n",
      "          Validation Loss (standardized): 0.4019194275259841\n",
      "Epoch: 86, Loss (standarized): 0.3686247192335075\n",
      "          Validation Loss (standardized): 0.400649546071909\n",
      "Epoch: 91, Loss (standarized): 0.366519689924597\n",
      "          Validation Loss (standardized): 0.3990143388757302\n",
      "Epoch: 96, Loss (standarized): 0.363756070644689\n",
      "          Validation Loss (standardized): 0.39907572973437383\n",
      "Final epoch: 100, Final loss (standarized): 0.3619285253701307\n",
      "Epoch: 1, Loss (standarized): 1.43378552139927\n",
      "          Validation Loss (standardized): 0.9774668118699985\n",
      "Epoch: 6, Loss (standarized): 0.7481494669459462\n",
      "          Validation Loss (standardized): 0.7167257918857567\n",
      "Epoch: 11, Loss (standarized): 0.6859995090962313\n",
      "          Validation Loss (standardized): 0.7028735423595353\n",
      "Epoch: 16, Loss (standarized): 0.6089167730766425\n",
      "          Validation Loss (standardized): 0.6697639439237966\n",
      "Epoch: 21, Loss (standarized): 0.5498050033511719\n",
      "          Validation Loss (standardized): 0.5482816270263998\n",
      "Epoch: 26, Loss (standarized): 0.4910203515422557\n",
      "          Validation Loss (standardized): 0.5679311037678629\n",
      "Epoch: 31, Loss (standarized): 0.4551769353964204\n",
      "          Validation Loss (standardized): 0.4958212925732752\n",
      "Epoch: 36, Loss (standarized): 0.4211837340274804\n",
      "          Validation Loss (standardized): 0.48726508834622445\n",
      "Epoch: 41, Loss (standarized): 0.40280802162615076\n",
      "          Validation Loss (standardized): 0.44328634958965885\n",
      "Epoch: 46, Loss (standarized): 0.3903343662425371\n",
      "          Validation Loss (standardized): 0.4467254315239636\n",
      "Epoch: 51, Loss (standarized): 0.3752060709675426\n",
      "          Validation Loss (standardized): 0.4130249891700867\n",
      "Epoch: 56, Loss (standarized): 0.3573615396912145\n",
      "          Validation Loss (standardized): 0.4027341593922224\n",
      "Epoch: 61, Loss (standarized): 0.34152228801197115\n",
      "          Validation Loss (standardized): 0.3860745938827581\n",
      "Epoch: 66, Loss (standarized): 0.32593984651275154\n",
      "          Validation Loss (standardized): 0.361882527748935\n",
      "Epoch: 71, Loss (standarized): 0.30784233419412155\n",
      "          Validation Loss (standardized): 0.3449640769016786\n",
      "Epoch: 76, Loss (standarized): 0.2907322722337239\n",
      "          Validation Loss (standardized): 0.3266464013463203\n",
      "Epoch: 81, Loss (standarized): 0.2738888292512204\n",
      "          Validation Loss (standardized): 0.30919565132225063\n",
      "Epoch: 86, Loss (standarized): 0.2580341228218277\n",
      "          Validation Loss (standardized): 0.2948741657794251\n",
      "Epoch: 91, Loss (standarized): 0.24360696299196705\n",
      "          Validation Loss (standardized): 0.2796980075780959\n",
      "Epoch: 96, Loss (standarized): 0.2293568934579473\n",
      "          Validation Loss (standardized): 0.26926249485302967\n",
      "Final epoch: 100, Final loss (standarized): 0.2187175274979231\n",
      "Epoch: 1, Loss (standarized): 1.80365728271289\n",
      "          Validation Loss (standardized): 1.5464137691676643\n",
      "Epoch: 6, Loss (standarized): 0.7431435617660114\n",
      "          Validation Loss (standardized): 0.7232338569926136\n",
      "Epoch: 11, Loss (standarized): 0.8001880435623185\n",
      "          Validation Loss (standardized): 0.6754701849185445\n",
      "Epoch: 16, Loss (standarized): 0.6125080385243858\n",
      "          Validation Loss (standardized): 0.6788243073390997\n",
      "Epoch: 21, Loss (standarized): 0.6303116002221338\n",
      "          Validation Loss (standardized): 0.7257649037362981\n",
      "Epoch: 26, Loss (standarized): 0.5527165689238129\n",
      "          Validation Loss (standardized): 0.5924050169686326\n",
      "Epoch: 31, Loss (standarized): 0.5216829321951527\n",
      "          Validation Loss (standardized): 0.5238776265216444\n",
      "Epoch: 36, Loss (standarized): 0.48385800378676364\n",
      "          Validation Loss (standardized): 0.4900009448455515\n",
      "Epoch: 41, Loss (standarized): 0.45259751240116064\n",
      "          Validation Loss (standardized): 0.5099149972038297\n",
      "Epoch: 46, Loss (standarized): 0.4321190084724115\n",
      "          Validation Loss (standardized): 0.4932875441819309\n",
      "Epoch: 51, Loss (standarized): 0.41186374340916554\n",
      "          Validation Loss (standardized): 0.4480074204221647\n",
      "Epoch: 56, Loss (standarized): 0.3958043886838432\n",
      "          Validation Loss (standardized): 0.4320535476331974\n",
      "Epoch: 61, Loss (standarized): 0.3711805022365905\n",
      "          Validation Loss (standardized): 0.4316085549741127\n",
      "Epoch: 66, Loss (standarized): 0.3609004386189179\n",
      "          Validation Loss (standardized): 0.4022920121141118\n",
      "Epoch: 71, Loss (standarized): 0.3475681999908309\n",
      "          Validation Loss (standardized): 0.39734994141598023\n",
      "Epoch: 76, Loss (standarized): 0.33792597096330795\n",
      "          Validation Loss (standardized): 0.39373510796720196\n",
      "Epoch: 81, Loss (standarized): 0.3279608101841705\n",
      "          Validation Loss (standardized): 0.3711333123625557\n",
      "Epoch: 86, Loss (standarized): 0.3155992688193859\n",
      "          Validation Loss (standardized): 0.358585910335478\n",
      "Epoch: 91, Loss (standarized): 0.30346076857625376\n",
      "          Validation Loss (standardized): 0.3507144522788497\n",
      "Epoch: 96, Loss (standarized): 0.2941719533846886\n",
      "          Validation Loss (standardized): 0.3398798545551472\n",
      "Final epoch: 100, Final loss (standarized): 0.2867125309030273\n",
      "Epoch: 1, Loss (standarized): 1.278966671796289\n",
      "          Validation Loss (standardized): 0.9475139855418214\n",
      "Epoch: 6, Loss (standarized): 0.8968519011272618\n",
      "          Validation Loss (standardized): 0.9317344926232235\n",
      "Epoch: 11, Loss (standarized): 0.6916101765571002\n",
      "          Validation Loss (standardized): 0.6730543837378994\n",
      "Epoch: 16, Loss (standarized): 0.661227235240091\n",
      "          Validation Loss (standardized): 0.5988001681301172\n",
      "Epoch: 21, Loss (standarized): 0.5845113241752503\n",
      "          Validation Loss (standardized): 0.6403587783991438\n",
      "Epoch: 26, Loss (standarized): 0.5492958293068709\n",
      "          Validation Loss (standardized): 0.5795295012521879\n",
      "Epoch: 31, Loss (standarized): 0.5227042027821113\n",
      "          Validation Loss (standardized): 0.5443983831969139\n",
      "Epoch: 36, Loss (standarized): 0.4980685869849724\n",
      "          Validation Loss (standardized): 0.5300239747526271\n",
      "Epoch: 41, Loss (standarized): 0.4825736140008384\n",
      "          Validation Loss (standardized): 0.5392927359411804\n",
      "Epoch: 46, Loss (standarized): 0.4708157139092079\n",
      "          Validation Loss (standardized): 0.5159822781885584\n",
      "Epoch: 51, Loss (standarized): 0.4633385280041704\n",
      "          Validation Loss (standardized): 0.5131555616702141\n",
      "Epoch: 56, Loss (standarized): 0.4557267475502318\n",
      "          Validation Loss (standardized): 0.5130256943982898\n",
      "Epoch: 61, Loss (standarized): 0.45166189791733047\n",
      "          Validation Loss (standardized): 0.504075600664833\n",
      "Epoch: 66, Loss (standarized): 0.44459143033443843\n",
      "          Validation Loss (standardized): 0.49881002245730316\n",
      "Epoch: 71, Loss (standarized): 0.4386550212083712\n",
      "          Validation Loss (standardized): 0.49349157500735985\n",
      "Epoch: 76, Loss (standarized): 0.43285851316538587\n",
      "          Validation Loss (standardized): 0.48666069216525437\n",
      "Epoch: 81, Loss (standarized): 0.42930634417753205\n",
      "          Validation Loss (standardized): 0.4825463460303976\n",
      "Epoch: 86, Loss (standarized): 0.42599701042034804\n",
      "          Validation Loss (standardized): 0.47975217688954075\n",
      "Epoch: 91, Loss (standarized): 0.4224887888765812\n",
      "          Validation Loss (standardized): 0.4739742127157629\n",
      "Epoch: 96, Loss (standarized): 0.41885623253419857\n",
      "          Validation Loss (standardized): 0.46910750804595236\n",
      "Final epoch: 100, Final loss (standarized): 0.4160638010351819\n",
      "Epoch: 1, Loss (standarized): 1.4702789963977672\n",
      "          Validation Loss (standardized): 0.8167186399985442\n",
      "Epoch: 6, Loss (standarized): 0.7582160072248018\n",
      "          Validation Loss (standardized): 0.6792461536365851\n",
      "Epoch: 11, Loss (standarized): 0.7079861228906216\n",
      "          Validation Loss (standardized): 0.6496963672378753\n",
      "Epoch: 16, Loss (standarized): 0.6011518405223807\n",
      "          Validation Loss (standardized): 0.6432599210373905\n",
      "Epoch: 21, Loss (standarized): 0.5242439928836665\n",
      "          Validation Loss (standardized): 0.516135805217526\n",
      "Epoch: 26, Loss (standarized): 0.503706447035588\n",
      "          Validation Loss (standardized): 0.5208450787840483\n",
      "Epoch: 31, Loss (standarized): 0.4903755483059399\n",
      "          Validation Loss (standardized): 0.4986542542225528\n",
      "Epoch: 36, Loss (standarized): 0.4666105436067719\n",
      "          Validation Loss (standardized): 0.473937035540807\n",
      "Epoch: 41, Loss (standarized): 0.4543763220236145\n",
      "          Validation Loss (standardized): 0.48092746345481624\n",
      "Epoch: 46, Loss (standarized): 0.44740424878953444\n",
      "          Validation Loss (standardized): 0.4556137253161197\n",
      "Epoch: 51, Loss (standarized): 0.4367577021092215\n",
      "          Validation Loss (standardized): 0.46096584335785523\n",
      "Epoch: 56, Loss (standarized): 0.431840152451192\n",
      "          Validation Loss (standardized): 0.4614994283920456\n",
      "Epoch: 61, Loss (standarized): 0.4258445635678032\n",
      "          Validation Loss (standardized): 0.4577270289331315\n",
      "Epoch: 66, Loss (standarized): 0.4203078932740718\n",
      "          Validation Loss (standardized): 0.45375517498084067\n",
      "Epoch: 71, Loss (standarized): 0.41536958691339343\n",
      "          Validation Loss (standardized): 0.4531273768587522\n",
      "Epoch: 76, Loss (standarized): 0.41047213205472655\n",
      "          Validation Loss (standardized): 0.448316403483077\n",
      "Epoch: 81, Loss (standarized): 0.4061841082129841\n",
      "          Validation Loss (standardized): 0.4414312024422117\n",
      "Epoch: 86, Loss (standarized): 0.4015153199800062\n",
      "          Validation Loss (standardized): 0.4337779152018226\n",
      "Epoch: 91, Loss (standarized): 0.3984635925418276\n",
      "          Validation Loss (standardized): 0.43480639699938195\n",
      "Epoch: 96, Loss (standarized): 0.39654989990996586\n",
      "          Validation Loss (standardized): 0.4327615663531214\n",
      "Final epoch: 100, Final loss (standarized): 0.39425912962462367\n",
      "Epoch: 1, Loss (standarized): 2.1356824430522487\n",
      "          Validation Loss (standardized): 1.35585349526433\n",
      "Epoch: 6, Loss (standarized): 0.8133526381511617\n",
      "          Validation Loss (standardized): 0.792759126492561\n",
      "Epoch: 11, Loss (standarized): 0.6899791030917577\n",
      "          Validation Loss (standardized): 0.6833198809309698\n",
      "Epoch: 16, Loss (standarized): 0.6169730462428195\n",
      "          Validation Loss (standardized): 0.6450709128427515\n",
      "Epoch: 21, Loss (standarized): 0.5612019261103113\n",
      "          Validation Loss (standardized): 0.5873809890478116\n",
      "Epoch: 26, Loss (standarized): 0.5177007096872808\n",
      "          Validation Loss (standardized): 0.5186832152489849\n",
      "Epoch: 31, Loss (standarized): 0.4792447536896093\n",
      "          Validation Loss (standardized): 0.5139232293833733\n",
      "Epoch: 36, Loss (standarized): 0.45770463630383296\n",
      "          Validation Loss (standardized): 0.49134478649431945\n",
      "Epoch: 41, Loss (standarized): 0.4479308862486068\n",
      "          Validation Loss (standardized): 0.4824437408115443\n",
      "Epoch: 46, Loss (standarized): 0.43835083654911033\n",
      "          Validation Loss (standardized): 0.4773637464854755\n",
      "Epoch: 51, Loss (standarized): 0.4316736241513146\n",
      "          Validation Loss (standardized): 0.4664294217540748\n",
      "Epoch: 56, Loss (standarized): 0.4265308481352667\n",
      "          Validation Loss (standardized): 0.4623326802165411\n",
      "Epoch: 61, Loss (standarized): 0.4216085827880812\n",
      "          Validation Loss (standardized): 0.45761071185817315\n",
      "Epoch: 66, Loss (standarized): 0.416392835976681\n",
      "          Validation Loss (standardized): 0.4544028071949643\n",
      "Epoch: 71, Loss (standarized): 0.4131638820712237\n",
      "          Validation Loss (standardized): 0.45163429226857477\n",
      "Epoch: 76, Loss (standarized): 0.4111349764689575\n",
      "          Validation Loss (standardized): 0.4464828604841098\n",
      "Epoch: 81, Loss (standarized): 0.40732055191585054\n",
      "          Validation Loss (standardized): 0.4455672403371129\n",
      "Epoch: 86, Loss (standarized): 0.40310225010070544\n",
      "          Validation Loss (standardized): 0.4414934738602828\n",
      "Epoch: 91, Loss (standarized): 0.4001283809961581\n",
      "          Validation Loss (standardized): 0.4408857756763297\n",
      "Epoch: 96, Loss (standarized): 0.3983008292039849\n",
      "          Validation Loss (standardized): 0.4375474345650442\n",
      "Final epoch: 100, Final loss (standarized): 0.39625011658242715\n",
      "Epoch: 1, Loss (standarized): 1.8065524844455134\n",
      "          Validation Loss (standardized): 1.0180677130580615\n",
      "Epoch: 6, Loss (standarized): 0.8790461626550841\n",
      "          Validation Loss (standardized): 0.9655273873338228\n",
      "Epoch: 11, Loss (standarized): 0.6348676798190925\n",
      "          Validation Loss (standardized): 0.6047685650024492\n",
      "Epoch: 16, Loss (standarized): 0.5867663947360614\n",
      "          Validation Loss (standardized): 0.5909712741788534\n",
      "Epoch: 21, Loss (standarized): 0.5002218606513953\n",
      "          Validation Loss (standardized): 0.5201770053879874\n",
      "Epoch: 26, Loss (standarized): 0.4645458022582689\n",
      "          Validation Loss (standardized): 0.4975042990021661\n",
      "Epoch: 31, Loss (standarized): 0.4438741273158316\n",
      "          Validation Loss (standardized): 0.49720975633899117\n",
      "Epoch: 36, Loss (standarized): 0.43073784088606343\n",
      "          Validation Loss (standardized): 0.4569962794788762\n",
      "Epoch: 41, Loss (standarized): 0.4227101310064339\n",
      "          Validation Loss (standardized): 0.46917429765259994\n",
      "Epoch: 46, Loss (standarized): 0.4142081971511925\n",
      "          Validation Loss (standardized): 0.4477668407805814\n",
      "Epoch: 51, Loss (standarized): 0.4084068410042274\n",
      "          Validation Loss (standardized): 0.45061515823004483\n",
      "Epoch: 56, Loss (standarized): 0.4041671264783286\n",
      "          Validation Loss (standardized): 0.43920368021271067\n",
      "Epoch: 61, Loss (standarized): 0.3987703321689118\n",
      "          Validation Loss (standardized): 0.43780542688761515\n",
      "Epoch: 66, Loss (standarized): 0.3942344641766576\n",
      "          Validation Loss (standardized): 0.4303465418838449\n",
      "Epoch: 71, Loss (standarized): 0.38995967759038164\n",
      "          Validation Loss (standardized): 0.4315422360273456\n",
      "Epoch: 76, Loss (standarized): 0.38626005600201924\n",
      "          Validation Loss (standardized): 0.42400731347247417\n",
      "Epoch: 81, Loss (standarized): 0.38291085575015027\n",
      "          Validation Loss (standardized): 0.4227001604316564\n",
      "Epoch: 86, Loss (standarized): 0.3804733513983999\n",
      "          Validation Loss (standardized): 0.42347638809149557\n",
      "Epoch: 91, Loss (standarized): 0.37726521267627666\n",
      "          Validation Loss (standardized): 0.41613987422593396\n",
      "Epoch: 96, Loss (standarized): 0.3750086377152111\n",
      "          Validation Loss (standardized): 0.41615744448249686\n",
      "Final epoch: 100, Final loss (standarized): 0.37339550072686484\n",
      "Epoch: 1, Loss (standarized): 5.109469335615538\n",
      "          Validation Loss (standardized): 3.275383194766759\n",
      "Epoch: 6, Loss (standarized): 0.9089073444949332\n",
      "          Validation Loss (standardized): 0.7769531345439966\n",
      "Epoch: 11, Loss (standarized): 1.1059137908388141\n",
      "          Validation Loss (standardized): 1.256805130544046\n",
      "Epoch: 16, Loss (standarized): 0.8057441209953643\n",
      "          Validation Loss (standardized): 0.757488046735794\n",
      "Epoch: 21, Loss (standarized): 0.6007671856094083\n",
      "          Validation Loss (standardized): 0.6521765593342459\n",
      "Epoch: 26, Loss (standarized): 0.589245676412431\n",
      "          Validation Loss (standardized): 0.5945734141688002\n",
      "Epoch: 31, Loss (standarized): 0.49808064019914866\n",
      "          Validation Loss (standardized): 0.5657669883641593\n",
      "Epoch: 36, Loss (standarized): 0.492482320911687\n",
      "          Validation Loss (standardized): 0.5754381363996489\n",
      "Epoch: 41, Loss (standarized): 0.47164125471183543\n",
      "          Validation Loss (standardized): 0.5454397553391346\n",
      "Epoch: 46, Loss (standarized): 0.45810664330101114\n",
      "          Validation Loss (standardized): 0.5235581387696555\n",
      "Epoch: 51, Loss (standarized): 0.44747731372826677\n",
      "          Validation Loss (standardized): 0.5161152205969775\n",
      "Epoch: 56, Loss (standarized): 0.43536658259650346\n",
      "          Validation Loss (standardized): 0.502589685396781\n",
      "Epoch: 61, Loss (standarized): 0.4281194599995983\n",
      "          Validation Loss (standardized): 0.49336850641105684\n",
      "Epoch: 66, Loss (standarized): 0.4187166742390264\n",
      "          Validation Loss (standardized): 0.47936701903972834\n",
      "Epoch: 71, Loss (standarized): 0.40903270294529753\n",
      "          Validation Loss (standardized): 0.46694830530418047\n",
      "Epoch: 76, Loss (standarized): 0.4007391151625299\n",
      "          Validation Loss (standardized): 0.45896331486707487\n",
      "Epoch: 81, Loss (standarized): 0.3940679264519091\n",
      "          Validation Loss (standardized): 0.45255507746971074\n",
      "Epoch: 86, Loss (standarized): 0.38748714899266584\n",
      "          Validation Loss (standardized): 0.44539923443036034\n",
      "Epoch: 91, Loss (standarized): 0.3806715496870142\n",
      "          Validation Loss (standardized): 0.4422402693239221\n",
      "Epoch: 96, Loss (standarized): 0.3738625706777236\n",
      "          Validation Loss (standardized): 0.4364535858605197\n",
      "Final epoch: 100, Final loss (standarized): 0.3682474729403478\n",
      "Epoch: 1, Loss (standarized): 2.124015768974117\n",
      "          Validation Loss (standardized): 1.2319090547235343\n",
      "Epoch: 6, Loss (standarized): 0.9760754147116042\n",
      "          Validation Loss (standardized): 1.131996163943355\n",
      "Epoch: 11, Loss (standarized): 0.7759535845106382\n",
      "          Validation Loss (standardized): 0.7883990291441654\n",
      "Epoch: 16, Loss (standarized): 0.7422783116093911\n",
      "          Validation Loss (standardized): 0.6907533219434631\n",
      "Epoch: 21, Loss (standarized): 0.632599970299311\n",
      "          Validation Loss (standardized): 0.6218607065531735\n",
      "Epoch: 26, Loss (standarized): 0.5769195899197445\n",
      "          Validation Loss (standardized): 0.6363499677374638\n",
      "Epoch: 31, Loss (standarized): 0.5298197041701973\n",
      "          Validation Loss (standardized): 0.5503656335902225\n",
      "Epoch: 36, Loss (standarized): 0.49869952678489343\n",
      "          Validation Loss (standardized): 0.5082709186802965\n",
      "Epoch: 41, Loss (standarized): 0.4620585388386848\n",
      "          Validation Loss (standardized): 0.5166390438702899\n",
      "Epoch: 46, Loss (standarized): 0.4414051774090814\n",
      "          Validation Loss (standardized): 0.49091409630816474\n",
      "Epoch: 51, Loss (standarized): 0.424261813811645\n",
      "          Validation Loss (standardized): 0.4659662340240125\n",
      "Epoch: 56, Loss (standarized): 0.4133758496410582\n",
      "          Validation Loss (standardized): 0.4705319692717744\n",
      "Epoch: 61, Loss (standarized): 0.40639145801364424\n",
      "          Validation Loss (standardized): 0.4514368926123995\n",
      "Epoch: 66, Loss (standarized): 0.4006865463189607\n",
      "          Validation Loss (standardized): 0.45408014422505055\n",
      "Epoch: 71, Loss (standarized): 0.3957775914668843\n",
      "          Validation Loss (standardized): 0.4494922066955158\n",
      "Epoch: 76, Loss (standarized): 0.39188223298370517\n",
      "          Validation Loss (standardized): 0.4465537647532223\n",
      "Epoch: 81, Loss (standarized): 0.3875581767818204\n",
      "          Validation Loss (standardized): 0.4430373529670778\n",
      "Epoch: 86, Loss (standarized): 0.3833357423703766\n",
      "          Validation Loss (standardized): 0.43925111622782986\n",
      "Epoch: 91, Loss (standarized): 0.3795800511379943\n",
      "          Validation Loss (standardized): 0.4365082627967958\n",
      "Epoch: 96, Loss (standarized): 0.3752964652984797\n",
      "          Validation Loss (standardized): 0.43306332838786\n",
      "Final epoch: 100, Final loss (standarized): 0.37189589300918263\n",
      "Epoch: 1, Loss (standarized): 6.585070689073983\n",
      "          Validation Loss (standardized): 5.382670115651401\n",
      "Epoch: 6, Loss (standarized): 0.8444563545685397\n",
      "          Validation Loss (standardized): 0.6858494528266283\n",
      "Epoch: 11, Loss (standarized): 1.2079150611071956\n",
      "          Validation Loss (standardized): 1.1277100499672852\n",
      "Epoch: 16, Loss (standarized): 0.982950979052039\n",
      "          Validation Loss (standardized): 0.7566005267018667\n",
      "Epoch: 21, Loss (standarized): 0.6373427217794768\n",
      "          Validation Loss (standardized): 0.6332599841450136\n",
      "Epoch: 26, Loss (standarized): 0.6631279170306147\n",
      "          Validation Loss (standardized): 0.795614994925055\n",
      "Epoch: 31, Loss (standarized): 0.624949524037764\n",
      "          Validation Loss (standardized): 0.6874768590689243\n",
      "Epoch: 36, Loss (standarized): 0.5503285291989732\n",
      "          Validation Loss (standardized): 0.5471405409144815\n",
      "Epoch: 41, Loss (standarized): 0.5348486225509461\n",
      "          Validation Loss (standardized): 0.5422997977920991\n",
      "Epoch: 46, Loss (standarized): 0.5041065508159243\n",
      "          Validation Loss (standardized): 0.5716187429177703\n",
      "Epoch: 51, Loss (standarized): 0.4769335921824359\n",
      "          Validation Loss (standardized): 0.5135847702955898\n",
      "Epoch: 56, Loss (standarized): 0.45661106324687195\n",
      "          Validation Loss (standardized): 0.49345345385751904\n",
      "Epoch: 61, Loss (standarized): 0.4383787047486388\n",
      "          Validation Loss (standardized): 0.5008442764535941\n",
      "Epoch: 66, Loss (standarized): 0.4260012103657235\n",
      "          Validation Loss (standardized): 0.47194834125208934\n",
      "Epoch: 71, Loss (standarized): 0.4132591643421037\n",
      "          Validation Loss (standardized): 0.4783753678553518\n",
      "Epoch: 76, Loss (standarized): 0.40530579952543616\n",
      "          Validation Loss (standardized): 0.46173485898029865\n",
      "Epoch: 81, Loss (standarized): 0.3988306687631068\n",
      "          Validation Loss (standardized): 0.4645238754937128\n",
      "Epoch: 86, Loss (standarized): 0.39303458283354054\n",
      "          Validation Loss (standardized): 0.4580917057731985\n",
      "Epoch: 91, Loss (standarized): 0.38796047865612737\n",
      "          Validation Loss (standardized): 0.45426042736273176\n",
      "Epoch: 96, Loss (standarized): 0.38376260812773033\n",
      "          Validation Loss (standardized): 0.4493205358942365\n",
      "Final epoch: 100, Final loss (standarized): 0.3802418786558698\n",
      "Epoch: 1, Loss (standarized): 3.8641965955743176\n",
      "          Validation Loss (standardized): 2.3762080504562224\n",
      "Epoch: 6, Loss (standarized): 1.1664825403069852\n",
      "          Validation Loss (standardized): 1.1134266109039612\n",
      "Epoch: 11, Loss (standarized): 0.8256001767237547\n",
      "          Validation Loss (standardized): 0.9195448708257133\n",
      "Epoch: 16, Loss (standarized): 0.8981582730353551\n",
      "          Validation Loss (standardized): 0.875838383728763\n",
      "Epoch: 21, Loss (standarized): 0.6894459075703059\n",
      "          Validation Loss (standardized): 0.6913253296518721\n",
      "Epoch: 26, Loss (standarized): 0.6320026614312015\n",
      "          Validation Loss (standardized): 0.6933588911791913\n",
      "Epoch: 31, Loss (standarized): 0.5964680019014578\n",
      "          Validation Loss (standardized): 0.5954989907902325\n",
      "Epoch: 36, Loss (standarized): 0.5349712919717605\n",
      "          Validation Loss (standardized): 0.5496457487204887\n",
      "Epoch: 41, Loss (standarized): 0.49471814608557396\n",
      "          Validation Loss (standardized): 0.5595298233022816\n",
      "Epoch: 46, Loss (standarized): 0.4599883523564047\n",
      "          Validation Loss (standardized): 0.49974147363595395\n",
      "Epoch: 51, Loss (standarized): 0.43639358120682326\n",
      "          Validation Loss (standardized): 0.5019439567730941\n",
      "Epoch: 56, Loss (standarized): 0.42728855027276735\n",
      "          Validation Loss (standardized): 0.48194542503254356\n",
      "Epoch: 61, Loss (standarized): 0.41833195715968907\n",
      "          Validation Loss (standardized): 0.481105266960654\n",
      "Epoch: 66, Loss (standarized): 0.4080167796487138\n",
      "          Validation Loss (standardized): 0.47323101166366455\n",
      "Epoch: 71, Loss (standarized): 0.39920702138419817\n",
      "          Validation Loss (standardized): 0.45951138643881023\n",
      "Epoch: 76, Loss (standarized): 0.3916494086950888\n",
      "          Validation Loss (standardized): 0.44492644717094343\n",
      "Epoch: 81, Loss (standarized): 0.38326356237589226\n",
      "          Validation Loss (standardized): 0.4362808978414467\n",
      "Epoch: 86, Loss (standarized): 0.37439547334771933\n",
      "          Validation Loss (standardized): 0.4274514873921158\n",
      "Epoch: 91, Loss (standarized): 0.3650126684761986\n",
      "          Validation Loss (standardized): 0.4195409558814006\n",
      "Epoch: 96, Loss (standarized): 0.35405508542066716\n",
      "          Validation Loss (standardized): 0.41155028125469983\n",
      "Final epoch: 100, Final loss (standarized): 0.3443712429210407\n",
      "Epoch: 1, Loss (standarized): 1.3993970899132548\n",
      "          Validation Loss (standardized): 1.0210330790706956\n",
      "Epoch: 6, Loss (standarized): 0.8728783761767118\n",
      "          Validation Loss (standardized): 0.779106624519006\n",
      "Epoch: 11, Loss (standarized): 0.6455356468754259\n",
      "          Validation Loss (standardized): 0.7453240023678152\n",
      "Epoch: 16, Loss (standarized): 0.6211910883585177\n",
      "          Validation Loss (standardized): 0.6412261063472116\n",
      "Epoch: 21, Loss (standarized): 0.564525346111262\n",
      "          Validation Loss (standardized): 0.5554061342746475\n",
      "Epoch: 26, Loss (standarized): 0.5212967534443277\n",
      "          Validation Loss (standardized): 0.5787219020789114\n",
      "Epoch: 31, Loss (standarized): 0.4892027945722403\n",
      "          Validation Loss (standardized): 0.5436492936943249\n",
      "Epoch: 36, Loss (standarized): 0.4676054957798092\n",
      "          Validation Loss (standardized): 0.48822706218108924\n",
      "Epoch: 41, Loss (standarized): 0.4383217523587687\n",
      "          Validation Loss (standardized): 0.5005177519467945\n",
      "Epoch: 46, Loss (standarized): 0.4196011618889702\n",
      "          Validation Loss (standardized): 0.47352967041154076\n",
      "Epoch: 51, Loss (standarized): 0.4052226404018356\n",
      "          Validation Loss (standardized): 0.45392497153167327\n",
      "Epoch: 56, Loss (standarized): 0.3923587184081375\n",
      "          Validation Loss (standardized): 0.45176136664006805\n",
      "Epoch: 61, Loss (standarized): 0.37890784906343017\n",
      "          Validation Loss (standardized): 0.42486518266877044\n",
      "Epoch: 66, Loss (standarized): 0.3632468918635977\n",
      "          Validation Loss (standardized): 0.4125538774609004\n",
      "Epoch: 71, Loss (standarized): 0.34670016728505615\n",
      "          Validation Loss (standardized): 0.392384328884534\n",
      "Epoch: 76, Loss (standarized): 0.3296688511483044\n",
      "          Validation Loss (standardized): 0.37586149746382175\n",
      "Epoch: 81, Loss (standarized): 0.3136528432928937\n",
      "          Validation Loss (standardized): 0.3634327396641758\n",
      "Epoch: 86, Loss (standarized): 0.29979610523858025\n",
      "          Validation Loss (standardized): 0.3415340150828503\n",
      "Epoch: 91, Loss (standarized): 0.2857070453561556\n",
      "          Validation Loss (standardized): 0.32609487220823996\n",
      "Epoch: 96, Loss (standarized): 0.2724278025700625\n",
      "          Validation Loss (standardized): 0.3131768848979529\n",
      "Final epoch: 100, Final loss (standarized): 0.2616445458921278\n",
      "Epoch: 1, Loss (standarized): 1.4125749039009092\n",
      "          Validation Loss (standardized): 0.8206191797900476\n",
      "Epoch: 6, Loss (standarized): 0.8067763845879877\n",
      "          Validation Loss (standardized): 0.7174896541216457\n",
      "Epoch: 11, Loss (standarized): 0.6435804439705934\n",
      "          Validation Loss (standardized): 0.6905003622738406\n",
      "Epoch: 16, Loss (standarized): 0.5679407887680906\n",
      "          Validation Loss (standardized): 0.5304833438380987\n",
      "Epoch: 21, Loss (standarized): 0.5283964217653871\n",
      "          Validation Loss (standardized): 0.5717060085707689\n",
      "Epoch: 26, Loss (standarized): 0.46759326213627517\n",
      "          Validation Loss (standardized): 0.4844494771975791\n",
      "Epoch: 31, Loss (standarized): 0.44798076484676147\n",
      "          Validation Loss (standardized): 0.49558320592185157\n",
      "Epoch: 36, Loss (standarized): 0.42840585480507193\n",
      "          Validation Loss (standardized): 0.46082924664333297\n",
      "Epoch: 41, Loss (standarized): 0.41120703773561174\n",
      "          Validation Loss (standardized): 0.46401920507552047\n",
      "Epoch: 46, Loss (standarized): 0.4004670130296063\n",
      "          Validation Loss (standardized): 0.4476899599721459\n",
      "Epoch: 51, Loss (standarized): 0.3916788685759248\n",
      "          Validation Loss (standardized): 0.4447213234373201\n",
      "Epoch: 56, Loss (standarized): 0.3805905545528509\n",
      "          Validation Loss (standardized): 0.42958014532452304\n",
      "Epoch: 61, Loss (standarized): 0.37109391133580694\n",
      "          Validation Loss (standardized): 0.4300310902402666\n",
      "Epoch: 66, Loss (standarized): 0.364558414542592\n",
      "          Validation Loss (standardized): 0.41425836601657673\n",
      "Epoch: 71, Loss (standarized): 0.3596661873279075\n",
      "          Validation Loss (standardized): 0.416600134852418\n",
      "Epoch: 76, Loss (standarized): 0.354913048882762\n",
      "          Validation Loss (standardized): 0.41272470413717227\n",
      "Epoch: 81, Loss (standarized): 0.3505936509547802\n",
      "          Validation Loss (standardized): 0.4052769868337909\n",
      "Epoch: 86, Loss (standarized): 0.3470098975093586\n",
      "          Validation Loss (standardized): 0.40342358208275814\n",
      "Epoch: 91, Loss (standarized): 0.3430438180112051\n",
      "          Validation Loss (standardized): 0.39833092673299375\n",
      "Epoch: 96, Loss (standarized): 0.3394467959880716\n",
      "          Validation Loss (standardized): 0.3926899808751552\n",
      "Final epoch: 100, Final loss (standarized): 0.33612355603492944\n",
      "Epoch: 1, Loss (standarized): 5.196465231969741\n",
      "          Validation Loss (standardized): 3.9957060874783656\n",
      "Epoch: 6, Loss (standarized): 0.8783635929989295\n",
      "          Validation Loss (standardized): 0.732501855303664\n",
      "Epoch: 11, Loss (standarized): 1.0026790182442316\n",
      "          Validation Loss (standardized): 0.8445163684022444\n",
      "Epoch: 16, Loss (standarized): 0.9159026968373587\n",
      "          Validation Loss (standardized): 0.7413291063445382\n",
      "Epoch: 21, Loss (standarized): 0.6879447120187834\n",
      "          Validation Loss (standardized): 0.6767263558956239\n",
      "Epoch: 26, Loss (standarized): 0.6245977513815907\n",
      "          Validation Loss (standardized): 0.6759309340105947\n",
      "Epoch: 31, Loss (standarized): 0.5855209513620234\n",
      "          Validation Loss (standardized): 0.6003250375610182\n",
      "Epoch: 36, Loss (standarized): 0.5662674331513001\n",
      "          Validation Loss (standardized): 0.5641586681005044\n",
      "Epoch: 41, Loss (standarized): 0.5080387713172139\n",
      "          Validation Loss (standardized): 0.5393095293515651\n",
      "Epoch: 46, Loss (standarized): 0.45926788883705666\n",
      "          Validation Loss (standardized): 0.4647291970592765\n",
      "Epoch: 51, Loss (standarized): 0.4295784545156291\n",
      "          Validation Loss (standardized): 0.4516279230365871\n",
      "Epoch: 56, Loss (standarized): 0.41202959764516933\n",
      "          Validation Loss (standardized): 0.44293115996989185\n",
      "Epoch: 61, Loss (standarized): 0.40722795458160144\n",
      "          Validation Loss (standardized): 0.4408929637533887\n",
      "Epoch: 66, Loss (standarized): 0.4032763753424945\n",
      "          Validation Loss (standardized): 0.4387919542377331\n",
      "Epoch: 71, Loss (standarized): 0.3956603837967526\n",
      "          Validation Loss (standardized): 0.4303200193290184\n",
      "Epoch: 76, Loss (standarized): 0.38803098008216097\n",
      "          Validation Loss (standardized): 0.4198542177086199\n",
      "Epoch: 81, Loss (standarized): 0.3817151816843902\n",
      "          Validation Loss (standardized): 0.41491085177320897\n",
      "Epoch: 86, Loss (standarized): 0.3757039332663005\n",
      "          Validation Loss (standardized): 0.4053931339647086\n",
      "Epoch: 91, Loss (standarized): 0.3680737252277633\n",
      "          Validation Loss (standardized): 0.40113489664027285\n",
      "Epoch: 96, Loss (standarized): 0.35930613830080016\n",
      "          Validation Loss (standardized): 0.39116123761595617\n",
      "Final epoch: 100, Final loss (standarized): 0.3525868217834541\n",
      "Epoch: 1, Loss (standarized): 4.450296260776009\n",
      "          Validation Loss (standardized): 2.8127597120904007\n",
      "Epoch: 6, Loss (standarized): 0.823546237247206\n",
      "          Validation Loss (standardized): 0.7873060532321293\n",
      "Epoch: 11, Loss (standarized): 0.9485624265146008\n",
      "          Validation Loss (standardized): 1.0795776623235849\n",
      "Epoch: 16, Loss (standarized): 0.787276600489958\n",
      "          Validation Loss (standardized): 0.7767628343702779\n",
      "Epoch: 21, Loss (standarized): 0.5496376038995416\n",
      "          Validation Loss (standardized): 0.5806006178444483\n",
      "Epoch: 26, Loss (standarized): 0.5230221692297163\n",
      "          Validation Loss (standardized): 0.5237966336126391\n",
      "Epoch: 31, Loss (standarized): 0.4262116420679039\n",
      "          Validation Loss (standardized): 0.4792710200740295\n",
      "Epoch: 36, Loss (standarized): 0.4048741707073752\n",
      "          Validation Loss (standardized): 0.4718003449268008\n",
      "Epoch: 41, Loss (standarized): 0.3902222416552749\n",
      "          Validation Loss (standardized): 0.4538678780802401\n",
      "Epoch: 46, Loss (standarized): 0.37589999841469357\n",
      "          Validation Loss (standardized): 0.4206201226090364\n",
      "Epoch: 51, Loss (standarized): 0.3659419921632794\n",
      "          Validation Loss (standardized): 0.4082957260541049\n",
      "Epoch: 56, Loss (standarized): 0.358505416501699\n",
      "          Validation Loss (standardized): 0.397939439787463\n",
      "Epoch: 61, Loss (standarized): 0.3498988775567212\n",
      "          Validation Loss (standardized): 0.387508618652805\n",
      "Epoch: 66, Loss (standarized): 0.34202023124469927\n",
      "          Validation Loss (standardized): 0.3787258683134836\n",
      "Epoch: 71, Loss (standarized): 0.3341242905599301\n",
      "          Validation Loss (standardized): 0.3659676622309733\n",
      "Epoch: 76, Loss (standarized): 0.32275026064834955\n",
      "          Validation Loss (standardized): 0.35127834317222467\n",
      "Epoch: 81, Loss (standarized): 0.3067266680722156\n",
      "          Validation Loss (standardized): 0.3374320016913506\n",
      "Epoch: 86, Loss (standarized): 0.29130940183533627\n",
      "          Validation Loss (standardized): 0.3138044737360024\n",
      "Epoch: 91, Loss (standarized): 0.2686219623509438\n",
      "          Validation Loss (standardized): 0.2997323611488809\n",
      "Epoch: 96, Loss (standarized): 0.24415833656414768\n",
      "          Validation Loss (standardized): 0.282070357107343\n",
      "Final epoch: 100, Final loss (standarized): 0.22260109448679338\n",
      "Epoch: 1, Loss (standarized): 0.779439518880749\n",
      "Epoch: 6, Loss (standarized): 0.7217924211893143\n",
      "Epoch: 11, Loss (standarized): 0.656199468512477\n",
      "Epoch: 16, Loss (standarized): 0.5590555501307064\n",
      "Epoch: 21, Loss (standarized): 0.47010847816405743\n",
      "Epoch: 26, Loss (standarized): 0.4295488755051105\n",
      "Epoch: 31, Loss (standarized): 0.4222086388866625\n",
      "Epoch: 36, Loss (standarized): 0.39354433490714213\n",
      "Epoch: 41, Loss (standarized): 0.3741480219224817\n",
      "Epoch: 46, Loss (standarized): 0.35915950175186256\n",
      "Epoch: 51, Loss (standarized): 0.3415062725532057\n",
      "Epoch: 56, Loss (standarized): 0.3260192506514903\n",
      "Epoch: 61, Loss (standarized): 0.31304028807676776\n",
      "Epoch: 66, Loss (standarized): 0.30093059344317885\n",
      "Epoch: 71, Loss (standarized): 0.29093008389615316\n",
      "Epoch: 76, Loss (standarized): 0.2831715002285568\n",
      "Epoch: 81, Loss (standarized): 0.2775010987358776\n",
      "Epoch: 86, Loss (standarized): 0.27334308596045503\n",
      "Epoch: 91, Loss (standarized): 0.2709075278272949\n",
      "Epoch: 96, Loss (standarized): 0.27089715915007073\n",
      "Final epoch: 100, Final loss (standarized): 0.26719586804794415\n",
      "Epoch: 1, Loss (standarized): 3.841921222853921\n",
      "Epoch: 6, Loss (standarized): 1.0862230380163695\n",
      "Epoch: 11, Loss (standarized): 0.8766644116388754\n",
      "Epoch: 16, Loss (standarized): 0.8262858131876115\n",
      "Epoch: 21, Loss (standarized): 0.6255966130008439\n",
      "Epoch: 26, Loss (standarized): 0.5671786350881541\n",
      "Epoch: 31, Loss (standarized): 0.5487283831335541\n",
      "Epoch: 36, Loss (standarized): 0.49267298499049517\n",
      "Epoch: 41, Loss (standarized): 0.4600666453662356\n",
      "Epoch: 46, Loss (standarized): 0.4428585488359033\n",
      "Epoch: 51, Loss (standarized): 0.42124489190949077\n",
      "Epoch: 56, Loss (standarized): 0.40858082166204657\n",
      "Epoch: 61, Loss (standarized): 0.3972554959684137\n",
      "Epoch: 66, Loss (standarized): 0.38719938028368467\n",
      "Epoch: 71, Loss (standarized): 0.3792297254929495\n",
      "Epoch: 76, Loss (standarized): 0.3727965802505125\n",
      "Epoch: 81, Loss (standarized): 0.3669617266640947\n",
      "Epoch: 86, Loss (standarized): 0.36154028824534634\n",
      "Epoch: 91, Loss (standarized): 0.3567114646458635\n",
      "Epoch: 96, Loss (standarized): 0.35253848400148236\n",
      "Final epoch: 100, Final loss (standarized): 0.3488550495722196\n",
      "Epoch: 1, Loss (standarized): 2.0070374979846313\n",
      "Epoch: 6, Loss (standarized): 1.0530995258275408\n",
      "Epoch: 11, Loss (standarized): 0.7640052909280011\n",
      "Epoch: 16, Loss (standarized): 0.7930070764148145\n",
      "Epoch: 21, Loss (standarized): 0.6921145921546298\n",
      "Epoch: 26, Loss (standarized): 0.6605349752992501\n",
      "Epoch: 31, Loss (standarized): 0.5784269738163477\n",
      "Epoch: 36, Loss (standarized): 0.5109752022114037\n",
      "Epoch: 41, Loss (standarized): 0.45058768387428555\n",
      "Epoch: 46, Loss (standarized): 0.41247331383119956\n",
      "Epoch: 51, Loss (standarized): 0.3951907948230485\n",
      "Epoch: 56, Loss (standarized): 0.3799104354572845\n",
      "Epoch: 61, Loss (standarized): 0.3611044994127555\n",
      "Epoch: 66, Loss (standarized): 0.3493151049683486\n",
      "Epoch: 71, Loss (standarized): 0.338550705901234\n",
      "Epoch: 76, Loss (standarized): 0.3281745630670633\n",
      "Epoch: 81, Loss (standarized): 0.31971523095997245\n",
      "Epoch: 86, Loss (standarized): 0.3122704507281984\n",
      "Epoch: 91, Loss (standarized): 0.3055578578964147\n",
      "Epoch: 96, Loss (standarized): 0.3000305398634244\n",
      "Final epoch: 100, Final loss (standarized): 0.2960242928617066\n",
      "Epoch: 1, Loss (standarized): 2.00120237755369\n",
      "Epoch: 6, Loss (standarized): 0.7134075177235146\n",
      "Epoch: 11, Loss (standarized): 0.8059641028614125\n",
      "Epoch: 16, Loss (standarized): 0.6310076762709956\n",
      "Epoch: 21, Loss (standarized): 0.5790181141519207\n",
      "Epoch: 26, Loss (standarized): 0.5174702037461854\n",
      "Epoch: 31, Loss (standarized): 0.46942043522859206\n",
      "Epoch: 36, Loss (standarized): 0.4202281303029012\n",
      "Epoch: 41, Loss (standarized): 0.40276412882827506\n",
      "Epoch: 46, Loss (standarized): 0.393275697621894\n",
      "Epoch: 51, Loss (standarized): 0.37841114143257226\n",
      "Epoch: 56, Loss (standarized): 0.3663290301014814\n",
      "Epoch: 61, Loss (standarized): 0.35686248527481496\n",
      "Epoch: 66, Loss (standarized): 0.3471398202874794\n",
      "Epoch: 71, Loss (standarized): 0.33697445639649726\n",
      "Epoch: 76, Loss (standarized): 0.3251791305174175\n",
      "Epoch: 81, Loss (standarized): 0.31271840444937016\n",
      "Epoch: 86, Loss (standarized): 0.2989856010490119\n",
      "Epoch: 91, Loss (standarized): 0.28326287546245377\n",
      "Epoch: 96, Loss (standarized): 0.2673577248977705\n",
      "Final epoch: 100, Final loss (standarized): 0.2545618444098405\n",
      "Epoch: 1, Loss (standarized): 2.889425379953979\n",
      "Epoch: 6, Loss (standarized): 1.1119460688591114\n",
      "Epoch: 11, Loss (standarized): 0.7209074457421499\n",
      "Epoch: 16, Loss (standarized): 0.7178209577073538\n",
      "Epoch: 21, Loss (standarized): 0.5534624919772703\n",
      "Epoch: 26, Loss (standarized): 0.4912256042282005\n",
      "Epoch: 31, Loss (standarized): 0.4500763863806222\n",
      "Epoch: 36, Loss (standarized): 0.4204040490090131\n",
      "Epoch: 41, Loss (standarized): 0.41834388144508283\n",
      "Epoch: 46, Loss (standarized): 0.40692516934423606\n",
      "Epoch: 51, Loss (standarized): 0.40499570134743046\n",
      "Epoch: 56, Loss (standarized): 0.4039075677789932\n",
      "Epoch: 61, Loss (standarized): 0.40143944815750954\n",
      "Epoch: 66, Loss (standarized): 0.39980314598834205\n",
      "Epoch: 71, Loss (standarized): 0.3968498987277914\n",
      "Epoch: 76, Loss (standarized): 0.39321049417553305\n",
      "Epoch: 81, Loss (standarized): 0.39254446503961954\n",
      "Epoch: 86, Loss (standarized): 0.3906693287909303\n",
      "Epoch: 91, Loss (standarized): 0.3878896037407515\n",
      "Epoch: 96, Loss (standarized): 0.3848220258375122\n",
      "Final epoch: 100, Final loss (standarized): 0.3827342755204185\n",
      "Epoch: 1, Loss (standarized): 3.889271258127027\n",
      "Epoch: 6, Loss (standarized): 0.9959359873740283\n",
      "Epoch: 11, Loss (standarized): 0.9052275102328018\n",
      "Epoch: 16, Loss (standarized): 0.8405103733410797\n",
      "Epoch: 21, Loss (standarized): 0.6664640913471519\n",
      "Epoch: 26, Loss (standarized): 0.6265384757513062\n",
      "Epoch: 31, Loss (standarized): 0.6259271423740566\n",
      "Epoch: 36, Loss (standarized): 0.5743236000582772\n",
      "Epoch: 41, Loss (standarized): 0.543382392233166\n",
      "Epoch: 46, Loss (standarized): 0.5256824458249078\n",
      "Epoch: 51, Loss (standarized): 0.5095961676151415\n",
      "Epoch: 56, Loss (standarized): 0.4954778303558136\n",
      "Epoch: 61, Loss (standarized): 0.480417905078178\n",
      "Epoch: 66, Loss (standarized): 0.47024182486937177\n",
      "Epoch: 71, Loss (standarized): 0.4634274350994346\n",
      "Epoch: 76, Loss (standarized): 0.45888574540183125\n",
      "Epoch: 81, Loss (standarized): 0.4557080718308525\n",
      "Epoch: 86, Loss (standarized): 0.45120608173011334\n",
      "Epoch: 91, Loss (standarized): 0.4478555579275693\n",
      "Epoch: 96, Loss (standarized): 0.44613648498373254\n",
      "Final epoch: 100, Final loss (standarized): 0.4451247662852385\n",
      "Epoch: 1, Loss (standarized): 0.7877564140606281\n",
      "Epoch: 6, Loss (standarized): 0.7089012227484919\n",
      "Epoch: 11, Loss (standarized): 0.6573936136665324\n",
      "Epoch: 16, Loss (standarized): 0.6146331017735045\n",
      "Epoch: 21, Loss (standarized): 0.5728766594635241\n",
      "Epoch: 26, Loss (standarized): 0.5321146757672711\n",
      "Epoch: 31, Loss (standarized): 0.4983139758119527\n",
      "Epoch: 36, Loss (standarized): 0.4699493506959843\n",
      "Epoch: 41, Loss (standarized): 0.4530427096914272\n",
      "Epoch: 46, Loss (standarized): 0.4482772018067219\n",
      "Epoch: 51, Loss (standarized): 0.4422543785471499\n",
      "Epoch: 56, Loss (standarized): 0.4372840830181233\n",
      "Epoch: 61, Loss (standarized): 0.4360065427968468\n",
      "Epoch: 66, Loss (standarized): 0.43375537446889306\n",
      "Epoch: 71, Loss (standarized): 0.42825008409563337\n",
      "Epoch: 76, Loss (standarized): 0.42234488681236043\n",
      "Epoch: 81, Loss (standarized): 0.4145217869884146\n",
      "Epoch: 86, Loss (standarized): 0.4072155528211657\n",
      "Epoch: 91, Loss (standarized): 0.4026701170709105\n",
      "Epoch: 96, Loss (standarized): 0.397114189965991\n",
      "Final epoch: 100, Final loss (standarized): 0.39200696741709695\n",
      "Epoch: 1, Loss (standarized): 8.41917209029348\n",
      "Epoch: 6, Loss (standarized): 1.331245851649468\n",
      "Epoch: 11, Loss (standarized): 0.8321669378457559\n",
      "Epoch: 16, Loss (standarized): 1.2004244654291463\n",
      "Epoch: 21, Loss (standarized): 0.8675789780047687\n",
      "Epoch: 26, Loss (standarized): 0.6279628582844767\n",
      "Epoch: 31, Loss (standarized): 0.6426286000072736\n",
      "Epoch: 36, Loss (standarized): 0.6625179366433664\n",
      "Epoch: 41, Loss (standarized): 0.6120918901398744\n",
      "Epoch: 46, Loss (standarized): 0.5739141053550403\n",
      "Epoch: 51, Loss (standarized): 0.5657667233794829\n",
      "Epoch: 56, Loss (standarized): 0.5579872514024438\n",
      "Epoch: 61, Loss (standarized): 0.5412714423058214\n",
      "Epoch: 66, Loss (standarized): 0.5277102593934806\n",
      "Epoch: 71, Loss (standarized): 0.5178097341084291\n",
      "Epoch: 76, Loss (standarized): 0.5072915354066717\n",
      "Epoch: 81, Loss (standarized): 0.4976363659406128\n",
      "Epoch: 86, Loss (standarized): 0.4881273023739695\n",
      "Epoch: 91, Loss (standarized): 0.47916199534997383\n",
      "Epoch: 96, Loss (standarized): 0.47269090186726925\n",
      "Final epoch: 100, Final loss (standarized): 0.469315870808813\n",
      "Epoch: 1, Loss (standarized): 10.638982496539843\n",
      "Epoch: 6, Loss (standarized): 1.2402435915185726\n",
      "Epoch: 11, Loss (standarized): 1.9296568099478855\n",
      "Epoch: 16, Loss (standarized): 1.482502216485262\n",
      "Epoch: 21, Loss (standarized): 0.8329895884315107\n",
      "Epoch: 26, Loss (standarized): 0.9000169902898927\n",
      "Epoch: 31, Loss (standarized): 0.8760542896581726\n",
      "Epoch: 36, Loss (standarized): 0.7161700815969976\n",
      "Epoch: 41, Loss (standarized): 0.6734732210978558\n",
      "Epoch: 46, Loss (standarized): 0.6578874358811637\n",
      "Epoch: 51, Loss (standarized): 0.6038076993357875\n",
      "Epoch: 56, Loss (standarized): 0.5794370197074727\n",
      "Epoch: 61, Loss (standarized): 0.5643059538173847\n",
      "Epoch: 66, Loss (standarized): 0.5423950271774323\n",
      "Epoch: 71, Loss (standarized): 0.5276839589075022\n",
      "Epoch: 76, Loss (standarized): 0.5159621642230112\n",
      "Epoch: 81, Loss (standarized): 0.5033994719812478\n",
      "Epoch: 86, Loss (standarized): 0.49322579896482993\n",
      "Epoch: 91, Loss (standarized): 0.4840762966761806\n",
      "Epoch: 96, Loss (standarized): 0.47578273727894727\n",
      "Final epoch: 100, Final loss (standarized): 0.47000250248170394\n",
      "Epoch: 1, Loss (standarized): 8.673299032427227\n",
      "Epoch: 6, Loss (standarized): 1.219195567671436\n",
      "Epoch: 11, Loss (standarized): 1.4865399818933114\n",
      "Epoch: 16, Loss (standarized): 1.1878618020993872\n",
      "Epoch: 21, Loss (standarized): 0.8377225418256323\n",
      "Epoch: 26, Loss (standarized): 0.7910049956334093\n",
      "Epoch: 31, Loss (standarized): 0.7592780955315689\n",
      "Epoch: 36, Loss (standarized): 0.64947277325263\n",
      "Epoch: 41, Loss (standarized): 0.5731946527048358\n",
      "Epoch: 46, Loss (standarized): 0.5055183571500507\n",
      "Epoch: 51, Loss (standarized): 0.4531447698835752\n",
      "Epoch: 56, Loss (standarized): 0.4244141266104582\n",
      "Epoch: 61, Loss (standarized): 0.41729997948370734\n",
      "Epoch: 66, Loss (standarized): 0.4168066185259384\n",
      "Epoch: 71, Loss (standarized): 0.4118787538568083\n",
      "Epoch: 76, Loss (standarized): 0.4082927487707252\n",
      "Epoch: 81, Loss (standarized): 0.4063217345684619\n",
      "Epoch: 86, Loss (standarized): 0.40509709454297094\n",
      "Epoch: 91, Loss (standarized): 0.4026594184942024\n",
      "Epoch: 96, Loss (standarized): 0.3997632856233605\n",
      "Final epoch: 100, Final loss (standarized): 0.39767469106389386\n",
      "Epoch: 1, Loss (standarized): 1.2394121853899207\n",
      "Epoch: 6, Loss (standarized): 0.8147176713224888\n",
      "Epoch: 11, Loss (standarized): 0.7625773679514439\n",
      "Epoch: 16, Loss (standarized): 0.651679536597384\n",
      "Epoch: 21, Loss (standarized): 0.6069677621423885\n",
      "Epoch: 26, Loss (standarized): 0.5360945859291218\n",
      "Epoch: 31, Loss (standarized): 0.4864634278754549\n",
      "Epoch: 36, Loss (standarized): 0.4508946628254516\n",
      "Epoch: 41, Loss (standarized): 0.42948768111993985\n",
      "Epoch: 46, Loss (standarized): 0.4187107389985691\n",
      "Epoch: 51, Loss (standarized): 0.4056508427520805\n",
      "Epoch: 56, Loss (standarized): 0.3927721275267711\n",
      "Epoch: 61, Loss (standarized): 0.3797904349761832\n",
      "Epoch: 66, Loss (standarized): 0.37151208521365964\n",
      "Epoch: 71, Loss (standarized): 0.36354128896165455\n",
      "Epoch: 76, Loss (standarized): 0.353845506490816\n",
      "Epoch: 81, Loss (standarized): 0.34485341023911076\n",
      "Epoch: 86, Loss (standarized): 0.3377232639997255\n",
      "Epoch: 91, Loss (standarized): 0.3301171528431247\n",
      "Epoch: 96, Loss (standarized): 0.3221609652161014\n",
      "Final epoch: 100, Final loss (standarized): 0.31597698414053405\n",
      "Epoch: 1, Loss (standarized): 1.8602099651778243\n",
      "Epoch: 6, Loss (standarized): 0.8458976691599837\n",
      "Epoch: 11, Loss (standarized): 0.6719618295849287\n",
      "Epoch: 16, Loss (standarized): 0.5567585979939267\n",
      "Epoch: 21, Loss (standarized): 0.509289018560027\n",
      "Epoch: 26, Loss (standarized): 0.44959883131141964\n",
      "Epoch: 31, Loss (standarized): 0.4514683923921051\n",
      "Epoch: 36, Loss (standarized): 0.42821544313936216\n",
      "Epoch: 41, Loss (standarized): 0.419693602251182\n",
      "Epoch: 46, Loss (standarized): 0.40490865421174044\n",
      "Epoch: 51, Loss (standarized): 0.3942673852050535\n",
      "Epoch: 56, Loss (standarized): 0.3823584687056989\n",
      "Epoch: 61, Loss (standarized): 0.3715325779334049\n",
      "Epoch: 66, Loss (standarized): 0.3569364337089613\n",
      "Epoch: 71, Loss (standarized): 0.342106927068785\n",
      "Epoch: 76, Loss (standarized): 0.3237463143873467\n",
      "Epoch: 81, Loss (standarized): 0.30683689197024877\n",
      "Epoch: 86, Loss (standarized): 0.2918715777698607\n",
      "Epoch: 91, Loss (standarized): 0.27779246360873266\n",
      "Epoch: 96, Loss (standarized): 0.2649365673504266\n",
      "Final epoch: 100, Final loss (standarized): 0.2538139388409094\n",
      "Epoch: 1, Loss (standarized): 1.5171251263853358\n",
      "Epoch: 6, Loss (standarized): 0.7879440567224464\n",
      "Epoch: 11, Loss (standarized): 0.7073882804986839\n",
      "Epoch: 16, Loss (standarized): 0.5966054260737594\n",
      "Epoch: 21, Loss (standarized): 0.5036788358072103\n",
      "Epoch: 26, Loss (standarized): 0.4430173345070475\n",
      "Epoch: 31, Loss (standarized): 0.41451635147798926\n",
      "Epoch: 36, Loss (standarized): 0.4041493978667544\n",
      "Epoch: 41, Loss (standarized): 0.3942790499596327\n",
      "Epoch: 46, Loss (standarized): 0.383283668053865\n",
      "Epoch: 51, Loss (standarized): 0.37284239370201744\n",
      "Epoch: 56, Loss (standarized): 0.3625975908731338\n",
      "Epoch: 61, Loss (standarized): 0.35282461457146763\n",
      "Epoch: 66, Loss (standarized): 0.34532599811342296\n",
      "Epoch: 71, Loss (standarized): 0.33747254724879944\n",
      "Epoch: 76, Loss (standarized): 0.33064202023836653\n",
      "Epoch: 81, Loss (standarized): 0.32399835410572586\n",
      "Epoch: 86, Loss (standarized): 0.3172722155594935\n",
      "Epoch: 91, Loss (standarized): 0.31099920560032557\n",
      "Epoch: 96, Loss (standarized): 0.30492208049974556\n",
      "Final epoch: 100, Final loss (standarized): 0.3000954316598631\n",
      "Epoch: 1, Loss (standarized): 7.9198884151621884\n",
      "Epoch: 6, Loss (standarized): 1.239403573833745\n",
      "Epoch: 11, Loss (standarized): 1.0376389468183018\n",
      "Epoch: 16, Loss (standarized): 1.0222289990746993\n",
      "Epoch: 21, Loss (standarized): 0.6690925191548001\n",
      "Epoch: 26, Loss (standarized): 0.5665790095894346\n",
      "Epoch: 31, Loss (standarized): 0.5661642484121534\n",
      "Epoch: 36, Loss (standarized): 0.5229749120947831\n",
      "Epoch: 41, Loss (standarized): 0.4717747694843413\n",
      "Epoch: 46, Loss (standarized): 0.43945285597493144\n",
      "Epoch: 51, Loss (standarized): 0.42358171337644446\n",
      "Epoch: 56, Loss (standarized): 0.4116662776575123\n",
      "Epoch: 61, Loss (standarized): 0.40070247547005183\n",
      "Epoch: 66, Loss (standarized): 0.3917443563726333\n",
      "Epoch: 71, Loss (standarized): 0.3839136755328401\n",
      "Epoch: 76, Loss (standarized): 0.3783322556329056\n",
      "Epoch: 81, Loss (standarized): 0.3738749072830602\n",
      "Epoch: 86, Loss (standarized): 0.37016151839236255\n",
      "Epoch: 91, Loss (standarized): 0.3666000523903218\n",
      "Epoch: 96, Loss (standarized): 0.3638596060607052\n",
      "Final epoch: 100, Final loss (standarized): 0.3617151337860136\n",
      "Epoch: 1, Loss (standarized): 7.674244056009149\n",
      "Epoch: 6, Loss (standarized): 0.7953560994810397\n",
      "Epoch: 11, Loss (standarized): 1.4948157549640106\n",
      "Epoch: 16, Loss (standarized): 0.7452045284353794\n",
      "Epoch: 21, Loss (standarized): 0.6415702637470323\n",
      "Epoch: 26, Loss (standarized): 0.6500320417635577\n",
      "Epoch: 31, Loss (standarized): 0.5269377573558002\n",
      "Epoch: 36, Loss (standarized): 0.48177330348595004\n",
      "Epoch: 41, Loss (standarized): 0.46055665270744195\n",
      "Epoch: 46, Loss (standarized): 0.43725292800373267\n",
      "Epoch: 51, Loss (standarized): 0.4167580966593999\n",
      "Epoch: 56, Loss (standarized): 0.4051941280820127\n",
      "Epoch: 61, Loss (standarized): 0.39733477586680255\n",
      "Epoch: 66, Loss (standarized): 0.3896164451400318\n",
      "Epoch: 71, Loss (standarized): 0.38423282537024406\n",
      "Epoch: 76, Loss (standarized): 0.3779228613274454\n",
      "Epoch: 81, Loss (standarized): 0.3732930701897431\n",
      "Epoch: 86, Loss (standarized): 0.36836646469706885\n",
      "Epoch: 91, Loss (standarized): 0.3635931231356657\n",
      "Epoch: 96, Loss (standarized): 0.359040112590863\n",
      "Final epoch: 100, Final loss (standarized): 0.3555040942897435\n",
      "Epoch: 1, Loss (standarized): 1.9574070346297396\n",
      "Epoch: 6, Loss (standarized): 0.7434163624284811\n",
      "Epoch: 11, Loss (standarized): 0.8174032828283737\n",
      "Epoch: 16, Loss (standarized): 0.6273610290130434\n",
      "Epoch: 21, Loss (standarized): 0.6189607642787197\n",
      "Epoch: 26, Loss (standarized): 0.5196353081854256\n",
      "Epoch: 31, Loss (standarized): 0.4808139722981185\n",
      "Epoch: 36, Loss (standarized): 0.4242992874278616\n",
      "Epoch: 41, Loss (standarized): 0.40646532815449204\n",
      "Epoch: 46, Loss (standarized): 0.3858333707169494\n",
      "Epoch: 51, Loss (standarized): 0.37491494732445096\n",
      "Epoch: 56, Loss (standarized): 0.36539765900057286\n",
      "Epoch: 61, Loss (standarized): 0.3537098645392261\n",
      "Epoch: 66, Loss (standarized): 0.34362480836551323\n",
      "Epoch: 71, Loss (standarized): 0.32921301145199705\n",
      "Epoch: 76, Loss (standarized): 0.318447704745619\n",
      "Epoch: 81, Loss (standarized): 0.3057166786476057\n",
      "Epoch: 86, Loss (standarized): 0.29199691115794135\n",
      "Epoch: 91, Loss (standarized): 0.2776943965081416\n",
      "Epoch: 96, Loss (standarized): 0.263449197864298\n",
      "Final epoch: 100, Final loss (standarized): 0.25229091170175544\n",
      "Epoch: 1, Loss (standarized): 1.476275540434009\n",
      "          Validation Loss (standardized): 1.1295272798574236\n",
      "Epoch: 6, Loss (standarized): 0.6908207369783875\n",
      "          Validation Loss (standardized): 0.7146982255463206\n",
      "Epoch: 11, Loss (standarized): 0.6802876685810395\n",
      "          Validation Loss (standardized): 0.6093300203528291\n",
      "Epoch: 16, Loss (standarized): 0.5335521437531912\n",
      "          Validation Loss (standardized): 0.5414841945535023\n",
      "Epoch: 21, Loss (standarized): 0.47442121086149003\n",
      "          Validation Loss (standardized): 0.5139536184845257\n",
      "Epoch: 26, Loss (standarized): 0.45769617437217747\n",
      "          Validation Loss (standardized): 0.5002421928274035\n",
      "Epoch: 31, Loss (standarized): 0.4288637553227576\n",
      "          Validation Loss (standardized): 0.4792100193945801\n",
      "Epoch: 36, Loss (standarized): 0.41686493860387674\n",
      "          Validation Loss (standardized): 0.44452972212382874\n",
      "Epoch: 41, Loss (standarized): 0.4109611731516086\n",
      "          Validation Loss (standardized): 0.4534331951945336\n",
      "Epoch: 46, Loss (standarized): 0.40003445277285066\n",
      "          Validation Loss (standardized): 0.4442219968090032\n",
      "Epoch: 51, Loss (standarized): 0.39230412269920756\n",
      "          Validation Loss (standardized): 0.43032283560292733\n",
      "Epoch: 56, Loss (standarized): 0.3853265244133796\n",
      "          Validation Loss (standardized): 0.4252908939497603\n",
      "Epoch: 61, Loss (standarized): 0.3781049995517093\n",
      "          Validation Loss (standardized): 0.41879574219343424\n",
      "Epoch: 66, Loss (standarized): 0.3712151706313288\n",
      "          Validation Loss (standardized): 0.40921279192405224\n",
      "Epoch: 71, Loss (standarized): 0.3636830034067168\n",
      "          Validation Loss (standardized): 0.40203326165455133\n",
      "Epoch: 76, Loss (standarized): 0.3569090413445265\n",
      "          Validation Loss (standardized): 0.39904223349946344\n",
      "Epoch: 81, Loss (standarized): 0.35000638272436085\n",
      "          Validation Loss (standardized): 0.3917526794411534\n",
      "Epoch: 86, Loss (standarized): 0.34320144947216447\n",
      "          Validation Loss (standardized): 0.38264778322803833\n",
      "Epoch: 91, Loss (standarized): 0.3365266937327596\n",
      "          Validation Loss (standardized): 0.3753756199705559\n",
      "Epoch: 96, Loss (standarized): 0.32923238400491084\n",
      "          Validation Loss (standardized): 0.3702965298492647\n",
      "Final epoch: 100, Final loss (standarized): 0.32345989902040095\n",
      "Epoch: 1, Loss (standarized): 1.972991223804452\n",
      "          Validation Loss (standardized): 0.9946270641675222\n",
      "Epoch: 6, Loss (standarized): 1.0569478196748918\n",
      "          Validation Loss (standardized): 1.2112305686983031\n",
      "Epoch: 11, Loss (standarized): 0.7346451737791997\n",
      "          Validation Loss (standardized): 0.6941664036908958\n",
      "Epoch: 16, Loss (standarized): 0.7377682996656123\n",
      "          Validation Loss (standardized): 0.6678979741553468\n",
      "Epoch: 21, Loss (standarized): 0.6241769063990054\n",
      "          Validation Loss (standardized): 0.677337009452652\n",
      "Epoch: 26, Loss (standarized): 0.6017565219909217\n",
      "          Validation Loss (standardized): 0.6455527043102084\n",
      "Epoch: 31, Loss (standarized): 0.5441676011010989\n",
      "          Validation Loss (standardized): 0.5491771584579975\n",
      "Epoch: 36, Loss (standarized): 0.5221453469520199\n",
      "          Validation Loss (standardized): 0.5397613134943989\n",
      "Epoch: 41, Loss (standarized): 0.4886980477780124\n",
      "          Validation Loss (standardized): 0.539778011369495\n",
      "Epoch: 46, Loss (standarized): 0.46491021775157615\n",
      "          Validation Loss (standardized): 0.5017859978263854\n",
      "Epoch: 51, Loss (standarized): 0.44396063314345635\n",
      "          Validation Loss (standardized): 0.4778509627386787\n",
      "Epoch: 56, Loss (standarized): 0.42601437870115655\n",
      "          Validation Loss (standardized): 0.47412612231564766\n",
      "Epoch: 61, Loss (standarized): 0.4148030465872134\n",
      "          Validation Loss (standardized): 0.46389552930375705\n",
      "Epoch: 66, Loss (standarized): 0.40238363734879695\n",
      "          Validation Loss (standardized): 0.4455416821432766\n",
      "Epoch: 71, Loss (standarized): 0.3919706547400463\n",
      "          Validation Loss (standardized): 0.4416595555419084\n",
      "Epoch: 76, Loss (standarized): 0.3828900368528773\n",
      "          Validation Loss (standardized): 0.4343132910935421\n",
      "Epoch: 81, Loss (standarized): 0.37395253880799145\n",
      "          Validation Loss (standardized): 0.41901774058631275\n",
      "Epoch: 86, Loss (standarized): 0.36592594897935693\n",
      "          Validation Loss (standardized): 0.4189098221965015\n",
      "Epoch: 91, Loss (standarized): 0.3577742274850846\n",
      "          Validation Loss (standardized): 0.40750050845937935\n",
      "Epoch: 96, Loss (standarized): 0.3473866309326995\n",
      "          Validation Loss (standardized): 0.39630526669191096\n",
      "Final epoch: 100, Final loss (standarized): 0.33842571108495767\n",
      "Epoch: 1, Loss (standarized): 1.4703639805621251\n",
      "          Validation Loss (standardized): 1.039375238626008\n",
      "Epoch: 6, Loss (standarized): 0.7560025790694515\n",
      "          Validation Loss (standardized): 0.8448887729353417\n",
      "Epoch: 11, Loss (standarized): 0.7236961537841629\n",
      "          Validation Loss (standardized): 0.7302636405329237\n",
      "Epoch: 16, Loss (standarized): 0.574057958023173\n",
      "          Validation Loss (standardized): 0.6153160088022993\n",
      "Epoch: 21, Loss (standarized): 0.5210628566849067\n",
      "          Validation Loss (standardized): 0.5317125835965558\n",
      "Epoch: 26, Loss (standarized): 0.45859255555593526\n",
      "          Validation Loss (standardized): 0.5039036724682086\n",
      "Epoch: 31, Loss (standarized): 0.41784360302895973\n",
      "          Validation Loss (standardized): 0.4855935657349902\n",
      "Epoch: 36, Loss (standarized): 0.4121863147608472\n",
      "          Validation Loss (standardized): 0.46888348783146727\n",
      "Epoch: 41, Loss (standarized): 0.389430030771104\n",
      "          Validation Loss (standardized): 0.43267504988557504\n",
      "Epoch: 46, Loss (standarized): 0.3690550065408152\n",
      "          Validation Loss (standardized): 0.40003309707577195\n",
      "Epoch: 51, Loss (standarized): 0.3491668401578164\n",
      "          Validation Loss (standardized): 0.3821492439153345\n",
      "Epoch: 56, Loss (standarized): 0.3304409568428467\n",
      "          Validation Loss (standardized): 0.36640535243198785\n",
      "Epoch: 61, Loss (standarized): 0.31590617663205683\n",
      "          Validation Loss (standardized): 0.34712636249232487\n",
      "Epoch: 66, Loss (standarized): 0.3007962260735524\n",
      "          Validation Loss (standardized): 0.32799900169652674\n",
      "Epoch: 71, Loss (standarized): 0.28432591871149004\n",
      "          Validation Loss (standardized): 0.3115771660705961\n",
      "Epoch: 76, Loss (standarized): 0.26708790150604134\n",
      "          Validation Loss (standardized): 0.2959249271522149\n",
      "Epoch: 81, Loss (standarized): 0.24929574145677807\n",
      "          Validation Loss (standardized): 0.2814865779040222\n",
      "Epoch: 86, Loss (standarized): 0.23109648173369549\n",
      "          Validation Loss (standardized): 0.26559810243514453\n",
      "Epoch: 91, Loss (standarized): 0.212899283459317\n",
      "          Validation Loss (standardized): 0.2496208050551383\n",
      "Epoch: 96, Loss (standarized): 0.1953593664020971\n",
      "          Validation Loss (standardized): 0.23277571441045544\n",
      "Final epoch: 100, Final loss (standarized): 0.18129939946405774\n",
      "Epoch: 1, Loss (standarized): 1.6465401460073061\n",
      "          Validation Loss (standardized): 0.8903953363485998\n",
      "Epoch: 6, Loss (standarized): 0.9813928071397455\n",
      "          Validation Loss (standardized): 1.0624329067016471\n",
      "Epoch: 11, Loss (standarized): 0.7213568099101368\n",
      "          Validation Loss (standardized): 0.6815588727648609\n",
      "Epoch: 16, Loss (standarized): 0.6785069267835617\n",
      "          Validation Loss (standardized): 0.6404301682071926\n",
      "Epoch: 21, Loss (standarized): 0.6156697680569717\n",
      "          Validation Loss (standardized): 0.6978389221785178\n",
      "Epoch: 26, Loss (standarized): 0.5606120469683452\n",
      "          Validation Loss (standardized): 0.5800678412111222\n",
      "Epoch: 31, Loss (standarized): 0.5382346503458437\n",
      "          Validation Loss (standardized): 0.5355696035022544\n",
      "Epoch: 36, Loss (standarized): 0.5061884113849761\n",
      "          Validation Loss (standardized): 0.563565641182821\n",
      "Epoch: 41, Loss (standarized): 0.48217996933473045\n",
      "          Validation Loss (standardized): 0.5195926725444275\n",
      "Epoch: 46, Loss (standarized): 0.46739960177158596\n",
      "          Validation Loss (standardized): 0.498806410123758\n",
      "Epoch: 51, Loss (standarized): 0.45528432238165023\n",
      "          Validation Loss (standardized): 0.5130871806986479\n",
      "Epoch: 56, Loss (standarized): 0.4453979409122798\n",
      "          Validation Loss (standardized): 0.48598048754185785\n",
      "Epoch: 61, Loss (standarized): 0.43588967236213333\n",
      "          Validation Loss (standardized): 0.4910368996571083\n",
      "Epoch: 66, Loss (standarized): 0.42679753115623775\n",
      "          Validation Loss (standardized): 0.47631913154671657\n",
      "Epoch: 71, Loss (standarized): 0.41780656219555323\n",
      "          Validation Loss (standardized): 0.4733965738620036\n",
      "Epoch: 76, Loss (standarized): 0.4090385798109157\n",
      "          Validation Loss (standardized): 0.4631537035356862\n",
      "Epoch: 81, Loss (standarized): 0.400382809335886\n",
      "          Validation Loss (standardized): 0.45604450097445864\n",
      "Epoch: 86, Loss (standarized): 0.3919423411998693\n",
      "          Validation Loss (standardized): 0.44295854014409486\n",
      "Epoch: 91, Loss (standarized): 0.38344842766253007\n",
      "          Validation Loss (standardized): 0.4368375909047991\n",
      "Epoch: 96, Loss (standarized): 0.37505183614481774\n",
      "          Validation Loss (standardized): 0.4265040463048233\n",
      "Final epoch: 100, Final loss (standarized): 0.3680549512961503\n",
      "Epoch: 1, Loss (standarized): 1.2179993060168157\n",
      "          Validation Loss (standardized): 0.8169575646396205\n",
      "Epoch: 6, Loss (standarized): 0.8015914432355966\n",
      "          Validation Loss (standardized): 0.830176671785793\n",
      "Epoch: 11, Loss (standarized): 0.6729639215801395\n",
      "          Validation Loss (standardized): 0.6517457097499246\n",
      "Epoch: 16, Loss (standarized): 0.6184583223162902\n",
      "          Validation Loss (standardized): 0.6123780656157959\n",
      "Epoch: 21, Loss (standarized): 0.5837036764441026\n",
      "          Validation Loss (standardized): 0.6186113031316092\n",
      "Epoch: 26, Loss (standarized): 0.5429038599017876\n",
      "          Validation Loss (standardized): 0.5613358701770662\n",
      "Epoch: 31, Loss (standarized): 0.5150101094230981\n",
      "          Validation Loss (standardized): 0.532934758091183\n",
      "Epoch: 36, Loss (standarized): 0.4924318298794188\n",
      "          Validation Loss (standardized): 0.5309496531919722\n",
      "Epoch: 41, Loss (standarized): 0.4708087427143425\n",
      "          Validation Loss (standardized): 0.5047695795323388\n",
      "Epoch: 46, Loss (standarized): 0.4581493658421837\n",
      "          Validation Loss (standardized): 0.5009522447833792\n",
      "Epoch: 51, Loss (standarized): 0.44831781583997443\n",
      "          Validation Loss (standardized): 0.4886684135844601\n",
      "Epoch: 56, Loss (standarized): 0.43803226030345643\n",
      "          Validation Loss (standardized): 0.4765758212615917\n",
      "Epoch: 61, Loss (standarized): 0.42731359047516876\n",
      "          Validation Loss (standardized): 0.46713685776974573\n",
      "Epoch: 66, Loss (standarized): 0.4192239268881594\n",
      "          Validation Loss (standardized): 0.45618084455151403\n",
      "Epoch: 71, Loss (standarized): 0.4100935037769274\n",
      "          Validation Loss (standardized): 0.45068815214644503\n",
      "Epoch: 76, Loss (standarized): 0.40748903108864826\n",
      "          Validation Loss (standardized): 0.4452512591863851\n",
      "Epoch: 81, Loss (standarized): 0.4056788773630881\n",
      "          Validation Loss (standardized): 0.44351625454659677\n",
      "Epoch: 86, Loss (standarized): 0.40319517806840344\n",
      "          Validation Loss (standardized): 0.44251230126545793\n",
      "Epoch: 91, Loss (standarized): 0.4010596903705902\n",
      "          Validation Loss (standardized): 0.43887416959626935\n",
      "Epoch: 96, Loss (standarized): 0.3984185844717144\n",
      "          Validation Loss (standardized): 0.4388469853480892\n",
      "Final epoch: 100, Final loss (standarized): 0.39639261608147713\n",
      "Epoch: 1, Loss (standarized): 2.420113865941744\n",
      "          Validation Loss (standardized): 1.4038614543633594\n",
      "Epoch: 6, Loss (standarized): 1.1053764024396353\n",
      "          Validation Loss (standardized): 1.0379218594541788\n",
      "Epoch: 11, Loss (standarized): 0.8025045998864696\n",
      "          Validation Loss (standardized): 0.7735583611356113\n",
      "Epoch: 16, Loss (standarized): 0.7241089634529053\n",
      "          Validation Loss (standardized): 0.6672201135043625\n",
      "Epoch: 21, Loss (standarized): 0.7468190218801103\n",
      "          Validation Loss (standardized): 0.7305653396259463\n",
      "Epoch: 26, Loss (standarized): 0.6618755432395218\n",
      "          Validation Loss (standardized): 0.6371084270825597\n",
      "Epoch: 31, Loss (standarized): 0.6583889267376501\n",
      "          Validation Loss (standardized): 0.635663705887678\n",
      "Epoch: 36, Loss (standarized): 0.6307640150915463\n",
      "          Validation Loss (standardized): 0.654968498405278\n",
      "Epoch: 41, Loss (standarized): 0.6164061128859314\n",
      "          Validation Loss (standardized): 0.6294873588726247\n",
      "Epoch: 46, Loss (standarized): 0.6038173367176654\n",
      "          Validation Loss (standardized): 0.6055599131723219\n",
      "Epoch: 51, Loss (standarized): 0.5898142442822408\n",
      "          Validation Loss (standardized): 0.5974130791365745\n",
      "Epoch: 56, Loss (standarized): 0.5817565676278249\n",
      "          Validation Loss (standardized): 0.584913432145806\n",
      "Epoch: 61, Loss (standarized): 0.5714738554185683\n",
      "          Validation Loss (standardized): 0.5711341329077645\n",
      "Epoch: 66, Loss (standarized): 0.5607018136729224\n",
      "          Validation Loss (standardized): 0.5671178171470397\n",
      "Epoch: 71, Loss (standarized): 0.5526129955807464\n",
      "          Validation Loss (standardized): 0.5625260479169532\n",
      "Epoch: 76, Loss (standarized): 0.5455687108916187\n",
      "          Validation Loss (standardized): 0.5527250845287308\n",
      "Epoch: 81, Loss (standarized): 0.5397192577759077\n",
      "          Validation Loss (standardized): 0.547604820158989\n",
      "Epoch: 86, Loss (standarized): 0.5334917139382677\n",
      "          Validation Loss (standardized): 0.5437163252425024\n",
      "Epoch: 91, Loss (standarized): 0.5273130051422147\n",
      "          Validation Loss (standardized): 0.5389257808686521\n",
      "Epoch: 96, Loss (standarized): 0.5218065373948451\n",
      "          Validation Loss (standardized): 0.5338275583826847\n",
      "Final epoch: 100, Final loss (standarized): 0.5175493174420293\n",
      "Epoch: 1, Loss (standarized): 1.2077972324096948\n",
      "          Validation Loss (standardized): 0.7935689030227466\n",
      "Epoch: 6, Loss (standarized): 0.815697214676792\n",
      "          Validation Loss (standardized): 0.7726653567522752\n",
      "Epoch: 11, Loss (standarized): 0.7045048278158281\n",
      "          Validation Loss (standardized): 0.7232298205335251\n",
      "Epoch: 16, Loss (standarized): 0.6313608730919005\n",
      "          Validation Loss (standardized): 0.624288050188658\n",
      "Epoch: 21, Loss (standarized): 0.6191609092389301\n",
      "          Validation Loss (standardized): 0.6217637061984298\n",
      "Epoch: 26, Loss (standarized): 0.5721410076225298\n",
      "          Validation Loss (standardized): 0.5763001695988499\n",
      "Epoch: 31, Loss (standarized): 0.5452960861571625\n",
      "          Validation Loss (standardized): 0.5649388754307322\n",
      "Epoch: 36, Loss (standarized): 0.5245193700723074\n",
      "          Validation Loss (standardized): 0.5244627478944163\n",
      "Epoch: 41, Loss (standarized): 0.5007336565485542\n",
      "          Validation Loss (standardized): 0.5216055781085803\n",
      "Epoch: 46, Loss (standarized): 0.4874229021717008\n",
      "          Validation Loss (standardized): 0.502026189608322\n",
      "Epoch: 51, Loss (standarized): 0.4732613682504356\n",
      "          Validation Loss (standardized): 0.49289229547127283\n",
      "Epoch: 56, Loss (standarized): 0.46196337327373255\n",
      "          Validation Loss (standardized): 0.48697601695153686\n",
      "Epoch: 61, Loss (standarized): 0.4528239605348535\n",
      "          Validation Loss (standardized): 0.4815664515198229\n",
      "Epoch: 66, Loss (standarized): 0.4420918502738174\n",
      "          Validation Loss (standardized): 0.47009629417498544\n",
      "Epoch: 71, Loss (standarized): 0.43488089137019426\n",
      "          Validation Loss (standardized): 0.4670246552015371\n",
      "Epoch: 76, Loss (standarized): 0.42959236038780413\n",
      "          Validation Loss (standardized): 0.464008090124036\n",
      "Epoch: 81, Loss (standarized): 0.42288732145078944\n",
      "          Validation Loss (standardized): 0.45448409767903003\n",
      "Epoch: 86, Loss (standarized): 0.4145143813788506\n",
      "          Validation Loss (standardized): 0.44699344827008874\n",
      "Epoch: 91, Loss (standarized): 0.40868867118480967\n",
      "          Validation Loss (standardized): 0.4437641045572137\n",
      "Epoch: 96, Loss (standarized): 0.3994980325504896\n",
      "          Validation Loss (standardized): 0.4400077760405155\n",
      "Final epoch: 100, Final loss (standarized): 0.39308655994724206\n",
      "Epoch: 1, Loss (standarized): 2.0603218237266234\n",
      "          Validation Loss (standardized): 1.267696240717396\n",
      "Epoch: 6, Loss (standarized): 1.0312800214152964\n",
      "          Validation Loss (standardized): 1.085408396311003\n",
      "Epoch: 11, Loss (standarized): 0.7296622470690605\n",
      "          Validation Loss (standardized): 0.7411522418100422\n",
      "Epoch: 16, Loss (standarized): 0.7327006344410953\n",
      "          Validation Loss (standardized): 0.6846969469430871\n",
      "Epoch: 21, Loss (standarized): 0.6312710099871521\n",
      "          Validation Loss (standardized): 0.6602847209509899\n",
      "Epoch: 26, Loss (standarized): 0.607682723294707\n",
      "          Validation Loss (standardized): 0.6480395178297755\n",
      "Epoch: 31, Loss (standarized): 0.5589140651772848\n",
      "          Validation Loss (standardized): 0.5597415259814816\n",
      "Epoch: 36, Loss (standarized): 0.539877954368447\n",
      "          Validation Loss (standardized): 0.5328695446572795\n",
      "Epoch: 41, Loss (standarized): 0.5133961732043415\n",
      "          Validation Loss (standardized): 0.5361230907218758\n",
      "Epoch: 46, Loss (standarized): 0.49739269495768745\n",
      "          Validation Loss (standardized): 0.5186528958358889\n",
      "Epoch: 51, Loss (standarized): 0.48705078228772736\n",
      "          Validation Loss (standardized): 0.5025537130131298\n",
      "Epoch: 56, Loss (standarized): 0.4781308869280251\n",
      "          Validation Loss (standardized): 0.5065219104712151\n",
      "Epoch: 61, Loss (standarized): 0.47397795901041484\n",
      "          Validation Loss (standardized): 0.5035790887264042\n",
      "Epoch: 66, Loss (standarized): 0.4718502726589479\n",
      "          Validation Loss (standardized): 0.49527238827296494\n",
      "Epoch: 71, Loss (standarized): 0.46900278645130766\n",
      "          Validation Loss (standardized): 0.5015463435895573\n",
      "Epoch: 76, Loss (standarized): 0.46700326006338877\n",
      "          Validation Loss (standardized): 0.49833002623712275\n",
      "Epoch: 81, Loss (standarized): 0.4629647182270876\n",
      "          Validation Loss (standardized): 0.49473474879610635\n",
      "Epoch: 86, Loss (standarized): 0.457654325945105\n",
      "          Validation Loss (standardized): 0.48910999865628857\n",
      "Epoch: 91, Loss (standarized): 0.45311233085318425\n",
      "          Validation Loss (standardized): 0.4864809178631995\n",
      "Epoch: 96, Loss (standarized): 0.45074211398442543\n",
      "          Validation Loss (standardized): 0.48293302460594717\n",
      "Final epoch: 100, Final loss (standarized): 0.44816703310669476\n",
      "Epoch: 1, Loss (standarized): 1.3293347664349404\n",
      "          Validation Loss (standardized): 0.8749772810413876\n",
      "Epoch: 6, Loss (standarized): 0.8182038526104227\n",
      "          Validation Loss (standardized): 0.7726556925434193\n",
      "Epoch: 11, Loss (standarized): 0.6179760560969063\n",
      "          Validation Loss (standardized): 0.7016722239359217\n",
      "Epoch: 16, Loss (standarized): 0.522498459771325\n",
      "          Validation Loss (standardized): 0.5267657299876928\n",
      "Epoch: 21, Loss (standarized): 0.4911563495791721\n",
      "          Validation Loss (standardized): 0.5750329499899133\n",
      "Epoch: 26, Loss (standarized): 0.44138324293861986\n",
      "          Validation Loss (standardized): 0.4941656269731249\n",
      "Epoch: 31, Loss (standarized): 0.4360237643089676\n",
      "          Validation Loss (standardized): 0.47841787763677934\n",
      "Epoch: 36, Loss (standarized): 0.4257044834847271\n",
      "          Validation Loss (standardized): 0.49997318360406384\n",
      "Epoch: 41, Loss (standarized): 0.40607120018874643\n",
      "          Validation Loss (standardized): 0.46432377864688107\n",
      "Epoch: 46, Loss (standarized): 0.3955313693155754\n",
      "          Validation Loss (standardized): 0.44336392733266633\n",
      "Epoch: 51, Loss (standarized): 0.3841867093344794\n",
      "          Validation Loss (standardized): 0.43650430494424625\n",
      "Epoch: 56, Loss (standarized): 0.3737936588401742\n",
      "          Validation Loss (standardized): 0.42458334725041896\n",
      "Epoch: 61, Loss (standarized): 0.36541799257699303\n",
      "          Validation Loss (standardized): 0.41574234130455756\n",
      "Epoch: 66, Loss (standarized): 0.3567723747103357\n",
      "          Validation Loss (standardized): 0.4090508048758989\n",
      "Epoch: 71, Loss (standarized): 0.347083093322731\n",
      "          Validation Loss (standardized): 0.39459927883044726\n",
      "Epoch: 76, Loss (standarized): 0.3387577047414323\n",
      "          Validation Loss (standardized): 0.3845646794341111\n",
      "Epoch: 81, Loss (standarized): 0.3312468435954169\n",
      "          Validation Loss (standardized): 0.37363658166833064\n",
      "Epoch: 86, Loss (standarized): 0.32370058509813104\n",
      "          Validation Loss (standardized): 0.36238802987993063\n",
      "Epoch: 91, Loss (standarized): 0.3166263332835223\n",
      "          Validation Loss (standardized): 0.3551105731960152\n",
      "Epoch: 96, Loss (standarized): 0.3099066900749505\n",
      "          Validation Loss (standardized): 0.3480526686413613\n",
      "Final epoch: 100, Final loss (standarized): 0.3047716810245019\n",
      "Epoch: 1, Loss (standarized): 0.8911528267995275\n",
      "          Validation Loss (standardized): 0.8379887204090344\n",
      "Epoch: 6, Loss (standarized): 0.7022777497115028\n",
      "          Validation Loss (standardized): 0.6603122838500712\n",
      "Epoch: 11, Loss (standarized): 0.6149007492777232\n",
      "          Validation Loss (standardized): 0.6647822659988154\n",
      "Epoch: 16, Loss (standarized): 0.5474480645628088\n",
      "          Validation Loss (standardized): 0.5466432635550825\n",
      "Epoch: 21, Loss (standarized): 0.49843745920329524\n",
      "          Validation Loss (standardized): 0.5674643483677348\n",
      "Epoch: 26, Loss (standarized): 0.46725228687921094\n",
      "          Validation Loss (standardized): 0.5044342387429073\n",
      "Epoch: 31, Loss (standarized): 0.4482300430469731\n",
      "          Validation Loss (standardized): 0.524789956528533\n",
      "Epoch: 36, Loss (standarized): 0.4377478149412912\n",
      "          Validation Loss (standardized): 0.49424474995923745\n",
      "Epoch: 41, Loss (standarized): 0.42938006968199194\n",
      "          Validation Loss (standardized): 0.5065971824599158\n",
      "Epoch: 46, Loss (standarized): 0.4225878928321546\n",
      "          Validation Loss (standardized): 0.4925850625652459\n",
      "Epoch: 51, Loss (standarized): 0.41673755630207376\n",
      "          Validation Loss (standardized): 0.48681663416468324\n",
      "Epoch: 56, Loss (standarized): 0.41092631423571807\n",
      "          Validation Loss (standardized): 0.48088261801201737\n",
      "Epoch: 61, Loss (standarized): 0.40737362696470114\n",
      "          Validation Loss (standardized): 0.47094618504333113\n",
      "Epoch: 66, Loss (standarized): 0.4029947442232671\n",
      "          Validation Loss (standardized): 0.470006186504228\n",
      "Epoch: 71, Loss (standarized): 0.39636078995748736\n",
      "          Validation Loss (standardized): 0.4568864971759521\n",
      "Epoch: 76, Loss (standarized): 0.38781293386157917\n",
      "          Validation Loss (standardized): 0.44569016401172845\n",
      "Epoch: 81, Loss (standarized): 0.37812901921529896\n",
      "          Validation Loss (standardized): 0.43582066616224774\n",
      "Epoch: 86, Loss (standarized): 0.36861235695103856\n",
      "          Validation Loss (standardized): 0.4244489072133784\n",
      "Epoch: 91, Loss (standarized): 0.35822455155126975\n",
      "          Validation Loss (standardized): 0.4156311331839855\n",
      "Epoch: 96, Loss (standarized): 0.3484131539305323\n",
      "          Validation Loss (standardized): 0.3993482508482223\n",
      "Final epoch: 100, Final loss (standarized): 0.3412673918956052\n",
      "Epoch: 1, Loss (standarized): 10.219581692063281\n",
      "          Validation Loss (standardized): 6.72257032482185\n",
      "Epoch: 6, Loss (standarized): 1.7076134524352686\n",
      "          Validation Loss (standardized): 1.1503983025127622\n",
      "Epoch: 11, Loss (standarized): 0.7866389774662313\n",
      "          Validation Loss (standardized): 0.9496346953807787\n",
      "Epoch: 16, Loss (standarized): 1.074014022959203\n",
      "          Validation Loss (standardized): 1.1354949132826115\n",
      "Epoch: 21, Loss (standarized): 0.6826115543428017\n",
      "          Validation Loss (standardized): 0.6870984199988124\n",
      "Epoch: 26, Loss (standarized): 0.45666178207684316\n",
      "          Validation Loss (standardized): 0.4994653934033483\n",
      "Epoch: 31, Loss (standarized): 0.4981890350425001\n",
      "          Validation Loss (standardized): 0.5280175437158318\n",
      "Epoch: 36, Loss (standarized): 0.4565979804106804\n",
      "          Validation Loss (standardized): 0.4902267144843682\n",
      "Epoch: 41, Loss (standarized): 0.41179163181182654\n",
      "          Validation Loss (standardized): 0.4596605600577472\n",
      "Epoch: 46, Loss (standarized): 0.39845640695053186\n",
      "          Validation Loss (standardized): 0.4551031537173595\n",
      "Epoch: 51, Loss (standarized): 0.3958791437576594\n",
      "          Validation Loss (standardized): 0.4509022687645918\n",
      "Epoch: 56, Loss (standarized): 0.3890136221707918\n",
      "          Validation Loss (standardized): 0.43724268029207614\n",
      "Epoch: 61, Loss (standarized): 0.3827473936270848\n",
      "          Validation Loss (standardized): 0.42191267896752116\n",
      "Epoch: 66, Loss (standarized): 0.3792326597776684\n",
      "          Validation Loss (standardized): 0.4152912672899564\n",
      "Epoch: 71, Loss (standarized): 0.3756094701965254\n",
      "          Validation Loss (standardized): 0.41171139206168533\n",
      "Epoch: 76, Loss (standarized): 0.3714664853757543\n",
      "          Validation Loss (standardized): 0.4103795576137108\n",
      "Epoch: 81, Loss (standarized): 0.3667221383608993\n",
      "          Validation Loss (standardized): 0.4075208201486532\n",
      "Epoch: 86, Loss (standarized): 0.35965561365219384\n",
      "          Validation Loss (standardized): 0.4019331086421497\n",
      "Epoch: 91, Loss (standarized): 0.3583068049741324\n",
      "          Validation Loss (standardized): 0.40006892199945443\n",
      "Epoch: 96, Loss (standarized): 0.3556162275916056\n",
      "          Validation Loss (standardized): 0.399063722537838\n",
      "Final epoch: 100, Final loss (standarized): 0.35324721292380595\n",
      "Epoch: 1, Loss (standarized): 4.918548425395383\n",
      "          Validation Loss (standardized): 3.7036038116505363\n",
      "Epoch: 6, Loss (standarized): 0.9060410002475757\n",
      "          Validation Loss (standardized): 0.9882845156468082\n",
      "Epoch: 11, Loss (standarized): 0.9567938245022466\n",
      "          Validation Loss (standardized): 0.9139417743949565\n",
      "Epoch: 16, Loss (standarized): 0.8470453991279367\n",
      "          Validation Loss (standardized): 0.6973447223624458\n",
      "Epoch: 21, Loss (standarized): 0.6130495056167027\n",
      "          Validation Loss (standardized): 0.5828440150030677\n",
      "Epoch: 26, Loss (standarized): 0.5724381869190402\n",
      "          Validation Loss (standardized): 0.6603153529173528\n",
      "Epoch: 31, Loss (standarized): 0.565311673035543\n",
      "          Validation Loss (standardized): 0.6543137086471055\n",
      "Epoch: 36, Loss (standarized): 0.49582034831703525\n",
      "          Validation Loss (standardized): 0.5284976744394444\n",
      "Epoch: 41, Loss (standarized): 0.48125709707584574\n",
      "          Validation Loss (standardized): 0.4791683794943657\n",
      "Epoch: 46, Loss (standarized): 0.4493365825145692\n",
      "          Validation Loss (standardized): 0.4736860336495795\n",
      "Epoch: 51, Loss (standarized): 0.433537734050085\n",
      "          Validation Loss (standardized): 0.48522824482258736\n",
      "Epoch: 56, Loss (standarized): 0.4121500189826879\n",
      "          Validation Loss (standardized): 0.44522521166539314\n",
      "Epoch: 61, Loss (standarized): 0.40326547674382207\n",
      "          Validation Loss (standardized): 0.4341224211748403\n",
      "Epoch: 66, Loss (standarized): 0.39254883023205656\n",
      "          Validation Loss (standardized): 0.4484234747248461\n",
      "Epoch: 71, Loss (standarized): 0.3861778872091649\n",
      "          Validation Loss (standardized): 0.4400400082223424\n",
      "Epoch: 76, Loss (standarized): 0.3797310061035758\n",
      "          Validation Loss (standardized): 0.4220031990511022\n",
      "Epoch: 81, Loss (standarized): 0.3725572167833357\n",
      "          Validation Loss (standardized): 0.42141710957338785\n",
      "Epoch: 86, Loss (standarized): 0.36565513914615233\n",
      "          Validation Loss (standardized): 0.4144341398498325\n",
      "Epoch: 91, Loss (standarized): 0.35896950417149853\n",
      "          Validation Loss (standardized): 0.3998764861287026\n",
      "Epoch: 96, Loss (standarized): 0.3521760608567626\n",
      "          Validation Loss (standardized): 0.39646394305029387\n",
      "Final epoch: 100, Final loss (standarized): 0.34665635754469354\n",
      "Epoch: 1, Loss (standarized): 18.980757858746223\n",
      "          Validation Loss (standardized): 12.817291046332935\n",
      "Epoch: 6, Loss (standarized): 2.3629461545502073\n",
      "          Validation Loss (standardized): 1.331989077672985\n",
      "Epoch: 11, Loss (standarized): 1.3654550139989623\n",
      "          Validation Loss (standardized): 1.82232025092853\n",
      "Epoch: 16, Loss (standarized): 1.7389851019354396\n",
      "          Validation Loss (standardized): 2.036280023709347\n",
      "Epoch: 21, Loss (standarized): 1.207683568884784\n",
      "          Validation Loss (standardized): 1.229761758770942\n",
      "Epoch: 26, Loss (standarized): 0.838372447940625\n",
      "          Validation Loss (standardized): 0.8555299404133947\n",
      "Epoch: 31, Loss (standarized): 0.8662557630842466\n",
      "          Validation Loss (standardized): 0.7998275244640893\n",
      "Epoch: 36, Loss (standarized): 0.8464448677697731\n",
      "          Validation Loss (standardized): 0.7443101070591562\n",
      "Epoch: 41, Loss (standarized): 0.731140656117627\n",
      "          Validation Loss (standardized): 0.6861856487351992\n",
      "Epoch: 46, Loss (standarized): 0.6590403076809067\n",
      "          Validation Loss (standardized): 0.6770896680122965\n",
      "Epoch: 51, Loss (standarized): 0.6236221993107002\n",
      "          Validation Loss (standardized): 0.6572822001186579\n",
      "Epoch: 56, Loss (standarized): 0.5771577078077128\n",
      "          Validation Loss (standardized): 0.5844097538892731\n",
      "Epoch: 61, Loss (standarized): 0.5364301761562102\n",
      "          Validation Loss (standardized): 0.5299176101567045\n",
      "Epoch: 66, Loss (standarized): 0.487410267867413\n",
      "          Validation Loss (standardized): 0.49834801047112814\n",
      "Epoch: 71, Loss (standarized): 0.44315667856677143\n",
      "          Validation Loss (standardized): 0.46599031763417925\n",
      "Epoch: 76, Loss (standarized): 0.41667017296779096\n",
      "          Validation Loss (standardized): 0.43119662707600986\n",
      "Epoch: 81, Loss (standarized): 0.39856912577265025\n",
      "          Validation Loss (standardized): 0.4288812809745923\n",
      "Epoch: 86, Loss (standarized): 0.3880635277172898\n",
      "          Validation Loss (standardized): 0.41175152600837495\n",
      "Epoch: 91, Loss (standarized): 0.3785784420147579\n",
      "          Validation Loss (standardized): 0.40767222672144\n",
      "Epoch: 96, Loss (standarized): 0.36794948428862584\n",
      "          Validation Loss (standardized): 0.39298891206274056\n",
      "Final epoch: 100, Final loss (standarized): 0.3596757869581656\n",
      "Epoch: 1, Loss (standarized): 4.710769381238693\n",
      "          Validation Loss (standardized): 3.3500461479539614\n",
      "Epoch: 6, Loss (standarized): 0.734311013959015\n",
      "          Validation Loss (standardized): 0.8322728674819959\n",
      "Epoch: 11, Loss (standarized): 1.1443094589937128\n",
      "          Validation Loss (standardized): 0.9403517481667957\n",
      "Epoch: 16, Loss (standarized): 0.6345209404885528\n",
      "          Validation Loss (standardized): 0.6506361652313308\n",
      "Epoch: 21, Loss (standarized): 0.6676433963002311\n",
      "          Validation Loss (standardized): 0.8020074150325339\n",
      "Epoch: 26, Loss (standarized): 0.6204976009618314\n",
      "          Validation Loss (standardized): 0.6557401909491786\n",
      "Epoch: 31, Loss (standarized): 0.526262601492868\n",
      "          Validation Loss (standardized): 0.5051008461569334\n",
      "Epoch: 36, Loss (standarized): 0.4997719274393127\n",
      "          Validation Loss (standardized): 0.5041683603728958\n",
      "Epoch: 41, Loss (standarized): 0.4823710006885459\n",
      "          Validation Loss (standardized): 0.5210554827412168\n",
      "Epoch: 46, Loss (standarized): 0.4427096217173891\n",
      "          Validation Loss (standardized): 0.46732639257815095\n",
      "Epoch: 51, Loss (standarized): 0.4287484596144182\n",
      "          Validation Loss (standardized): 0.46329168714882885\n",
      "Epoch: 56, Loss (standarized): 0.4188106624783806\n",
      "          Validation Loss (standardized): 0.45370073488056684\n",
      "Epoch: 61, Loss (standarized): 0.40460760301086324\n",
      "          Validation Loss (standardized): 0.439698505184109\n",
      "Epoch: 66, Loss (standarized): 0.39733009198578834\n",
      "          Validation Loss (standardized): 0.4468424895587313\n",
      "Epoch: 71, Loss (standarized): 0.3916703162642331\n",
      "          Validation Loss (standardized): 0.436748845291448\n",
      "Epoch: 76, Loss (standarized): 0.3856619250411075\n",
      "          Validation Loss (standardized): 0.43155410084053997\n",
      "Epoch: 81, Loss (standarized): 0.3806933914078052\n",
      "          Validation Loss (standardized): 0.4274189415956206\n",
      "Epoch: 86, Loss (standarized): 0.37503981505736633\n",
      "          Validation Loss (standardized): 0.41960735897285517\n",
      "Epoch: 91, Loss (standarized): 0.36919065262162337\n",
      "          Validation Loss (standardized): 0.41680248326491987\n",
      "Epoch: 96, Loss (standarized): 0.36167743035710265\n",
      "          Validation Loss (standardized): 0.40807773409411024\n",
      "Final epoch: 100, Final loss (standarized): 0.35514217029961703\n",
      "Epoch: 1, Loss (standarized): 1.6190690328427906\n",
      "          Validation Loss (standardized): 0.9530834484846114\n",
      "Epoch: 6, Loss (standarized): 0.8854221301946549\n",
      "          Validation Loss (standardized): 0.6900622951180178\n",
      "Epoch: 11, Loss (standarized): 0.6649007091943243\n",
      "          Validation Loss (standardized): 0.7658174441604538\n",
      "Epoch: 16, Loss (standarized): 0.534368571384089\n",
      "          Validation Loss (standardized): 0.5621082899759989\n",
      "Epoch: 21, Loss (standarized): 0.5102224067698838\n",
      "          Validation Loss (standardized): 0.5322657133590856\n",
      "Epoch: 26, Loss (standarized): 0.49211355109322935\n",
      "          Validation Loss (standardized): 0.5570798992790472\n",
      "Epoch: 31, Loss (standarized): 0.4621390152982431\n",
      "          Validation Loss (standardized): 0.4991887730514178\n",
      "Epoch: 36, Loss (standarized): 0.44067342107537977\n",
      "          Validation Loss (standardized): 0.5136209626929977\n",
      "Epoch: 41, Loss (standarized): 0.4306101936779504\n",
      "          Validation Loss (standardized): 0.4806388059379703\n",
      "Epoch: 46, Loss (standarized): 0.42019322048280416\n",
      "          Validation Loss (standardized): 0.48299997119665894\n",
      "Epoch: 51, Loss (standarized): 0.4084356568172442\n",
      "          Validation Loss (standardized): 0.4691414607071181\n",
      "Epoch: 56, Loss (standarized): 0.3945558442702294\n",
      "          Validation Loss (standardized): 0.45530523756895136\n",
      "Epoch: 61, Loss (standarized): 0.37986975966953873\n",
      "          Validation Loss (standardized): 0.4379617523140408\n",
      "Epoch: 66, Loss (standarized): 0.36462454284894974\n",
      "          Validation Loss (standardized): 0.4173757759692665\n",
      "Epoch: 71, Loss (standarized): 0.3523430111395619\n",
      "          Validation Loss (standardized): 0.4016328959580287\n",
      "Epoch: 76, Loss (standarized): 0.34137191724358207\n",
      "          Validation Loss (standardized): 0.38811408384302887\n",
      "Epoch: 81, Loss (standarized): 0.3312403369568203\n",
      "          Validation Loss (standardized): 0.3751966594251545\n",
      "Epoch: 86, Loss (standarized): 0.32165944558226034\n",
      "          Validation Loss (standardized): 0.3639793457124352\n",
      "Epoch: 91, Loss (standarized): 0.3135134400389331\n",
      "          Validation Loss (standardized): 0.3549587671125516\n",
      "Epoch: 96, Loss (standarized): 0.305414221298557\n",
      "          Validation Loss (standardized): 0.34501958438725794\n",
      "Final epoch: 100, Final loss (standarized): 0.2992139773720503\n",
      "Epoch: 1, Loss (standarized): 0.998362810761277\n",
      "          Validation Loss (standardized): 0.750527638395908\n",
      "Epoch: 6, Loss (standarized): 0.7376652427410748\n",
      "          Validation Loss (standardized): 0.78693101841013\n",
      "Epoch: 11, Loss (standarized): 0.6123010796147588\n",
      "          Validation Loss (standardized): 0.6109932278663152\n",
      "Epoch: 16, Loss (standarized): 0.5517598785752222\n",
      "          Validation Loss (standardized): 0.5772163893104163\n",
      "Epoch: 21, Loss (standarized): 0.5059983342180356\n",
      "          Validation Loss (standardized): 0.5604015053577401\n",
      "Epoch: 26, Loss (standarized): 0.4530910050043905\n",
      "          Validation Loss (standardized): 0.4802668878568542\n",
      "Epoch: 31, Loss (standarized): 0.4326344990215253\n",
      "          Validation Loss (standardized): 0.46441558176750275\n",
      "Epoch: 36, Loss (standarized): 0.4013118760480302\n",
      "          Validation Loss (standardized): 0.45420342072064984\n",
      "Epoch: 41, Loss (standarized): 0.3663850961526492\n",
      "          Validation Loss (standardized): 0.4032556716756616\n",
      "Epoch: 46, Loss (standarized): 0.34701948000375143\n",
      "          Validation Loss (standardized): 0.3763720675506961\n",
      "Epoch: 51, Loss (standarized): 0.32972056679880124\n",
      "          Validation Loss (standardized): 0.35988428285477175\n",
      "Epoch: 56, Loss (standarized): 0.3169807178143144\n",
      "          Validation Loss (standardized): 0.3458351384820273\n",
      "Epoch: 61, Loss (standarized): 0.3075401521828195\n",
      "          Validation Loss (standardized): 0.3365273320929994\n",
      "Epoch: 66, Loss (standarized): 0.300478949801099\n",
      "          Validation Loss (standardized): 0.33321209809922747\n",
      "Epoch: 71, Loss (standarized): 0.2952484838561505\n",
      "          Validation Loss (standardized): 0.3315986001538057\n",
      "Epoch: 76, Loss (standarized): 0.2901331088218236\n",
      "          Validation Loss (standardized): 0.32747419781903475\n",
      "Epoch: 81, Loss (standarized): 0.2855648044530677\n",
      "          Validation Loss (standardized): 0.3241078779521308\n",
      "Epoch: 86, Loss (standarized): 0.28099423916492927\n",
      "          Validation Loss (standardized): 0.32046744997753435\n",
      "Epoch: 91, Loss (standarized): 0.27626929819632834\n",
      "          Validation Loss (standardized): 0.32191620720035957\n",
      "Epoch: 96, Loss (standarized): 0.2729732050681669\n",
      "          Validation Loss (standardized): 0.31773553520927006\n",
      "Final epoch: 100, Final loss (standarized): 0.26978451650362817\n",
      "Epoch: 1, Loss (standarized): 1.1076118605059078\n",
      "          Validation Loss (standardized): 0.8003765995388477\n",
      "Epoch: 6, Loss (standarized): 0.7820650476860059\n",
      "          Validation Loss (standardized): 0.7720820449812212\n",
      "Epoch: 11, Loss (standarized): 0.6575626768982075\n",
      "          Validation Loss (standardized): 0.6876742175361816\n",
      "Epoch: 16, Loss (standarized): 0.6040857097923823\n",
      "          Validation Loss (standardized): 0.6081479748295842\n",
      "Epoch: 21, Loss (standarized): 0.5572728156688068\n",
      "          Validation Loss (standardized): 0.5924511966977208\n",
      "Epoch: 26, Loss (standarized): 0.5109192628638836\n",
      "          Validation Loss (standardized): 0.5312027954527517\n",
      "Epoch: 31, Loss (standarized): 0.4744936063384758\n",
      "          Validation Loss (standardized): 0.4884054224190234\n",
      "Epoch: 36, Loss (standarized): 0.43922900475722526\n",
      "          Validation Loss (standardized): 0.47576274291717796\n",
      "Epoch: 41, Loss (standarized): 0.4132191561447236\n",
      "          Validation Loss (standardized): 0.46205572338794765\n",
      "Epoch: 46, Loss (standarized): 0.3945668563507927\n",
      "          Validation Loss (standardized): 0.4392398184804982\n",
      "Epoch: 51, Loss (standarized): 0.37327328414473526\n",
      "          Validation Loss (standardized): 0.42185008151464\n",
      "Epoch: 56, Loss (standarized): 0.3567476948487419\n",
      "          Validation Loss (standardized): 0.39816896538097346\n",
      "Epoch: 61, Loss (standarized): 0.3414707144926708\n",
      "          Validation Loss (standardized): 0.37892782960487154\n",
      "Epoch: 66, Loss (standarized): 0.32774456456772605\n",
      "          Validation Loss (standardized): 0.368544723438586\n",
      "Epoch: 71, Loss (standarized): 0.316541836438163\n",
      "          Validation Loss (standardized): 0.353189150205073\n",
      "Epoch: 76, Loss (standarized): 0.30634943723351926\n",
      "          Validation Loss (standardized): 0.34467711780837634\n",
      "Epoch: 81, Loss (standarized): 0.2978419923166906\n",
      "          Validation Loss (standardized): 0.33723896050417024\n",
      "Epoch: 86, Loss (standarized): 0.29020026920561126\n",
      "          Validation Loss (standardized): 0.3309334284729837\n",
      "Epoch: 91, Loss (standarized): 0.2841972907340594\n",
      "          Validation Loss (standardized): 0.3293614788232777\n",
      "Epoch: 96, Loss (standarized): 0.2794438777197814\n",
      "          Validation Loss (standardized): 0.3263378942118923\n",
      "Final epoch: 100, Final loss (standarized): 0.2765414466458495\n",
      "Epoch: 1, Loss (standarized): 5.129591096251287\n",
      "          Validation Loss (standardized): 2.962915566934579\n",
      "Epoch: 6, Loss (standarized): 0.958337686965867\n",
      "          Validation Loss (standardized): 1.2188858019419815\n",
      "Epoch: 11, Loss (standarized): 1.2045093197734016\n",
      "          Validation Loss (standardized): 1.0777323237650849\n",
      "Epoch: 16, Loss (standarized): 0.6616598753845787\n",
      "          Validation Loss (standardized): 0.7020122163083758\n",
      "Epoch: 21, Loss (standarized): 0.770101835301771\n",
      "          Validation Loss (standardized): 0.7293398917619446\n",
      "Epoch: 26, Loss (standarized): 0.6289101795248981\n",
      "          Validation Loss (standardized): 0.5917037591220935\n",
      "Epoch: 31, Loss (standarized): 0.5623135068459999\n",
      "          Validation Loss (standardized): 0.6079760316000491\n",
      "Epoch: 36, Loss (standarized): 0.5580710292682058\n",
      "          Validation Loss (standardized): 0.5784117087618693\n",
      "Epoch: 41, Loss (standarized): 0.5010709555366566\n",
      "          Validation Loss (standardized): 0.5104715557544073\n",
      "Epoch: 46, Loss (standarized): 0.4818633335769853\n",
      "          Validation Loss (standardized): 0.5030879065835843\n",
      "Epoch: 51, Loss (standarized): 0.4612410247456066\n",
      "          Validation Loss (standardized): 0.48279894252163197\n",
      "Epoch: 56, Loss (standarized): 0.43683404055360625\n",
      "          Validation Loss (standardized): 0.46235557074920197\n",
      "Epoch: 61, Loss (standarized): 0.4249097085415163\n",
      "          Validation Loss (standardized): 0.4585896620071422\n",
      "Epoch: 66, Loss (standarized): 0.41025572248053893\n",
      "          Validation Loss (standardized): 0.44496102521637726\n",
      "Epoch: 71, Loss (standarized): 0.39859290788426727\n",
      "          Validation Loss (standardized): 0.43024723106657276\n",
      "Epoch: 76, Loss (standarized): 0.3878784717318279\n",
      "          Validation Loss (standardized): 0.42648042435828887\n",
      "Epoch: 81, Loss (standarized): 0.3789888904935844\n",
      "          Validation Loss (standardized): 0.42264721590443477\n",
      "Epoch: 86, Loss (standarized): 0.3695815000144356\n",
      "          Validation Loss (standardized): 0.41187037100156404\n",
      "Epoch: 91, Loss (standarized): 0.3613019021653369\n",
      "          Validation Loss (standardized): 0.4024394781622416\n",
      "Epoch: 96, Loss (standarized): 0.35311464762501343\n",
      "          Validation Loss (standardized): 0.3988907699702731\n",
      "Final epoch: 100, Final loss (standarized): 0.34736772568730806\n",
      "Epoch: 1, Loss (standarized): 9.521469529617315\n",
      "          Validation Loss (standardized): 6.298720162901138\n",
      "Epoch: 6, Loss (standarized): 2.0453054374374062\n",
      "          Validation Loss (standardized): 1.2315009125495244\n",
      "Epoch: 11, Loss (standarized): 1.0196665186441323\n",
      "          Validation Loss (standardized): 1.3535237273748562\n",
      "Epoch: 16, Loss (standarized): 1.3398836438226869\n",
      "          Validation Loss (standardized): 1.2720147138983744\n",
      "Epoch: 21, Loss (standarized): 0.7124289814369391\n",
      "          Validation Loss (standardized): 0.6717246114855989\n",
      "Epoch: 26, Loss (standarized): 0.6182144072044555\n",
      "          Validation Loss (standardized): 0.6341040011355666\n",
      "Epoch: 31, Loss (standarized): 0.5898554679984903\n",
      "          Validation Loss (standardized): 0.5841016399641026\n",
      "Epoch: 36, Loss (standarized): 0.4649478013492834\n",
      "          Validation Loss (standardized): 0.5067381469574942\n",
      "Epoch: 41, Loss (standarized): 0.4361736891502366\n",
      "          Validation Loss (standardized): 0.5282888525625888\n",
      "Epoch: 46, Loss (standarized): 0.4446914654456002\n",
      "          Validation Loss (standardized): 0.5328895666626473\n",
      "Epoch: 51, Loss (standarized): 0.4250890346488694\n",
      "          Validation Loss (standardized): 0.497705690098657\n",
      "Epoch: 56, Loss (standarized): 0.41200892553152035\n",
      "          Validation Loss (standardized): 0.4748252632518433\n",
      "Epoch: 61, Loss (standarized): 0.40537839535524\n",
      "          Validation Loss (standardized): 0.4631749295294334\n",
      "Epoch: 66, Loss (standarized): 0.40102606265958174\n",
      "          Validation Loss (standardized): 0.461994310842648\n",
      "Epoch: 71, Loss (standarized): 0.39608281938233353\n",
      "          Validation Loss (standardized): 0.45973504653340386\n",
      "Epoch: 76, Loss (standarized): 0.39240295540021186\n",
      "          Validation Loss (standardized): 0.4543836662903999\n",
      "Epoch: 81, Loss (standarized): 0.3839518228929152\n",
      "          Validation Loss (standardized): 0.4455587664334488\n",
      "Epoch: 86, Loss (standarized): 0.38129023809192975\n",
      "          Validation Loss (standardized): 0.4405992367310998\n",
      "Epoch: 91, Loss (standarized): 0.3777144735889924\n",
      "          Validation Loss (standardized): 0.4358566539538338\n",
      "Epoch: 96, Loss (standarized): 0.37371168297952995\n",
      "          Validation Loss (standardized): 0.43098554619988877\n",
      "Final epoch: 100, Final loss (standarized): 0.37051760896395175\n",
      "Epoch: 1, Loss (standarized): 3.7074496064861022\n",
      "          Validation Loss (standardized): 2.6004717073783308\n",
      "Epoch: 6, Loss (standarized): 1.0529151918994928\n",
      "          Validation Loss (standardized): 0.9857437213559492\n",
      "Epoch: 11, Loss (standarized): 0.7935468808558409\n",
      "          Validation Loss (standardized): 0.6608351273109654\n",
      "Epoch: 16, Loss (standarized): 0.6894071615770293\n",
      "          Validation Loss (standardized): 0.8047057769183107\n",
      "Epoch: 21, Loss (standarized): 0.6803248161202375\n",
      "          Validation Loss (standardized): 0.7312987393468134\n",
      "Epoch: 26, Loss (standarized): 0.5992458364486766\n",
      "          Validation Loss (standardized): 0.5697936385004264\n",
      "Epoch: 31, Loss (standarized): 0.5886754525221075\n",
      "          Validation Loss (standardized): 0.5535770997016679\n",
      "Epoch: 36, Loss (standarized): 0.5468955946187652\n",
      "          Validation Loss (standardized): 0.5615502695476012\n",
      "Epoch: 41, Loss (standarized): 0.5199706289866796\n",
      "          Validation Loss (standardized): 0.5614587176391292\n",
      "Epoch: 46, Loss (standarized): 0.4916462546595882\n",
      "          Validation Loss (standardized): 0.5134880244938845\n",
      "Epoch: 51, Loss (standarized): 0.467714366401392\n",
      "          Validation Loss (standardized): 0.49186196273141675\n",
      "Epoch: 56, Loss (standarized): 0.4425521633082129\n",
      "          Validation Loss (standardized): 0.4832092218989984\n",
      "Epoch: 61, Loss (standarized): 0.4272490380970818\n",
      "          Validation Loss (standardized): 0.4841647881737152\n",
      "Epoch: 66, Loss (standarized): 0.4094367924844205\n",
      "          Validation Loss (standardized): 0.46951159000222814\n",
      "Epoch: 71, Loss (standarized): 0.39549657810351696\n",
      "          Validation Loss (standardized): 0.45030081909119135\n",
      "Epoch: 76, Loss (standarized): 0.38313589789245917\n",
      "          Validation Loss (standardized): 0.4472539070874484\n",
      "Epoch: 81, Loss (standarized): 0.37176384109840727\n",
      "          Validation Loss (standardized): 0.43360992507438695\n",
      "Epoch: 86, Loss (standarized): 0.36343561802735025\n",
      "          Validation Loss (standardized): 0.42093209104405493\n",
      "Epoch: 91, Loss (standarized): 0.35556105412007144\n",
      "          Validation Loss (standardized): 0.4159515664485221\n",
      "Epoch: 96, Loss (standarized): 0.34752794547862653\n",
      "          Validation Loss (standardized): 0.40005488870248485\n",
      "Final epoch: 100, Final loss (standarized): 0.3407740186475634\n",
      "Epoch: 1, Loss (standarized): 4.479543772939579\n",
      "          Validation Loss (standardized): 2.9478885500839174\n",
      "Epoch: 6, Loss (standarized): 1.2661090963862858\n",
      "          Validation Loss (standardized): 0.8868140468312355\n",
      "Epoch: 11, Loss (standarized): 0.7910554918334536\n",
      "          Validation Loss (standardized): 0.9911267089290411\n",
      "Epoch: 16, Loss (standarized): 0.8535031691160928\n",
      "          Validation Loss (standardized): 0.8909698669595079\n",
      "Epoch: 21, Loss (standarized): 0.6665007266090532\n",
      "          Validation Loss (standardized): 0.6435156472418803\n",
      "Epoch: 26, Loss (standarized): 0.5477112585938919\n",
      "          Validation Loss (standardized): 0.6126157891768551\n",
      "Epoch: 31, Loss (standarized): 0.5270845181373145\n",
      "          Validation Loss (standardized): 0.5477175968730025\n",
      "Epoch: 36, Loss (standarized): 0.47913999255351475\n",
      "          Validation Loss (standardized): 0.5042087869143449\n",
      "Epoch: 41, Loss (standarized): 0.45446550769302146\n",
      "          Validation Loss (standardized): 0.5239820802385574\n",
      "Epoch: 46, Loss (standarized): 0.4362417068761724\n",
      "          Validation Loss (standardized): 0.49468227269040965\n",
      "Epoch: 51, Loss (standarized): 0.4294106362922447\n",
      "          Validation Loss (standardized): 0.48615953163061976\n",
      "Epoch: 56, Loss (standarized): 0.4247672675997099\n",
      "          Validation Loss (standardized): 0.4936172738176424\n",
      "Epoch: 61, Loss (standarized): 0.42106999431459274\n",
      "          Validation Loss (standardized): 0.4829042881306657\n",
      "Epoch: 66, Loss (standarized): 0.41925000194496514\n",
      "          Validation Loss (standardized): 0.48615634951793085\n",
      "Epoch: 71, Loss (standarized): 0.4182369051789866\n",
      "          Validation Loss (standardized): 0.4786717217969956\n",
      "Epoch: 76, Loss (standarized): 0.41737407072254823\n",
      "          Validation Loss (standardized): 0.4779477896648656\n",
      "Epoch: 81, Loss (standarized): 0.4161282724247911\n",
      "          Validation Loss (standardized): 0.47550825836340005\n",
      "Epoch: 86, Loss (standarized): 0.4146876165747366\n",
      "          Validation Loss (standardized): 0.4726036100325608\n",
      "Epoch: 91, Loss (standarized): 0.4129810379158364\n",
      "          Validation Loss (standardized): 0.47071813605415097\n",
      "Epoch: 96, Loss (standarized): 0.4107494821857315\n",
      "          Validation Loss (standardized): 0.46796298115960566\n",
      "Final epoch: 100, Final loss (standarized): 0.4092742669197932\n",
      "Epoch: 1, Loss (standarized): 3.0215292077358877\n",
      "          Validation Loss (standardized): 1.6542390409853411\n",
      "Epoch: 6, Loss (standarized): 0.8478998181077433\n",
      "          Validation Loss (standardized): 1.0595658436780482\n",
      "Epoch: 11, Loss (standarized): 0.9356370476240983\n",
      "          Validation Loss (standardized): 0.8889408472865071\n",
      "Epoch: 16, Loss (standarized): 0.634981755767185\n",
      "          Validation Loss (standardized): 0.6525944086340877\n",
      "Epoch: 21, Loss (standarized): 0.6715325932026296\n",
      "          Validation Loss (standardized): 0.6659788121801538\n",
      "Epoch: 26, Loss (standarized): 0.56270849918356\n",
      "          Validation Loss (standardized): 0.5449595084203098\n",
      "Epoch: 31, Loss (standarized): 0.5072784323468108\n",
      "          Validation Loss (standardized): 0.5288605368034238\n",
      "Epoch: 36, Loss (standarized): 0.49382948970417484\n",
      "          Validation Loss (standardized): 0.5234282961687421\n",
      "Epoch: 41, Loss (standarized): 0.461288824680307\n",
      "          Validation Loss (standardized): 0.47629555305374743\n",
      "Epoch: 46, Loss (standarized): 0.4409648007643129\n",
      "          Validation Loss (standardized): 0.46943675024821646\n",
      "Epoch: 51, Loss (standarized): 0.42881397751449724\n",
      "          Validation Loss (standardized): 0.4532627681289172\n",
      "Epoch: 56, Loss (standarized): 0.41923276089107764\n",
      "          Validation Loss (standardized): 0.4549834303228132\n",
      "Epoch: 61, Loss (standarized): 0.4144085944275595\n",
      "          Validation Loss (standardized): 0.44794316884418856\n",
      "Epoch: 66, Loss (standarized): 0.40942444826323215\n",
      "          Validation Loss (standardized): 0.4459849271698011\n",
      "Epoch: 71, Loss (standarized): 0.40584505768140866\n",
      "          Validation Loss (standardized): 0.44064819659713295\n",
      "Epoch: 76, Loss (standarized): 0.4038710332298293\n",
      "          Validation Loss (standardized): 0.43929682418474214\n",
      "Epoch: 81, Loss (standarized): 0.40131024791670944\n",
      "          Validation Loss (standardized): 0.4370512678344042\n",
      "Epoch: 86, Loss (standarized): 0.39866351488658136\n",
      "          Validation Loss (standardized): 0.4332741328592995\n",
      "Epoch: 91, Loss (standarized): 0.3961740005904998\n",
      "          Validation Loss (standardized): 0.43291316038573896\n",
      "Epoch: 96, Loss (standarized): 0.3940847408651552\n",
      "          Validation Loss (standardized): 0.4294318713501079\n",
      "Final epoch: 100, Final loss (standarized): 0.39215803325388904\n",
      "Epoch: 1, Loss (standarized): 1.5924263199213944\n",
      "          Validation Loss (standardized): 0.9191340388123033\n",
      "Epoch: 6, Loss (standarized): 0.8559651704688633\n",
      "          Validation Loss (standardized): 0.9236949315548972\n",
      "Epoch: 11, Loss (standarized): 0.7007219798968205\n",
      "          Validation Loss (standardized): 0.6795287082382595\n",
      "Epoch: 16, Loss (standarized): 0.6381434977419357\n",
      "          Validation Loss (standardized): 0.6147155932930967\n",
      "Epoch: 21, Loss (standarized): 0.5857198230141621\n",
      "          Validation Loss (standardized): 0.6297370258225371\n",
      "Epoch: 26, Loss (standarized): 0.5303084436031263\n",
      "          Validation Loss (standardized): 0.5398205161229558\n",
      "Epoch: 31, Loss (standarized): 0.5025693689071498\n",
      "          Validation Loss (standardized): 0.5175474894793579\n",
      "Epoch: 36, Loss (standarized): 0.47922896084977384\n",
      "          Validation Loss (standardized): 0.5178532995935862\n",
      "Epoch: 41, Loss (standarized): 0.4702060266432472\n",
      "          Validation Loss (standardized): 0.492505571977348\n",
      "Epoch: 46, Loss (standarized): 0.4642725972631328\n",
      "          Validation Loss (standardized): 0.5016589951526901\n",
      "Epoch: 51, Loss (standarized): 0.45892930467023724\n",
      "          Validation Loss (standardized): 0.49041175273217347\n",
      "Epoch: 56, Loss (standarized): 0.4523970574617113\n",
      "          Validation Loss (standardized): 0.4925318344653696\n",
      "Epoch: 61, Loss (standarized): 0.44851375171158275\n",
      "          Validation Loss (standardized): 0.4839535182655185\n",
      "Epoch: 66, Loss (standarized): 0.4481794572575463\n",
      "          Validation Loss (standardized): 0.48604636256048694\n",
      "Epoch: 71, Loss (standarized): 0.44924163521734056\n",
      "          Validation Loss (standardized): 0.4852109820358815\n",
      "Epoch: 76, Loss (standarized): 0.44983495354641023\n",
      "          Validation Loss (standardized): 0.48270004678791123\n",
      "Epoch: 81, Loss (standarized): 0.4488156623740913\n",
      "          Validation Loss (standardized): 0.4795205453668821\n",
      "Epoch: 86, Loss (standarized): 0.44503504622138423\n",
      "          Validation Loss (standardized): 0.47724855538490446\n",
      "Epoch: 91, Loss (standarized): 0.4400765538935126\n",
      "          Validation Loss (standardized): 0.472572321547664\n",
      "Epoch: 96, Loss (standarized): 0.4395768316866329\n",
      "          Validation Loss (standardized): 0.46874823849947744\n",
      "Final epoch: 100, Final loss (standarized): 0.4397968209059536\n",
      "Epoch: 1, Loss (standarized): 1.8754901049786075\n",
      "          Validation Loss (standardized): 1.4353761855073304\n",
      "Epoch: 6, Loss (standarized): 0.7487474722217704\n",
      "          Validation Loss (standardized): 0.6941175692455134\n",
      "Epoch: 11, Loss (standarized): 0.7905845151304982\n",
      "          Validation Loss (standardized): 0.7060632382933906\n",
      "Epoch: 16, Loss (standarized): 0.644883762789054\n",
      "          Validation Loss (standardized): 0.648534403708016\n",
      "Epoch: 21, Loss (standarized): 0.5764343432811632\n",
      "          Validation Loss (standardized): 0.5883991596289876\n",
      "Epoch: 26, Loss (standarized): 0.5445295320338801\n",
      "          Validation Loss (standardized): 0.5676516449749813\n",
      "Epoch: 31, Loss (standarized): 0.49656845241657416\n",
      "          Validation Loss (standardized): 0.5133668089022804\n",
      "Epoch: 36, Loss (standarized): 0.46588216548861433\n",
      "          Validation Loss (standardized): 0.49126872496987484\n",
      "Epoch: 41, Loss (standarized): 0.4487890171848202\n",
      "          Validation Loss (standardized): 0.4745435381979746\n",
      "Epoch: 46, Loss (standarized): 0.4389642884653326\n",
      "          Validation Loss (standardized): 0.4743175000663103\n",
      "Epoch: 51, Loss (standarized): 0.4316575279347766\n",
      "          Validation Loss (standardized): 0.46601419478796857\n",
      "Epoch: 56, Loss (standarized): 0.42650776872092866\n",
      "          Validation Loss (standardized): 0.46005267110845494\n",
      "Epoch: 61, Loss (standarized): 0.42135994440055435\n",
      "          Validation Loss (standardized): 0.4632998683922049\n",
      "Epoch: 66, Loss (standarized): 0.41894882457965377\n",
      "          Validation Loss (standardized): 0.45831981034745867\n",
      "Epoch: 71, Loss (standarized): 0.41495631886573836\n",
      "          Validation Loss (standardized): 0.4500806806794945\n",
      "Epoch: 76, Loss (standarized): 0.4093073652410408\n",
      "          Validation Loss (standardized): 0.4451864596045961\n",
      "Epoch: 81, Loss (standarized): 0.40360872404148385\n",
      "          Validation Loss (standardized): 0.4407242920124186\n",
      "Epoch: 86, Loss (standarized): 0.3990187424051939\n",
      "          Validation Loss (standardized): 0.43694020928029487\n",
      "Epoch: 91, Loss (standarized): 0.3948517094128358\n",
      "          Validation Loss (standardized): 0.4355695400879793\n",
      "Epoch: 96, Loss (standarized): 0.3922327360493815\n",
      "          Validation Loss (standardized): 0.43118523587042856\n",
      "Final epoch: 100, Final loss (standarized): 0.39063616462596745\n",
      "Epoch: 1, Loss (standarized): 2.381846529194557\n",
      "          Validation Loss (standardized): 1.3926264634009982\n",
      "Epoch: 6, Loss (standarized): 1.1642223696399192\n",
      "          Validation Loss (standardized): 0.9089074344556203\n",
      "Epoch: 11, Loss (standarized): 0.6722960010199056\n",
      "          Validation Loss (standardized): 0.7695827516212533\n",
      "Epoch: 16, Loss (standarized): 0.7319718247278353\n",
      "          Validation Loss (standardized): 0.767359726330136\n",
      "Epoch: 21, Loss (standarized): 0.5993542725595329\n",
      "          Validation Loss (standardized): 0.5587584022801358\n",
      "Epoch: 26, Loss (standarized): 0.5559652401081087\n",
      "          Validation Loss (standardized): 0.5635076171468963\n",
      "Epoch: 31, Loss (standarized): 0.502662475569695\n",
      "          Validation Loss (standardized): 0.5347333175790745\n",
      "Epoch: 36, Loss (standarized): 0.46736776821420667\n",
      "          Validation Loss (standardized): 0.46313667690609045\n",
      "Epoch: 41, Loss (standarized): 0.43064864833006966\n",
      "          Validation Loss (standardized): 0.4707732714542756\n",
      "Epoch: 46, Loss (standarized): 0.4081984341029571\n",
      "          Validation Loss (standardized): 0.4299001016751529\n",
      "Epoch: 51, Loss (standarized): 0.39729921332620893\n",
      "          Validation Loss (standardized): 0.4419378397486696\n",
      "Epoch: 56, Loss (standarized): 0.3844418120346947\n",
      "          Validation Loss (standardized): 0.41007905228289876\n",
      "Epoch: 61, Loss (standarized): 0.3731251446301392\n",
      "          Validation Loss (standardized): 0.411015599452356\n",
      "Epoch: 66, Loss (standarized): 0.3600054342912079\n",
      "          Validation Loss (standardized): 0.38930987719011084\n",
      "Epoch: 71, Loss (standarized): 0.34701468974857724\n",
      "          Validation Loss (standardized): 0.3805345927358658\n",
      "Epoch: 76, Loss (standarized): 0.33506876836651917\n",
      "          Validation Loss (standardized): 0.37593994340540876\n",
      "Epoch: 81, Loss (standarized): 0.32494820257281365\n",
      "          Validation Loss (standardized): 0.36123893999800755\n",
      "Epoch: 86, Loss (standarized): 0.3160693817916359\n",
      "          Validation Loss (standardized): 0.352008732848798\n",
      "Epoch: 91, Loss (standarized): 0.3088983849264727\n",
      "          Validation Loss (standardized): 0.349483351665086\n",
      "Epoch: 96, Loss (standarized): 0.3027678785607189\n",
      "          Validation Loss (standardized): 0.34035437570712845\n",
      "Final epoch: 100, Final loss (standarized): 0.2983937764145621\n",
      "Epoch: 1, Loss (standarized): 5.909109950022004\n",
      "          Validation Loss (standardized): 5.301940730596401\n",
      "Epoch: 6, Loss (standarized): 0.8696027342079631\n",
      "          Validation Loss (standardized): 0.7466399999654556\n",
      "Epoch: 11, Loss (standarized): 1.1439102215988888\n",
      "          Validation Loss (standardized): 1.0492270617060084\n",
      "Epoch: 16, Loss (standarized): 1.0485302545703628\n",
      "          Validation Loss (standardized): 0.824163096340309\n",
      "Epoch: 21, Loss (standarized): 0.6244657118289882\n",
      "          Validation Loss (standardized): 0.6069292368058665\n",
      "Epoch: 26, Loss (standarized): 0.6285170020915116\n",
      "          Validation Loss (standardized): 0.7810612600992485\n",
      "Epoch: 31, Loss (standarized): 0.6121103597995233\n",
      "          Validation Loss (standardized): 0.6955555801607776\n",
      "Epoch: 36, Loss (standarized): 0.503017673135827\n",
      "          Validation Loss (standardized): 0.5210967004947413\n",
      "Epoch: 41, Loss (standarized): 0.5020278083484201\n",
      "          Validation Loss (standardized): 0.5029378984283684\n",
      "Epoch: 46, Loss (standarized): 0.4655897756512285\n",
      "          Validation Loss (standardized): 0.542382334059945\n",
      "Epoch: 51, Loss (standarized): 0.44019289647035914\n",
      "          Validation Loss (standardized): 0.4915546986265287\n",
      "Epoch: 56, Loss (standarized): 0.43139639292671833\n",
      "          Validation Loss (standardized): 0.4584238367781995\n",
      "Epoch: 61, Loss (standarized): 0.41514478735905713\n",
      "          Validation Loss (standardized): 0.4809862360359692\n",
      "Epoch: 66, Loss (standarized): 0.4098669424006762\n",
      "          Validation Loss (standardized): 0.4761697987589714\n",
      "Epoch: 71, Loss (standarized): 0.40489816219994595\n",
      "          Validation Loss (standardized): 0.4567975577019382\n",
      "Epoch: 76, Loss (standarized): 0.3996707681984467\n",
      "          Validation Loss (standardized): 0.4686753650208415\n",
      "Epoch: 81, Loss (standarized): 0.39390811026738093\n",
      "          Validation Loss (standardized): 0.4579192153033408\n",
      "Epoch: 86, Loss (standarized): 0.39207825197997054\n",
      "          Validation Loss (standardized): 0.4521820897819073\n",
      "Epoch: 91, Loss (standarized): 0.38810418260745483\n",
      "          Validation Loss (standardized): 0.4556796994361518\n",
      "Epoch: 96, Loss (standarized): 0.3851360462353766\n",
      "          Validation Loss (standardized): 0.4466892892968417\n",
      "Final epoch: 100, Final loss (standarized): 0.3810815181345128\n",
      "Epoch: 1, Loss (standarized): 0.9159521979330684\n",
      "          Validation Loss (standardized): 0.7209393284431325\n",
      "Epoch: 6, Loss (standarized): 0.6570004431093744\n",
      "          Validation Loss (standardized): 0.6519781539779794\n",
      "Epoch: 11, Loss (standarized): 0.5917694409268144\n",
      "          Validation Loss (standardized): 0.593607186988331\n",
      "Epoch: 16, Loss (standarized): 0.5412602005804568\n",
      "          Validation Loss (standardized): 0.5972132410872903\n",
      "Epoch: 21, Loss (standarized): 0.5039911106765805\n",
      "          Validation Loss (standardized): 0.533138703999513\n",
      "Epoch: 26, Loss (standarized): 0.4729948420738778\n",
      "          Validation Loss (standardized): 0.5346941834753117\n",
      "Epoch: 31, Loss (standarized): 0.45775714573048915\n",
      "          Validation Loss (standardized): 0.5086652037781622\n",
      "Epoch: 36, Loss (standarized): 0.44634089878233674\n",
      "          Validation Loss (standardized): 0.5143835222264465\n",
      "Epoch: 41, Loss (standarized): 0.4319035024326431\n",
      "          Validation Loss (standardized): 0.49263440618485194\n",
      "Epoch: 46, Loss (standarized): 0.41744388737329263\n",
      "          Validation Loss (standardized): 0.4933461472825568\n",
      "Epoch: 51, Loss (standarized): 0.40366660245559804\n",
      "          Validation Loss (standardized): 0.47116804022907915\n",
      "Epoch: 56, Loss (standarized): 0.39196303964012696\n",
      "          Validation Loss (standardized): 0.46502845374075136\n",
      "Epoch: 61, Loss (standarized): 0.381818784648137\n",
      "          Validation Loss (standardized): 0.4454306337527335\n",
      "Epoch: 66, Loss (standarized): 0.3703209884481958\n",
      "          Validation Loss (standardized): 0.4315988816865254\n",
      "Epoch: 71, Loss (standarized): 0.3596800975032739\n",
      "          Validation Loss (standardized): 0.4268188899980527\n",
      "Epoch: 76, Loss (standarized): 0.3502855749406525\n",
      "          Validation Loss (standardized): 0.4074424073554177\n",
      "Epoch: 81, Loss (standarized): 0.3392205933745299\n",
      "          Validation Loss (standardized): 0.39354320537890763\n",
      "Epoch: 86, Loss (standarized): 0.3254712674931547\n",
      "          Validation Loss (standardized): 0.3724409654513977\n",
      "Epoch: 91, Loss (standarized): 0.31206250195821034\n",
      "          Validation Loss (standardized): 0.35705953706342636\n",
      "Epoch: 96, Loss (standarized): 0.29707575424361293\n",
      "          Validation Loss (standardized): 0.34528663644041296\n",
      "Final epoch: 100, Final loss (standarized): 0.28415091757723276\n",
      "Epoch: 1, Loss (standarized): 1.0696793670754599\n",
      "          Validation Loss (standardized): 0.9543230726086914\n",
      "Epoch: 6, Loss (standarized): 0.7578661473786152\n",
      "          Validation Loss (standardized): 0.6878994809533435\n",
      "Epoch: 11, Loss (standarized): 0.6486889906903468\n",
      "          Validation Loss (standardized): 0.6575948783242407\n",
      "Epoch: 16, Loss (standarized): 0.6125305972787267\n",
      "          Validation Loss (standardized): 0.6610974713985415\n",
      "Epoch: 21, Loss (standarized): 0.5430898944553961\n",
      "          Validation Loss (standardized): 0.5595823142729688\n",
      "Epoch: 26, Loss (standarized): 0.5018200408702713\n",
      "          Validation Loss (standardized): 0.510373097906096\n",
      "Epoch: 31, Loss (standarized): 0.45788127194536\n",
      "          Validation Loss (standardized): 0.5154131096600907\n",
      "Epoch: 36, Loss (standarized): 0.430252735919303\n",
      "          Validation Loss (standardized): 0.4710816239041955\n",
      "Epoch: 41, Loss (standarized): 0.4094410322965206\n",
      "          Validation Loss (standardized): 0.44624084339745723\n",
      "Epoch: 46, Loss (standarized): 0.39052537981183644\n",
      "          Validation Loss (standardized): 0.45380343437817944\n",
      "Epoch: 51, Loss (standarized): 0.3781915411371146\n",
      "          Validation Loss (standardized): 0.426691424963395\n",
      "Epoch: 56, Loss (standarized): 0.36767787693793885\n",
      "          Validation Loss (standardized): 0.41331432939037394\n",
      "Epoch: 61, Loss (standarized): 0.35308422447759924\n",
      "          Validation Loss (standardized): 0.40571701415175804\n",
      "Epoch: 66, Loss (standarized): 0.34023338531801484\n",
      "          Validation Loss (standardized): 0.3758819397599544\n",
      "Epoch: 71, Loss (standarized): 0.32375168939262505\n",
      "          Validation Loss (standardized): 0.3692634668493991\n",
      "Epoch: 76, Loss (standarized): 0.3088580939522128\n",
      "          Validation Loss (standardized): 0.3541507874456346\n",
      "Epoch: 81, Loss (standarized): 0.2912189390931489\n",
      "          Validation Loss (standardized): 0.34265816051718384\n",
      "Epoch: 86, Loss (standarized): 0.27198884197876383\n",
      "          Validation Loss (standardized): 0.3201470852697148\n",
      "Epoch: 91, Loss (standarized): 0.2524498380646823\n",
      "          Validation Loss (standardized): 0.29971621452235664\n",
      "Epoch: 96, Loss (standarized): 0.23054758191280658\n",
      "          Validation Loss (standardized): 0.2750093528891234\n",
      "Final epoch: 100, Final loss (standarized): 0.2132071247062298\n",
      "Epoch: 1, Loss (standarized): 1.3689969280693859\n",
      "          Validation Loss (standardized): 0.8540563875649504\n",
      "Epoch: 6, Loss (standarized): 0.8590404847946743\n",
      "          Validation Loss (standardized): 0.9608176209936116\n",
      "Epoch: 11, Loss (standarized): 0.7019475294749663\n",
      "          Validation Loss (standardized): 0.6836827867309826\n",
      "Epoch: 16, Loss (standarized): 0.6657582691573973\n",
      "          Validation Loss (standardized): 0.6276985011816619\n",
      "Epoch: 21, Loss (standarized): 0.5897008719553424\n",
      "          Validation Loss (standardized): 0.6283893417368797\n",
      "Epoch: 26, Loss (standarized): 0.5250476203711524\n",
      "          Validation Loss (standardized): 0.5370778642739775\n",
      "Epoch: 31, Loss (standarized): 0.4465488942192891\n",
      "          Validation Loss (standardized): 0.44525573002254193\n",
      "Epoch: 36, Loss (standarized): 0.4050416830270174\n",
      "          Validation Loss (standardized): 0.44657074826706245\n",
      "Epoch: 41, Loss (standarized): 0.37495684252379846\n",
      "          Validation Loss (standardized): 0.40229626245135547\n",
      "Epoch: 46, Loss (standarized): 0.35679175481835773\n",
      "          Validation Loss (standardized): 0.3968006684120222\n",
      "Epoch: 51, Loss (standarized): 0.34266738839251387\n",
      "          Validation Loss (standardized): 0.367871410103363\n",
      "Epoch: 56, Loss (standarized): 0.32707727412787013\n",
      "          Validation Loss (standardized): 0.3675420370728294\n",
      "Epoch: 61, Loss (standarized): 0.3101854598399781\n",
      "          Validation Loss (standardized): 0.34463645418122163\n",
      "Epoch: 66, Loss (standarized): 0.29372278685676945\n",
      "          Validation Loss (standardized): 0.3285210672945884\n",
      "Epoch: 71, Loss (standarized): 0.2750796450656064\n",
      "          Validation Loss (standardized): 0.313891411201925\n",
      "Epoch: 76, Loss (standarized): 0.2544127627158792\n",
      "          Validation Loss (standardized): 0.2894274938116259\n",
      "Epoch: 81, Loss (standarized): 0.23333424009107828\n",
      "          Validation Loss (standardized): 0.26855389707582594\n",
      "Epoch: 86, Loss (standarized): 0.21343593053336435\n",
      "          Validation Loss (standardized): 0.25162823016104047\n",
      "Epoch: 91, Loss (standarized): 0.19399039581059233\n",
      "          Validation Loss (standardized): 0.2375851773576504\n",
      "Epoch: 96, Loss (standarized): 0.17617080397907556\n",
      "          Validation Loss (standardized): 0.22307494813426576\n",
      "Final epoch: 100, Final loss (standarized): 0.16394331606661258\n",
      "Epoch: 1, Loss (standarized): 2.6270822492682018\n",
      "          Validation Loss (standardized): 1.662604775929914\n",
      "Epoch: 6, Loss (standarized): 0.802958010624408\n",
      "          Validation Loss (standardized): 0.7892657541140331\n",
      "Epoch: 11, Loss (standarized): 0.8208829913096736\n",
      "          Validation Loss (standardized): 0.8970217445069636\n",
      "Epoch: 16, Loss (standarized): 0.6487363726704664\n",
      "          Validation Loss (standardized): 0.6203760776242558\n",
      "Epoch: 21, Loss (standarized): 0.507101757097273\n",
      "          Validation Loss (standardized): 0.5311407847778393\n",
      "Epoch: 26, Loss (standarized): 0.4859532841442234\n",
      "          Validation Loss (standardized): 0.4671489099623187\n",
      "Epoch: 31, Loss (standarized): 0.42596785647876134\n",
      "          Validation Loss (standardized): 0.4718301954949048\n",
      "Epoch: 36, Loss (standarized): 0.4113182924053744\n",
      "          Validation Loss (standardized): 0.4541481936698126\n",
      "Epoch: 41, Loss (standarized): 0.39466233181328164\n",
      "          Validation Loss (standardized): 0.4585440980267442\n",
      "Epoch: 46, Loss (standarized): 0.3813688224324651\n",
      "          Validation Loss (standardized): 0.422228064484195\n",
      "Epoch: 51, Loss (standarized): 0.3738667058272644\n",
      "          Validation Loss (standardized): 0.4233585874387032\n",
      "Epoch: 56, Loss (standarized): 0.3651812616493986\n",
      "          Validation Loss (standardized): 0.407174362940311\n",
      "Epoch: 61, Loss (standarized): 0.3585334425067056\n",
      "          Validation Loss (standardized): 0.40412433570058626\n",
      "Epoch: 66, Loss (standarized): 0.353422524498457\n",
      "          Validation Loss (standardized): 0.3981288714661473\n",
      "Epoch: 71, Loss (standarized): 0.3487641409484488\n",
      "          Validation Loss (standardized): 0.38830022786103496\n",
      "Epoch: 76, Loss (standarized): 0.34493838449247727\n",
      "          Validation Loss (standardized): 0.38482352863108077\n",
      "Epoch: 81, Loss (standarized): 0.3416352116112678\n",
      "          Validation Loss (standardized): 0.37944942110711577\n",
      "Epoch: 86, Loss (standarized): 0.338469498048945\n",
      "          Validation Loss (standardized): 0.3765083261188543\n",
      "Epoch: 91, Loss (standarized): 0.33562763968284004\n",
      "          Validation Loss (standardized): 0.37241586671747756\n",
      "Epoch: 96, Loss (standarized): 0.33278931409816825\n",
      "          Validation Loss (standardized): 0.3677149178547407\n",
      "Final epoch: 100, Final loss (standarized): 0.32866873084806186\n",
      "Epoch: 1, Loss (standarized): 1.0616629460654292\n",
      "          Validation Loss (standardized): 0.7770636702295846\n",
      "Epoch: 6, Loss (standarized): 0.7637833423277364\n",
      "          Validation Loss (standardized): 0.7717199490259175\n",
      "Epoch: 11, Loss (standarized): 0.6595017227960392\n",
      "          Validation Loss (standardized): 0.6248755465625626\n",
      "Epoch: 16, Loss (standarized): 0.5591598839244573\n",
      "          Validation Loss (standardized): 0.5924852621909871\n",
      "Epoch: 21, Loss (standarized): 0.48531986559843565\n",
      "          Validation Loss (standardized): 0.5095743043448152\n",
      "Epoch: 26, Loss (standarized): 0.436318119506877\n",
      "          Validation Loss (standardized): 0.46950900530388506\n",
      "Epoch: 31, Loss (standarized): 0.39511224405089684\n",
      "          Validation Loss (standardized): 0.461673289038057\n",
      "Epoch: 36, Loss (standarized): 0.3808928607699931\n",
      "          Validation Loss (standardized): 0.4290538577066496\n",
      "Epoch: 41, Loss (standarized): 0.3658881533207146\n",
      "          Validation Loss (standardized): 0.4135310944006326\n",
      "Epoch: 46, Loss (standarized): 0.3559196038337558\n",
      "          Validation Loss (standardized): 0.40866016139740824\n",
      "Epoch: 51, Loss (standarized): 0.3435737370310597\n",
      "          Validation Loss (standardized): 0.3855887902662356\n",
      "Epoch: 56, Loss (standarized): 0.33212022505221267\n",
      "          Validation Loss (standardized): 0.37396109332077726\n",
      "Epoch: 61, Loss (standarized): 0.32121942022939465\n",
      "          Validation Loss (standardized): 0.360884888810955\n",
      "Epoch: 66, Loss (standarized): 0.30540031917153954\n",
      "          Validation Loss (standardized): 0.34211542523509\n",
      "Epoch: 71, Loss (standarized): 0.29006101161201575\n",
      "          Validation Loss (standardized): 0.3282831376679124\n",
      "Epoch: 76, Loss (standarized): 0.2720025324793002\n",
      "          Validation Loss (standardized): 0.29890704685846303\n",
      "Epoch: 81, Loss (standarized): 0.26070608928241956\n",
      "          Validation Loss (standardized): 0.29617879429820454\n",
      "Epoch: 86, Loss (standarized): 0.2422123586383656\n",
      "          Validation Loss (standardized): 0.2814939375317447\n",
      "Epoch: 91, Loss (standarized): 0.22455530155880993\n",
      "          Validation Loss (standardized): 0.2659101927380917\n",
      "Epoch: 96, Loss (standarized): 0.20810182514386813\n",
      "          Validation Loss (standardized): 0.24602784000030004\n",
      "Final epoch: 100, Final loss (standarized): 0.19490796636431443\n",
      "Epoch: 1, Loss (standarized): 3.5052185540837306\n",
      "          Validation Loss (standardized): 2.3776186467747373\n",
      "Epoch: 6, Loss (standarized): 0.8225402333230647\n",
      "          Validation Loss (standardized): 0.8165118017097917\n",
      "Epoch: 11, Loss (standarized): 1.0096663698529138\n",
      "          Validation Loss (standardized): 1.0107641347658964\n",
      "Epoch: 16, Loss (standarized): 0.738051933391518\n",
      "          Validation Loss (standardized): 0.7096380097501879\n",
      "Epoch: 21, Loss (standarized): 0.6832360906772176\n",
      "          Validation Loss (standardized): 0.6707696639002526\n",
      "Epoch: 26, Loss (standarized): 0.6439680882500566\n",
      "          Validation Loss (standardized): 0.6319996946778375\n",
      "Epoch: 31, Loss (standarized): 0.568750408980206\n",
      "          Validation Loss (standardized): 0.568682547550597\n",
      "Epoch: 36, Loss (standarized): 0.5099721009743303\n",
      "          Validation Loss (standardized): 0.5213306624470266\n",
      "Epoch: 41, Loss (standarized): 0.46710995441273234\n",
      "          Validation Loss (standardized): 0.4962975057915797\n",
      "Epoch: 46, Loss (standarized): 0.43997780312308227\n",
      "          Validation Loss (standardized): 0.46658450944447794\n",
      "Epoch: 51, Loss (standarized): 0.43608098893986347\n",
      "          Validation Loss (standardized): 0.465406849147515\n",
      "Epoch: 56, Loss (standarized): 0.4229741655622779\n",
      "          Validation Loss (standardized): 0.461112832684133\n",
      "Epoch: 61, Loss (standarized): 0.40854481924533703\n",
      "          Validation Loss (standardized): 0.4525933322571284\n",
      "Epoch: 66, Loss (standarized): 0.40120313381087575\n",
      "          Validation Loss (standardized): 0.4455642750686216\n",
      "Epoch: 71, Loss (standarized): 0.39448649434096145\n",
      "          Validation Loss (standardized): 0.43585878999306443\n",
      "Epoch: 76, Loss (standarized): 0.3871003836843546\n",
      "          Validation Loss (standardized): 0.42817769463707966\n",
      "Epoch: 81, Loss (standarized): 0.379943127669548\n",
      "          Validation Loss (standardized): 0.4215334834282708\n",
      "Epoch: 86, Loss (standarized): 0.37178173028268374\n",
      "          Validation Loss (standardized): 0.4107800361503833\n",
      "Epoch: 91, Loss (standarized): 0.3623595386881241\n",
      "          Validation Loss (standardized): 0.3993939060023807\n",
      "Epoch: 96, Loss (standarized): 0.3520981984436472\n",
      "          Validation Loss (standardized): 0.3856216346601654\n",
      "Final epoch: 100, Final loss (standarized): 0.34342394790622466\n",
      "Epoch: 1, Loss (standarized): 1.3819059756016903\n",
      "          Validation Loss (standardized): 0.9941326940590546\n",
      "Epoch: 6, Loss (standarized): 0.862907548109955\n",
      "          Validation Loss (standardized): 0.7421766177119753\n",
      "Epoch: 11, Loss (standarized): 0.5879849354745319\n",
      "          Validation Loss (standardized): 0.6774248467034494\n",
      "Epoch: 16, Loss (standarized): 0.5775272735185476\n",
      "          Validation Loss (standardized): 0.5856575259161425\n",
      "Epoch: 21, Loss (standarized): 0.5156816176535448\n",
      "          Validation Loss (standardized): 0.5761648516889032\n",
      "Epoch: 26, Loss (standarized): 0.49236805548411666\n",
      "          Validation Loss (standardized): 0.5196879433582209\n",
      "Epoch: 31, Loss (standarized): 0.48374627873807885\n",
      "          Validation Loss (standardized): 0.5714182042833404\n",
      "Epoch: 36, Loss (standarized): 0.46722046331359024\n",
      "          Validation Loss (standardized): 0.5225913135302678\n",
      "Epoch: 41, Loss (standarized): 0.46488260165512507\n",
      "          Validation Loss (standardized): 0.5243640333208223\n",
      "Epoch: 46, Loss (standarized): 0.45240885169673567\n",
      "          Validation Loss (standardized): 0.5328306002491238\n",
      "Epoch: 51, Loss (standarized): 0.44442920375166406\n",
      "          Validation Loss (standardized): 0.5120123570299231\n",
      "Epoch: 56, Loss (standarized): 0.43541596616060324\n",
      "          Validation Loss (standardized): 0.5026318188683332\n",
      "Epoch: 61, Loss (standarized): 0.4237580875392034\n",
      "          Validation Loss (standardized): 0.4968224017276653\n",
      "Epoch: 66, Loss (standarized): 0.4125298201000206\n",
      "          Validation Loss (standardized): 0.47695404638849526\n",
      "Epoch: 71, Loss (standarized): 0.40596731490524024\n",
      "          Validation Loss (standardized): 0.46595672157286744\n",
      "Epoch: 76, Loss (standarized): 0.39839008446063684\n",
      "          Validation Loss (standardized): 0.46301294996302417\n",
      "Epoch: 81, Loss (standarized): 0.39027186726508883\n",
      "          Validation Loss (standardized): 0.4535227456805801\n",
      "Epoch: 86, Loss (standarized): 0.3829869802343028\n",
      "          Validation Loss (standardized): 0.4463417518534794\n",
      "Epoch: 91, Loss (standarized): 0.3756001956142339\n",
      "          Validation Loss (standardized): 0.43930253492674354\n",
      "Epoch: 96, Loss (standarized): 0.36767605161586203\n",
      "          Validation Loss (standardized): 0.42942087159118203\n",
      "Final epoch: 100, Final loss (standarized): 0.360972494223348\n",
      "Epoch: 1, Loss (standarized): 0.9162175286155005\n",
      "          Validation Loss (standardized): 0.7251495436658908\n",
      "Epoch: 6, Loss (standarized): 0.7082152596990522\n",
      "          Validation Loss (standardized): 0.7593178913008052\n",
      "Epoch: 11, Loss (standarized): 0.6342373164742923\n",
      "          Validation Loss (standardized): 0.6162140764317222\n",
      "Epoch: 16, Loss (standarized): 0.571616854322067\n",
      "          Validation Loss (standardized): 0.6050088501440818\n",
      "Epoch: 21, Loss (standarized): 0.5157299367599595\n",
      "          Validation Loss (standardized): 0.5339011053589907\n",
      "Epoch: 26, Loss (standarized): 0.47742443503705995\n",
      "          Validation Loss (standardized): 0.5305855093688495\n",
      "Epoch: 31, Loss (standarized): 0.44704529265909915\n",
      "          Validation Loss (standardized): 0.4939084979283134\n",
      "Epoch: 36, Loss (standarized): 0.4279585992093019\n",
      "          Validation Loss (standardized): 0.48782055766086274\n",
      "Epoch: 41, Loss (standarized): 0.4132222768114193\n",
      "          Validation Loss (standardized): 0.47101957351809703\n",
      "Epoch: 46, Loss (standarized): 0.39445696623197035\n",
      "          Validation Loss (standardized): 0.4458864242195567\n",
      "Epoch: 51, Loss (standarized): 0.3791180188824145\n",
      "          Validation Loss (standardized): 0.43982872643574183\n",
      "Epoch: 56, Loss (standarized): 0.367512113528095\n",
      "          Validation Loss (standardized): 0.42026599342683757\n",
      "Epoch: 61, Loss (standarized): 0.35512340436328693\n",
      "          Validation Loss (standardized): 0.40463773756826815\n",
      "Epoch: 66, Loss (standarized): 0.3433776905285387\n",
      "          Validation Loss (standardized): 0.3928570137340908\n",
      "Epoch: 71, Loss (standarized): 0.3342314718985711\n",
      "          Validation Loss (standardized): 0.3795016392366998\n",
      "Epoch: 76, Loss (standarized): 0.32739981757781456\n",
      "          Validation Loss (standardized): 0.36965952384106926\n",
      "Epoch: 81, Loss (standarized): 0.3214752815970425\n",
      "          Validation Loss (standardized): 0.36043591826726556\n",
      "Epoch: 86, Loss (standarized): 0.31625868294522824\n",
      "          Validation Loss (standardized): 0.35481074588362577\n",
      "Epoch: 91, Loss (standarized): 0.312160226662154\n",
      "          Validation Loss (standardized): 0.3491380144419567\n",
      "Epoch: 96, Loss (standarized): 0.3081620629197318\n",
      "          Validation Loss (standardized): 0.34318077994448964\n",
      "Final epoch: 100, Final loss (standarized): 0.30541540108636106\n",
      "Epoch: 1, Loss (standarized): 1.6333187135646807\n",
      "          Validation Loss (standardized): 0.9816150652625126\n",
      "Epoch: 6, Loss (standarized): 0.8944503385006968\n",
      "          Validation Loss (standardized): 0.9333621467146468\n",
      "Epoch: 11, Loss (standarized): 0.6694275579118093\n",
      "          Validation Loss (standardized): 0.6682395827100946\n",
      "Epoch: 16, Loss (standarized): 0.6444906212582693\n",
      "          Validation Loss (standardized): 0.6441985501667524\n",
      "Epoch: 21, Loss (standarized): 0.5365933864846625\n",
      "          Validation Loss (standardized): 0.536653505238185\n",
      "Epoch: 26, Loss (standarized): 0.46575950318311954\n",
      "          Validation Loss (standardized): 0.5304086973423005\n",
      "Epoch: 31, Loss (standarized): 0.43574138347049535\n",
      "          Validation Loss (standardized): 0.49298577289876805\n",
      "Epoch: 36, Loss (standarized): 0.4148557685270816\n",
      "          Validation Loss (standardized): 0.467527040046703\n",
      "Epoch: 41, Loss (standarized): 0.407781238307261\n",
      "          Validation Loss (standardized): 0.4462975834494854\n",
      "Epoch: 46, Loss (standarized): 0.39479872358948515\n",
      "          Validation Loss (standardized): 0.43811971519242987\n",
      "Epoch: 51, Loss (standarized): 0.3847720995662252\n",
      "          Validation Loss (standardized): 0.4200503142843467\n",
      "Epoch: 56, Loss (standarized): 0.3757590436115957\n",
      "          Validation Loss (standardized): 0.4031736782471383\n",
      "Epoch: 61, Loss (standarized): 0.3648347694882491\n",
      "          Validation Loss (standardized): 0.3896475009594629\n",
      "Epoch: 66, Loss (standarized): 0.3564892441844504\n",
      "          Validation Loss (standardized): 0.38451403077573587\n",
      "Epoch: 71, Loss (standarized): 0.34931883892296417\n",
      "          Validation Loss (standardized): 0.3761415725945642\n",
      "Epoch: 76, Loss (standarized): 0.34246018510461856\n",
      "          Validation Loss (standardized): 0.3693981081089964\n",
      "Epoch: 81, Loss (standarized): 0.3332242580073081\n",
      "          Validation Loss (standardized): 0.35607532172670625\n",
      "Epoch: 86, Loss (standarized): 0.3249333623550761\n",
      "          Validation Loss (standardized): 0.3554129836355513\n",
      "Epoch: 91, Loss (standarized): 0.31748115095831503\n",
      "          Validation Loss (standardized): 0.3459122327714709\n",
      "Epoch: 96, Loss (standarized): 0.30968694338957686\n",
      "          Validation Loss (standardized): 0.34002261309748955\n",
      "Final epoch: 100, Final loss (standarized): 0.3029608333757955\n",
      "Epoch: 1, Loss (standarized): 8.491144566215961\n",
      "          Validation Loss (standardized): 5.767698164131249\n",
      "Epoch: 6, Loss (standarized): 1.2674715983857818\n",
      "          Validation Loss (standardized): 0.8922691092338867\n",
      "Epoch: 11, Loss (standarized): 1.3445800002127186\n",
      "          Validation Loss (standardized): 1.7318862900125225\n",
      "Epoch: 16, Loss (standarized): 1.194566407307762\n",
      "          Validation Loss (standardized): 1.256573418455121\n",
      "Epoch: 21, Loss (standarized): 0.7473193852390652\n",
      "          Validation Loss (standardized): 0.7140699533300366\n",
      "Epoch: 26, Loss (standarized): 0.7907701595637835\n",
      "          Validation Loss (standardized): 0.6901212477327392\n",
      "Epoch: 31, Loss (standarized): 0.6871535368441047\n",
      "          Validation Loss (standardized): 0.5849213154063126\n",
      "Epoch: 36, Loss (standarized): 0.5530788727487519\n",
      "          Validation Loss (standardized): 0.5513484779398421\n",
      "Epoch: 41, Loss (standarized): 0.5004256409550731\n",
      "          Validation Loss (standardized): 0.532546424208643\n",
      "Epoch: 46, Loss (standarized): 0.45763568265396903\n",
      "          Validation Loss (standardized): 0.46147993983846397\n",
      "Epoch: 51, Loss (standarized): 0.42346661863547\n",
      "          Validation Loss (standardized): 0.44169565246705267\n",
      "Epoch: 56, Loss (standarized): 0.39951852834593204\n",
      "          Validation Loss (standardized): 0.4428908231715228\n",
      "Epoch: 61, Loss (standarized): 0.37689214287035144\n",
      "          Validation Loss (standardized): 0.40976126182084377\n",
      "Epoch: 66, Loss (standarized): 0.36069881281382454\n",
      "          Validation Loss (standardized): 0.41428946517341475\n",
      "Epoch: 71, Loss (standarized): 0.34900474243538115\n",
      "          Validation Loss (standardized): 0.399959364075832\n",
      "Epoch: 76, Loss (standarized): 0.33871002908936243\n",
      "          Validation Loss (standardized): 0.38886951738118114\n",
      "Epoch: 81, Loss (standarized): 0.32944113743303577\n",
      "          Validation Loss (standardized): 0.3688745619809122\n",
      "Epoch: 86, Loss (standarized): 0.3214486007561944\n",
      "          Validation Loss (standardized): 0.3590239849915477\n",
      "Epoch: 91, Loss (standarized): 0.30639779217455726\n",
      "          Validation Loss (standardized): 0.3368753699020354\n",
      "Epoch: 96, Loss (standarized): 0.2934177314522906\n",
      "          Validation Loss (standardized): 0.3260936777094267\n",
      "Final epoch: 100, Final loss (standarized): 0.28754689393779687\n",
      "Epoch: 1, Loss (standarized): 0.8323862432936029\n",
      "          Validation Loss (standardized): 0.7368328455338468\n",
      "Epoch: 6, Loss (standarized): 0.6493520523715157\n",
      "          Validation Loss (standardized): 0.6341614658384469\n",
      "Epoch: 11, Loss (standarized): 0.5689303202167334\n",
      "          Validation Loss (standardized): 0.5995037259768587\n",
      "Epoch: 16, Loss (standarized): 0.5075267514960631\n",
      "          Validation Loss (standardized): 0.5191941848253943\n",
      "Epoch: 21, Loss (standarized): 0.46458283322618055\n",
      "          Validation Loss (standardized): 0.4954489862703173\n",
      "Epoch: 26, Loss (standarized): 0.43741439656104736\n",
      "          Validation Loss (standardized): 0.4692280227130938\n",
      "Epoch: 31, Loss (standarized): 0.4295758847355774\n",
      "          Validation Loss (standardized): 0.46707599561256274\n",
      "Epoch: 36, Loss (standarized): 0.4232295677474962\n",
      "          Validation Loss (standardized): 0.4599058766908917\n",
      "Epoch: 41, Loss (standarized): 0.4212871973734675\n",
      "          Validation Loss (standardized): 0.46765867968663477\n",
      "Epoch: 46, Loss (standarized): 0.4192001983228105\n",
      "          Validation Loss (standardized): 0.4585479905973454\n",
      "Epoch: 51, Loss (standarized): 0.4174239157261953\n",
      "          Validation Loss (standardized): 0.4589361494756986\n",
      "Epoch: 56, Loss (standarized): 0.4162197235903286\n",
      "          Validation Loss (standardized): 0.4569245947387012\n",
      "Epoch: 61, Loss (standarized): 0.41332860790352954\n",
      "          Validation Loss (standardized): 0.45248678976078816\n",
      "Epoch: 66, Loss (standarized): 0.41006995020007997\n",
      "          Validation Loss (standardized): 0.4523313560225512\n",
      "Epoch: 71, Loss (standarized): 0.40777246011803764\n",
      "          Validation Loss (standardized): 0.44945304303048494\n",
      "Epoch: 76, Loss (standarized): 0.40380293665700834\n",
      "          Validation Loss (standardized): 0.4467037111810974\n",
      "Epoch: 81, Loss (standarized): 0.40170814468408267\n",
      "          Validation Loss (standardized): 0.444416025753725\n",
      "Epoch: 86, Loss (standarized): 0.3986627783644916\n",
      "          Validation Loss (standardized): 0.44332980673070177\n",
      "Epoch: 91, Loss (standarized): 0.3964288933049055\n",
      "          Validation Loss (standardized): 0.439057982566376\n",
      "Epoch: 96, Loss (standarized): 0.39373315476737003\n",
      "          Validation Loss (standardized): 0.4386457302675632\n",
      "Final epoch: 100, Final loss (standarized): 0.3911542509656979\n",
      "Epoch: 1, Loss (standarized): 11.882767639832378\n",
      "          Validation Loss (standardized): 7.640704139622505\n",
      "Epoch: 6, Loss (standarized): 0.9835775041402754\n",
      "          Validation Loss (standardized): 1.1782095223972286\n",
      "Epoch: 11, Loss (standarized): 1.9496302289527798\n",
      "          Validation Loss (standardized): 1.9330748421423305\n",
      "Epoch: 16, Loss (standarized): 1.1021893396952023\n",
      "          Validation Loss (standardized): 0.9108082265093138\n",
      "Epoch: 21, Loss (standarized): 0.7290912860346996\n",
      "          Validation Loss (standardized): 0.730145687013146\n",
      "Epoch: 26, Loss (standarized): 0.8546714251948984\n",
      "          Validation Loss (standardized): 0.8362455997577914\n",
      "Epoch: 31, Loss (standarized): 0.6558592036356219\n",
      "          Validation Loss (standardized): 0.7021975370929178\n",
      "Epoch: 36, Loss (standarized): 0.5693633839269164\n",
      "          Validation Loss (standardized): 0.675397683175195\n",
      "Epoch: 41, Loss (standarized): 0.5479512023593767\n",
      "          Validation Loss (standardized): 0.6100593075801876\n",
      "Epoch: 46, Loss (standarized): 0.4921491003110569\n",
      "          Validation Loss (standardized): 0.5251333519758216\n",
      "Epoch: 51, Loss (standarized): 0.48216171523773743\n",
      "          Validation Loss (standardized): 0.5150975146395703\n",
      "Epoch: 56, Loss (standarized): 0.45882742015413547\n",
      "          Validation Loss (standardized): 0.5090827803789303\n",
      "Epoch: 61, Loss (standarized): 0.44518057934430716\n",
      "          Validation Loss (standardized): 0.49503943261230143\n",
      "Epoch: 66, Loss (standarized): 0.43815229478909573\n",
      "          Validation Loss (standardized): 0.4806493662151556\n",
      "Epoch: 71, Loss (standarized): 0.426325146668545\n",
      "          Validation Loss (standardized): 0.4710654376140567\n",
      "Epoch: 76, Loss (standarized): 0.4184878570709927\n",
      "          Validation Loss (standardized): 0.4639863643901431\n",
      "Epoch: 81, Loss (standarized): 0.40927418739625326\n",
      "          Validation Loss (standardized): 0.45509733090295484\n",
      "Epoch: 86, Loss (standarized): 0.40254394800649507\n",
      "          Validation Loss (standardized): 0.44910436015795385\n",
      "Epoch: 91, Loss (standarized): 0.3987960540987879\n",
      "          Validation Loss (standardized): 0.4432729495296808\n",
      "Epoch: 96, Loss (standarized): 0.39646208992036247\n",
      "          Validation Loss (standardized): 0.43971098799998937\n",
      "Final epoch: 100, Final loss (standarized): 0.39538828341172894\n",
      "Epoch: 1, Loss (standarized): 0.8566240468720643\n",
      "          Validation Loss (standardized): 0.8160155099031132\n",
      "Epoch: 6, Loss (standarized): 0.7350348263340163\n",
      "          Validation Loss (standardized): 0.7294095581336438\n",
      "Epoch: 11, Loss (standarized): 0.6992840774251068\n",
      "          Validation Loss (standardized): 0.6918608078144589\n",
      "Epoch: 16, Loss (standarized): 0.675538850583158\n",
      "          Validation Loss (standardized): 0.6826771074289638\n",
      "Epoch: 21, Loss (standarized): 0.6426690452926892\n",
      "          Validation Loss (standardized): 0.6454577089489066\n",
      "Epoch: 26, Loss (standarized): 0.6161547074622798\n",
      "          Validation Loss (standardized): 0.6118047276854608\n",
      "Epoch: 31, Loss (standarized): 0.5902674292810313\n",
      "          Validation Loss (standardized): 0.5924754539647257\n",
      "Epoch: 36, Loss (standarized): 0.5656892449391318\n",
      "          Validation Loss (standardized): 0.563738455709062\n",
      "Epoch: 41, Loss (standarized): 0.5435703250674396\n",
      "          Validation Loss (standardized): 0.5445627841980486\n",
      "Epoch: 46, Loss (standarized): 0.5263752242226337\n",
      "          Validation Loss (standardized): 0.527776353159549\n",
      "Epoch: 51, Loss (standarized): 0.5166594248770219\n",
      "          Validation Loss (standardized): 0.526662460920714\n",
      "Epoch: 56, Loss (standarized): 0.5059311757956566\n",
      "          Validation Loss (standardized): 0.5171443866019494\n",
      "Epoch: 61, Loss (standarized): 0.49462794733448845\n",
      "          Validation Loss (standardized): 0.5159666069500893\n",
      "Epoch: 66, Loss (standarized): 0.48035199125672107\n",
      "          Validation Loss (standardized): 0.4954105853577243\n",
      "Epoch: 71, Loss (standarized): 0.46603494603470563\n",
      "          Validation Loss (standardized): 0.49630645880651303\n",
      "Epoch: 76, Loss (standarized): 0.45470204695608285\n",
      "          Validation Loss (standardized): 0.4759752973266023\n",
      "Epoch: 81, Loss (standarized): 0.4440024637078272\n",
      "          Validation Loss (standardized): 0.47208068237267453\n",
      "Epoch: 86, Loss (standarized): 0.4325713681139307\n",
      "          Validation Loss (standardized): 0.46304730175418407\n",
      "Epoch: 91, Loss (standarized): 0.4198243386327709\n",
      "          Validation Loss (standardized): 0.45523247957318724\n",
      "Epoch: 96, Loss (standarized): 0.4056268649414749\n",
      "          Validation Loss (standardized): 0.4466887274882126\n",
      "Final epoch: 100, Final loss (standarized): 0.3957197044556794\n",
      "Epoch: 1, Loss (standarized): 14.585415411594301\n",
      "          Validation Loss (standardized): 10.120052138142572\n",
      "Epoch: 6, Loss (standarized): 3.900580385659675\n",
      "          Validation Loss (standardized): 2.712788693279498\n",
      "Epoch: 11, Loss (standarized): 1.3101969138296632\n",
      "          Validation Loss (standardized): 1.4638853482420873\n",
      "Epoch: 16, Loss (standarized): 1.4101893544345707\n",
      "          Validation Loss (standardized): 1.559374098128556\n",
      "Epoch: 21, Loss (standarized): 1.443314092078897\n",
      "          Validation Loss (standardized): 1.316833788284506\n",
      "Epoch: 26, Loss (standarized): 0.8808628224766505\n",
      "          Validation Loss (standardized): 0.8059127210205028\n",
      "Epoch: 31, Loss (standarized): 0.7864263470904138\n",
      "          Validation Loss (standardized): 0.8164994390825978\n",
      "Epoch: 36, Loss (standarized): 0.7559480589322858\n",
      "          Validation Loss (standardized): 0.7754378934765477\n",
      "Epoch: 41, Loss (standarized): 0.6423895964498073\n",
      "          Validation Loss (standardized): 0.670243775274405\n",
      "Epoch: 46, Loss (standarized): 0.579520933381446\n",
      "          Validation Loss (standardized): 0.6014555385861321\n",
      "Epoch: 51, Loss (standarized): 0.5353285449153222\n",
      "          Validation Loss (standardized): 0.5575419442546325\n",
      "Epoch: 56, Loss (standarized): 0.4989495078858983\n",
      "          Validation Loss (standardized): 0.5322932664138049\n",
      "Epoch: 61, Loss (standarized): 0.4727508292743952\n",
      "          Validation Loss (standardized): 0.5030947634122801\n",
      "Epoch: 66, Loss (standarized): 0.45332575676817016\n",
      "          Validation Loss (standardized): 0.4864082686255037\n",
      "Epoch: 71, Loss (standarized): 0.4401465210613119\n",
      "          Validation Loss (standardized): 0.48273846646082774\n",
      "Epoch: 76, Loss (standarized): 0.4298538178526979\n",
      "          Validation Loss (standardized): 0.46579880924343464\n",
      "Epoch: 81, Loss (standarized): 0.42336068893189893\n",
      "          Validation Loss (standardized): 0.46733146281270316\n",
      "Epoch: 86, Loss (standarized): 0.41750715660362214\n",
      "          Validation Loss (standardized): 0.46015210046822264\n",
      "Epoch: 91, Loss (standarized): 0.4123502467553095\n",
      "          Validation Loss (standardized): 0.4587098187001423\n",
      "Epoch: 96, Loss (standarized): 0.40860651760459976\n",
      "          Validation Loss (standardized): 0.4524914298392271\n",
      "Final epoch: 100, Final loss (standarized): 0.40501231934651216\n",
      "Epoch: 1, Loss (standarized): 1.729756003791542\n",
      "          Validation Loss (standardized): 1.4835866437352467\n",
      "Epoch: 6, Loss (standarized): 0.8678994794243874\n",
      "          Validation Loss (standardized): 0.8340447838297158\n",
      "Epoch: 11, Loss (standarized): 0.7497225533936863\n",
      "          Validation Loss (standardized): 0.6423734561062443\n",
      "Epoch: 16, Loss (standarized): 0.6567155830986187\n",
      "          Validation Loss (standardized): 0.7771688857262714\n",
      "Epoch: 21, Loss (standarized): 0.6143823726255639\n",
      "          Validation Loss (standardized): 0.6541025741495414\n",
      "Epoch: 26, Loss (standarized): 0.5318211382658777\n",
      "          Validation Loss (standardized): 0.5368158654469789\n",
      "Epoch: 31, Loss (standarized): 0.49370990635476364\n",
      "          Validation Loss (standardized): 0.5079810132766674\n",
      "Epoch: 36, Loss (standarized): 0.4484884514660508\n",
      "          Validation Loss (standardized): 0.5096128322705954\n",
      "Epoch: 41, Loss (standarized): 0.43031600437928075\n",
      "          Validation Loss (standardized): 0.48710729909892947\n",
      "Epoch: 46, Loss (standarized): 0.41655636090438275\n",
      "          Validation Loss (standardized): 0.4829517110177264\n",
      "Epoch: 51, Loss (standarized): 0.4063933391647632\n",
      "          Validation Loss (standardized): 0.46964451224567516\n",
      "Epoch: 56, Loss (standarized): 0.40149347255279233\n",
      "          Validation Loss (standardized): 0.471702806331839\n",
      "Epoch: 61, Loss (standarized): 0.39495922478883416\n",
      "          Validation Loss (standardized): 0.4572361411158314\n",
      "Epoch: 66, Loss (standarized): 0.3851893383091931\n",
      "          Validation Loss (standardized): 0.4506675936217937\n",
      "Epoch: 71, Loss (standarized): 0.37478769342872725\n",
      "          Validation Loss (standardized): 0.44039932358857625\n",
      "Epoch: 76, Loss (standarized): 0.36576628330720934\n",
      "          Validation Loss (standardized): 0.4294101405602372\n",
      "Epoch: 81, Loss (standarized): 0.3580518311074039\n",
      "          Validation Loss (standardized): 0.413789746340065\n",
      "Epoch: 86, Loss (standarized): 0.34983770888897586\n",
      "          Validation Loss (standardized): 0.41235898164717333\n",
      "Epoch: 91, Loss (standarized): 0.34139221349609217\n",
      "          Validation Loss (standardized): 0.4019007443516662\n",
      "Epoch: 96, Loss (standarized): 0.33262208869848753\n",
      "          Validation Loss (standardized): 0.3897878035843643\n",
      "Final epoch: 100, Final loss (standarized): 0.3248334207049569\n",
      "Epoch: 1, Loss (standarized): 3.574644329030739\n",
      "          Validation Loss (standardized): 2.3729733068130203\n",
      "Epoch: 6, Loss (standarized): 1.6945976215574383\n",
      "          Validation Loss (standardized): 1.4484824755060137\n",
      "Epoch: 11, Loss (standarized): 0.9782630175665059\n",
      "          Validation Loss (standardized): 0.8367855323849466\n",
      "Epoch: 16, Loss (standarized): 0.720997254959623\n",
      "          Validation Loss (standardized): 0.7303050001396397\n",
      "Epoch: 21, Loss (standarized): 0.6604591753028238\n",
      "          Validation Loss (standardized): 0.7253040167340898\n",
      "Epoch: 26, Loss (standarized): 0.5952343157232047\n",
      "          Validation Loss (standardized): 0.6101659205477766\n",
      "Epoch: 31, Loss (standarized): 0.5298329189757749\n",
      "          Validation Loss (standardized): 0.5584848481712593\n",
      "Epoch: 36, Loss (standarized): 0.4824484902784839\n",
      "          Validation Loss (standardized): 0.5075386271075307\n",
      "Epoch: 41, Loss (standarized): 0.4506024897720936\n",
      "          Validation Loss (standardized): 0.4758348210613559\n",
      "Epoch: 46, Loss (standarized): 0.4247432329927429\n",
      "          Validation Loss (standardized): 0.46056445860014406\n",
      "Epoch: 51, Loss (standarized): 0.4071846054955149\n",
      "          Validation Loss (standardized): 0.45547041546816414\n",
      "Epoch: 56, Loss (standarized): 0.39646121926812977\n",
      "          Validation Loss (standardized): 0.4425124619370061\n",
      "Epoch: 61, Loss (standarized): 0.39064102077069773\n",
      "          Validation Loss (standardized): 0.44212629237078344\n",
      "Epoch: 66, Loss (standarized): 0.38560321431543226\n",
      "          Validation Loss (standardized): 0.43411021693076174\n",
      "Epoch: 71, Loss (standarized): 0.38095948430962834\n",
      "          Validation Loss (standardized): 0.4276888565929464\n",
      "Epoch: 76, Loss (standarized): 0.3778859156255763\n",
      "          Validation Loss (standardized): 0.4266224368431939\n",
      "Epoch: 81, Loss (standarized): 0.3755403931330609\n",
      "          Validation Loss (standardized): 0.4239499669302478\n",
      "Epoch: 86, Loss (standarized): 0.3737922783757265\n",
      "          Validation Loss (standardized): 0.4196842133108473\n",
      "Epoch: 91, Loss (standarized): 0.370986983129699\n",
      "          Validation Loss (standardized): 0.4172893630171929\n",
      "Epoch: 96, Loss (standarized): 0.36856598064325097\n",
      "          Validation Loss (standardized): 0.4148346752843976\n",
      "Final epoch: 100, Final loss (standarized): 0.36719671586359665\n",
      "Epoch: 1, Loss (standarized): 0.8049192716663779\n",
      "          Validation Loss (standardized): 0.7412894178109795\n",
      "Epoch: 6, Loss (standarized): 0.701174660495044\n",
      "          Validation Loss (standardized): 0.6978492204470959\n",
      "Epoch: 11, Loss (standarized): 0.6253743567241309\n",
      "          Validation Loss (standardized): 0.6140791573849345\n",
      "Epoch: 16, Loss (standarized): 0.5283434384468706\n",
      "          Validation Loss (standardized): 0.5320462025702334\n",
      "Epoch: 21, Loss (standarized): 0.4524336540379218\n",
      "          Validation Loss (standardized): 0.4695165589259303\n",
      "Epoch: 26, Loss (standarized): 0.4119286418585931\n",
      "          Validation Loss (standardized): 0.45000198456516927\n",
      "Epoch: 31, Loss (standarized): 0.3942100842131394\n",
      "          Validation Loss (standardized): 0.4542890283774847\n",
      "Epoch: 36, Loss (standarized): 0.377115853423719\n",
      "          Validation Loss (standardized): 0.43951838700336165\n",
      "Epoch: 41, Loss (standarized): 0.3660843478542116\n",
      "          Validation Loss (standardized): 0.4233168925479586\n",
      "Epoch: 46, Loss (standarized): 0.3566422590543349\n",
      "          Validation Loss (standardized): 0.4102360499958914\n",
      "Epoch: 51, Loss (standarized): 0.34618866348887245\n",
      "          Validation Loss (standardized): 0.3992441040091044\n",
      "Epoch: 56, Loss (standarized): 0.3345940519205105\n",
      "          Validation Loss (standardized): 0.3899016615132124\n",
      "Epoch: 61, Loss (standarized): 0.3235492550080302\n",
      "          Validation Loss (standardized): 0.37955927675408746\n",
      "Epoch: 66, Loss (standarized): 0.31267396544230086\n",
      "          Validation Loss (standardized): 0.36628084634888664\n",
      "Epoch: 71, Loss (standarized): 0.30154911835031695\n",
      "          Validation Loss (standardized): 0.35006733891181413\n",
      "Epoch: 76, Loss (standarized): 0.290056625581569\n",
      "          Validation Loss (standardized): 0.33729658046154654\n",
      "Epoch: 81, Loss (standarized): 0.2780041282280738\n",
      "          Validation Loss (standardized): 0.3250739131640389\n",
      "Epoch: 86, Loss (standarized): 0.2658866835359093\n",
      "          Validation Loss (standardized): 0.3136346615520691\n",
      "Epoch: 91, Loss (standarized): 0.2542910025153421\n",
      "          Validation Loss (standardized): 0.30491018377202317\n",
      "Epoch: 96, Loss (standarized): 0.2432280275362754\n",
      "          Validation Loss (standardized): 0.29268174020557325\n",
      "Final epoch: 100, Final loss (standarized): 0.23450972724140579\n",
      "Epoch: 1, Loss (standarized): 1.852477521840978\n",
      "          Validation Loss (standardized): 1.6077404798855581\n",
      "Epoch: 6, Loss (standarized): 0.685219071908409\n",
      "          Validation Loss (standardized): 0.6673997972949582\n",
      "Epoch: 11, Loss (standarized): 0.7478253871542798\n",
      "          Validation Loss (standardized): 0.6615443987474205\n",
      "Epoch: 16, Loss (standarized): 0.5604699114829179\n",
      "          Validation Loss (standardized): 0.6077757066612368\n",
      "Epoch: 21, Loss (standarized): 0.5573603105452126\n",
      "          Validation Loss (standardized): 0.6733257008520712\n",
      "Epoch: 26, Loss (standarized): 0.4829933600999873\n",
      "          Validation Loss (standardized): 0.5386022280349078\n",
      "Epoch: 31, Loss (standarized): 0.466162200559196\n",
      "          Validation Loss (standardized): 0.5030381010601441\n",
      "Epoch: 36, Loss (standarized): 0.44080166847640373\n",
      "          Validation Loss (standardized): 0.5024810038836133\n",
      "Epoch: 41, Loss (standarized): 0.42864216688481316\n",
      "          Validation Loss (standardized): 0.5124285222405498\n",
      "Epoch: 46, Loss (standarized): 0.4112901826722915\n",
      "          Validation Loss (standardized): 0.472139512352842\n",
      "Epoch: 51, Loss (standarized): 0.398359450940594\n",
      "          Validation Loss (standardized): 0.45006698322405286\n",
      "Epoch: 56, Loss (standarized): 0.38843296521868736\n",
      "          Validation Loss (standardized): 0.45644066674184247\n",
      "Epoch: 61, Loss (standarized): 0.37975077016434267\n",
      "          Validation Loss (standardized): 0.44344953419956495\n",
      "Epoch: 66, Loss (standarized): 0.3707289097273196\n",
      "          Validation Loss (standardized): 0.4318002797226373\n",
      "Epoch: 71, Loss (standarized): 0.36200841079400503\n",
      "          Validation Loss (standardized): 0.42372904426652297\n",
      "Epoch: 76, Loss (standarized): 0.3533689617115562\n",
      "          Validation Loss (standardized): 0.4119815263084165\n",
      "Epoch: 81, Loss (standarized): 0.34500787157935586\n",
      "          Validation Loss (standardized): 0.40012282245446584\n",
      "Epoch: 86, Loss (standarized): 0.3367843346330083\n",
      "          Validation Loss (standardized): 0.3912774092810989\n",
      "Epoch: 91, Loss (standarized): 0.32926347609836343\n",
      "          Validation Loss (standardized): 0.38058317870299446\n",
      "Epoch: 96, Loss (standarized): 0.3214936099489381\n",
      "          Validation Loss (standardized): 0.3703319282344563\n",
      "Final epoch: 100, Final loss (standarized): 0.3152513988262088\n",
      "Epoch: 1, Loss (standarized): 4.314874588527869\n",
      "          Validation Loss (standardized): 2.8009741431578954\n",
      "Epoch: 6, Loss (standarized): 1.0206570427585282\n",
      "          Validation Loss (standardized): 0.8593532063766606\n",
      "Epoch: 11, Loss (standarized): 0.7785986821508033\n",
      "          Validation Loss (standardized): 0.7875670788885719\n",
      "Epoch: 16, Loss (standarized): 0.7078311574673576\n",
      "          Validation Loss (standardized): 0.7662474490626127\n",
      "Epoch: 21, Loss (standarized): 0.6132168472232958\n",
      "          Validation Loss (standardized): 0.6398160419525795\n",
      "Epoch: 26, Loss (standarized): 0.5179911848276865\n",
      "          Validation Loss (standardized): 0.5461664192489905\n",
      "Epoch: 31, Loss (standarized): 0.45569049014272495\n",
      "          Validation Loss (standardized): 0.5079223695607917\n",
      "Epoch: 36, Loss (standarized): 0.44210079369360933\n",
      "          Validation Loss (standardized): 0.5105670396506494\n",
      "Epoch: 41, Loss (standarized): 0.4393707253546495\n",
      "          Validation Loss (standardized): 0.4831566736726237\n",
      "Epoch: 46, Loss (standarized): 0.412194552340743\n",
      "          Validation Loss (standardized): 0.45615128495517665\n",
      "Epoch: 51, Loss (standarized): 0.40349863255354573\n",
      "          Validation Loss (standardized): 0.45703067561948757\n",
      "Epoch: 56, Loss (standarized): 0.39692232547187745\n",
      "          Validation Loss (standardized): 0.446060118114566\n",
      "Epoch: 61, Loss (standarized): 0.3787710127111602\n",
      "          Validation Loss (standardized): 0.4138081016882106\n",
      "Epoch: 66, Loss (standarized): 0.36970224836679455\n",
      "          Validation Loss (standardized): 0.4036065106012687\n",
      "Epoch: 71, Loss (standarized): 0.3624120159571705\n",
      "          Validation Loss (standardized): 0.3956277624334297\n",
      "Epoch: 76, Loss (standarized): 0.35473179160511886\n",
      "          Validation Loss (standardized): 0.3833377942513326\n",
      "Epoch: 81, Loss (standarized): 0.34861224616940895\n",
      "          Validation Loss (standardized): 0.37725158587777136\n",
      "Epoch: 86, Loss (standarized): 0.342754110734527\n",
      "          Validation Loss (standardized): 0.36744946999719974\n",
      "Epoch: 91, Loss (standarized): 0.33730011970726226\n",
      "          Validation Loss (standardized): 0.36263601666166023\n",
      "Epoch: 96, Loss (standarized): 0.33179174668518013\n",
      "          Validation Loss (standardized): 0.35858438083646826\n",
      "Final epoch: 100, Final loss (standarized): 0.32761662099028654\n",
      "Epoch: 1, Loss (standarized): 4.9205542875877075\n",
      "          Validation Loss (standardized): 3.4058208271827572\n",
      "Epoch: 6, Loss (standarized): 0.835382028035369\n",
      "          Validation Loss (standardized): 0.6917185757456604\n",
      "Epoch: 11, Loss (standarized): 0.9307164344400611\n",
      "          Validation Loss (standardized): 0.8387698387970596\n",
      "Epoch: 16, Loss (standarized): 0.9113012217028069\n",
      "          Validation Loss (standardized): 0.7998060784637535\n",
      "Epoch: 21, Loss (standarized): 0.6595919825346954\n",
      "          Validation Loss (standardized): 0.6059906973676152\n",
      "Epoch: 26, Loss (standarized): 0.562336267955643\n",
      "          Validation Loss (standardized): 0.5834875859095757\n",
      "Epoch: 31, Loss (standarized): 0.5352884480917842\n",
      "          Validation Loss (standardized): 0.5729682222006209\n",
      "Epoch: 36, Loss (standarized): 0.4771468097071854\n",
      "          Validation Loss (standardized): 0.5117940726802906\n",
      "Epoch: 41, Loss (standarized): 0.43565903924674476\n",
      "          Validation Loss (standardized): 0.47385011241657254\n",
      "Epoch: 46, Loss (standarized): 0.42424138165378356\n",
      "          Validation Loss (standardized): 0.45427571545314493\n",
      "Epoch: 51, Loss (standarized): 0.4203065954531347\n",
      "          Validation Loss (standardized): 0.4422834641951082\n",
      "Epoch: 56, Loss (standarized): 0.4098008554522229\n",
      "          Validation Loss (standardized): 0.4333259875076891\n",
      "Epoch: 61, Loss (standarized): 0.40172589980623236\n",
      "          Validation Loss (standardized): 0.4266526648100063\n",
      "Epoch: 66, Loss (standarized): 0.39496476028444877\n",
      "          Validation Loss (standardized): 0.420425112159582\n",
      "Epoch: 71, Loss (standarized): 0.3783036689171372\n",
      "          Validation Loss (standardized): 0.4039439703181017\n",
      "Epoch: 76, Loss (standarized): 0.37388423089495565\n",
      "          Validation Loss (standardized): 0.3964512868514102\n",
      "Epoch: 81, Loss (standarized): 0.3626839834739869\n",
      "          Validation Loss (standardized): 0.39205397117506635\n",
      "Epoch: 86, Loss (standarized): 0.3582745281376908\n",
      "          Validation Loss (standardized): 0.3844860610258661\n",
      "Epoch: 91, Loss (standarized): 0.34957458194778396\n",
      "          Validation Loss (standardized): 0.3803719721260124\n",
      "Epoch: 96, Loss (standarized): 0.3432613724463794\n",
      "          Validation Loss (standardized): 0.37706020376974125\n",
      "Final epoch: 100, Final loss (standarized): 0.33777079309508884\n",
      "Epoch: 1, Loss (standarized): 4.2930635115350855\n",
      "          Validation Loss (standardized): 2.7367870247300994\n",
      "Epoch: 6, Loss (standarized): 0.7853891008999969\n",
      "          Validation Loss (standardized): 0.8150836833759371\n",
      "Epoch: 11, Loss (standarized): 1.1486938317337172\n",
      "          Validation Loss (standardized): 1.1392825323025457\n",
      "Epoch: 16, Loss (standarized): 0.7581052438479732\n",
      "          Validation Loss (standardized): 0.7495558791002596\n",
      "Epoch: 21, Loss (standarized): 0.6623726529456525\n",
      "          Validation Loss (standardized): 0.6871504704662579\n",
      "Epoch: 26, Loss (standarized): 0.6649490855518299\n",
      "          Validation Loss (standardized): 0.6301018691924714\n",
      "Epoch: 31, Loss (standarized): 0.5407040418119033\n",
      "          Validation Loss (standardized): 0.5233970739252825\n",
      "Epoch: 36, Loss (standarized): 0.49538290409402136\n",
      "          Validation Loss (standardized): 0.5287352006214413\n",
      "Epoch: 41, Loss (standarized): 0.46025025616648635\n",
      "          Validation Loss (standardized): 0.48842350931165307\n",
      "Epoch: 46, Loss (standarized): 0.41753367459174884\n",
      "          Validation Loss (standardized): 0.43685344141754384\n",
      "Epoch: 51, Loss (standarized): 0.41072367089208345\n",
      "          Validation Loss (standardized): 0.44014822566805967\n",
      "Epoch: 56, Loss (standarized): 0.39953947729371747\n",
      "          Validation Loss (standardized): 0.42731322454048093\n",
      "Epoch: 61, Loss (standarized): 0.38892291093682185\n",
      "          Validation Loss (standardized): 0.4293066969392595\n",
      "Epoch: 66, Loss (standarized): 0.376826772491233\n",
      "          Validation Loss (standardized): 0.40946293474229123\n",
      "Epoch: 71, Loss (standarized): 0.3689301899970373\n",
      "          Validation Loss (standardized): 0.39719812387192904\n",
      "Epoch: 76, Loss (standarized): 0.3572123442667375\n",
      "          Validation Loss (standardized): 0.3902367784675907\n",
      "Epoch: 81, Loss (standarized): 0.34817742224737797\n",
      "          Validation Loss (standardized): 0.3781266645486727\n",
      "Epoch: 86, Loss (standarized): 0.3394136069241854\n",
      "          Validation Loss (standardized): 0.3710545185193844\n",
      "Epoch: 91, Loss (standarized): 0.33192783513395474\n",
      "          Validation Loss (standardized): 0.36149013148291376\n",
      "Epoch: 96, Loss (standarized): 0.32482140908391066\n",
      "          Validation Loss (standardized): 0.35292975143612326\n",
      "Final epoch: 100, Final loss (standarized): 0.319731874435405\n",
      "Epoch: 1, Loss (standarized): 3.232415844010074\n",
      "          Validation Loss (standardized): 2.4193997406272127\n",
      "Epoch: 6, Loss (standarized): 0.691385325789224\n",
      "          Validation Loss (standardized): 0.6606883103558951\n",
      "Epoch: 11, Loss (standarized): 0.9729257188860302\n",
      "          Validation Loss (standardized): 0.765606002347327\n",
      "Epoch: 16, Loss (standarized): 0.662401854713163\n",
      "          Validation Loss (standardized): 0.6057402644658553\n",
      "Epoch: 21, Loss (standarized): 0.5921972406671469\n",
      "          Validation Loss (standardized): 0.65922720108629\n",
      "Epoch: 26, Loss (standarized): 0.5277052771812436\n",
      "          Validation Loss (standardized): 0.5333995638413117\n",
      "Epoch: 31, Loss (standarized): 0.49459963573548754\n",
      "          Validation Loss (standardized): 0.47541414726399345\n",
      "Epoch: 36, Loss (standarized): 0.4362612210720679\n",
      "          Validation Loss (standardized): 0.47967255567499295\n",
      "Epoch: 41, Loss (standarized): 0.4192693668955558\n",
      "          Validation Loss (standardized): 0.43772068287332233\n",
      "Epoch: 46, Loss (standarized): 0.41331383018503054\n",
      "          Validation Loss (standardized): 0.43392621315168844\n",
      "Epoch: 51, Loss (standarized): 0.40470560391333743\n",
      "          Validation Loss (standardized): 0.44582691046699696\n",
      "Epoch: 56, Loss (standarized): 0.39813674901592605\n",
      "          Validation Loss (standardized): 0.4274994331149\n",
      "Epoch: 61, Loss (standarized): 0.39134773236134296\n",
      "          Validation Loss (standardized): 0.43290882939741254\n",
      "Epoch: 66, Loss (standarized): 0.3842391287928952\n",
      "          Validation Loss (standardized): 0.4120080992210607\n",
      "Epoch: 71, Loss (standarized): 0.3786600409201211\n",
      "          Validation Loss (standardized): 0.41286870874287357\n",
      "Epoch: 76, Loss (standarized): 0.37270095074427034\n",
      "          Validation Loss (standardized): 0.40236914931131745\n",
      "Epoch: 81, Loss (standarized): 0.36669884047560597\n",
      "          Validation Loss (standardized): 0.40395918882926635\n",
      "Epoch: 86, Loss (standarized): 0.361084784093807\n",
      "          Validation Loss (standardized): 0.39602592408848564\n",
      "Epoch: 91, Loss (standarized): 0.35525579344218616\n",
      "          Validation Loss (standardized): 0.39392694350238217\n",
      "Epoch: 96, Loss (standarized): 0.34976996677934213\n",
      "          Validation Loss (standardized): 0.3869844089604286\n",
      "Final epoch: 100, Final loss (standarized): 0.3450523237817767\n",
      "Epoch: 1, Loss (standarized): 0.8025928139223508\n",
      "          Validation Loss (standardized): 0.7876108141385763\n",
      "Epoch: 6, Loss (standarized): 0.7250208601512703\n",
      "          Validation Loss (standardized): 0.7070545321271154\n",
      "Epoch: 11, Loss (standarized): 0.6051709082502471\n",
      "          Validation Loss (standardized): 0.581203511074075\n",
      "Epoch: 16, Loss (standarized): 0.5182940372193177\n",
      "          Validation Loss (standardized): 0.5322123197548003\n",
      "Epoch: 21, Loss (standarized): 0.4615638721585298\n",
      "          Validation Loss (standardized): 0.5124647196533071\n",
      "Epoch: 26, Loss (standarized): 0.42793740507418326\n",
      "          Validation Loss (standardized): 0.4706268309754099\n",
      "Epoch: 31, Loss (standarized): 0.41163968690660824\n",
      "          Validation Loss (standardized): 0.4694065009431945\n",
      "Epoch: 36, Loss (standarized): 0.39294876099625187\n",
      "          Validation Loss (standardized): 0.4460528603953554\n",
      "Epoch: 41, Loss (standarized): 0.3754698868613395\n",
      "          Validation Loss (standardized): 0.43793608145519675\n",
      "Epoch: 46, Loss (standarized): 0.3610430656634882\n",
      "          Validation Loss (standardized): 0.4082631231900333\n",
      "Epoch: 51, Loss (standarized): 0.34779941192932207\n",
      "          Validation Loss (standardized): 0.38920446982903767\n",
      "Epoch: 56, Loss (standarized): 0.3364446394106984\n",
      "          Validation Loss (standardized): 0.36950031550694007\n",
      "Epoch: 61, Loss (standarized): 0.32632540186064724\n",
      "          Validation Loss (standardized): 0.3519808361279821\n",
      "Epoch: 66, Loss (standarized): 0.3158956617251098\n",
      "          Validation Loss (standardized): 0.34379189585413483\n",
      "Epoch: 71, Loss (standarized): 0.3060128223502287\n",
      "          Validation Loss (standardized): 0.3370158544752951\n",
      "Epoch: 76, Loss (standarized): 0.29707227927096297\n",
      "          Validation Loss (standardized): 0.33079728041849377\n",
      "Epoch: 81, Loss (standarized): 0.2894174008956184\n",
      "          Validation Loss (standardized): 0.32510137955698964\n",
      "Epoch: 86, Loss (standarized): 0.28239303395327753\n",
      "          Validation Loss (standardized): 0.3197792698565392\n",
      "Epoch: 91, Loss (standarized): 0.27567463263065556\n",
      "          Validation Loss (standardized): 0.31676642802704646\n",
      "Epoch: 96, Loss (standarized): 0.27001354850974807\n",
      "          Validation Loss (standardized): 0.31239364754458604\n",
      "Final epoch: 100, Final loss (standarized): 0.2676371915716852\n",
      "Epoch: 1, Loss (standarized): 7.812124488507328\n",
      "          Validation Loss (standardized): 4.482620388152465\n",
      "Epoch: 6, Loss (standarized): 0.7759951638443969\n",
      "          Validation Loss (standardized): 0.9618162252830358\n",
      "Epoch: 11, Loss (standarized): 1.4808219442676314\n",
      "          Validation Loss (standardized): 1.487315032967901\n",
      "Epoch: 16, Loss (standarized): 0.8081640224212887\n",
      "          Validation Loss (standardized): 0.7817421158810012\n",
      "Epoch: 21, Loss (standarized): 0.6304928019307676\n",
      "          Validation Loss (standardized): 0.6763159062422958\n",
      "Epoch: 26, Loss (standarized): 0.6624347762107887\n",
      "          Validation Loss (standardized): 0.6596023175141899\n",
      "Epoch: 31, Loss (standarized): 0.49967749976995196\n",
      "          Validation Loss (standardized): 0.5562146234532733\n",
      "Epoch: 36, Loss (standarized): 0.45518882826178625\n",
      "          Validation Loss (standardized): 0.5801767152541869\n",
      "Epoch: 41, Loss (standarized): 0.4686744139354195\n",
      "          Validation Loss (standardized): 0.5653446706762422\n",
      "Epoch: 46, Loss (standarized): 0.4328108755289712\n",
      "          Validation Loss (standardized): 0.513696202735367\n",
      "Epoch: 51, Loss (standarized): 0.4234970409204018\n",
      "          Validation Loss (standardized): 0.49259528659254115\n",
      "Epoch: 56, Loss (standarized): 0.41774528515036036\n",
      "          Validation Loss (standardized): 0.47502754167198696\n",
      "Epoch: 61, Loss (standarized): 0.4001015468204553\n",
      "          Validation Loss (standardized): 0.45591052264849596\n",
      "Epoch: 66, Loss (standarized): 0.3917368897378732\n",
      "          Validation Loss (standardized): 0.4511290283691197\n",
      "Epoch: 71, Loss (standarized): 0.38070569410504174\n",
      "          Validation Loss (standardized): 0.4413366186000735\n",
      "Epoch: 76, Loss (standarized): 0.3725355785227252\n",
      "          Validation Loss (standardized): 0.4287108157508493\n",
      "Epoch: 81, Loss (standarized): 0.3674786222021508\n",
      "          Validation Loss (standardized): 0.4180679223509901\n",
      "Epoch: 86, Loss (standarized): 0.36040838076696136\n",
      "          Validation Loss (standardized): 0.4146162503101044\n",
      "Epoch: 91, Loss (standarized): 0.3548336322132125\n",
      "          Validation Loss (standardized): 0.4056568609920708\n",
      "Epoch: 96, Loss (standarized): 0.3495155476984374\n",
      "          Validation Loss (standardized): 0.40031918091436536\n",
      "Final epoch: 100, Final loss (standarized): 0.34546285481774364\n",
      "Epoch: 1, Loss (standarized): 1.1620431644930425\n",
      "          Validation Loss (standardized): 0.7659511242126249\n",
      "Epoch: 6, Loss (standarized): 0.6784876995107835\n",
      "          Validation Loss (standardized): 0.6965304005116244\n",
      "Epoch: 11, Loss (standarized): 0.5644304204692999\n",
      "          Validation Loss (standardized): 0.5573058349721858\n",
      "Epoch: 16, Loss (standarized): 0.48440047004942227\n",
      "          Validation Loss (standardized): 0.5551672031082648\n",
      "Epoch: 21, Loss (standarized): 0.4330447635240445\n",
      "          Validation Loss (standardized): 0.46298013583855935\n",
      "Epoch: 26, Loss (standarized): 0.4153322338644373\n",
      "          Validation Loss (standardized): 0.4998462695119582\n",
      "Epoch: 31, Loss (standarized): 0.4125630612815546\n",
      "          Validation Loss (standardized): 0.46832258605460425\n",
      "Epoch: 36, Loss (standarized): 0.40633942641955284\n",
      "          Validation Loss (standardized): 0.47864248881178056\n",
      "Epoch: 41, Loss (standarized): 0.395852495627672\n",
      "          Validation Loss (standardized): 0.4698916823763797\n",
      "Epoch: 46, Loss (standarized): 0.38571774192878666\n",
      "          Validation Loss (standardized): 0.45016225149177386\n",
      "Epoch: 51, Loss (standarized): 0.37803283585345576\n",
      "          Validation Loss (standardized): 0.4501641308777204\n",
      "Epoch: 56, Loss (standarized): 0.3710236992087842\n",
      "          Validation Loss (standardized): 0.43583349352281675\n",
      "Epoch: 61, Loss (standarized): 0.36436988515674423\n",
      "          Validation Loss (standardized): 0.42325264502698123\n",
      "Epoch: 66, Loss (standarized): 0.3575913482150469\n",
      "          Validation Loss (standardized): 0.41172053616600396\n",
      "Epoch: 71, Loss (standarized): 0.34869543750343934\n",
      "          Validation Loss (standardized): 0.4040716948312233\n",
      "Epoch: 76, Loss (standarized): 0.3377718262404391\n",
      "          Validation Loss (standardized): 0.38989726142557146\n",
      "Epoch: 81, Loss (standarized): 0.32728075197367873\n",
      "          Validation Loss (standardized): 0.37646866468745244\n",
      "Epoch: 86, Loss (standarized): 0.3181960608596452\n",
      "          Validation Loss (standardized): 0.36831627451615245\n",
      "Epoch: 91, Loss (standarized): 0.3088766242177849\n",
      "          Validation Loss (standardized): 0.3561116799679847\n",
      "Epoch: 96, Loss (standarized): 0.29931456240376736\n",
      "          Validation Loss (standardized): 0.34474993866866\n",
      "Final epoch: 100, Final loss (standarized): 0.29116906829407546\n",
      "Epoch: 1, Loss (standarized): 1.3093017653840577\n",
      "          Validation Loss (standardized): 0.8390288249459009\n",
      "Epoch: 6, Loss (standarized): 0.8029280992482208\n",
      "          Validation Loss (standardized): 0.7271573243675624\n",
      "Epoch: 11, Loss (standarized): 0.614727748615544\n",
      "          Validation Loss (standardized): 0.6482785957223901\n",
      "Epoch: 16, Loss (standarized): 0.49753152829299\n",
      "          Validation Loss (standardized): 0.5561734753786705\n",
      "Epoch: 21, Loss (standarized): 0.4907097023310006\n",
      "          Validation Loss (standardized): 0.4977056367041617\n",
      "Epoch: 26, Loss (standarized): 0.458762319999629\n",
      "          Validation Loss (standardized): 0.5354068975449695\n",
      "Epoch: 31, Loss (standarized): 0.4338781852248772\n",
      "          Validation Loss (standardized): 0.4780545422363868\n",
      "Epoch: 36, Loss (standarized): 0.42322872247797394\n",
      "          Validation Loss (standardized): 0.45860998457306507\n",
      "Epoch: 41, Loss (standarized): 0.406208603781519\n",
      "          Validation Loss (standardized): 0.4645353773962331\n",
      "Epoch: 46, Loss (standarized): 0.39350610923330537\n",
      "          Validation Loss (standardized): 0.4286545778852687\n",
      "Epoch: 51, Loss (standarized): 0.37848397971453757\n",
      "          Validation Loss (standardized): 0.4175047347675023\n",
      "Epoch: 56, Loss (standarized): 0.3662051344761129\n",
      "          Validation Loss (standardized): 0.41874582308570046\n",
      "Epoch: 61, Loss (standarized): 0.35806930957262617\n",
      "          Validation Loss (standardized): 0.3975049736932191\n",
      "Epoch: 66, Loss (standarized): 0.3492429518600178\n",
      "          Validation Loss (standardized): 0.38866143867098457\n",
      "Epoch: 71, Loss (standarized): 0.34100508229163423\n",
      "          Validation Loss (standardized): 0.38235212407411184\n",
      "Epoch: 76, Loss (standarized): 0.33321437819262834\n",
      "          Validation Loss (standardized): 0.37005477057619596\n",
      "Epoch: 81, Loss (standarized): 0.32510408745879593\n",
      "          Validation Loss (standardized): 0.36062803212236516\n",
      "Epoch: 86, Loss (standarized): 0.31695150959125185\n",
      "          Validation Loss (standardized): 0.3516730527320786\n",
      "Epoch: 91, Loss (standarized): 0.3058982190604792\n",
      "          Validation Loss (standardized): 0.3425150280921861\n",
      "Epoch: 96, Loss (standarized): 0.2976618310566975\n",
      "          Validation Loss (standardized): 0.3339960530868403\n",
      "Final epoch: 100, Final loss (standarized): 0.2928989395715434\n",
      "Epoch: 1, Loss (standarized): 4.057098004546316\n",
      "          Validation Loss (standardized): 2.431621616091344\n",
      "Epoch: 6, Loss (standarized): 1.01287793319089\n",
      "          Validation Loss (standardized): 1.007728465359639\n",
      "Epoch: 11, Loss (standarized): 0.9515075523932175\n",
      "          Validation Loss (standardized): 1.0768366093611645\n",
      "Epoch: 16, Loss (standarized): 0.8108305360108595\n",
      "          Validation Loss (standardized): 0.8369800443977894\n",
      "Epoch: 21, Loss (standarized): 0.7363940292637967\n",
      "          Validation Loss (standardized): 0.7049392265787521\n",
      "Epoch: 26, Loss (standarized): 0.6834717166654991\n",
      "          Validation Loss (standardized): 0.6446390660316631\n",
      "Epoch: 31, Loss (standarized): 0.6207794794825059\n",
      "          Validation Loss (standardized): 0.6253777992521364\n",
      "Epoch: 36, Loss (standarized): 0.5842027943416153\n",
      "          Validation Loss (standardized): 0.6101742986338377\n",
      "Epoch: 41, Loss (standarized): 0.5384211052075988\n",
      "          Validation Loss (standardized): 0.5515340982526782\n",
      "Epoch: 46, Loss (standarized): 0.5042899837379333\n",
      "          Validation Loss (standardized): 0.5004384316374061\n",
      "Epoch: 51, Loss (standarized): 0.47573823257647546\n",
      "          Validation Loss (standardized): 0.4872158870181246\n",
      "Epoch: 56, Loss (standarized): 0.45227871564230676\n",
      "          Validation Loss (standardized): 0.4901343853202165\n",
      "Epoch: 61, Loss (standarized): 0.4387977776724781\n",
      "          Validation Loss (standardized): 0.4653485933062691\n",
      "Epoch: 66, Loss (standarized): 0.4273958383088761\n",
      "          Validation Loss (standardized): 0.46502154605350354\n",
      "Epoch: 71, Loss (standarized): 0.42008522597510245\n",
      "          Validation Loss (standardized): 0.4603520941488226\n",
      "Epoch: 76, Loss (standarized): 0.414664389151805\n",
      "          Validation Loss (standardized): 0.45498407471836094\n",
      "Epoch: 81, Loss (standarized): 0.4100656716578703\n",
      "          Validation Loss (standardized): 0.45211928140372004\n",
      "Epoch: 86, Loss (standarized): 0.40577554947304034\n",
      "          Validation Loss (standardized): 0.4475687102712915\n",
      "Epoch: 91, Loss (standarized): 0.40207180343480575\n",
      "          Validation Loss (standardized): 0.4421900727889006\n",
      "Epoch: 96, Loss (standarized): 0.398116053100952\n",
      "          Validation Loss (standardized): 0.4387730171350278\n",
      "Final epoch: 100, Final loss (standarized): 0.3952451110610896\n",
      "Epoch: 1, Loss (standarized): 2.2147747099516573\n",
      "          Validation Loss (standardized): 1.0443761652667225\n",
      "Epoch: 6, Loss (standarized): 1.0417531194523133\n",
      "          Validation Loss (standardized): 1.2188415331760785\n",
      "Epoch: 11, Loss (standarized): 0.827414216349504\n",
      "          Validation Loss (standardized): 0.776019004309496\n",
      "Epoch: 16, Loss (standarized): 0.7478534724877548\n",
      "          Validation Loss (standardized): 0.7183108544093151\n",
      "Epoch: 21, Loss (standarized): 0.6589078196750948\n",
      "          Validation Loss (standardized): 0.6487018301032563\n",
      "Epoch: 26, Loss (standarized): 0.6182832088229272\n",
      "          Validation Loss (standardized): 0.6788803320666277\n",
      "Epoch: 31, Loss (standarized): 0.557740538946066\n",
      "          Validation Loss (standardized): 0.5809913996215452\n",
      "Epoch: 36, Loss (standarized): 0.529845948598792\n",
      "          Validation Loss (standardized): 0.5495056303764843\n",
      "Epoch: 41, Loss (standarized): 0.4966597601847165\n",
      "          Validation Loss (standardized): 0.5390822681603231\n",
      "Epoch: 46, Loss (standarized): 0.47857904880136104\n",
      "          Validation Loss (standardized): 0.5063489905658465\n",
      "Epoch: 51, Loss (standarized): 0.46811017394863547\n",
      "          Validation Loss (standardized): 0.5021311846267106\n",
      "Epoch: 56, Loss (standarized): 0.45804747672660734\n",
      "          Validation Loss (standardized): 0.4956950551786191\n",
      "Epoch: 61, Loss (standarized): 0.4507468688139447\n",
      "          Validation Loss (standardized): 0.47993126960038174\n",
      "Epoch: 66, Loss (standarized): 0.4445306979027766\n",
      "          Validation Loss (standardized): 0.48383964458617695\n",
      "Epoch: 71, Loss (standarized): 0.4414348031577475\n",
      "          Validation Loss (standardized): 0.48035838687120797\n",
      "Epoch: 76, Loss (standarized): 0.4376994393920922\n",
      "          Validation Loss (standardized): 0.47615315937357067\n",
      "Epoch: 81, Loss (standarized): 0.43510452849917713\n",
      "          Validation Loss (standardized): 0.47711310497121706\n",
      "Epoch: 86, Loss (standarized): 0.4341694262323029\n",
      "          Validation Loss (standardized): 0.4754924176569407\n",
      "Epoch: 91, Loss (standarized): 0.4336845422403918\n",
      "          Validation Loss (standardized): 0.47547090553042926\n",
      "Epoch: 96, Loss (standarized): 0.43309020623505046\n",
      "          Validation Loss (standardized): 0.47546825315583313\n",
      "Final epoch: 100, Final loss (standarized): 0.4332266289347976\n",
      "Epoch: 1, Loss (standarized): 1.101743183916201\n",
      "          Validation Loss (standardized): 0.8167429302550946\n",
      "Epoch: 6, Loss (standarized): 0.7753131081630368\n",
      "          Validation Loss (standardized): 0.7692755604261537\n",
      "Epoch: 11, Loss (standarized): 0.6448838157798429\n",
      "          Validation Loss (standardized): 0.6823547120177323\n",
      "Epoch: 16, Loss (standarized): 0.6007135885353283\n",
      "          Validation Loss (standardized): 0.6094768186146691\n",
      "Epoch: 21, Loss (standarized): 0.5363260324416119\n",
      "          Validation Loss (standardized): 0.5715168543391003\n",
      "Epoch: 26, Loss (standarized): 0.4909139642273869\n",
      "          Validation Loss (standardized): 0.5277788716977994\n",
      "Epoch: 31, Loss (standarized): 0.46496152901865423\n",
      "          Validation Loss (standardized): 0.5068236102486678\n",
      "Epoch: 36, Loss (standarized): 0.4501347957552898\n",
      "          Validation Loss (standardized): 0.4820911310856235\n",
      "Epoch: 41, Loss (standarized): 0.42909970267402403\n",
      "          Validation Loss (standardized): 0.48714146296339145\n",
      "Epoch: 46, Loss (standarized): 0.4235914485890099\n",
      "          Validation Loss (standardized): 0.4609524758342573\n",
      "Epoch: 51, Loss (standarized): 0.4165036200679154\n",
      "          Validation Loss (standardized): 0.46799988318551244\n",
      "Epoch: 56, Loss (standarized): 0.4151353624793238\n",
      "          Validation Loss (standardized): 0.4634194910275235\n",
      "Epoch: 61, Loss (standarized): 0.41488074884218334\n",
      "          Validation Loss (standardized): 0.45367082407612075\n",
      "Epoch: 66, Loss (standarized): 0.4139246619946503\n",
      "          Validation Loss (standardized): 0.45804917493672037\n",
      "Epoch: 71, Loss (standarized): 0.41230595634363193\n",
      "          Validation Loss (standardized): 0.4571740807066422\n",
      "Epoch: 76, Loss (standarized): 0.4094423006921886\n",
      "          Validation Loss (standardized): 0.4542173597148249\n",
      "Epoch: 81, Loss (standarized): 0.4069235994072831\n",
      "          Validation Loss (standardized): 0.4513221325489066\n",
      "Epoch: 86, Loss (standarized): 0.4033970219267431\n",
      "          Validation Loss (standardized): 0.4483895593029113\n",
      "Epoch: 91, Loss (standarized): 0.3994210205639002\n",
      "          Validation Loss (standardized): 0.44418641570181705\n",
      "Epoch: 96, Loss (standarized): 0.3960363688734251\n",
      "          Validation Loss (standardized): 0.4406195144229127\n",
      "Final epoch: 100, Final loss (standarized): 0.39268109274112295\n",
      "Epoch: 1, Loss (standarized): 1.0692242453364418\n",
      "          Validation Loss (standardized): 0.8540056700835353\n",
      "Epoch: 6, Loss (standarized): 0.6900473774336259\n",
      "          Validation Loss (standardized): 0.7009721166457475\n",
      "Epoch: 11, Loss (standarized): 0.6125653782480758\n",
      "          Validation Loss (standardized): 0.6670831076671808\n",
      "Epoch: 16, Loss (standarized): 0.524188796944518\n",
      "          Validation Loss (standardized): 0.5363532839365769\n",
      "Epoch: 21, Loss (standarized): 0.48389049979200804\n",
      "          Validation Loss (standardized): 0.5195365437232169\n",
      "Epoch: 26, Loss (standarized): 0.4501544750304992\n",
      "          Validation Loss (standardized): 0.4795291744109635\n",
      "Epoch: 31, Loss (standarized): 0.4333288626889649\n",
      "          Validation Loss (standardized): 0.48990665470556055\n",
      "Epoch: 36, Loss (standarized): 0.426150685535516\n",
      "          Validation Loss (standardized): 0.47340972233368633\n",
      "Epoch: 41, Loss (standarized): 0.4238760279648509\n",
      "          Validation Loss (standardized): 0.47918500435141853\n",
      "Epoch: 46, Loss (standarized): 0.4229899697922125\n",
      "          Validation Loss (standardized): 0.46627799935584024\n",
      "Epoch: 51, Loss (standarized): 0.4202605937191624\n",
      "          Validation Loss (standardized): 0.47326275483184366\n",
      "Epoch: 56, Loss (standarized): 0.42102576976951794\n",
      "          Validation Loss (standardized): 0.47735836022177053\n",
      "Epoch: 61, Loss (standarized): 0.42341896058852413\n",
      "          Validation Loss (standardized): 0.4758011791665788\n",
      "Epoch: 66, Loss (standarized): 0.42254604193043904\n",
      "          Validation Loss (standardized): 0.4752641212537374\n",
      "Epoch: 71, Loss (standarized): 0.4215416447759127\n",
      "          Validation Loss (standardized): 0.4694437975335438\n",
      "Epoch: 76, Loss (standarized): 0.4197051436365717\n",
      "          Validation Loss (standardized): 0.4692752263025314\n",
      "Epoch: 81, Loss (standarized): 0.4181174587321096\n",
      "          Validation Loss (standardized): 0.4674942298925197\n",
      "Epoch: 86, Loss (standarized): 0.41731018526037983\n",
      "          Validation Loss (standardized): 0.464339552311126\n",
      "Epoch: 91, Loss (standarized): 0.4159917467502076\n",
      "          Validation Loss (standardized): 0.46009462887546076\n",
      "Epoch: 96, Loss (standarized): 0.41366697692544285\n",
      "          Validation Loss (standardized): 0.45778744549194017\n",
      "Final epoch: 100, Final loss (standarized): 0.41143831436977285\n",
      "Epoch: 1, Loss (standarized): 1.6365326706865795\n",
      "          Validation Loss (standardized): 1.004180359000756\n",
      "Epoch: 6, Loss (standarized): 0.8957346072521908\n",
      "          Validation Loss (standardized): 0.7985726396353781\n",
      "Epoch: 11, Loss (standarized): 0.609330421591167\n",
      "          Validation Loss (standardized): 0.6660087708242745\n",
      "Epoch: 16, Loss (standarized): 0.6255419466720319\n",
      "          Validation Loss (standardized): 0.6424106510169775\n",
      "Epoch: 21, Loss (standarized): 0.5157143247109287\n",
      "          Validation Loss (standardized): 0.5529029006395088\n",
      "Epoch: 26, Loss (standarized): 0.4995981548110759\n",
      "          Validation Loss (standardized): 0.5170603211367455\n",
      "Epoch: 31, Loss (standarized): 0.4620388244213062\n",
      "          Validation Loss (standardized): 0.540405953216008\n",
      "Epoch: 36, Loss (standarized): 0.45468854780097506\n",
      "          Validation Loss (standardized): 0.504336631086503\n",
      "Epoch: 41, Loss (standarized): 0.43209004208694635\n",
      "          Validation Loss (standardized): 0.4735450803170235\n",
      "Epoch: 46, Loss (standarized): 0.4157125585040638\n",
      "          Validation Loss (standardized): 0.46817918843627665\n",
      "Epoch: 51, Loss (standarized): 0.40617118373215655\n",
      "          Validation Loss (standardized): 0.4526926749329243\n",
      "Epoch: 56, Loss (standarized): 0.39558470102925763\n",
      "          Validation Loss (standardized): 0.43247580425145854\n",
      "Epoch: 61, Loss (standarized): 0.3848139027778868\n",
      "          Validation Loss (standardized): 0.4227244462194221\n",
      "Epoch: 66, Loss (standarized): 0.3730554874523373\n",
      "          Validation Loss (standardized): 0.41598592242812543\n",
      "Epoch: 71, Loss (standarized): 0.3647294738202542\n",
      "          Validation Loss (standardized): 0.4102426161933458\n",
      "Epoch: 76, Loss (standarized): 0.3558934548073772\n",
      "          Validation Loss (standardized): 0.3978501773263968\n",
      "Epoch: 81, Loss (standarized): 0.3471898645500168\n",
      "          Validation Loss (standardized): 0.3920687850127256\n",
      "Epoch: 86, Loss (standarized): 0.33910000709543436\n",
      "          Validation Loss (standardized): 0.3804226174946821\n",
      "Epoch: 91, Loss (standarized): 0.33108070498560815\n",
      "          Validation Loss (standardized): 0.3694855759799352\n",
      "Epoch: 96, Loss (standarized): 0.32244230818888314\n",
      "          Validation Loss (standardized): 0.36050712767326404\n",
      "Final epoch: 100, Final loss (standarized): 0.31574367034944667\n",
      "Epoch: 1, Loss (standarized): 1.4352567700278047\n",
      "          Validation Loss (standardized): 0.8669241901361928\n",
      "Epoch: 6, Loss (standarized): 0.8721472663234036\n",
      "          Validation Loss (standardized): 0.9726525978686508\n",
      "Epoch: 11, Loss (standarized): 0.7003343723056673\n",
      "          Validation Loss (standardized): 0.7131032388422207\n",
      "Epoch: 16, Loss (standarized): 0.6849479336032948\n",
      "          Validation Loss (standardized): 0.6442474957864336\n",
      "Epoch: 21, Loss (standarized): 0.5948705036084446\n",
      "          Validation Loss (standardized): 0.5939096554349631\n",
      "Epoch: 26, Loss (standarized): 0.5455777825354413\n",
      "          Validation Loss (standardized): 0.5814003489013398\n",
      "Epoch: 31, Loss (standarized): 0.481716417388265\n",
      "          Validation Loss (standardized): 0.48522852228979246\n",
      "Epoch: 36, Loss (standarized): 0.4421057797892175\n",
      "          Validation Loss (standardized): 0.4760921886045526\n",
      "Epoch: 41, Loss (standarized): 0.418592128351065\n",
      "          Validation Loss (standardized): 0.4513137367257535\n",
      "Epoch: 46, Loss (standarized): 0.40803202879770045\n",
      "          Validation Loss (standardized): 0.46266997967820556\n",
      "Epoch: 51, Loss (standarized): 0.3992190939209198\n",
      "          Validation Loss (standardized): 0.44178331940485877\n",
      "Epoch: 56, Loss (standarized): 0.3920514151395448\n",
      "          Validation Loss (standardized): 0.4324889976885376\n",
      "Epoch: 61, Loss (standarized): 0.3875895705784973\n",
      "          Validation Loss (standardized): 0.4314527596467712\n",
      "Epoch: 66, Loss (standarized): 0.38261103104942196\n",
      "          Validation Loss (standardized): 0.42449918702662714\n",
      "Epoch: 71, Loss (standarized): 0.3764071967638465\n",
      "          Validation Loss (standardized): 0.41865333786791553\n",
      "Epoch: 76, Loss (standarized): 0.3705103091035372\n",
      "          Validation Loss (standardized): 0.41613973862528864\n",
      "Epoch: 81, Loss (standarized): 0.365937251709858\n",
      "          Validation Loss (standardized): 0.41294031686322846\n",
      "Epoch: 86, Loss (standarized): 0.36178307905359225\n",
      "          Validation Loss (standardized): 0.40898168076127034\n",
      "Epoch: 91, Loss (standarized): 0.3574987490715532\n",
      "          Validation Loss (standardized): 0.402636038461624\n",
      "Epoch: 96, Loss (standarized): 0.35267640648215753\n",
      "          Validation Loss (standardized): 0.39860766282830523\n",
      "Final epoch: 100, Final loss (standarized): 0.3485264801099822\n",
      "Epoch: 1, Loss (standarized): 1.3579430918760473\n",
      "          Validation Loss (standardized): 0.9083892285376497\n",
      "Epoch: 6, Loss (standarized): 0.7994434457114332\n",
      "          Validation Loss (standardized): 0.8501321103084346\n",
      "Epoch: 11, Loss (standarized): 0.6380900024892106\n",
      "          Validation Loss (standardized): 0.6581185612570897\n",
      "Epoch: 16, Loss (standarized): 0.6280146330129298\n",
      "          Validation Loss (standardized): 0.6106574392853852\n",
      "Epoch: 21, Loss (standarized): 0.5499751581049025\n",
      "          Validation Loss (standardized): 0.5956491787622126\n",
      "Epoch: 26, Loss (standarized): 0.5321767565489344\n",
      "          Validation Loss (standardized): 0.5680182545113486\n",
      "Epoch: 31, Loss (standarized): 0.4959872874394158\n",
      "          Validation Loss (standardized): 0.5328649337324781\n",
      "Epoch: 36, Loss (standarized): 0.4776885698062924\n",
      "          Validation Loss (standardized): 0.5034806917336536\n",
      "Epoch: 41, Loss (standarized): 0.45313063316991914\n",
      "          Validation Loss (standardized): 0.4960781225752538\n",
      "Epoch: 46, Loss (standarized): 0.43787554929215877\n",
      "          Validation Loss (standardized): 0.4852946983798144\n",
      "Epoch: 51, Loss (standarized): 0.42518291260662056\n",
      "          Validation Loss (standardized): 0.47461162366744497\n",
      "Epoch: 56, Loss (standarized): 0.4148731649973795\n",
      "          Validation Loss (standardized): 0.4622628451943911\n",
      "Epoch: 61, Loss (standarized): 0.40297582595924075\n",
      "          Validation Loss (standardized): 0.45413477515510164\n",
      "Epoch: 66, Loss (standarized): 0.38983128930600464\n",
      "          Validation Loss (standardized): 0.44028040666245033\n",
      "Epoch: 71, Loss (standarized): 0.3744477790249062\n",
      "          Validation Loss (standardized): 0.4246385795499555\n",
      "Epoch: 76, Loss (standarized): 0.35644291543078427\n",
      "          Validation Loss (standardized): 0.40692544344701814\n",
      "Epoch: 81, Loss (standarized): 0.3420200439523948\n",
      "          Validation Loss (standardized): 0.38923341647227017\n",
      "Epoch: 86, Loss (standarized): 0.32802352920652994\n",
      "          Validation Loss (standardized): 0.37324714611121634\n",
      "Epoch: 91, Loss (standarized): 0.31255327681791806\n",
      "          Validation Loss (standardized): 0.3592971263724335\n",
      "Epoch: 96, Loss (standarized): 0.29775904066071823\n",
      "          Validation Loss (standardized): 0.3385698278560387\n",
      "Final epoch: 100, Final loss (standarized): 0.2858207046238016\n",
      "Epoch: 1, Loss (standarized): 1.7129839016408865\n",
      "          Validation Loss (standardized): 1.4468641079618463\n",
      "Epoch: 6, Loss (standarized): 0.7341043253556562\n",
      "          Validation Loss (standardized): 0.6958143063863125\n",
      "Epoch: 11, Loss (standarized): 0.7550841188917345\n",
      "          Validation Loss (standardized): 0.6714752692636377\n",
      "Epoch: 16, Loss (standarized): 0.6386675422505906\n",
      "          Validation Loss (standardized): 0.6457827933994857\n",
      "Epoch: 21, Loss (standarized): 0.6054253476349005\n",
      "          Validation Loss (standardized): 0.6348420788614403\n",
      "Epoch: 26, Loss (standarized): 0.5575733381035605\n",
      "          Validation Loss (standardized): 0.5581561944186494\n",
      "Epoch: 31, Loss (standarized): 0.5063334262515984\n",
      "          Validation Loss (standardized): 0.5402407236610834\n",
      "Epoch: 36, Loss (standarized): 0.46159373810838134\n",
      "          Validation Loss (standardized): 0.48680423973205433\n",
      "Epoch: 41, Loss (standarized): 0.4271843155512579\n",
      "          Validation Loss (standardized): 0.4755971437371825\n",
      "Epoch: 46, Loss (standarized): 0.41168742268705605\n",
      "          Validation Loss (standardized): 0.4546485240534464\n",
      "Epoch: 51, Loss (standarized): 0.403413594247876\n",
      "          Validation Loss (standardized): 0.45568584718035754\n",
      "Epoch: 56, Loss (standarized): 0.39019014997691975\n",
      "          Validation Loss (standardized): 0.45042904187984356\n",
      "Epoch: 61, Loss (standarized): 0.37686157694046174\n",
      "          Validation Loss (standardized): 0.4318731087676686\n",
      "Epoch: 66, Loss (standarized): 0.3694217203340863\n",
      "          Validation Loss (standardized): 0.4170369347531049\n",
      "Epoch: 71, Loss (standarized): 0.3602654728080449\n",
      "          Validation Loss (standardized): 0.4057324359608691\n",
      "Epoch: 76, Loss (standarized): 0.35114688527796495\n",
      "          Validation Loss (standardized): 0.39898670180735757\n",
      "Epoch: 81, Loss (standarized): 0.34406029536349997\n",
      "          Validation Loss (standardized): 0.3904838730085211\n",
      "Epoch: 86, Loss (standarized): 0.33683468300055897\n",
      "          Validation Loss (standardized): 0.38103307811730003\n",
      "Epoch: 91, Loss (standarized): 0.32938432277654184\n",
      "          Validation Loss (standardized): 0.37266470325916745\n",
      "Epoch: 96, Loss (standarized): 0.3217283880919648\n",
      "          Validation Loss (standardized): 0.3629718978832358\n",
      "Final epoch: 100, Final loss (standarized): 0.3153110899024646\n",
      "Epoch: 1, Loss (standarized): 4.23585910176636\n",
      "          Validation Loss (standardized): 2.6600937981126624\n",
      "Epoch: 6, Loss (standarized): 0.9634418371956525\n",
      "          Validation Loss (standardized): 0.861572865422478\n",
      "Epoch: 11, Loss (standarized): 1.1248345788552072\n",
      "          Validation Loss (standardized): 1.3415590042293246\n",
      "Epoch: 16, Loss (standarized): 0.9294224719398262\n",
      "          Validation Loss (standardized): 0.98680796985265\n",
      "Epoch: 21, Loss (standarized): 0.7367284440179429\n",
      "          Validation Loss (standardized): 0.6986587935498179\n",
      "Epoch: 26, Loss (standarized): 0.7541807959532966\n",
      "          Validation Loss (standardized): 0.6867105353723858\n",
      "Epoch: 31, Loss (standarized): 0.6786840167299337\n",
      "          Validation Loss (standardized): 0.6424892495917347\n",
      "Epoch: 36, Loss (standarized): 0.623216476482536\n",
      "          Validation Loss (standardized): 0.6466452383800404\n",
      "Epoch: 41, Loss (standarized): 0.5871238732129106\n",
      "          Validation Loss (standardized): 0.6314763500814717\n",
      "Epoch: 46, Loss (standarized): 0.5316598044981701\n",
      "          Validation Loss (standardized): 0.5468371569861253\n",
      "Epoch: 51, Loss (standarized): 0.4970005921864164\n",
      "          Validation Loss (standardized): 0.5045132944103635\n",
      "Epoch: 56, Loss (standarized): 0.45956342463858907\n",
      "          Validation Loss (standardized): 0.48849093561512885\n",
      "Epoch: 61, Loss (standarized): 0.432201227089981\n",
      "          Validation Loss (standardized): 0.48812730411408595\n",
      "Epoch: 66, Loss (standarized): 0.4104502019709896\n",
      "          Validation Loss (standardized): 0.4677064137637247\n",
      "Epoch: 71, Loss (standarized): 0.39580964099134797\n",
      "          Validation Loss (standardized): 0.4460904363012175\n",
      "Epoch: 76, Loss (standarized): 0.38483665434479936\n",
      "          Validation Loss (standardized): 0.4486958027397592\n",
      "Epoch: 81, Loss (standarized): 0.3762164235447293\n",
      "          Validation Loss (standardized): 0.4362079308394334\n",
      "Epoch: 86, Loss (standarized): 0.36090675913729153\n",
      "          Validation Loss (standardized): 0.4168181305850603\n",
      "Epoch: 91, Loss (standarized): 0.35404611055015145\n",
      "          Validation Loss (standardized): 0.417245377783142\n",
      "Epoch: 96, Loss (standarized): 0.345268961196497\n",
      "          Validation Loss (standardized): 0.40651461119047044\n",
      "Final epoch: 100, Final loss (standarized): 0.33982277573668007\n",
      "Epoch: 1, Loss (standarized): 1.501214469436499\n",
      "          Validation Loss (standardized): 0.880922613531475\n",
      "Epoch: 6, Loss (standarized): 0.8197843258893727\n",
      "          Validation Loss (standardized): 0.6658780962615891\n",
      "Epoch: 11, Loss (standarized): 0.6471011280686242\n",
      "          Validation Loss (standardized): 0.7220477058244889\n",
      "Epoch: 16, Loss (standarized): 0.5979443910208037\n",
      "          Validation Loss (standardized): 0.6089902730877317\n",
      "Epoch: 21, Loss (standarized): 0.5727602460596423\n",
      "          Validation Loss (standardized): 0.5203971082186051\n",
      "Epoch: 26, Loss (standarized): 0.5112298799268687\n",
      "          Validation Loss (standardized): 0.5567243509394844\n",
      "Epoch: 31, Loss (standarized): 0.4915819929233317\n",
      "          Validation Loss (standardized): 0.512515935622551\n",
      "Epoch: 36, Loss (standarized): 0.4683573972330121\n",
      "          Validation Loss (standardized): 0.48373646256927977\n",
      "Epoch: 41, Loss (standarized): 0.45160372354348804\n",
      "          Validation Loss (standardized): 0.4858365912032207\n",
      "Epoch: 46, Loss (standarized): 0.4365418229488213\n",
      "          Validation Loss (standardized): 0.47098856860620303\n",
      "Epoch: 51, Loss (standarized): 0.42215479288007973\n",
      "          Validation Loss (standardized): 0.4635337525044227\n",
      "Epoch: 56, Loss (standarized): 0.409663483007101\n",
      "          Validation Loss (standardized): 0.45486190474699967\n",
      "Epoch: 61, Loss (standarized): 0.39643888708065667\n",
      "          Validation Loss (standardized): 0.44408820711865404\n",
      "Epoch: 66, Loss (standarized): 0.3841284112334838\n",
      "          Validation Loss (standardized): 0.4357443737043105\n",
      "Epoch: 71, Loss (standarized): 0.3728038613760033\n",
      "          Validation Loss (standardized): 0.42065824019007836\n",
      "Epoch: 76, Loss (standarized): 0.3627131956067558\n",
      "          Validation Loss (standardized): 0.4115744927545238\n",
      "Epoch: 81, Loss (standarized): 0.3534062570334483\n",
      "          Validation Loss (standardized): 0.40103091284719494\n",
      "Epoch: 86, Loss (standarized): 0.3439688631260252\n",
      "          Validation Loss (standardized): 0.3929313522308807\n",
      "Epoch: 91, Loss (standarized): 0.333601833687156\n",
      "          Validation Loss (standardized): 0.3808385621084593\n",
      "Epoch: 96, Loss (standarized): 0.32291200177620727\n",
      "          Validation Loss (standardized): 0.3698946184298937\n",
      "Final epoch: 100, Final loss (standarized): 0.315187233949369\n",
      "Epoch: 1, Loss (standarized): 3.044146439074334\n",
      "          Validation Loss (standardized): 2.6696947493887113\n",
      "Epoch: 6, Loss (standarized): 0.6983616293912128\n",
      "          Validation Loss (standardized): 0.6954857534901755\n",
      "Epoch: 11, Loss (standarized): 0.9849702654928384\n",
      "          Validation Loss (standardized): 0.8242493319063899\n",
      "Epoch: 16, Loss (standarized): 0.6899410450184282\n",
      "          Validation Loss (standardized): 0.6441785933416025\n",
      "Epoch: 21, Loss (standarized): 0.6567501080751521\n",
      "          Validation Loss (standardized): 0.7427274158374015\n",
      "Epoch: 26, Loss (standarized): 0.6550611193058863\n",
      "          Validation Loss (standardized): 0.7234870545951688\n",
      "Epoch: 31, Loss (standarized): 0.6010628112189436\n",
      "          Validation Loss (standardized): 0.6316417027126162\n",
      "Epoch: 36, Loss (standarized): 0.5743701675718479\n",
      "          Validation Loss (standardized): 0.5737195241666878\n",
      "Epoch: 41, Loss (standarized): 0.548097330799407\n",
      "          Validation Loss (standardized): 0.5509764868060962\n",
      "Epoch: 46, Loss (standarized): 0.5070325179818743\n",
      "          Validation Loss (standardized): 0.5355778372631571\n",
      "Epoch: 51, Loss (standarized): 0.47844052889417765\n",
      "          Validation Loss (standardized): 0.5315396071118531\n",
      "Epoch: 56, Loss (standarized): 0.4472605166063689\n",
      "          Validation Loss (standardized): 0.49742360524739465\n",
      "Epoch: 61, Loss (standarized): 0.4098487710873628\n",
      "          Validation Loss (standardized): 0.4495395314531813\n",
      "Epoch: 66, Loss (standarized): 0.38337853044579506\n",
      "          Validation Loss (standardized): 0.42044227418611224\n",
      "Epoch: 71, Loss (standarized): 0.3605184245153954\n",
      "          Validation Loss (standardized): 0.4103520328315515\n",
      "Epoch: 76, Loss (standarized): 0.344791903984067\n",
      "          Validation Loss (standardized): 0.39926975156192734\n",
      "Epoch: 81, Loss (standarized): 0.33126225703229356\n",
      "          Validation Loss (standardized): 0.37501409780238104\n",
      "Epoch: 86, Loss (standarized): 0.31823203804956884\n",
      "          Validation Loss (standardized): 0.35281974599032184\n",
      "Epoch: 91, Loss (standarized): 0.30649706412977995\n",
      "          Validation Loss (standardized): 0.33773743378549087\n",
      "Epoch: 96, Loss (standarized): 0.2962114258849822\n",
      "          Validation Loss (standardized): 0.3282552625647576\n",
      "Final epoch: 100, Final loss (standarized): 0.2878545645097622\n",
      "Epoch: 1, Loss (standarized): 1.1620508007733075\n",
      "          Validation Loss (standardized): 0.8809941313218103\n",
      "Epoch: 6, Loss (standarized): 0.7088465103028749\n",
      "          Validation Loss (standardized): 0.7236507702084389\n",
      "Epoch: 11, Loss (standarized): 0.6529973711663071\n",
      "          Validation Loss (standardized): 0.705229784242857\n",
      "Epoch: 16, Loss (standarized): 0.5551584245344717\n",
      "          Validation Loss (standardized): 0.5458533966098423\n",
      "Epoch: 21, Loss (standarized): 0.492902553962035\n",
      "          Validation Loss (standardized): 0.5162273857342106\n",
      "Epoch: 26, Loss (standarized): 0.44014023212591835\n",
      "          Validation Loss (standardized): 0.46343694261777196\n",
      "Epoch: 31, Loss (standarized): 0.4137166698414151\n",
      "          Validation Loss (standardized): 0.46555162427938795\n",
      "Epoch: 36, Loss (standarized): 0.39205934828994476\n",
      "          Validation Loss (standardized): 0.42844147936970367\n",
      "Epoch: 41, Loss (standarized): 0.3782324182640742\n",
      "          Validation Loss (standardized): 0.41981342900124785\n",
      "Epoch: 46, Loss (standarized): 0.36244069624603564\n",
      "          Validation Loss (standardized): 0.39800395861538185\n",
      "Epoch: 51, Loss (standarized): 0.3488122083428148\n",
      "          Validation Loss (standardized): 0.3791716101886716\n",
      "Epoch: 56, Loss (standarized): 0.33686919008029453\n",
      "          Validation Loss (standardized): 0.37104169363224193\n",
      "Epoch: 61, Loss (standarized): 0.3245920887547548\n",
      "          Validation Loss (standardized): 0.35612749598344046\n",
      "Epoch: 66, Loss (standarized): 0.3117604146652808\n",
      "          Validation Loss (standardized): 0.34386071898480564\n",
      "Epoch: 71, Loss (standarized): 0.2998500824246807\n",
      "          Validation Loss (standardized): 0.33405917153413356\n",
      "Epoch: 76, Loss (standarized): 0.2881059822756901\n",
      "          Validation Loss (standardized): 0.3216278331988849\n",
      "Epoch: 81, Loss (standarized): 0.27075056284006027\n",
      "          Validation Loss (standardized): 0.2983209363364226\n",
      "Epoch: 86, Loss (standarized): 0.2426453603204486\n",
      "          Validation Loss (standardized): 0.2836624275657109\n",
      "Epoch: 91, Loss (standarized): 0.23192727436724941\n",
      "          Validation Loss (standardized): 0.2656459061915989\n",
      "Epoch: 96, Loss (standarized): 0.21895115129442128\n",
      "          Validation Loss (standardized): 0.2627861429831294\n",
      "Final epoch: 100, Final loss (standarized): 0.21128259176998848\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "archs = [[1, 20, 20, 1]]\n",
    "funs = [sigmoid, tanh, relu, leaky_relu]\n",
    "fun_derivs = [sigmoid_deriv, tanh_deriv, relu_deriv, leaky_relu_deriv]\n",
    "dropouts = [0] # Testy dropout'u usunąłem\n",
    "early_stops = [0, 50, 100, 200, 500]  # Patience = 1 jest za mały tak samo = 5 oraz 10 i 20, więc usunąłem\n",
    "l1_vals = [0, 0.01, 0.001, 0.0001]\n",
    "l2_vals = [0, 0.01, 0.001, 0.0001]\n",
    "initialization = [\"xavier\", \"xavier\", \"he\", \"he\"]\n",
    "results = { \"Arch\": [],\n",
    "            \"Fun\": [],\n",
    "            \"Test_loss\": [],\n",
    "            \"Train_results\": [], \n",
    "            \"Dropout\": [],\n",
    "            \"Patience\": [],\n",
    "            \"Net\": [],\n",
    "            \"L1\": [],\n",
    "            \"L2\": [],}\n",
    "\n",
    "for arch in archs:\n",
    "    for i in range(len(funs)):\n",
    "        for dropout in dropouts:\n",
    "            for early_stop in early_stops:\n",
    "                for l1 in l1_vals:\n",
    "                    for l2 in l2_vals:\n",
    "                        net = MLP(arch, act_fun=funs[i], act_derivative=fun_derivs[i], out_fun=linear, out_derivative=linear_deriv, init_type=initialization[i], dropout_rate=dropout)\n",
    "                        curr_result = net.train(x = x_train, y = y_train, epochs = 10000, optimizer=Adam(), batch_size=None, early_stopping_patience=early_stop, val_x=x_test, val_y=y_test, l1_lambda=l1, l2_lambda=l2)\n",
    "                        y_pred = net.predict(x_test)\n",
    "                        test_loss = mse(y_pred, y_test)\n",
    "                        results[\"Arch\"].append(arch)\n",
    "                        results[\"Fun\"].append(funs[i])\n",
    "                        results[\"Test_loss\"].append(test_loss)\n",
    "                        results[\"Train_results\"].append(curr_result)\n",
    "                        results[\"Dropout\"].append(dropout)\n",
    "                        results[\"Patience\"].append(early_stop)\n",
    "                        results[\"Net\"].append(net)\n",
    "                        results[\"L1\"].append(l1)\n",
    "                        results[\"L2\"].append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d35a934b-d962-458b-b62f-ecce3ffc6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(\"Test_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fdf14cbe-515f-4272-b0cd-47e9b456cfa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Test_loss</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>1165.210034</td>\n",
       "      <td>[0.8393655662556828, 0.7442459381425269, 0.761...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E7E2B75C0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>1193.319559</td>\n",
       "      <td>[1.3689969280693859, 0.9827594344104055, 0.816...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0173D940&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>1253.092974</td>\n",
       "      <td>[1.4703639805621251, 1.1408431956841618, 0.974...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F8E660&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>1336.482945</td>\n",
       "      <td>[1.0616629460654292, 0.8185342156089499, 0.805...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0173E270&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>1391.377766</td>\n",
       "      <td>[3.2888732237682596, 2.526030572807918, 1.8423...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A35040&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>1411.146362</td>\n",
       "      <td>[1.1620508007733075, 0.915319164280394, 0.8380...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0173FEF0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>1463.631263</td>\n",
       "      <td>[1.0696793670754599, 0.8307669621206637, 0.747...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0173D8B0&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>1472.928206</td>\n",
       "      <td>[1.43378552139927, 1.0574375429072225, 1.03716...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F8C950&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>1483.261405</td>\n",
       "      <td>[4.450296260776009, 3.1838579895487333, 2.2097...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F8D4F0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>1506.286948</td>\n",
       "      <td>[2.824084945254153, 2.3061321823378167, 1.8825...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F8C320&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Arch                                          Fun    Test_loss  \\\n",
       "194  [1, 20, 20, 1]        <function relu at 0x0000029E039CF2E0>  1165.210034   \n",
       "284  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E039CE980>  1193.319559   \n",
       "258  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E039CE980>  1253.092974   \n",
       "286  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E039CE980>  1336.482945   \n",
       "224  [1, 20, 20, 1]        <function relu at 0x0000029E039CF2E0>  1391.377766   \n",
       "319  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E039CE980>  1411.146362   \n",
       "283  [1, 20, 20, 1]  <function leaky_relu at 0x0000029E039CE980>  1463.631263   \n",
       "226  [1, 20, 20, 1]        <function relu at 0x0000029E039CF2E0>  1472.928206   \n",
       "239  [1, 20, 20, 1]        <function relu at 0x0000029E039CF2E0>  1483.261405   \n",
       "220  [1, 20, 20, 1]        <function relu at 0x0000029E039CF2E0>  1506.286948   \n",
       "\n",
       "                                         Train_results  Dropout  Patience  \\\n",
       "194  [0.8393655662556828, 0.7442459381425269, 0.761...        0       100   \n",
       "284  [1.3689969280693859, 0.9827594344104055, 0.816...        0       100   \n",
       "258  [1.4703639805621251, 1.1408431956841618, 0.974...        0        50   \n",
       "286  [1.0616629460654292, 0.8185342156089499, 0.805...        0       100   \n",
       "224  [3.2888732237682596, 2.526030572807918, 1.8423...        0       500   \n",
       "319  [1.1620508007733075, 0.915319164280394, 0.8380...        0       500   \n",
       "283  [1.0696793670754599, 0.8307669621206637, 0.747...        0       100   \n",
       "226  [1.43378552139927, 1.0574375429072225, 1.03716...        0       500   \n",
       "239  [4.450296260776009, 3.1838579895487333, 2.2097...        0       500   \n",
       "220  [2.824084945254153, 2.3061321823378167, 1.8825...        0       200   \n",
       "\n",
       "                                             Net      L1      L2  \n",
       "194  <__main__.MLP object at 0x0000029E7E2B75C0>  0.0000  0.0010  \n",
       "284  <__main__.MLP object at 0x0000029E0173D940>  0.0001  0.0000  \n",
       "258  <__main__.MLP object at 0x0000029E79F8E660>  0.0000  0.0010  \n",
       "286  <__main__.MLP object at 0x0000029E0173E270>  0.0001  0.0010  \n",
       "224  <__main__.MLP object at 0x0000029E03A35040>  0.0000  0.0000  \n",
       "319  <__main__.MLP object at 0x0000029E0173FEF0>  0.0001  0.0001  \n",
       "283  <__main__.MLP object at 0x0000029E0173D8B0>  0.0010  0.0001  \n",
       "226  <__main__.MLP object at 0x0000029E79F8C950>  0.0000  0.0010  \n",
       "239  <__main__.MLP object at 0x0000029E79F8D4F0>  0.0001  0.0001  \n",
       "220  <__main__.MLP object at 0x0000029E79F8C320>  0.0001  0.0000  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b112fe01-428b-4b92-b442-3e70e804b29a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Test_loss</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5448.070444</td>\n",
       "      <td>[1.5792068699180553, 1.3141334148610782, 1.134...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A35070&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5448.159944</td>\n",
       "      <td>[1.2535163667040912, 1.076820019948192, 1.0116...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A36690&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5450.815074</td>\n",
       "      <td>[1.8278220700761303, 1.4458151270639807, 1.195...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A367B0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5451.589107</td>\n",
       "      <td>[2.412219205466239, 1.9962136258593604, 1.6679...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04AFBC20&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5453.206325</td>\n",
       "      <td>[1.0955578609145067, 1.015552181532708, 0.9929...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0193AD80&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5453.661066</td>\n",
       "      <td>[1.3582197003779097, 1.1985118741701704, 1.092...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04AF91C0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5455.202234</td>\n",
       "      <td>[1.2938240350005343, 1.0986800903983747, 0.997...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0182B1D0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5455.777951</td>\n",
       "      <td>[1.090975787751296, 1.0090030484525991, 0.9975...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01949520&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5456.336688</td>\n",
       "      <td>[1.1857173814767594, 1.0676138579676338, 1.012...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A34E90&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1, 20, 20, 1]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>5464.935959</td>\n",
       "      <td>[1.0238334203009334, 0.9922339922141283, 0.995...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04C31160&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Arch                                       Fun    Test_loss  \\\n",
       "38  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5448.070444   \n",
       "52  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5448.159944   \n",
       "55  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5450.815074   \n",
       "68  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5451.589107   \n",
       "6   [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5453.206325   \n",
       "69  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5453.661066   \n",
       "71  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5455.202234   \n",
       "23  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5455.777951   \n",
       "39  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5456.336688   \n",
       "20  [1, 20, 20, 1]  <function sigmoid at 0x0000029E017B67A0>  5464.935959   \n",
       "\n",
       "                                        Train_results  Dropout  Patience  \\\n",
       "38  [1.5792068699180553, 1.3141334148610782, 1.134...        0       100   \n",
       "52  [1.2535163667040912, 1.076820019948192, 1.0116...        0       200   \n",
       "55  [1.8278220700761303, 1.4458151270639807, 1.195...        0       200   \n",
       "68  [2.412219205466239, 1.9962136258593604, 1.6679...        0       500   \n",
       "6   [1.0955578609145067, 1.015552181532708, 0.9929...        0         0   \n",
       "69  [1.3582197003779097, 1.1985118741701704, 1.092...        0       500   \n",
       "71  [1.2938240350005343, 1.0986800903983747, 0.997...        0       500   \n",
       "23  [1.090975787751296, 1.0090030484525991, 0.9975...        0        50   \n",
       "39  [1.1857173814767594, 1.0676138579676338, 1.012...        0       100   \n",
       "20  [1.0238334203009334, 0.9922339922141283, 0.995...        0        50   \n",
       "\n",
       "                                            Net    L1      L2  \n",
       "38  <__main__.MLP object at 0x0000029E03A35070>  0.01  0.0010  \n",
       "52  <__main__.MLP object at 0x0000029E03A36690>  0.01  0.0000  \n",
       "55  <__main__.MLP object at 0x0000029E03A367B0>  0.01  0.0001  \n",
       "68  <__main__.MLP object at 0x0000029E04AFBC20>  0.01  0.0000  \n",
       "6   <__main__.MLP object at 0x0000029E0193AD80>  0.01  0.0010  \n",
       "69  <__main__.MLP object at 0x0000029E04AF91C0>  0.01  0.0100  \n",
       "71  <__main__.MLP object at 0x0000029E0182B1D0>  0.01  0.0001  \n",
       "23  <__main__.MLP object at 0x0000029E01949520>  0.01  0.0001  \n",
       "39  <__main__.MLP object at 0x0000029E03A34E90>  0.01  0.0001  \n",
       "20  <__main__.MLP object at 0x0000029E04C31160>  0.01  0.0000  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee500d9-6314-4624-b51a-63704d32528c",
   "metadata": {},
   "source": [
    "## Dane rings5-sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f24a5-cc11-44c6-ab28-950a64959a36",
   "metadata": {},
   "source": [
    "### Pobranie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "446f8507-5d59-4639-9579-bdd82f1d3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobieramy dane\n",
    "data_train = pd.read_csv(\"../Data/classification/rings5-sparse-training.csv\").to_numpy()\n",
    "x_train = data_train[:, 0:2].reshape(-1, 2)\n",
    "y_train = one_hot(np.int64(data_train[:, 2]))\n",
    "\n",
    "data_test = pd.read_csv(\"../Data/classification/rings5-sparse-test.csv\").to_numpy()\n",
    "x_test = data_test[:, 0:2].reshape(-1, 2)\n",
    "y_test = one_hot(np.int64(data_test[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a3bdba9e-0b55-4aa3-97c8-74b8db7d46c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25.26965966, -16.25999766,   0.        ],\n",
       "       [-89.68853978,  86.48973461,   0.        ],\n",
       "       [-89.93592928,  95.1058066 ,   0.        ],\n",
       "       [-74.53446775,  98.08525946,   0.        ],\n",
       "       [ 33.59794887, -15.74661601,   0.        ],\n",
       "       [-93.14145171,  79.89311726,   0.        ],\n",
       "       [  2.21957145,  -7.30543341,   0.        ],\n",
       "       [ 22.72700612, -16.76695468,   0.        ],\n",
       "       [  3.86143951, -18.81307755,   0.        ],\n",
       "       [  8.14270857, -29.96900198,   0.        ],\n",
       "       [  4.13282271, -32.25259855,   0.        ],\n",
       "       [-74.109923  ,  98.80834608,   0.        ],\n",
       "       [ 16.26473721, -18.3080981 ,   0.        ],\n",
       "       [-95.54828075,  80.86739928,   0.        ],\n",
       "       [-98.08457494,  95.35361901,   0.        ],\n",
       "       [  2.66649765, -15.42152101,   0.        ],\n",
       "       [ 25.59958203, -25.20979303,   0.        ],\n",
       "       [-85.75852676,  92.64481403,   0.        ],\n",
       "       [-85.70460747,  89.59549516,   0.        ],\n",
       "       [  3.73966354, -32.37635153,   0.        ],\n",
       "       [  1.37727167, -26.75514463,   0.        ],\n",
       "       [ 22.77932824, -10.33067526,   0.        ],\n",
       "       [ 25.23515839, -18.35042662,   0.        ],\n",
       "       [-84.69970701,  96.65246028,   0.        ],\n",
       "       [-72.2618307 ,  96.98147886,   0.        ],\n",
       "       [ 23.18028733, -21.09067477,   0.        ],\n",
       "       [-95.23868086,  77.4720056 ,   0.        ],\n",
       "       [-95.40689997,  89.48421832,   0.        ],\n",
       "       [  8.33400083,  -3.7929174 ,   0.        ],\n",
       "       [ 27.30621332,  -3.87117141,   0.        ],\n",
       "       [-78.26494146,  99.5024153 ,   0.        ],\n",
       "       [ 22.71107663,  -3.49219553,   0.        ],\n",
       "       [  2.21777149, -26.76243405,   0.        ],\n",
       "       [ 14.34457777, -11.9505425 ,   0.        ],\n",
       "       [ 14.79664417, -29.7720544 ,   0.        ],\n",
       "       [  4.55350243,  -3.02030221,   0.        ],\n",
       "       [ 19.36706575,  -6.63991068,   0.        ],\n",
       "       [ 13.16553899, -13.29396795,   0.        ],\n",
       "       [ 19.13487832,  -9.94080673,   0.        ],\n",
       "       [ 17.98195299, -12.97732936,   0.        ],\n",
       "       [ 49.33843766, -42.53650755,   1.        ],\n",
       "       [ -8.96592862, -13.17596161,   1.        ],\n",
       "       [ 18.91142698, -40.4413613 ,   1.        ],\n",
       "       [ 51.42074828,  -4.62746192,   1.        ],\n",
       "       [  4.26297192, -69.3876354 ,   1.        ],\n",
       "       [ 18.58633403, -51.1071885 ,   1.        ],\n",
       "       [ 49.41208372, -56.06757142,   1.        ],\n",
       "       [ 41.61025877, -39.38696664,   1.        ],\n",
       "       [ 20.15536046, -56.24793549,   1.        ],\n",
       "       [ 12.52084523, -75.23080199,   1.        ],\n",
       "       [ 40.04002172, -51.48893455,   1.        ],\n",
       "       [-33.62574289,  -5.23094246,   1.        ],\n",
       "       [ 25.16620304, -46.88075213,   1.        ],\n",
       "       [ -9.55795539, -22.19292987,   1.        ],\n",
       "       [ 26.56121054,  27.56121978,   1.        ],\n",
       "       [ 44.13789264, -53.32997516,   1.        ],\n",
       "       [ 36.62813567, -26.70266279,   1.        ],\n",
       "       [ 17.52412897, -46.97990664,   1.        ],\n",
       "       [-22.62369529, -13.62934182,   1.        ],\n",
       "       [ 52.48777024, -19.61103291,   1.        ],\n",
       "       [ 52.61648716, -49.29341418,   1.        ],\n",
       "       [ 13.65938564, -44.92459954,   1.        ],\n",
       "       [ 51.02881603, -25.44336813,   1.        ],\n",
       "       [ 69.20595644,  -4.13482217,   1.        ],\n",
       "       [ -1.798973  ,  -7.89824808,   1.        ],\n",
       "       [ 17.28779851, -73.92478189,   1.        ],\n",
       "       [ 70.6835133 ,  -3.25294607,   1.        ],\n",
       "       [ 69.73621119, -33.87578195,   1.        ],\n",
       "       [-25.65617356, -16.32993165,   1.        ],\n",
       "       [-20.11359329, -26.19180144,   1.        ],\n",
       "       [ 10.44175681, -67.71549694,   1.        ],\n",
       "       [ -7.30860229, -22.0050402 ,   1.        ],\n",
       "       [ 19.78677735, -41.63532928,   1.        ],\n",
       "       [  8.09009066, -67.59065869,   1.        ],\n",
       "       [ 21.72241225,  28.01423217,   1.        ],\n",
       "       [-21.77070845, -32.46219237,   1.        ],\n",
       "       [ 67.06317789, -25.66365334,   1.        ],\n",
       "       [  4.46182629,  24.34226475,   1.        ],\n",
       "       [ 19.82319173, -35.76039118,   1.        ],\n",
       "       [ 44.1884249 , -28.73478755,   1.        ],\n",
       "       [-21.89458283,  17.10585272,   2.        ],\n",
       "       [-54.18600175, -44.69816312,   2.        ],\n",
       "       [ 54.5716553 ,  39.11231128,   2.        ],\n",
       "       [ 60.1393268 , -63.28501543,   2.        ],\n",
       "       [ 46.24976269, -98.6415477 ,   2.        ],\n",
       "       [ 45.59410526,  64.16822574,   2.        ],\n",
       "       [ 75.62096389, -90.41983611,   2.        ],\n",
       "       [ 63.4491893 ,  23.04507452,   2.        ],\n",
       "       [ 14.16553813,  74.79566126,   2.        ],\n",
       "       [ 85.9622512 , -16.84689149,   2.        ],\n",
       "       [-62.93056956, -23.03043641,   2.        ],\n",
       "       [ 18.7982962 , -80.97095857,   2.        ],\n",
       "       [ 30.76795652, -84.70129939,   2.        ],\n",
       "       [-61.88894636,  -4.86155418,   2.        ],\n",
       "       [-61.16259019,  -3.56233525,   2.        ],\n",
       "       [-41.57449277, -44.24544503,   2.        ],\n",
       "       [-50.23937547,  -7.27189863,   2.        ],\n",
       "       [ 78.05262967, -45.00150606,   2.        ],\n",
       "       [-59.64134084,  -3.87327611,   2.        ],\n",
       "       [ 68.86616913,   5.60630807,   2.        ],\n",
       "       [ 37.32580566, -73.30863574,   2.        ],\n",
       "       [ 21.11228881,  65.3004685 ,   2.        ],\n",
       "       [  8.34337464, -89.25719843,   2.        ],\n",
       "       [ -6.82492973,  21.95534003,   2.        ],\n",
       "       [ 13.19301077,  37.92735715,   2.        ],\n",
       "       [ -0.56801578,   9.75910532,   2.        ],\n",
       "       [ 49.59378103,  31.27487376,   2.        ],\n",
       "       [-16.61566109, -60.09634528,   2.        ],\n",
       "       [ 32.70898336,  24.29225156,   2.        ],\n",
       "       [-49.12987091, -60.94653718,   2.        ],\n",
       "       [ 25.35138032, -84.74803772,   2.        ],\n",
       "       [ 99.33777684,  -9.95831029,   2.        ],\n",
       "       [ 79.29707649, -82.48037635,   2.        ],\n",
       "       [ 39.1683674 ,  50.72727944,   2.        ],\n",
       "       [ 70.98119333,   7.83243072,   2.        ],\n",
       "       [ -8.56431369, -52.8230208 ,   2.        ],\n",
       "       [  9.72985504, -93.32209085,   2.        ],\n",
       "       [ 56.64805179,   1.22539746,   2.        ],\n",
       "       [ 45.93456872,  18.35119426,   2.        ],\n",
       "       [-49.94504531, -12.4375666 ,   2.        ],\n",
       "       [-48.37011811,  36.26511022,   3.        ],\n",
       "       [ 55.5277694 ,  82.20037492,   3.        ],\n",
       "       [-99.05137322, -42.89827682,   3.        ],\n",
       "       [-71.33868877, -73.99331005,   3.        ],\n",
       "       [ 98.79024406,  41.46424588,   3.        ],\n",
       "       [ 59.07193492,  55.04302229,   3.        ],\n",
       "       [-22.16999861,  53.48721636,   3.        ],\n",
       "       [ 81.33725892,  64.28186167,   3.        ],\n",
       "       [-63.69440439, -81.56273235,   3.        ],\n",
       "       [-15.46884738,  39.16977937,   3.        ],\n",
       "       [-92.91581404, -54.88629001,   3.        ],\n",
       "       [ 91.43729205,  62.78031259,   3.        ],\n",
       "       [-21.22352999,  49.60530451,   3.        ],\n",
       "       [ 86.59305242,  50.82444674,   3.        ],\n",
       "       [-88.71423616, -80.48030538,   3.        ],\n",
       "       [ 52.53382269,  64.1685599 ,   3.        ],\n",
       "       [ 97.12335542, -74.70625835,   3.        ],\n",
       "       [-34.86033776, -94.78595606,   3.        ],\n",
       "       [-46.40328786,  64.14338276,   3.        ],\n",
       "       [-75.62005618, -74.10062319,   3.        ],\n",
       "       [ 99.43212187,  65.8043338 ,   3.        ],\n",
       "       [ 85.08695033,  10.53440594,   3.        ],\n",
       "       [-59.06328107, -97.27955246,   3.        ],\n",
       "       [-82.25744492, -56.56134104,   3.        ],\n",
       "       [ 64.93845959,  65.34967315,   3.        ],\n",
       "       [-53.53326062,  37.60747113,   3.        ],\n",
       "       [-24.68008092,  33.3373229 ,   3.        ],\n",
       "       [-30.04924282, -97.83210978,   3.        ],\n",
       "       [-19.69758226,  48.33460618,   3.        ],\n",
       "       [-93.95159171, -42.31185694,   3.        ],\n",
       "       [ 74.77158848,  90.35485084,   3.        ],\n",
       "       [-68.41274747, -94.43065892,   3.        ],\n",
       "       [ 81.67794286, -95.10690342,   3.        ],\n",
       "       [-19.18005622,  45.36469546,   3.        ],\n",
       "       [-47.66444345,  32.09210448,   3.        ],\n",
       "       [ 54.21287199,  84.24271573,   3.        ],\n",
       "       [-99.13964276, -52.16600937,   3.        ],\n",
       "       [-36.65212593,  37.45312113,   3.        ],\n",
       "       [ 64.41103308,  79.84307474,   3.        ],\n",
       "       [-24.19759082, -92.27285883,   3.        ],\n",
       "       [-88.2361358 ,  63.24684862,   4.        ],\n",
       "       [-52.30853101,  76.88791957,   4.        ],\n",
       "       [-86.69713186,  53.85806914,   4.        ],\n",
       "       [ 99.63331893,  97.07746832,   4.        ],\n",
       "       [-82.12612737,  23.29372615,   4.        ],\n",
       "       [-49.40457651,  78.16172871,   4.        ],\n",
       "       [-27.1183602 ,  83.33455659,   4.        ],\n",
       "       [-85.18057358,  38.87457261,   4.        ],\n",
       "       [-93.84567509, -75.36953539,   4.        ],\n",
       "       [-93.45531524,  45.07087362,   4.        ],\n",
       "       [-73.7741061 ,  75.35142577,   4.        ],\n",
       "       [-64.63273657,  71.93363234,   4.        ],\n",
       "       [-49.57361836,  65.54672699,   4.        ],\n",
       "       [-68.06186978,  85.8408805 ,   4.        ],\n",
       "       [-99.24093019, -99.76339573,   4.        ],\n",
       "       [-81.74321502,  39.30210085,   4.        ],\n",
       "       [-73.34317393,  59.83750606,   4.        ],\n",
       "       [-96.58939191,  54.45267158,   4.        ],\n",
       "       [-83.80538141,  21.23098141,   4.        ],\n",
       "       [-75.3709536 ,  51.24029242,   4.        ],\n",
       "       [-45.70199428,  67.72490274,   4.        ],\n",
       "       [-77.38082241,  53.98400007,   4.        ],\n",
       "       [-71.06049452,  61.93511384,   4.        ],\n",
       "       [-55.66899749,  83.21064739,   4.        ],\n",
       "       [-69.59482306,  59.29816025,   4.        ],\n",
       "       [-82.09674335,  25.11053039,   4.        ],\n",
       "       [-57.78898774,  81.88967826,   4.        ],\n",
       "       [-45.79015551,  87.37102291,   4.        ],\n",
       "       [-47.35857733,  80.83901294,   4.        ],\n",
       "       [-46.38855252,  95.93119915,   4.        ],\n",
       "       [ 91.16103146,  89.00881023,   4.        ],\n",
       "       [-50.14883503,  91.22036984,   4.        ],\n",
       "       [-94.59674819, -79.44011902,   4.        ],\n",
       "       [ -2.73558716,  80.21053504,   4.        ],\n",
       "       [-60.23472627,  74.07942982,   4.        ],\n",
       "       [-99.91368083,  40.86693153,   4.        ],\n",
       "       [-70.74949667,  71.32497067,   4.        ],\n",
       "       [-52.83041811,  85.89567933,   4.        ],\n",
       "       [ 67.67114801,  99.38121019,   4.        ],\n",
       "       [ 99.32900658,  81.69786981,   4.        ]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "baa841b6-cb42-446e-ae1e-6394f27ee33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5f922c74-2f6d-4117-a107-153def4c140b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train[:, 0], x_train[:, 1], c = data_train[:, 2], s = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc84de3-5db8-41b4-aefb-02c7dc1cd8ea",
   "metadata": {},
   "source": [
    "### Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "53c1a7d9-827f-49ed-90b7-296c95a86123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss (standarized): 1.673852457674859\n",
      "Epoch: 6, Loss (standarized): 1.6089090795956207\n",
      "Epoch: 11, Loss (standarized): 1.5782808585589947\n",
      "Epoch: 16, Loss (standarized): 1.5512183190177928\n",
      "Epoch: 21, Loss (standarized): 1.5101230212814698\n",
      "Epoch: 26, Loss (standarized): 1.4613881095126826\n",
      "Epoch: 31, Loss (standarized): 1.408997618630997\n",
      "Epoch: 36, Loss (standarized): 1.3688331817698227\n",
      "Epoch: 41, Loss (standarized): 1.3469082016050278\n",
      "Epoch: 46, Loss (standarized): 1.3378288228123836\n",
      "Epoch: 51, Loss (standarized): 1.3313929723249507\n",
      "Epoch: 56, Loss (standarized): 1.3244973820702959\n",
      "Epoch: 61, Loss (standarized): 1.3169185057107966\n",
      "Epoch: 66, Loss (standarized): 1.3086725306024574\n",
      "Epoch: 71, Loss (standarized): 1.299204006398324\n",
      "Epoch: 76, Loss (standarized): 1.287968848661547\n",
      "Epoch: 81, Loss (standarized): 1.2747095499553616\n",
      "Epoch: 86, Loss (standarized): 1.2591678915307272\n",
      "Epoch: 91, Loss (standarized): 1.2412023581824638\n",
      "Epoch: 96, Loss (standarized): 1.2209610230648293\n",
      "Final epoch: 100, Final loss (standarized): 1.2032043136647845\n",
      "Epoch: 1, Loss (standarized): 1.7395882973367593\n",
      "Epoch: 6, Loss (standarized): 1.610935299575636\n",
      "Epoch: 11, Loss (standarized): 1.607842575188567\n",
      "Epoch: 16, Loss (standarized): 1.5874729299258679\n",
      "Epoch: 21, Loss (standarized): 1.584829233847886\n",
      "Epoch: 26, Loss (standarized): 1.5689692969159028\n",
      "Epoch: 31, Loss (standarized): 1.5572645274471546\n",
      "Epoch: 36, Loss (standarized): 1.5396659789228375\n",
      "Epoch: 41, Loss (standarized): 1.5187867251951863\n",
      "Epoch: 46, Loss (standarized): 1.492521960091421\n",
      "Epoch: 51, Loss (standarized): 1.4634554404378093\n",
      "Epoch: 56, Loss (standarized): 1.4357404026394551\n",
      "Epoch: 61, Loss (standarized): 1.4135766690375926\n",
      "Epoch: 66, Loss (standarized): 1.3986904855053046\n",
      "Epoch: 71, Loss (standarized): 1.3902452383920518\n",
      "Epoch: 76, Loss (standarized): 1.3856137173787015\n",
      "Epoch: 81, Loss (standarized): 1.3827954001842182\n",
      "Epoch: 86, Loss (standarized): 1.3804761360499356\n",
      "Epoch: 91, Loss (standarized): 1.3779806485381516\n",
      "Epoch: 96, Loss (standarized): 1.3754725326914876\n",
      "Final epoch: 100, Final loss (standarized): 1.3738966800031016\n",
      "Epoch: 1, Loss (standarized): 1.8727715310199817\n",
      "Epoch: 6, Loss (standarized): 1.6121045859134258\n",
      "Epoch: 11, Loss (standarized): 1.6181379018187534\n",
      "Epoch: 16, Loss (standarized): 1.5851079644935282\n",
      "Epoch: 21, Loss (standarized): 1.5418289401092544\n",
      "Epoch: 26, Loss (standarized): 1.5149275499146062\n",
      "Epoch: 31, Loss (standarized): 1.473873844013129\n",
      "Epoch: 36, Loss (standarized): 1.4307381667217363\n",
      "Epoch: 41, Loss (standarized): 1.398635343280137\n",
      "Epoch: 46, Loss (standarized): 1.374210817302914\n",
      "Epoch: 51, Loss (standarized): 1.359757333890072\n",
      "Epoch: 56, Loss (standarized): 1.3520631029369183\n",
      "Epoch: 61, Loss (standarized): 1.3462056615418965\n",
      "Epoch: 66, Loss (standarized): 1.3417512836554828\n",
      "Epoch: 71, Loss (standarized): 1.3380044240663345\n",
      "Epoch: 76, Loss (standarized): 1.335073634672013\n",
      "Epoch: 81, Loss (standarized): 1.3323887678664894\n",
      "Epoch: 86, Loss (standarized): 1.32965264212084\n",
      "Epoch: 91, Loss (standarized): 1.3266757972853207\n",
      "Epoch: 96, Loss (standarized): 1.3232995115994377\n",
      "Final epoch: 100, Final loss (standarized): 1.3202208328968552\n",
      "Epoch: 1, Loss (standarized): 1.7043291867905324\n",
      "Epoch: 6, Loss (standarized): 1.613030838497614\n",
      "Epoch: 11, Loss (standarized): 1.5856686131016153\n",
      "Epoch: 16, Loss (standarized): 1.5624725465161107\n",
      "Epoch: 21, Loss (standarized): 1.5306928250141967\n",
      "Epoch: 26, Loss (standarized): 1.4907126378052202\n",
      "Epoch: 31, Loss (standarized): 1.4474327419187056\n",
      "Epoch: 36, Loss (standarized): 1.4049707968054241\n",
      "Epoch: 41, Loss (standarized): 1.3732610570941617\n",
      "Epoch: 46, Loss (standarized): 1.3521173803678253\n",
      "Epoch: 51, Loss (standarized): 1.339276693853356\n",
      "Epoch: 56, Loss (standarized): 1.3299796508353305\n",
      "Epoch: 61, Loss (standarized): 1.322275560285259\n",
      "Epoch: 66, Loss (standarized): 1.3151351786983654\n",
      "Epoch: 71, Loss (standarized): 1.3077366872088974\n",
      "Epoch: 76, Loss (standarized): 1.2996708227932703\n",
      "Epoch: 81, Loss (standarized): 1.2902079975021021\n",
      "Epoch: 86, Loss (standarized): 1.2788334007100834\n",
      "Epoch: 91, Loss (standarized): 1.2653403812206734\n",
      "Epoch: 96, Loss (standarized): 1.2495626547104945\n",
      "Final epoch: 100, Final loss (standarized): 1.2351540700466341\n",
      "Epoch: 1, Loss (standarized): 1.778917647946804\n",
      "Epoch: 6, Loss (standarized): 1.600396478896014\n",
      "Epoch: 11, Loss (standarized): 1.614766039176371\n",
      "Epoch: 16, Loss (standarized): 1.6039295438167545\n",
      "Epoch: 21, Loss (standarized): 1.604066320407927\n",
      "Epoch: 26, Loss (standarized): 1.6063193794582569\n",
      "Epoch: 31, Loss (standarized): 1.6067938468689724\n",
      "Epoch: 36, Loss (standarized): 1.608348915908753\n",
      "Epoch: 41, Loss (standarized): 1.6088641088389977\n",
      "Epoch: 46, Loss (standarized): 1.6092877038992248\n",
      "Epoch: 51, Loss (standarized): 1.6093285693604713\n",
      "Epoch: 56, Loss (standarized): 1.609547634474061\n",
      "Epoch: 61, Loss (standarized): 1.6095376919764925\n",
      "Epoch: 66, Loss (standarized): 1.6095342108435988\n",
      "Epoch: 71, Loss (standarized): 1.6095762923321992\n",
      "Epoch: 76, Loss (standarized): 1.6095111984014667\n",
      "Epoch: 81, Loss (standarized): 1.6094992106983494\n",
      "Epoch: 86, Loss (standarized): 1.6095345645524748\n",
      "Epoch: 91, Loss (standarized): 1.6095181620780699\n",
      "Epoch: 96, Loss (standarized): 1.6095448763954798\n",
      "Final epoch: 100, Final loss (standarized): 1.6094831326622774\n",
      "Epoch: 1, Loss (standarized): 1.6361728166896898\n",
      "Epoch: 6, Loss (standarized): 1.6064081599381341\n",
      "Epoch: 11, Loss (standarized): 1.606204286767329\n",
      "Epoch: 16, Loss (standarized): 1.607842404805469\n",
      "Epoch: 21, Loss (standarized): 1.6081818847746872\n",
      "Epoch: 26, Loss (standarized): 1.6091405785957449\n",
      "Epoch: 31, Loss (standarized): 1.6095892466798032\n",
      "Epoch: 36, Loss (standarized): 1.609591838798031\n",
      "Epoch: 41, Loss (standarized): 1.609482440271488\n",
      "Epoch: 46, Loss (standarized): 1.6094932142107314\n",
      "Epoch: 51, Loss (standarized): 1.6097515931753372\n",
      "Epoch: 56, Loss (standarized): 1.6098620267752435\n",
      "Epoch: 61, Loss (standarized): 1.609492072826478\n",
      "Epoch: 66, Loss (standarized): 1.609463152994993\n",
      "Epoch: 71, Loss (standarized): 1.609471247537581\n",
      "Epoch: 76, Loss (standarized): 1.6095858743834424\n",
      "Epoch: 81, Loss (standarized): 1.609563078369864\n",
      "Epoch: 86, Loss (standarized): 1.6095604106540038\n",
      "Epoch: 91, Loss (standarized): 1.6095769918636536\n",
      "Epoch: 96, Loss (standarized): 1.6095276293762015\n",
      "Final epoch: 100, Final loss (standarized): 1.609455898674471\n",
      "Epoch: 1, Loss (standarized): 1.7217866141885876\n",
      "Epoch: 6, Loss (standarized): 1.6104011495746766\n",
      "Epoch: 11, Loss (standarized): 1.6158210223906884\n",
      "Epoch: 16, Loss (standarized): 1.6148138674877992\n",
      "Epoch: 21, Loss (standarized): 1.6084134425649494\n",
      "Epoch: 26, Loss (standarized): 1.6105522232533567\n",
      "Epoch: 31, Loss (standarized): 1.6102440649669936\n",
      "Epoch: 36, Loss (standarized): 1.6094384500121297\n",
      "Epoch: 41, Loss (standarized): 1.6096660573145574\n",
      "Epoch: 46, Loss (standarized): 1.609474366703833\n",
      "Epoch: 51, Loss (standarized): 1.6098147260005513\n",
      "Epoch: 56, Loss (standarized): 1.6097484105678348\n",
      "Epoch: 61, Loss (standarized): 1.6095983890824408\n",
      "Epoch: 66, Loss (standarized): 1.6096948182495805\n",
      "Epoch: 71, Loss (standarized): 1.6095693410193572\n",
      "Epoch: 76, Loss (standarized): 1.609549326700584\n",
      "Epoch: 81, Loss (standarized): 1.6094908375242083\n",
      "Epoch: 86, Loss (standarized): 1.609446265544275\n",
      "Epoch: 91, Loss (standarized): 1.6094532003515547\n",
      "Epoch: 96, Loss (standarized): 1.609494806268951\n",
      "Final epoch: 100, Final loss (standarized): 1.6094910561567246\n",
      "Epoch: 1, Loss (standarized): 2.0092469193639038\n",
      "Epoch: 6, Loss (standarized): 1.6471960269327979\n",
      "Epoch: 11, Loss (standarized): 1.6018581067168964\n",
      "Epoch: 16, Loss (standarized): 1.6135590925898742\n",
      "Epoch: 21, Loss (standarized): 1.6118409753940464\n",
      "Epoch: 26, Loss (standarized): 1.6076584318482117\n",
      "Epoch: 31, Loss (standarized): 1.6081108402627162\n",
      "Epoch: 36, Loss (standarized): 1.6099660548592727\n",
      "Epoch: 41, Loss (standarized): 1.6102226409271103\n",
      "Epoch: 46, Loss (standarized): 1.6096591135085612\n",
      "Epoch: 51, Loss (standarized): 1.6094253405629138\n",
      "Epoch: 56, Loss (standarized): 1.6094567706280063\n",
      "Epoch: 61, Loss (standarized): 1.60947516101757\n",
      "Epoch: 66, Loss (standarized): 1.6095763066195758\n",
      "Epoch: 71, Loss (standarized): 1.6095759446649105\n",
      "Epoch: 76, Loss (standarized): 1.60964019743086\n",
      "Epoch: 81, Loss (standarized): 1.6098241701991411\n",
      "Epoch: 86, Loss (standarized): 1.6097292861840173\n",
      "Epoch: 91, Loss (standarized): 1.6096986678727077\n",
      "Epoch: 96, Loss (standarized): 1.6097336902205948\n",
      "Final epoch: 100, Final loss (standarized): 1.6096891567686953\n",
      "Epoch: 1, Loss (standarized): 1.6447404533709653\n",
      "Epoch: 6, Loss (standarized): 1.579308063902136\n",
      "Epoch: 11, Loss (standarized): 1.5385959577187145\n",
      "Epoch: 16, Loss (standarized): 1.499778220625567\n",
      "Epoch: 21, Loss (standarized): 1.4490557116271885\n",
      "Epoch: 26, Loss (standarized): 1.403854784413312\n",
      "Epoch: 31, Loss (standarized): 1.3677158748006428\n",
      "Epoch: 36, Loss (standarized): 1.3472095016407082\n",
      "Epoch: 41, Loss (standarized): 1.337022949931453\n",
      "Epoch: 46, Loss (standarized): 1.3321193241194402\n",
      "Epoch: 51, Loss (standarized): 1.3293433509116397\n",
      "Epoch: 56, Loss (standarized): 1.327440792950787\n",
      "Epoch: 61, Loss (standarized): 1.3261982171648214\n",
      "Epoch: 66, Loss (standarized): 1.3250709629526733\n",
      "Epoch: 71, Loss (standarized): 1.3235953116534762\n",
      "Epoch: 76, Loss (standarized): 1.321413334330646\n",
      "Epoch: 81, Loss (standarized): 1.31854588753085\n",
      "Epoch: 86, Loss (standarized): 1.3149980608230931\n",
      "Epoch: 91, Loss (standarized): 1.3109440913962072\n",
      "Epoch: 96, Loss (standarized): 1.3063335487339942\n",
      "Final epoch: 100, Final loss (standarized): 1.3022471719842121\n",
      "Epoch: 1, Loss (standarized): 1.7955947093675573\n",
      "Epoch: 6, Loss (standarized): 1.6099443168206746\n",
      "Epoch: 11, Loss (standarized): 1.6030082491567827\n",
      "Epoch: 16, Loss (standarized): 1.5950608454205977\n",
      "Epoch: 21, Loss (standarized): 1.5834608476553926\n",
      "Epoch: 26, Loss (standarized): 1.5835180133876379\n",
      "Epoch: 31, Loss (standarized): 1.5774578416363136\n",
      "Epoch: 36, Loss (standarized): 1.572722465034641\n",
      "Epoch: 41, Loss (standarized): 1.5681054113455581\n",
      "Epoch: 46, Loss (standarized): 1.560803108087739\n",
      "Epoch: 51, Loss (standarized): 1.55204408744377\n",
      "Epoch: 56, Loss (standarized): 1.5397413317572537\n",
      "Epoch: 61, Loss (standarized): 1.5239613523290665\n",
      "Epoch: 66, Loss (standarized): 1.5042136465542044\n",
      "Epoch: 71, Loss (standarized): 1.4817489686356036\n",
      "Epoch: 76, Loss (standarized): 1.4586165919930645\n",
      "Epoch: 81, Loss (standarized): 1.4377070958397928\n",
      "Epoch: 86, Loss (standarized): 1.4211780531799456\n",
      "Epoch: 91, Loss (standarized): 1.4097749908085637\n",
      "Epoch: 96, Loss (standarized): 1.4030041893064753\n",
      "Final epoch: 100, Final loss (standarized): 1.4000006520579462\n",
      "Epoch: 1, Loss (standarized): 1.6795651776226912\n",
      "Epoch: 6, Loss (standarized): 1.6124582354375752\n",
      "Epoch: 11, Loss (standarized): 1.591161845906401\n",
      "Epoch: 16, Loss (standarized): 1.5772123922612573\n",
      "Epoch: 21, Loss (standarized): 1.5578912854986282\n",
      "Epoch: 26, Loss (standarized): 1.5373685846943266\n",
      "Epoch: 31, Loss (standarized): 1.508754609726214\n",
      "Epoch: 36, Loss (standarized): 1.475865726612706\n",
      "Epoch: 41, Loss (standarized): 1.4390795830695102\n",
      "Epoch: 46, Loss (standarized): 1.4046832930658808\n",
      "Epoch: 51, Loss (standarized): 1.3771588398952672\n",
      "Epoch: 56, Loss (standarized): 1.3588477020482934\n",
      "Epoch: 61, Loss (standarized): 1.34818526631222\n",
      "Epoch: 66, Loss (standarized): 1.3423415317782217\n",
      "Epoch: 71, Loss (standarized): 1.3391887999054695\n",
      "Epoch: 76, Loss (standarized): 1.337562948461847\n",
      "Epoch: 81, Loss (standarized): 1.3365439693880652\n",
      "Epoch: 86, Loss (standarized): 1.3356264378180032\n",
      "Epoch: 91, Loss (standarized): 1.3344856790437762\n",
      "Epoch: 96, Loss (standarized): 1.332902678007125\n",
      "Final epoch: 100, Final loss (standarized): 1.3313371684212538\n",
      "Epoch: 1, Loss (standarized): 1.8124989863771426\n",
      "Epoch: 6, Loss (standarized): 1.6145046367722347\n",
      "Epoch: 11, Loss (standarized): 1.6105720547200713\n",
      "Epoch: 16, Loss (standarized): 1.5860681630903253\n",
      "Epoch: 21, Loss (standarized): 1.5541339821497795\n",
      "Epoch: 26, Loss (standarized): 1.5314679849262296\n",
      "Epoch: 31, Loss (standarized): 1.4919946177081949\n",
      "Epoch: 36, Loss (standarized): 1.447735777739338\n",
      "Epoch: 41, Loss (standarized): 1.4076681700852829\n",
      "Epoch: 46, Loss (standarized): 1.3750417359197848\n",
      "Epoch: 51, Loss (standarized): 1.355438056147397\n",
      "Epoch: 56, Loss (standarized): 1.3448350960531534\n",
      "Epoch: 61, Loss (standarized): 1.339122446724246\n",
      "Epoch: 66, Loss (standarized): 1.3361126428434735\n",
      "Epoch: 71, Loss (standarized): 1.334332937063006\n",
      "Epoch: 76, Loss (standarized): 1.3335092493369383\n",
      "Epoch: 81, Loss (standarized): 1.3329264776093908\n",
      "Epoch: 86, Loss (standarized): 1.3321388787760409\n",
      "Epoch: 91, Loss (standarized): 1.3309320211131728\n",
      "Epoch: 96, Loss (standarized): 1.329214097814888\n",
      "Final epoch: 100, Final loss (standarized): 1.3275336332476175\n",
      "Epoch: 1, Loss (standarized): 1.8343227302510712\n",
      "Epoch: 6, Loss (standarized): 1.620368265319093\n",
      "Epoch: 11, Loss (standarized): 1.6211352518638944\n",
      "Epoch: 16, Loss (standarized): 1.5967644623728205\n",
      "Epoch: 21, Loss (standarized): 1.5617048932303685\n",
      "Epoch: 26, Loss (standarized): 1.5374179980301406\n",
      "Epoch: 31, Loss (standarized): 1.501253503305863\n",
      "Epoch: 36, Loss (standarized): 1.456540840197062\n",
      "Epoch: 41, Loss (standarized): 1.4176717816873141\n",
      "Epoch: 46, Loss (standarized): 1.3851225352981311\n",
      "Epoch: 51, Loss (standarized): 1.3627759032586653\n",
      "Epoch: 56, Loss (standarized): 1.3490741814431593\n",
      "Epoch: 61, Loss (standarized): 1.3403240423194547\n",
      "Epoch: 66, Loss (standarized): 1.3351188717906597\n",
      "Epoch: 71, Loss (standarized): 1.3307257986469552\n",
      "Epoch: 76, Loss (standarized): 1.3260613200484794\n",
      "Epoch: 81, Loss (standarized): 1.3209489983105334\n",
      "Epoch: 86, Loss (standarized): 1.3152200867543404\n",
      "Epoch: 91, Loss (standarized): 1.3084293160702205\n",
      "Epoch: 96, Loss (standarized): 1.3000754556136713\n",
      "Final epoch: 100, Final loss (standarized): 1.2921032996088524\n",
      "Epoch: 1, Loss (standarized): 1.7866294837056558\n",
      "Epoch: 6, Loss (standarized): 1.611768426822347\n",
      "Epoch: 11, Loss (standarized): 1.615598359868481\n",
      "Epoch: 16, Loss (standarized): 1.5904535377844644\n",
      "Epoch: 21, Loss (standarized): 1.575636824027745\n",
      "Epoch: 26, Loss (standarized): 1.5689758079980722\n",
      "Epoch: 31, Loss (standarized): 1.5525402114156208\n",
      "Epoch: 36, Loss (standarized): 1.5396941327532254\n",
      "Epoch: 41, Loss (standarized): 1.5229907233724551\n",
      "Epoch: 46, Loss (standarized): 1.503357663425818\n",
      "Epoch: 51, Loss (standarized): 1.4823394380158843\n",
      "Epoch: 56, Loss (standarized): 1.4597743090945596\n",
      "Epoch: 61, Loss (standarized): 1.4387550100543103\n",
      "Epoch: 66, Loss (standarized): 1.4205180186487334\n",
      "Epoch: 71, Loss (standarized): 1.4063285764244393\n",
      "Epoch: 76, Loss (standarized): 1.3963505635222588\n",
      "Epoch: 81, Loss (standarized): 1.3896940731738332\n",
      "Epoch: 86, Loss (standarized): 1.3851161564301708\n",
      "Epoch: 91, Loss (standarized): 1.382008388115077\n",
      "Epoch: 96, Loss (standarized): 1.379855696566433\n",
      "Final epoch: 100, Final loss (standarized): 1.3785705056586328\n",
      "Epoch: 1, Loss (standarized): 1.8317297696966035\n",
      "Epoch: 6, Loss (standarized): 1.6005441145781847\n",
      "Epoch: 11, Loss (standarized): 1.6145970185709013\n",
      "Epoch: 16, Loss (standarized): 1.5772546243184056\n",
      "Epoch: 21, Loss (standarized): 1.541661848817597\n",
      "Epoch: 26, Loss (standarized): 1.5182163950430825\n",
      "Epoch: 31, Loss (standarized): 1.4794639580135283\n",
      "Epoch: 36, Loss (standarized): 1.4424958912196224\n",
      "Epoch: 41, Loss (standarized): 1.4122189589715652\n",
      "Epoch: 46, Loss (standarized): 1.385840824323222\n",
      "Epoch: 51, Loss (standarized): 1.3665985761241188\n",
      "Epoch: 56, Loss (standarized): 1.3528792740013769\n",
      "Epoch: 61, Loss (standarized): 1.3433263851380082\n",
      "Epoch: 66, Loss (standarized): 1.3372569030986983\n",
      "Epoch: 71, Loss (standarized): 1.332661518783607\n",
      "Epoch: 76, Loss (standarized): 1.328826616756715\n",
      "Epoch: 81, Loss (standarized): 1.3252302507275358\n",
      "Epoch: 86, Loss (standarized): 1.321623261145546\n",
      "Epoch: 91, Loss (standarized): 1.317681919175431\n",
      "Epoch: 96, Loss (standarized): 1.3131864736788719\n",
      "Final epoch: 100, Final loss (standarized): 1.3090325326755448\n",
      "Epoch: 1, Loss (standarized): 1.6410922872960125\n",
      "Epoch: 6, Loss (standarized): 1.6002918588996846\n",
      "Epoch: 11, Loss (standarized): 1.5696029717750344\n",
      "Epoch: 16, Loss (standarized): 1.5419407627561705\n",
      "Epoch: 21, Loss (standarized): 1.4996916811409158\n",
      "Epoch: 26, Loss (standarized): 1.45014262237835\n",
      "Epoch: 31, Loss (standarized): 1.4005134445064045\n",
      "Epoch: 36, Loss (standarized): 1.363474442196825\n",
      "Epoch: 41, Loss (standarized): 1.3443535477748183\n",
      "Epoch: 46, Loss (standarized): 1.3370857128624332\n",
      "Epoch: 51, Loss (standarized): 1.333296856501366\n",
      "Epoch: 56, Loss (standarized): 1.3283209546523842\n",
      "Epoch: 61, Loss (standarized): 1.322689896635738\n",
      "Epoch: 66, Loss (standarized): 1.317690412045508\n",
      "Epoch: 71, Loss (standarized): 1.312254237458941\n",
      "Epoch: 76, Loss (standarized): 1.3053232755673718\n",
      "Epoch: 81, Loss (standarized): 1.2969337156686631\n",
      "Epoch: 86, Loss (standarized): 1.2869119477912276\n",
      "Epoch: 91, Loss (standarized): 1.2746446147355905\n",
      "Epoch: 96, Loss (standarized): 1.259770988538527\n",
      "Final epoch: 100, Final loss (standarized): 1.2457893680484502\n",
      "Epoch: 1, Loss (standarized): 1.9785704378939704\n",
      "          Validation Loss (standardized): 2.1118419139232154\n",
      "Epoch: 6, Loss (standarized): 1.6391088813853691\n",
      "          Validation Loss (standardized): 1.6914951925766686\n",
      "Epoch: 11, Loss (standarized): 1.60651503068462\n",
      "          Validation Loss (standardized): 1.5419050971514652\n",
      "Epoch: 16, Loss (standarized): 1.6137954853355938\n",
      "          Validation Loss (standardized): 1.5291514438116283\n",
      "Epoch: 21, Loss (standarized): 1.5869794201677383\n",
      "          Validation Loss (standardized): 1.5540325762795415\n",
      "Epoch: 26, Loss (standarized): 1.5544192488057655\n",
      "          Validation Loss (standardized): 1.5558257102566053\n",
      "Epoch: 31, Loss (standarized): 1.5301209353411491\n",
      "          Validation Loss (standardized): 1.5476927890544707\n",
      "Epoch: 36, Loss (standarized): 1.50364817832065\n",
      "          Validation Loss (standardized): 1.5291826294436182\n",
      "Epoch: 41, Loss (standarized): 1.4708340535605544\n",
      "          Validation Loss (standardized): 1.498631414057226\n",
      "Epoch: 46, Loss (standarized): 1.4398527438828774\n",
      "          Validation Loss (standardized): 1.4609381282493359\n",
      "Epoch: 51, Loss (standarized): 1.4137792163206382\n",
      "          Validation Loss (standardized): 1.4261322425953449\n",
      "Epoch: 56, Loss (standarized): 1.3906160932020537\n",
      "          Validation Loss (standardized): 1.4120872324638913\n",
      "Epoch: 61, Loss (standarized): 1.3699586372775803\n",
      "          Validation Loss (standardized): 1.405504791725107\n",
      "Epoch: 66, Loss (standarized): 1.3528786938007982\n",
      "          Validation Loss (standardized): 1.3952222530900704\n",
      "Epoch: 71, Loss (standarized): 1.3395090673404149\n",
      "          Validation Loss (standardized): 1.3822826467155573\n",
      "Epoch: 76, Loss (standarized): 1.3290761754665783\n",
      "          Validation Loss (standardized): 1.3717686272548248\n",
      "Epoch: 81, Loss (standarized): 1.3196786488414032\n",
      "          Validation Loss (standardized): 1.363178834354771\n",
      "Epoch: 86, Loss (standarized): 1.3101045028929326\n",
      "          Validation Loss (standardized): 1.3554390729916905\n",
      "Epoch: 91, Loss (standarized): 1.2999784237804395\n",
      "          Validation Loss (standardized): 1.3462514155535872\n",
      "Epoch: 96, Loss (standarized): 1.288959716873135\n",
      "          Validation Loss (standardized): 1.33589414894821\n",
      "Final epoch: 100, Final loss (standarized): 1.2793848184269134\n",
      "Epoch: 1, Loss (standarized): 1.8706956655688458\n",
      "          Validation Loss (standardized): 1.8988407027247807\n",
      "Epoch: 6, Loss (standarized): 1.6125891765712839\n",
      "          Validation Loss (standardized): 1.5866215427429464\n",
      "Epoch: 11, Loss (standarized): 1.6082875199975217\n",
      "          Validation Loss (standardized): 1.5618378119827707\n",
      "Epoch: 16, Loss (standarized): 1.6043971182006191\n",
      "          Validation Loss (standardized): 1.554652018203556\n",
      "Epoch: 21, Loss (standarized): 1.5797320854463124\n",
      "          Validation Loss (standardized): 1.5628518131299862\n",
      "Epoch: 26, Loss (standarized): 1.5645524712052625\n",
      "          Validation Loss (standardized): 1.5830616079858786\n",
      "Epoch: 31, Loss (standarized): 1.5523387706679015\n",
      "          Validation Loss (standardized): 1.583790920880835\n",
      "Epoch: 36, Loss (standarized): 1.5293209281428728\n",
      "          Validation Loss (standardized): 1.5559108384986395\n",
      "Epoch: 41, Loss (standarized): 1.5021748933901982\n",
      "          Validation Loss (standardized): 1.5137881796493164\n",
      "Epoch: 46, Loss (standarized): 1.473830261892104\n",
      "          Validation Loss (standardized): 1.4789810668838508\n",
      "Epoch: 51, Loss (standarized): 1.443925972102369\n",
      "          Validation Loss (standardized): 1.4618410460641087\n",
      "Epoch: 56, Loss (standarized): 1.4182234400369254\n",
      "          Validation Loss (standardized): 1.446754982411948\n",
      "Epoch: 61, Loss (standarized): 1.4000757296414046\n",
      "          Validation Loss (standardized): 1.4332633788078313\n",
      "Epoch: 66, Loss (standarized): 1.3885708956106706\n",
      "          Validation Loss (standardized): 1.4221499606372379\n",
      "Epoch: 71, Loss (standarized): 1.3827522407540647\n",
      "          Validation Loss (standardized): 1.4147818777681982\n",
      "Epoch: 76, Loss (standarized): 1.380768760539037\n",
      "          Validation Loss (standardized): 1.4164730044433986\n",
      "Epoch: 81, Loss (standarized): 1.3802488352318563\n",
      "          Validation Loss (standardized): 1.4178518520391579\n",
      "Epoch: 86, Loss (standarized): 1.3792415317777897\n",
      "          Validation Loss (standardized): 1.4182846433637915\n",
      "Epoch: 91, Loss (standarized): 1.377245245532918\n",
      "          Validation Loss (standardized): 1.4151317546772892\n",
      "Epoch: 96, Loss (standarized): 1.3749307289881705\n",
      "          Validation Loss (standardized): 1.4129844311834499\n",
      "Final epoch: 100, Final loss (standarized): 1.37337830280277\n",
      "Epoch: 1, Loss (standarized): 1.67650933091681\n",
      "          Validation Loss (standardized): 1.5462159783347342\n",
      "Epoch: 6, Loss (standarized): 1.615318729063151\n",
      "          Validation Loss (standardized): 1.697866255940564\n",
      "Epoch: 11, Loss (standarized): 1.5903936343646148\n",
      "          Validation Loss (standardized): 1.5627728008599722\n",
      "Epoch: 16, Loss (standarized): 1.5732548767258874\n",
      "          Validation Loss (standardized): 1.554471077329415\n",
      "Epoch: 21, Loss (standarized): 1.5447295370459733\n",
      "          Validation Loss (standardized): 1.5698307487669025\n",
      "Epoch: 26, Loss (standarized): 1.5069446110147025\n",
      "          Validation Loss (standardized): 1.5189162301487658\n",
      "Epoch: 31, Loss (standarized): 1.4604431507407778\n",
      "          Validation Loss (standardized): 1.470137745493174\n",
      "Epoch: 36, Loss (standarized): 1.4139449547514729\n",
      "          Validation Loss (standardized): 1.4401193120433464\n",
      "Epoch: 41, Loss (standarized): 1.377927406428725\n",
      "          Validation Loss (standardized): 1.4035359046606468\n",
      "Epoch: 46, Loss (standarized): 1.357623837938053\n",
      "          Validation Loss (standardized): 1.3872222785672652\n",
      "Epoch: 51, Loss (standarized): 1.34581347597584\n",
      "          Validation Loss (standardized): 1.3813495695238152\n",
      "Epoch: 56, Loss (standarized): 1.3370078024781589\n",
      "          Validation Loss (standardized): 1.3672517469848953\n",
      "Epoch: 61, Loss (standarized): 1.329225087037832\n",
      "          Validation Loss (standardized): 1.3662528491594286\n",
      "Epoch: 66, Loss (standarized): 1.323662035396095\n",
      "          Validation Loss (standardized): 1.368272366892045\n",
      "Epoch: 71, Loss (standarized): 1.319540645061696\n",
      "          Validation Loss (standardized): 1.3619514105844541\n",
      "Epoch: 76, Loss (standarized): 1.3149457917507659\n",
      "          Validation Loss (standardized): 1.3615563182020625\n",
      "Epoch: 81, Loss (standarized): 1.3092102982645801\n",
      "          Validation Loss (standardized): 1.3556976672194125\n",
      "Epoch: 86, Loss (standarized): 1.3025205728177156\n",
      "          Validation Loss (standardized): 1.3463685547494209\n",
      "Epoch: 91, Loss (standarized): 1.2948598830630547\n",
      "          Validation Loss (standardized): 1.3416471744421932\n",
      "Epoch: 96, Loss (standarized): 1.2857852706408903\n",
      "          Validation Loss (standardized): 1.333265650606937\n",
      "Final epoch: 100, Final loss (standarized): 1.2770876991464193\n",
      "Epoch: 1, Loss (standarized): 1.6430032094966145\n",
      "          Validation Loss (standardized): 1.570227060461276\n",
      "Epoch: 6, Loss (standarized): 1.602444396302965\n",
      "          Validation Loss (standardized): 1.6519786992045182\n",
      "Epoch: 11, Loss (standarized): 1.5692293934584602\n",
      "          Validation Loss (standardized): 1.5519439932350405\n",
      "Epoch: 16, Loss (standarized): 1.5376178361535195\n",
      "          Validation Loss (standardized): 1.5340542050804635\n",
      "Epoch: 21, Loss (standarized): 1.4920391136141202\n",
      "          Validation Loss (standardized): 1.5153905774376895\n",
      "Epoch: 26, Loss (standarized): 1.439767033842642\n",
      "          Validation Loss (standardized): 1.468803507999888\n",
      "Epoch: 31, Loss (standarized): 1.390470475759227\n",
      "          Validation Loss (standardized): 1.4098860866684615\n",
      "Epoch: 36, Loss (standarized): 1.3591303871070233\n",
      "          Validation Loss (standardized): 1.3969227174176644\n",
      "Epoch: 41, Loss (standarized): 1.3460661439203025\n",
      "          Validation Loss (standardized): 1.3849169678200033\n",
      "Epoch: 46, Loss (standarized): 1.338030432649377\n",
      "          Validation Loss (standardized): 1.3660672134636889\n",
      "Epoch: 51, Loss (standarized): 1.3299659375058877\n",
      "          Validation Loss (standardized): 1.3580225257113403\n",
      "Epoch: 56, Loss (standarized): 1.322625066465151\n",
      "          Validation Loss (standardized): 1.3561136260731457\n",
      "Epoch: 61, Loss (standarized): 1.3160284782496683\n",
      "          Validation Loss (standardized): 1.352677644677498\n",
      "Epoch: 66, Loss (standarized): 1.3087009027415093\n",
      "          Validation Loss (standardized): 1.3507701339030094\n",
      "Epoch: 71, Loss (standarized): 1.2992225848610923\n",
      "          Validation Loss (standardized): 1.3429613657081771\n",
      "Epoch: 76, Loss (standarized): 1.2869177568290702\n",
      "          Validation Loss (standardized): 1.3286400416934605\n",
      "Epoch: 81, Loss (standarized): 1.2713489449782545\n",
      "          Validation Loss (standardized): 1.3151188066799864\n",
      "Epoch: 86, Loss (standarized): 1.2516015168148966\n",
      "          Validation Loss (standardized): 1.298882502205041\n",
      "Epoch: 91, Loss (standarized): 1.2271393574367517\n",
      "          Validation Loss (standardized): 1.281286559477428\n",
      "Epoch: 96, Loss (standarized): 1.1981444526528007\n",
      "          Validation Loss (standardized): 1.2618789833705273\n",
      "Final epoch: 100, Final loss (standarized): 1.1721797412912458\n",
      "Epoch: 1, Loss (standarized): 1.687406860356348\n",
      "          Validation Loss (standardized): 1.6196163111902706\n",
      "Epoch: 6, Loss (standarized): 1.6061127671561428\n",
      "          Validation Loss (standardized): 1.6087177092927532\n",
      "Epoch: 11, Loss (standarized): 1.6106266403437848\n",
      "          Validation Loss (standardized): 1.6033189669438075\n",
      "Epoch: 16, Loss (standarized): 1.6076436418222686\n",
      "          Validation Loss (standardized): 1.5977297500874286\n",
      "Epoch: 21, Loss (standarized): 1.6101229197496931\n",
      "          Validation Loss (standardized): 1.605024474249029\n",
      "Epoch: 26, Loss (standarized): 1.608966416329134\n",
      "          Validation Loss (standardized): 1.6023915105485462\n",
      "Epoch: 31, Loss (standarized): 1.6096123580631303\n",
      "          Validation Loss (standardized): 1.5975614722758016\n",
      "Epoch: 36, Loss (standarized): 1.6094514169530254\n",
      "          Validation Loss (standardized): 1.6063448322962481\n",
      "Epoch: 41, Loss (standarized): 1.609511389437073\n",
      "          Validation Loss (standardized): 1.6050999453417911\n",
      "Epoch: 46, Loss (standarized): 1.6094944561284703\n",
      "          Validation Loss (standardized): 1.6044971927855036\n",
      "Epoch: 51, Loss (standarized): 1.6094892497080673\n",
      "          Validation Loss (standardized): 1.6035213842936282\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 1.6097707515203792\n",
      "          Validation Loss (standardized): 1.596588016701221\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 1.6097040198597765\n",
      "          Validation Loss (standardized): 1.6052304924854224\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 1.6096037631503373\n",
      "          Validation Loss (standardized): 1.6198718748328547\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 1.6097559852485477\n",
      "          Validation Loss (standardized): 1.6206244507473806\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 1.6096657795664964\n",
      "          Validation Loss (standardized): 1.6192919748856427\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 1.6097087215725137\n",
      "          Validation Loss (standardized): 1.6190529941996588\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 1.6095545688075565\n",
      "          Validation Loss (standardized): 1.6140636852357064\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 1.6095830210886306\n",
      "          Validation Loss (standardized): 1.6177628966043016\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 1.6095015711610323\n",
      "          Validation Loss (standardized): 1.6142080284559253\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 1.6096073601023824\n",
      "Epoch: 1, Loss (standarized): 1.7839498309050048\n",
      "          Validation Loss (standardized): 1.715240560815839\n",
      "Epoch: 6, Loss (standarized): 1.6188893256900725\n",
      "          Validation Loss (standardized): 1.5987097259624352\n",
      "Epoch: 11, Loss (standarized): 1.625145780586548\n",
      "          Validation Loss (standardized): 1.6135652730761365\n",
      "Epoch: 16, Loss (standarized): 1.6172798459708253\n",
      "          Validation Loss (standardized): 1.6139485295449132\n",
      "Epoch: 21, Loss (standarized): 1.6122688189280805\n",
      "          Validation Loss (standardized): 1.610419045702637\n",
      "Epoch: 26, Loss (standarized): 1.6125642796872373\n",
      "          Validation Loss (standardized): 1.6015121558083045\n",
      "Epoch: 31, Loss (standarized): 1.6109122617376546\n",
      "          Validation Loss (standardized): 1.594367277266682\n",
      "Epoch: 36, Loss (standarized): 1.6105034281317632\n",
      "          Validation Loss (standardized): 1.6018286838579383\n",
      "Epoch: 41, Loss (standarized): 1.6103226024102761\n",
      "          Validation Loss (standardized): 1.6063256798866554\n",
      "Epoch: 46, Loss (standarized): 1.609646472894906\n",
      "          Validation Loss (standardized): 1.6007879851967912\n",
      "Epoch: 51, Loss (standarized): 1.6096507786651006\n",
      "          Validation Loss (standardized): 1.600105427031481\n",
      "Epoch: 56, Loss (standarized): 1.6096727591806406\n",
      "          Validation Loss (standardized): 1.6025867533374665\n",
      "Epoch: 61, Loss (standarized): 1.6097271654170637\n",
      "          Validation Loss (standardized): 1.605069904328625\n",
      "Epoch: 66, Loss (standarized): 1.6099193483024425\n",
      "          Validation Loss (standardized): 1.6013875522454135\n",
      "Epoch: 71, Loss (standarized): 1.6097255601793623\n",
      "          Validation Loss (standardized): 1.608085416174443\n",
      "Epoch: 76, Loss (standarized): 1.6095175708581553\n",
      "          Validation Loss (standardized): 1.609311495556196\n",
      "Epoch: 81, Loss (standarized): 1.609449602098892\n",
      "          Validation Loss (standardized): 1.612607611317481\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 1.6095484629483172\n",
      "          Validation Loss (standardized): 1.616733739476347\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 1.6096428596538794\n",
      "          Validation Loss (standardized): 1.6177593027304933\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 1.6096484920902225\n",
      "          Validation Loss (standardized): 1.6187110372694322\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 1.6096406281825926\n",
      "Epoch: 1, Loss (standarized): 1.713329755559914\n",
      "          Validation Loss (standardized): 1.7723768151208619\n",
      "Epoch: 6, Loss (standarized): 1.6009068351816944\n",
      "          Validation Loss (standardized): 1.601702183219393\n",
      "Epoch: 11, Loss (standarized): 1.6123104156084112\n",
      "          Validation Loss (standardized): 1.5678060599455528\n",
      "Epoch: 16, Loss (standarized): 1.611292186367392\n",
      "          Validation Loss (standardized): 1.5799710129004627\n",
      "Epoch: 21, Loss (standarized): 1.607702479192772\n",
      "          Validation Loss (standardized): 1.617461832375407\n",
      "Epoch: 26, Loss (standarized): 1.6094646433566253\n",
      "          Validation Loss (standardized): 1.629497098926894\n",
      "Epoch: 31, Loss (standarized): 1.6096836231305158\n",
      "          Validation Loss (standardized): 1.6167980018822468\n",
      "Epoch: 36, Loss (standarized): 1.6097446199042549\n",
      "          Validation Loss (standardized): 1.6095656282457493\n",
      "Epoch: 41, Loss (standarized): 1.610036124652134\n",
      "          Validation Loss (standardized): 1.6086558746408266\n",
      "Epoch: 46, Loss (standarized): 1.6097803475113313\n",
      "          Validation Loss (standardized): 1.6078270651727713\n",
      "Epoch: 51, Loss (standarized): 1.6094979190197267\n",
      "          Validation Loss (standardized): 1.6096626736415411\n",
      "Epoch: 56, Loss (standarized): 1.6096997828726456\n",
      "          Validation Loss (standardized): 1.6095613482317708\n",
      "Epoch: 61, Loss (standarized): 1.6094872004664733\n",
      "          Validation Loss (standardized): 1.6075872312252641\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 1.6095793594777736\n",
      "          Validation Loss (standardized): 1.5996748944242887\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 1.609590429300342\n",
      "          Validation Loss (standardized): 1.5990844940431368\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 1.6096585320555392\n",
      "          Validation Loss (standardized): 1.5983593408866164\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 1.609690589103448\n",
      "          Validation Loss (standardized): 1.6012664358739443\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 1.609622873373303\n",
      "          Validation Loss (standardized): 1.6045648016431746\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 1.6095725815315733\n",
      "          Validation Loss (standardized): 1.6076746909786974\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 1.6095203991118547\n",
      "          Validation Loss (standardized): 1.6073910227844381\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 1.609472477600162\n",
      "Epoch: 1, Loss (standarized): 1.7877092605158345\n",
      "          Validation Loss (standardized): 1.5751378311053619\n",
      "Epoch: 6, Loss (standarized): 1.6101794099431572\n",
      "          Validation Loss (standardized): 1.5786228015135926\n",
      "Epoch: 11, Loss (standarized): 1.616865753317075\n",
      "          Validation Loss (standardized): 1.6701629511169191\n",
      "Epoch: 16, Loss (standarized): 1.6153877757158324\n",
      "          Validation Loss (standardized): 1.6656355411206443\n",
      "Epoch: 21, Loss (standarized): 1.6090289238165\n",
      "          Validation Loss (standardized): 1.6060102313523295\n",
      "Epoch: 26, Loss (standarized): 1.6109715964200815\n",
      "          Validation Loss (standardized): 1.5807369302558505\n",
      "Epoch: 31, Loss (standarized): 1.610211164955202\n",
      "          Validation Loss (standardized): 1.6010301023674582\n",
      "Epoch: 36, Loss (standarized): 1.6095358642309878\n",
      "          Validation Loss (standardized): 1.619665045765892\n",
      "Epoch: 41, Loss (standarized): 1.6097595538978116\n",
      "          Validation Loss (standardized): 1.6125440266249589\n",
      "Epoch: 46, Loss (standarized): 1.6095430846203975\n",
      "          Validation Loss (standardized): 1.6063292339493123\n",
      "Epoch: 51, Loss (standarized): 1.609660705989438\n",
      "          Validation Loss (standardized): 1.6015467861505204\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 1.6099760050158796\n",
      "          Validation Loss (standardized): 1.5981736167164613\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 1.6098504094759107\n",
      "          Validation Loss (standardized): 1.6044979621969861\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 1.6097014566226244\n",
      "          Validation Loss (standardized): 1.6087580871516116\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 1.6096931098433398\n",
      "          Validation Loss (standardized): 1.6069916022537318\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 1.6096555613088264\n",
      "          Validation Loss (standardized): 1.6153035669676319\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 1.6097269971870258\n",
      "          Validation Loss (standardized): 1.619965020037441\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 1.6099051861784757\n",
      "          Validation Loss (standardized): 1.6292400095321642\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 1.609923225777158\n",
      "          Validation Loss (standardized): 1.6278172409806448\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 1.6098657081539145\n",
      "          Validation Loss (standardized): 1.6256551929039211\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 1.609848989864702\n",
      "Epoch: 1, Loss (standarized): 1.7937662488377593\n",
      "          Validation Loss (standardized): 1.5441232675577623\n",
      "Epoch: 6, Loss (standarized): 1.6064111627553919\n",
      "          Validation Loss (standardized): 1.6583106267737207\n",
      "Epoch: 11, Loss (standarized): 1.6205495967409325\n",
      "          Validation Loss (standardized): 1.6632666058621823\n",
      "Epoch: 16, Loss (standarized): 1.599135823231889\n",
      "          Validation Loss (standardized): 1.595196754921168\n",
      "Epoch: 21, Loss (standarized): 1.5836470041453605\n",
      "          Validation Loss (standardized): 1.5839005871413387\n",
      "Epoch: 26, Loss (standarized): 1.577783209280001\n",
      "          Validation Loss (standardized): 1.5673765577390164\n",
      "Epoch: 31, Loss (standarized): 1.5599732014162755\n",
      "          Validation Loss (standardized): 1.5593819249079357\n",
      "Epoch: 36, Loss (standarized): 1.5412220860063561\n",
      "          Validation Loss (standardized): 1.5635845137078568\n",
      "Epoch: 41, Loss (standarized): 1.516824227780308\n",
      "          Validation Loss (standardized): 1.5318431440471318\n",
      "Epoch: 46, Loss (standarized): 1.4859272312366432\n",
      "          Validation Loss (standardized): 1.4987796811646876\n",
      "Epoch: 51, Loss (standarized): 1.4516737171544065\n",
      "          Validation Loss (standardized): 1.4721312121318841\n",
      "Epoch: 56, Loss (standarized): 1.4174200181531031\n",
      "          Validation Loss (standardized): 1.4460360512451529\n",
      "Epoch: 61, Loss (standarized): 1.3896824214237968\n",
      "          Validation Loss (standardized): 1.4205351809853135\n",
      "Epoch: 66, Loss (standarized): 1.3700590171398808\n",
      "          Validation Loss (standardized): 1.4029793865059994\n",
      "Epoch: 71, Loss (standarized): 1.3567149621323489\n",
      "          Validation Loss (standardized): 1.3947235652351873\n",
      "Epoch: 76, Loss (standarized): 1.3475669244501205\n",
      "          Validation Loss (standardized): 1.3854825098135994\n",
      "Epoch: 81, Loss (standarized): 1.3413215187949397\n",
      "          Validation Loss (standardized): 1.381078364212264\n",
      "Epoch: 86, Loss (standarized): 1.3368978899644355\n",
      "          Validation Loss (standardized): 1.3785042511885\n",
      "Epoch: 91, Loss (standarized): 1.3333441467392653\n",
      "          Validation Loss (standardized): 1.374408742132511\n",
      "Epoch: 96, Loss (standarized): 1.3298732253457508\n",
      "          Validation Loss (standardized): 1.3705086816860943\n",
      "Final epoch: 100, Final loss (standarized): 1.3267448362853116\n",
      "Epoch: 1, Loss (standarized): 1.655691540231586\n",
      "          Validation Loss (standardized): 1.5805097532150107\n",
      "Epoch: 6, Loss (standarized): 1.600231328246752\n",
      "          Validation Loss (standardized): 1.6336950893172937\n",
      "Epoch: 11, Loss (standarized): 1.5813027113560012\n",
      "          Validation Loss (standardized): 1.593157762529568\n",
      "Epoch: 16, Loss (standarized): 1.5741832855781133\n",
      "          Validation Loss (standardized): 1.5646283298854473\n",
      "Epoch: 21, Loss (standarized): 1.5599160949786743\n",
      "          Validation Loss (standardized): 1.5712188805081873\n",
      "Epoch: 26, Loss (standarized): 1.5472858495218245\n",
      "          Validation Loss (standardized): 1.5726172430349703\n",
      "Epoch: 31, Loss (standarized): 1.5297397053100243\n",
      "          Validation Loss (standardized): 1.5468498345869712\n",
      "Epoch: 36, Loss (standarized): 1.5088078208601974\n",
      "          Validation Loss (standardized): 1.5211102324377963\n",
      "Epoch: 41, Loss (standarized): 1.4831755705785312\n",
      "          Validation Loss (standardized): 1.513825187601748\n",
      "Epoch: 46, Loss (standarized): 1.4560972037535804\n",
      "          Validation Loss (standardized): 1.4854642871132169\n",
      "Epoch: 51, Loss (standarized): 1.4311200813318576\n",
      "          Validation Loss (standardized): 1.460520675838573\n",
      "Epoch: 56, Loss (standarized): 1.4117110133960347\n",
      "          Validation Loss (standardized): 1.4459067470996168\n",
      "Epoch: 61, Loss (standarized): 1.3998917178364472\n",
      "          Validation Loss (standardized): 1.4385499075031936\n",
      "Epoch: 66, Loss (standarized): 1.3945678305351101\n",
      "          Validation Loss (standardized): 1.4310333459286182\n",
      "Epoch: 71, Loss (standarized): 1.3930567724777938\n",
      "          Validation Loss (standardized): 1.4328144243769463\n",
      "Epoch: 76, Loss (standarized): 1.3930726889822933\n",
      "          Validation Loss (standardized): 1.4339100595949588\n",
      "Epoch: 81, Loss (standarized): 1.3929254981354615\n",
      "          Validation Loss (standardized): 1.4330798224099834\n",
      "Epoch: 86, Loss (standarized): 1.391884699166727\n",
      "          Validation Loss (standardized): 1.433241994421685\n",
      "Epoch: 91, Loss (standarized): 1.3902969569450863\n",
      "          Validation Loss (standardized): 1.432577299275186\n",
      "Epoch: 96, Loss (standarized): 1.388978948928672\n",
      "          Validation Loss (standardized): 1.432080617606746\n",
      "Final epoch: 100, Final loss (standarized): 1.3883051035242864\n",
      "Epoch: 1, Loss (standarized): 1.666492038105548\n",
      "          Validation Loss (standardized): 1.7208935798651115\n",
      "Epoch: 6, Loss (standarized): 1.6057954554684128\n",
      "          Validation Loss (standardized): 1.5361163199067156\n",
      "Epoch: 11, Loss (standarized): 1.585143097210632\n",
      "          Validation Loss (standardized): 1.5686925494993675\n",
      "Epoch: 16, Loss (standarized): 1.565086528112829\n",
      "          Validation Loss (standardized): 1.6098867226038225\n",
      "Epoch: 21, Loss (standarized): 1.5375062890154994\n",
      "          Validation Loss (standardized): 1.5593512800120273\n",
      "Epoch: 26, Loss (standarized): 1.5004565526597458\n",
      "          Validation Loss (standardized): 1.4960657413934833\n",
      "Epoch: 31, Loss (standarized): 1.4566033312942497\n",
      "          Validation Loss (standardized): 1.4692163173845265\n",
      "Epoch: 36, Loss (standarized): 1.4136398162605877\n",
      "          Validation Loss (standardized): 1.4524855071291116\n",
      "Epoch: 41, Loss (standarized): 1.380881442344445\n",
      "          Validation Loss (standardized): 1.4158168715628812\n",
      "Epoch: 46, Loss (standarized): 1.3619107196689908\n",
      "          Validation Loss (standardized): 1.387010698758334\n",
      "Epoch: 51, Loss (standarized): 1.3519230018472226\n",
      "          Validation Loss (standardized): 1.386986040706834\n",
      "Epoch: 56, Loss (standarized): 1.3465597006498777\n",
      "          Validation Loss (standardized): 1.3876405230574758\n",
      "Epoch: 61, Loss (standarized): 1.3437078906397693\n",
      "          Validation Loss (standardized): 1.3804785338322307\n",
      "Epoch: 66, Loss (standarized): 1.3426811421841638\n",
      "          Validation Loss (standardized): 1.3817877184666294\n",
      "Epoch: 71, Loss (standarized): 1.3421760986430895\n",
      "          Validation Loss (standardized): 1.3844982936426176\n",
      "Epoch: 76, Loss (standarized): 1.3410697212832512\n",
      "          Validation Loss (standardized): 1.3829280940699602\n",
      "Epoch: 81, Loss (standarized): 1.3392299623462467\n",
      "          Validation Loss (standardized): 1.3804506964876158\n",
      "Epoch: 86, Loss (standarized): 1.337036263789655\n",
      "          Validation Loss (standardized): 1.3784769582020595\n",
      "Epoch: 91, Loss (standarized): 1.334752709391799\n",
      "          Validation Loss (standardized): 1.3757012876666457\n",
      "Epoch: 96, Loss (standarized): 1.3324825666204605\n",
      "          Validation Loss (standardized): 1.371063599329745\n",
      "Final epoch: 100, Final loss (standarized): 1.3306908330151652\n",
      "Epoch: 1, Loss (standarized): 1.8563669022839167\n",
      "          Validation Loss (standardized): 1.4981459976544194\n",
      "Epoch: 6, Loss (standarized): 1.6127165990334253\n",
      "          Validation Loss (standardized): 1.6582653284645121\n",
      "Epoch: 11, Loss (standarized): 1.6150476926580233\n",
      "          Validation Loss (standardized): 1.7085792063410463\n",
      "Epoch: 16, Loss (standarized): 1.5948805806889346\n",
      "          Validation Loss (standardized): 1.6526144759100563\n",
      "Epoch: 21, Loss (standarized): 1.560236816842088\n",
      "          Validation Loss (standardized): 1.5876378867810585\n",
      "Epoch: 26, Loss (standarized): 1.5368107064645011\n",
      "          Validation Loss (standardized): 1.5198319643436302\n",
      "Epoch: 31, Loss (standarized): 1.5061742822289268\n",
      "          Validation Loss (standardized): 1.4860485182395264\n",
      "Epoch: 36, Loss (standarized): 1.4645083739904388\n",
      "          Validation Loss (standardized): 1.4888014122543254\n",
      "Epoch: 41, Loss (standarized): 1.4268400850263396\n",
      "          Validation Loss (standardized): 1.4783799839129232\n",
      "Epoch: 46, Loss (standarized): 1.394064535477016\n",
      "          Validation Loss (standardized): 1.4415431102817104\n",
      "Epoch: 51, Loss (standarized): 1.3693469967725929\n",
      "          Validation Loss (standardized): 1.4081737360072335\n",
      "Epoch: 56, Loss (standarized): 1.3543906136055153\n",
      "          Validation Loss (standardized): 1.387215960241473\n",
      "Epoch: 61, Loss (standarized): 1.3451114235494743\n",
      "          Validation Loss (standardized): 1.3793101129717018\n",
      "Epoch: 66, Loss (standarized): 1.3394588524163609\n",
      "          Validation Loss (standardized): 1.3812303875519645\n",
      "Epoch: 71, Loss (standarized): 1.3364761835694006\n",
      "          Validation Loss (standardized): 1.3806706626157204\n",
      "Epoch: 76, Loss (standarized): 1.3347040844589895\n",
      "          Validation Loss (standardized): 1.3772209641603874\n",
      "Epoch: 81, Loss (standarized): 1.3332908411767976\n",
      "          Validation Loss (standardized): 1.3761422801737717\n",
      "Epoch: 86, Loss (standarized): 1.3318751199991528\n",
      "          Validation Loss (standardized): 1.3765272333180347\n",
      "Epoch: 91, Loss (standarized): 1.3305199378930366\n",
      "          Validation Loss (standardized): 1.376548561691055\n",
      "Epoch: 96, Loss (standarized): 1.3291354829539852\n",
      "          Validation Loss (standardized): 1.3753549498801527\n",
      "Final epoch: 100, Final loss (standarized): 1.3279495026873778\n",
      "Epoch: 1, Loss (standarized): 1.802871850131193\n",
      "          Validation Loss (standardized): 1.494250298114123\n",
      "Epoch: 6, Loss (standarized): 1.6153370015032136\n",
      "          Validation Loss (standardized): 1.575182300735719\n",
      "Epoch: 11, Loss (standarized): 1.609029746344528\n",
      "          Validation Loss (standardized): 1.7232334567065348\n",
      "Epoch: 16, Loss (standarized): 1.5865275531034198\n",
      "          Validation Loss (standardized): 1.6554174694703607\n",
      "Epoch: 21, Loss (standarized): 1.550146300511086\n",
      "          Validation Loss (standardized): 1.5541161345774859\n",
      "Epoch: 26, Loss (standarized): 1.5216512181340573\n",
      "          Validation Loss (standardized): 1.508573590694501\n",
      "Epoch: 31, Loss (standarized): 1.4782557066274455\n",
      "          Validation Loss (standardized): 1.4938594053040983\n",
      "Epoch: 36, Loss (standarized): 1.427869164904084\n",
      "          Validation Loss (standardized): 1.4763179591193745\n",
      "Epoch: 41, Loss (standarized): 1.3845569693586723\n",
      "          Validation Loss (standardized): 1.4482000843018654\n",
      "Epoch: 46, Loss (standarized): 1.354071131489025\n",
      "          Validation Loss (standardized): 1.4095385173976933\n",
      "Epoch: 51, Loss (standarized): 1.3384225285861726\n",
      "          Validation Loss (standardized): 1.3745200059143317\n",
      "Epoch: 56, Loss (standarized): 1.3321150117497593\n",
      "          Validation Loss (standardized): 1.3641892933322515\n",
      "Epoch: 61, Loss (standarized): 1.3289919706725073\n",
      "          Validation Loss (standardized): 1.3694976366763245\n",
      "Epoch: 66, Loss (standarized): 1.3264615254396088\n",
      "          Validation Loss (standardized): 1.3691781640854597\n",
      "Epoch: 71, Loss (standarized): 1.3227252339893305\n",
      "          Validation Loss (standardized): 1.3600944684782126\n",
      "Epoch: 76, Loss (standarized): 1.3181183844487387\n",
      "          Validation Loss (standardized): 1.351687109356792\n",
      "Epoch: 81, Loss (standarized): 1.3130174966293702\n",
      "          Validation Loss (standardized): 1.3483863667172975\n",
      "Epoch: 86, Loss (standarized): 1.3074989671832145\n",
      "          Validation Loss (standardized): 1.3469262014691192\n",
      "Epoch: 91, Loss (standarized): 1.3012143077995255\n",
      "          Validation Loss (standardized): 1.3407492224649613\n",
      "Epoch: 96, Loss (standarized): 1.2936814407114088\n",
      "          Validation Loss (standardized): 1.3302928495185515\n",
      "Final epoch: 100, Final loss (standarized): 1.2866273533582493\n",
      "Epoch: 1, Loss (standarized): 1.6724880425959254\n",
      "          Validation Loss (standardized): 1.5868670715675224\n",
      "Epoch: 6, Loss (standarized): 1.6168100038130704\n",
      "          Validation Loss (standardized): 1.647887249477337\n",
      "Epoch: 11, Loss (standarized): 1.5973744055059915\n",
      "          Validation Loss (standardized): 1.603801666915349\n",
      "Epoch: 16, Loss (standarized): 1.5896383506134453\n",
      "          Validation Loss (standardized): 1.5691697587208042\n",
      "Epoch: 21, Loss (standarized): 1.5764914145798195\n",
      "          Validation Loss (standardized): 1.5806831372809629\n",
      "Epoch: 26, Loss (standarized): 1.5647941532999439\n",
      "          Validation Loss (standardized): 1.5862331553540492\n",
      "Epoch: 31, Loss (standarized): 1.5461478028506297\n",
      "          Validation Loss (standardized): 1.5501613583787335\n",
      "Epoch: 36, Loss (standarized): 1.5221789021731746\n",
      "          Validation Loss (standardized): 1.5279946235462418\n",
      "Epoch: 41, Loss (standarized): 1.490425251421966\n",
      "          Validation Loss (standardized): 1.5123321946550676\n",
      "Epoch: 46, Loss (standarized): 1.4542220635446383\n",
      "          Validation Loss (standardized): 1.4795735574734887\n",
      "Epoch: 51, Loss (standarized): 1.4195537921666699\n",
      "          Validation Loss (standardized): 1.444028125072124\n",
      "Epoch: 56, Loss (standarized): 1.3935066771141964\n",
      "          Validation Loss (standardized): 1.429066370871271\n",
      "Epoch: 61, Loss (standarized): 1.3785532842653696\n",
      "          Validation Loss (standardized): 1.4157793005553598\n",
      "Epoch: 66, Loss (standarized): 1.3723409985212303\n",
      "          Validation Loss (standardized): 1.4102159456131038\n",
      "Epoch: 71, Loss (standarized): 1.3713699021753536\n",
      "          Validation Loss (standardized): 1.4133101971413142\n",
      "Epoch: 76, Loss (standarized): 1.372730887506369\n",
      "          Validation Loss (standardized): 1.416140363061635\n",
      "Epoch: 81, Loss (standarized): 1.3737998309171666\n",
      "          Validation Loss (standardized): 1.4160170879074039\n",
      "Epoch: 86, Loss (standarized): 1.3733035952329948\n",
      "          Validation Loss (standardized): 1.4161171516479525\n",
      "Epoch: 91, Loss (standarized): 1.371946110066301\n",
      "          Validation Loss (standardized): 1.4143960585062567\n",
      "Epoch: 96, Loss (standarized): 1.3707197774134006\n",
      "          Validation Loss (standardized): 1.412255230266288\n",
      "Final epoch: 100, Final loss (standarized): 1.3701705361281713\n",
      "Epoch: 1, Loss (standarized): 1.6865422322041979\n",
      "          Validation Loss (standardized): 1.7253019987893277\n",
      "Epoch: 6, Loss (standarized): 1.5809371638093936\n",
      "          Validation Loss (standardized): 1.601839077597812\n",
      "Epoch: 11, Loss (standarized): 1.5565512090650973\n",
      "          Validation Loss (standardized): 1.51333892178569\n",
      "Epoch: 16, Loss (standarized): 1.5130677722320867\n",
      "          Validation Loss (standardized): 1.5015455747282722\n",
      "Epoch: 21, Loss (standarized): 1.4657229645132264\n",
      "          Validation Loss (standardized): 1.5163943883504634\n",
      "Epoch: 26, Loss (standarized): 1.4206699899769644\n",
      "          Validation Loss (standardized): 1.4844260525553836\n",
      "Epoch: 31, Loss (standarized): 1.3800401773081972\n",
      "          Validation Loss (standardized): 1.4194903843787852\n",
      "Epoch: 36, Loss (standarized): 1.3570096862652081\n",
      "          Validation Loss (standardized): 1.3773625661809874\n",
      "Epoch: 41, Loss (standarized): 1.3459806991247538\n",
      "          Validation Loss (standardized): 1.3693484735551797\n",
      "Epoch: 46, Loss (standarized): 1.3399682093355154\n",
      "          Validation Loss (standardized): 1.3767912682356496\n",
      "Epoch: 51, Loss (standarized): 1.335401884752808\n",
      "          Validation Loss (standardized): 1.363766903592714\n",
      "Epoch: 56, Loss (standarized): 1.332601570335223\n",
      "          Validation Loss (standardized): 1.3599645290778604\n",
      "Epoch: 61, Loss (standarized): 1.3311429825615004\n",
      "          Validation Loss (standardized): 1.3644919247103298\n",
      "Epoch: 66, Loss (standarized): 1.3300059739932033\n",
      "          Validation Loss (standardized): 1.368607470089035\n",
      "Epoch: 71, Loss (standarized): 1.3284515893635467\n",
      "          Validation Loss (standardized): 1.3640475493941633\n",
      "Epoch: 76, Loss (standarized): 1.326364904794205\n",
      "          Validation Loss (standardized): 1.3617077030200215\n",
      "Epoch: 81, Loss (standarized): 1.323863943333302\n",
      "          Validation Loss (standardized): 1.3591648080656733\n",
      "Epoch: 86, Loss (standarized): 1.3210689213878868\n",
      "          Validation Loss (standardized): 1.3554916721703751\n",
      "Epoch: 91, Loss (standarized): 1.317847348281162\n",
      "          Validation Loss (standardized): 1.350937862310819\n",
      "Epoch: 96, Loss (standarized): 1.3139630410698069\n",
      "          Validation Loss (standardized): 1.347433372209699\n",
      "Final epoch: 100, Final loss (standarized): 1.3102264369808199\n",
      "Epoch: 1, Loss (standarized): 2.273866547575608\n",
      "          Validation Loss (standardized): 1.8214518829874131\n",
      "Epoch: 6, Loss (standarized): 1.7111729471944233\n",
      "          Validation Loss (standardized): 1.5365265292116588\n",
      "Epoch: 11, Loss (standarized): 1.6314522620742056\n",
      "          Validation Loss (standardized): 1.6348434941908934\n",
      "Epoch: 16, Loss (standarized): 1.6312203422924432\n",
      "          Validation Loss (standardized): 1.7397168673536112\n",
      "Epoch: 21, Loss (standarized): 1.6227748211608088\n",
      "          Validation Loss (standardized): 1.7331025166684897\n",
      "Epoch: 26, Loss (standarized): 1.5923162055747213\n",
      "          Validation Loss (standardized): 1.6342008496186398\n",
      "Epoch: 31, Loss (standarized): 1.566965406821938\n",
      "          Validation Loss (standardized): 1.5420757138388865\n",
      "Epoch: 36, Loss (standarized): 1.5507582917561888\n",
      "          Validation Loss (standardized): 1.5080741766831998\n",
      "Epoch: 41, Loss (standarized): 1.5307086415190503\n",
      "          Validation Loss (standardized): 1.5118741766314625\n",
      "Epoch: 46, Loss (standarized): 1.5042206823335749\n",
      "          Validation Loss (standardized): 1.5097277503590567\n",
      "Epoch: 51, Loss (standarized): 1.473797286732659\n",
      "          Validation Loss (standardized): 1.4930345203565234\n",
      "Epoch: 56, Loss (standarized): 1.4446983325854887\n",
      "          Validation Loss (standardized): 1.4788183842698603\n",
      "Epoch: 61, Loss (standarized): 1.4174311048975776\n",
      "          Validation Loss (standardized): 1.4647276552967416\n",
      "Epoch: 66, Loss (standarized): 1.392247375254467\n",
      "          Validation Loss (standardized): 1.4426638033402457\n",
      "Epoch: 71, Loss (standarized): 1.3715580207570042\n",
      "          Validation Loss (standardized): 1.4190695512884621\n",
      "Epoch: 76, Loss (standarized): 1.3563493372106603\n",
      "          Validation Loss (standardized): 1.4003436435721006\n",
      "Epoch: 81, Loss (standarized): 1.3456043534373885\n",
      "          Validation Loss (standardized): 1.3864513313659939\n",
      "Epoch: 86, Loss (standarized): 1.3372487485772533\n",
      "          Validation Loss (standardized): 1.3785137774891816\n",
      "Epoch: 91, Loss (standarized): 1.3299413586462043\n",
      "          Validation Loss (standardized): 1.3742006182550826\n",
      "Epoch: 96, Loss (standarized): 1.3231391697064607\n",
      "          Validation Loss (standardized): 1.3672964488172357\n",
      "Final epoch: 100, Final loss (standarized): 1.3177660576434733\n",
      "Epoch: 1, Loss (standarized): 2.00364518896542\n",
      "          Validation Loss (standardized): 1.5576595113192533\n",
      "Epoch: 6, Loss (standarized): 1.6286363460065627\n",
      "          Validation Loss (standardized): 1.5746164340420015\n",
      "Epoch: 11, Loss (standarized): 1.6104143378490006\n",
      "          Validation Loss (standardized): 1.7378098052423536\n",
      "Epoch: 16, Loss (standarized): 1.6111496009442532\n",
      "          Validation Loss (standardized): 1.7247037289993044\n",
      "Epoch: 21, Loss (standarized): 1.5706900392523249\n",
      "          Validation Loss (standardized): 1.6192376084491953\n",
      "Epoch: 26, Loss (standarized): 1.5376418530301244\n",
      "          Validation Loss (standardized): 1.544088109673255\n",
      "Epoch: 31, Loss (standarized): 1.5137712888961912\n",
      "          Validation Loss (standardized): 1.4963470216443884\n",
      "Epoch: 36, Loss (standarized): 1.480613639663811\n",
      "          Validation Loss (standardized): 1.4636160573071362\n",
      "Epoch: 41, Loss (standarized): 1.441456077695595\n",
      "          Validation Loss (standardized): 1.4547301855643677\n",
      "Epoch: 46, Loss (standarized): 1.4073889389316883\n",
      "          Validation Loss (standardized): 1.4556531453985486\n",
      "Epoch: 51, Loss (standarized): 1.3817609506242312\n",
      "          Validation Loss (standardized): 1.440528571290657\n",
      "Epoch: 56, Loss (standarized): 1.362750078270124\n",
      "          Validation Loss (standardized): 1.4136154938311094\n",
      "Epoch: 61, Loss (standarized): 1.3508037706391562\n",
      "          Validation Loss (standardized): 1.3929480096187161\n",
      "Epoch: 66, Loss (standarized): 1.3436003860874277\n",
      "          Validation Loss (standardized): 1.3805897271981038\n",
      "Epoch: 71, Loss (standarized): 1.3383090742323611\n",
      "          Validation Loss (standardized): 1.3781745566626724\n",
      "Epoch: 76, Loss (standarized): 1.3342030739170099\n",
      "          Validation Loss (standardized): 1.3821339400760893\n",
      "Epoch: 81, Loss (standarized): 1.3307285152070494\n",
      "          Validation Loss (standardized): 1.379865519031246\n",
      "Epoch: 86, Loss (standarized): 1.3271896408845576\n",
      "          Validation Loss (standardized): 1.3726029350027233\n",
      "Epoch: 91, Loss (standarized): 1.3233376338034015\n",
      "          Validation Loss (standardized): 1.3670973241232491\n",
      "Epoch: 96, Loss (standarized): 1.318936355480752\n",
      "          Validation Loss (standardized): 1.3627860312144162\n",
      "Final epoch: 100, Final loss (standarized): 1.3149568801400437\n",
      "Epoch: 1, Loss (standarized): 1.7636581887496317\n",
      "          Validation Loss (standardized): 1.9062839114492474\n",
      "Epoch: 6, Loss (standarized): 1.6145000017086217\n",
      "          Validation Loss (standardized): 1.6015466623406864\n",
      "Epoch: 11, Loss (standarized): 1.6248347008680646\n",
      "          Validation Loss (standardized): 1.548006541693483\n",
      "Epoch: 16, Loss (standarized): 1.6069167002323101\n",
      "          Validation Loss (standardized): 1.5746976813900528\n",
      "Epoch: 21, Loss (standarized): 1.6013985438582246\n",
      "          Validation Loss (standardized): 1.6341831580879076\n",
      "Epoch: 26, Loss (standarized): 1.6007224579584518\n",
      "          Validation Loss (standardized): 1.6375211951524624\n",
      "Epoch: 31, Loss (standarized): 1.5933987867533392\n",
      "          Validation Loss (standardized): 1.5935685359808325\n",
      "Epoch: 36, Loss (standarized): 1.5892985686618644\n",
      "          Validation Loss (standardized): 1.5728238198273106\n",
      "Epoch: 41, Loss (standarized): 1.5816633049919653\n",
      "          Validation Loss (standardized): 1.5778833732018585\n",
      "Epoch: 46, Loss (standarized): 1.5704779658018424\n",
      "          Validation Loss (standardized): 1.5864512703904812\n",
      "Epoch: 51, Loss (standarized): 1.5530642889691704\n",
      "          Validation Loss (standardized): 1.5686332867653354\n",
      "Epoch: 56, Loss (standarized): 1.5255197557139213\n",
      "          Validation Loss (standardized): 1.5344005143678172\n",
      "Epoch: 61, Loss (standarized): 1.4867530986105384\n",
      "          Validation Loss (standardized): 1.4997479463636987\n",
      "Epoch: 66, Loss (standarized): 1.4405184455512166\n",
      "          Validation Loss (standardized): 1.46833823923393\n",
      "Epoch: 71, Loss (standarized): 1.3995465893685963\n",
      "          Validation Loss (standardized): 1.4359339372795583\n",
      "Epoch: 76, Loss (standarized): 1.3739854248829255\n",
      "          Validation Loss (standardized): 1.4101377142591969\n",
      "Epoch: 81, Loss (standarized): 1.363256307319456\n",
      "          Validation Loss (standardized): 1.4003614800651176\n",
      "Epoch: 86, Loss (standarized): 1.3618807217923552\n",
      "          Validation Loss (standardized): 1.403835920486157\n",
      "Epoch: 91, Loss (standarized): 1.36515022125945\n",
      "          Validation Loss (standardized): 1.4099335639980954\n",
      "Epoch: 96, Loss (standarized): 1.3684657007966612\n",
      "          Validation Loss (standardized): 1.4116128264152392\n",
      "Final epoch: 100, Final loss (standarized): 1.3693040026656862\n",
      "Epoch: 1, Loss (standarized): 1.6729295100859167\n",
      "          Validation Loss (standardized): 1.6390712932332554\n",
      "Epoch: 6, Loss (standarized): 1.6020771697727485\n",
      "          Validation Loss (standardized): 1.6133361188875792\n",
      "Epoch: 11, Loss (standarized): 1.5753458898279513\n",
      "          Validation Loss (standardized): 1.5710562363674212\n",
      "Epoch: 16, Loss (standarized): 1.543722459065212\n",
      "          Validation Loss (standardized): 1.5597354957141512\n",
      "Epoch: 21, Loss (standarized): 1.504495183822454\n",
      "          Validation Loss (standardized): 1.5353996992469696\n",
      "Epoch: 26, Loss (standarized): 1.4548407620075745\n",
      "          Validation Loss (standardized): 1.4742917901300203\n",
      "Epoch: 31, Loss (standarized): 1.4079442354202656\n",
      "          Validation Loss (standardized): 1.4429079308875958\n",
      "Epoch: 36, Loss (standarized): 1.3715332683560701\n",
      "          Validation Loss (standardized): 1.4133268129105896\n",
      "Epoch: 41, Loss (standarized): 1.3496054812470255\n",
      "          Validation Loss (standardized): 1.386798623934195\n",
      "Epoch: 46, Loss (standarized): 1.3382814091502004\n",
      "          Validation Loss (standardized): 1.3750975659441929\n",
      "Epoch: 51, Loss (standarized): 1.3335360036184085\n",
      "          Validation Loss (standardized): 1.36633788310152\n",
      "Epoch: 56, Loss (standarized): 1.3295968817397232\n",
      "          Validation Loss (standardized): 1.362991693418719\n",
      "Epoch: 61, Loss (standarized): 1.3253629669990459\n",
      "          Validation Loss (standardized): 1.3625249787001041\n",
      "Epoch: 66, Loss (standarized): 1.3213738860319513\n",
      "          Validation Loss (standardized): 1.3605189569169027\n",
      "Epoch: 71, Loss (standarized): 1.3172057895975662\n",
      "          Validation Loss (standardized): 1.3579084536629926\n",
      "Epoch: 76, Loss (standarized): 1.31231374188647\n",
      "          Validation Loss (standardized): 1.3553300241356114\n",
      "Epoch: 81, Loss (standarized): 1.3061208232602473\n",
      "          Validation Loss (standardized): 1.3487357028275364\n",
      "Epoch: 86, Loss (standarized): 1.2981637652196178\n",
      "          Validation Loss (standardized): 1.34153467114501\n",
      "Epoch: 91, Loss (standarized): 1.2881065881622027\n",
      "          Validation Loss (standardized): 1.3331111995763099\n",
      "Epoch: 96, Loss (standarized): 1.275607748231372\n",
      "          Validation Loss (standardized): 1.323664453325587\n",
      "Final epoch: 100, Final loss (standarized): 1.2636381775181131\n",
      "Epoch: 1, Loss (standarized): 1.667522923508173\n",
      "          Validation Loss (standardized): 1.5823216602876127\n",
      "Epoch: 6, Loss (standarized): 1.6068983174698979\n",
      "          Validation Loss (standardized): 1.6380990083444567\n",
      "Epoch: 11, Loss (standarized): 1.57469714494689\n",
      "          Validation Loss (standardized): 1.5693502214819446\n",
      "Epoch: 16, Loss (standarized): 1.5496901846945883\n",
      "          Validation Loss (standardized): 1.5422752290106063\n",
      "Epoch: 21, Loss (standarized): 1.5100134490609605\n",
      "          Validation Loss (standardized): 1.5166289264163597\n",
      "Epoch: 26, Loss (standarized): 1.4665902488979623\n",
      "          Validation Loss (standardized): 1.4942372854465065\n",
      "Epoch: 31, Loss (standarized): 1.4176606066334687\n",
      "          Validation Loss (standardized): 1.4353860290254425\n",
      "Epoch: 36, Loss (standarized): 1.3779743756905463\n",
      "          Validation Loss (standardized): 1.4040312979027987\n",
      "Epoch: 41, Loss (standarized): 1.3522173247793667\n",
      "          Validation Loss (standardized): 1.3887028158108188\n",
      "Epoch: 46, Loss (standarized): 1.3387628221216465\n",
      "          Validation Loss (standardized): 1.3757172659694885\n",
      "Epoch: 51, Loss (standarized): 1.3302194278257946\n",
      "          Validation Loss (standardized): 1.3600570776240541\n",
      "Epoch: 56, Loss (standarized): 1.3226038536990774\n",
      "          Validation Loss (standardized): 1.3538701418105552\n",
      "Epoch: 61, Loss (standarized): 1.3143204455530304\n",
      "          Validation Loss (standardized): 1.3522735740367695\n",
      "Epoch: 66, Loss (standarized): 1.3055880787562717\n",
      "          Validation Loss (standardized): 1.3425000545994845\n",
      "Epoch: 71, Loss (standarized): 1.2964979694896563\n",
      "          Validation Loss (standardized): 1.3394686230296324\n",
      "Epoch: 76, Loss (standarized): 1.285468342697534\n",
      "          Validation Loss (standardized): 1.3310113305520466\n",
      "Epoch: 81, Loss (standarized): 1.2714141079129295\n",
      "          Validation Loss (standardized): 1.3156989859771901\n",
      "Epoch: 86, Loss (standarized): 1.2545290906636035\n",
      "          Validation Loss (standardized): 1.3009316790967496\n",
      "Epoch: 91, Loss (standarized): 1.2346965589639982\n",
      "          Validation Loss (standardized): 1.2838243300298657\n",
      "Epoch: 96, Loss (standarized): 1.211818816879562\n",
      "          Validation Loss (standardized): 1.2647050935160862\n",
      "Final epoch: 100, Final loss (standarized): 1.1914981709999701\n",
      "Epoch: 1, Loss (standarized): 2.0079465943642436\n",
      "          Validation Loss (standardized): 2.122756020713517\n",
      "Epoch: 6, Loss (standarized): 1.6318312799817098\n",
      "          Validation Loss (standardized): 1.6574602058893304\n",
      "Epoch: 11, Loss (standarized): 1.6260137193869408\n",
      "          Validation Loss (standardized): 1.5622977285609247\n",
      "Epoch: 16, Loss (standarized): 1.6354167605477574\n",
      "          Validation Loss (standardized): 1.5487465437275905\n",
      "Epoch: 21, Loss (standarized): 1.6186818827997234\n",
      "          Validation Loss (standardized): 1.5715292741975653\n",
      "Epoch: 26, Loss (standarized): 1.6100469315870418\n",
      "          Validation Loss (standardized): 1.6124109658757586\n",
      "Epoch: 31, Loss (standarized): 1.6114133862618203\n",
      "          Validation Loss (standardized): 1.6368033069649177\n",
      "Epoch: 36, Loss (standarized): 1.6108199173956848\n",
      "          Validation Loss (standardized): 1.6325443321205226\n",
      "Epoch: 41, Loss (standarized): 1.6094510431188422\n",
      "          Validation Loss (standardized): 1.6138202659862027\n",
      "Epoch: 46, Loss (standarized): 1.6094954441924392\n",
      "          Validation Loss (standardized): 1.6033123911279994\n",
      "Epoch: 51, Loss (standarized): 1.609541736071578\n",
      "          Validation Loss (standardized): 1.6017354989272792\n",
      "Epoch: 56, Loss (standarized): 1.6095754747144742\n",
      "          Validation Loss (standardized): 1.60535603375634\n",
      "Epoch: 61, Loss (standarized): 1.60949753986919\n",
      "          Validation Loss (standardized): 1.605590573948717\n",
      "Epoch: 66, Loss (standarized): 1.6095872886041216\n",
      "          Validation Loss (standardized): 1.6017948037826881\n",
      "Epoch: 71, Loss (standarized): 1.6095605982380317\n",
      "          Validation Loss (standardized): 1.604894288409659\n",
      "Epoch: 76, Loss (standarized): 1.6095761750314919\n",
      "          Validation Loss (standardized): 1.602293119299181\n",
      "Epoch: 81, Loss (standarized): 1.6097748132409708\n",
      "          Validation Loss (standardized): 1.5962501531201623\n",
      "Epoch: 86, Loss (standarized): 1.6099030409062711\n",
      "          Validation Loss (standardized): 1.5946240284499582\n",
      "Epoch: 91, Loss (standarized): 1.6098593763546432\n",
      "          Validation Loss (standardized): 1.5969300098448393\n",
      "Epoch: 96, Loss (standarized): 1.6096797877383762\n",
      "          Validation Loss (standardized): 1.6051303987528134\n",
      "Final epoch: 100, Final loss (standarized): 1.6097642203286109\n",
      "Epoch: 1, Loss (standarized): 1.6355951292937365\n",
      "          Validation Loss (standardized): 1.599686045149351\n",
      "Epoch: 6, Loss (standarized): 1.6117805486995775\n",
      "          Validation Loss (standardized): 1.6333572598570936\n",
      "Epoch: 11, Loss (standarized): 1.611463250180139\n",
      "          Validation Loss (standardized): 1.627408796984064\n",
      "Epoch: 16, Loss (standarized): 1.6095416191528014\n",
      "          Validation Loss (standardized): 1.610021844122955\n",
      "Epoch: 21, Loss (standarized): 1.6100480626209446\n",
      "          Validation Loss (standardized): 1.5998516280751591\n",
      "Epoch: 26, Loss (standarized): 1.6096605953169023\n",
      "          Validation Loss (standardized): 1.6032018662633372\n",
      "Epoch: 31, Loss (standarized): 1.6095078141221413\n",
      "          Validation Loss (standardized): 1.6099969186601566\n",
      "Epoch: 36, Loss (standarized): 1.609515746941011\n",
      "          Validation Loss (standardized): 1.6083873974120457\n",
      "Epoch: 41, Loss (standarized): 1.6096483262258454\n",
      "          Validation Loss (standardized): 1.6095079576587696\n",
      "Epoch: 46, Loss (standarized): 1.6098398990625293\n",
      "          Validation Loss (standardized): 1.613893219920142\n",
      "Epoch: 51, Loss (standarized): 1.609620752729922\n",
      "          Validation Loss (standardized): 1.6032892287004652\n",
      "Epoch: 56, Loss (standarized): 1.6096074224272914\n",
      "          Validation Loss (standardized): 1.6085367960824937\n",
      "Epoch: 61, Loss (standarized): 1.6096360590411714\n",
      "          Validation Loss (standardized): 1.6134756673155282\n",
      "Epoch: 66, Loss (standarized): 1.6095411038505483\n",
      "          Validation Loss (standardized): 1.6106915190691813\n",
      "Epoch: 71, Loss (standarized): 1.6096782060439805\n",
      "          Validation Loss (standardized): 1.612884916886747\n",
      "Epoch: 76, Loss (standarized): 1.60956628752448\n",
      "          Validation Loss (standardized): 1.6119960792117767\n",
      "Epoch: 81, Loss (standarized): 1.6096195482685598\n",
      "          Validation Loss (standardized): 1.6095514756062863\n",
      "Epoch: 86, Loss (standarized): 1.6096305659659922\n",
      "          Validation Loss (standardized): 1.6074780148725274\n",
      "Epoch: 91, Loss (standarized): 1.6096028270430238\n",
      "          Validation Loss (standardized): 1.604966710595563\n",
      "Epoch: 96, Loss (standarized): 1.6095078257898812\n",
      "          Validation Loss (standardized): 1.6050567953354982\n",
      "Final epoch: 100, Final loss (standarized): 1.609535918673895\n",
      "Epoch: 1, Loss (standarized): 1.6909743737820657\n",
      "          Validation Loss (standardized): 1.5388867629722818\n",
      "Epoch: 6, Loss (standarized): 1.6085526425813397\n",
      "          Validation Loss (standardized): 1.6459471099516556\n",
      "Epoch: 11, Loss (standarized): 1.616364065093789\n",
      "          Validation Loss (standardized): 1.6675658521213221\n",
      "Epoch: 16, Loss (standarized): 1.6101500955076629\n",
      "          Validation Loss (standardized): 1.621631022518226\n",
      "Epoch: 21, Loss (standarized): 1.6095072968933661\n",
      "          Validation Loss (standardized): 1.5892807504792303\n",
      "Epoch: 26, Loss (standarized): 1.6105135319934996\n",
      "          Validation Loss (standardized): 1.58957188308208\n",
      "Epoch: 31, Loss (standarized): 1.6095720472681183\n",
      "          Validation Loss (standardized): 1.6115700522757197\n",
      "Epoch: 36, Loss (standarized): 1.6098826729072044\n",
      "          Validation Loss (standardized): 1.620468880391315\n",
      "Epoch: 41, Loss (standarized): 1.6096360078763035\n",
      "          Validation Loss (standardized): 1.6178498264962862\n",
      "Epoch: 46, Loss (standarized): 1.6095922056862428\n",
      "          Validation Loss (standardized): 1.6169874100609878\n",
      "Epoch: 51, Loss (standarized): 1.6095643963557518\n",
      "          Validation Loss (standardized): 1.6146513892504613\n",
      "Epoch: 56, Loss (standarized): 1.609573399557737\n",
      "          Validation Loss (standardized): 1.6143978969552355\n",
      "Epoch: 61, Loss (standarized): 1.6095632789394898\n",
      "          Validation Loss (standardized): 1.6060785824427835\n",
      "Epoch: 66, Loss (standarized): 1.6094737296224009\n",
      "          Validation Loss (standardized): 1.6130612493755456\n",
      "Epoch: 71, Loss (standarized): 1.6094831420867315\n",
      "          Validation Loss (standardized): 1.608964876807306\n",
      "Epoch: 76, Loss (standarized): 1.60947848446604\n",
      "          Validation Loss (standardized): 1.606968069417614\n",
      "Epoch: 81, Loss (standarized): 1.60955321035574\n",
      "          Validation Loss (standardized): 1.6073118217868503\n",
      "Epoch: 86, Loss (standarized): 1.6095391294632606\n",
      "          Validation Loss (standardized): 1.608671484765649\n",
      "Epoch: 91, Loss (standarized): 1.6096163795446272\n",
      "          Validation Loss (standardized): 1.610253927191146\n",
      "Epoch: 96, Loss (standarized): 1.6095810798013235\n",
      "          Validation Loss (standardized): 1.6128339415865736\n",
      "Final epoch: 100, Final loss (standarized): 1.6095200955529112\n",
      "Epoch: 1, Loss (standarized): 1.8316692422534349\n",
      "          Validation Loss (standardized): 1.6952530237964685\n",
      "Epoch: 6, Loss (standarized): 1.6266766007262858\n",
      "          Validation Loss (standardized): 1.6758194203954737\n",
      "Epoch: 11, Loss (standarized): 1.6152922543358201\n",
      "          Validation Loss (standardized): 1.630437922943261\n",
      "Epoch: 16, Loss (standarized): 1.6215982856869267\n",
      "          Validation Loss (standardized): 1.601773088452454\n",
      "Epoch: 21, Loss (standarized): 1.6127986523346431\n",
      "          Validation Loss (standardized): 1.5961176880208094\n",
      "Epoch: 26, Loss (standarized): 1.6085946162811586\n",
      "          Validation Loss (standardized): 1.6041711808934191\n",
      "Epoch: 31, Loss (standarized): 1.6102585994277343\n",
      "          Validation Loss (standardized): 1.6116962659655272\n",
      "Epoch: 36, Loss (standarized): 1.6100169197596645\n",
      "          Validation Loss (standardized): 1.6076565226124588\n",
      "Epoch: 41, Loss (standarized): 1.6093978598519112\n",
      "          Validation Loss (standardized): 1.6036402428233891\n",
      "Epoch: 46, Loss (standarized): 1.6096548745314323\n",
      "          Validation Loss (standardized): 1.608297936683969\n",
      "Epoch: 51, Loss (standarized): 1.6097834402144884\n",
      "          Validation Loss (standardized): 1.6066352915447402\n",
      "Epoch: 56, Loss (standarized): 1.609578401146682\n",
      "          Validation Loss (standardized): 1.6020347975467866\n",
      "Epoch: 61, Loss (standarized): 1.6095535634617943\n",
      "          Validation Loss (standardized): 1.603777060929148\n",
      "Epoch: 66, Loss (standarized): 1.6096705559644555\n",
      "          Validation Loss (standardized): 1.6111404593357892\n",
      "Epoch: 71, Loss (standarized): 1.6097172175213716\n",
      "          Validation Loss (standardized): 1.6193983838952681\n",
      "Epoch: 76, Loss (standarized): 1.609866136809552\n",
      "          Validation Loss (standardized): 1.6196780220310907\n",
      "Epoch: 81, Loss (standarized): 1.609814735106535\n",
      "          Validation Loss (standardized): 1.6180191293151318\n",
      "Epoch: 86, Loss (standarized): 1.6096844811880937\n",
      "          Validation Loss (standardized): 1.6192851671029576\n",
      "Epoch: 91, Loss (standarized): 1.609652802294856\n",
      "          Validation Loss (standardized): 1.6212068351841318\n",
      "Epoch: 96, Loss (standarized): 1.6095721536878034\n",
      "          Validation Loss (standardized): 1.6169043475775868\n",
      "Final epoch: 100, Final loss (standarized): 1.6095497834099592\n",
      "Epoch: 1, Loss (standarized): 1.7733958300612362\n",
      "          Validation Loss (standardized): 1.6588079615685358\n",
      "Epoch: 6, Loss (standarized): 1.60993267875254\n",
      "          Validation Loss (standardized): 1.6438540203281886\n",
      "Epoch: 11, Loss (standarized): 1.6146797713861025\n",
      "          Validation Loss (standardized): 1.6428342114662458\n",
      "Epoch: 16, Loss (standarized): 1.5915946127747014\n",
      "          Validation Loss (standardized): 1.5895373111383406\n",
      "Epoch: 21, Loss (standarized): 1.575055165611316\n",
      "          Validation Loss (standardized): 1.5585927962669648\n",
      "Epoch: 26, Loss (standarized): 1.5594181965932576\n",
      "          Validation Loss (standardized): 1.5669859166755205\n",
      "Epoch: 31, Loss (standarized): 1.5311764808972483\n",
      "          Validation Loss (standardized): 1.5590464794772325\n",
      "Epoch: 36, Loss (standarized): 1.5005506466800307\n",
      "          Validation Loss (standardized): 1.5163654520880734\n",
      "Epoch: 41, Loss (standarized): 1.462091420530781\n",
      "          Validation Loss (standardized): 1.478158225275024\n",
      "Epoch: 46, Loss (standarized): 1.4235977297292055\n",
      "          Validation Loss (standardized): 1.4585422501969338\n",
      "Epoch: 51, Loss (standarized): 1.3905585826225069\n",
      "          Validation Loss (standardized): 1.431145213796697\n",
      "Epoch: 56, Loss (standarized): 1.3664319651690513\n",
      "          Validation Loss (standardized): 1.4033773315390254\n",
      "Epoch: 61, Loss (standarized): 1.3513986856667322\n",
      "          Validation Loss (standardized): 1.3911765293319205\n",
      "Epoch: 66, Loss (standarized): 1.3424304835851433\n",
      "          Validation Loss (standardized): 1.3850330754288016\n",
      "Epoch: 71, Loss (standarized): 1.3370859802869695\n",
      "          Validation Loss (standardized): 1.3780331141625768\n",
      "Epoch: 76, Loss (standarized): 1.3337107623848408\n",
      "          Validation Loss (standardized): 1.3743754424073105\n",
      "Epoch: 81, Loss (standarized): 1.331383653687119\n",
      "          Validation Loss (standardized): 1.3735397833464331\n",
      "Epoch: 86, Loss (standarized): 1.3295139689817568\n",
      "          Validation Loss (standardized): 1.3715744686729257\n",
      "Epoch: 91, Loss (standarized): 1.3275271147272216\n",
      "          Validation Loss (standardized): 1.3693096613732592\n",
      "Epoch: 96, Loss (standarized): 1.3251313996795107\n",
      "          Validation Loss (standardized): 1.3682097839763718\n",
      "Final epoch: 100, Final loss (standarized): 1.322893085208406\n",
      "Epoch: 1, Loss (standarized): 1.8468833125356958\n",
      "          Validation Loss (standardized): 1.491589033122301\n",
      "Epoch: 6, Loss (standarized): 1.6059294484633708\n",
      "          Validation Loss (standardized): 1.623791071832617\n",
      "Epoch: 11, Loss (standarized): 1.6240031877543266\n",
      "          Validation Loss (standardized): 1.741431593184122\n",
      "Epoch: 16, Loss (standarized): 1.6036273145183486\n",
      "          Validation Loss (standardized): 1.6556082657535274\n",
      "Epoch: 21, Loss (standarized): 1.5893731262341146\n",
      "          Validation Loss (standardized): 1.5590297881594146\n",
      "Epoch: 26, Loss (standarized): 1.5895965988747907\n",
      "          Validation Loss (standardized): 1.5400762319657337\n",
      "Epoch: 31, Loss (standarized): 1.5797854354741856\n",
      "          Validation Loss (standardized): 1.5708582964070559\n",
      "Epoch: 36, Loss (standarized): 1.5727591485365378\n",
      "          Validation Loss (standardized): 1.598541702180498\n",
      "Epoch: 41, Loss (standarized): 1.5653083507111267\n",
      "          Validation Loss (standardized): 1.590032497571076\n",
      "Epoch: 46, Loss (standarized): 1.554261189497713\n",
      "          Validation Loss (standardized): 1.5570482080140642\n",
      "Epoch: 51, Loss (standarized): 1.541788060714971\n",
      "          Validation Loss (standardized): 1.5398375209814568\n",
      "Epoch: 56, Loss (standarized): 1.5252787736339035\n",
      "          Validation Loss (standardized): 1.5418431355226712\n",
      "Epoch: 61, Loss (standarized): 1.5064408382117132\n",
      "          Validation Loss (standardized): 1.5318007199905241\n",
      "Epoch: 66, Loss (standarized): 1.485444530804816\n",
      "          Validation Loss (standardized): 1.5098050789429336\n",
      "Epoch: 71, Loss (standarized): 1.464428371702642\n",
      "          Validation Loss (standardized): 1.4875907194154314\n",
      "Epoch: 76, Loss (standarized): 1.4454228528529678\n",
      "          Validation Loss (standardized): 1.4757065539207266\n",
      "Epoch: 81, Loss (standarized): 1.4302128465856652\n",
      "          Validation Loss (standardized): 1.4661670764120405\n",
      "Epoch: 86, Loss (standarized): 1.4192326286983121\n",
      "          Validation Loss (standardized): 1.4574393676424093\n",
      "Epoch: 91, Loss (standarized): 1.4119591572894346\n",
      "          Validation Loss (standardized): 1.4490692219835974\n",
      "Epoch: 96, Loss (standarized): 1.4071944498738942\n",
      "          Validation Loss (standardized): 1.4462180289881854\n",
      "Final epoch: 100, Final loss (standarized): 1.404538623418756\n",
      "Epoch: 1, Loss (standarized): 1.7473787458181016\n",
      "          Validation Loss (standardized): 1.6412042259896507\n",
      "Epoch: 6, Loss (standarized): 1.6131722827265995\n",
      "          Validation Loss (standardized): 1.6456387918658595\n",
      "Epoch: 11, Loss (standarized): 1.6097653941577263\n",
      "          Validation Loss (standardized): 1.5802609787440947\n",
      "Epoch: 16, Loss (standarized): 1.5810385043115958\n",
      "          Validation Loss (standardized): 1.581568438809862\n",
      "Epoch: 21, Loss (standarized): 1.5711227560059375\n",
      "          Validation Loss (standardized): 1.5995288236032739\n",
      "Epoch: 26, Loss (standarized): 1.5501437247393455\n",
      "          Validation Loss (standardized): 1.5571093460820475\n",
      "Epoch: 31, Loss (standarized): 1.5266444723753432\n",
      "          Validation Loss (standardized): 1.5331630977707873\n",
      "Epoch: 36, Loss (standarized): 1.4970747598261442\n",
      "          Validation Loss (standardized): 1.5138523788928442\n",
      "Epoch: 41, Loss (standarized): 1.4611431409557405\n",
      "          Validation Loss (standardized): 1.4800732511882337\n",
      "Epoch: 46, Loss (standarized): 1.4254674613997098\n",
      "          Validation Loss (standardized): 1.4544970653841758\n",
      "Epoch: 51, Loss (standarized): 1.3940360683117314\n",
      "          Validation Loss (standardized): 1.425320409714872\n",
      "Epoch: 56, Loss (standarized): 1.3716533386400591\n",
      "          Validation Loss (standardized): 1.4017026841008449\n",
      "Epoch: 61, Loss (standarized): 1.3572092469488268\n",
      "          Validation Loss (standardized): 1.3978374040311\n",
      "Epoch: 66, Loss (standarized): 1.3483482105470832\n",
      "          Validation Loss (standardized): 1.3876677686116932\n",
      "Epoch: 71, Loss (standarized): 1.3430203149383038\n",
      "          Validation Loss (standardized): 1.3808490793893853\n",
      "Epoch: 76, Loss (standarized): 1.339730582830518\n",
      "          Validation Loss (standardized): 1.3819811562092728\n",
      "Epoch: 81, Loss (standarized): 1.3373572629764636\n",
      "          Validation Loss (standardized): 1.3811944113727295\n",
      "Epoch: 86, Loss (standarized): 1.335223336201899\n",
      "          Validation Loss (standardized): 1.379234251034864\n",
      "Epoch: 91, Loss (standarized): 1.3327828064122216\n",
      "          Validation Loss (standardized): 1.376076015728106\n",
      "Epoch: 96, Loss (standarized): 1.3299046694322363\n",
      "          Validation Loss (standardized): 1.373379816998793\n",
      "Final epoch: 100, Final loss (standarized): 1.3273977456492145\n",
      "Epoch: 1, Loss (standarized): 1.6771200023584731\n",
      "          Validation Loss (standardized): 1.642821926592698\n",
      "Epoch: 6, Loss (standarized): 1.617000132365348\n",
      "          Validation Loss (standardized): 1.589975397999463\n",
      "Epoch: 11, Loss (standarized): 1.5933386726938636\n",
      "          Validation Loss (standardized): 1.6080819116183038\n",
      "Epoch: 16, Loss (standarized): 1.5840024195555131\n",
      "          Validation Loss (standardized): 1.5947459630565768\n",
      "Epoch: 21, Loss (standarized): 1.5658855387383703\n",
      "          Validation Loss (standardized): 1.547328825823573\n",
      "Epoch: 26, Loss (standarized): 1.545514174935846\n",
      "          Validation Loss (standardized): 1.5546698550550164\n",
      "Epoch: 31, Loss (standarized): 1.5176936969177905\n",
      "          Validation Loss (standardized): 1.5341610515440498\n",
      "Epoch: 36, Loss (standarized): 1.4839347358306878\n",
      "          Validation Loss (standardized): 1.490616228269435\n",
      "Epoch: 41, Loss (standarized): 1.445373656750557\n",
      "          Validation Loss (standardized): 1.464249882625428\n",
      "Epoch: 46, Loss (standarized): 1.4097325372767537\n",
      "          Validation Loss (standardized): 1.4366155666063414\n",
      "Epoch: 51, Loss (standarized): 1.381459402079779\n",
      "          Validation Loss (standardized): 1.408430047594576\n",
      "Epoch: 56, Loss (standarized): 1.3612079186612227\n",
      "          Validation Loss (standardized): 1.3907088438000796\n",
      "Epoch: 61, Loss (standarized): 1.3473791469171028\n",
      "          Validation Loss (standardized): 1.37851971733005\n",
      "Epoch: 66, Loss (standarized): 1.338095725304326\n",
      "          Validation Loss (standardized): 1.3690010750397912\n",
      "Epoch: 71, Loss (standarized): 1.3316732954534316\n",
      "          Validation Loss (standardized): 1.3667874644834312\n",
      "Epoch: 76, Loss (standarized): 1.3267757720794338\n",
      "          Validation Loss (standardized): 1.3617484043752817\n",
      "Epoch: 81, Loss (standarized): 1.3223673127015076\n",
      "          Validation Loss (standardized): 1.357817016173065\n",
      "Epoch: 86, Loss (standarized): 1.318025911433606\n",
      "          Validation Loss (standardized): 1.3539393510226923\n",
      "Epoch: 91, Loss (standarized): 1.3132523880102533\n",
      "          Validation Loss (standardized): 1.350241688644168\n",
      "Epoch: 96, Loss (standarized): 1.3079267822078808\n",
      "          Validation Loss (standardized): 1.3427362990884766\n",
      "Final epoch: 100, Final loss (standarized): 1.303167452086027\n",
      "Epoch: 1, Loss (standarized): 1.7611742667444035\n",
      "          Validation Loss (standardized): 1.51855899067955\n",
      "Epoch: 6, Loss (standarized): 1.5999661284396445\n",
      "          Validation Loss (standardized): 1.6817473090172608\n",
      "Epoch: 11, Loss (standarized): 1.5916096827252533\n",
      "          Validation Loss (standardized): 1.660190503540756\n",
      "Epoch: 16, Loss (standarized): 1.5582185930737773\n",
      "          Validation Loss (standardized): 1.571920711323784\n",
      "Epoch: 21, Loss (standarized): 1.5293130929252248\n",
      "          Validation Loss (standardized): 1.534332729827443\n",
      "Epoch: 26, Loss (standarized): 1.4990865205888253\n",
      "          Validation Loss (standardized): 1.5149693780152038\n",
      "Epoch: 31, Loss (standarized): 1.4595423303190471\n",
      "          Validation Loss (standardized): 1.5041139384830804\n",
      "Epoch: 36, Loss (standarized): 1.4240350719155266\n",
      "          Validation Loss (standardized): 1.4873341895386911\n",
      "Epoch: 41, Loss (standarized): 1.3885625535346622\n",
      "          Validation Loss (standardized): 1.4389871613542955\n",
      "Epoch: 46, Loss (standarized): 1.3619407502319774\n",
      "          Validation Loss (standardized): 1.399378708354841\n",
      "Epoch: 51, Loss (standarized): 1.3438270352190893\n",
      "          Validation Loss (standardized): 1.3857854594182304\n",
      "Epoch: 56, Loss (standarized): 1.3324292014409247\n",
      "          Validation Loss (standardized): 1.3790324195903432\n",
      "Epoch: 61, Loss (standarized): 1.325489830581742\n",
      "          Validation Loss (standardized): 1.3696859770262138\n",
      "Epoch: 66, Loss (standarized): 1.3200808270665612\n",
      "          Validation Loss (standardized): 1.3560327912297372\n",
      "Epoch: 71, Loss (standarized): 1.3144111266500154\n",
      "          Validation Loss (standardized): 1.3505829973044658\n",
      "Epoch: 76, Loss (standarized): 1.3076737152271358\n",
      "          Validation Loss (standardized): 1.347190753146374\n",
      "Epoch: 81, Loss (standarized): 1.2998186319716274\n",
      "          Validation Loss (standardized): 1.3382059923401748\n",
      "Epoch: 86, Loss (standarized): 1.2906480370996953\n",
      "          Validation Loss (standardized): 1.3311827603368247\n",
      "Epoch: 91, Loss (standarized): 1.279636635358104\n",
      "          Validation Loss (standardized): 1.3223255750588092\n",
      "Epoch: 96, Loss (standarized): 1.2661720433363073\n",
      "          Validation Loss (standardized): 1.3102776786743682\n",
      "Final epoch: 100, Final loss (standarized): 1.2533247279464996\n",
      "Epoch: 1, Loss (standarized): 1.7840790955521073\n",
      "          Validation Loss (standardized): 1.8150845933785023\n",
      "Epoch: 6, Loss (standarized): 1.6079447631106227\n",
      "          Validation Loss (standardized): 1.6294079277698796\n",
      "Epoch: 11, Loss (standarized): 1.617803587338576\n",
      "          Validation Loss (standardized): 1.5531487743124608\n",
      "Epoch: 16, Loss (standarized): 1.58813573277846\n",
      "          Validation Loss (standardized): 1.578261682207522\n",
      "Epoch: 21, Loss (standarized): 1.5879604536013603\n",
      "          Validation Loss (standardized): 1.6329965138951639\n",
      "Epoch: 26, Loss (standarized): 1.575389659933901\n",
      "          Validation Loss (standardized): 1.5976274680440374\n",
      "Epoch: 31, Loss (standarized): 1.5644856469283084\n",
      "          Validation Loss (standardized): 1.5457486194498915\n",
      "Epoch: 36, Loss (standarized): 1.550899123697106\n",
      "          Validation Loss (standardized): 1.542999760020607\n",
      "Epoch: 41, Loss (standarized): 1.5315622541020246\n",
      "          Validation Loss (standardized): 1.5549281259911294\n",
      "Epoch: 46, Loss (standarized): 1.50781210008705\n",
      "          Validation Loss (standardized): 1.530187018193211\n",
      "Epoch: 51, Loss (standarized): 1.4780793765300901\n",
      "          Validation Loss (standardized): 1.4937771021099215\n",
      "Epoch: 56, Loss (standarized): 1.446881594876349\n",
      "          Validation Loss (standardized): 1.472583829080902\n",
      "Epoch: 61, Loss (standarized): 1.4183124281461188\n",
      "          Validation Loss (standardized): 1.4559466766426403\n",
      "Epoch: 66, Loss (standarized): 1.3969105886814648\n",
      "          Validation Loss (standardized): 1.4360690305556554\n",
      "Epoch: 71, Loss (standarized): 1.3834805574113762\n",
      "          Validation Loss (standardized): 1.4211401428610182\n",
      "Epoch: 76, Loss (standarized): 1.376405367881339\n",
      "          Validation Loss (standardized): 1.417008334875473\n",
      "Epoch: 81, Loss (standarized): 1.3736293002419488\n",
      "          Validation Loss (standardized): 1.4165890185691374\n",
      "Epoch: 86, Loss (standarized): 1.372825083761918\n",
      "          Validation Loss (standardized): 1.4137536500293286\n",
      "Epoch: 91, Loss (standarized): 1.372261181664762\n",
      "          Validation Loss (standardized): 1.412980287123583\n",
      "Epoch: 96, Loss (standarized): 1.3715301446315993\n",
      "          Validation Loss (standardized): 1.4128912525343666\n",
      "Final epoch: 100, Final loss (standarized): 1.3708502574458206\n",
      "Epoch: 1, Loss (standarized): 1.90617488274661\n",
      "          Validation Loss (standardized): 1.7582995864262572\n",
      "Epoch: 6, Loss (standarized): 1.5907229399090996\n",
      "          Validation Loss (standardized): 1.6365932813149553\n",
      "Epoch: 11, Loss (standarized): 1.6056788014492553\n",
      "          Validation Loss (standardized): 1.6197583084502707\n",
      "Epoch: 16, Loss (standarized): 1.5569649433638417\n",
      "          Validation Loss (standardized): 1.5393871391424763\n",
      "Epoch: 21, Loss (standarized): 1.5180612889933627\n",
      "          Validation Loss (standardized): 1.5241057611332527\n",
      "Epoch: 26, Loss (standarized): 1.493925835434937\n",
      "          Validation Loss (standardized): 1.5276951169036506\n",
      "Epoch: 31, Loss (standarized): 1.454102529513304\n",
      "          Validation Loss (standardized): 1.4923926481735417\n",
      "Epoch: 36, Loss (standarized): 1.4227991945909637\n",
      "          Validation Loss (standardized): 1.4516429025816813\n",
      "Epoch: 41, Loss (standarized): 1.3974367350271526\n",
      "          Validation Loss (standardized): 1.4248445566690675\n",
      "Epoch: 46, Loss (standarized): 1.376069817186363\n",
      "          Validation Loss (standardized): 1.411906904839272\n",
      "Epoch: 51, Loss (standarized): 1.362440917440253\n",
      "          Validation Loss (standardized): 1.3991753418800217\n",
      "Epoch: 56, Loss (standarized): 1.3517994645041866\n",
      "          Validation Loss (standardized): 1.3857111438690928\n",
      "Epoch: 61, Loss (standarized): 1.344425326337194\n",
      "          Validation Loss (standardized): 1.3796195455456932\n",
      "Epoch: 66, Loss (standarized): 1.3387134292415026\n",
      "          Validation Loss (standardized): 1.3759401175784054\n",
      "Epoch: 71, Loss (standarized): 1.3345692897843637\n",
      "          Validation Loss (standardized): 1.3716983503014262\n",
      "Epoch: 76, Loss (standarized): 1.3312816742848395\n",
      "          Validation Loss (standardized): 1.3696283359091448\n",
      "Epoch: 81, Loss (standarized): 1.3284592120519323\n",
      "          Validation Loss (standardized): 1.3685935244980882\n",
      "Epoch: 86, Loss (standarized): 1.325732045966501\n",
      "          Validation Loss (standardized): 1.3653035819163106\n",
      "Epoch: 91, Loss (standarized): 1.3228637374149246\n",
      "          Validation Loss (standardized): 1.3616642993687171\n",
      "Epoch: 96, Loss (standarized): 1.3196706719047262\n",
      "          Validation Loss (standardized): 1.3584063289535129\n",
      "Final epoch: 100, Final loss (standarized): 1.3168524829197799\n",
      "Epoch: 1, Loss (standarized): 1.7026436957426034\n",
      "          Validation Loss (standardized): 1.5166092621063454\n",
      "Epoch: 6, Loss (standarized): 1.5977069306512228\n",
      "          Validation Loss (standardized): 1.6788583319109893\n",
      "Epoch: 11, Loss (standarized): 1.5790728079515701\n",
      "          Validation Loss (standardized): 1.6113153702449792\n",
      "Epoch: 16, Loss (standarized): 1.5448613251601302\n",
      "          Validation Loss (standardized): 1.5106815660677027\n",
      "Epoch: 21, Loss (standarized): 1.508718607503559\n",
      "          Validation Loss (standardized): 1.4932511468246992\n",
      "Epoch: 26, Loss (standarized): 1.4588548325146353\n",
      "          Validation Loss (standardized): 1.4884519589574683\n",
      "Epoch: 31, Loss (standarized): 1.4147778829683852\n",
      "          Validation Loss (standardized): 1.4603493569704427\n",
      "Epoch: 36, Loss (standarized): 1.378534320013375\n",
      "          Validation Loss (standardized): 1.4050563746033518\n",
      "Epoch: 41, Loss (standarized): 1.3569282355453636\n",
      "          Validation Loss (standardized): 1.3830169863382547\n",
      "Epoch: 46, Loss (standarized): 1.3427259102574451\n",
      "          Validation Loss (standardized): 1.387866716701214\n",
      "Epoch: 51, Loss (standarized): 1.3345413254831837\n",
      "          Validation Loss (standardized): 1.381784102196143\n",
      "Epoch: 56, Loss (standarized): 1.3288476977990857\n",
      "          Validation Loss (standardized): 1.366375956600466\n",
      "Epoch: 61, Loss (standarized): 1.3248610469016457\n",
      "          Validation Loss (standardized): 1.3635141944421776\n",
      "Epoch: 66, Loss (standarized): 1.3206426975860261\n",
      "          Validation Loss (standardized): 1.3666341943949991\n",
      "Epoch: 71, Loss (standarized): 1.3154634669818948\n",
      "          Validation Loss (standardized): 1.3593053047382553\n",
      "Epoch: 76, Loss (standarized): 1.3091663337296182\n",
      "          Validation Loss (standardized): 1.3492494949187537\n",
      "Epoch: 81, Loss (standarized): 1.3016925450847399\n",
      "          Validation Loss (standardized): 1.3427938436990137\n",
      "Epoch: 86, Loss (standarized): 1.2927040145736908\n",
      "          Validation Loss (standardized): 1.334401493934652\n",
      "Epoch: 91, Loss (standarized): 1.281803774335642\n",
      "          Validation Loss (standardized): 1.322042793367059\n",
      "Epoch: 96, Loss (standarized): 1.2686099937959425\n",
      "          Validation Loss (standardized): 1.309808507209477\n",
      "Final epoch: 100, Final loss (standarized): 1.2561711472267405\n",
      "Epoch: 1, Loss (standarized): 1.7631909116083162\n",
      "          Validation Loss (standardized): 1.4879668525913299\n",
      "Epoch: 6, Loss (standarized): 1.6117124014620372\n",
      "          Validation Loss (standardized): 1.6864019455476016\n",
      "Epoch: 11, Loss (standarized): 1.6115007017801402\n",
      "          Validation Loss (standardized): 1.6706986016502825\n",
      "Epoch: 16, Loss (standarized): 1.5692563393163312\n",
      "          Validation Loss (standardized): 1.5678601406668942\n",
      "Epoch: 21, Loss (standarized): 1.5470749137108282\n",
      "          Validation Loss (standardized): 1.5026336290633475\n",
      "Epoch: 26, Loss (standarized): 1.5077475748292455\n",
      "          Validation Loss (standardized): 1.4991541396187877\n",
      "Epoch: 31, Loss (standarized): 1.4633391293256388\n",
      "          Validation Loss (standardized): 1.5021502330968883\n",
      "Epoch: 36, Loss (standarized): 1.420495597390842\n",
      "          Validation Loss (standardized): 1.4553803548169062\n",
      "Epoch: 41, Loss (standarized): 1.3832319203815415\n",
      "          Validation Loss (standardized): 1.4109302586209533\n",
      "Epoch: 46, Loss (standarized): 1.3599315530259286\n",
      "          Validation Loss (standardized): 1.38330062078307\n",
      "Epoch: 51, Loss (standarized): 1.345095187687918\n",
      "          Validation Loss (standardized): 1.3832486490621634\n",
      "Epoch: 56, Loss (standarized): 1.3368045866283358\n",
      "          Validation Loss (standardized): 1.3820107181699564\n",
      "Epoch: 61, Loss (standarized): 1.3314827267774634\n",
      "          Validation Loss (standardized): 1.3692967413409056\n",
      "Epoch: 66, Loss (standarized): 1.3279213861768335\n",
      "          Validation Loss (standardized): 1.3621829141303423\n",
      "Epoch: 71, Loss (standarized): 1.3246744443814016\n",
      "          Validation Loss (standardized): 1.3616932778608124\n",
      "Epoch: 76, Loss (standarized): 1.3210438869346597\n",
      "          Validation Loss (standardized): 1.3622376081897987\n",
      "Epoch: 81, Loss (standarized): 1.316741928756617\n",
      "          Validation Loss (standardized): 1.3551562598104905\n",
      "Epoch: 86, Loss (standarized): 1.3118541278266553\n",
      "          Validation Loss (standardized): 1.3494264903566058\n",
      "Epoch: 91, Loss (standarized): 1.3062211415829241\n",
      "          Validation Loss (standardized): 1.344897948963622\n",
      "Epoch: 96, Loss (standarized): 1.299647595405707\n",
      "          Validation Loss (standardized): 1.3375869776653944\n",
      "Final epoch: 100, Final loss (standarized): 1.293546326922662\n",
      "Epoch: 1, Loss (standarized): 1.6643751219930547\n",
      "          Validation Loss (standardized): 1.6246072934641338\n",
      "Epoch: 6, Loss (standarized): 1.610405373864256\n",
      "          Validation Loss (standardized): 1.6027675041131\n",
      "Epoch: 11, Loss (standarized): 1.5844598282668247\n",
      "          Validation Loss (standardized): 1.5959956496660999\n",
      "Epoch: 16, Loss (standarized): 1.57526102766706\n",
      "          Validation Loss (standardized): 1.5837288877114988\n",
      "Epoch: 21, Loss (standarized): 1.5550519909564924\n",
      "          Validation Loss (standardized): 1.5622782205912968\n",
      "Epoch: 26, Loss (standarized): 1.5337057417476638\n",
      "          Validation Loss (standardized): 1.552217825232668\n",
      "Epoch: 31, Loss (standarized): 1.5042469072666018\n",
      "          Validation Loss (standardized): 1.5249945911660228\n",
      "Epoch: 36, Loss (standarized): 1.4688626344514397\n",
      "          Validation Loss (standardized): 1.4896227211905382\n",
      "Epoch: 41, Loss (standarized): 1.4331585367647077\n",
      "          Validation Loss (standardized): 1.4682468169018665\n",
      "Epoch: 46, Loss (standarized): 1.4029293592502752\n",
      "          Validation Loss (standardized): 1.4401057631779808\n",
      "Epoch: 51, Loss (standarized): 1.3831614651835744\n",
      "          Validation Loss (standardized): 1.4223108526774195\n",
      "Epoch: 56, Loss (standarized): 1.3731080983455184\n",
      "          Validation Loss (standardized): 1.4144396452192394\n",
      "Epoch: 61, Loss (standarized): 1.370396661535696\n",
      "          Validation Loss (standardized): 1.4120372817544564\n",
      "Epoch: 66, Loss (standarized): 1.3711174455911745\n",
      "          Validation Loss (standardized): 1.4110210623066601\n",
      "Epoch: 71, Loss (standarized): 1.3722110814429178\n",
      "          Validation Loss (standardized): 1.4126719008866635\n",
      "Epoch: 76, Loss (standarized): 1.3721643598565298\n",
      "          Validation Loss (standardized): 1.4123723535018362\n",
      "Epoch: 81, Loss (standarized): 1.3704981922715234\n",
      "          Validation Loss (standardized): 1.4102711984285572\n",
      "Epoch: 86, Loss (standarized): 1.3686591045048855\n",
      "          Validation Loss (standardized): 1.409211891122896\n",
      "Epoch: 91, Loss (standarized): 1.367685940981463\n",
      "          Validation Loss (standardized): 1.4086948924763896\n",
      "Epoch: 96, Loss (standarized): 1.3674401350014775\n",
      "          Validation Loss (standardized): 1.408496761748425\n",
      "Final epoch: 100, Final loss (standarized): 1.3676198647787134\n",
      "Epoch: 1, Loss (standarized): 1.8973445436520295\n",
      "          Validation Loss (standardized): 1.8827597346277387\n",
      "Epoch: 6, Loss (standarized): 1.601432277755339\n",
      "          Validation Loss (standardized): 1.562477916185048\n",
      "Epoch: 11, Loss (standarized): 1.610755037574889\n",
      "          Validation Loss (standardized): 1.54563086403245\n",
      "Epoch: 16, Loss (standarized): 1.5824616364611126\n",
      "          Validation Loss (standardized): 1.5606544443405945\n",
      "Epoch: 21, Loss (standarized): 1.5346697091181705\n",
      "          Validation Loss (standardized): 1.5500393552492402\n",
      "Epoch: 26, Loss (standarized): 1.506676434564703\n",
      "          Validation Loss (standardized): 1.530986141522466\n",
      "Epoch: 31, Loss (standarized): 1.4697249119043079\n",
      "          Validation Loss (standardized): 1.4973954139734118\n",
      "Epoch: 36, Loss (standarized): 1.4275388443416994\n",
      "          Validation Loss (standardized): 1.4526982212659245\n",
      "Epoch: 41, Loss (standarized): 1.3981019142755093\n",
      "          Validation Loss (standardized): 1.416216889375521\n",
      "Epoch: 46, Loss (standarized): 1.3768530062914632\n",
      "          Validation Loss (standardized): 1.394637460552432\n",
      "Epoch: 51, Loss (standarized): 1.360040370686762\n",
      "          Validation Loss (standardized): 1.3874768581911667\n",
      "Epoch: 56, Loss (standarized): 1.3485037192965459\n",
      "          Validation Loss (standardized): 1.3875949174866924\n",
      "Epoch: 61, Loss (standarized): 1.340011592492791\n",
      "          Validation Loss (standardized): 1.37966349590628\n",
      "Epoch: 66, Loss (standarized): 1.3338455712362691\n",
      "          Validation Loss (standardized): 1.3693634988971595\n",
      "Epoch: 71, Loss (standarized): 1.3299349633872706\n",
      "          Validation Loss (standardized): 1.3656975755460194\n",
      "Epoch: 76, Loss (standarized): 1.3266912706731344\n",
      "          Validation Loss (standardized): 1.366702653473639\n",
      "Epoch: 81, Loss (standarized): 1.3235088685961662\n",
      "          Validation Loss (standardized): 1.365722808820653\n",
      "Epoch: 86, Loss (standarized): 1.3201602831727195\n",
      "          Validation Loss (standardized): 1.3609665256624788\n",
      "Epoch: 91, Loss (standarized): 1.316667778108978\n",
      "          Validation Loss (standardized): 1.3549909889942677\n",
      "Epoch: 96, Loss (standarized): 1.313006808181124\n",
      "          Validation Loss (standardized): 1.3501040021805795\n",
      "Final epoch: 100, Final loss (standarized): 1.3098174879893048\n",
      "Epoch: 1, Loss (standarized): 1.8638321056884768\n",
      "          Validation Loss (standardized): 1.7975818158410573\n",
      "Epoch: 6, Loss (standarized): 1.617447954637001\n",
      "          Validation Loss (standardized): 1.6353939443471577\n",
      "Epoch: 11, Loss (standarized): 1.632885098387271\n",
      "          Validation Loss (standardized): 1.5881510727642216\n",
      "Epoch: 16, Loss (standarized): 1.601381993363722\n",
      "          Validation Loss (standardized): 1.5612273461183364\n",
      "Epoch: 21, Loss (standarized): 1.570374182520233\n",
      "          Validation Loss (standardized): 1.5948383083279596\n",
      "Epoch: 26, Loss (standarized): 1.5587944828711473\n",
      "          Validation Loss (standardized): 1.5952768594914248\n",
      "Epoch: 31, Loss (standarized): 1.5311244801950585\n",
      "          Validation Loss (standardized): 1.5408680419593643\n",
      "Epoch: 36, Loss (standarized): 1.500687356140598\n",
      "          Validation Loss (standardized): 1.5102875867436019\n",
      "Epoch: 41, Loss (standarized): 1.468717967572668\n",
      "          Validation Loss (standardized): 1.4911754740424494\n",
      "Epoch: 46, Loss (standarized): 1.4335137518190464\n",
      "          Validation Loss (standardized): 1.4577301642030265\n",
      "Epoch: 51, Loss (standarized): 1.404617365590319\n",
      "          Validation Loss (standardized): 1.4308564186369417\n",
      "Epoch: 56, Loss (standarized): 1.3811042928995685\n",
      "          Validation Loss (standardized): 1.4086301545518234\n",
      "Epoch: 61, Loss (standarized): 1.3629978489984285\n",
      "          Validation Loss (standardized): 1.3893266552677215\n",
      "Epoch: 66, Loss (standarized): 1.3495814172341165\n",
      "          Validation Loss (standardized): 1.3800753818570073\n",
      "Epoch: 71, Loss (standarized): 1.3400654134050112\n",
      "          Validation Loss (standardized): 1.3721040388584365\n",
      "Epoch: 76, Loss (standarized): 1.3339389387069622\n",
      "          Validation Loss (standardized): 1.3653439841784694\n",
      "Epoch: 81, Loss (standarized): 1.3296202481358725\n",
      "          Validation Loss (standardized): 1.3614938512754975\n",
      "Epoch: 86, Loss (standarized): 1.3256460020878758\n",
      "          Validation Loss (standardized): 1.356735885328338\n",
      "Epoch: 91, Loss (standarized): 1.3212903154411493\n",
      "          Validation Loss (standardized): 1.3545464351724772\n",
      "Epoch: 96, Loss (standarized): 1.316301245101509\n",
      "          Validation Loss (standardized): 1.350553628823079\n",
      "Final epoch: 100, Final loss (standarized): 1.3116856166358541\n",
      "Epoch: 1, Loss (standarized): 1.6865070378277423\n",
      "          Validation Loss (standardized): 1.6548057402599439\n",
      "Epoch: 6, Loss (standarized): 1.611354351708777\n",
      "          Validation Loss (standardized): 1.5875330767503673\n",
      "Epoch: 11, Loss (standarized): 1.6167642523696208\n",
      "          Validation Loss (standardized): 1.629085811565933\n",
      "Epoch: 16, Loss (standarized): 1.6115252159165407\n",
      "          Validation Loss (standardized): 1.629709021011386\n",
      "Epoch: 21, Loss (standarized): 1.6081181002828755\n",
      "          Validation Loss (standardized): 1.6161920408746369\n",
      "Epoch: 26, Loss (standarized): 1.6090847359570224\n",
      "          Validation Loss (standardized): 1.6129709389270392\n",
      "Epoch: 31, Loss (standarized): 1.6090313309082547\n",
      "          Validation Loss (standardized): 1.6156108213474878\n",
      "Epoch: 36, Loss (standarized): 1.6100338152100135\n",
      "          Validation Loss (standardized): 1.6101150527981876\n",
      "Epoch: 41, Loss (standarized): 1.609702359805092\n",
      "          Validation Loss (standardized): 1.6021860129532404\n",
      "Epoch: 46, Loss (standarized): 1.6095935418094967\n",
      "          Validation Loss (standardized): 1.5972152675170905\n",
      "Epoch: 51, Loss (standarized): 1.6097411654968052\n",
      "          Validation Loss (standardized): 1.5961530611900399\n",
      "Epoch: 56, Loss (standarized): 1.6095980090114475\n",
      "          Validation Loss (standardized): 1.6008239700834643\n",
      "Epoch: 61, Loss (standarized): 1.6096031277523337\n",
      "          Validation Loss (standardized): 1.6131726849568893\n",
      "Epoch: 66, Loss (standarized): 1.6098154924245784\n",
      "          Validation Loss (standardized): 1.6127733208441424\n",
      "Epoch: 71, Loss (standarized): 1.6098677299265476\n",
      "          Validation Loss (standardized): 1.608169605978111\n",
      "Epoch: 76, Loss (standarized): 1.6095545363012773\n",
      "          Validation Loss (standardized): 1.6080953937555067\n",
      "Epoch: 81, Loss (standarized): 1.6094535949392588\n",
      "          Validation Loss (standardized): 1.6108619610835084\n",
      "Epoch: 86, Loss (standarized): 1.609474961462756\n",
      "          Validation Loss (standardized): 1.6120689113436328\n",
      "Epoch: 91, Loss (standarized): 1.6094577569851185\n",
      "          Validation Loss (standardized): 1.6088906555159779\n",
      "Epoch: 96, Loss (standarized): 1.6095972985836078\n",
      "          Validation Loss (standardized): 1.6060084274798274\n",
      "Final epoch: 100, Final loss (standarized): 1.6095363705454102\n",
      "Epoch: 1, Loss (standarized): 1.6918160033086542\n",
      "          Validation Loss (standardized): 1.684620963894593\n",
      "Epoch: 6, Loss (standarized): 1.608147045358133\n",
      "          Validation Loss (standardized): 1.5877185214450746\n",
      "Epoch: 11, Loss (standarized): 1.6152557378292294\n",
      "          Validation Loss (standardized): 1.620503445050257\n",
      "Epoch: 16, Loss (standarized): 1.6104787733453088\n",
      "          Validation Loss (standardized): 1.6039765719764616\n",
      "Epoch: 21, Loss (standarized): 1.6084317684790073\n",
      "          Validation Loss (standardized): 1.5949232458202154\n",
      "Epoch: 26, Loss (standarized): 1.6094516770920295\n",
      "          Validation Loss (standardized): 1.6089476739187258\n",
      "Epoch: 31, Loss (standarized): 1.6091351788821242\n",
      "          Validation Loss (standardized): 1.6112686638213527\n",
      "Epoch: 36, Loss (standarized): 1.6091259120848234\n",
      "          Validation Loss (standardized): 1.6126063435360594\n",
      "Epoch: 41, Loss (standarized): 1.6093216399751182\n",
      "          Validation Loss (standardized): 1.6048002657050406\n",
      "Epoch: 46, Loss (standarized): 1.6094121075972543\n",
      "          Validation Loss (standardized): 1.6056798736534117\n",
      "Epoch: 51, Loss (standarized): 1.6095135002661691\n",
      "          Validation Loss (standardized): 1.6122789161586988\n",
      "Epoch: 56, Loss (standarized): 1.609583910983639\n",
      "          Validation Loss (standardized): 1.6065818097510087\n",
      "Epoch: 61, Loss (standarized): 1.609637620601261\n",
      "          Validation Loss (standardized): 1.611358239605461\n",
      "Epoch: 66, Loss (standarized): 1.609563709823376\n",
      "          Validation Loss (standardized): 1.6134226769018714\n",
      "Epoch: 71, Loss (standarized): 1.6094922035907415\n",
      "          Validation Loss (standardized): 1.615604707980766\n",
      "Epoch: 76, Loss (standarized): 1.609584239144059\n",
      "          Validation Loss (standardized): 1.6098564344692792\n",
      "Epoch: 81, Loss (standarized): 1.6095355540609473\n",
      "          Validation Loss (standardized): 1.6135681431280315\n",
      "Epoch: 86, Loss (standarized): 1.6095151233662597\n",
      "          Validation Loss (standardized): 1.610302055644939\n",
      "Epoch: 91, Loss (standarized): 1.6095367687323598\n",
      "          Validation Loss (standardized): 1.6111645389642175\n",
      "Epoch: 96, Loss (standarized): 1.609590095975513\n",
      "          Validation Loss (standardized): 1.6060562092847626\n",
      "Final epoch: 100, Final loss (standarized): 1.60956007409531\n",
      "Epoch: 1, Loss (standarized): 1.8988415833215564\n",
      "          Validation Loss (standardized): 1.6923625965170246\n",
      "Epoch: 6, Loss (standarized): 1.644321019280548\n",
      "          Validation Loss (standardized): 1.5679487167403257\n",
      "Epoch: 11, Loss (standarized): 1.608405503278488\n",
      "          Validation Loss (standardized): 1.598805512640814\n",
      "Epoch: 16, Loss (standarized): 1.6179661216530263\n",
      "          Validation Loss (standardized): 1.6619682305566832\n",
      "Epoch: 21, Loss (standarized): 1.6166962594332963\n",
      "          Validation Loss (standardized): 1.6718150036052484\n",
      "Epoch: 26, Loss (standarized): 1.6102176318859\n",
      "          Validation Loss (standardized): 1.6328552064568502\n",
      "Epoch: 31, Loss (standarized): 1.6098153185116173\n",
      "          Validation Loss (standardized): 1.5905840488562841\n",
      "Epoch: 36, Loss (standarized): 1.610978249422135\n",
      "          Validation Loss (standardized): 1.5848911503557375\n",
      "Epoch: 41, Loss (standarized): 1.6099219019278936\n",
      "          Validation Loss (standardized): 1.6009671525932967\n",
      "Epoch: 46, Loss (standarized): 1.609503295486528\n",
      "          Validation Loss (standardized): 1.616210096660237\n",
      "Epoch: 51, Loss (standarized): 1.6097839925592314\n",
      "          Validation Loss (standardized): 1.621353947091935\n",
      "Epoch: 56, Loss (standarized): 1.6096668424723573\n",
      "          Validation Loss (standardized): 1.6100491726534243\n",
      "Epoch: 61, Loss (standarized): 1.6094504334064386\n",
      "          Validation Loss (standardized): 1.607570698400069\n",
      "Epoch: 66, Loss (standarized): 1.6096527879659153\n",
      "          Validation Loss (standardized): 1.6211111811639884\n",
      "Epoch: 71, Loss (standarized): 1.6099162964476594\n",
      "          Validation Loss (standardized): 1.6239420479274962\n",
      "Epoch: 76, Loss (standarized): 1.6096886560835175\n",
      "          Validation Loss (standardized): 1.6177265764683748\n",
      "Epoch: 81, Loss (standarized): 1.6095767975067536\n",
      "          Validation Loss (standardized): 1.614060922823449\n",
      "Epoch: 86, Loss (standarized): 1.609527840470241\n",
      "          Validation Loss (standardized): 1.6094338054327508\n",
      "Epoch: 91, Loss (standarized): 1.6094847321920762\n",
      "          Validation Loss (standardized): 1.6076005986620907\n",
      "Epoch: 96, Loss (standarized): 1.6095451205935654\n",
      "          Validation Loss (standardized): 1.6056814091437523\n",
      "Final epoch: 100, Final loss (standarized): 1.6095525235204093\n",
      "Epoch: 1, Loss (standarized): 1.8671441229560608\n",
      "          Validation Loss (standardized): 1.5810925646754994\n",
      "Epoch: 6, Loss (standarized): 1.6490864677243409\n",
      "          Validation Loss (standardized): 1.6108470154527994\n",
      "Epoch: 11, Loss (standarized): 1.6071245516749428\n",
      "          Validation Loss (standardized): 1.6545618411843612\n",
      "Epoch: 16, Loss (standarized): 1.6134851096920033\n",
      "          Validation Loss (standardized): 1.6408937547376772\n",
      "Epoch: 21, Loss (standarized): 1.6053660772800549\n",
      "          Validation Loss (standardized): 1.6019453595917321\n",
      "Epoch: 26, Loss (standarized): 1.6059026039765332\n",
      "          Validation Loss (standardized): 1.6014190235828074\n",
      "Epoch: 31, Loss (standarized): 1.608635390947306\n",
      "          Validation Loss (standardized): 1.6090224927800791\n",
      "Epoch: 36, Loss (standarized): 1.6081181484957963\n",
      "          Validation Loss (standardized): 1.6140460423672458\n",
      "Epoch: 41, Loss (standarized): 1.6088516810922584\n",
      "          Validation Loss (standardized): 1.6238716730816367\n",
      "Epoch: 46, Loss (standarized): 1.609486597175541\n",
      "          Validation Loss (standardized): 1.6209385521002337\n",
      "Epoch: 51, Loss (standarized): 1.6096569243827648\n",
      "          Validation Loss (standardized): 1.6148865612799772\n",
      "Epoch: 56, Loss (standarized): 1.6096231018334453\n",
      "          Validation Loss (standardized): 1.6073762439929729\n",
      "Epoch: 61, Loss (standarized): 1.6098022192322676\n",
      "          Validation Loss (standardized): 1.6104379448110269\n",
      "Epoch: 66, Loss (standarized): 1.609586998024788\n",
      "          Validation Loss (standardized): 1.6079281960657705\n",
      "Epoch: 71, Loss (standarized): 1.6095008715864112\n",
      "          Validation Loss (standardized): 1.6071546273193817\n",
      "Epoch: 76, Loss (standarized): 1.6095763653425734\n",
      "          Validation Loss (standardized): 1.6047225028671632\n",
      "Epoch: 81, Loss (standarized): 1.6095056114778938\n",
      "          Validation Loss (standardized): 1.6087647788364365\n",
      "Epoch: 86, Loss (standarized): 1.6095299943141452\n",
      "          Validation Loss (standardized): 1.604358338728241\n",
      "Epoch: 91, Loss (standarized): 1.609529083259268\n",
      "          Validation Loss (standardized): 1.603246329018116\n",
      "Epoch: 96, Loss (standarized): 1.6095659920035905\n",
      "          Validation Loss (standardized): 1.6047808271410553\n",
      "Final epoch: 100, Final loss (standarized): 1.6094795124320647\n",
      "Epoch: 1, Loss (standarized): 1.681471328694596\n",
      "          Validation Loss (standardized): 1.5467869543021113\n",
      "Epoch: 6, Loss (standarized): 1.5816722979390982\n",
      "          Validation Loss (standardized): 1.6231210518751866\n",
      "Epoch: 11, Loss (standarized): 1.557756526019575\n",
      "          Validation Loss (standardized): 1.59982012017288\n",
      "Epoch: 16, Loss (standarized): 1.517586550859162\n",
      "          Validation Loss (standardized): 1.5260418627580188\n",
      "Epoch: 21, Loss (standarized): 1.484164419138677\n",
      "          Validation Loss (standardized): 1.4766304696556736\n",
      "Epoch: 26, Loss (standarized): 1.4419087931085586\n",
      "          Validation Loss (standardized): 1.4616756568499758\n",
      "Epoch: 31, Loss (standarized): 1.4056255075105792\n",
      "          Validation Loss (standardized): 1.458362145899949\n",
      "Epoch: 36, Loss (standarized): 1.3762316396027081\n",
      "          Validation Loss (standardized): 1.4124540960307843\n",
      "Epoch: 41, Loss (standarized): 1.3568850321259305\n",
      "          Validation Loss (standardized): 1.3889524124331913\n",
      "Epoch: 46, Loss (standarized): 1.344961026496643\n",
      "          Validation Loss (standardized): 1.3799872782553857\n",
      "Epoch: 51, Loss (standarized): 1.3379761472072735\n",
      "          Validation Loss (standardized): 1.3790436191813185\n",
      "Epoch: 56, Loss (standarized): 1.3334852180524057\n",
      "          Validation Loss (standardized): 1.367329579721162\n",
      "Epoch: 61, Loss (standarized): 1.330409232799245\n",
      "          Validation Loss (standardized): 1.3608408231657385\n",
      "Epoch: 66, Loss (standarized): 1.3276127735539724\n",
      "          Validation Loss (standardized): 1.3633334659345555\n",
      "Epoch: 71, Loss (standarized): 1.3249589112272133\n",
      "          Validation Loss (standardized): 1.3599246366205935\n",
      "Epoch: 76, Loss (standarized): 1.3220274702393708\n",
      "          Validation Loss (standardized): 1.3554477878126787\n",
      "Epoch: 81, Loss (standarized): 1.3186538198985593\n",
      "          Validation Loss (standardized): 1.3510870751921884\n",
      "Epoch: 86, Loss (standarized): 1.3147560212902745\n",
      "          Validation Loss (standardized): 1.3473788895010899\n",
      "Epoch: 91, Loss (standarized): 1.3101777044027734\n",
      "          Validation Loss (standardized): 1.342681985924666\n",
      "Epoch: 96, Loss (standarized): 1.304724815645339\n",
      "          Validation Loss (standardized): 1.335041237170254\n",
      "Final epoch: 100, Final loss (standarized): 1.2996829935754548\n",
      "Epoch: 1, Loss (standarized): 1.7837141509338952\n",
      "          Validation Loss (standardized): 1.6221300741257123\n",
      "Epoch: 6, Loss (standarized): 1.60819307278773\n",
      "          Validation Loss (standardized): 1.6226459803478688\n",
      "Epoch: 11, Loss (standarized): 1.622595815415119\n",
      "          Validation Loss (standardized): 1.6582191250888434\n",
      "Epoch: 16, Loss (standarized): 1.6008078648525674\n",
      "          Validation Loss (standardized): 1.600948421535475\n",
      "Epoch: 21, Loss (standarized): 1.5958140673244423\n",
      "          Validation Loss (standardized): 1.5873621974254737\n",
      "Epoch: 26, Loss (standarized): 1.5971100479364433\n",
      "          Validation Loss (standardized): 1.5998581360190667\n",
      "Epoch: 31, Loss (standarized): 1.5904383932120556\n",
      "          Validation Loss (standardized): 1.5946721015592653\n",
      "Epoch: 36, Loss (standarized): 1.5898308477721284\n",
      "          Validation Loss (standardized): 1.5990358982577786\n",
      "Epoch: 41, Loss (standarized): 1.5881771605083295\n",
      "          Validation Loss (standardized): 1.6000651109715527\n",
      "Epoch: 46, Loss (standarized): 1.5869271987260691\n",
      "          Validation Loss (standardized): 1.590564191669928\n",
      "Epoch: 51, Loss (standarized): 1.5860562645569718\n",
      "          Validation Loss (standardized): 1.5880796720312185\n",
      "Epoch: 56, Loss (standarized): 1.5843248232981781\n",
      "          Validation Loss (standardized): 1.5931579613379472\n",
      "Epoch: 61, Loss (standarized): 1.5827787481288818\n",
      "          Validation Loss (standardized): 1.590693018560734\n",
      "Epoch: 66, Loss (standarized): 1.5806125401573832\n",
      "          Validation Loss (standardized): 1.5858647944663435\n",
      "Epoch: 71, Loss (standarized): 1.577856293025909\n",
      "          Validation Loss (standardized): 1.5842504320847237\n",
      "Epoch: 76, Loss (standarized): 1.5741631559397575\n",
      "          Validation Loss (standardized): 1.5822347583445564\n",
      "Epoch: 81, Loss (standarized): 1.5693842600175116\n",
      "          Validation Loss (standardized): 1.578189566282495\n",
      "Epoch: 86, Loss (standarized): 1.5632310647233505\n",
      "          Validation Loss (standardized): 1.5728815530978104\n",
      "Epoch: 91, Loss (standarized): 1.5553186600754048\n",
      "          Validation Loss (standardized): 1.5665668691292378\n",
      "Epoch: 96, Loss (standarized): 1.5453785555358974\n",
      "          Validation Loss (standardized): 1.557676154483428\n",
      "Final epoch: 100, Final loss (standarized): 1.5357113869243517\n",
      "Epoch: 1, Loss (standarized): 1.896015414055409\n",
      "          Validation Loss (standardized): 1.4969512430406517\n",
      "Epoch: 6, Loss (standarized): 1.6109756823608772\n",
      "          Validation Loss (standardized): 1.580533710562411\n",
      "Epoch: 11, Loss (standarized): 1.6083174160699456\n",
      "          Validation Loss (standardized): 1.7118090849063141\n",
      "Epoch: 16, Loss (standarized): 1.607427046221626\n",
      "          Validation Loss (standardized): 1.7088126933631276\n",
      "Epoch: 21, Loss (standarized): 1.5792686807195264\n",
      "          Validation Loss (standardized): 1.6312432694867685\n",
      "Epoch: 26, Loss (standarized): 1.5567621881922837\n",
      "          Validation Loss (standardized): 1.55753577429089\n",
      "Epoch: 31, Loss (standarized): 1.5410290043214971\n",
      "          Validation Loss (standardized): 1.5195875259683838\n",
      "Epoch: 36, Loss (standarized): 1.5139259176767053\n",
      "          Validation Loss (standardized): 1.5162041277143203\n",
      "Epoch: 41, Loss (standarized): 1.480876097050877\n",
      "          Validation Loss (standardized): 1.523382382808721\n",
      "Epoch: 46, Loss (standarized): 1.4490983334161984\n",
      "          Validation Loss (standardized): 1.5118965151066113\n",
      "Epoch: 51, Loss (standarized): 1.4174195382614192\n",
      "          Validation Loss (standardized): 1.4705529119468839\n",
      "Epoch: 56, Loss (standarized): 1.3908605426860288\n",
      "          Validation Loss (standardized): 1.431368299224532\n",
      "Epoch: 61, Loss (standarized): 1.3709923667962567\n",
      "          Validation Loss (standardized): 1.4134765641186906\n",
      "Epoch: 66, Loss (standarized): 1.3569330530688961\n",
      "          Validation Loss (standardized): 1.4086428219773075\n",
      "Epoch: 71, Loss (standarized): 1.3480456458855234\n",
      "          Validation Loss (standardized): 1.3988952129401226\n",
      "Epoch: 76, Loss (standarized): 1.3425796276921\n",
      "          Validation Loss (standardized): 1.3874308736773941\n",
      "Epoch: 81, Loss (standarized): 1.3392311444162002\n",
      "          Validation Loss (standardized): 1.3814849168423933\n",
      "Epoch: 86, Loss (standarized): 1.3369841931101079\n",
      "          Validation Loss (standardized): 1.380970284433727\n",
      "Epoch: 91, Loss (standarized): 1.3353976835335755\n",
      "          Validation Loss (standardized): 1.380022442364177\n",
      "Epoch: 96, Loss (standarized): 1.3339218023929282\n",
      "          Validation Loss (standardized): 1.3767376378666973\n",
      "Final epoch: 100, Final loss (standarized): 1.332655051829238\n",
      "Epoch: 1, Loss (standarized): 1.7202572274684087\n",
      "          Validation Loss (standardized): 1.6923089226969865\n",
      "Epoch: 6, Loss (standarized): 1.608962335488943\n",
      "          Validation Loss (standardized): 1.593813318774358\n",
      "Epoch: 11, Loss (standarized): 1.5957293410351345\n",
      "          Validation Loss (standardized): 1.5712016854593138\n",
      "Epoch: 16, Loss (standarized): 1.5697872136166304\n",
      "          Validation Loss (standardized): 1.5798189665924283\n",
      "Epoch: 21, Loss (standarized): 1.5558935284881914\n",
      "          Validation Loss (standardized): 1.5598975304900418\n",
      "Epoch: 26, Loss (standarized): 1.5306769161151348\n",
      "          Validation Loss (standardized): 1.526169077954052\n",
      "Epoch: 31, Loss (standarized): 1.506064730529716\n",
      "          Validation Loss (standardized): 1.514040075587816\n",
      "Epoch: 36, Loss (standarized): 1.4745429062287736\n",
      "          Validation Loss (standardized): 1.4848601766876022\n",
      "Epoch: 41, Loss (standarized): 1.4423026743680767\n",
      "          Validation Loss (standardized): 1.4549726235142098\n",
      "Epoch: 46, Loss (standarized): 1.411284258481503\n",
      "          Validation Loss (standardized): 1.4353048053934738\n",
      "Epoch: 51, Loss (standarized): 1.3850907006771787\n",
      "          Validation Loss (standardized): 1.411820468634734\n",
      "Epoch: 56, Loss (standarized): 1.364484078035995\n",
      "          Validation Loss (standardized): 1.3952767047263388\n",
      "Epoch: 61, Loss (standarized): 1.3496516901823719\n",
      "          Validation Loss (standardized): 1.3856784456572013\n",
      "Epoch: 66, Loss (standarized): 1.3397586827056116\n",
      "          Validation Loss (standardized): 1.3780055819161734\n",
      "Epoch: 71, Loss (standarized): 1.3331381312141515\n",
      "          Validation Loss (standardized): 1.3721579494773515\n",
      "Epoch: 76, Loss (standarized): 1.3280980895425814\n",
      "          Validation Loss (standardized): 1.3659576301857563\n",
      "Epoch: 81, Loss (standarized): 1.3238610167765819\n",
      "          Validation Loss (standardized): 1.3617329354126986\n",
      "Epoch: 86, Loss (standarized): 1.3196380520255504\n",
      "          Validation Loss (standardized): 1.357422508209817\n",
      "Epoch: 91, Loss (standarized): 1.3149565322362238\n",
      "          Validation Loss (standardized): 1.3515247857453832\n",
      "Epoch: 96, Loss (standarized): 1.309607376269908\n",
      "          Validation Loss (standardized): 1.3460316208672585\n",
      "Final epoch: 100, Final loss (standarized): 1.304630571395153\n",
      "Epoch: 1, Loss (standarized): 1.6919170987220626\n",
      "          Validation Loss (standardized): 1.728077407686414\n",
      "Epoch: 6, Loss (standarized): 1.6096853719999347\n",
      "          Validation Loss (standardized): 1.5632148259704126\n",
      "Epoch: 11, Loss (standarized): 1.594291615954829\n",
      "          Validation Loss (standardized): 1.5508737488341147\n",
      "Epoch: 16, Loss (standarized): 1.563667481477666\n",
      "          Validation Loss (standardized): 1.6043995997093927\n",
      "Epoch: 21, Loss (standarized): 1.5357861914701059\n",
      "          Validation Loss (standardized): 1.5804878583361945\n",
      "Epoch: 26, Loss (standarized): 1.4895490080454399\n",
      "          Validation Loss (standardized): 1.4985488900726114\n",
      "Epoch: 31, Loss (standarized): 1.4411013456288242\n",
      "          Validation Loss (standardized): 1.455211066070285\n",
      "Epoch: 36, Loss (standarized): 1.3922898227154292\n",
      "          Validation Loss (standardized): 1.42720745820079\n",
      "Epoch: 41, Loss (standarized): 1.358140331479759\n",
      "          Validation Loss (standardized): 1.4002346962947245\n",
      "Epoch: 46, Loss (standarized): 1.3406523452182089\n",
      "          Validation Loss (standardized): 1.375217538678447\n",
      "Epoch: 51, Loss (standarized): 1.3332256476730038\n",
      "          Validation Loss (standardized): 1.3562404795305947\n",
      "Epoch: 56, Loss (standarized): 1.3281166221607856\n",
      "          Validation Loss (standardized): 1.355422371113406\n",
      "Epoch: 61, Loss (standarized): 1.3234555346595571\n",
      "          Validation Loss (standardized): 1.3543853839443951\n",
      "Epoch: 66, Loss (standarized): 1.318637490886184\n",
      "          Validation Loss (standardized): 1.3467893965043507\n",
      "Epoch: 71, Loss (standarized): 1.3134526680689935\n",
      "          Validation Loss (standardized): 1.3437311124558367\n",
      "Epoch: 76, Loss (standarized): 1.3072966277455913\n",
      "          Validation Loss (standardized): 1.3418349808769559\n",
      "Epoch: 81, Loss (standarized): 1.3000926065902905\n",
      "          Validation Loss (standardized): 1.3353616388763603\n",
      "Epoch: 86, Loss (standarized): 1.2915788734333677\n",
      "          Validation Loss (standardized): 1.324385325449986\n",
      "Epoch: 91, Loss (standarized): 1.2812341390248365\n",
      "          Validation Loss (standardized): 1.3142514379429153\n",
      "Epoch: 96, Loss (standarized): 1.268527699059062\n",
      "          Validation Loss (standardized): 1.3026403958778694\n",
      "Final epoch: 100, Final loss (standarized): 1.2563716706178085\n",
      "Epoch: 1, Loss (standarized): 1.6884614897605235\n",
      "          Validation Loss (standardized): 1.754876562970262\n",
      "Epoch: 6, Loss (standarized): 1.6164437213377518\n",
      "          Validation Loss (standardized): 1.5670438583429573\n",
      "Epoch: 11, Loss (standarized): 1.60350307292593\n",
      "          Validation Loss (standardized): 1.5784295631705403\n",
      "Epoch: 16, Loss (standarized): 1.592981699500448\n",
      "          Validation Loss (standardized): 1.633092864893094\n",
      "Epoch: 21, Loss (standarized): 1.5847968003298945\n",
      "          Validation Loss (standardized): 1.6096739482661342\n",
      "Epoch: 26, Loss (standarized): 1.5731774423240905\n",
      "          Validation Loss (standardized): 1.5614616453615744\n",
      "Epoch: 31, Loss (standarized): 1.5571130476076227\n",
      "          Validation Loss (standardized): 1.5591647825744221\n",
      "Epoch: 36, Loss (standarized): 1.531945218677443\n",
      "          Validation Loss (standardized): 1.5597184249496485\n",
      "Epoch: 41, Loss (standarized): 1.4958881234007135\n",
      "          Validation Loss (standardized): 1.520970201249354\n",
      "Epoch: 46, Loss (standarized): 1.4517069183439026\n",
      "          Validation Loss (standardized): 1.4726395457226578\n",
      "Epoch: 51, Loss (standarized): 1.4086812551864412\n",
      "          Validation Loss (standardized): 1.4459778408087538\n",
      "Epoch: 56, Loss (standarized): 1.378825758586279\n",
      "          Validation Loss (standardized): 1.424127232640337\n",
      "Epoch: 61, Loss (standarized): 1.3645034233386781\n",
      "          Validation Loss (standardized): 1.4052946059639648\n",
      "Epoch: 66, Loss (standarized): 1.3613448532184012\n",
      "          Validation Loss (standardized): 1.4038857027292402\n",
      "Epoch: 71, Loss (standarized): 1.3645124505550654\n",
      "          Validation Loss (standardized): 1.4103685130795167\n",
      "Epoch: 76, Loss (standarized): 1.3693379205930534\n",
      "          Validation Loss (standardized): 1.411463473973782\n",
      "Epoch: 81, Loss (standarized): 1.3721962282215288\n",
      "          Validation Loss (standardized): 1.413493352359147\n",
      "Epoch: 86, Loss (standarized): 1.3720430702526454\n",
      "          Validation Loss (standardized): 1.4147014037508097\n",
      "Epoch: 91, Loss (standarized): 1.3702981527040965\n",
      "          Validation Loss (standardized): 1.4118615555711207\n",
      "Epoch: 96, Loss (standarized): 1.3689027779034115\n",
      "          Validation Loss (standardized): 1.410493893576644\n",
      "Final epoch: 100, Final loss (standarized): 1.3685932907365685\n",
      "Epoch: 1, Loss (standarized): 1.7573926276862601\n",
      "          Validation Loss (standardized): 1.6734719906189957\n",
      "Epoch: 6, Loss (standarized): 1.6177110115862976\n",
      "          Validation Loss (standardized): 1.6334230104501415\n",
      "Epoch: 11, Loss (standarized): 1.607765451567638\n",
      "          Validation Loss (standardized): 1.6024026911981375\n",
      "Epoch: 16, Loss (standarized): 1.5819841061280147\n",
      "          Validation Loss (standardized): 1.5831753920680625\n",
      "Epoch: 21, Loss (standarized): 1.568429722985564\n",
      "          Validation Loss (standardized): 1.5612142567822698\n",
      "Epoch: 26, Loss (standarized): 1.5380031129081584\n",
      "          Validation Loss (standardized): 1.5388397222462926\n",
      "Epoch: 31, Loss (standarized): 1.5092918869853458\n",
      "          Validation Loss (standardized): 1.5184830713061155\n",
      "Epoch: 36, Loss (standarized): 1.4691894655025473\n",
      "          Validation Loss (standardized): 1.48501579096916\n",
      "Epoch: 41, Loss (standarized): 1.4302594376304552\n",
      "          Validation Loss (standardized): 1.4465206022298063\n",
      "Epoch: 46, Loss (standarized): 1.3941206610155956\n",
      "          Validation Loss (standardized): 1.4177474476755256\n",
      "Epoch: 51, Loss (standarized): 1.3680254498259086\n",
      "          Validation Loss (standardized): 1.4020095258095269\n",
      "Epoch: 56, Loss (standarized): 1.350860458025772\n",
      "          Validation Loss (standardized): 1.3842415581664218\n",
      "Epoch: 61, Loss (standarized): 1.34073768217711\n",
      "          Validation Loss (standardized): 1.3704212269466436\n",
      "Epoch: 66, Loss (standarized): 1.3345004392815474\n",
      "          Validation Loss (standardized): 1.3672111091747887\n",
      "Epoch: 71, Loss (standarized): 1.3300508518858836\n",
      "          Validation Loss (standardized): 1.3650336093153206\n",
      "Epoch: 76, Loss (standarized): 1.3261584387949483\n",
      "          Validation Loss (standardized): 1.3610111589298353\n",
      "Epoch: 81, Loss (standarized): 1.3225932593824552\n",
      "          Validation Loss (standardized): 1.3596578554395424\n",
      "Epoch: 86, Loss (standarized): 1.3192149011128718\n",
      "          Validation Loss (standardized): 1.3589976249914737\n",
      "Epoch: 91, Loss (standarized): 1.3157472650503792\n",
      "          Validation Loss (standardized): 1.3565792870067197\n",
      "Epoch: 96, Loss (standarized): 1.311863169938535\n",
      "          Validation Loss (standardized): 1.353775498876908\n",
      "Final epoch: 100, Final loss (standarized): 1.308312422319835\n",
      "Epoch: 1, Loss (standarized): 1.7571176143638536\n",
      "          Validation Loss (standardized): 1.7403437956048817\n",
      "Epoch: 6, Loss (standarized): 1.5982166207042423\n",
      "          Validation Loss (standardized): 1.587227356218209\n",
      "Epoch: 11, Loss (standarized): 1.604007051039456\n",
      "          Validation Loss (standardized): 1.557623712682671\n",
      "Epoch: 16, Loss (standarized): 1.5670667538345027\n",
      "          Validation Loss (standardized): 1.5463165985919032\n",
      "Epoch: 21, Loss (standarized): 1.5397587418905143\n",
      "          Validation Loss (standardized): 1.5523806296781755\n",
      "Epoch: 26, Loss (standarized): 1.5121639232474817\n",
      "          Validation Loss (standardized): 1.5304097306973685\n",
      "Epoch: 31, Loss (standarized): 1.4722751062026673\n",
      "          Validation Loss (standardized): 1.4870537707318727\n",
      "Epoch: 36, Loss (standarized): 1.4349809342134534\n",
      "          Validation Loss (standardized): 1.4455484059190489\n",
      "Epoch: 41, Loss (standarized): 1.4014551932060386\n",
      "          Validation Loss (standardized): 1.4174572845307767\n",
      "Epoch: 46, Loss (standarized): 1.375694807518922\n",
      "          Validation Loss (standardized): 1.4016179465849063\n",
      "Epoch: 51, Loss (standarized): 1.3565166393285295\n",
      "          Validation Loss (standardized): 1.3848227703979943\n",
      "Epoch: 56, Loss (standarized): 1.3423204010738623\n",
      "          Validation Loss (standardized): 1.367249709625256\n",
      "Epoch: 61, Loss (standarized): 1.3335204253071242\n",
      "          Validation Loss (standardized): 1.356307588717591\n",
      "Epoch: 66, Loss (standarized): 1.3265101965416688\n",
      "          Validation Loss (standardized): 1.3545177698090531\n",
      "Epoch: 71, Loss (standarized): 1.3201075320698863\n",
      "          Validation Loss (standardized): 1.3510394645296493\n",
      "Epoch: 76, Loss (standarized): 1.3134721042542226\n",
      "          Validation Loss (standardized): 1.3436369731325213\n",
      "Epoch: 81, Loss (standarized): 1.3065082829732524\n",
      "          Validation Loss (standardized): 1.3367056818702103\n",
      "Epoch: 86, Loss (standarized): 1.298552960825747\n",
      "          Validation Loss (standardized): 1.3325926779597717\n",
      "Epoch: 91, Loss (standarized): 1.2893330941778194\n",
      "          Validation Loss (standardized): 1.3256377664057408\n",
      "Epoch: 96, Loss (standarized): 1.2786439587744156\n",
      "          Validation Loss (standardized): 1.3150782313169145\n",
      "Final epoch: 100, Final loss (standarized): 1.2688551210924464\n",
      "Epoch: 1, Loss (standarized): 1.6976651064938495\n",
      "          Validation Loss (standardized): 1.5229468369480952\n",
      "Epoch: 6, Loss (standarized): 1.6083132272804948\n",
      "          Validation Loss (standardized): 1.7003875678199114\n",
      "Epoch: 11, Loss (standarized): 1.5812953802088512\n",
      "          Validation Loss (standardized): 1.590967755186048\n",
      "Epoch: 16, Loss (standarized): 1.5518044185318371\n",
      "          Validation Loss (standardized): 1.5333614791707433\n",
      "Epoch: 21, Loss (standarized): 1.522711317038796\n",
      "          Validation Loss (standardized): 1.5385611686556238\n",
      "Epoch: 26, Loss (standarized): 1.4814729478491437\n",
      "          Validation Loss (standardized): 1.517538038899998\n",
      "Epoch: 31, Loss (standarized): 1.4395067570694087\n",
      "          Validation Loss (standardized): 1.4843237975006591\n",
      "Epoch: 36, Loss (standarized): 1.3970339516113877\n",
      "          Validation Loss (standardized): 1.4428281452815206\n",
      "Epoch: 41, Loss (standarized): 1.365727702932993\n",
      "          Validation Loss (standardized): 1.4011229565072767\n",
      "Epoch: 46, Loss (standarized): 1.3454236554492536\n",
      "          Validation Loss (standardized): 1.3847842745658903\n",
      "Epoch: 51, Loss (standarized): 1.3335652192967218\n",
      "          Validation Loss (standardized): 1.3742334276561636\n",
      "Epoch: 56, Loss (standarized): 1.3268154932505936\n",
      "          Validation Loss (standardized): 1.3534556266052133\n",
      "Epoch: 61, Loss (standarized): 1.3223121199381913\n",
      "          Validation Loss (standardized): 1.3504810984009337\n",
      "Epoch: 66, Loss (standarized): 1.317183551216237\n",
      "          Validation Loss (standardized): 1.3487139807239468\n",
      "Epoch: 71, Loss (standarized): 1.3101656717926184\n",
      "          Validation Loss (standardized): 1.3378692064970088\n",
      "Epoch: 76, Loss (standarized): 1.3014852783597468\n",
      "          Validation Loss (standardized): 1.3333469680301575\n",
      "Epoch: 81, Loss (standarized): 1.290861486212813\n",
      "          Validation Loss (standardized): 1.3259224542498944\n",
      "Epoch: 86, Loss (standarized): 1.2777035777395513\n",
      "          Validation Loss (standardized): 1.3140327494195596\n",
      "Epoch: 91, Loss (standarized): 1.2613871336554943\n",
      "          Validation Loss (standardized): 1.3008415883409463\n",
      "Epoch: 96, Loss (standarized): 1.2412810896723925\n",
      "          Validation Loss (standardized): 1.2834010614931366\n",
      "Final epoch: 100, Final loss (standarized): 1.2223306584280427\n",
      "Epoch: 1, Loss (standarized): 1.718276249901331\n",
      "          Validation Loss (standardized): 1.682766884675266\n",
      "Epoch: 6, Loss (standarized): 1.6161249196817584\n",
      "          Validation Loss (standardized): 1.5846565770595722\n",
      "Epoch: 11, Loss (standarized): 1.6063962527315008\n",
      "          Validation Loss (standardized): 1.6045101912324649\n",
      "Epoch: 16, Loss (standarized): 1.5859000759744515\n",
      "          Validation Loss (standardized): 1.5922020093916527\n",
      "Epoch: 21, Loss (standarized): 1.5813341530158538\n",
      "          Validation Loss (standardized): 1.5746189579397412\n",
      "Epoch: 26, Loss (standarized): 1.565804526586702\n",
      "          Validation Loss (standardized): 1.564986540708533\n",
      "Epoch: 31, Loss (standarized): 1.552143714807746\n",
      "          Validation Loss (standardized): 1.5580329250984468\n",
      "Epoch: 36, Loss (standarized): 1.5314280700196952\n",
      "          Validation Loss (standardized): 1.5333002807699623\n",
      "Epoch: 41, Loss (standarized): 1.5047023541944429\n",
      "          Validation Loss (standardized): 1.5097763079341757\n",
      "Epoch: 46, Loss (standarized): 1.4718992645470959\n",
      "          Validation Loss (standardized): 1.483115528085854\n",
      "Epoch: 51, Loss (standarized): 1.4382495062283869\n",
      "          Validation Loss (standardized): 1.4531527869155862\n",
      "Epoch: 56, Loss (standarized): 1.4111534938055394\n",
      "          Validation Loss (standardized): 1.43224478774863\n",
      "Epoch: 61, Loss (standarized): 1.3938323416256753\n",
      "          Validation Loss (standardized): 1.423488100152207\n",
      "Epoch: 66, Loss (standarized): 1.3851836466672536\n",
      "          Validation Loss (standardized): 1.4184553654168768\n",
      "Epoch: 71, Loss (standarized): 1.3822878282230948\n",
      "          Validation Loss (standardized): 1.4165256019605388\n",
      "Epoch: 76, Loss (standarized): 1.3812721267960646\n",
      "          Validation Loss (standardized): 1.418029855861738\n",
      "Epoch: 81, Loss (standarized): 1.3800032896286132\n",
      "          Validation Loss (standardized): 1.4180163060469277\n",
      "Epoch: 86, Loss (standarized): 1.3777262569942474\n",
      "          Validation Loss (standardized): 1.41471451980882\n",
      "Epoch: 91, Loss (standarized): 1.3749829214642517\n",
      "          Validation Loss (standardized): 1.4130499625034487\n",
      "Epoch: 96, Loss (standarized): 1.3729047408385813\n",
      "          Validation Loss (standardized): 1.411972298248918\n",
      "Final epoch: 100, Final loss (standarized): 1.3720241541845553\n",
      "Epoch: 1, Loss (standarized): 1.6734780106631661\n",
      "          Validation Loss (standardized): 1.5817829358681155\n",
      "Epoch: 6, Loss (standarized): 1.6099978572940672\n",
      "          Validation Loss (standardized): 1.6428448115724656\n",
      "Epoch: 11, Loss (standarized): 1.5879282545634674\n",
      "          Validation Loss (standardized): 1.6016745216793111\n",
      "Epoch: 16, Loss (standarized): 1.5686014866395472\n",
      "          Validation Loss (standardized): 1.5587587188158607\n",
      "Epoch: 21, Loss (standarized): 1.5419823396389167\n",
      "          Validation Loss (standardized): 1.5517721796144717\n",
      "Epoch: 26, Loss (standarized): 1.5096245372032775\n",
      "          Validation Loss (standardized): 1.5273169194516136\n",
      "Epoch: 31, Loss (standarized): 1.4708531530759674\n",
      "          Validation Loss (standardized): 1.4872147423178155\n",
      "Epoch: 36, Loss (standarized): 1.430787946454106\n",
      "          Validation Loss (standardized): 1.444277642027007\n",
      "Epoch: 41, Loss (standarized): 1.3937592419025844\n",
      "          Validation Loss (standardized): 1.4173938817069534\n",
      "Epoch: 46, Loss (standarized): 1.3644085723718138\n",
      "          Validation Loss (standardized): 1.398425677233876\n",
      "Epoch: 51, Loss (standarized): 1.3440447696701028\n",
      "          Validation Loss (standardized): 1.3807081854247318\n",
      "Epoch: 56, Loss (standarized): 1.3328997843886878\n",
      "          Validation Loss (standardized): 1.3668550393699896\n",
      "Epoch: 61, Loss (standarized): 1.3256837269010688\n",
      "          Validation Loss (standardized): 1.3637210875336558\n",
      "Epoch: 66, Loss (standarized): 1.3184957706835683\n",
      "          Validation Loss (standardized): 1.3563894003425534\n",
      "Epoch: 71, Loss (standarized): 1.310693672343001\n",
      "          Validation Loss (standardized): 1.3531795132170024\n",
      "Epoch: 76, Loss (standarized): 1.3020778035543679\n",
      "          Validation Loss (standardized): 1.3475187313620909\n",
      "Epoch: 81, Loss (standarized): 1.2918104037543932\n",
      "          Validation Loss (standardized): 1.338012531358335\n",
      "Epoch: 86, Loss (standarized): 1.2786536227718757\n",
      "          Validation Loss (standardized): 1.3260451367573065\n",
      "Epoch: 91, Loss (standarized): 1.2620017182454966\n",
      "          Validation Loss (standardized): 1.3100772786700527\n",
      "Epoch: 96, Loss (standarized): 1.2413718378900216\n",
      "          Validation Loss (standardized): 1.292050527262111\n",
      "Final epoch: 100, Final loss (standarized): 1.2218367560083112\n",
      "Epoch: 1, Loss (standarized): 1.8040705904571839\n",
      "          Validation Loss (standardized): 1.7586073427087567\n",
      "Epoch: 6, Loss (standarized): 1.617410340738425\n",
      "          Validation Loss (standardized): 1.6873615951316883\n",
      "Epoch: 11, Loss (standarized): 1.6097729109967958\n",
      "          Validation Loss (standardized): 1.5584388690500546\n",
      "Epoch: 16, Loss (standarized): 1.5857841576184768\n",
      "          Validation Loss (standardized): 1.5238548133118766\n",
      "Epoch: 21, Loss (standarized): 1.5585644450915412\n",
      "          Validation Loss (standardized): 1.5573956088993754\n",
      "Epoch: 26, Loss (standarized): 1.534799131382764\n",
      "          Validation Loss (standardized): 1.5727557513612511\n",
      "Epoch: 31, Loss (standarized): 1.502452211846089\n",
      "          Validation Loss (standardized): 1.5460681429626237\n",
      "Epoch: 36, Loss (standarized): 1.4607940364337688\n",
      "          Validation Loss (standardized): 1.4809252553989447\n",
      "Epoch: 41, Loss (standarized): 1.420652143937459\n",
      "          Validation Loss (standardized): 1.4235591369532994\n",
      "Epoch: 46, Loss (standarized): 1.3864668029715101\n",
      "          Validation Loss (standardized): 1.4090248119291677\n",
      "Epoch: 51, Loss (standarized): 1.3642959846836948\n",
      "          Validation Loss (standardized): 1.4111079342436088\n",
      "Epoch: 56, Loss (standarized): 1.3521408514909705\n",
      "          Validation Loss (standardized): 1.4001379717460625\n",
      "Epoch: 61, Loss (standarized): 1.3439896669784839\n",
      "          Validation Loss (standardized): 1.38097191791754\n",
      "Epoch: 66, Loss (standarized): 1.3381041889281098\n",
      "          Validation Loss (standardized): 1.3708607357273466\n",
      "Epoch: 71, Loss (standarized): 1.3331922834894328\n",
      "          Validation Loss (standardized): 1.3757934524551683\n",
      "Epoch: 76, Loss (standarized): 1.329262905005264\n",
      "          Validation Loss (standardized): 1.3780418847897369\n",
      "Epoch: 81, Loss (standarized): 1.325580990506644\n",
      "          Validation Loss (standardized): 1.3737956779140323\n",
      "Epoch: 86, Loss (standarized): 1.3215381341687347\n",
      "          Validation Loss (standardized): 1.3684396727010817\n",
      "Epoch: 91, Loss (standarized): 1.3168334732000784\n",
      "          Validation Loss (standardized): 1.3643774728337812\n",
      "Epoch: 96, Loss (standarized): 1.3114795788025235\n",
      "          Validation Loss (standardized): 1.358531570988383\n",
      "Final epoch: 100, Final loss (standarized): 1.3065865506046845\n",
      "Epoch: 1, Loss (standarized): 1.7537996444391082\n",
      "          Validation Loss (standardized): 1.5196264497597283\n",
      "Epoch: 6, Loss (standarized): 1.6126705851687866\n",
      "          Validation Loss (standardized): 1.6244009645307744\n",
      "Epoch: 11, Loss (standarized): 1.625103515195797\n",
      "          Validation Loss (standardized): 1.6937006888350754\n",
      "Epoch: 16, Loss (standarized): 1.6153282853858288\n",
      "          Validation Loss (standardized): 1.6398360396980498\n",
      "Epoch: 21, Loss (standarized): 1.6105792675471455\n",
      "          Validation Loss (standardized): 1.5968970142972432\n",
      "Epoch: 26, Loss (standarized): 1.612233542119942\n",
      "          Validation Loss (standardized): 1.5902923700403815\n",
      "Epoch: 31, Loss (standarized): 1.6100876160755997\n",
      "          Validation Loss (standardized): 1.6065047974827007\n",
      "Epoch: 36, Loss (standarized): 1.6102934540274219\n",
      "          Validation Loss (standardized): 1.6291089075873728\n",
      "Epoch: 41, Loss (standarized): 1.610080145159729\n",
      "          Validation Loss (standardized): 1.6199264710482457\n",
      "Epoch: 46, Loss (standarized): 1.6096405149600486\n",
      "          Validation Loss (standardized): 1.6026918821808616\n",
      "Epoch: 51, Loss (standarized): 1.6096866290033662\n",
      "          Validation Loss (standardized): 1.604880612318678\n",
      "Epoch: 56, Loss (standarized): 1.609603491848133\n",
      "          Validation Loss (standardized): 1.6157512882558258\n",
      "Epoch: 61, Loss (standarized): 1.6095323513681825\n",
      "          Validation Loss (standardized): 1.6099258309411129\n",
      "Epoch: 66, Loss (standarized): 1.6095732773980962\n",
      "          Validation Loss (standardized): 1.607846798537798\n",
      "Epoch: 71, Loss (standarized): 1.6094852947489628\n",
      "          Validation Loss (standardized): 1.611505921876397\n",
      "Epoch: 76, Loss (standarized): 1.6095437779484927\n",
      "          Validation Loss (standardized): 1.6137322014933972\n",
      "Epoch: 81, Loss (standarized): 1.6096484596855292\n",
      "          Validation Loss (standardized): 1.6182928313716334\n",
      "Epoch: 86, Loss (standarized): 1.6096352337008775\n",
      "          Validation Loss (standardized): 1.6172809923215805\n",
      "Epoch: 91, Loss (standarized): 1.6095040474400832\n",
      "          Validation Loss (standardized): 1.6157661752262211\n",
      "Epoch: 96, Loss (standarized): 1.6094937599242554\n",
      "          Validation Loss (standardized): 1.613206767257836\n",
      "Final epoch: 100, Final loss (standarized): 1.609451608249974\n",
      "Epoch: 1, Loss (standarized): 1.6460152109751758\n",
      "          Validation Loss (standardized): 1.5406661901116743\n",
      "Epoch: 6, Loss (standarized): 1.61545027328356\n",
      "          Validation Loss (standardized): 1.655988094582276\n",
      "Epoch: 11, Loss (standarized): 1.6135480779878395\n",
      "          Validation Loss (standardized): 1.6281987747824689\n",
      "Epoch: 16, Loss (standarized): 1.610460606308405\n",
      "          Validation Loss (standardized): 1.599110798600549\n",
      "Epoch: 21, Loss (standarized): 1.6102333245208051\n",
      "          Validation Loss (standardized): 1.610102698240983\n",
      "Epoch: 26, Loss (standarized): 1.6099217070597733\n",
      "          Validation Loss (standardized): 1.622123514760535\n",
      "Epoch: 31, Loss (standarized): 1.6099403129529346\n",
      "          Validation Loss (standardized): 1.6184053563163698\n",
      "Epoch: 36, Loss (standarized): 1.6097569694474219\n",
      "          Validation Loss (standardized): 1.6101699374217524\n",
      "Epoch: 41, Loss (standarized): 1.6097133786070288\n",
      "          Validation Loss (standardized): 1.6135765884328963\n",
      "Epoch: 46, Loss (standarized): 1.6096917569685179\n",
      "          Validation Loss (standardized): 1.614543398834486\n",
      "Epoch: 51, Loss (standarized): 1.6094887760148238\n",
      "          Validation Loss (standardized): 1.611507087368374\n",
      "Epoch: 56, Loss (standarized): 1.6094687972517823\n",
      "          Validation Loss (standardized): 1.6065245887369275\n",
      "Epoch: 61, Loss (standarized): 1.6098107166933593\n",
      "          Validation Loss (standardized): 1.6011086599381121\n",
      "Epoch: 66, Loss (standarized): 1.6098093984269497\n",
      "          Validation Loss (standardized): 1.6070923748723538\n",
      "Epoch: 71, Loss (standarized): 1.6096670501351247\n",
      "          Validation Loss (standardized): 1.608611420886898\n",
      "Epoch: 76, Loss (standarized): 1.609822396666638\n",
      "          Validation Loss (standardized): 1.6107133497294732\n",
      "Epoch: 81, Loss (standarized): 1.6095487273951619\n",
      "          Validation Loss (standardized): 1.6087054503313825\n",
      "Epoch: 86, Loss (standarized): 1.6094679881395177\n",
      "          Validation Loss (standardized): 1.6100832076676548\n",
      "Epoch: 91, Loss (standarized): 1.6095016570961735\n",
      "          Validation Loss (standardized): 1.607347077447557\n",
      "Epoch: 96, Loss (standarized): 1.609653957063002\n",
      "          Validation Loss (standardized): 1.6083730954525708\n",
      "Final epoch: 100, Final loss (standarized): 1.6095102769284808\n",
      "Epoch: 1, Loss (standarized): 2.011322672861445\n",
      "          Validation Loss (standardized): 1.6639000606282934\n",
      "Epoch: 6, Loss (standarized): 1.6697629444676096\n",
      "          Validation Loss (standardized): 1.5510698877692635\n",
      "Epoch: 11, Loss (standarized): 1.6020363203833932\n",
      "          Validation Loss (standardized): 1.6268692564249816\n",
      "Epoch: 16, Loss (standarized): 1.6177692695449861\n",
      "          Validation Loss (standardized): 1.677724241053928\n",
      "Epoch: 21, Loss (standarized): 1.610384450534648\n",
      "          Validation Loss (standardized): 1.64836516767099\n",
      "Epoch: 26, Loss (standarized): 1.6042814503444902\n",
      "          Validation Loss (standardized): 1.6058951961440489\n",
      "Epoch: 31, Loss (standarized): 1.606211197836088\n",
      "          Validation Loss (standardized): 1.5832789488458698\n",
      "Epoch: 36, Loss (standarized): 1.6083807862003456\n",
      "          Validation Loss (standardized): 1.5849298021950913\n",
      "Epoch: 41, Loss (standarized): 1.6083827355578364\n",
      "          Validation Loss (standardized): 1.597964518976845\n",
      "Epoch: 46, Loss (standarized): 1.6088031130988143\n",
      "          Validation Loss (standardized): 1.6092348697338767\n",
      "Epoch: 51, Loss (standarized): 1.6094610991402876\n",
      "          Validation Loss (standardized): 1.6135744766043976\n",
      "Epoch: 56, Loss (standarized): 1.6096136168634354\n",
      "          Validation Loss (standardized): 1.604388121383741\n",
      "Epoch: 61, Loss (standarized): 1.6097521825330257\n",
      "          Validation Loss (standardized): 1.6000132734089085\n",
      "Epoch: 66, Loss (standarized): 1.6095985577586651\n",
      "          Validation Loss (standardized): 1.608023054315188\n",
      "Epoch: 71, Loss (standarized): 1.6095528707944344\n",
      "          Validation Loss (standardized): 1.6152849991270672\n",
      "Epoch: 76, Loss (standarized): 1.6095736057032584\n",
      "          Validation Loss (standardized): 1.6192287381961883\n",
      "Epoch: 81, Loss (standarized): 1.6096174017150902\n",
      "          Validation Loss (standardized): 1.61621515817808\n",
      "Epoch: 86, Loss (standarized): 1.6095406385614683\n",
      "          Validation Loss (standardized): 1.6103058869886477\n",
      "Epoch: 91, Loss (standarized): 1.6095993910780309\n",
      "          Validation Loss (standardized): 1.6127151587178608\n",
      "Epoch: 96, Loss (standarized): 1.6097610114339493\n",
      "          Validation Loss (standardized): 1.6178353501872684\n",
      "Final epoch: 100, Final loss (standarized): 1.6098007090132078\n",
      "Epoch: 1, Loss (standarized): 2.136535367349408\n",
      "          Validation Loss (standardized): 2.598918469773352\n",
      "Epoch: 6, Loss (standarized): 1.7026855767511468\n",
      "          Validation Loss (standardized): 1.829837719460636\n",
      "Epoch: 11, Loss (standarized): 1.6269104661416771\n",
      "          Validation Loss (standardized): 1.5504962518091199\n",
      "Epoch: 16, Loss (standarized): 1.6372376610993933\n",
      "          Validation Loss (standardized): 1.5106701674834726\n",
      "Epoch: 21, Loss (standarized): 1.6231317714754092\n",
      "          Validation Loss (standardized): 1.5614834321664914\n",
      "Epoch: 26, Loss (standarized): 1.6138339667050083\n",
      "          Validation Loss (standardized): 1.6263034380676211\n",
      "Epoch: 31, Loss (standarized): 1.61212469692311\n",
      "          Validation Loss (standardized): 1.648457911613226\n",
      "Epoch: 36, Loss (standarized): 1.6114434747745348\n",
      "          Validation Loss (standardized): 1.6330345251755856\n",
      "Epoch: 41, Loss (standarized): 1.61098820967483\n",
      "          Validation Loss (standardized): 1.6142250261747781\n",
      "Epoch: 46, Loss (standarized): 1.6101702517023955\n",
      "          Validation Loss (standardized): 1.60967433439765\n",
      "Epoch: 51, Loss (standarized): 1.6096829436559597\n",
      "          Validation Loss (standardized): 1.610855749046375\n",
      "Epoch: 56, Loss (standarized): 1.6096426299293922\n",
      "          Validation Loss (standardized): 1.6122047118871619\n",
      "Epoch: 61, Loss (standarized): 1.6095451739811406\n",
      "          Validation Loss (standardized): 1.6120782641427118\n",
      "Epoch: 66, Loss (standarized): 1.6095430859722932\n",
      "          Validation Loss (standardized): 1.6122180910879453\n",
      "Epoch: 71, Loss (standarized): 1.6094651038904602\n",
      "          Validation Loss (standardized): 1.6104179922193844\n",
      "Epoch: 76, Loss (standarized): 1.6094797418445228\n",
      "          Validation Loss (standardized): 1.606518130244241\n",
      "Epoch: 81, Loss (standarized): 1.6094788541018188\n",
      "          Validation Loss (standardized): 1.605989746114686\n",
      "Epoch: 86, Loss (standarized): 1.6095901968313473\n",
      "          Validation Loss (standardized): 1.6092213737024388\n",
      "Epoch: 91, Loss (standarized): 1.6096640648519476\n",
      "          Validation Loss (standardized): 1.6103295055969236\n",
      "Epoch: 96, Loss (standarized): 1.6096925449351673\n",
      "          Validation Loss (standardized): 1.6058299157796774\n",
      "Final epoch: 100, Final loss (standarized): 1.6097951163556874\n",
      "Epoch: 1, Loss (standarized): 1.661583820130187\n",
      "          Validation Loss (standardized): 1.548831339245469\n",
      "Epoch: 6, Loss (standarized): 1.6071712963847333\n",
      "          Validation Loss (standardized): 1.668028515156286\n",
      "Epoch: 11, Loss (standarized): 1.5834476152912424\n",
      "          Validation Loss (standardized): 1.5983812473034282\n",
      "Epoch: 16, Loss (standarized): 1.5668786473387073\n",
      "          Validation Loss (standardized): 1.53852408205499\n",
      "Epoch: 21, Loss (standarized): 1.5393186086943969\n",
      "          Validation Loss (standardized): 1.5562260630157048\n",
      "Epoch: 26, Loss (standarized): 1.5088508818464321\n",
      "          Validation Loss (standardized): 1.5509948300786032\n",
      "Epoch: 31, Loss (standarized): 1.4688061302232307\n",
      "          Validation Loss (standardized): 1.4966804546867556\n",
      "Epoch: 36, Loss (standarized): 1.4275257130022363\n",
      "          Validation Loss (standardized): 1.4582809356028374\n",
      "Epoch: 41, Loss (standarized): 1.390368848894593\n",
      "          Validation Loss (standardized): 1.4420344034039831\n",
      "Epoch: 46, Loss (standarized): 1.3638756103247358\n",
      "          Validation Loss (standardized): 1.4086246103736149\n",
      "Epoch: 51, Loss (standarized): 1.34826922176534\n",
      "          Validation Loss (standardized): 1.3859612975073448\n",
      "Epoch: 56, Loss (standarized): 1.3402032362063467\n",
      "          Validation Loss (standardized): 1.3817609312505088\n",
      "Epoch: 61, Loss (standarized): 1.3363755383839864\n",
      "          Validation Loss (standardized): 1.3737129142362126\n",
      "Epoch: 66, Loss (standarized): 1.3344189883793747\n",
      "          Validation Loss (standardized): 1.3689458503048466\n",
      "Epoch: 71, Loss (standarized): 1.333076678603558\n",
      "          Validation Loss (standardized): 1.3706668050720945\n",
      "Epoch: 76, Loss (standarized): 1.3320797022679227\n",
      "          Validation Loss (standardized): 1.3692017852864449\n",
      "Epoch: 81, Loss (standarized): 1.3310696755695222\n",
      "          Validation Loss (standardized): 1.3682263231630216\n",
      "Epoch: 86, Loss (standarized): 1.3295900198083412\n",
      "          Validation Loss (standardized): 1.3689964573099591\n",
      "Epoch: 91, Loss (standarized): 1.3274520650102997\n",
      "          Validation Loss (standardized): 1.3629301605116513\n",
      "Epoch: 96, Loss (standarized): 1.3246307805616024\n",
      "          Validation Loss (standardized): 1.3598569219519667\n",
      "Final epoch: 100, Final loss (standarized): 1.3217657514924541\n",
      "Epoch: 1, Loss (standarized): 1.7965391610312784\n",
      "          Validation Loss (standardized): 1.57808967395299\n",
      "Epoch: 6, Loss (standarized): 1.6193616121988674\n",
      "          Validation Loss (standardized): 1.6479025171176553\n",
      "Epoch: 11, Loss (standarized): 1.620580503447396\n",
      "          Validation Loss (standardized): 1.6853825115115546\n",
      "Epoch: 16, Loss (standarized): 1.6044156080673013\n",
      "          Validation Loss (standardized): 1.626685938812495\n",
      "Epoch: 21, Loss (standarized): 1.5923131163888524\n",
      "          Validation Loss (standardized): 1.5740510146654205\n",
      "Epoch: 26, Loss (standarized): 1.591713373981982\n",
      "          Validation Loss (standardized): 1.5768461793906432\n",
      "Epoch: 31, Loss (standarized): 1.5850603784431478\n",
      "          Validation Loss (standardized): 1.591080335243846\n",
      "Epoch: 36, Loss (standarized): 1.5812588436011612\n",
      "          Validation Loss (standardized): 1.5958391868924786\n",
      "Epoch: 41, Loss (standarized): 1.577175774168436\n",
      "          Validation Loss (standardized): 1.5944841716531999\n",
      "Epoch: 46, Loss (standarized): 1.5717400316556145\n",
      "          Validation Loss (standardized): 1.5826615937665907\n",
      "Epoch: 51, Loss (standarized): 1.5658064515703436\n",
      "          Validation Loss (standardized): 1.5682884369658123\n",
      "Epoch: 56, Loss (standarized): 1.5577169817348755\n",
      "          Validation Loss (standardized): 1.5697773793195178\n",
      "Epoch: 61, Loss (standarized): 1.547646250919754\n",
      "          Validation Loss (standardized): 1.568523912605335\n",
      "Epoch: 66, Loss (standarized): 1.534458428981511\n",
      "          Validation Loss (standardized): 1.5524323148737869\n",
      "Epoch: 71, Loss (standarized): 1.5178567632842646\n",
      "          Validation Loss (standardized): 1.5364467109213642\n",
      "Epoch: 76, Loss (standarized): 1.4978101130444719\n",
      "          Validation Loss (standardized): 1.5218220792586208\n",
      "Epoch: 81, Loss (standarized): 1.475280861184616\n",
      "          Validation Loss (standardized): 1.5052135390435106\n",
      "Epoch: 86, Loss (standarized): 1.452448097582019\n",
      "          Validation Loss (standardized): 1.485860730647864\n",
      "Epoch: 91, Loss (standarized): 1.4321139860880863\n",
      "          Validation Loss (standardized): 1.4685010629651667\n",
      "Epoch: 96, Loss (standarized): 1.41640229577793\n",
      "          Validation Loss (standardized): 1.4547941032453577\n",
      "Final epoch: 100, Final loss (standarized): 1.407662616070595\n",
      "Epoch: 1, Loss (standarized): 1.6560011111709048\n",
      "          Validation Loss (standardized): 1.648568461053829\n",
      "Epoch: 6, Loss (standarized): 1.6024619346839932\n",
      "          Validation Loss (standardized): 1.5672732911091944\n",
      "Epoch: 11, Loss (standarized): 1.5728159685269378\n",
      "          Validation Loss (standardized): 1.5633608114132738\n",
      "Epoch: 16, Loss (standarized): 1.5480306212294557\n",
      "          Validation Loss (standardized): 1.569945921756519\n",
      "Epoch: 21, Loss (standarized): 1.5150849652927565\n",
      "          Validation Loss (standardized): 1.5127551421004544\n",
      "Epoch: 26, Loss (standarized): 1.4782121479605093\n",
      "          Validation Loss (standardized): 1.4769668572613568\n",
      "Epoch: 31, Loss (standarized): 1.4371435838345792\n",
      "          Validation Loss (standardized): 1.4593340647589503\n",
      "Epoch: 36, Loss (standarized): 1.4010016753163066\n",
      "          Validation Loss (standardized): 1.4293764482582725\n",
      "Epoch: 41, Loss (standarized): 1.3743860921163267\n",
      "          Validation Loss (standardized): 1.3984210178380472\n",
      "Epoch: 46, Loss (standarized): 1.3576050015609709\n",
      "          Validation Loss (standardized): 1.389485728619947\n",
      "Epoch: 51, Loss (standarized): 1.3478867585619543\n",
      "          Validation Loss (standardized): 1.3852084331285508\n",
      "Epoch: 56, Loss (standarized): 1.3424314770138184\n",
      "          Validation Loss (standardized): 1.3738904839913246\n",
      "Epoch: 61, Loss (standarized): 1.3398452429541134\n",
      "          Validation Loss (standardized): 1.3788288623694003\n",
      "Epoch: 66, Loss (standarized): 1.3387651411025545\n",
      "          Validation Loss (standardized): 1.3793264711039102\n",
      "Epoch: 71, Loss (standarized): 1.338119453360893\n",
      "          Validation Loss (standardized): 1.379054935604296\n",
      "Epoch: 76, Loss (standarized): 1.3370631299539084\n",
      "          Validation Loss (standardized): 1.3788200224949045\n",
      "Epoch: 81, Loss (standarized): 1.3353986239769304\n",
      "          Validation Loss (standardized): 1.3768427369428768\n",
      "Epoch: 86, Loss (standarized): 1.3333172951171575\n",
      "          Validation Loss (standardized): 1.37300194013108\n",
      "Epoch: 91, Loss (standarized): 1.3309456998939384\n",
      "          Validation Loss (standardized): 1.3704425185178561\n",
      "Epoch: 96, Loss (standarized): 1.3283625063838533\n",
      "          Validation Loss (standardized): 1.3668687973572746\n",
      "Final epoch: 100, Final loss (standarized): 1.3260964352661915\n",
      "Epoch: 1, Loss (standarized): 1.6299347623290945\n",
      "          Validation Loss (standardized): 1.5943461468222146\n",
      "Epoch: 6, Loss (standarized): 1.5952584472444615\n",
      "          Validation Loss (standardized): 1.609936762715593\n",
      "Epoch: 11, Loss (standarized): 1.5676284115351928\n",
      "          Validation Loss (standardized): 1.5687193955350627\n",
      "Epoch: 16, Loss (standarized): 1.5399217077646208\n",
      "          Validation Loss (standardized): 1.5470052285031788\n",
      "Epoch: 21, Loss (standarized): 1.5032064602459172\n",
      "          Validation Loss (standardized): 1.529617438849749\n",
      "Epoch: 26, Loss (standarized): 1.4580340038565895\n",
      "          Validation Loss (standardized): 1.4827881949587411\n",
      "Epoch: 31, Loss (standarized): 1.4145215348927618\n",
      "          Validation Loss (standardized): 1.4409734223931225\n",
      "Epoch: 36, Loss (standarized): 1.3794265161358936\n",
      "          Validation Loss (standardized): 1.4174226183645955\n",
      "Epoch: 41, Loss (standarized): 1.356905115992192\n",
      "          Validation Loss (standardized): 1.3919605800037442\n",
      "Epoch: 46, Loss (standarized): 1.344338148299323\n",
      "          Validation Loss (standardized): 1.377122171349751\n",
      "Epoch: 51, Loss (standarized): 1.3379074058172995\n",
      "          Validation Loss (standardized): 1.3764283523904095\n",
      "Epoch: 56, Loss (standarized): 1.334953682709134\n",
      "          Validation Loss (standardized): 1.367759049354587\n",
      "Epoch: 61, Loss (standarized): 1.333618388350731\n",
      "          Validation Loss (standardized): 1.3681709372151603\n",
      "Epoch: 66, Loss (standarized): 1.3326739493689879\n",
      "          Validation Loss (standardized): 1.3707084682898243\n",
      "Epoch: 71, Loss (standarized): 1.3315129021767484\n",
      "          Validation Loss (standardized): 1.368049247849378\n",
      "Epoch: 76, Loss (standarized): 1.3300295688327881\n",
      "          Validation Loss (standardized): 1.3680983207368724\n",
      "Epoch: 81, Loss (standarized): 1.3282835831493782\n",
      "          Validation Loss (standardized): 1.3664544744782867\n",
      "Epoch: 86, Loss (standarized): 1.3260985804240726\n",
      "          Validation Loss (standardized): 1.362345670525629\n",
      "Epoch: 91, Loss (standarized): 1.3235186164997714\n",
      "          Validation Loss (standardized): 1.3581935742658606\n",
      "Epoch: 96, Loss (standarized): 1.3204998186978336\n",
      "          Validation Loss (standardized): 1.3544227017201023\n",
      "Final epoch: 100, Final loss (standarized): 1.3177675972554743\n",
      "Epoch: 1, Loss (standarized): 1.7196025005758395\n",
      "          Validation Loss (standardized): 1.651995619274041\n",
      "Epoch: 6, Loss (standarized): 1.6026005545811204\n",
      "          Validation Loss (standardized): 1.6246849386323592\n",
      "Epoch: 11, Loss (standarized): 1.5964100601948377\n",
      "          Validation Loss (standardized): 1.6293226830054215\n",
      "Epoch: 16, Loss (standarized): 1.557829289884508\n",
      "          Validation Loss (standardized): 1.570586044980555\n",
      "Epoch: 21, Loss (standarized): 1.5303784290741946\n",
      "          Validation Loss (standardized): 1.5351110708101874\n",
      "Epoch: 26, Loss (standarized): 1.4844647413327487\n",
      "          Validation Loss (standardized): 1.5115119753810455\n",
      "Epoch: 31, Loss (standarized): 1.4375400895398815\n",
      "          Validation Loss (standardized): 1.4878804709796354\n",
      "Epoch: 36, Loss (standarized): 1.3973450092137125\n",
      "          Validation Loss (standardized): 1.4540244564920521\n",
      "Epoch: 41, Loss (standarized): 1.36928314916974\n",
      "          Validation Loss (standardized): 1.4137627786831\n",
      "Epoch: 46, Loss (standarized): 1.3532936458528446\n",
      "          Validation Loss (standardized): 1.3942455684897195\n",
      "Epoch: 51, Loss (standarized): 1.3421973540559538\n",
      "          Validation Loss (standardized): 1.3789736967245092\n",
      "Epoch: 56, Loss (standarized): 1.3339500237253483\n",
      "          Validation Loss (standardized): 1.3697342677261712\n",
      "Epoch: 61, Loss (standarized): 1.327140655869676\n",
      "          Validation Loss (standardized): 1.3625642625896375\n",
      "Epoch: 66, Loss (standarized): 1.3206687689134435\n",
      "          Validation Loss (standardized): 1.3620758400235877\n",
      "Epoch: 71, Loss (standarized): 1.3135117539815693\n",
      "          Validation Loss (standardized): 1.3583188554822323\n",
      "Epoch: 76, Loss (standarized): 1.304979497237393\n",
      "          Validation Loss (standardized): 1.3493118607902983\n",
      "Epoch: 81, Loss (standarized): 1.2949829429493445\n",
      "          Validation Loss (standardized): 1.3402393189544617\n",
      "Epoch: 86, Loss (standarized): 1.2831630155977791\n",
      "          Validation Loss (standardized): 1.3303623382911798\n",
      "Epoch: 91, Loss (standarized): 1.2691431185642577\n",
      "          Validation Loss (standardized): 1.319169738909509\n",
      "Epoch: 96, Loss (standarized): 1.252857311146113\n",
      "          Validation Loss (standardized): 1.3076218915505855\n",
      "Final epoch: 100, Final loss (standarized): 1.2381226215833532\n",
      "Epoch: 1, Loss (standarized): 1.6630760389257568\n",
      "          Validation Loss (standardized): 1.7458050302206376\n",
      "Epoch: 6, Loss (standarized): 1.6001561761761776\n",
      "          Validation Loss (standardized): 1.511656816445896\n",
      "Epoch: 11, Loss (standarized): 1.582110344601886\n",
      "          Validation Loss (standardized): 1.5689374214168115\n",
      "Epoch: 16, Loss (standarized): 1.5695867870179359\n",
      "          Validation Loss (standardized): 1.6201914812768816\n",
      "Epoch: 21, Loss (standarized): 1.5492138683127796\n",
      "          Validation Loss (standardized): 1.5640363903007177\n",
      "Epoch: 26, Loss (standarized): 1.5238667528381984\n",
      "          Validation Loss (standardized): 1.5116281050030829\n",
      "Epoch: 31, Loss (standarized): 1.4883919773447787\n",
      "          Validation Loss (standardized): 1.5011426037723439\n",
      "Epoch: 36, Loss (standarized): 1.4481407045786636\n",
      "          Validation Loss (standardized): 1.4883155390063907\n",
      "Epoch: 41, Loss (standarized): 1.4098533413412906\n",
      "          Validation Loss (standardized): 1.4408472257781895\n",
      "Epoch: 46, Loss (standarized): 1.3841330730701242\n",
      "          Validation Loss (standardized): 1.4093957045320091\n",
      "Epoch: 51, Loss (standarized): 1.3711575433755727\n",
      "          Validation Loss (standardized): 1.4140449196787486\n",
      "Epoch: 56, Loss (standarized): 1.3675926808882781\n",
      "          Validation Loss (standardized): 1.4142469156810187\n",
      "Epoch: 61, Loss (standarized): 1.368844706426883\n",
      "          Validation Loss (standardized): 1.4070885697435895\n",
      "Epoch: 66, Loss (standarized): 1.3714182469006102\n",
      "          Validation Loss (standardized): 1.4128327816686865\n",
      "Epoch: 71, Loss (standarized): 1.3724105098886965\n",
      "          Validation Loss (standardized): 1.4170697779137023\n",
      "Epoch: 76, Loss (standarized): 1.371178037424341\n",
      "          Validation Loss (standardized): 1.4118388393511045\n",
      "Epoch: 81, Loss (standarized): 1.3694461443321015\n",
      "          Validation Loss (standardized): 1.4091911534622945\n",
      "Epoch: 86, Loss (standarized): 1.3685209664499167\n",
      "          Validation Loss (standardized): 1.411062680739294\n",
      "Epoch: 91, Loss (standarized): 1.3685655640630012\n",
      "          Validation Loss (standardized): 1.4099388680265947\n",
      "Epoch: 96, Loss (standarized): 1.369103132336622\n",
      "          Validation Loss (standardized): 1.4097662724988158\n",
      "Final epoch: 100, Final loss (standarized): 1.3694492244252456\n",
      "Epoch: 1, Loss (standarized): 1.7142592181393914\n",
      "          Validation Loss (standardized): 1.4919536974635017\n",
      "Epoch: 6, Loss (standarized): 1.616062039751937\n",
      "          Validation Loss (standardized): 1.7361441146087508\n",
      "Epoch: 11, Loss (standarized): 1.5946038516191943\n",
      "          Validation Loss (standardized): 1.6238021342281872\n",
      "Epoch: 16, Loss (standarized): 1.574673388927651\n",
      "          Validation Loss (standardized): 1.5389418884628012\n",
      "Epoch: 21, Loss (standarized): 1.5448872686168555\n",
      "          Validation Loss (standardized): 1.5549114620727351\n",
      "Epoch: 26, Loss (standarized): 1.509452738086876\n",
      "          Validation Loss (standardized): 1.5472330660139824\n",
      "Epoch: 31, Loss (standarized): 1.4610368119594357\n",
      "          Validation Loss (standardized): 1.4884212720472743\n",
      "Epoch: 36, Loss (standarized): 1.414241609795589\n",
      "          Validation Loss (standardized): 1.4450583485774735\n",
      "Epoch: 41, Loss (standarized): 1.3739230218745089\n",
      "          Validation Loss (standardized): 1.4239535413520856\n",
      "Epoch: 46, Loss (standarized): 1.349243907675872\n",
      "          Validation Loss (standardized): 1.388507281232474\n",
      "Epoch: 51, Loss (standarized): 1.336958291405685\n",
      "          Validation Loss (standardized): 1.3690592178987253\n",
      "Epoch: 56, Loss (standarized): 1.330724492091891\n",
      "          Validation Loss (standardized): 1.3740728193060425\n",
      "Epoch: 61, Loss (standarized): 1.3265171961338853\n",
      "          Validation Loss (standardized): 1.3684194049357594\n",
      "Epoch: 66, Loss (standarized): 1.3228491881733029\n",
      "          Validation Loss (standardized): 1.3566050301949621\n",
      "Epoch: 71, Loss (standarized): 1.319617318683263\n",
      "          Validation Loss (standardized): 1.3596336381930345\n",
      "Epoch: 76, Loss (standarized): 1.3167785464299435\n",
      "          Validation Loss (standardized): 1.3607068705138514\n",
      "Epoch: 81, Loss (standarized): 1.313630922589486\n",
      "          Validation Loss (standardized): 1.3554406135950194\n",
      "Epoch: 86, Loss (standarized): 1.3096570893079587\n",
      "          Validation Loss (standardized): 1.3525942313368824\n",
      "Epoch: 91, Loss (standarized): 1.3048940223301397\n",
      "          Validation Loss (standardized): 1.3470110226425591\n",
      "Epoch: 96, Loss (standarized): 1.2993436489535228\n",
      "          Validation Loss (standardized): 1.3400287438761471\n",
      "Final epoch: 100, Final loss (standarized): 1.2941756997152578\n",
      "Epoch: 1, Loss (standarized): 1.8207048962773746\n",
      "          Validation Loss (standardized): 1.718248854934138\n",
      "Epoch: 6, Loss (standarized): 1.6046225073402618\n",
      "          Validation Loss (standardized): 1.601133201037571\n",
      "Epoch: 11, Loss (standarized): 1.610928626979388\n",
      "          Validation Loss (standardized): 1.6344772548772262\n",
      "Epoch: 16, Loss (standarized): 1.5638332051882549\n",
      "          Validation Loss (standardized): 1.616984117931972\n",
      "Epoch: 21, Loss (standarized): 1.533348001810446\n",
      "          Validation Loss (standardized): 1.5606144170957017\n",
      "Epoch: 26, Loss (standarized): 1.4931162492586685\n",
      "          Validation Loss (standardized): 1.4852973804012888\n",
      "Epoch: 31, Loss (standarized): 1.4477508188730723\n",
      "          Validation Loss (standardized): 1.4462228752165525\n",
      "Epoch: 36, Loss (standarized): 1.406761031603977\n",
      "          Validation Loss (standardized): 1.438888856809122\n",
      "Epoch: 41, Loss (standarized): 1.3754783106836945\n",
      "          Validation Loss (standardized): 1.425318496956501\n",
      "Epoch: 46, Loss (standarized): 1.355960862759794\n",
      "          Validation Loss (standardized): 1.3932874798322261\n",
      "Epoch: 51, Loss (standarized): 1.3457929540350144\n",
      "          Validation Loss (standardized): 1.3644383230586963\n",
      "Epoch: 56, Loss (standarized): 1.3400594827614893\n",
      "          Validation Loss (standardized): 1.357835970685995\n",
      "Epoch: 61, Loss (standarized): 1.3352798555650112\n",
      "          Validation Loss (standardized): 1.3648173874333391\n",
      "Epoch: 66, Loss (standarized): 1.3304891423040812\n",
      "          Validation Loss (standardized): 1.3634269479330328\n",
      "Epoch: 71, Loss (standarized): 1.3258392487550896\n",
      "          Validation Loss (standardized): 1.355187117263777\n",
      "Epoch: 76, Loss (standarized): 1.3215481617360194\n",
      "          Validation Loss (standardized): 1.3530144962041675\n",
      "Epoch: 81, Loss (standarized): 1.3169947792659442\n",
      "          Validation Loss (standardized): 1.3544964572354272\n",
      "Epoch: 86, Loss (standarized): 1.3116195273037687\n",
      "          Validation Loss (standardized): 1.3503872078423464\n",
      "Epoch: 91, Loss (standarized): 1.3050524946338096\n",
      "          Validation Loss (standardized): 1.3408106696307658\n",
      "Epoch: 96, Loss (standarized): 1.2970665743437282\n",
      "          Validation Loss (standardized): 1.3315233305819651\n",
      "Final epoch: 100, Final loss (standarized): 1.28938577626538\n",
      "Epoch: 1, Loss (standarized): 1.6565643454395127\n",
      "Epoch: 6, Loss (standarized): 1.4066307274160217\n",
      "Epoch: 11, Loss (standarized): 1.3532720807616943\n",
      "Epoch: 16, Loss (standarized): 1.3264175304067185\n",
      "Epoch: 21, Loss (standarized): 1.3011723489400502\n",
      "Epoch: 26, Loss (standarized): 1.265747150490934\n",
      "Epoch: 31, Loss (standarized): 1.225325643905128\n",
      "Epoch: 36, Loss (standarized): 1.174859307232476\n",
      "Epoch: 41, Loss (standarized): 1.1144827490240625\n",
      "Epoch: 46, Loss (standarized): 1.0439458700125686\n",
      "Epoch: 51, Loss (standarized): 0.9687124838381255\n",
      "Epoch: 56, Loss (standarized): 0.8953733108625496\n",
      "Epoch: 61, Loss (standarized): 0.8267623189544893\n",
      "Epoch: 66, Loss (standarized): 0.7649312490228541\n",
      "Epoch: 71, Loss (standarized): 0.7106447571215277\n",
      "Epoch: 76, Loss (standarized): 0.6620392703320545\n",
      "Epoch: 81, Loss (standarized): 0.616464811606247\n",
      "Epoch: 86, Loss (standarized): 0.5734386092817076\n",
      "Epoch: 91, Loss (standarized): 0.5333555187032282\n",
      "Epoch: 96, Loss (standarized): 0.49666595143533515\n",
      "Final epoch: 100, Final loss (standarized): 0.46931854756333785\n",
      "Epoch: 1, Loss (standarized): 1.5143591454787788\n",
      "Epoch: 6, Loss (standarized): 1.3632825168917333\n",
      "Epoch: 11, Loss (standarized): 1.3369461498788775\n",
      "Epoch: 16, Loss (standarized): 1.3209383703277076\n",
      "Epoch: 21, Loss (standarized): 1.3134093535521587\n",
      "Epoch: 26, Loss (standarized): 1.3027951638555875\n",
      "Epoch: 31, Loss (standarized): 1.288684176423735\n",
      "Epoch: 36, Loss (standarized): 1.2728633174029529\n",
      "Epoch: 41, Loss (standarized): 1.2518895062257385\n",
      "Epoch: 46, Loss (standarized): 1.2234730029971956\n",
      "Epoch: 51, Loss (standarized): 1.1862589131292227\n",
      "Epoch: 56, Loss (standarized): 1.1395112139744328\n",
      "Epoch: 61, Loss (standarized): 1.0864192349313004\n",
      "Epoch: 66, Loss (standarized): 1.0305189426623087\n",
      "Epoch: 71, Loss (standarized): 0.9741177260585464\n",
      "Epoch: 76, Loss (standarized): 0.9173953173010907\n",
      "Epoch: 81, Loss (standarized): 0.8597917076519775\n",
      "Epoch: 86, Loss (standarized): 0.8021486061416779\n",
      "Epoch: 91, Loss (standarized): 0.7466369578204405\n",
      "Epoch: 96, Loss (standarized): 0.6948379002096765\n",
      "Final epoch: 100, Final loss (standarized): 0.6569314629325647\n",
      "Epoch: 1, Loss (standarized): 1.716350755155032\n",
      "Epoch: 6, Loss (standarized): 1.415604784388409\n",
      "Epoch: 11, Loss (standarized): 1.3385897298346094\n",
      "Epoch: 16, Loss (standarized): 1.3092776932524208\n",
      "Epoch: 21, Loss (standarized): 1.275701225983616\n",
      "Epoch: 26, Loss (standarized): 1.2359932308443655\n",
      "Epoch: 31, Loss (standarized): 1.183596921628798\n",
      "Epoch: 36, Loss (standarized): 1.1271055398989998\n",
      "Epoch: 41, Loss (standarized): 1.0707279460400732\n",
      "Epoch: 46, Loss (standarized): 1.0191084474832297\n",
      "Epoch: 51, Loss (standarized): 0.9727051748877612\n",
      "Epoch: 56, Loss (standarized): 0.9276400681765955\n",
      "Epoch: 61, Loss (standarized): 0.8813333229801722\n",
      "Epoch: 66, Loss (standarized): 0.8326847405473944\n",
      "Epoch: 71, Loss (standarized): 0.7818580333181652\n",
      "Epoch: 76, Loss (standarized): 0.7301014036114717\n",
      "Epoch: 81, Loss (standarized): 0.6803341458981312\n",
      "Epoch: 86, Loss (standarized): 0.6343191577740587\n",
      "Epoch: 91, Loss (standarized): 0.5922600856170859\n",
      "Epoch: 96, Loss (standarized): 0.5540632090051233\n",
      "Final epoch: 100, Final loss (standarized): 0.5261062792821342\n",
      "Epoch: 1, Loss (standarized): 1.9100653544394561\n",
      "Epoch: 6, Loss (standarized): 1.437328681815672\n",
      "Epoch: 11, Loss (standarized): 1.3557668530549334\n",
      "Epoch: 16, Loss (standarized): 1.3333275770248845\n",
      "Epoch: 21, Loss (standarized): 1.312929687287233\n",
      "Epoch: 26, Loss (standarized): 1.2905255033816372\n",
      "Epoch: 31, Loss (standarized): 1.2636437755095984\n",
      "Epoch: 36, Loss (standarized): 1.2231322476558588\n",
      "Epoch: 41, Loss (standarized): 1.1734865736492677\n",
      "Epoch: 46, Loss (standarized): 1.1145958560106788\n",
      "Epoch: 51, Loss (standarized): 1.0518007958429967\n",
      "Epoch: 56, Loss (standarized): 0.9874547956297235\n",
      "Epoch: 61, Loss (standarized): 0.9218867498948691\n",
      "Epoch: 66, Loss (standarized): 0.8588279915422384\n",
      "Epoch: 71, Loss (standarized): 0.7994950166904486\n",
      "Epoch: 76, Loss (standarized): 0.7442883689783709\n",
      "Epoch: 81, Loss (standarized): 0.6931314097693871\n",
      "Epoch: 86, Loss (standarized): 0.645566836579273\n",
      "Epoch: 91, Loss (standarized): 0.6010225954442568\n",
      "Epoch: 96, Loss (standarized): 0.5598494167909674\n",
      "Final epoch: 100, Final loss (standarized): 0.5301410248764189\n",
      "Epoch: 1, Loss (standarized): 1.835618806773893\n",
      "Epoch: 6, Loss (standarized): 1.4571216043675241\n",
      "Epoch: 11, Loss (standarized): 1.3733265330076956\n",
      "Epoch: 16, Loss (standarized): 1.3525923924761576\n",
      "Epoch: 21, Loss (standarized): 1.346949980934575\n",
      "Epoch: 26, Loss (standarized): 1.3488896366866197\n",
      "Epoch: 31, Loss (standarized): 1.3519003262734253\n",
      "Epoch: 36, Loss (standarized): 1.354583928000897\n",
      "Epoch: 41, Loss (standarized): 1.3556026301247834\n",
      "Epoch: 46, Loss (standarized): 1.3553588627490967\n",
      "Epoch: 51, Loss (standarized): 1.3548328246759411\n",
      "Epoch: 56, Loss (standarized): 1.352893081144166\n",
      "Epoch: 61, Loss (standarized): 1.349533255169876\n",
      "Epoch: 66, Loss (standarized): 1.3461213941046393\n",
      "Epoch: 71, Loss (standarized): 1.3405089577571316\n",
      "Epoch: 76, Loss (standarized): 1.3333585244928463\n",
      "Epoch: 81, Loss (standarized): 1.3256611248898407\n",
      "Epoch: 86, Loss (standarized): 1.3176995996891492\n",
      "Epoch: 91, Loss (standarized): 1.3101877570952305\n",
      "Epoch: 96, Loss (standarized): 1.3026912223872835\n",
      "Final epoch: 100, Final loss (standarized): 1.2963694194424482\n",
      "Epoch: 1, Loss (standarized): 1.734042565696095\n",
      "Epoch: 6, Loss (standarized): 1.44608562065402\n",
      "Epoch: 11, Loss (standarized): 1.385276444474147\n",
      "Epoch: 16, Loss (standarized): 1.3648123179547864\n",
      "Epoch: 21, Loss (standarized): 1.3593945279305404\n",
      "Epoch: 26, Loss (standarized): 1.3581934101700042\n",
      "Epoch: 31, Loss (standarized): 1.3583037165704592\n",
      "Epoch: 36, Loss (standarized): 1.3595020166270004\n",
      "Epoch: 41, Loss (standarized): 1.3598654843798754\n",
      "Epoch: 46, Loss (standarized): 1.3575260396730728\n",
      "Epoch: 51, Loss (standarized): 1.3542875548455635\n",
      "Epoch: 56, Loss (standarized): 1.350549915951574\n",
      "Epoch: 61, Loss (standarized): 1.3461139072108965\n",
      "Epoch: 66, Loss (standarized): 1.340410041039717\n",
      "Epoch: 71, Loss (standarized): 1.335273337269581\n",
      "Epoch: 76, Loss (standarized): 1.330225163906462\n",
      "Epoch: 81, Loss (standarized): 1.3247794992389472\n",
      "Epoch: 86, Loss (standarized): 1.3192009900278727\n",
      "Epoch: 91, Loss (standarized): 1.3135709989356987\n",
      "Epoch: 96, Loss (standarized): 1.3073829551745269\n",
      "Final epoch: 100, Final loss (standarized): 1.3020949599171001\n",
      "Epoch: 1, Loss (standarized): 1.7494552664013456\n",
      "Epoch: 6, Loss (standarized): 1.491319225071996\n",
      "Epoch: 11, Loss (standarized): 1.391881216690735\n",
      "Epoch: 16, Loss (standarized): 1.3571179463101726\n",
      "Epoch: 21, Loss (standarized): 1.3478108520698675\n",
      "Epoch: 26, Loss (standarized): 1.3491338861904965\n",
      "Epoch: 31, Loss (standarized): 1.3507776911229694\n",
      "Epoch: 36, Loss (standarized): 1.3511362185891373\n",
      "Epoch: 41, Loss (standarized): 1.351979090748009\n",
      "Epoch: 46, Loss (standarized): 1.349823905377334\n",
      "Epoch: 51, Loss (standarized): 1.34657945535897\n",
      "Epoch: 56, Loss (standarized): 1.3415938509103893\n",
      "Epoch: 61, Loss (standarized): 1.3358921481118669\n",
      "Epoch: 66, Loss (standarized): 1.3293435867228982\n",
      "Epoch: 71, Loss (standarized): 1.3224946532367021\n",
      "Epoch: 76, Loss (standarized): 1.3155264422706179\n",
      "Epoch: 81, Loss (standarized): 1.3088516801784693\n",
      "Epoch: 86, Loss (standarized): 1.3012468129192007\n",
      "Epoch: 91, Loss (standarized): 1.29409210536548\n",
      "Epoch: 96, Loss (standarized): 1.2866119527715434\n",
      "Final epoch: 100, Final loss (standarized): 1.2808808617298286\n",
      "Epoch: 1, Loss (standarized): 1.5792506560794708\n",
      "Epoch: 6, Loss (standarized): 1.3940164003188107\n",
      "Epoch: 11, Loss (standarized): 1.3591936004836294\n",
      "Epoch: 16, Loss (standarized): 1.3512185959831424\n",
      "Epoch: 21, Loss (standarized): 1.3494947913818758\n",
      "Epoch: 26, Loss (standarized): 1.3455760496131393\n",
      "Epoch: 31, Loss (standarized): 1.342757965597807\n",
      "Epoch: 36, Loss (standarized): 1.3402853070172602\n",
      "Epoch: 41, Loss (standarized): 1.3354957051262033\n",
      "Epoch: 46, Loss (standarized): 1.3274845732527647\n",
      "Epoch: 51, Loss (standarized): 1.319901916112541\n",
      "Epoch: 56, Loss (standarized): 1.3120533079022039\n",
      "Epoch: 61, Loss (standarized): 1.3034610797837975\n",
      "Epoch: 66, Loss (standarized): 1.2944319235809991\n",
      "Epoch: 71, Loss (standarized): 1.2852420122755677\n",
      "Epoch: 76, Loss (standarized): 1.2769109043601274\n",
      "Epoch: 81, Loss (standarized): 1.2682162084406747\n",
      "Epoch: 86, Loss (standarized): 1.2592522628877643\n",
      "Epoch: 91, Loss (standarized): 1.2504776561296942\n",
      "Epoch: 96, Loss (standarized): 1.242599513362458\n",
      "Final epoch: 100, Final loss (standarized): 1.2362550604907578\n",
      "Epoch: 1, Loss (standarized): 1.7758454122752565\n",
      "Epoch: 6, Loss (standarized): 1.431194506655886\n",
      "Epoch: 11, Loss (standarized): 1.3497610125198292\n",
      "Epoch: 16, Loss (standarized): 1.3108570836593265\n",
      "Epoch: 21, Loss (standarized): 1.2939190220410999\n",
      "Epoch: 26, Loss (standarized): 1.272649933256245\n",
      "Epoch: 31, Loss (standarized): 1.23971347478545\n",
      "Epoch: 36, Loss (standarized): 1.202017113177333\n",
      "Epoch: 41, Loss (standarized): 1.1525031600712035\n",
      "Epoch: 46, Loss (standarized): 1.092356010735268\n",
      "Epoch: 51, Loss (standarized): 1.026317210178475\n",
      "Epoch: 56, Loss (standarized): 0.9620292968623523\n",
      "Epoch: 61, Loss (standarized): 0.9033779172343189\n",
      "Epoch: 66, Loss (standarized): 0.8486470085530428\n",
      "Epoch: 71, Loss (standarized): 0.7960936314648864\n",
      "Epoch: 76, Loss (standarized): 0.74538263041942\n",
      "Epoch: 81, Loss (standarized): 0.6972792052765255\n",
      "Epoch: 86, Loss (standarized): 0.6522284263749479\n",
      "Epoch: 91, Loss (standarized): 0.6098684551908273\n",
      "Epoch: 96, Loss (standarized): 0.5707219659224712\n",
      "Final epoch: 100, Final loss (standarized): 0.5424601043685162\n",
      "Epoch: 1, Loss (standarized): 1.6732405012905935\n",
      "Epoch: 6, Loss (standarized): 1.4017914511715412\n",
      "Epoch: 11, Loss (standarized): 1.3402667166764652\n",
      "Epoch: 16, Loss (standarized): 1.3257004371207433\n",
      "Epoch: 21, Loss (standarized): 1.313117727457409\n",
      "Epoch: 26, Loss (standarized): 1.3008608298104198\n",
      "Epoch: 31, Loss (standarized): 1.2898651516587818\n",
      "Epoch: 36, Loss (standarized): 1.277425298034434\n",
      "Epoch: 41, Loss (standarized): 1.2633659199811846\n",
      "Epoch: 46, Loss (standarized): 1.2465420012393844\n",
      "Epoch: 51, Loss (standarized): 1.2264324611279527\n",
      "Epoch: 56, Loss (standarized): 1.202232191417819\n",
      "Epoch: 61, Loss (standarized): 1.1716681312371515\n",
      "Epoch: 66, Loss (standarized): 1.133279294934181\n",
      "Epoch: 71, Loss (standarized): 1.089683389211839\n",
      "Epoch: 76, Loss (standarized): 1.0455692021247136\n",
      "Epoch: 81, Loss (standarized): 1.0026702379124979\n",
      "Epoch: 86, Loss (standarized): 0.961787685018331\n",
      "Epoch: 91, Loss (standarized): 0.9234783750313035\n",
      "Epoch: 96, Loss (standarized): 0.8885088930926653\n",
      "Final epoch: 100, Final loss (standarized): 0.8631294605681059\n",
      "Epoch: 1, Loss (standarized): 1.5875829701965836\n",
      "Epoch: 6, Loss (standarized): 1.3651959540105207\n",
      "Epoch: 11, Loss (standarized): 1.307023360221465\n",
      "Epoch: 16, Loss (standarized): 1.2624296120561\n",
      "Epoch: 21, Loss (standarized): 1.2200446783019756\n",
      "Epoch: 26, Loss (standarized): 1.1639285777024206\n",
      "Epoch: 31, Loss (standarized): 1.1053044668858425\n",
      "Epoch: 36, Loss (standarized): 1.0426116309968696\n",
      "Epoch: 41, Loss (standarized): 0.982762749893748\n",
      "Epoch: 46, Loss (standarized): 0.9255293841105271\n",
      "Epoch: 51, Loss (standarized): 0.8710113247014684\n",
      "Epoch: 56, Loss (standarized): 0.8196005140648353\n",
      "Epoch: 61, Loss (standarized): 0.7718148434015957\n",
      "Epoch: 66, Loss (standarized): 0.7276388589649985\n",
      "Epoch: 71, Loss (standarized): 0.6864732604024778\n",
      "Epoch: 76, Loss (standarized): 0.6475613061346743\n",
      "Epoch: 81, Loss (standarized): 0.6106286903887637\n",
      "Epoch: 86, Loss (standarized): 0.5763420457396008\n",
      "Epoch: 91, Loss (standarized): 0.5454605703453745\n",
      "Epoch: 96, Loss (standarized): 0.5180609733445712\n",
      "Final epoch: 100, Final loss (standarized): 0.498572196525046\n",
      "Epoch: 1, Loss (standarized): 1.5402395300170701\n",
      "Epoch: 6, Loss (standarized): 1.3593419332636003\n",
      "Epoch: 11, Loss (standarized): 1.3361071181292379\n",
      "Epoch: 16, Loss (standarized): 1.3110888622831498\n",
      "Epoch: 21, Loss (standarized): 1.2900988313938495\n",
      "Epoch: 26, Loss (standarized): 1.2563250700411075\n",
      "Epoch: 31, Loss (standarized): 1.209491441571252\n",
      "Epoch: 36, Loss (standarized): 1.1501633071754598\n",
      "Epoch: 41, Loss (standarized): 1.0811144896941192\n",
      "Epoch: 46, Loss (standarized): 1.0105890756027014\n",
      "Epoch: 51, Loss (standarized): 0.9426090828154011\n",
      "Epoch: 56, Loss (standarized): 0.8787001110379186\n",
      "Epoch: 61, Loss (standarized): 0.8178301345937189\n",
      "Epoch: 66, Loss (standarized): 0.7604873394334959\n",
      "Epoch: 71, Loss (standarized): 0.706687949025739\n",
      "Epoch: 76, Loss (standarized): 0.6558055329385448\n",
      "Epoch: 81, Loss (standarized): 0.6086477824293044\n",
      "Epoch: 86, Loss (standarized): 0.5657460079506148\n",
      "Epoch: 91, Loss (standarized): 0.5273460637063845\n",
      "Epoch: 96, Loss (standarized): 0.49365025066622037\n",
      "Final epoch: 100, Final loss (standarized): 0.4699441454196604\n",
      "Epoch: 1, Loss (standarized): 1.5713906897272716\n",
      "Epoch: 6, Loss (standarized): 1.3827031334753948\n",
      "Epoch: 11, Loss (standarized): 1.3222665979610388\n",
      "Epoch: 16, Loss (standarized): 1.2925500464407538\n",
      "Epoch: 21, Loss (standarized): 1.2501690411239463\n",
      "Epoch: 26, Loss (standarized): 1.2061156459805908\n",
      "Epoch: 31, Loss (standarized): 1.1564872278410188\n",
      "Epoch: 36, Loss (standarized): 1.1081940448471814\n",
      "Epoch: 41, Loss (standarized): 1.0591079537789114\n",
      "Epoch: 46, Loss (standarized): 1.0066142122952504\n",
      "Epoch: 51, Loss (standarized): 0.9507531027517063\n",
      "Epoch: 56, Loss (standarized): 0.8916625710146521\n",
      "Epoch: 61, Loss (standarized): 0.8274363508070763\n",
      "Epoch: 66, Loss (standarized): 0.7607027499786576\n",
      "Epoch: 71, Loss (standarized): 0.6972675639100575\n",
      "Epoch: 76, Loss (standarized): 0.6408395762717083\n",
      "Epoch: 81, Loss (standarized): 0.5911952005579701\n",
      "Epoch: 86, Loss (standarized): 0.5471178404922408\n",
      "Epoch: 91, Loss (standarized): 0.5079723651187453\n",
      "Epoch: 96, Loss (standarized): 0.4719114755279213\n",
      "Final epoch: 100, Final loss (standarized): 0.44499727303339304\n",
      "Epoch: 1, Loss (standarized): 1.8299665864476673\n",
      "Epoch: 6, Loss (standarized): 1.47182140094672\n",
      "Epoch: 11, Loss (standarized): 1.366511560555554\n",
      "Epoch: 16, Loss (standarized): 1.3349829454279785\n",
      "Epoch: 21, Loss (standarized): 1.313322634281314\n",
      "Epoch: 26, Loss (standarized): 1.3001725026730224\n",
      "Epoch: 31, Loss (standarized): 1.2807710108860169\n",
      "Epoch: 36, Loss (standarized): 1.2560755800594918\n",
      "Epoch: 41, Loss (standarized): 1.2232477065497873\n",
      "Epoch: 46, Loss (standarized): 1.1777464384138319\n",
      "Epoch: 51, Loss (standarized): 1.1176150405046004\n",
      "Epoch: 56, Loss (standarized): 1.0463545340297176\n",
      "Epoch: 61, Loss (standarized): 0.9729129601451809\n",
      "Epoch: 66, Loss (standarized): 0.9063053893482292\n",
      "Epoch: 71, Loss (standarized): 0.8502910510678544\n",
      "Epoch: 76, Loss (standarized): 0.8045907864979401\n",
      "Epoch: 81, Loss (standarized): 0.7671362732184008\n",
      "Epoch: 86, Loss (standarized): 0.735696132583222\n",
      "Epoch: 91, Loss (standarized): 0.7083140076272297\n",
      "Epoch: 96, Loss (standarized): 0.6838676349191024\n",
      "Final epoch: 100, Final loss (standarized): 0.6660035552378528\n",
      "Epoch: 1, Loss (standarized): 1.6507978781255945\n",
      "Epoch: 6, Loss (standarized): 1.4008079894525418\n",
      "Epoch: 11, Loss (standarized): 1.3374059973319903\n",
      "Epoch: 16, Loss (standarized): 1.3156780641320478\n",
      "Epoch: 21, Loss (standarized): 1.293177512551601\n",
      "Epoch: 26, Loss (standarized): 1.2584383617891253\n",
      "Epoch: 31, Loss (standarized): 1.2188766256755441\n",
      "Epoch: 36, Loss (standarized): 1.1757860126806043\n",
      "Epoch: 41, Loss (standarized): 1.1270912131007789\n",
      "Epoch: 46, Loss (standarized): 1.0736071329940782\n",
      "Epoch: 51, Loss (standarized): 1.0165668213665042\n",
      "Epoch: 56, Loss (standarized): 0.957724306383131\n",
      "Epoch: 61, Loss (standarized): 0.8980241336442848\n",
      "Epoch: 66, Loss (standarized): 0.8393675614061871\n",
      "Epoch: 71, Loss (standarized): 0.7824853702370403\n",
      "Epoch: 76, Loss (standarized): 0.7273140853417608\n",
      "Epoch: 81, Loss (standarized): 0.6751325875169105\n",
      "Epoch: 86, Loss (standarized): 0.6272553867719706\n",
      "Epoch: 91, Loss (standarized): 0.5831558163361993\n",
      "Epoch: 96, Loss (standarized): 0.5421962538965996\n",
      "Final epoch: 100, Final loss (standarized): 0.5114206596201327\n",
      "Epoch: 1, Loss (standarized): 1.655592079323266\n",
      "Epoch: 6, Loss (standarized): 1.418913274915603\n",
      "Epoch: 11, Loss (standarized): 1.3191039740200445\n",
      "Epoch: 16, Loss (standarized): 1.2775063177628105\n",
      "Epoch: 21, Loss (standarized): 1.225639904183117\n",
      "Epoch: 26, Loss (standarized): 1.1641953979286817\n",
      "Epoch: 31, Loss (standarized): 1.0953092103164395\n",
      "Epoch: 36, Loss (standarized): 1.027242609161481\n",
      "Epoch: 41, Loss (standarized): 0.959975317266385\n",
      "Epoch: 46, Loss (standarized): 0.8922239848345578\n",
      "Epoch: 51, Loss (standarized): 0.8260048869576092\n",
      "Epoch: 56, Loss (standarized): 0.7630224115869604\n",
      "Epoch: 61, Loss (standarized): 0.704098827662457\n",
      "Epoch: 66, Loss (standarized): 0.6501156331203123\n",
      "Epoch: 71, Loss (standarized): 0.6005725793792348\n",
      "Epoch: 76, Loss (standarized): 0.5566383209487191\n",
      "Epoch: 81, Loss (standarized): 0.519011535302037\n",
      "Epoch: 86, Loss (standarized): 0.48668827344089777\n",
      "Epoch: 91, Loss (standarized): 0.45888441741294206\n",
      "Epoch: 96, Loss (standarized): 0.4347797340854777\n",
      "Final epoch: 100, Final loss (standarized): 0.4175865217281992\n",
      "Epoch: 1, Loss (standarized): 1.4842403794461325\n",
      "          Validation Loss (standardized): 1.4833430303988757\n",
      "Epoch: 6, Loss (standarized): 1.3472691082793846\n",
      "          Validation Loss (standardized): 1.416372691136982\n",
      "Epoch: 11, Loss (standarized): 1.3089849500299846\n",
      "          Validation Loss (standardized): 1.3792192127077292\n",
      "Epoch: 16, Loss (standarized): 1.2682779624957883\n",
      "          Validation Loss (standardized): 1.3151243172065823\n",
      "Epoch: 21, Loss (standarized): 1.2210111784126472\n",
      "          Validation Loss (standardized): 1.2788959255640124\n",
      "Epoch: 26, Loss (standarized): 1.1626723801049372\n",
      "          Validation Loss (standardized): 1.25428296334155\n",
      "Epoch: 31, Loss (standarized): 1.092886394341741\n",
      "          Validation Loss (standardized): 1.1795955201646693\n",
      "Epoch: 36, Loss (standarized): 1.0170539450119458\n",
      "          Validation Loss (standardized): 1.1163915386569472\n",
      "Epoch: 41, Loss (standarized): 0.936788355777619\n",
      "          Validation Loss (standardized): 1.0400976812808032\n",
      "Epoch: 46, Loss (standarized): 0.8550571781199742\n",
      "          Validation Loss (standardized): 0.964988116714904\n",
      "Epoch: 51, Loss (standarized): 0.7763809076501729\n",
      "          Validation Loss (standardized): 0.9019133998195851\n",
      "Epoch: 56, Loss (standarized): 0.7042942447009923\n",
      "          Validation Loss (standardized): 0.8477918583850294\n",
      "Epoch: 61, Loss (standarized): 0.6392176189299172\n",
      "          Validation Loss (standardized): 0.8070681248133378\n",
      "Epoch: 66, Loss (standarized): 0.5813855977364589\n",
      "          Validation Loss (standardized): 0.7759228349011613\n",
      "Epoch: 71, Loss (standarized): 0.5316362456792203\n",
      "          Validation Loss (standardized): 0.741568578995255\n",
      "Epoch: 76, Loss (standarized): 0.4901891860784483\n",
      "          Validation Loss (standardized): 0.7097508365859898\n",
      "Epoch: 81, Loss (standarized): 0.4549638883408552\n",
      "          Validation Loss (standardized): 0.679598345845178\n",
      "Epoch: 86, Loss (standarized): 0.42416208632240054\n",
      "          Validation Loss (standardized): 0.6486495687165609\n",
      "Epoch: 91, Loss (standarized): 0.39657491813210266\n",
      "          Validation Loss (standardized): 0.6190614912356288\n",
      "Epoch: 96, Loss (standarized): 0.3721347099738018\n",
      "          Validation Loss (standardized): 0.5922640883824006\n",
      "Final epoch: 100, Final loss (standarized): 0.35420728579614114\n",
      "Epoch: 1, Loss (standarized): 1.4979725944802593\n",
      "          Validation Loss (standardized): 1.5403623447445192\n",
      "Epoch: 6, Loss (standarized): 1.3393590159351698\n",
      "          Validation Loss (standardized): 1.3817273152934533\n",
      "Epoch: 11, Loss (standarized): 1.3165419795038642\n",
      "          Validation Loss (standardized): 1.3446571739770317\n",
      "Epoch: 16, Loss (standarized): 1.2907323915129405\n",
      "          Validation Loss (standardized): 1.3654303029283243\n",
      "Epoch: 21, Loss (standarized): 1.2695033279651406\n",
      "          Validation Loss (standardized): 1.3343761957235667\n",
      "Epoch: 26, Loss (standarized): 1.238836128727176\n",
      "          Validation Loss (standardized): 1.2762570232665982\n",
      "Epoch: 31, Loss (standarized): 1.2003179291709174\n",
      "          Validation Loss (standardized): 1.2509448708794537\n",
      "Epoch: 36, Loss (standarized): 1.151270511303834\n",
      "          Validation Loss (standardized): 1.2162898693689002\n",
      "Epoch: 41, Loss (standarized): 1.09498986297897\n",
      "          Validation Loss (standardized): 1.155868873866954\n",
      "Epoch: 46, Loss (standarized): 1.0358007533121372\n",
      "          Validation Loss (standardized): 1.1049446271601955\n",
      "Epoch: 51, Loss (standarized): 0.9780596666819455\n",
      "          Validation Loss (standardized): 1.0536230016509316\n",
      "Epoch: 56, Loss (standarized): 0.9233360093463656\n",
      "          Validation Loss (standardized): 1.0106405292861866\n",
      "Epoch: 61, Loss (standarized): 0.8719352189206334\n",
      "          Validation Loss (standardized): 0.9700784458378577\n",
      "Epoch: 66, Loss (standarized): 0.8239671190524274\n",
      "          Validation Loss (standardized): 0.9357232939946872\n",
      "Epoch: 71, Loss (standarized): 0.7792168978393212\n",
      "          Validation Loss (standardized): 0.9031654309734013\n",
      "Epoch: 76, Loss (standarized): 0.7369601124790884\n",
      "          Validation Loss (standardized): 0.8725732763689602\n",
      "Epoch: 81, Loss (standarized): 0.6972171019201014\n",
      "          Validation Loss (standardized): 0.8412025658341097\n",
      "Epoch: 86, Loss (standarized): 0.6631727782077523\n",
      "          Validation Loss (standardized): 0.8123160543634816\n",
      "Epoch: 91, Loss (standarized): 0.6337282376579965\n",
      "          Validation Loss (standardized): 0.7878173504395543\n",
      "Epoch: 96, Loss (standarized): 0.6091988107394178\n",
      "          Validation Loss (standardized): 0.7669263606869613\n",
      "Final epoch: 100, Final loss (standarized): 0.5922324438320392\n",
      "Epoch: 1, Loss (standarized): 1.7384382687033884\n",
      "          Validation Loss (standardized): 1.6124630365164958\n",
      "Epoch: 6, Loss (standarized): 1.4241976599941903\n",
      "          Validation Loss (standardized): 1.4375466617777664\n",
      "Epoch: 11, Loss (standarized): 1.3557760443663776\n",
      "          Validation Loss (standardized): 1.3930979045242162\n",
      "Epoch: 16, Loss (standarized): 1.3172826237772615\n",
      "          Validation Loss (standardized): 1.3525038049799898\n",
      "Epoch: 21, Loss (standarized): 1.2846226124985909\n",
      "          Validation Loss (standardized): 1.3296632187553772\n",
      "Epoch: 26, Loss (standarized): 1.2457145905793974\n",
      "          Validation Loss (standardized): 1.2999310658759884\n",
      "Epoch: 31, Loss (standarized): 1.1959766138976013\n",
      "          Validation Loss (standardized): 1.2445709721865124\n",
      "Epoch: 36, Loss (standarized): 1.1393888968483912\n",
      "          Validation Loss (standardized): 1.189985451914179\n",
      "Epoch: 41, Loss (standarized): 1.0773199960754258\n",
      "          Validation Loss (standardized): 1.1287304122023527\n",
      "Epoch: 46, Loss (standarized): 1.014247909442336\n",
      "          Validation Loss (standardized): 1.0625666956108155\n",
      "Epoch: 51, Loss (standarized): 0.9539129689312655\n",
      "          Validation Loss (standardized): 1.0051123308764007\n",
      "Epoch: 56, Loss (standarized): 0.8965328102064296\n",
      "          Validation Loss (standardized): 0.9564496830303456\n",
      "Epoch: 61, Loss (standarized): 0.8393101641333716\n",
      "          Validation Loss (standardized): 0.9163751995127907\n",
      "Epoch: 66, Loss (standarized): 0.780540876195959\n",
      "          Validation Loss (standardized): 0.876372622300978\n",
      "Epoch: 71, Loss (standarized): 0.7220542745161437\n",
      "          Validation Loss (standardized): 0.8322839835927124\n",
      "Epoch: 76, Loss (standarized): 0.6674969703007201\n",
      "          Validation Loss (standardized): 0.7944347894589596\n",
      "Epoch: 81, Loss (standarized): 0.6182631312702236\n",
      "          Validation Loss (standardized): 0.7610942667845487\n",
      "Epoch: 86, Loss (standarized): 0.5745168453694391\n",
      "          Validation Loss (standardized): 0.72991029095412\n",
      "Epoch: 91, Loss (standarized): 0.5357617365293685\n",
      "          Validation Loss (standardized): 0.7006480354506344\n",
      "Epoch: 96, Loss (standarized): 0.5015421436610247\n",
      "          Validation Loss (standardized): 0.6749339783732391\n",
      "Final epoch: 100, Final loss (standarized): 0.4768934852024946\n",
      "Epoch: 1, Loss (standarized): 1.740949525014341\n",
      "          Validation Loss (standardized): 1.670437342975532\n",
      "Epoch: 6, Loss (standarized): 1.3965709684768814\n",
      "          Validation Loss (standardized): 1.4147567844750408\n",
      "Epoch: 11, Loss (standarized): 1.3359712304576652\n",
      "          Validation Loss (standardized): 1.361601809561826\n",
      "Epoch: 16, Loss (standarized): 1.3099485197413123\n",
      "          Validation Loss (standardized): 1.3537159999003257\n",
      "Epoch: 21, Loss (standarized): 1.2833744504325693\n",
      "          Validation Loss (standardized): 1.3180217105830023\n",
      "Epoch: 26, Loss (standarized): 1.2454795986512144\n",
      "          Validation Loss (standardized): 1.274173807492433\n",
      "Epoch: 31, Loss (standarized): 1.204042291862132\n",
      "          Validation Loss (standardized): 1.228794488860225\n",
      "Epoch: 36, Loss (standarized): 1.1576280072855147\n",
      "          Validation Loss (standardized): 1.1926561120556602\n",
      "Epoch: 41, Loss (standarized): 1.1096699997706763\n",
      "          Validation Loss (standardized): 1.1546908877062476\n",
      "Epoch: 46, Loss (standarized): 1.0596215102374098\n",
      "          Validation Loss (standardized): 1.0932318586531966\n",
      "Epoch: 51, Loss (standarized): 1.0076205387906612\n",
      "          Validation Loss (standardized): 1.051899179057203\n",
      "Epoch: 56, Loss (standarized): 0.95137757254641\n",
      "          Validation Loss (standardized): 0.9971820900371015\n",
      "Epoch: 61, Loss (standarized): 0.8899291149135651\n",
      "          Validation Loss (standardized): 0.9466927399331335\n",
      "Epoch: 66, Loss (standarized): 0.8255573611247412\n",
      "          Validation Loss (standardized): 0.8919888674031533\n",
      "Epoch: 71, Loss (standarized): 0.7605088656740192\n",
      "          Validation Loss (standardized): 0.8383996775941941\n",
      "Epoch: 76, Loss (standarized): 0.6970973480180576\n",
      "          Validation Loss (standardized): 0.7895988927628691\n",
      "Epoch: 81, Loss (standarized): 0.6373723081068937\n",
      "          Validation Loss (standardized): 0.747647122132335\n",
      "Epoch: 86, Loss (standarized): 0.5817348937126251\n",
      "          Validation Loss (standardized): 0.7096598882885862\n",
      "Epoch: 91, Loss (standarized): 0.5312697909393849\n",
      "          Validation Loss (standardized): 0.6741971792060171\n",
      "Epoch: 96, Loss (standarized): 0.4865259020374084\n",
      "          Validation Loss (standardized): 0.6449147428922009\n",
      "Final epoch: 100, Final loss (standarized): 0.4546315407964235\n",
      "Epoch: 1, Loss (standarized): 1.6280238500878632\n",
      "          Validation Loss (standardized): 1.594319900400609\n",
      "Epoch: 6, Loss (standarized): 1.4113931400113213\n",
      "          Validation Loss (standardized): 1.4559056159842678\n",
      "Epoch: 11, Loss (standarized): 1.353824129579838\n",
      "          Validation Loss (standardized): 1.3985427383061622\n",
      "Epoch: 16, Loss (standarized): 1.3361098260193318\n",
      "          Validation Loss (standardized): 1.3682811996227546\n",
      "Epoch: 21, Loss (standarized): 1.3348880171130768\n",
      "          Validation Loss (standardized): 1.3729675698249353\n",
      "Epoch: 26, Loss (standarized): 1.3363951114978068\n",
      "          Validation Loss (standardized): 1.3847447812844367\n",
      "Epoch: 31, Loss (standarized): 1.3391909421900283\n",
      "          Validation Loss (standardized): 1.3905278819914118\n",
      "Epoch: 36, Loss (standarized): 1.342096905706961\n",
      "          Validation Loss (standardized): 1.3926666311827043\n",
      "Epoch: 41, Loss (standarized): 1.3428106263751414\n",
      "          Validation Loss (standardized): 1.390679601128137\n",
      "Epoch: 46, Loss (standarized): 1.3414650639323218\n",
      "          Validation Loss (standardized): 1.3875873222222426\n",
      "Epoch: 51, Loss (standarized): 1.3374048243609378\n",
      "          Validation Loss (standardized): 1.3788250760817733\n",
      "Epoch: 56, Loss (standarized): 1.3316669209700245\n",
      "          Validation Loss (standardized): 1.372266011625914\n",
      "Epoch: 61, Loss (standarized): 1.3259271283022864\n",
      "          Validation Loss (standardized): 1.3641302604222942\n",
      "Epoch: 66, Loss (standarized): 1.3195285314722964\n",
      "          Validation Loss (standardized): 1.3511746482133935\n",
      "Epoch: 71, Loss (standarized): 1.312711491428844\n",
      "          Validation Loss (standardized): 1.342446308108646\n",
      "Epoch: 76, Loss (standarized): 1.305064509788315\n",
      "          Validation Loss (standardized): 1.336226304236939\n",
      "Epoch: 81, Loss (standarized): 1.2971714512344645\n",
      "          Validation Loss (standardized): 1.3261490136578618\n",
      "Epoch: 86, Loss (standarized): 1.289716276825796\n",
      "          Validation Loss (standardized): 1.3131695386741102\n",
      "Epoch: 91, Loss (standarized): 1.2833198253034666\n",
      "          Validation Loss (standardized): 1.3044155489456033\n",
      "Epoch: 96, Loss (standarized): 1.277197731933579\n",
      "          Validation Loss (standardized): 1.2947440077615588\n",
      "Final epoch: 100, Final loss (standarized): 1.2722888469207516\n",
      "Epoch: 1, Loss (standarized): 1.6960138022411624\n",
      "          Validation Loss (standardized): 1.6070174462789766\n",
      "Epoch: 6, Loss (standarized): 1.3952584934717636\n",
      "          Validation Loss (standardized): 1.4274815048553255\n",
      "Epoch: 11, Loss (standarized): 1.3491282304877887\n",
      "          Validation Loss (standardized): 1.3900559145961509\n",
      "Epoch: 16, Loss (standarized): 1.3446924214248668\n",
      "          Validation Loss (standardized): 1.3785495453115493\n",
      "Epoch: 21, Loss (standarized): 1.3493089502322533\n",
      "          Validation Loss (standardized): 1.388512066882109\n",
      "Epoch: 26, Loss (standarized): 1.3542334531976281\n",
      "          Validation Loss (standardized): 1.4057511932647044\n",
      "Epoch: 31, Loss (standarized): 1.3575075430709456\n",
      "          Validation Loss (standardized): 1.4081733750683196\n",
      "Epoch: 36, Loss (standarized): 1.3579292333792663\n",
      "          Validation Loss (standardized): 1.4023743390629795\n",
      "Epoch: 41, Loss (standarized): 1.355553251613839\n",
      "          Validation Loss (standardized): 1.3970426072813469\n",
      "Epoch: 46, Loss (standarized): 1.3514620982502228\n",
      "          Validation Loss (standardized): 1.3945166483010811\n",
      "Epoch: 51, Loss (standarized): 1.346055891280418\n",
      "          Validation Loss (standardized): 1.3864898787405293\n",
      "Epoch: 56, Loss (standarized): 1.33983575242519\n",
      "          Validation Loss (standardized): 1.3789639353297185\n",
      "Epoch: 61, Loss (standarized): 1.3325970832511436\n",
      "          Validation Loss (standardized): 1.3753381873319395\n",
      "Epoch: 66, Loss (standarized): 1.325069426437459\n",
      "          Validation Loss (standardized): 1.3642693741961402\n",
      "Epoch: 71, Loss (standarized): 1.317634539889969\n",
      "          Validation Loss (standardized): 1.3483145220642292\n",
      "Epoch: 76, Loss (standarized): 1.309653092511346\n",
      "          Validation Loss (standardized): 1.3415138503877038\n",
      "Epoch: 81, Loss (standarized): 1.3007955889612757\n",
      "          Validation Loss (standardized): 1.3327693469495752\n",
      "Epoch: 86, Loss (standarized): 1.291852299838056\n",
      "          Validation Loss (standardized): 1.320493390605794\n",
      "Epoch: 91, Loss (standarized): 1.2837356868560346\n",
      "          Validation Loss (standardized): 1.3078384096850477\n",
      "Epoch: 96, Loss (standarized): 1.2764506223848857\n",
      "          Validation Loss (standardized): 1.2995097557654653\n",
      "Final epoch: 100, Final loss (standarized): 1.2706892632179865\n",
      "Epoch: 1, Loss (standarized): 1.5410529129386235\n",
      "          Validation Loss (standardized): 1.5431552923375134\n",
      "Epoch: 6, Loss (standarized): 1.382015735045169\n",
      "          Validation Loss (standardized): 1.4348846228180445\n",
      "Epoch: 11, Loss (standarized): 1.3510214896976687\n",
      "          Validation Loss (standardized): 1.4077337470319762\n",
      "Epoch: 16, Loss (standarized): 1.3448342738876409\n",
      "          Validation Loss (standardized): 1.391378975877843\n",
      "Epoch: 21, Loss (standarized): 1.3449057077513096\n",
      "          Validation Loss (standardized): 1.3851182029424203\n",
      "Epoch: 26, Loss (standarized): 1.344079456147985\n",
      "          Validation Loss (standardized): 1.3868655133896508\n",
      "Epoch: 31, Loss (standarized): 1.3437924327720492\n",
      "          Validation Loss (standardized): 1.3865747340184018\n",
      "Epoch: 36, Loss (standarized): 1.3424299802522193\n",
      "          Validation Loss (standardized): 1.3818385249683278\n",
      "Epoch: 41, Loss (standarized): 1.3403218097802432\n",
      "          Validation Loss (standardized): 1.381131240936759\n",
      "Epoch: 46, Loss (standarized): 1.3362351946734667\n",
      "          Validation Loss (standardized): 1.377694540911234\n",
      "Epoch: 51, Loss (standarized): 1.3300574698875538\n",
      "          Validation Loss (standardized): 1.3699641912830243\n",
      "Epoch: 56, Loss (standarized): 1.3238252084048923\n",
      "          Validation Loss (standardized): 1.3597881702902745\n",
      "Epoch: 61, Loss (standarized): 1.318008363678336\n",
      "          Validation Loss (standardized): 1.3490975583937508\n",
      "Epoch: 66, Loss (standarized): 1.311393554357382\n",
      "          Validation Loss (standardized): 1.3410362580537678\n",
      "Epoch: 71, Loss (standarized): 1.3035777011007743\n",
      "          Validation Loss (standardized): 1.3305221053542287\n",
      "Epoch: 76, Loss (standarized): 1.2956234816366752\n",
      "          Validation Loss (standardized): 1.3251118428554447\n",
      "Epoch: 81, Loss (standarized): 1.2875464522019084\n",
      "          Validation Loss (standardized): 1.3126157302275492\n",
      "Epoch: 86, Loss (standarized): 1.2788551496936436\n",
      "          Validation Loss (standardized): 1.2988749615062107\n",
      "Epoch: 91, Loss (standarized): 1.269244759678266\n",
      "          Validation Loss (standardized): 1.2836874132042784\n",
      "Epoch: 96, Loss (standarized): 1.2592741142897337\n",
      "          Validation Loss (standardized): 1.2702780093492063\n",
      "Final epoch: 100, Final loss (standarized): 1.2513895235994517\n",
      "Epoch: 1, Loss (standarized): 1.7059281659485206\n",
      "          Validation Loss (standardized): 1.6051579970889707\n",
      "Epoch: 6, Loss (standarized): 1.429295772144094\n",
      "          Validation Loss (standardized): 1.4485781597619198\n",
      "Epoch: 11, Loss (standarized): 1.3620041915253842\n",
      "          Validation Loss (standardized): 1.371941559718174\n",
      "Epoch: 16, Loss (standarized): 1.341814977877716\n",
      "          Validation Loss (standardized): 1.3633739863476904\n",
      "Epoch: 21, Loss (standarized): 1.33380108275169\n",
      "          Validation Loss (standardized): 1.370346672365097\n",
      "Epoch: 26, Loss (standarized): 1.3366132971462412\n",
      "          Validation Loss (standardized): 1.371170998558387\n",
      "Epoch: 31, Loss (standarized): 1.3396187144264422\n",
      "          Validation Loss (standardized): 1.3734425693440417\n",
      "Epoch: 36, Loss (standarized): 1.3357609600188678\n",
      "          Validation Loss (standardized): 1.3720842993759452\n",
      "Epoch: 41, Loss (standarized): 1.3306920553671489\n",
      "          Validation Loss (standardized): 1.3655209202464547\n",
      "Epoch: 46, Loss (standarized): 1.3260452552997912\n",
      "          Validation Loss (standardized): 1.3563492459985014\n",
      "Epoch: 51, Loss (standarized): 1.3208404743847866\n",
      "          Validation Loss (standardized): 1.3516488302127505\n",
      "Epoch: 56, Loss (standarized): 1.3150265291978342\n",
      "          Validation Loss (standardized): 1.3467846085728339\n",
      "Epoch: 61, Loss (standarized): 1.3087093279463704\n",
      "          Validation Loss (standardized): 1.3393324178240358\n",
      "Epoch: 66, Loss (standarized): 1.3020177640834658\n",
      "          Validation Loss (standardized): 1.32955417162484\n",
      "Epoch: 71, Loss (standarized): 1.294508826008584\n",
      "          Validation Loss (standardized): 1.3175654736500813\n",
      "Epoch: 76, Loss (standarized): 1.285786261686128\n",
      "          Validation Loss (standardized): 1.3035014846155895\n",
      "Epoch: 81, Loss (standarized): 1.2757962562281753\n",
      "          Validation Loss (standardized): 1.2908717483121392\n",
      "Epoch: 86, Loss (standarized): 1.265799011149806\n",
      "          Validation Loss (standardized): 1.2823556657477289\n",
      "Epoch: 91, Loss (standarized): 1.2549074425174314\n",
      "          Validation Loss (standardized): 1.269784753601202\n",
      "Epoch: 96, Loss (standarized): 1.2422138947067551\n",
      "          Validation Loss (standardized): 1.2506092054738474\n",
      "Final epoch: 100, Final loss (standarized): 1.229780194648291\n",
      "Epoch: 1, Loss (standarized): 1.6860397728671537\n",
      "          Validation Loss (standardized): 1.5704425909895023\n",
      "Epoch: 6, Loss (standarized): 1.3810025547254088\n",
      "          Validation Loss (standardized): 1.4007632273592876\n",
      "Epoch: 11, Loss (standarized): 1.3498039615661224\n",
      "          Validation Loss (standardized): 1.3936271782893945\n",
      "Epoch: 16, Loss (standarized): 1.322472799541162\n",
      "          Validation Loss (standardized): 1.3641050660141278\n",
      "Epoch: 21, Loss (standarized): 1.3066472998126508\n",
      "          Validation Loss (standardized): 1.3351652980991187\n",
      "Epoch: 26, Loss (standarized): 1.2811502013675988\n",
      "          Validation Loss (standardized): 1.3157485605286674\n",
      "Epoch: 31, Loss (standarized): 1.2520313715878775\n",
      "          Validation Loss (standardized): 1.3036401115227214\n",
      "Epoch: 36, Loss (standarized): 1.2143005713068669\n",
      "          Validation Loss (standardized): 1.2657081399304333\n",
      "Epoch: 41, Loss (standarized): 1.1700480923443108\n",
      "          Validation Loss (standardized): 1.2212411857440066\n",
      "Epoch: 46, Loss (standarized): 1.1188699212997935\n",
      "          Validation Loss (standardized): 1.1862829425591859\n",
      "Epoch: 51, Loss (standarized): 1.0615458456336295\n",
      "          Validation Loss (standardized): 1.1376299984212688\n",
      "Epoch: 56, Loss (standarized): 0.9984151793912319\n",
      "          Validation Loss (standardized): 1.0849194254875838\n",
      "Epoch: 61, Loss (standarized): 0.9317444927814589\n",
      "          Validation Loss (standardized): 1.0338762843454081\n",
      "Epoch: 66, Loss (standarized): 0.8645229643359087\n",
      "          Validation Loss (standardized): 0.974644061508441\n",
      "Epoch: 71, Loss (standarized): 0.799054954974663\n",
      "          Validation Loss (standardized): 0.9211425100779591\n",
      "Epoch: 76, Loss (standarized): 0.7372329406064944\n",
      "          Validation Loss (standardized): 0.8697162074718533\n",
      "Epoch: 81, Loss (standarized): 0.6800474879027287\n",
      "          Validation Loss (standardized): 0.8226167806597321\n",
      "Epoch: 86, Loss (standarized): 0.6268796727080163\n",
      "          Validation Loss (standardized): 0.7783276556018659\n",
      "Epoch: 91, Loss (standarized): 0.5786329991998665\n",
      "          Validation Loss (standardized): 0.7400835300999004\n",
      "Epoch: 96, Loss (standarized): 0.5370216886996141\n",
      "          Validation Loss (standardized): 0.7070153377871887\n",
      "Final epoch: 100, Final loss (standarized): 0.5075296038279066\n",
      "Epoch: 1, Loss (standarized): 1.6968486620539245\n",
      "          Validation Loss (standardized): 1.6521306135459006\n",
      "Epoch: 6, Loss (standarized): 1.4462275253590244\n",
      "          Validation Loss (standardized): 1.4627232669211845\n",
      "Epoch: 11, Loss (standarized): 1.3486623372029396\n",
      "          Validation Loss (standardized): 1.3931406033943277\n",
      "Epoch: 16, Loss (standarized): 1.3207688991115072\n",
      "          Validation Loss (standardized): 1.3718755381086234\n",
      "Epoch: 21, Loss (standarized): 1.3075007958915381\n",
      "          Validation Loss (standardized): 1.3522380177099638\n",
      "Epoch: 26, Loss (standarized): 1.2954996606135865\n",
      "          Validation Loss (standardized): 1.3371334013685752\n",
      "Epoch: 31, Loss (standarized): 1.2821262258313249\n",
      "          Validation Loss (standardized): 1.3353257997816714\n",
      "Epoch: 36, Loss (standarized): 1.26490698563705\n",
      "          Validation Loss (standardized): 1.3165766106828982\n",
      "Epoch: 41, Loss (standarized): 1.2410421395876905\n",
      "          Validation Loss (standardized): 1.291828630108926\n",
      "Epoch: 46, Loss (standarized): 1.2069217029304644\n",
      "          Validation Loss (standardized): 1.2624349058079256\n",
      "Epoch: 51, Loss (standarized): 1.1613014725637913\n",
      "          Validation Loss (standardized): 1.2145594038120335\n",
      "Epoch: 56, Loss (standarized): 1.108093396517888\n",
      "          Validation Loss (standardized): 1.1641701448438426\n",
      "Epoch: 61, Loss (standarized): 1.0546014727950312\n",
      "          Validation Loss (standardized): 1.1104812025325244\n",
      "Epoch: 66, Loss (standarized): 1.0060738771410076\n",
      "          Validation Loss (standardized): 1.0653124773291975\n",
      "Epoch: 71, Loss (standarized): 0.9630769123850711\n",
      "          Validation Loss (standardized): 1.0294048521136379\n",
      "Epoch: 76, Loss (standarized): 0.9241665564312246\n",
      "          Validation Loss (standardized): 0.9985955442481702\n",
      "Epoch: 81, Loss (standarized): 0.8889565154778409\n",
      "          Validation Loss (standardized): 0.9710045882620962\n",
      "Epoch: 86, Loss (standarized): 0.8571204660495454\n",
      "          Validation Loss (standardized): 0.9463814549932464\n",
      "Epoch: 91, Loss (standarized): 0.828782553622416\n",
      "          Validation Loss (standardized): 0.9239619815257241\n",
      "Epoch: 96, Loss (standarized): 0.8031513942339968\n",
      "          Validation Loss (standardized): 0.9025216256386659\n",
      "Final epoch: 100, Final loss (standarized): 0.7838794413887626\n",
      "Epoch: 1, Loss (standarized): 1.6978669791298842\n",
      "          Validation Loss (standardized): 1.6273900353502397\n",
      "Epoch: 6, Loss (standarized): 1.3986285605311115\n",
      "          Validation Loss (standardized): 1.446395221050251\n",
      "Epoch: 11, Loss (standarized): 1.3313532144209577\n",
      "          Validation Loss (standardized): 1.4031399485344374\n",
      "Epoch: 16, Loss (standarized): 1.2926395122900949\n",
      "          Validation Loss (standardized): 1.365667675748128\n",
      "Epoch: 21, Loss (standarized): 1.2552623553751332\n",
      "          Validation Loss (standardized): 1.3146239441217658\n",
      "Epoch: 26, Loss (standarized): 1.210658323219602\n",
      "          Validation Loss (standardized): 1.2559153339687104\n",
      "Epoch: 31, Loss (standarized): 1.1567522393914422\n",
      "          Validation Loss (standardized): 1.2423456638184112\n",
      "Epoch: 36, Loss (standarized): 1.1051744801440788\n",
      "          Validation Loss (standardized): 1.204654871428881\n",
      "Epoch: 41, Loss (standarized): 1.0549893018856629\n",
      "          Validation Loss (standardized): 1.1427805360698253\n",
      "Epoch: 46, Loss (standarized): 1.007142290967412\n",
      "          Validation Loss (standardized): 1.107084149514908\n",
      "Epoch: 51, Loss (standarized): 0.9614051672720001\n",
      "          Validation Loss (standardized): 1.0633876220013714\n",
      "Epoch: 56, Loss (standarized): 0.9168179930691807\n",
      "          Validation Loss (standardized): 1.0262617286590077\n",
      "Epoch: 61, Loss (standarized): 0.8723687902533933\n",
      "          Validation Loss (standardized): 0.9919712621446927\n",
      "Epoch: 66, Loss (standarized): 0.8274101470596509\n",
      "          Validation Loss (standardized): 0.9578701083096589\n",
      "Epoch: 71, Loss (standarized): 0.7822412747026387\n",
      "          Validation Loss (standardized): 0.9232129370468636\n",
      "Epoch: 76, Loss (standarized): 0.7373582807311132\n",
      "          Validation Loss (standardized): 0.8898536046610087\n",
      "Epoch: 81, Loss (standarized): 0.6935296096552329\n",
      "          Validation Loss (standardized): 0.8551166783880151\n",
      "Epoch: 86, Loss (standarized): 0.6512105604387318\n",
      "          Validation Loss (standardized): 0.8231008150272052\n",
      "Epoch: 91, Loss (standarized): 0.6111413725919324\n",
      "          Validation Loss (standardized): 0.7925322347546907\n",
      "Epoch: 96, Loss (standarized): 0.5742060543183203\n",
      "          Validation Loss (standardized): 0.7635003777150016\n",
      "Final epoch: 100, Final loss (standarized): 0.5472662793336016\n",
      "Epoch: 1, Loss (standarized): 1.7647572023787736\n",
      "          Validation Loss (standardized): 1.649981109442016\n",
      "Epoch: 6, Loss (standarized): 1.4127691189844962\n",
      "          Validation Loss (standardized): 1.4586618599184111\n",
      "Epoch: 11, Loss (standarized): 1.334098804709559\n",
      "          Validation Loss (standardized): 1.423584165442916\n",
      "Epoch: 16, Loss (standarized): 1.311425239092639\n",
      "          Validation Loss (standardized): 1.3877679427479166\n",
      "Epoch: 21, Loss (standarized): 1.2831242834446752\n",
      "          Validation Loss (standardized): 1.3219884800741857\n",
      "Epoch: 26, Loss (standarized): 1.2531670337048775\n",
      "          Validation Loss (standardized): 1.2896355009184803\n",
      "Epoch: 31, Loss (standarized): 1.2117339591926224\n",
      "          Validation Loss (standardized): 1.2836977573861745\n",
      "Epoch: 36, Loss (standarized): 1.1619216674788464\n",
      "          Validation Loss (standardized): 1.2408793143208388\n",
      "Epoch: 41, Loss (standarized): 1.1041532974967945\n",
      "          Validation Loss (standardized): 1.1806579305570861\n",
      "Epoch: 46, Loss (standarized): 1.0425056876375138\n",
      "          Validation Loss (standardized): 1.1240170477265778\n",
      "Epoch: 51, Loss (standarized): 0.9803885762930008\n",
      "          Validation Loss (standardized): 1.0709087894291451\n",
      "Epoch: 56, Loss (standarized): 0.9212046938090634\n",
      "          Validation Loss (standardized): 1.020623421441446\n",
      "Epoch: 61, Loss (standarized): 0.8654422381138667\n",
      "          Validation Loss (standardized): 0.9756769703677226\n",
      "Epoch: 66, Loss (standarized): 0.8126804515913545\n",
      "          Validation Loss (standardized): 0.9357014799951189\n",
      "Epoch: 71, Loss (standarized): 0.7623947245751806\n",
      "          Validation Loss (standardized): 0.9008946018829833\n",
      "Epoch: 76, Loss (standarized): 0.7144706994286468\n",
      "          Validation Loss (standardized): 0.8715240228712057\n",
      "Epoch: 81, Loss (standarized): 0.6696280165716412\n",
      "          Validation Loss (standardized): 0.8461009095817726\n",
      "Epoch: 86, Loss (standarized): 0.6284875882978381\n",
      "          Validation Loss (standardized): 0.8256011337001634\n",
      "Epoch: 91, Loss (standarized): 0.591431926653096\n",
      "          Validation Loss (standardized): 0.8068623912857303\n",
      "Epoch: 96, Loss (standarized): 0.5589420775436663\n",
      "          Validation Loss (standardized): 0.7903324293900982\n",
      "Final epoch: 100, Final loss (standarized): 0.5362683891900716\n",
      "Epoch: 1, Loss (standarized): 1.5860196677780898\n",
      "          Validation Loss (standardized): 1.5295172586928762\n",
      "Epoch: 6, Loss (standarized): 1.3792860016210409\n",
      "          Validation Loss (standardized): 1.430138429062401\n",
      "Epoch: 11, Loss (standarized): 1.3298407409297643\n",
      "          Validation Loss (standardized): 1.3985190939154828\n",
      "Epoch: 16, Loss (standarized): 1.3071958105064951\n",
      "          Validation Loss (standardized): 1.3497231157466125\n",
      "Epoch: 21, Loss (standarized): 1.2763715152311064\n",
      "          Validation Loss (standardized): 1.2978112680752139\n",
      "Epoch: 26, Loss (standarized): 1.2410080206635996\n",
      "          Validation Loss (standardized): 1.260225315098379\n",
      "Epoch: 31, Loss (standarized): 1.193732984151433\n",
      "          Validation Loss (standardized): 1.2309252573275458\n",
      "Epoch: 36, Loss (standarized): 1.1390439851656593\n",
      "          Validation Loss (standardized): 1.1808424346940525\n",
      "Epoch: 41, Loss (standarized): 1.0751368216099835\n",
      "          Validation Loss (standardized): 1.1220347337658603\n",
      "Epoch: 46, Loss (standarized): 1.0051506567162414\n",
      "          Validation Loss (standardized): 1.0581978119372488\n",
      "Epoch: 51, Loss (standarized): 0.9338416508914332\n",
      "          Validation Loss (standardized): 1.008477246542717\n",
      "Epoch: 56, Loss (standarized): 0.8640802048179662\n",
      "          Validation Loss (standardized): 0.95232445100472\n",
      "Epoch: 61, Loss (standarized): 0.7974650353492198\n",
      "          Validation Loss (standardized): 0.9002424432217854\n",
      "Epoch: 66, Loss (standarized): 0.7329155996666682\n",
      "          Validation Loss (standardized): 0.85207821886353\n",
      "Epoch: 71, Loss (standarized): 0.6701628713403401\n",
      "          Validation Loss (standardized): 0.8027955831807692\n",
      "Epoch: 76, Loss (standarized): 0.6105855122150905\n",
      "          Validation Loss (standardized): 0.7577795566731114\n",
      "Epoch: 81, Loss (standarized): 0.5576609252140806\n",
      "          Validation Loss (standardized): 0.7165558727375526\n",
      "Epoch: 86, Loss (standarized): 0.5110913523296702\n",
      "          Validation Loss (standardized): 0.6836525560807278\n",
      "Epoch: 91, Loss (standarized): 0.46964588189741746\n",
      "          Validation Loss (standardized): 0.6606715525246278\n",
      "Epoch: 96, Loss (standarized): 0.433014372382127\n",
      "          Validation Loss (standardized): 0.6372747163905471\n",
      "Final epoch: 100, Final loss (standarized): 0.4064854883412531\n",
      "Epoch: 1, Loss (standarized): 1.634288884128468\n",
      "          Validation Loss (standardized): 1.614795906328688\n",
      "Epoch: 6, Loss (standarized): 1.4031832736021572\n",
      "          Validation Loss (standardized): 1.4290120974984413\n",
      "Epoch: 11, Loss (standarized): 1.3548616154725084\n",
      "          Validation Loss (standardized): 1.3842536230736657\n",
      "Epoch: 16, Loss (standarized): 1.333226963529183\n",
      "          Validation Loss (standardized): 1.3671043151526534\n",
      "Epoch: 21, Loss (standarized): 1.3172826520002618\n",
      "          Validation Loss (standardized): 1.3574725757911967\n",
      "Epoch: 26, Loss (standarized): 1.306004456194514\n",
      "          Validation Loss (standardized): 1.3501658660495377\n",
      "Epoch: 31, Loss (standarized): 1.2923259110940615\n",
      "          Validation Loss (standardized): 1.3379526558576926\n",
      "Epoch: 36, Loss (standarized): 1.2754118541160946\n",
      "          Validation Loss (standardized): 1.318445671378578\n",
      "Epoch: 41, Loss (standarized): 1.2504729071051117\n",
      "          Validation Loss (standardized): 1.2958633061774005\n",
      "Epoch: 46, Loss (standarized): 1.2149142365646635\n",
      "          Validation Loss (standardized): 1.2692715981163452\n",
      "Epoch: 51, Loss (standarized): 1.1682666255685774\n",
      "          Validation Loss (standardized): 1.23166076909407\n",
      "Epoch: 56, Loss (standarized): 1.1124336908532129\n",
      "          Validation Loss (standardized): 1.1823640351919897\n",
      "Epoch: 61, Loss (standarized): 1.0512413061462578\n",
      "          Validation Loss (standardized): 1.125079099419117\n",
      "Epoch: 66, Loss (standarized): 0.9907837637200436\n",
      "          Validation Loss (standardized): 1.0688927522418334\n",
      "Epoch: 71, Loss (standarized): 0.9352866594319024\n",
      "          Validation Loss (standardized): 1.0230198034980242\n",
      "Epoch: 76, Loss (standarized): 0.8862953143063163\n",
      "          Validation Loss (standardized): 0.9827599735238103\n",
      "Epoch: 81, Loss (standarized): 0.8434117178137344\n",
      "          Validation Loss (standardized): 0.9483600220013452\n",
      "Epoch: 86, Loss (standarized): 0.8054297068531565\n",
      "          Validation Loss (standardized): 0.9183970465850316\n",
      "Epoch: 91, Loss (standarized): 0.7716292142813558\n",
      "          Validation Loss (standardized): 0.890823631412048\n",
      "Epoch: 96, Loss (standarized): 0.7413391447866675\n",
      "          Validation Loss (standardized): 0.8668478284631531\n",
      "Final epoch: 100, Final loss (standarized): 0.7192789159748213\n",
      "Epoch: 1, Loss (standarized): 1.6373053389176488\n",
      "          Validation Loss (standardized): 1.60755005224664\n",
      "Epoch: 6, Loss (standarized): 1.4023487966462742\n",
      "          Validation Loss (standardized): 1.4331567687626734\n",
      "Epoch: 11, Loss (standarized): 1.3356139344762346\n",
      "          Validation Loss (standardized): 1.399843458295154\n",
      "Epoch: 16, Loss (standarized): 1.2977458995636402\n",
      "          Validation Loss (standardized): 1.3467765885489853\n",
      "Epoch: 21, Loss (standarized): 1.2601523902951737\n",
      "          Validation Loss (standardized): 1.2860191088396786\n",
      "Epoch: 26, Loss (standarized): 1.2173247146298452\n",
      "          Validation Loss (standardized): 1.2735176895704066\n",
      "Epoch: 31, Loss (standarized): 1.1636609514156642\n",
      "          Validation Loss (standardized): 1.2143202178108905\n",
      "Epoch: 36, Loss (standarized): 1.1018733664083318\n",
      "          Validation Loss (standardized): 1.1663726931545026\n",
      "Epoch: 41, Loss (standarized): 1.0361441364840802\n",
      "          Validation Loss (standardized): 1.0926283705001223\n",
      "Epoch: 46, Loss (standarized): 0.9733144424652578\n",
      "          Validation Loss (standardized): 1.0377364504584448\n",
      "Epoch: 51, Loss (standarized): 0.9145608359116278\n",
      "          Validation Loss (standardized): 0.9870796569290512\n",
      "Epoch: 56, Loss (standarized): 0.8595556410731053\n",
      "          Validation Loss (standardized): 0.9416627123543921\n",
      "Epoch: 61, Loss (standarized): 0.8066663025562616\n",
      "          Validation Loss (standardized): 0.8977314290374525\n",
      "Epoch: 66, Loss (standarized): 0.7534859183999219\n",
      "          Validation Loss (standardized): 0.8528773058652853\n",
      "Epoch: 71, Loss (standarized): 0.702227748890972\n",
      "          Validation Loss (standardized): 0.8115724825080709\n",
      "Epoch: 76, Loss (standarized): 0.65631580481614\n",
      "          Validation Loss (standardized): 0.7797199918928702\n",
      "Epoch: 81, Loss (standarized): 0.6133544979388027\n",
      "          Validation Loss (standardized): 0.7536565089104138\n",
      "Epoch: 86, Loss (standarized): 0.572114485704246\n",
      "          Validation Loss (standardized): 0.7238968109856728\n",
      "Epoch: 91, Loss (standarized): 0.5337089339271669\n",
      "          Validation Loss (standardized): 0.6971446015177544\n",
      "Epoch: 96, Loss (standarized): 0.49863794863018684\n",
      "          Validation Loss (standardized): 0.672256739930363\n",
      "Final epoch: 100, Final loss (standarized): 0.47241452615905827\n",
      "Epoch: 1, Loss (standarized): 1.7225535804680399\n",
      "          Validation Loss (standardized): 1.6058292107514713\n",
      "Epoch: 6, Loss (standarized): 1.3853027140558578\n",
      "          Validation Loss (standardized): 1.4087376012493926\n",
      "Epoch: 11, Loss (standarized): 1.335832038349409\n",
      "          Validation Loss (standardized): 1.3540481413292087\n",
      "Epoch: 16, Loss (standarized): 1.3063230763451394\n",
      "          Validation Loss (standardized): 1.308478631565484\n",
      "Epoch: 21, Loss (standarized): 1.2822856407583256\n",
      "          Validation Loss (standardized): 1.314033548526254\n",
      "Epoch: 26, Loss (standarized): 1.2544683695496028\n",
      "          Validation Loss (standardized): 1.2991964428212415\n",
      "Epoch: 31, Loss (standarized): 1.2223678434366494\n",
      "          Validation Loss (standardized): 1.2598385641801066\n",
      "Epoch: 36, Loss (standarized): 1.1808499161023867\n",
      "          Validation Loss (standardized): 1.2295576461576765\n",
      "Epoch: 41, Loss (standarized): 1.1295126821989618\n",
      "          Validation Loss (standardized): 1.1938508197219517\n",
      "Epoch: 46, Loss (standarized): 1.0715654619814925\n",
      "          Validation Loss (standardized): 1.1438519226110648\n",
      "Epoch: 51, Loss (standarized): 1.0089870646858616\n",
      "          Validation Loss (standardized): 1.0836672591224366\n",
      "Epoch: 56, Loss (standarized): 0.9456682969453689\n",
      "          Validation Loss (standardized): 1.0365771629412164\n",
      "Epoch: 61, Loss (standarized): 0.883468504057738\n",
      "          Validation Loss (standardized): 0.9777030541419149\n",
      "Epoch: 66, Loss (standarized): 0.8214056629947212\n",
      "          Validation Loss (standardized): 0.9330089321239384\n",
      "Epoch: 71, Loss (standarized): 0.7596085749507612\n",
      "          Validation Loss (standardized): 0.8825378035763957\n",
      "Epoch: 76, Loss (standarized): 0.699665017672458\n",
      "          Validation Loss (standardized): 0.8384680084008337\n",
      "Epoch: 81, Loss (standarized): 0.6436299120030341\n",
      "          Validation Loss (standardized): 0.8045485458053022\n",
      "Epoch: 86, Loss (standarized): 0.5935532510595525\n",
      "          Validation Loss (standardized): 0.7751794333663048\n",
      "Epoch: 91, Loss (standarized): 0.5497045554695468\n",
      "          Validation Loss (standardized): 0.7485223421867335\n",
      "Epoch: 96, Loss (standarized): 0.5120277824396742\n",
      "          Validation Loss (standardized): 0.7244419767337664\n",
      "Final epoch: 100, Final loss (standarized): 0.4851476806530938\n",
      "Epoch: 1, Loss (standarized): 1.4933532721254046\n",
      "          Validation Loss (standardized): 1.4970246713568203\n",
      "Epoch: 6, Loss (standarized): 1.349493921604699\n",
      "          Validation Loss (standardized): 1.3965271812151514\n",
      "Epoch: 11, Loss (standarized): 1.3238673559534606\n",
      "          Validation Loss (standardized): 1.3513692509417718\n",
      "Epoch: 16, Loss (standarized): 1.2817476745250724\n",
      "          Validation Loss (standardized): 1.3118907549202528\n",
      "Epoch: 21, Loss (standarized): 1.229952073625563\n",
      "          Validation Loss (standardized): 1.279775638392635\n",
      "Epoch: 26, Loss (standarized): 1.1660704648816493\n",
      "          Validation Loss (standardized): 1.2242021586832375\n",
      "Epoch: 31, Loss (standarized): 1.0947956319401198\n",
      "          Validation Loss (standardized): 1.1649142900884129\n",
      "Epoch: 36, Loss (standarized): 1.0248006650282375\n",
      "          Validation Loss (standardized): 1.0988623696639448\n",
      "Epoch: 41, Loss (standarized): 0.9588710119354292\n",
      "          Validation Loss (standardized): 1.038711992905754\n",
      "Epoch: 46, Loss (standarized): 0.8959573126519856\n",
      "          Validation Loss (standardized): 0.9821855930444916\n",
      "Epoch: 51, Loss (standarized): 0.8325897576595007\n",
      "          Validation Loss (standardized): 0.9309146662110136\n",
      "Epoch: 56, Loss (standarized): 0.7680960179847441\n",
      "          Validation Loss (standardized): 0.8857851303653478\n",
      "Epoch: 61, Loss (standarized): 0.7040759309312924\n",
      "          Validation Loss (standardized): 0.8448167633212849\n",
      "Epoch: 66, Loss (standarized): 0.642759524362488\n",
      "          Validation Loss (standardized): 0.8038272637461825\n",
      "Epoch: 71, Loss (standarized): 0.5854968188941798\n",
      "          Validation Loss (standardized): 0.7597673700826678\n",
      "Epoch: 76, Loss (standarized): 0.5325785148207561\n",
      "          Validation Loss (standardized): 0.721157353310494\n",
      "Epoch: 81, Loss (standarized): 0.4846394695174335\n",
      "          Validation Loss (standardized): 0.6917252393204433\n",
      "Epoch: 86, Loss (standarized): 0.44541099030715364\n",
      "          Validation Loss (standardized): 0.6657002655256236\n",
      "Epoch: 91, Loss (standarized): 0.4124172062271683\n",
      "          Validation Loss (standardized): 0.6381880236963958\n",
      "Epoch: 96, Loss (standarized): 0.38265654505574603\n",
      "          Validation Loss (standardized): 0.6099919518445477\n",
      "Final epoch: 100, Final loss (standarized): 0.3617365768209046\n",
      "Epoch: 1, Loss (standarized): 1.543578802426622\n",
      "          Validation Loss (standardized): 1.521719589761864\n",
      "Epoch: 6, Loss (standarized): 1.3677456377186457\n",
      "          Validation Loss (standardized): 1.3969880098238094\n",
      "Epoch: 11, Loss (standarized): 1.326056523850868\n",
      "          Validation Loss (standardized): 1.3423783113296863\n",
      "Epoch: 16, Loss (standarized): 1.3042072539809209\n",
      "          Validation Loss (standardized): 1.3353432306682647\n",
      "Epoch: 21, Loss (standarized): 1.2848240007069263\n",
      "          Validation Loss (standardized): 1.3290020407840002\n",
      "Epoch: 26, Loss (standarized): 1.2655000363616196\n",
      "          Validation Loss (standardized): 1.30923023032202\n",
      "Epoch: 31, Loss (standarized): 1.2419778250957314\n",
      "          Validation Loss (standardized): 1.2852664854948497\n",
      "Epoch: 36, Loss (standarized): 1.2093416239027173\n",
      "          Validation Loss (standardized): 1.2668614756976333\n",
      "Epoch: 41, Loss (standarized): 1.1717775749061878\n",
      "          Validation Loss (standardized): 1.2335123613777277\n",
      "Epoch: 46, Loss (standarized): 1.1316503334501713\n",
      "          Validation Loss (standardized): 1.1890869790338492\n",
      "Epoch: 51, Loss (standarized): 1.087906412599728\n",
      "          Validation Loss (standardized): 1.151294009679106\n",
      "Epoch: 56, Loss (standarized): 1.0401616453396219\n",
      "          Validation Loss (standardized): 1.111199481742545\n",
      "Epoch: 61, Loss (standarized): 0.9895330872656629\n",
      "          Validation Loss (standardized): 1.0647284430690147\n",
      "Epoch: 66, Loss (standarized): 0.9375540438192057\n",
      "          Validation Loss (standardized): 1.0179654861333778\n",
      "Epoch: 71, Loss (standarized): 0.8850829299243554\n",
      "          Validation Loss (standardized): 0.9719335711205438\n",
      "Epoch: 76, Loss (standarized): 0.8327616039028548\n",
      "          Validation Loss (standardized): 0.9273968210796427\n",
      "Epoch: 81, Loss (standarized): 0.7819964829929797\n",
      "          Validation Loss (standardized): 0.8896290148747217\n",
      "Epoch: 86, Loss (standarized): 0.7353589510625156\n",
      "          Validation Loss (standardized): 0.8539350604376309\n",
      "Epoch: 91, Loss (standarized): 0.6943127998015288\n",
      "          Validation Loss (standardized): 0.8209311679203892\n",
      "Epoch: 96, Loss (standarized): 0.65895951840436\n",
      "          Validation Loss (standardized): 0.7919873527965201\n",
      "Final epoch: 100, Final loss (standarized): 0.6342215532422686\n",
      "Epoch: 1, Loss (standarized): 1.5737841022678405\n",
      "          Validation Loss (standardized): 1.5428893600426876\n",
      "Epoch: 6, Loss (standarized): 1.3784413927694397\n",
      "          Validation Loss (standardized): 1.4286663598891258\n",
      "Epoch: 11, Loss (standarized): 1.3308550187193304\n",
      "          Validation Loss (standardized): 1.401331200751376\n",
      "Epoch: 16, Loss (standarized): 1.2934539441624338\n",
      "          Validation Loss (standardized): 1.331680442452117\n",
      "Epoch: 21, Loss (standarized): 1.2549021105576836\n",
      "          Validation Loss (standardized): 1.2949534421873614\n",
      "Epoch: 26, Loss (standarized): 1.2031604215401985\n",
      "          Validation Loss (standardized): 1.270966022364547\n",
      "Epoch: 31, Loss (standarized): 1.1420024572872174\n",
      "          Validation Loss (standardized): 1.2095867188189198\n",
      "Epoch: 36, Loss (standarized): 1.075479955918329\n",
      "          Validation Loss (standardized): 1.1391204537385304\n",
      "Epoch: 41, Loss (standarized): 1.0102867291577515\n",
      "          Validation Loss (standardized): 1.080639295917087\n",
      "Epoch: 46, Loss (standarized): 0.9494163961183653\n",
      "          Validation Loss (standardized): 1.0233830511015318\n",
      "Epoch: 51, Loss (standarized): 0.8898748761646524\n",
      "          Validation Loss (standardized): 0.9747364987807892\n",
      "Epoch: 56, Loss (standarized): 0.8302777875212192\n",
      "          Validation Loss (standardized): 0.9304146319872266\n",
      "Epoch: 61, Loss (standarized): 0.7702307811949666\n",
      "          Validation Loss (standardized): 0.8841422001302737\n",
      "Epoch: 66, Loss (standarized): 0.7111815599699327\n",
      "          Validation Loss (standardized): 0.8385015083345945\n",
      "Epoch: 71, Loss (standarized): 0.6549761288491581\n",
      "          Validation Loss (standardized): 0.7934417612768746\n",
      "Epoch: 76, Loss (standarized): 0.6030441509866783\n",
      "          Validation Loss (standardized): 0.7484182965257862\n",
      "Epoch: 81, Loss (standarized): 0.5574579664713168\n",
      "          Validation Loss (standardized): 0.7098568147418329\n",
      "Epoch: 86, Loss (standarized): 0.5173966839142045\n",
      "          Validation Loss (standardized): 0.6782183965337053\n",
      "Epoch: 91, Loss (standarized): 0.4815832576501125\n",
      "          Validation Loss (standardized): 0.6516129403714835\n",
      "Epoch: 96, Loss (standarized): 0.4493248530620005\n",
      "          Validation Loss (standardized): 0.6261115466281985\n",
      "Final epoch: 100, Final loss (standarized): 0.42599847912229594\n",
      "Epoch: 1, Loss (standarized): 1.7480373713536255\n",
      "          Validation Loss (standardized): 1.6568086268432352\n",
      "Epoch: 6, Loss (standarized): 1.3751787837628375\n",
      "          Validation Loss (standardized): 1.4449230510872995\n",
      "Epoch: 11, Loss (standarized): 1.331440201038135\n",
      "          Validation Loss (standardized): 1.3574950242699704\n",
      "Epoch: 16, Loss (standarized): 1.3032306053477074\n",
      "          Validation Loss (standardized): 1.342834315348361\n",
      "Epoch: 21, Loss (standarized): 1.2797035456430135\n",
      "          Validation Loss (standardized): 1.353136396743964\n",
      "Epoch: 26, Loss (standarized): 1.2439250645390971\n",
      "          Validation Loss (standardized): 1.3031542970054089\n",
      "Epoch: 31, Loss (standarized): 1.2014574447501725\n",
      "          Validation Loss (standardized): 1.2443089358926909\n",
      "Epoch: 36, Loss (standarized): 1.1473216288895816\n",
      "          Validation Loss (standardized): 1.2146421482820287\n",
      "Epoch: 41, Loss (standarized): 1.0879722853978384\n",
      "          Validation Loss (standardized): 1.1708511828612223\n",
      "Epoch: 46, Loss (standarized): 1.0237789111107924\n",
      "          Validation Loss (standardized): 1.104471562733092\n",
      "Epoch: 51, Loss (standarized): 0.9600939342923259\n",
      "          Validation Loss (standardized): 1.0560958942366738\n",
      "Epoch: 56, Loss (standarized): 0.8988813196306871\n",
      "          Validation Loss (standardized): 1.0061694251153261\n",
      "Epoch: 61, Loss (standarized): 0.8408666458494386\n",
      "          Validation Loss (standardized): 0.9644491408974546\n",
      "Epoch: 66, Loss (standarized): 0.7869212828985929\n",
      "          Validation Loss (standardized): 0.9261891797235705\n",
      "Epoch: 71, Loss (standarized): 0.7361838211700932\n",
      "          Validation Loss (standardized): 0.8880318397451297\n",
      "Epoch: 76, Loss (standarized): 0.6878539813306075\n",
      "          Validation Loss (standardized): 0.85587252473203\n",
      "Epoch: 81, Loss (standarized): 0.6425484795427749\n",
      "          Validation Loss (standardized): 0.8237650450757342\n",
      "Epoch: 86, Loss (standarized): 0.6006526220365401\n",
      "          Validation Loss (standardized): 0.7960999531209244\n",
      "Epoch: 91, Loss (standarized): 0.5617671117077414\n",
      "          Validation Loss (standardized): 0.7686873262436902\n",
      "Epoch: 96, Loss (standarized): 0.5255244702906814\n",
      "          Validation Loss (standardized): 0.7391451960733784\n",
      "Final epoch: 100, Final loss (standarized): 0.4987175168257696\n",
      "Epoch: 1, Loss (standarized): 1.9493379425521198\n",
      "          Validation Loss (standardized): 1.7380923620236581\n",
      "Epoch: 6, Loss (standarized): 1.4583676747171381\n",
      "          Validation Loss (standardized): 1.4593641609768973\n",
      "Epoch: 11, Loss (standarized): 1.385174493084633\n",
      "          Validation Loss (standardized): 1.4177073526426707\n",
      "Epoch: 16, Loss (standarized): 1.3563251606955884\n",
      "          Validation Loss (standardized): 1.3862256289099582\n",
      "Epoch: 21, Loss (standarized): 1.3480029063750607\n",
      "          Validation Loss (standardized): 1.3843735351176625\n",
      "Epoch: 26, Loss (standarized): 1.3489328612804325\n",
      "          Validation Loss (standardized): 1.39818535220507\n",
      "Epoch: 31, Loss (standarized): 1.3497836812476667\n",
      "          Validation Loss (standardized): 1.4037504823581546\n",
      "Epoch: 36, Loss (standarized): 1.3515575354869087\n",
      "          Validation Loss (standardized): 1.398942402840686\n",
      "Epoch: 41, Loss (standarized): 1.3543911604433232\n",
      "          Validation Loss (standardized): 1.3943416990165969\n",
      "Epoch: 46, Loss (standarized): 1.3555617735531387\n",
      "          Validation Loss (standardized): 1.3978717617850256\n",
      "Epoch: 51, Loss (standarized): 1.3547793629653568\n",
      "          Validation Loss (standardized): 1.4018929931888269\n",
      "Epoch: 56, Loss (standarized): 1.3535151018600735\n",
      "          Validation Loss (standardized): 1.4002770943697587\n",
      "Epoch: 61, Loss (standarized): 1.3517575114020826\n",
      "          Validation Loss (standardized): 1.4002076550847145\n",
      "Epoch: 66, Loss (standarized): 1.3492144382076532\n",
      "          Validation Loss (standardized): 1.3969662088641643\n",
      "Epoch: 71, Loss (standarized): 1.3458847495205288\n",
      "          Validation Loss (standardized): 1.391072879966464\n",
      "Epoch: 76, Loss (standarized): 1.342100488011076\n",
      "          Validation Loss (standardized): 1.3842653929270285\n",
      "Epoch: 81, Loss (standarized): 1.337680464010532\n",
      "          Validation Loss (standardized): 1.3764050640545729\n",
      "Epoch: 86, Loss (standarized): 1.3323799094865922\n",
      "          Validation Loss (standardized): 1.3697873036910866\n",
      "Epoch: 91, Loss (standarized): 1.3272827894076693\n",
      "          Validation Loss (standardized): 1.3643907186610365\n",
      "Epoch: 96, Loss (standarized): 1.321750607511966\n",
      "          Validation Loss (standardized): 1.3587428760023372\n",
      "Final epoch: 100, Final loss (standarized): 1.3170533647069078\n",
      "Epoch: 1, Loss (standarized): 1.5955351344371287\n",
      "          Validation Loss (standardized): 1.5708994258607605\n",
      "Epoch: 6, Loss (standarized): 1.433240646807705\n",
      "          Validation Loss (standardized): 1.467206170375012\n",
      "Epoch: 11, Loss (standarized): 1.381093408096284\n",
      "          Validation Loss (standardized): 1.4284094712082938\n",
      "Epoch: 16, Loss (standarized): 1.3616301026619573\n",
      "          Validation Loss (standardized): 1.4107500439229053\n",
      "Epoch: 21, Loss (standarized): 1.3577298685109769\n",
      "          Validation Loss (standardized): 1.3980523317131814\n",
      "Epoch: 26, Loss (standarized): 1.356351082327413\n",
      "          Validation Loss (standardized): 1.3970276246982343\n",
      "Epoch: 31, Loss (standarized): 1.3555512350429086\n",
      "          Validation Loss (standardized): 1.401255833604167\n",
      "Epoch: 36, Loss (standarized): 1.3545873057720894\n",
      "          Validation Loss (standardized): 1.4008953800570338\n",
      "Epoch: 41, Loss (standarized): 1.3532259061653584\n",
      "          Validation Loss (standardized): 1.3969310157088393\n",
      "Epoch: 46, Loss (standarized): 1.3496288822754385\n",
      "          Validation Loss (standardized): 1.3935241849242326\n",
      "Epoch: 51, Loss (standarized): 1.344736360590162\n",
      "          Validation Loss (standardized): 1.3886584263863693\n",
      "Epoch: 56, Loss (standarized): 1.3401035011615137\n",
      "          Validation Loss (standardized): 1.3805199298120856\n",
      "Epoch: 61, Loss (standarized): 1.3347542971262647\n",
      "          Validation Loss (standardized): 1.3746469202482234\n",
      "Epoch: 66, Loss (standarized): 1.3291709029968815\n",
      "          Validation Loss (standardized): 1.3690849076624094\n",
      "Epoch: 71, Loss (standarized): 1.3225791796112878\n",
      "          Validation Loss (standardized): 1.3614392202665908\n",
      "Epoch: 76, Loss (standarized): 1.3150372875022753\n",
      "          Validation Loss (standardized): 1.3509726834259113\n",
      "Epoch: 81, Loss (standarized): 1.306832225258961\n",
      "          Validation Loss (standardized): 1.3382144495250397\n",
      "Epoch: 86, Loss (standarized): 1.2988452649641926\n",
      "          Validation Loss (standardized): 1.3280678148036829\n",
      "Epoch: 91, Loss (standarized): 1.2913886762274829\n",
      "          Validation Loss (standardized): 1.3207148171382965\n",
      "Epoch: 96, Loss (standarized): 1.2835348187855806\n",
      "          Validation Loss (standardized): 1.307483856761342\n",
      "Final epoch: 100, Final loss (standarized): 1.2777574060536854\n",
      "Epoch: 1, Loss (standarized): 1.6222438030450577\n",
      "          Validation Loss (standardized): 1.6233841999578236\n",
      "Epoch: 6, Loss (standarized): 1.4013373223861516\n",
      "          Validation Loss (standardized): 1.407078071117378\n",
      "Epoch: 11, Loss (standarized): 1.3528022978233134\n",
      "          Validation Loss (standardized): 1.3971577929668626\n",
      "Epoch: 16, Loss (standarized): 1.3379253414163725\n",
      "          Validation Loss (standardized): 1.4023883619682345\n",
      "Epoch: 21, Loss (standarized): 1.3337034720175174\n",
      "          Validation Loss (standardized): 1.3789165277560334\n",
      "Epoch: 26, Loss (standarized): 1.3336745739829718\n",
      "          Validation Loss (standardized): 1.3630066080370906\n",
      "Epoch: 31, Loss (standarized): 1.3301300163005616\n",
      "          Validation Loss (standardized): 1.3623912052516998\n",
      "Epoch: 36, Loss (standarized): 1.325218404996369\n",
      "          Validation Loss (standardized): 1.367030380073921\n",
      "Epoch: 41, Loss (standarized): 1.3203500743338394\n",
      "          Validation Loss (standardized): 1.3654699899350011\n",
      "Epoch: 46, Loss (standarized): 1.3139213282503142\n",
      "          Validation Loss (standardized): 1.3562669177862403\n",
      "Epoch: 51, Loss (standarized): 1.307218145295505\n",
      "          Validation Loss (standardized): 1.3471036675001\n",
      "Epoch: 56, Loss (standarized): 1.3015370920113076\n",
      "          Validation Loss (standardized): 1.3372411191875475\n",
      "Epoch: 61, Loss (standarized): 1.2964898710929242\n",
      "          Validation Loss (standardized): 1.3288186130592585\n",
      "Epoch: 66, Loss (standarized): 1.2915317082595812\n",
      "          Validation Loss (standardized): 1.3165717133294188\n",
      "Epoch: 71, Loss (standarized): 1.2872709323380933\n",
      "          Validation Loss (standardized): 1.309335864449919\n",
      "Epoch: 76, Loss (standarized): 1.2823521519847259\n",
      "          Validation Loss (standardized): 1.3049685788405176\n",
      "Epoch: 81, Loss (standarized): 1.2768283998066738\n",
      "          Validation Loss (standardized): 1.3028870194796875\n",
      "Epoch: 86, Loss (standarized): 1.2712406538528367\n",
      "          Validation Loss (standardized): 1.2963308198424195\n",
      "Epoch: 91, Loss (standarized): 1.2652117815356023\n",
      "          Validation Loss (standardized): 1.2874259425499786\n",
      "Epoch: 96, Loss (standarized): 1.2590755304591243\n",
      "          Validation Loss (standardized): 1.2807428669391943\n",
      "Final epoch: 100, Final loss (standarized): 1.254121860987409\n",
      "Epoch: 1, Loss (standarized): 1.679731111034629\n",
      "          Validation Loss (standardized): 1.5857462012453876\n",
      "Epoch: 6, Loss (standarized): 1.421291152660595\n",
      "          Validation Loss (standardized): 1.4778885363848044\n",
      "Epoch: 11, Loss (standarized): 1.3674863330698872\n",
      "          Validation Loss (standardized): 1.4182432745826523\n",
      "Epoch: 16, Loss (standarized): 1.3458470779274623\n",
      "          Validation Loss (standardized): 1.3721712069689203\n",
      "Epoch: 21, Loss (standarized): 1.3402328999603241\n",
      "          Validation Loss (standardized): 1.3729668560676975\n",
      "Epoch: 26, Loss (standarized): 1.338050097080653\n",
      "          Validation Loss (standardized): 1.386027971779703\n",
      "Epoch: 31, Loss (standarized): 1.3368112336460234\n",
      "          Validation Loss (standardized): 1.3891248194697392\n",
      "Epoch: 36, Loss (standarized): 1.33582886242188\n",
      "          Validation Loss (standardized): 1.386939826538688\n",
      "Epoch: 41, Loss (standarized): 1.3337800491435934\n",
      "          Validation Loss (standardized): 1.3777412525054678\n",
      "Epoch: 46, Loss (standarized): 1.3299691522036694\n",
      "          Validation Loss (standardized): 1.368840882778162\n",
      "Epoch: 51, Loss (standarized): 1.3254462767271349\n",
      "          Validation Loss (standardized): 1.3648694811951334\n",
      "Epoch: 56, Loss (standarized): 1.319605978491373\n",
      "          Validation Loss (standardized): 1.360832287710841\n",
      "Epoch: 61, Loss (standarized): 1.3129509475602814\n",
      "          Validation Loss (standardized): 1.3506006994641526\n",
      "Epoch: 66, Loss (standarized): 1.3061459093376586\n",
      "          Validation Loss (standardized): 1.3373935718631387\n",
      "Epoch: 71, Loss (standarized): 1.2994958184338845\n",
      "          Validation Loss (standardized): 1.3283584908520525\n",
      "Epoch: 76, Loss (standarized): 1.2920161698976713\n",
      "          Validation Loss (standardized): 1.3191987090053758\n",
      "Epoch: 81, Loss (standarized): 1.284679116137771\n",
      "          Validation Loss (standardized): 1.3094064170746578\n",
      "Epoch: 86, Loss (standarized): 1.277838799746995\n",
      "          Validation Loss (standardized): 1.3012584228847763\n",
      "Epoch: 91, Loss (standarized): 1.2712202671994786\n",
      "          Validation Loss (standardized): 1.2904609050204838\n",
      "Epoch: 96, Loss (standarized): 1.2640721628467884\n",
      "          Validation Loss (standardized): 1.2781513472978272\n",
      "Final epoch: 100, Final loss (standarized): 1.2586685710146055\n",
      "Epoch: 1, Loss (standarized): 1.5588156515963383\n",
      "          Validation Loss (standardized): 1.500068340453905\n",
      "Epoch: 6, Loss (standarized): 1.3684981578529092\n",
      "          Validation Loss (standardized): 1.4096480760375436\n",
      "Epoch: 11, Loss (standarized): 1.3066494664316592\n",
      "          Validation Loss (standardized): 1.3548411183586253\n",
      "Epoch: 16, Loss (standarized): 1.2610618815307917\n",
      "          Validation Loss (standardized): 1.2764618105857661\n",
      "Epoch: 21, Loss (standarized): 1.2200320665299154\n",
      "          Validation Loss (standardized): 1.252416558673092\n",
      "Epoch: 26, Loss (standarized): 1.1704635029955004\n",
      "          Validation Loss (standardized): 1.2282361029918585\n",
      "Epoch: 31, Loss (standarized): 1.1186742932701055\n",
      "          Validation Loss (standardized): 1.1739982755258265\n",
      "Epoch: 36, Loss (standarized): 1.0628785921243489\n",
      "          Validation Loss (standardized): 1.129263390148133\n",
      "Epoch: 41, Loss (standarized): 1.0084152419567103\n",
      "          Validation Loss (standardized): 1.076812124005587\n",
      "Epoch: 46, Loss (standarized): 0.9548667693302371\n",
      "          Validation Loss (standardized): 1.0315369012125322\n",
      "Epoch: 51, Loss (standarized): 0.9023775860772989\n",
      "          Validation Loss (standardized): 0.9871353485862726\n",
      "Epoch: 56, Loss (standarized): 0.8495768556515657\n",
      "          Validation Loss (standardized): 0.9468344287875419\n",
      "Epoch: 61, Loss (standarized): 0.795792376005449\n",
      "          Validation Loss (standardized): 0.9077467523386895\n",
      "Epoch: 66, Loss (standarized): 0.7409320783560891\n",
      "          Validation Loss (standardized): 0.8676840204298614\n",
      "Epoch: 71, Loss (standarized): 0.6857308245613961\n",
      "          Validation Loss (standardized): 0.8290076020579338\n",
      "Epoch: 76, Loss (standarized): 0.6319476895430686\n",
      "          Validation Loss (standardized): 0.7891629747397025\n",
      "Epoch: 81, Loss (standarized): 0.5815022640833256\n",
      "          Validation Loss (standardized): 0.7519664554418445\n",
      "Epoch: 86, Loss (standarized): 0.5360585695270487\n",
      "          Validation Loss (standardized): 0.7187185281111168\n",
      "Epoch: 91, Loss (standarized): 0.496588580251994\n",
      "          Validation Loss (standardized): 0.6882041473974257\n",
      "Epoch: 96, Loss (standarized): 0.46302617416896424\n",
      "          Validation Loss (standardized): 0.6630589040859584\n",
      "Final epoch: 100, Final loss (standarized): 0.43976088544524683\n",
      "Epoch: 1, Loss (standarized): 1.735474559171965\n",
      "          Validation Loss (standardized): 1.6235556239310571\n",
      "Epoch: 6, Loss (standarized): 1.3894928531299262\n",
      "          Validation Loss (standardized): 1.445038766019682\n",
      "Epoch: 11, Loss (standarized): 1.3379028399064332\n",
      "          Validation Loss (standardized): 1.4107646522269106\n",
      "Epoch: 16, Loss (standarized): 1.3186547700275246\n",
      "          Validation Loss (standardized): 1.3768436671822772\n",
      "Epoch: 21, Loss (standarized): 1.3030971017159578\n",
      "          Validation Loss (standardized): 1.3509435233806502\n",
      "Epoch: 26, Loss (standarized): 1.2882144300526275\n",
      "          Validation Loss (standardized): 1.3232869129545368\n",
      "Epoch: 31, Loss (standarized): 1.2674166585949913\n",
      "          Validation Loss (standardized): 1.3180845635721865\n",
      "Epoch: 36, Loss (standarized): 1.243403244779366\n",
      "          Validation Loss (standardized): 1.3070455026721455\n",
      "Epoch: 41, Loss (standarized): 1.2143116404549608\n",
      "          Validation Loss (standardized): 1.2731329098048518\n",
      "Epoch: 46, Loss (standarized): 1.1780116067341782\n",
      "          Validation Loss (standardized): 1.2359761138700776\n",
      "Epoch: 51, Loss (standarized): 1.136277390572336\n",
      "          Validation Loss (standardized): 1.1945789601624202\n",
      "Epoch: 56, Loss (standarized): 1.0926395337204549\n",
      "          Validation Loss (standardized): 1.15389391511395\n",
      "Epoch: 61, Loss (standarized): 1.049793927350404\n",
      "          Validation Loss (standardized): 1.1137257430849066\n",
      "Epoch: 66, Loss (standarized): 1.0086292482243582\n",
      "          Validation Loss (standardized): 1.0771615774288066\n",
      "Epoch: 71, Loss (standarized): 0.9696393594197688\n",
      "          Validation Loss (standardized): 1.0455566867588313\n",
      "Epoch: 76, Loss (standarized): 0.9324345002843066\n",
      "          Validation Loss (standardized): 1.0153777472724224\n",
      "Epoch: 81, Loss (standarized): 0.8962567885561654\n",
      "          Validation Loss (standardized): 0.9865480209710104\n",
      "Epoch: 86, Loss (standarized): 0.8602522269642104\n",
      "          Validation Loss (standardized): 0.9573342306642285\n",
      "Epoch: 91, Loss (standarized): 0.8244517072266677\n",
      "          Validation Loss (standardized): 0.9282418280171255\n",
      "Epoch: 96, Loss (standarized): 0.7895364391925334\n",
      "          Validation Loss (standardized): 0.9000722937466193\n",
      "Final epoch: 100, Final loss (standarized): 0.7626508942329228\n",
      "Epoch: 1, Loss (standarized): 1.9495550096626804\n",
      "          Validation Loss (standardized): 1.7662771787847913\n",
      "Epoch: 6, Loss (standarized): 1.4951361973265955\n",
      "          Validation Loss (standardized): 1.4951929873282812\n",
      "Epoch: 11, Loss (standarized): 1.3625741254547892\n",
      "          Validation Loss (standardized): 1.4218824930325569\n",
      "Epoch: 16, Loss (standarized): 1.3282255558627865\n",
      "          Validation Loss (standardized): 1.40353139086027\n",
      "Epoch: 21, Loss (standarized): 1.3011550958431293\n",
      "          Validation Loss (standardized): 1.3676734074634727\n",
      "Epoch: 26, Loss (standarized): 1.2724715207262802\n",
      "          Validation Loss (standardized): 1.3139172685148905\n",
      "Epoch: 31, Loss (standarized): 1.2387032917772025\n",
      "          Validation Loss (standardized): 1.277721848449669\n",
      "Epoch: 36, Loss (standarized): 1.2004865495339767\n",
      "          Validation Loss (standardized): 1.2581356324924582\n",
      "Epoch: 41, Loss (standarized): 1.1587804073210703\n",
      "          Validation Loss (standardized): 1.2231306735815874\n",
      "Epoch: 46, Loss (standarized): 1.114618698620823\n",
      "          Validation Loss (standardized): 1.1745073913308666\n",
      "Epoch: 51, Loss (standarized): 1.0686289539933198\n",
      "          Validation Loss (standardized): 1.1309203742401723\n",
      "Epoch: 56, Loss (standarized): 1.022045829822815\n",
      "          Validation Loss (standardized): 1.0822851461393075\n",
      "Epoch: 61, Loss (standarized): 0.9744325271326363\n",
      "          Validation Loss (standardized): 1.048116315722583\n",
      "Epoch: 66, Loss (standarized): 0.9266424426616601\n",
      "          Validation Loss (standardized): 1.0086766291470444\n",
      "Epoch: 71, Loss (standarized): 0.8798621476663765\n",
      "          Validation Loss (standardized): 0.9732834136699818\n",
      "Epoch: 76, Loss (standarized): 0.8350373187713421\n",
      "          Validation Loss (standardized): 0.9399506364981971\n",
      "Epoch: 81, Loss (standarized): 0.7928955025935605\n",
      "          Validation Loss (standardized): 0.9093292304623315\n",
      "Epoch: 86, Loss (standarized): 0.7533421349143735\n",
      "          Validation Loss (standardized): 0.8824780702345486\n",
      "Epoch: 91, Loss (standarized): 0.7160323991874281\n",
      "          Validation Loss (standardized): 0.8591127685790692\n",
      "Epoch: 96, Loss (standarized): 0.6811592568886289\n",
      "          Validation Loss (standardized): 0.8357663176371375\n",
      "Final epoch: 100, Final loss (standarized): 0.6546668522003103\n",
      "Epoch: 1, Loss (standarized): 1.5544117567909996\n",
      "          Validation Loss (standardized): 1.5395310393699349\n",
      "Epoch: 6, Loss (standarized): 1.3516077543404048\n",
      "          Validation Loss (standardized): 1.3800542813480812\n",
      "Epoch: 11, Loss (standarized): 1.3315488994593487\n",
      "          Validation Loss (standardized): 1.369937524552054\n",
      "Epoch: 16, Loss (standarized): 1.3008978345616993\n",
      "          Validation Loss (standardized): 1.337069988263636\n",
      "Epoch: 21, Loss (standarized): 1.2778831138407047\n",
      "          Validation Loss (standardized): 1.3210964907455487\n",
      "Epoch: 26, Loss (standarized): 1.2469531590442406\n",
      "          Validation Loss (standardized): 1.3175110913250079\n",
      "Epoch: 31, Loss (standarized): 1.2125099416644864\n",
      "          Validation Loss (standardized): 1.2822560268532557\n",
      "Epoch: 36, Loss (standarized): 1.1683708752514614\n",
      "          Validation Loss (standardized): 1.2312310423797588\n",
      "Epoch: 41, Loss (standarized): 1.116632027022296\n",
      "          Validation Loss (standardized): 1.1950790922035148\n",
      "Epoch: 46, Loss (standarized): 1.0604051100327458\n",
      "          Validation Loss (standardized): 1.1343232886471206\n",
      "Epoch: 51, Loss (standarized): 1.00270475455899\n",
      "          Validation Loss (standardized): 1.0850437365137695\n",
      "Epoch: 56, Loss (standarized): 0.9450304239511591\n",
      "          Validation Loss (standardized): 1.0349816184930476\n",
      "Epoch: 61, Loss (standarized): 0.8880978259628821\n",
      "          Validation Loss (standardized): 0.9822849897449949\n",
      "Epoch: 66, Loss (standarized): 0.8318060738330684\n",
      "          Validation Loss (standardized): 0.9357812134223098\n",
      "Epoch: 71, Loss (standarized): 0.7757577992991898\n",
      "          Validation Loss (standardized): 0.8908002615301305\n",
      "Epoch: 76, Loss (standarized): 0.7197640744488558\n",
      "          Validation Loss (standardized): 0.8476919964600992\n",
      "Epoch: 81, Loss (standarized): 0.6649794730263103\n",
      "          Validation Loss (standardized): 0.8064225418421773\n",
      "Epoch: 86, Loss (standarized): 0.6135687563348773\n",
      "          Validation Loss (standardized): 0.7677987850818847\n",
      "Epoch: 91, Loss (standarized): 0.5663485994320363\n",
      "          Validation Loss (standardized): 0.73405189932963\n",
      "Epoch: 96, Loss (standarized): 0.523846176337948\n",
      "          Validation Loss (standardized): 0.7034563831737142\n",
      "Final epoch: 100, Final loss (standarized): 0.49312764029239003\n",
      "Epoch: 1, Loss (standarized): 1.6081391294190563\n",
      "          Validation Loss (standardized): 1.5239043065475695\n",
      "Epoch: 6, Loss (standarized): 1.3627401238643915\n",
      "          Validation Loss (standardized): 1.4255094274581095\n",
      "Epoch: 11, Loss (standarized): 1.3335375123596802\n",
      "          Validation Loss (standardized): 1.4030113909323336\n",
      "Epoch: 16, Loss (standarized): 1.3014482900120734\n",
      "          Validation Loss (standardized): 1.3420833540337835\n",
      "Epoch: 21, Loss (standarized): 1.267101749095177\n",
      "          Validation Loss (standardized): 1.3038907020080446\n",
      "Epoch: 26, Loss (standarized): 1.2181437120302747\n",
      "          Validation Loss (standardized): 1.257506966964014\n",
      "Epoch: 31, Loss (standarized): 1.155480442926336\n",
      "          Validation Loss (standardized): 1.2179966832910458\n",
      "Epoch: 36, Loss (standarized): 1.0795379124932651\n",
      "          Validation Loss (standardized): 1.1479902722587574\n",
      "Epoch: 41, Loss (standarized): 0.9961499169437572\n",
      "          Validation Loss (standardized): 1.0771753115840037\n",
      "Epoch: 46, Loss (standarized): 0.9154257375800399\n",
      "          Validation Loss (standardized): 1.0097468200694721\n",
      "Epoch: 51, Loss (standarized): 0.842002525020687\n",
      "          Validation Loss (standardized): 0.948884486320748\n",
      "Epoch: 56, Loss (standarized): 0.7776224067972768\n",
      "          Validation Loss (standardized): 0.905484316600989\n",
      "Epoch: 61, Loss (standarized): 0.7210232102859016\n",
      "          Validation Loss (standardized): 0.8666392684568409\n",
      "Epoch: 66, Loss (standarized): 0.6701546460945574\n",
      "          Validation Loss (standardized): 0.8324593578497075\n",
      "Epoch: 71, Loss (standarized): 0.6238986555739403\n",
      "          Validation Loss (standardized): 0.7982889050841052\n",
      "Epoch: 76, Loss (standarized): 0.5814711613496601\n",
      "          Validation Loss (standardized): 0.7641521255368878\n",
      "Epoch: 81, Loss (standarized): 0.5422885231423901\n",
      "          Validation Loss (standardized): 0.7395392787508104\n",
      "Epoch: 86, Loss (standarized): 0.5069645636464286\n",
      "          Validation Loss (standardized): 0.7124214175397388\n",
      "Epoch: 91, Loss (standarized): 0.4744305772490101\n",
      "          Validation Loss (standardized): 0.6852117325415101\n",
      "Epoch: 96, Loss (standarized): 0.44548899681452026\n",
      "          Validation Loss (standardized): 0.6636868162542187\n",
      "Final epoch: 100, Final loss (standarized): 0.42445704422848496\n",
      "Epoch: 1, Loss (standarized): 1.6993119727667252\n",
      "          Validation Loss (standardized): 1.6811018698612392\n",
      "Epoch: 6, Loss (standarized): 1.3907516629099268\n",
      "          Validation Loss (standardized): 1.4638196385128317\n",
      "Epoch: 11, Loss (standarized): 1.3362365698708003\n",
      "          Validation Loss (standardized): 1.381067078625375\n",
      "Epoch: 16, Loss (standarized): 1.3173956229933677\n",
      "          Validation Loss (standardized): 1.363262819145189\n",
      "Epoch: 21, Loss (standarized): 1.298388175835975\n",
      "          Validation Loss (standardized): 1.3582529676771107\n",
      "Epoch: 26, Loss (standarized): 1.2769640797976414\n",
      "          Validation Loss (standardized): 1.3289183705097416\n",
      "Epoch: 31, Loss (standarized): 1.2467346004353386\n",
      "          Validation Loss (standardized): 1.2968253062540502\n",
      "Epoch: 36, Loss (standarized): 1.2114954193195595\n",
      "          Validation Loss (standardized): 1.276466208779691\n",
      "Epoch: 41, Loss (standarized): 1.1693687513210864\n",
      "          Validation Loss (standardized): 1.2331634981539814\n",
      "Epoch: 46, Loss (standarized): 1.122204343825481\n",
      "          Validation Loss (standardized): 1.177605158297588\n",
      "Epoch: 51, Loss (standarized): 1.0732847252488198\n",
      "          Validation Loss (standardized): 1.1386013718766466\n",
      "Epoch: 56, Loss (standarized): 1.0252708339341903\n",
      "          Validation Loss (standardized): 1.08794531254708\n",
      "Epoch: 61, Loss (standarized): 0.979082848190822\n",
      "          Validation Loss (standardized): 1.0508939195784919\n",
      "Epoch: 66, Loss (standarized): 0.9350125513701115\n",
      "          Validation Loss (standardized): 1.0128642158914902\n",
      "Epoch: 71, Loss (standarized): 0.8919591902653593\n",
      "          Validation Loss (standardized): 0.9780006563518703\n",
      "Epoch: 76, Loss (standarized): 0.8491421687463853\n",
      "          Validation Loss (standardized): 0.9436670126709\n",
      "Epoch: 81, Loss (standarized): 0.8064481020422894\n",
      "          Validation Loss (standardized): 0.9085883067287405\n",
      "Epoch: 86, Loss (standarized): 0.7639492309006606\n",
      "          Validation Loss (standardized): 0.8754050811934876\n",
      "Epoch: 91, Loss (standarized): 0.7226943659268307\n",
      "          Validation Loss (standardized): 0.8430161653697001\n",
      "Epoch: 96, Loss (standarized): 0.684374849437876\n",
      "          Validation Loss (standardized): 0.811452412350791\n",
      "Final epoch: 100, Final loss (standarized): 0.6566421054382156\n",
      "Epoch: 1, Loss (standarized): 1.737193472286952\n",
      "          Validation Loss (standardized): 1.6421062442777634\n",
      "Epoch: 6, Loss (standarized): 1.4034665425428068\n",
      "          Validation Loss (standardized): 1.4198393622856074\n",
      "Epoch: 11, Loss (standarized): 1.3282975400863029\n",
      "          Validation Loss (standardized): 1.3590366416808888\n",
      "Epoch: 16, Loss (standarized): 1.2950936038321033\n",
      "          Validation Loss (standardized): 1.3111646746000971\n",
      "Epoch: 21, Loss (standarized): 1.2642629043255205\n",
      "          Validation Loss (standardized): 1.310592534892616\n",
      "Epoch: 26, Loss (standarized): 1.2254008455034702\n",
      "          Validation Loss (standardized): 1.2716900598658485\n",
      "Epoch: 31, Loss (standarized): 1.1759227760752708\n",
      "          Validation Loss (standardized): 1.2209638067728896\n",
      "Epoch: 36, Loss (standarized): 1.1166297757299908\n",
      "          Validation Loss (standardized): 1.1711073218324026\n",
      "Epoch: 41, Loss (standarized): 1.0537959351009423\n",
      "          Validation Loss (standardized): 1.1059299042150246\n",
      "Epoch: 46, Loss (standarized): 0.9894379390303746\n",
      "          Validation Loss (standardized): 1.04425347944328\n",
      "Epoch: 51, Loss (standarized): 0.9258175198631682\n",
      "          Validation Loss (standardized): 0.9830943738371462\n",
      "Epoch: 56, Loss (standarized): 0.8629479068232843\n",
      "          Validation Loss (standardized): 0.9349481452999946\n",
      "Epoch: 61, Loss (standarized): 0.8028428163588966\n",
      "          Validation Loss (standardized): 0.8970088948487497\n",
      "Epoch: 66, Loss (standarized): 0.7458835988340747\n",
      "          Validation Loss (standardized): 0.8626381466789339\n",
      "Epoch: 71, Loss (standarized): 0.6923684075567842\n",
      "          Validation Loss (standardized): 0.8260521426192741\n",
      "Epoch: 76, Loss (standarized): 0.6424133659774753\n",
      "          Validation Loss (standardized): 0.7888723873711779\n",
      "Epoch: 81, Loss (standarized): 0.5950943007732961\n",
      "          Validation Loss (standardized): 0.7550605615475197\n",
      "Epoch: 86, Loss (standarized): 0.551119180001013\n",
      "          Validation Loss (standardized): 0.722397853976192\n",
      "Epoch: 91, Loss (standarized): 0.510908642084848\n",
      "          Validation Loss (standardized): 0.6931691869939134\n",
      "Epoch: 96, Loss (standarized): 0.4749714632367783\n",
      "          Validation Loss (standardized): 0.667217482538369\n",
      "Final epoch: 100, Final loss (standarized): 0.44883174178383156\n",
      "Epoch: 1, Loss (standarized): 1.6145438707356556\n",
      "          Validation Loss (standardized): 1.5299215335371983\n",
      "Epoch: 6, Loss (standarized): 1.388194503970418\n",
      "          Validation Loss (standardized): 1.473178305799024\n",
      "Epoch: 11, Loss (standarized): 1.3438282999504079\n",
      "          Validation Loss (standardized): 1.3880140151042653\n",
      "Epoch: 16, Loss (standarized): 1.3210437085201665\n",
      "          Validation Loss (standardized): 1.3567747721554415\n",
      "Epoch: 21, Loss (standarized): 1.302084729818835\n",
      "          Validation Loss (standardized): 1.3512075500042116\n",
      "Epoch: 26, Loss (standarized): 1.2757517941758492\n",
      "          Validation Loss (standardized): 1.3082377062143205\n",
      "Epoch: 31, Loss (standarized): 1.2468679797141669\n",
      "          Validation Loss (standardized): 1.295724626918618\n",
      "Epoch: 36, Loss (standarized): 1.2093041839823746\n",
      "          Validation Loss (standardized): 1.2789916567837372\n",
      "Epoch: 41, Loss (standarized): 1.1617150016517506\n",
      "          Validation Loss (standardized): 1.2224871768072936\n",
      "Epoch: 46, Loss (standarized): 1.1036168736931087\n",
      "          Validation Loss (standardized): 1.1751296554267538\n",
      "Epoch: 51, Loss (standarized): 1.0405545234115556\n",
      "          Validation Loss (standardized): 1.1192725565305903\n",
      "Epoch: 56, Loss (standarized): 0.9777624917580993\n",
      "          Validation Loss (standardized): 1.0618052450428257\n",
      "Epoch: 61, Loss (standarized): 0.9165514886658361\n",
      "          Validation Loss (standardized): 1.0089906235631012\n",
      "Epoch: 66, Loss (standarized): 0.8549226202584435\n",
      "          Validation Loss (standardized): 0.9592114234624659\n",
      "Epoch: 71, Loss (standarized): 0.7919768514195159\n",
      "          Validation Loss (standardized): 0.9091833677762177\n",
      "Epoch: 76, Loss (standarized): 0.7294335407475971\n",
      "          Validation Loss (standardized): 0.8621773804667404\n",
      "Epoch: 81, Loss (standarized): 0.6693968459909541\n",
      "          Validation Loss (standardized): 0.8179075831550585\n",
      "Epoch: 86, Loss (standarized): 0.6125021512338387\n",
      "          Validation Loss (standardized): 0.7744900187947406\n",
      "Epoch: 91, Loss (standarized): 0.5594420561393297\n",
      "          Validation Loss (standardized): 0.7335767003134618\n",
      "Epoch: 96, Loss (standarized): 0.5116360528837001\n",
      "          Validation Loss (standardized): 0.7001717732752976\n",
      "Final epoch: 100, Final loss (standarized): 0.4777107926595626\n",
      "Epoch: 1, Loss (standarized): 1.5835108734101575\n",
      "          Validation Loss (standardized): 1.515300327614138\n",
      "Epoch: 6, Loss (standarized): 1.3625967516110138\n",
      "          Validation Loss (standardized): 1.3884158825007644\n",
      "Epoch: 11, Loss (standarized): 1.3137196946511336\n",
      "          Validation Loss (standardized): 1.3368879295397271\n",
      "Epoch: 16, Loss (standarized): 1.2822204311371381\n",
      "          Validation Loss (standardized): 1.3111872376845572\n",
      "Epoch: 21, Loss (standarized): 1.2488229845876229\n",
      "          Validation Loss (standardized): 1.3074957500582196\n",
      "Epoch: 26, Loss (standarized): 1.2048944397742576\n",
      "          Validation Loss (standardized): 1.2560458027012196\n",
      "Epoch: 31, Loss (standarized): 1.1536312022087625\n",
      "          Validation Loss (standardized): 1.1812413271009212\n",
      "Epoch: 36, Loss (standarized): 1.0936714415394797\n",
      "          Validation Loss (standardized): 1.1403235628254642\n",
      "Epoch: 41, Loss (standarized): 1.0261783449681403\n",
      "          Validation Loss (standardized): 1.0743078325855564\n",
      "Epoch: 46, Loss (standarized): 0.9533477209199063\n",
      "          Validation Loss (standardized): 1.0147980355605\n",
      "Epoch: 51, Loss (standarized): 0.8752234901290921\n",
      "          Validation Loss (standardized): 0.9519521963751779\n",
      "Epoch: 56, Loss (standarized): 0.7951641947688387\n",
      "          Validation Loss (standardized): 0.9005426408043254\n",
      "Epoch: 61, Loss (standarized): 0.7186079980869144\n",
      "          Validation Loss (standardized): 0.845200980260433\n",
      "Epoch: 66, Loss (standarized): 0.6491957258056544\n",
      "          Validation Loss (standardized): 0.7949329910636481\n",
      "Epoch: 71, Loss (standarized): 0.5877638247692393\n",
      "          Validation Loss (standardized): 0.7515722307152103\n",
      "Epoch: 76, Loss (standarized): 0.5344159185943288\n",
      "          Validation Loss (standardized): 0.7176117396145867\n",
      "Epoch: 81, Loss (standarized): 0.4901467367499455\n",
      "          Validation Loss (standardized): 0.6887155351408666\n",
      "Epoch: 86, Loss (standarized): 0.4523739083676984\n",
      "          Validation Loss (standardized): 0.6619195404524548\n",
      "Epoch: 91, Loss (standarized): 0.41989947914731474\n",
      "          Validation Loss (standardized): 0.6402519151932943\n",
      "Epoch: 96, Loss (standarized): 0.39129568548748184\n",
      "          Validation Loss (standardized): 0.6236834536888377\n",
      "Final epoch: 100, Final loss (standarized): 0.37101717719139443\n",
      "Epoch: 1, Loss (standarized): 1.6879695815066775\n",
      "          Validation Loss (standardized): 1.6494167061456737\n",
      "Epoch: 6, Loss (standarized): 1.404096012218318\n",
      "          Validation Loss (standardized): 1.4392870744355533\n",
      "Epoch: 11, Loss (standarized): 1.3458125591181966\n",
      "          Validation Loss (standardized): 1.390604318134006\n",
      "Epoch: 16, Loss (standarized): 1.327713127578615\n",
      "          Validation Loss (standardized): 1.3669670190368115\n",
      "Epoch: 21, Loss (standarized): 1.3117534203961105\n",
      "          Validation Loss (standardized): 1.3470629180269118\n",
      "Epoch: 26, Loss (standarized): 1.2960834794073015\n",
      "          Validation Loss (standardized): 1.344443655924443\n",
      "Epoch: 31, Loss (standarized): 1.2765464754287665\n",
      "          Validation Loss (standardized): 1.3294656958119109\n",
      "Epoch: 36, Loss (standarized): 1.2493263301133226\n",
      "          Validation Loss (standardized): 1.3030800128457647\n",
      "Epoch: 41, Loss (standarized): 1.2127639022455816\n",
      "          Validation Loss (standardized): 1.264933141684788\n",
      "Epoch: 46, Loss (standarized): 1.1673084068099164\n",
      "          Validation Loss (standardized): 1.219843269407022\n",
      "Epoch: 51, Loss (standarized): 1.1167269484694053\n",
      "          Validation Loss (standardized): 1.1743129277628672\n",
      "Epoch: 56, Loss (standarized): 1.0654793928482773\n",
      "          Validation Loss (standardized): 1.1238559724400583\n",
      "Epoch: 61, Loss (standarized): 1.0159026621052205\n",
      "          Validation Loss (standardized): 1.081347081099205\n",
      "Epoch: 66, Loss (standarized): 0.968479314536032\n",
      "          Validation Loss (standardized): 1.0423922819901157\n",
      "Epoch: 71, Loss (standarized): 0.92282821358604\n",
      "          Validation Loss (standardized): 1.0054795814588382\n",
      "Epoch: 76, Loss (standarized): 0.8790476345287342\n",
      "          Validation Loss (standardized): 0.9710001021750029\n",
      "Epoch: 81, Loss (standarized): 0.837898576044649\n",
      "          Validation Loss (standardized): 0.9386334337873845\n",
      "Epoch: 86, Loss (standarized): 0.7994350034875042\n",
      "          Validation Loss (standardized): 0.9081276328000475\n",
      "Epoch: 91, Loss (standarized): 0.7642875432450299\n",
      "          Validation Loss (standardized): 0.8791075951298631\n",
      "Epoch: 96, Loss (standarized): 0.7330006549561097\n",
      "          Validation Loss (standardized): 0.852440966253569\n",
      "Final epoch: 100, Final loss (standarized): 0.7113352947643133\n",
      "Epoch: 1, Loss (standarized): 1.7570628444078829\n",
      "          Validation Loss (standardized): 1.678312772279214\n",
      "Epoch: 6, Loss (standarized): 1.3885340590177901\n",
      "          Validation Loss (standardized): 1.4217063118434838\n",
      "Epoch: 11, Loss (standarized): 1.3352334036371254\n",
      "          Validation Loss (standardized): 1.4037469063671966\n",
      "Epoch: 16, Loss (standarized): 1.3098113863323348\n",
      "          Validation Loss (standardized): 1.3559192318186724\n",
      "Epoch: 21, Loss (standarized): 1.2903438740872872\n",
      "          Validation Loss (standardized): 1.3326039385852324\n",
      "Epoch: 26, Loss (standarized): 1.255591489531529\n",
      "          Validation Loss (standardized): 1.2761935280824723\n",
      "Epoch: 31, Loss (standarized): 1.2160593965495416\n",
      "          Validation Loss (standardized): 1.2705435022001528\n",
      "Epoch: 36, Loss (standarized): 1.1686654941046732\n",
      "          Validation Loss (standardized): 1.2283265102010188\n",
      "Epoch: 41, Loss (standarized): 1.1141138830960378\n",
      "          Validation Loss (standardized): 1.183513135714837\n",
      "Epoch: 46, Loss (standarized): 1.0519860012600675\n",
      "          Validation Loss (standardized): 1.1251010663990615\n",
      "Epoch: 51, Loss (standarized): 0.9874511952123628\n",
      "          Validation Loss (standardized): 1.0720246960344297\n",
      "Epoch: 56, Loss (standarized): 0.9230554262950177\n",
      "          Validation Loss (standardized): 1.0182058032251058\n",
      "Epoch: 61, Loss (standarized): 0.8621526733229575\n",
      "          Validation Loss (standardized): 0.9689744999893917\n",
      "Epoch: 66, Loss (standarized): 0.8056663240968369\n",
      "          Validation Loss (standardized): 0.9222326571050384\n",
      "Epoch: 71, Loss (standarized): 0.7539797733687624\n",
      "          Validation Loss (standardized): 0.8831636532978991\n",
      "Epoch: 76, Loss (standarized): 0.7069084383080698\n",
      "          Validation Loss (standardized): 0.8490550458560137\n",
      "Epoch: 81, Loss (standarized): 0.6636901755227005\n",
      "          Validation Loss (standardized): 0.8183720330696638\n",
      "Epoch: 86, Loss (standarized): 0.6239609684654629\n",
      "          Validation Loss (standardized): 0.7907437774342263\n",
      "Epoch: 91, Loss (standarized): 0.5877395572860665\n",
      "          Validation Loss (standardized): 0.7652336882750846\n",
      "Epoch: 96, Loss (standarized): 0.5548349183400637\n",
      "          Validation Loss (standardized): 0.7417449271362361\n",
      "Final epoch: 100, Final loss (standarized): 0.5306337813964128\n",
      "Epoch: 1, Loss (standarized): 1.7057642038971783\n",
      "          Validation Loss (standardized): 1.6444982964554036\n",
      "Epoch: 6, Loss (standarized): 1.3787245866150943\n",
      "          Validation Loss (standardized): 1.3990081681845676\n",
      "Epoch: 11, Loss (standarized): 1.3521494423806546\n",
      "          Validation Loss (standardized): 1.403923864240946\n",
      "Epoch: 16, Loss (standarized): 1.3243112891028561\n",
      "          Validation Loss (standardized): 1.3801783986426004\n",
      "Epoch: 21, Loss (standarized): 1.2988910035023544\n",
      "          Validation Loss (standardized): 1.3313526449148079\n",
      "Epoch: 26, Loss (standarized): 1.2690131305633126\n",
      "          Validation Loss (standardized): 1.3100003387017227\n",
      "Epoch: 31, Loss (standarized): 1.232062444851334\n",
      "          Validation Loss (standardized): 1.298122972097492\n",
      "Epoch: 36, Loss (standarized): 1.1865398040616457\n",
      "          Validation Loss (standardized): 1.2536210738632179\n",
      "Epoch: 41, Loss (standarized): 1.1357194043461476\n",
      "          Validation Loss (standardized): 1.2044713237440212\n",
      "Epoch: 46, Loss (standarized): 1.0768912519145386\n",
      "          Validation Loss (standardized): 1.156011100184706\n",
      "Epoch: 51, Loss (standarized): 1.0143277979554215\n",
      "          Validation Loss (standardized): 1.0887401332790378\n",
      "Epoch: 56, Loss (standarized): 0.951673400627304\n",
      "          Validation Loss (standardized): 1.0352959655234832\n",
      "Epoch: 61, Loss (standarized): 0.8893856862063976\n",
      "          Validation Loss (standardized): 0.9845030211892886\n",
      "Epoch: 66, Loss (standarized): 0.8273702946221982\n",
      "          Validation Loss (standardized): 0.9410665146939029\n",
      "Epoch: 71, Loss (standarized): 0.7663053727019961\n",
      "          Validation Loss (standardized): 0.8946076665930821\n",
      "Epoch: 76, Loss (standarized): 0.707402049350016\n",
      "          Validation Loss (standardized): 0.8482029180554822\n",
      "Epoch: 81, Loss (standarized): 0.652536848131031\n",
      "          Validation Loss (standardized): 0.8005136716671468\n",
      "Epoch: 86, Loss (standarized): 0.6026292676422706\n",
      "          Validation Loss (standardized): 0.7579261918613522\n",
      "Epoch: 91, Loss (standarized): 0.5576856796577434\n",
      "          Validation Loss (standardized): 0.7224790094763212\n",
      "Epoch: 96, Loss (standarized): 0.5184774813931788\n",
      "          Validation Loss (standardized): 0.6942112738943085\n",
      "Final epoch: 100, Final loss (standarized): 0.49052621478733754\n",
      "Epoch: 1, Loss (standarized): 1.6715857921821982\n",
      "          Validation Loss (standardized): 1.6244515817316287\n",
      "Epoch: 6, Loss (standarized): 1.4051402488260982\n",
      "          Validation Loss (standardized): 1.44742819126096\n",
      "Epoch: 11, Loss (standarized): 1.3495376429511416\n",
      "          Validation Loss (standardized): 1.4028649449428017\n",
      "Epoch: 16, Loss (standarized): 1.3354730495463139\n",
      "          Validation Loss (standardized): 1.3846537983734657\n",
      "Epoch: 21, Loss (standarized): 1.3335188800390767\n",
      "          Validation Loss (standardized): 1.377262207339067\n",
      "Epoch: 26, Loss (standarized): 1.3349441979808256\n",
      "          Validation Loss (standardized): 1.38068354721121\n",
      "Epoch: 31, Loss (standarized): 1.3349133818559564\n",
      "          Validation Loss (standardized): 1.3789030131560063\n",
      "Epoch: 36, Loss (standarized): 1.3338949811263396\n",
      "          Validation Loss (standardized): 1.3714248842168095\n",
      "Epoch: 41, Loss (standarized): 1.3320234794129204\n",
      "          Validation Loss (standardized): 1.3657505740876215\n",
      "Epoch: 46, Loss (standarized): 1.328418592876341\n",
      "          Validation Loss (standardized): 1.3614650857609722\n",
      "Epoch: 51, Loss (standarized): 1.3226321175055005\n",
      "          Validation Loss (standardized): 1.3576090146770197\n",
      "Epoch: 56, Loss (standarized): 1.3158669744443767\n",
      "          Validation Loss (standardized): 1.3482559940372463\n",
      "Epoch: 61, Loss (standarized): 1.3090500441728694\n",
      "          Validation Loss (standardized): 1.3380602391780754\n",
      "Epoch: 66, Loss (standarized): 1.3030337119357767\n",
      "          Validation Loss (standardized): 1.33118095109407\n",
      "Epoch: 71, Loss (standarized): 1.2965932134761635\n",
      "          Validation Loss (standardized): 1.3207980712432736\n",
      "Epoch: 76, Loss (standarized): 1.2900542419662335\n",
      "          Validation Loss (standardized): 1.3103905183172593\n",
      "Epoch: 81, Loss (standarized): 1.283262586375148\n",
      "          Validation Loss (standardized): 1.304518725913346\n",
      "Epoch: 86, Loss (standarized): 1.275824699430374\n",
      "          Validation Loss (standardized): 1.29341144220264\n",
      "Epoch: 91, Loss (standarized): 1.2682052637841488\n",
      "          Validation Loss (standardized): 1.2818288574728771\n",
      "Epoch: 96, Loss (standarized): 1.2605930262210192\n",
      "          Validation Loss (standardized): 1.270376884155677\n",
      "Final epoch: 100, Final loss (standarized): 1.254798100485643\n",
      "Epoch: 1, Loss (standarized): 1.7918743228192076\n",
      "          Validation Loss (standardized): 1.7085419366609536\n",
      "Epoch: 6, Loss (standarized): 1.558832375338077\n",
      "          Validation Loss (standardized): 1.5451452996854236\n",
      "Epoch: 11, Loss (standarized): 1.454358110944084\n",
      "          Validation Loss (standardized): 1.475747023924856\n",
      "Epoch: 16, Loss (standarized): 1.396359508283797\n",
      "          Validation Loss (standardized): 1.424208969456759\n",
      "Epoch: 21, Loss (standarized): 1.3697240589633042\n",
      "          Validation Loss (standardized): 1.404016094935828\n",
      "Epoch: 26, Loss (standarized): 1.36058896185435\n",
      "          Validation Loss (standardized): 1.4036658161681717\n",
      "Epoch: 31, Loss (standarized): 1.3615842374310858\n",
      "          Validation Loss (standardized): 1.4071744276607216\n",
      "Epoch: 36, Loss (standarized): 1.364994941034919\n",
      "          Validation Loss (standardized): 1.4110097584985528\n",
      "Epoch: 41, Loss (standarized): 1.3655062331552972\n",
      "          Validation Loss (standardized): 1.4086545794448662\n",
      "Epoch: 46, Loss (standarized): 1.3655378833005434\n",
      "          Validation Loss (standardized): 1.4120138324559794\n",
      "Epoch: 51, Loss (standarized): 1.3654555180412355\n",
      "          Validation Loss (standardized): 1.4146953319266\n",
      "Epoch: 56, Loss (standarized): 1.3649545306024475\n",
      "          Validation Loss (standardized): 1.4116530282969046\n",
      "Epoch: 61, Loss (standarized): 1.3638858864120338\n",
      "          Validation Loss (standardized): 1.40881303527886\n",
      "Epoch: 66, Loss (standarized): 1.362352458496051\n",
      "          Validation Loss (standardized): 1.4082059505368671\n",
      "Epoch: 71, Loss (standarized): 1.3614692467965746\n",
      "          Validation Loss (standardized): 1.4055293985974764\n",
      "Epoch: 76, Loss (standarized): 1.3596386609702602\n",
      "          Validation Loss (standardized): 1.4086536752066767\n",
      "Epoch: 81, Loss (standarized): 1.3573241752741216\n",
      "          Validation Loss (standardized): 1.4037363414841375\n",
      "Epoch: 86, Loss (standarized): 1.3537954159951646\n",
      "          Validation Loss (standardized): 1.3979161057044989\n",
      "Epoch: 91, Loss (standarized): 1.3501111336817044\n",
      "          Validation Loss (standardized): 1.3955102175788228\n",
      "Epoch: 96, Loss (standarized): 1.3459349292654617\n",
      "          Validation Loss (standardized): 1.3902975386145193\n",
      "Final epoch: 100, Final loss (standarized): 1.3415506832951387\n",
      "Epoch: 1, Loss (standarized): 1.5889869260421607\n",
      "          Validation Loss (standardized): 1.5305085492557513\n",
      "Epoch: 6, Loss (standarized): 1.4030512083815296\n",
      "          Validation Loss (standardized): 1.4357663367687488\n",
      "Epoch: 11, Loss (standarized): 1.3544685617774945\n",
      "          Validation Loss (standardized): 1.3954531202172928\n",
      "Epoch: 16, Loss (standarized): 1.3424684304116852\n",
      "          Validation Loss (standardized): 1.3777551308013039\n",
      "Epoch: 21, Loss (standarized): 1.342323232044922\n",
      "          Validation Loss (standardized): 1.3804494265042104\n",
      "Epoch: 26, Loss (standarized): 1.345222940444035\n",
      "          Validation Loss (standardized): 1.3878506545413631\n",
      "Epoch: 31, Loss (standarized): 1.3477112390251784\n",
      "          Validation Loss (standardized): 1.3914393974346435\n",
      "Epoch: 36, Loss (standarized): 1.3474968075436484\n",
      "          Validation Loss (standardized): 1.3897931729398658\n",
      "Epoch: 41, Loss (standarized): 1.3429129145634675\n",
      "          Validation Loss (standardized): 1.3838268728964342\n",
      "Epoch: 46, Loss (standarized): 1.3364777813748157\n",
      "          Validation Loss (standardized): 1.374450181729765\n",
      "Epoch: 51, Loss (standarized): 1.3310474868314741\n",
      "          Validation Loss (standardized): 1.3664394940314573\n",
      "Epoch: 56, Loss (standarized): 1.32601544312994\n",
      "          Validation Loss (standardized): 1.3588465139878667\n",
      "Epoch: 61, Loss (standarized): 1.3205437191859488\n",
      "          Validation Loss (standardized): 1.3530039949304127\n",
      "Epoch: 66, Loss (standarized): 1.314609519613037\n",
      "          Validation Loss (standardized): 1.3453041677676347\n",
      "Epoch: 71, Loss (standarized): 1.3080773485456267\n",
      "          Validation Loss (standardized): 1.335569736361231\n",
      "Epoch: 76, Loss (standarized): 1.300378698989442\n",
      "          Validation Loss (standardized): 1.3231525444664873\n",
      "Epoch: 81, Loss (standarized): 1.2935678456130484\n",
      "          Validation Loss (standardized): 1.3119680665671487\n",
      "Epoch: 86, Loss (standarized): 1.2877322054745224\n",
      "          Validation Loss (standardized): 1.3056566918183095\n",
      "Epoch: 91, Loss (standarized): 1.2811287298530454\n",
      "          Validation Loss (standardized): 1.2964847625762428\n",
      "Epoch: 96, Loss (standarized): 1.2745845925511596\n",
      "          Validation Loss (standardized): 1.2896824378385303\n",
      "Final epoch: 100, Final loss (standarized): 1.2695473468702212\n",
      "Epoch: 1, Loss (standarized): 1.5679197509005625\n",
      "          Validation Loss (standardized): 1.554176207735607\n",
      "Epoch: 6, Loss (standarized): 1.3782824456749325\n",
      "          Validation Loss (standardized): 1.4267871771090546\n",
      "Epoch: 11, Loss (standarized): 1.3346603818661862\n",
      "          Validation Loss (standardized): 1.383276585214635\n",
      "Epoch: 16, Loss (standarized): 1.328300409430782\n",
      "          Validation Loss (standardized): 1.3670529566624923\n",
      "Epoch: 21, Loss (standarized): 1.3271566953771605\n",
      "          Validation Loss (standardized): 1.3583070288516184\n",
      "Epoch: 26, Loss (standarized): 1.3290552037598287\n",
      "          Validation Loss (standardized): 1.3631318048352055\n",
      "Epoch: 31, Loss (standarized): 1.3310910245380023\n",
      "          Validation Loss (standardized): 1.367826079560402\n",
      "Epoch: 36, Loss (standarized): 1.3293746464047462\n",
      "          Validation Loss (standardized): 1.3659572811101666\n",
      "Epoch: 41, Loss (standarized): 1.3242005411523392\n",
      "          Validation Loss (standardized): 1.365015597696445\n",
      "Epoch: 46, Loss (standarized): 1.316004455864158\n",
      "          Validation Loss (standardized): 1.3550552557631308\n",
      "Epoch: 51, Loss (standarized): 1.3073336620652634\n",
      "          Validation Loss (standardized): 1.339102103645082\n",
      "Epoch: 56, Loss (standarized): 1.2989706485696033\n",
      "          Validation Loss (standardized): 1.3245693496890298\n",
      "Epoch: 61, Loss (standarized): 1.289840138675447\n",
      "          Validation Loss (standardized): 1.3106961995072195\n",
      "Epoch: 66, Loss (standarized): 1.2795836259226476\n",
      "          Validation Loss (standardized): 1.2979604989022835\n",
      "Epoch: 71, Loss (standarized): 1.268281478154706\n",
      "          Validation Loss (standardized): 1.2822241112764414\n",
      "Epoch: 76, Loss (standarized): 1.2555844081802545\n",
      "          Validation Loss (standardized): 1.2653351323045587\n",
      "Epoch: 81, Loss (standarized): 1.2414681269966366\n",
      "          Validation Loss (standardized): 1.2485003534505135\n",
      "Epoch: 86, Loss (standarized): 1.2252224484645944\n",
      "          Validation Loss (standardized): 1.2344449616903026\n",
      "Epoch: 91, Loss (standarized): 1.2071456339462385\n",
      "          Validation Loss (standardized): 1.2231570785726602\n",
      "Epoch: 96, Loss (standarized): 1.1866918770942458\n",
      "          Validation Loss (standardized): 1.1995769660649072\n",
      "Final epoch: 100, Final loss (standarized): 1.169261252912272\n",
      "Epoch: 1, Loss (standarized): 1.7432897537802459\n",
      "          Validation Loss (standardized): 1.6719227137489905\n",
      "Epoch: 6, Loss (standarized): 1.4329961805758777\n",
      "          Validation Loss (standardized): 1.450303284669733\n",
      "Epoch: 11, Loss (standarized): 1.346635000831655\n",
      "          Validation Loss (standardized): 1.3642116194185996\n",
      "Epoch: 16, Loss (standarized): 1.3210987234382716\n",
      "          Validation Loss (standardized): 1.3565713822725702\n",
      "Epoch: 21, Loss (standarized): 1.29473743700896\n",
      "          Validation Loss (standardized): 1.3417469871053718\n",
      "Epoch: 26, Loss (standarized): 1.258340102003285\n",
      "          Validation Loss (standardized): 1.3052241474296862\n",
      "Epoch: 31, Loss (standarized): 1.211982259441851\n",
      "          Validation Loss (standardized): 1.2545496292168052\n",
      "Epoch: 36, Loss (standarized): 1.1595082531711376\n",
      "          Validation Loss (standardized): 1.2076492610347769\n",
      "Epoch: 41, Loss (standarized): 1.102967766959622\n",
      "          Validation Loss (standardized): 1.1645751311893142\n",
      "Epoch: 46, Loss (standarized): 1.046362358767493\n",
      "          Validation Loss (standardized): 1.1121531084599443\n",
      "Epoch: 51, Loss (standarized): 0.9932728880756244\n",
      "          Validation Loss (standardized): 1.0666236261379287\n",
      "Epoch: 56, Loss (standarized): 0.9422233578088156\n",
      "          Validation Loss (standardized): 1.0289043887556117\n",
      "Epoch: 61, Loss (standarized): 0.8914389080103129\n",
      "          Validation Loss (standardized): 0.9901939504161417\n",
      "Epoch: 66, Loss (standarized): 0.8404302033187301\n",
      "          Validation Loss (standardized): 0.9564319183484112\n",
      "Epoch: 71, Loss (standarized): 0.7893320010228868\n",
      "          Validation Loss (standardized): 0.9142272615458614\n",
      "Epoch: 76, Loss (standarized): 0.738333709152138\n",
      "          Validation Loss (standardized): 0.8753313550419164\n",
      "Epoch: 81, Loss (standarized): 0.689946605958135\n",
      "          Validation Loss (standardized): 0.8375383388077985\n",
      "Epoch: 86, Loss (standarized): 0.6443079969069716\n",
      "          Validation Loss (standardized): 0.8052564130136283\n",
      "Epoch: 91, Loss (standarized): 0.6024653738854205\n",
      "          Validation Loss (standardized): 0.7758185219207698\n",
      "Epoch: 96, Loss (standarized): 0.5644388883640922\n",
      "          Validation Loss (standardized): 0.7462612857789972\n",
      "Final epoch: 100, Final loss (standarized): 0.5366420921213796\n",
      "Epoch: 1, Loss (standarized): 1.7423617324397411\n",
      "          Validation Loss (standardized): 1.6095709725332497\n",
      "Epoch: 6, Loss (standarized): 1.4738874006184792\n",
      "          Validation Loss (standardized): 1.4893354940560035\n",
      "Epoch: 11, Loss (standarized): 1.3808695225306697\n",
      "          Validation Loss (standardized): 1.4252283425801116\n",
      "Epoch: 16, Loss (standarized): 1.3391862501424925\n",
      "          Validation Loss (standardized): 1.3892326327864002\n",
      "Epoch: 21, Loss (standarized): 1.3194577101223603\n",
      "          Validation Loss (standardized): 1.381215525824858\n",
      "Epoch: 26, Loss (standarized): 1.3029700979692793\n",
      "          Validation Loss (standardized): 1.3490772011533818\n",
      "Epoch: 31, Loss (standarized): 1.2839954884299238\n",
      "          Validation Loss (standardized): 1.323031261858613\n",
      "Epoch: 36, Loss (standarized): 1.263008124298199\n",
      "          Validation Loss (standardized): 1.3215665166695412\n",
      "Epoch: 41, Loss (standarized): 1.2379517866368064\n",
      "          Validation Loss (standardized): 1.2954374780611038\n",
      "Epoch: 46, Loss (standarized): 1.2059291944303434\n",
      "          Validation Loss (standardized): 1.2587881167145092\n",
      "Epoch: 51, Loss (standarized): 1.1668385810966162\n",
      "          Validation Loss (standardized): 1.2270827275075586\n",
      "Epoch: 56, Loss (standarized): 1.1229469327851662\n",
      "          Validation Loss (standardized): 1.174070537769449\n",
      "Epoch: 61, Loss (standarized): 1.0765314742208534\n",
      "          Validation Loss (standardized): 1.1339385138597304\n",
      "Epoch: 66, Loss (standarized): 1.029207046338067\n",
      "          Validation Loss (standardized): 1.087292010354774\n",
      "Epoch: 71, Loss (standarized): 0.9832118723250506\n",
      "          Validation Loss (standardized): 1.0459682218708044\n",
      "Epoch: 76, Loss (standarized): 0.940495798519489\n",
      "          Validation Loss (standardized): 1.01095144799786\n",
      "Epoch: 81, Loss (standarized): 0.9019208266573336\n",
      "          Validation Loss (standardized): 0.9801946607759858\n",
      "Epoch: 86, Loss (standarized): 0.8674023734221643\n",
      "          Validation Loss (standardized): 0.9513001221025686\n",
      "Epoch: 91, Loss (standarized): 0.8363795692943076\n",
      "          Validation Loss (standardized): 0.9262700852688844\n",
      "Epoch: 96, Loss (standarized): 0.8082891119293191\n",
      "          Validation Loss (standardized): 0.9032910813308039\n",
      "Final epoch: 100, Final loss (standarized): 0.7877313257491798\n",
      "Epoch: 1, Loss (standarized): 1.6536829138775295\n",
      "          Validation Loss (standardized): 1.5579164526578237\n",
      "Epoch: 6, Loss (standarized): 1.3904526374643877\n",
      "          Validation Loss (standardized): 1.4337994671407992\n",
      "Epoch: 11, Loss (standarized): 1.3495548844248293\n",
      "          Validation Loss (standardized): 1.4339402147085387\n",
      "Epoch: 16, Loss (standarized): 1.3271640288461837\n",
      "          Validation Loss (standardized): 1.3963011067253523\n",
      "Epoch: 21, Loss (standarized): 1.3106661397788353\n",
      "          Validation Loss (standardized): 1.3487416509625432\n",
      "Epoch: 26, Loss (standarized): 1.2892837854516512\n",
      "          Validation Loss (standardized): 1.3285801578704097\n",
      "Epoch: 31, Loss (standarized): 1.2604036588989804\n",
      "          Validation Loss (standardized): 1.3249789549758342\n",
      "Epoch: 36, Loss (standarized): 1.2253453803272807\n",
      "          Validation Loss (standardized): 1.2939313361928466\n",
      "Epoch: 41, Loss (standarized): 1.1811409978144534\n",
      "          Validation Loss (standardized): 1.241610589369612\n",
      "Epoch: 46, Loss (standarized): 1.1271424639776881\n",
      "          Validation Loss (standardized): 1.2062741386681954\n",
      "Epoch: 51, Loss (standarized): 1.0664171437506458\n",
      "          Validation Loss (standardized): 1.14840620668399\n",
      "Epoch: 56, Loss (standarized): 1.0041767237361645\n",
      "          Validation Loss (standardized): 1.0977109180189315\n",
      "Epoch: 61, Loss (standarized): 0.9419207922973767\n",
      "          Validation Loss (standardized): 1.0416078560575792\n",
      "Epoch: 66, Loss (standarized): 0.8799975586220953\n",
      "          Validation Loss (standardized): 0.9844917798927886\n",
      "Epoch: 71, Loss (standarized): 0.8209414837966368\n",
      "          Validation Loss (standardized): 0.9341952556609435\n",
      "Epoch: 76, Loss (standarized): 0.7661490677004685\n",
      "          Validation Loss (standardized): 0.8865557786533114\n",
      "Epoch: 81, Loss (standarized): 0.7158389809508354\n",
      "          Validation Loss (standardized): 0.8440926254550077\n",
      "Epoch: 86, Loss (standarized): 0.6705464872636437\n",
      "          Validation Loss (standardized): 0.8066798779370181\n",
      "Epoch: 91, Loss (standarized): 0.6298592124894246\n",
      "          Validation Loss (standardized): 0.77301737674505\n",
      "Epoch: 96, Loss (standarized): 0.5927009984796647\n",
      "          Validation Loss (standardized): 0.7435876755147076\n",
      "Final epoch: 100, Final loss (standarized): 0.5650979189451596\n",
      "Epoch: 1, Loss (standarized): 1.6329499254784037\n",
      "          Validation Loss (standardized): 1.5684110852254862\n",
      "Epoch: 6, Loss (standarized): 1.3727193135229203\n",
      "          Validation Loss (standardized): 1.411270430678703\n",
      "Epoch: 11, Loss (standarized): 1.318486193692209\n",
      "          Validation Loss (standardized): 1.3954193382549218\n",
      "Epoch: 16, Loss (standarized): 1.27986641108175\n",
      "          Validation Loss (standardized): 1.3313758646842793\n",
      "Epoch: 21, Loss (standarized): 1.2410068096997109\n",
      "          Validation Loss (standardized): 1.2818345120709402\n",
      "Epoch: 26, Loss (standarized): 1.189340755625667\n",
      "          Validation Loss (standardized): 1.2550898624795142\n",
      "Epoch: 31, Loss (standarized): 1.1285711930889994\n",
      "          Validation Loss (standardized): 1.1931094572588663\n",
      "Epoch: 36, Loss (standarized): 1.0599650674481949\n",
      "          Validation Loss (standardized): 1.1262625752848816\n",
      "Epoch: 41, Loss (standarized): 0.9905048757269994\n",
      "          Validation Loss (standardized): 1.0551772659716798\n",
      "Epoch: 46, Loss (standarized): 0.9234534658656116\n",
      "          Validation Loss (standardized): 1.0046645687017646\n",
      "Epoch: 51, Loss (standarized): 0.8592401830039137\n",
      "          Validation Loss (standardized): 0.9507411064932046\n",
      "Epoch: 56, Loss (standarized): 0.7981823521711715\n",
      "          Validation Loss (standardized): 0.8991653516849328\n",
      "Epoch: 61, Loss (standarized): 0.7412435653367698\n",
      "          Validation Loss (standardized): 0.8565281357488805\n",
      "Epoch: 66, Loss (standarized): 0.6877725265820867\n",
      "          Validation Loss (standardized): 0.8165624916901959\n",
      "Epoch: 71, Loss (standarized): 0.638837826676388\n",
      "          Validation Loss (standardized): 0.7812036722641839\n",
      "Epoch: 76, Loss (standarized): 0.5944621910370061\n",
      "          Validation Loss (standardized): 0.7500566267613412\n",
      "Epoch: 81, Loss (standarized): 0.5545592550949675\n",
      "          Validation Loss (standardized): 0.722261405947742\n",
      "Epoch: 86, Loss (standarized): 0.5193885381828225\n",
      "          Validation Loss (standardized): 0.7009048658187205\n",
      "Epoch: 91, Loss (standarized): 0.48874543858590624\n",
      "          Validation Loss (standardized): 0.6825659602677185\n",
      "Epoch: 96, Loss (standarized): 0.4621006513022162\n",
      "          Validation Loss (standardized): 0.6664716886331841\n",
      "Final epoch: 100, Final loss (standarized): 0.4430411763083258\n",
      "Epoch: 1, Loss (standarized): 1.5639653177872532\n",
      "          Validation Loss (standardized): 1.5534771692376503\n",
      "Epoch: 6, Loss (standarized): 1.4029376441393362\n",
      "          Validation Loss (standardized): 1.4333348665621537\n",
      "Epoch: 11, Loss (standarized): 1.3184138586392748\n",
      "          Validation Loss (standardized): 1.3591033113654267\n",
      "Epoch: 16, Loss (standarized): 1.2631421533490188\n",
      "          Validation Loss (standardized): 1.3081989480053746\n",
      "Epoch: 21, Loss (standarized): 1.2043528335818445\n",
      "          Validation Loss (standardized): 1.2470528120292097\n",
      "Epoch: 26, Loss (standarized): 1.1392037452978871\n",
      "          Validation Loss (standardized): 1.1828903445651735\n",
      "Epoch: 31, Loss (standarized): 1.0753819311746315\n",
      "          Validation Loss (standardized): 1.1330954824420352\n",
      "Epoch: 36, Loss (standarized): 1.0111364735178032\n",
      "          Validation Loss (standardized): 1.0768772557059085\n",
      "Epoch: 41, Loss (standarized): 0.9468022888333022\n",
      "          Validation Loss (standardized): 1.0156346133688503\n",
      "Epoch: 46, Loss (standarized): 0.8833444333997132\n",
      "          Validation Loss (standardized): 0.9567846700850229\n",
      "Epoch: 51, Loss (standarized): 0.8197647013439419\n",
      "          Validation Loss (standardized): 0.9033516923195787\n",
      "Epoch: 56, Loss (standarized): 0.758043706625774\n",
      "          Validation Loss (standardized): 0.8512400490506323\n",
      "Epoch: 61, Loss (standarized): 0.6996226983318382\n",
      "          Validation Loss (standardized): 0.8024006950542527\n",
      "Epoch: 66, Loss (standarized): 0.6437142572353727\n",
      "          Validation Loss (standardized): 0.7618702109560908\n",
      "Epoch: 71, Loss (standarized): 0.5906675778399173\n",
      "          Validation Loss (standardized): 0.7268331336947037\n",
      "Epoch: 76, Loss (standarized): 0.5416751396228627\n",
      "          Validation Loss (standardized): 0.6977548677585219\n",
      "Epoch: 81, Loss (standarized): 0.49785505688159865\n",
      "          Validation Loss (standardized): 0.6712074569378245\n",
      "Epoch: 86, Loss (standarized): 0.4586516582580967\n",
      "          Validation Loss (standardized): 0.6462043976518368\n",
      "Epoch: 91, Loss (standarized): 0.42316246246425004\n",
      "          Validation Loss (standardized): 0.6228380041205717\n",
      "Epoch: 96, Loss (standarized): 0.3912213512880006\n",
      "          Validation Loss (standardized): 0.5969349784235598\n",
      "Final epoch: 100, Final loss (standarized): 0.3681418349319408\n",
      "Epoch: 1, Loss (standarized): 1.7731508163546843\n",
      "          Validation Loss (standardized): 1.6934491894977515\n",
      "Epoch: 6, Loss (standarized): 1.4346011794700624\n",
      "          Validation Loss (standardized): 1.4411565597061005\n",
      "Epoch: 11, Loss (standarized): 1.3388489325177455\n",
      "          Validation Loss (standardized): 1.4089844625254633\n",
      "Epoch: 16, Loss (standarized): 1.3021305124974827\n",
      "          Validation Loss (standardized): 1.3720177830122569\n",
      "Epoch: 21, Loss (standarized): 1.2680411745393356\n",
      "          Validation Loss (standardized): 1.3243111883877845\n",
      "Epoch: 26, Loss (standarized): 1.2406758931731723\n",
      "          Validation Loss (standardized): 1.2986299565118635\n",
      "Epoch: 31, Loss (standarized): 1.2052958331435413\n",
      "          Validation Loss (standardized): 1.274555456824181\n",
      "Epoch: 36, Loss (standarized): 1.16919410194072\n",
      "          Validation Loss (standardized): 1.2414515600232034\n",
      "Epoch: 41, Loss (standarized): 1.1322291838438885\n",
      "          Validation Loss (standardized): 1.2016699558719226\n",
      "Epoch: 46, Loss (standarized): 1.0938926735685064\n",
      "          Validation Loss (standardized): 1.16474923689858\n",
      "Epoch: 51, Loss (standarized): 1.054552570658231\n",
      "          Validation Loss (standardized): 1.1289822098490996\n",
      "Epoch: 56, Loss (standarized): 1.0146014455763597\n",
      "          Validation Loss (standardized): 1.092926568365378\n",
      "Epoch: 61, Loss (standarized): 0.9738427069242794\n",
      "          Validation Loss (standardized): 1.0557119687291023\n",
      "Epoch: 66, Loss (standarized): 0.9325092030679238\n",
      "          Validation Loss (standardized): 1.022068786120283\n",
      "Epoch: 71, Loss (standarized): 0.891831563989432\n",
      "          Validation Loss (standardized): 0.9894289281510384\n",
      "Epoch: 76, Loss (standarized): 0.8527728757708829\n",
      "          Validation Loss (standardized): 0.9599579649048591\n",
      "Epoch: 81, Loss (standarized): 0.8160515451636663\n",
      "          Validation Loss (standardized): 0.9326083984544113\n",
      "Epoch: 86, Loss (standarized): 0.7819372511005828\n",
      "          Validation Loss (standardized): 0.9056865798961347\n",
      "Epoch: 91, Loss (standarized): 0.7506909353556557\n",
      "          Validation Loss (standardized): 0.8799533803211225\n",
      "Epoch: 96, Loss (standarized): 0.7222972979540936\n",
      "          Validation Loss (standardized): 0.855022967732762\n",
      "Final epoch: 100, Final loss (standarized): 0.7015063456434865\n",
      "Epoch: 1, Loss (standarized): 1.7734230364970518\n",
      "          Validation Loss (standardized): 1.6928410664552511\n",
      "Epoch: 6, Loss (standarized): 1.4615703867792116\n",
      "          Validation Loss (standardized): 1.4510344383901157\n",
      "Epoch: 11, Loss (standarized): 1.349072751663116\n",
      "          Validation Loss (standardized): 1.4097845735881005\n",
      "Epoch: 16, Loss (standarized): 1.2968761312669994\n",
      "          Validation Loss (standardized): 1.3530108335055584\n",
      "Epoch: 21, Loss (standarized): 1.2550602465051925\n",
      "          Validation Loss (standardized): 1.309845711975128\n",
      "Epoch: 26, Loss (standarized): 1.2134392764235464\n",
      "          Validation Loss (standardized): 1.268633676796297\n",
      "Epoch: 31, Loss (standarized): 1.1644034686283016\n",
      "          Validation Loss (standardized): 1.2437187944166317\n",
      "Epoch: 36, Loss (standarized): 1.1088746077226128\n",
      "          Validation Loss (standardized): 1.195062368800118\n",
      "Epoch: 41, Loss (standarized): 1.0456839004947103\n",
      "          Validation Loss (standardized): 1.130645528009526\n",
      "Epoch: 46, Loss (standarized): 0.9786511991709073\n",
      "          Validation Loss (standardized): 1.0701822957943674\n",
      "Epoch: 51, Loss (standarized): 0.9106482285019214\n",
      "          Validation Loss (standardized): 1.0111397867193834\n",
      "Epoch: 56, Loss (standarized): 0.8449611509561228\n",
      "          Validation Loss (standardized): 0.9561436674919541\n",
      "Epoch: 61, Loss (standarized): 0.7853149585876796\n",
      "          Validation Loss (standardized): 0.9069410780305034\n",
      "Epoch: 66, Loss (standarized): 0.7331360081352867\n",
      "          Validation Loss (standardized): 0.8647658840117698\n",
      "Epoch: 71, Loss (standarized): 0.6869621741709864\n",
      "          Validation Loss (standardized): 0.830896332786606\n",
      "Epoch: 76, Loss (standarized): 0.6463361297004243\n",
      "          Validation Loss (standardized): 0.8031129430089721\n",
      "Epoch: 81, Loss (standarized): 0.6098197114118004\n",
      "          Validation Loss (standardized): 0.779453501480281\n",
      "Epoch: 86, Loss (standarized): 0.5767011063211273\n",
      "          Validation Loss (standardized): 0.7601773465529428\n",
      "Epoch: 91, Loss (standarized): 0.5465466699203587\n",
      "          Validation Loss (standardized): 0.7408685933411201\n",
      "Epoch: 96, Loss (standarized): 0.5188993623572404\n",
      "          Validation Loss (standardized): 0.7224509246282812\n",
      "Final epoch: 100, Final loss (standarized): 0.4984290969134834\n",
      "Epoch: 1, Loss (standarized): 1.6933831192893087\n",
      "          Validation Loss (standardized): 1.6447849852614134\n",
      "Epoch: 6, Loss (standarized): 1.4579535800993915\n",
      "          Validation Loss (standardized): 1.4739682051976\n",
      "Epoch: 11, Loss (standarized): 1.3463494639415399\n",
      "          Validation Loss (standardized): 1.3768736192414726\n",
      "Epoch: 16, Loss (standarized): 1.3134295636339306\n",
      "          Validation Loss (standardized): 1.31805909428678\n",
      "Epoch: 21, Loss (standarized): 1.2819028164549713\n",
      "          Validation Loss (standardized): 1.3067649245707067\n",
      "Epoch: 26, Loss (standarized): 1.236219352374296\n",
      "          Validation Loss (standardized): 1.278760780516711\n",
      "Epoch: 31, Loss (standarized): 1.1811113445691972\n",
      "          Validation Loss (standardized): 1.217982305947458\n",
      "Epoch: 36, Loss (standarized): 1.11975776221079\n",
      "          Validation Loss (standardized): 1.1800409606148607\n",
      "Epoch: 41, Loss (standarized): 1.05774998217373\n",
      "          Validation Loss (standardized): 1.1254724523577002\n",
      "Epoch: 46, Loss (standarized): 0.9960111531303779\n",
      "          Validation Loss (standardized): 1.0702235390876944\n",
      "Epoch: 51, Loss (standarized): 0.9352548203987741\n",
      "          Validation Loss (standardized): 1.0221266502921966\n",
      "Epoch: 56, Loss (standarized): 0.8741770915494905\n",
      "          Validation Loss (standardized): 0.9791172003069469\n",
      "Epoch: 61, Loss (standarized): 0.8110158862543253\n",
      "          Validation Loss (standardized): 0.9350324864244146\n",
      "Epoch: 66, Loss (standarized): 0.7484546983098171\n",
      "          Validation Loss (standardized): 0.8884141487036861\n",
      "Epoch: 71, Loss (standarized): 0.6889359132510129\n",
      "          Validation Loss (standardized): 0.8390754724288555\n",
      "Epoch: 76, Loss (standarized): 0.6326377226412311\n",
      "          Validation Loss (standardized): 0.7917509269660377\n",
      "Epoch: 81, Loss (standarized): 0.5792392945940626\n",
      "          Validation Loss (standardized): 0.7490980670895374\n",
      "Epoch: 86, Loss (standarized): 0.5299401468953445\n",
      "          Validation Loss (standardized): 0.7051224797130916\n",
      "Epoch: 91, Loss (standarized): 0.48552667673956973\n",
      "          Validation Loss (standardized): 0.6679698563253541\n",
      "Epoch: 96, Loss (standarized): 0.4444797589098879\n",
      "          Validation Loss (standardized): 0.6346775816195684\n",
      "Final epoch: 100, Final loss (standarized): 0.4141875626345234\n",
      "Epoch: 1, Loss (standarized): 1.7108092036880396\n",
      "          Validation Loss (standardized): 1.5821225009392286\n",
      "Epoch: 6, Loss (standarized): 1.3987642605245754\n",
      "          Validation Loss (standardized): 1.465391778608267\n",
      "Epoch: 11, Loss (standarized): 1.3477593493821325\n",
      "          Validation Loss (standardized): 1.3943350889413348\n",
      "Epoch: 16, Loss (standarized): 1.3230193400909056\n",
      "          Validation Loss (standardized): 1.3796211610996416\n",
      "Epoch: 21, Loss (standarized): 1.3021678401620562\n",
      "          Validation Loss (standardized): 1.3660096178384098\n",
      "Epoch: 26, Loss (standarized): 1.2697100032390702\n",
      "          Validation Loss (standardized): 1.3168011940806559\n",
      "Epoch: 31, Loss (standarized): 1.2311455842108694\n",
      "          Validation Loss (standardized): 1.3008645178171512\n",
      "Epoch: 36, Loss (standarized): 1.1828651274851119\n",
      "          Validation Loss (standardized): 1.2599070024175685\n",
      "Epoch: 41, Loss (standarized): 1.1238085290947886\n",
      "          Validation Loss (standardized): 1.1931949795658952\n",
      "Epoch: 46, Loss (standarized): 1.0560630212255293\n",
      "          Validation Loss (standardized): 1.1388608081105438\n",
      "Epoch: 51, Loss (standarized): 0.9885028625548662\n",
      "          Validation Loss (standardized): 1.077826397652816\n",
      "Epoch: 56, Loss (standarized): 0.9262282585468753\n",
      "          Validation Loss (standardized): 1.0267508860358772\n",
      "Epoch: 61, Loss (standarized): 0.8694425186512337\n",
      "          Validation Loss (standardized): 0.98768750099468\n",
      "Epoch: 66, Loss (standarized): 0.8157622410036811\n",
      "          Validation Loss (standardized): 0.9518560766210692\n",
      "Epoch: 71, Loss (standarized): 0.7630602891895759\n",
      "          Validation Loss (standardized): 0.9146378907074197\n",
      "Epoch: 76, Loss (standarized): 0.7109992263912482\n",
      "          Validation Loss (standardized): 0.87731351171778\n",
      "Epoch: 81, Loss (standarized): 0.6601745624541536\n",
      "          Validation Loss (standardized): 0.8388568459721332\n",
      "Epoch: 86, Loss (standarized): 0.6110661976777335\n",
      "          Validation Loss (standardized): 0.8036663857161671\n",
      "Epoch: 91, Loss (standarized): 0.5640503729508768\n",
      "          Validation Loss (standardized): 0.7714617101103792\n",
      "Epoch: 96, Loss (standarized): 0.5204809015775771\n",
      "          Validation Loss (standardized): 0.7399804082612295\n",
      "Final epoch: 100, Final loss (standarized): 0.4889875487396215\n",
      "Epoch: 1, Loss (standarized): 1.7450801454069063\n",
      "          Validation Loss (standardized): 1.5786271103098843\n",
      "Epoch: 6, Loss (standarized): 1.392300475686435\n",
      "          Validation Loss (standardized): 1.4223055220977279\n",
      "Epoch: 11, Loss (standarized): 1.3456266649401323\n",
      "          Validation Loss (standardized): 1.378271656464003\n",
      "Epoch: 16, Loss (standarized): 1.3202903728587307\n",
      "          Validation Loss (standardized): 1.3389123782041092\n",
      "Epoch: 21, Loss (standarized): 1.313808754553907\n",
      "          Validation Loss (standardized): 1.3432479980465823\n",
      "Epoch: 26, Loss (standarized): 1.2971703597882884\n",
      "          Validation Loss (standardized): 1.345271459495424\n",
      "Epoch: 31, Loss (standarized): 1.2814802113425825\n",
      "          Validation Loss (standardized): 1.325615017530157\n",
      "Epoch: 36, Loss (standarized): 1.2636701682041216\n",
      "          Validation Loss (standardized): 1.3034033406150005\n",
      "Epoch: 41, Loss (standarized): 1.241433648074376\n",
      "          Validation Loss (standardized): 1.288293365135933\n",
      "Epoch: 46, Loss (standarized): 1.2118075947248341\n",
      "          Validation Loss (standardized): 1.2648733302052078\n",
      "Epoch: 51, Loss (standarized): 1.1730898646909984\n",
      "          Validation Loss (standardized): 1.2273588565951798\n",
      "Epoch: 56, Loss (standarized): 1.1247989785405037\n",
      "          Validation Loss (standardized): 1.1847168165797732\n",
      "Epoch: 61, Loss (standarized): 1.0708553149487994\n",
      "          Validation Loss (standardized): 1.1334084421256763\n",
      "Epoch: 66, Loss (standarized): 1.0176042391560816\n",
      "          Validation Loss (standardized): 1.0816664381017416\n",
      "Epoch: 71, Loss (standarized): 0.9684931075861501\n",
      "          Validation Loss (standardized): 1.034037119699112\n",
      "Epoch: 76, Loss (standarized): 0.923312559479159\n",
      "          Validation Loss (standardized): 0.9955808213053897\n",
      "Epoch: 81, Loss (standarized): 0.8820074358467884\n",
      "          Validation Loss (standardized): 0.961656823431296\n",
      "Epoch: 86, Loss (standarized): 0.8447172934972512\n",
      "          Validation Loss (standardized): 0.9333517445273016\n",
      "Epoch: 91, Loss (standarized): 0.8108736391131549\n",
      "          Validation Loss (standardized): 0.9072829644819674\n",
      "Epoch: 96, Loss (standarized): 0.7798584139723598\n",
      "          Validation Loss (standardized): 0.8825363831688836\n",
      "Final epoch: 100, Final loss (standarized): 0.7567652624917419\n",
      "Epoch: 1, Loss (standarized): 1.794660099383985\n",
      "          Validation Loss (standardized): 1.645690357266026\n",
      "Epoch: 6, Loss (standarized): 1.4433644580088383\n",
      "          Validation Loss (standardized): 1.4740134231172226\n",
      "Epoch: 11, Loss (standarized): 1.3581397040120584\n",
      "          Validation Loss (standardized): 1.4337702218480795\n",
      "Epoch: 16, Loss (standarized): 1.325444241392288\n",
      "          Validation Loss (standardized): 1.375268402553043\n",
      "Epoch: 21, Loss (standarized): 1.3073924562287822\n",
      "          Validation Loss (standardized): 1.3423594659599185\n",
      "Epoch: 26, Loss (standarized): 1.2837270274095818\n",
      "          Validation Loss (standardized): 1.3080969478862794\n",
      "Epoch: 31, Loss (standarized): 1.2541686836798334\n",
      "          Validation Loss (standardized): 1.291126511896538\n",
      "Epoch: 36, Loss (standarized): 1.2147749916446908\n",
      "          Validation Loss (standardized): 1.270142664777502\n",
      "Epoch: 41, Loss (standarized): 1.1702758738290353\n",
      "          Validation Loss (standardized): 1.2113891424075518\n",
      "Epoch: 46, Loss (standarized): 1.120129356072046\n",
      "          Validation Loss (standardized): 1.1704099496205476\n",
      "Epoch: 51, Loss (standarized): 1.065686695842874\n",
      "          Validation Loss (standardized): 1.1220056872717072\n",
      "Epoch: 56, Loss (standarized): 1.00985353525181\n",
      "          Validation Loss (standardized): 1.0627613020626163\n",
      "Epoch: 61, Loss (standarized): 0.9544588991071477\n",
      "          Validation Loss (standardized): 1.017177019251787\n",
      "Epoch: 66, Loss (standarized): 0.8993383709561725\n",
      "          Validation Loss (standardized): 0.9737344397000954\n",
      "Epoch: 71, Loss (standarized): 0.8445539221393773\n",
      "          Validation Loss (standardized): 0.9327578855889245\n",
      "Epoch: 76, Loss (standarized): 0.7902654257453858\n",
      "          Validation Loss (standardized): 0.8893965338699745\n",
      "Epoch: 81, Loss (standarized): 0.7387181913741849\n",
      "          Validation Loss (standardized): 0.846858929745305\n",
      "Epoch: 86, Loss (standarized): 0.6919467053268302\n",
      "          Validation Loss (standardized): 0.8114240692088119\n",
      "Epoch: 91, Loss (standarized): 0.6488655851247691\n",
      "          Validation Loss (standardized): 0.779263827738394\n",
      "Epoch: 96, Loss (standarized): 0.6091537944907257\n",
      "          Validation Loss (standardized): 0.7498223764668271\n",
      "Final epoch: 100, Final loss (standarized): 0.5793921208575682\n",
      "Epoch: 1, Loss (standarized): 1.7388802110460844\n",
      "          Validation Loss (standardized): 1.600285978454298\n",
      "Epoch: 6, Loss (standarized): 1.4025340610440225\n",
      "          Validation Loss (standardized): 1.4842955217602332\n",
      "Epoch: 11, Loss (standarized): 1.3503286975747033\n",
      "          Validation Loss (standardized): 1.4237244640693294\n",
      "Epoch: 16, Loss (standarized): 1.313732271075491\n",
      "          Validation Loss (standardized): 1.3593622910844416\n",
      "Epoch: 21, Loss (standarized): 1.2825202466312635\n",
      "          Validation Loss (standardized): 1.339774731540833\n",
      "Epoch: 26, Loss (standarized): 1.245574272158879\n",
      "          Validation Loss (standardized): 1.294730295410416\n",
      "Epoch: 31, Loss (standarized): 1.1972864767890798\n",
      "          Validation Loss (standardized): 1.2509658683904459\n",
      "Epoch: 36, Loss (standarized): 1.1389965191457367\n",
      "          Validation Loss (standardized): 1.2117966647474705\n",
      "Epoch: 41, Loss (standarized): 1.0715483687211234\n",
      "          Validation Loss (standardized): 1.1488086455348887\n",
      "Epoch: 46, Loss (standarized): 1.0006998807369545\n",
      "          Validation Loss (standardized): 1.0865146172790292\n",
      "Epoch: 51, Loss (standarized): 0.9297559344195728\n",
      "          Validation Loss (standardized): 1.0241725230256242\n",
      "Epoch: 56, Loss (standarized): 0.8637365590528807\n",
      "          Validation Loss (standardized): 0.9742265560084168\n",
      "Epoch: 61, Loss (standarized): 0.8020612435085929\n",
      "          Validation Loss (standardized): 0.9189415854695935\n",
      "Epoch: 66, Loss (standarized): 0.7444931409466252\n",
      "          Validation Loss (standardized): 0.8737335700241876\n",
      "Epoch: 71, Loss (standarized): 0.6895598753299476\n",
      "          Validation Loss (standardized): 0.8329696894051165\n",
      "Epoch: 76, Loss (standarized): 0.6380117717531395\n",
      "          Validation Loss (standardized): 0.7931423264614834\n",
      "Epoch: 81, Loss (standarized): 0.5909790278438503\n",
      "          Validation Loss (standardized): 0.7569404486417414\n",
      "Epoch: 86, Loss (standarized): 0.5483141314050689\n",
      "          Validation Loss (standardized): 0.7248569495145685\n",
      "Epoch: 91, Loss (standarized): 0.5094654961286599\n",
      "          Validation Loss (standardized): 0.6949783064658837\n",
      "Epoch: 96, Loss (standarized): 0.47426762944590684\n",
      "          Validation Loss (standardized): 0.6680062483147123\n",
      "Final epoch: 100, Final loss (standarized): 0.44879453647618367\n",
      "Epoch: 1, Loss (standarized): 1.5273148011357183\n",
      "          Validation Loss (standardized): 1.5128944027810503\n",
      "Epoch: 6, Loss (standarized): 1.3727373837361652\n",
      "          Validation Loss (standardized): 1.4318090011368063\n",
      "Epoch: 11, Loss (standarized): 1.3475520657163087\n",
      "          Validation Loss (standardized): 1.4002512814369457\n",
      "Epoch: 16, Loss (standarized): 1.3390725847376814\n",
      "          Validation Loss (standardized): 1.37337308235797\n",
      "Epoch: 21, Loss (standarized): 1.3375949648623413\n",
      "          Validation Loss (standardized): 1.3725362517049602\n",
      "Epoch: 26, Loss (standarized): 1.3371416046348024\n",
      "          Validation Loss (standardized): 1.383455554457352\n",
      "Epoch: 31, Loss (standarized): 1.336178891101207\n",
      "          Validation Loss (standardized): 1.38993572237328\n",
      "Epoch: 36, Loss (standarized): 1.3336247058435686\n",
      "          Validation Loss (standardized): 1.3852769691284326\n",
      "Epoch: 41, Loss (standarized): 1.3292921982095123\n",
      "          Validation Loss (standardized): 1.375176447387048\n",
      "Epoch: 46, Loss (standarized): 1.3239222785674138\n",
      "          Validation Loss (standardized): 1.3589250087972944\n",
      "Epoch: 51, Loss (standarized): 1.3186275344909182\n",
      "          Validation Loss (standardized): 1.3513959008174206\n",
      "Epoch: 56, Loss (standarized): 1.3129828364121523\n",
      "          Validation Loss (standardized): 1.3492158955722406\n",
      "Epoch: 61, Loss (standarized): 1.3068204056090575\n",
      "          Validation Loss (standardized): 1.338787072279392\n",
      "Epoch: 66, Loss (standarized): 1.301140571444358\n",
      "          Validation Loss (standardized): 1.3293704715942594\n",
      "Epoch: 71, Loss (standarized): 1.2950751217919174\n",
      "          Validation Loss (standardized): 1.3205950587496464\n",
      "Epoch: 76, Loss (standarized): 1.2878785368418113\n",
      "          Validation Loss (standardized): 1.3131133898420726\n",
      "Epoch: 81, Loss (standarized): 1.280307537694149\n",
      "          Validation Loss (standardized): 1.30401259410497\n",
      "Epoch: 86, Loss (standarized): 1.2712122842238667\n",
      "          Validation Loss (standardized): 1.2934712691937749\n",
      "Epoch: 91, Loss (standarized): 1.261164050328415\n",
      "          Validation Loss (standardized): 1.2811838278216001\n",
      "Epoch: 96, Loss (standarized): 1.2510163092780027\n",
      "          Validation Loss (standardized): 1.269788694916488\n",
      "Final epoch: 100, Final loss (standarized): 1.2429378091691472\n",
      "Epoch: 1, Loss (standarized): 1.7355874589314775\n",
      "          Validation Loss (standardized): 1.6366534951938478\n",
      "Epoch: 6, Loss (standarized): 1.5240777843739266\n",
      "          Validation Loss (standardized): 1.5129192121397068\n",
      "Epoch: 11, Loss (standarized): 1.4403161725728189\n",
      "          Validation Loss (standardized): 1.4574135441242138\n",
      "Epoch: 16, Loss (standarized): 1.3903562355822248\n",
      "          Validation Loss (standardized): 1.4147242711820764\n",
      "Epoch: 21, Loss (standarized): 1.362122048243837\n",
      "          Validation Loss (standardized): 1.4030508820396157\n",
      "Epoch: 26, Loss (standarized): 1.3518880650937906\n",
      "          Validation Loss (standardized): 1.398916377942987\n",
      "Epoch: 31, Loss (standarized): 1.3500906524673524\n",
      "          Validation Loss (standardized): 1.390460373440915\n",
      "Epoch: 36, Loss (standarized): 1.350961900840926\n",
      "          Validation Loss (standardized): 1.3918404551743124\n",
      "Epoch: 41, Loss (standarized): 1.3534624635068815\n",
      "          Validation Loss (standardized): 1.3996757209508448\n",
      "Epoch: 46, Loss (standarized): 1.3547924135156382\n",
      "          Validation Loss (standardized): 1.4020076635187022\n",
      "Epoch: 51, Loss (standarized): 1.354313736330368\n",
      "          Validation Loss (standardized): 1.404449986599739\n",
      "Epoch: 56, Loss (standarized): 1.3519843697652707\n",
      "          Validation Loss (standardized): 1.3983945785343086\n",
      "Epoch: 61, Loss (standarized): 1.345826772728222\n",
      "          Validation Loss (standardized): 1.3875923647070207\n",
      "Epoch: 66, Loss (standarized): 1.3380942443910828\n",
      "          Validation Loss (standardized): 1.3795062037384274\n",
      "Epoch: 71, Loss (standarized): 1.3292876650723306\n",
      "          Validation Loss (standardized): 1.3658351517604375\n",
      "Epoch: 76, Loss (standarized): 1.3212191827684623\n",
      "          Validation Loss (standardized): 1.3563183590059575\n",
      "Epoch: 81, Loss (standarized): 1.31354479452943\n",
      "          Validation Loss (standardized): 1.3471624032347824\n",
      "Epoch: 86, Loss (standarized): 1.3060478683788994\n",
      "          Validation Loss (standardized): 1.337436576854005\n",
      "Epoch: 91, Loss (standarized): 1.2991158284133615\n",
      "          Validation Loss (standardized): 1.3247077493335204\n",
      "Epoch: 96, Loss (standarized): 1.2930038038053708\n",
      "          Validation Loss (standardized): 1.3143011705838425\n",
      "Final epoch: 100, Final loss (standarized): 1.2889168298879903\n",
      "Epoch: 1, Loss (standarized): 1.736808384099063\n",
      "          Validation Loss (standardized): 1.664596310477142\n",
      "Epoch: 6, Loss (standarized): 1.4223051263321655\n",
      "          Validation Loss (standardized): 1.434024353005756\n",
      "Epoch: 11, Loss (standarized): 1.364766614973027\n",
      "          Validation Loss (standardized): 1.392219707668672\n",
      "Epoch: 16, Loss (standarized): 1.3431341028449975\n",
      "          Validation Loss (standardized): 1.38349481757206\n",
      "Epoch: 21, Loss (standarized): 1.3399477818455034\n",
      "          Validation Loss (standardized): 1.3796763583417206\n",
      "Epoch: 26, Loss (standarized): 1.3396429411847672\n",
      "          Validation Loss (standardized): 1.3770383062788336\n",
      "Epoch: 31, Loss (standarized): 1.3399810667757779\n",
      "          Validation Loss (standardized): 1.380070517543441\n",
      "Epoch: 36, Loss (standarized): 1.3408744318444445\n",
      "          Validation Loss (standardized): 1.3843472043950051\n",
      "Epoch: 41, Loss (standarized): 1.3405088966850713\n",
      "          Validation Loss (standardized): 1.3841241938398228\n",
      "Epoch: 46, Loss (standarized): 1.339647084356725\n",
      "          Validation Loss (standardized): 1.3857956418082444\n",
      "Epoch: 51, Loss (standarized): 1.3373101136384227\n",
      "          Validation Loss (standardized): 1.3811980119314111\n",
      "Epoch: 56, Loss (standarized): 1.3340086690950215\n",
      "          Validation Loss (standardized): 1.373959546210659\n",
      "Epoch: 61, Loss (standarized): 1.3297229573940603\n",
      "          Validation Loss (standardized): 1.3673026109439814\n",
      "Epoch: 66, Loss (standarized): 1.324681603677027\n",
      "          Validation Loss (standardized): 1.3586093232221013\n",
      "Epoch: 71, Loss (standarized): 1.319277337891891\n",
      "          Validation Loss (standardized): 1.3494710304844826\n",
      "Epoch: 76, Loss (standarized): 1.3136730334589948\n",
      "          Validation Loss (standardized): 1.3418011589586558\n",
      "Epoch: 81, Loss (standarized): 1.3084312624162318\n",
      "          Validation Loss (standardized): 1.3370218039120667\n",
      "Epoch: 86, Loss (standarized): 1.3033830921717344\n",
      "          Validation Loss (standardized): 1.3312727810939473\n",
      "Epoch: 91, Loss (standarized): 1.297425998198371\n",
      "          Validation Loss (standardized): 1.3271282626934422\n",
      "Epoch: 96, Loss (standarized): 1.2920665430078966\n",
      "          Validation Loss (standardized): 1.319067604494809\n",
      "Final epoch: 100, Final loss (standarized): 1.287883485734779\n",
      "Epoch: 1, Loss (standarized): 1.5483014502574202\n",
      "          Validation Loss (standardized): 1.5310314071622628\n",
      "Epoch: 6, Loss (standarized): 1.3688904846348373\n",
      "          Validation Loss (standardized): 1.4112951004241059\n",
      "Epoch: 11, Loss (standarized): 1.3455923671202694\n",
      "          Validation Loss (standardized): 1.3821295703576524\n",
      "Epoch: 16, Loss (standarized): 1.3438036148321162\n",
      "          Validation Loss (standardized): 1.3888119608565612\n",
      "Epoch: 21, Loss (standarized): 1.3461737034065513\n",
      "          Validation Loss (standardized): 1.4009646398004973\n",
      "Epoch: 26, Loss (standarized): 1.3453606890326575\n",
      "          Validation Loss (standardized): 1.3980253978887596\n",
      "Epoch: 31, Loss (standarized): 1.346862534263307\n",
      "          Validation Loss (standardized): 1.3924746588932895\n",
      "Epoch: 36, Loss (standarized): 1.3490125616085349\n",
      "          Validation Loss (standardized): 1.3959690050207898\n",
      "Epoch: 41, Loss (standarized): 1.3489264301760673\n",
      "          Validation Loss (standardized): 1.3981320984164214\n",
      "Epoch: 46, Loss (standarized): 1.3447178373998303\n",
      "          Validation Loss (standardized): 1.3937030904396934\n",
      "Epoch: 51, Loss (standarized): 1.3384681324769216\n",
      "          Validation Loss (standardized): 1.3842429805828442\n",
      "Epoch: 56, Loss (standarized): 1.3317805103543157\n",
      "          Validation Loss (standardized): 1.3744505708836643\n",
      "Epoch: 61, Loss (standarized): 1.324552919072225\n",
      "          Validation Loss (standardized): 1.3627846392160206\n",
      "Epoch: 66, Loss (standarized): 1.3169590396630446\n",
      "          Validation Loss (standardized): 1.3512585113216447\n",
      "Epoch: 71, Loss (standarized): 1.308679207867692\n",
      "          Validation Loss (standardized): 1.3374913732440232\n",
      "Epoch: 76, Loss (standarized): 1.2991293974824023\n",
      "          Validation Loss (standardized): 1.3259848477198781\n",
      "Epoch: 81, Loss (standarized): 1.289317516603017\n",
      "          Validation Loss (standardized): 1.313275760496935\n",
      "Epoch: 86, Loss (standarized): 1.2790911004948962\n",
      "          Validation Loss (standardized): 1.299510918463352\n",
      "Epoch: 91, Loss (standarized): 1.2686786620985802\n",
      "          Validation Loss (standardized): 1.28940181364601\n",
      "Epoch: 96, Loss (standarized): 1.2579617493231063\n",
      "          Validation Loss (standardized): 1.2745938193079493\n",
      "Final epoch: 100, Final loss (standarized): 1.2495630092113055\n",
      "Epoch: 1, Loss (standarized): 1.6325812874566394\n",
      "          Validation Loss (standardized): 1.5785477861688078\n",
      "Epoch: 6, Loss (standarized): 1.3637479314918302\n",
      "          Validation Loss (standardized): 1.4002301683887337\n",
      "Epoch: 11, Loss (standarized): 1.3134469722796127\n",
      "          Validation Loss (standardized): 1.367752385694238\n",
      "Epoch: 16, Loss (standarized): 1.2741203942937926\n",
      "          Validation Loss (standardized): 1.3030268265073046\n",
      "Epoch: 21, Loss (standarized): 1.2396943636718492\n",
      "          Validation Loss (standardized): 1.2789772933463053\n",
      "Epoch: 26, Loss (standarized): 1.1952065965249148\n",
      "          Validation Loss (standardized): 1.2470292419509852\n",
      "Epoch: 31, Loss (standarized): 1.1446103991368823\n",
      "          Validation Loss (standardized): 1.2047913607026624\n",
      "Epoch: 36, Loss (standarized): 1.0881943418123656\n",
      "          Validation Loss (standardized): 1.163467374693123\n",
      "Epoch: 41, Loss (standarized): 1.0291510313573011\n",
      "          Validation Loss (standardized): 1.1049934631002958\n",
      "Epoch: 46, Loss (standarized): 0.9722741780244596\n",
      "          Validation Loss (standardized): 1.0602193656282817\n",
      "Epoch: 51, Loss (standarized): 0.9173722185241457\n",
      "          Validation Loss (standardized): 1.004868503695371\n",
      "Epoch: 56, Loss (standarized): 0.8637465495360621\n",
      "          Validation Loss (standardized): 0.9616232539065743\n",
      "Epoch: 61, Loss (standarized): 0.8116171973028835\n",
      "          Validation Loss (standardized): 0.9192206771588408\n",
      "Epoch: 66, Loss (standarized): 0.7612088121100029\n",
      "          Validation Loss (standardized): 0.8780467217831992\n",
      "Epoch: 71, Loss (standarized): 0.7117750704830353\n",
      "          Validation Loss (standardized): 0.8414702217919279\n",
      "Epoch: 76, Loss (standarized): 0.6631452245989428\n",
      "          Validation Loss (standardized): 0.8047638279313915\n",
      "Epoch: 81, Loss (standarized): 0.6159468409221291\n",
      "          Validation Loss (standardized): 0.7687450980171158\n",
      "Epoch: 86, Loss (standarized): 0.5709783549933601\n",
      "          Validation Loss (standardized): 0.7323494280635846\n",
      "Epoch: 91, Loss (standarized): 0.5297559408120356\n",
      "          Validation Loss (standardized): 0.6994314722472715\n",
      "Epoch: 96, Loss (standarized): 0.4930352387026972\n",
      "          Validation Loss (standardized): 0.6693913707642466\n",
      "Final epoch: 100, Final loss (standarized): 0.46664084199089007\n",
      "Epoch: 1, Loss (standarized): 1.645849536748994\n",
      "          Validation Loss (standardized): 1.5799440368790811\n",
      "Epoch: 6, Loss (standarized): 1.3610197657447807\n",
      "          Validation Loss (standardized): 1.404128009638318\n",
      "Epoch: 11, Loss (standarized): 1.3235886671387271\n",
      "          Validation Loss (standardized): 1.3633778554694014\n",
      "Epoch: 16, Loss (standarized): 1.308780468275321\n",
      "          Validation Loss (standardized): 1.3458874790975384\n",
      "Epoch: 21, Loss (standarized): 1.2930976347755763\n",
      "          Validation Loss (standardized): 1.3375005029891018\n",
      "Epoch: 26, Loss (standarized): 1.2770943344452323\n",
      "          Validation Loss (standardized): 1.3352091319796044\n",
      "Epoch: 31, Loss (standarized): 1.2619565466713407\n",
      "          Validation Loss (standardized): 1.324680995695546\n",
      "Epoch: 36, Loss (standarized): 1.2426358704608704\n",
      "          Validation Loss (standardized): 1.3081239283424784\n",
      "Epoch: 41, Loss (standarized): 1.215629590683696\n",
      "          Validation Loss (standardized): 1.2799224218059198\n",
      "Epoch: 46, Loss (standarized): 1.1827961850655293\n",
      "          Validation Loss (standardized): 1.2507649148030227\n",
      "Epoch: 51, Loss (standarized): 1.1442718960191007\n",
      "          Validation Loss (standardized): 1.2127176078299648\n",
      "Epoch: 56, Loss (standarized): 1.1028271654605921\n",
      "          Validation Loss (standardized): 1.1742239678557294\n",
      "Epoch: 61, Loss (standarized): 1.062348027267683\n",
      "          Validation Loss (standardized): 1.1324673914095156\n",
      "Epoch: 66, Loss (standarized): 1.0243081556637683\n",
      "          Validation Loss (standardized): 1.0977904656791317\n",
      "Epoch: 71, Loss (standarized): 0.990276977890749\n",
      "          Validation Loss (standardized): 1.06408988378864\n",
      "Epoch: 76, Loss (standarized): 0.9595537237657851\n",
      "          Validation Loss (standardized): 1.038982661355623\n",
      "Epoch: 81, Loss (standarized): 0.9318591424994814\n",
      "          Validation Loss (standardized): 1.015824650096577\n",
      "Epoch: 86, Loss (standarized): 0.9062322407044645\n",
      "          Validation Loss (standardized): 0.9952842326986973\n",
      "Epoch: 91, Loss (standarized): 0.8818380677921773\n",
      "          Validation Loss (standardized): 0.9770061897479378\n",
      "Epoch: 96, Loss (standarized): 0.8583222614549575\n",
      "          Validation Loss (standardized): 0.9590104137069781\n",
      "Final epoch: 100, Final loss (standarized): 0.8399355597746165\n",
      "Epoch: 1, Loss (standarized): 1.7754887185281272\n",
      "          Validation Loss (standardized): 1.6426610722185386\n",
      "Epoch: 6, Loss (standarized): 1.4066059676310678\n",
      "          Validation Loss (standardized): 1.4288748424065993\n",
      "Epoch: 11, Loss (standarized): 1.345463727094737\n",
      "          Validation Loss (standardized): 1.396608318167756\n",
      "Epoch: 16, Loss (standarized): 1.3257366267267108\n",
      "          Validation Loss (standardized): 1.3778940832278759\n",
      "Epoch: 21, Loss (standarized): 1.3065416751677876\n",
      "          Validation Loss (standardized): 1.3589922414048012\n",
      "Epoch: 26, Loss (standarized): 1.2873761773080354\n",
      "          Validation Loss (standardized): 1.3315297202853575\n",
      "Epoch: 31, Loss (standarized): 1.2610143586820448\n",
      "          Validation Loss (standardized): 1.3058078970911915\n",
      "Epoch: 36, Loss (standarized): 1.2265519934771298\n",
      "          Validation Loss (standardized): 1.2905429580105412\n",
      "Epoch: 41, Loss (standarized): 1.1842830732605554\n",
      "          Validation Loss (standardized): 1.2554090810274625\n",
      "Epoch: 46, Loss (standarized): 1.1355649197596316\n",
      "          Validation Loss (standardized): 1.2010183861814407\n",
      "Epoch: 51, Loss (standarized): 1.084048597459978\n",
      "          Validation Loss (standardized): 1.1580992608532314\n",
      "Epoch: 56, Loss (standarized): 1.032144528223076\n",
      "          Validation Loss (standardized): 1.1062543028120517\n",
      "Epoch: 61, Loss (standarized): 0.9803317348891344\n",
      "          Validation Loss (standardized): 1.0582989438485046\n",
      "Epoch: 66, Loss (standarized): 0.928354133745701\n",
      "          Validation Loss (standardized): 1.0094688780545937\n",
      "Epoch: 71, Loss (standarized): 0.8768529900665551\n",
      "          Validation Loss (standardized): 0.9646993110276063\n",
      "Epoch: 76, Loss (standarized): 0.8263420398274072\n",
      "          Validation Loss (standardized): 0.923311355113194\n",
      "Epoch: 81, Loss (standarized): 0.7775719511467213\n",
      "          Validation Loss (standardized): 0.8866126854062957\n",
      "Epoch: 86, Loss (standarized): 0.7311793538244191\n",
      "          Validation Loss (standardized): 0.8537383100607742\n",
      "Epoch: 91, Loss (standarized): 0.6876357408342528\n",
      "          Validation Loss (standardized): 0.8247448485493309\n",
      "Epoch: 96, Loss (standarized): 0.6471772187660124\n",
      "          Validation Loss (standardized): 0.7984233963289183\n",
      "Final epoch: 100, Final loss (standarized): 0.6172309803753258\n",
      "Epoch: 1, Loss (standarized): 1.7730196850888762\n",
      "          Validation Loss (standardized): 1.642303293692847\n",
      "Epoch: 6, Loss (standarized): 1.3963270171061977\n",
      "          Validation Loss (standardized): 1.4339740390214561\n",
      "Epoch: 11, Loss (standarized): 1.3439647093953755\n",
      "          Validation Loss (standardized): 1.4628778230924167\n",
      "Epoch: 16, Loss (standarized): 1.3174044111094974\n",
      "          Validation Loss (standardized): 1.4251674462859123\n",
      "Epoch: 21, Loss (standarized): 1.2811656810802798\n",
      "          Validation Loss (standardized): 1.3359376682379576\n",
      "Epoch: 26, Loss (standarized): 1.2515297439786612\n",
      "          Validation Loss (standardized): 1.2840112438076499\n",
      "Epoch: 31, Loss (standarized): 1.2128199702912914\n",
      "          Validation Loss (standardized): 1.281960486772793\n",
      "Epoch: 36, Loss (standarized): 1.1633295627123723\n",
      "          Validation Loss (standardized): 1.252907651579892\n",
      "Epoch: 41, Loss (standarized): 1.0998489642719176\n",
      "          Validation Loss (standardized): 1.1827504738905572\n",
      "Epoch: 46, Loss (standarized): 1.0260231269905\n",
      "          Validation Loss (standardized): 1.1266713747577137\n",
      "Epoch: 51, Loss (standarized): 0.9500854293386598\n",
      "          Validation Loss (standardized): 1.0580826053303134\n",
      "Epoch: 56, Loss (standarized): 0.8794917051131311\n",
      "          Validation Loss (standardized): 0.993110468063631\n",
      "Epoch: 61, Loss (standarized): 0.816586132645047\n",
      "          Validation Loss (standardized): 0.9411676515314185\n",
      "Epoch: 66, Loss (standarized): 0.7614458428375716\n",
      "          Validation Loss (standardized): 0.8968311140769026\n",
      "Epoch: 71, Loss (standarized): 0.7126308225476887\n",
      "          Validation Loss (standardized): 0.8576881036011987\n",
      "Epoch: 76, Loss (standarized): 0.6684792211937617\n",
      "          Validation Loss (standardized): 0.8266133011299799\n",
      "Epoch: 81, Loss (standarized): 0.6278935684358228\n",
      "          Validation Loss (standardized): 0.7976985234559122\n",
      "Epoch: 86, Loss (standarized): 0.5903615035760046\n",
      "          Validation Loss (standardized): 0.7675091116099384\n",
      "Epoch: 91, Loss (standarized): 0.5555357665081868\n",
      "          Validation Loss (standardized): 0.739267279944792\n",
      "Epoch: 96, Loss (standarized): 0.5231026854956151\n",
      "          Validation Loss (standardized): 0.7132282867934111\n",
      "Final epoch: 100, Final loss (standarized): 0.49902397183399555\n",
      "Epoch: 1, Loss (standarized): 1.6466559626958388\n",
      "          Validation Loss (standardized): 1.5880370527562406\n",
      "Epoch: 6, Loss (standarized): 1.3760010650951637\n",
      "          Validation Loss (standardized): 1.437247407699368\n",
      "Epoch: 11, Loss (standarized): 1.3542230239906448\n",
      "          Validation Loss (standardized): 1.388299302739416\n",
      "Epoch: 16, Loss (standarized): 1.3261595941504947\n",
      "          Validation Loss (standardized): 1.3596754123000865\n",
      "Epoch: 21, Loss (standarized): 1.301432094095081\n",
      "          Validation Loss (standardized): 1.355089039472887\n",
      "Epoch: 26, Loss (standarized): 1.2714473947755875\n",
      "          Validation Loss (standardized): 1.3293362514256268\n",
      "Epoch: 31, Loss (standarized): 1.2283481497246862\n",
      "          Validation Loss (standardized): 1.288403176547349\n",
      "Epoch: 36, Loss (standarized): 1.1761623642170966\n",
      "          Validation Loss (standardized): 1.2304342594597675\n",
      "Epoch: 41, Loss (standarized): 1.11366030795243\n",
      "          Validation Loss (standardized): 1.171833677211874\n",
      "Epoch: 46, Loss (standarized): 1.046188737898925\n",
      "          Validation Loss (standardized): 1.1041692522297335\n",
      "Epoch: 51, Loss (standarized): 0.9790462762786868\n",
      "          Validation Loss (standardized): 1.03703786635648\n",
      "Epoch: 56, Loss (standarized): 0.9146160518558708\n",
      "          Validation Loss (standardized): 0.9794112005332647\n",
      "Epoch: 61, Loss (standarized): 0.8537775940743418\n",
      "          Validation Loss (standardized): 0.9305449986846951\n",
      "Epoch: 66, Loss (standarized): 0.7955571652622233\n",
      "          Validation Loss (standardized): 0.8847978247408321\n",
      "Epoch: 71, Loss (standarized): 0.7399662325223031\n",
      "          Validation Loss (standardized): 0.8465872052088753\n",
      "Epoch: 76, Loss (standarized): 0.6868322659337808\n",
      "          Validation Loss (standardized): 0.8079656881192409\n",
      "Epoch: 81, Loss (standarized): 0.6357094528146803\n",
      "          Validation Loss (standardized): 0.769187252198063\n",
      "Epoch: 86, Loss (standarized): 0.5872187488426455\n",
      "          Validation Loss (standardized): 0.7335010013843741\n",
      "Epoch: 91, Loss (standarized): 0.5427382583736851\n",
      "          Validation Loss (standardized): 0.7041631550502437\n",
      "Epoch: 96, Loss (standarized): 0.5027523176646673\n",
      "          Validation Loss (standardized): 0.6790535247979531\n",
      "Final epoch: 100, Final loss (standarized): 0.4738283203021328\n",
      "Epoch: 1, Loss (standarized): 1.6797062622978565\n",
      "          Validation Loss (standardized): 1.5966352375790125\n",
      "Epoch: 6, Loss (standarized): 1.4009606696538157\n",
      "          Validation Loss (standardized): 1.451380550392886\n",
      "Epoch: 11, Loss (standarized): 1.3443882917665508\n",
      "          Validation Loss (standardized): 1.4016179019202883\n",
      "Epoch: 16, Loss (standarized): 1.3167416535919432\n",
      "          Validation Loss (standardized): 1.354995430880198\n",
      "Epoch: 21, Loss (standarized): 1.2991389674330356\n",
      "          Validation Loss (standardized): 1.3496804063018304\n",
      "Epoch: 26, Loss (standarized): 1.2730680538811179\n",
      "          Validation Loss (standardized): 1.3349468915170941\n",
      "Epoch: 31, Loss (standarized): 1.2424619244039934\n",
      "          Validation Loss (standardized): 1.3040107011885276\n",
      "Epoch: 36, Loss (standarized): 1.206036046804283\n",
      "          Validation Loss (standardized): 1.2723684704621163\n",
      "Epoch: 41, Loss (standarized): 1.1676550660743372\n",
      "          Validation Loss (standardized): 1.232031818242189\n",
      "Epoch: 46, Loss (standarized): 1.1270390960060976\n",
      "          Validation Loss (standardized): 1.1864690315381732\n",
      "Epoch: 51, Loss (standarized): 1.0878429102194107\n",
      "          Validation Loss (standardized): 1.1512947047796316\n",
      "Epoch: 56, Loss (standarized): 1.0502728140702013\n",
      "          Validation Loss (standardized): 1.1114170324612564\n",
      "Epoch: 61, Loss (standarized): 1.0132670929478953\n",
      "          Validation Loss (standardized): 1.0812887170085936\n",
      "Epoch: 66, Loss (standarized): 0.9764289693097359\n",
      "          Validation Loss (standardized): 1.0482976660962944\n",
      "Epoch: 71, Loss (standarized): 0.9382307129017875\n",
      "          Validation Loss (standardized): 1.0156782692853483\n",
      "Epoch: 76, Loss (standarized): 0.8979476709546875\n",
      "          Validation Loss (standardized): 0.9841145106973161\n",
      "Epoch: 81, Loss (standarized): 0.8562836368063179\n",
      "          Validation Loss (standardized): 0.950163232095498\n",
      "Epoch: 86, Loss (standarized): 0.8136404840096229\n",
      "          Validation Loss (standardized): 0.9179829208944563\n",
      "Epoch: 91, Loss (standarized): 0.7717831638116236\n",
      "          Validation Loss (standardized): 0.8851271011563124\n",
      "Epoch: 96, Loss (standarized): 0.7331200292062447\n",
      "          Validation Loss (standardized): 0.8572010459539768\n",
      "Final epoch: 100, Final loss (standarized): 0.7058058672518743\n",
      "Epoch: 1, Loss (standarized): 1.631869035679294\n",
      "          Validation Loss (standardized): 1.5713495877167951\n",
      "Epoch: 6, Loss (standarized): 1.3879658886180497\n",
      "          Validation Loss (standardized): 1.468086492208242\n",
      "Epoch: 11, Loss (standarized): 1.3317730131050143\n",
      "          Validation Loss (standardized): 1.3723108456024973\n",
      "Epoch: 16, Loss (standarized): 1.3057681422132805\n",
      "          Validation Loss (standardized): 1.3255303096728754\n",
      "Epoch: 21, Loss (standarized): 1.2777485461587332\n",
      "          Validation Loss (standardized): 1.326422064558875\n",
      "Epoch: 26, Loss (standarized): 1.2396721547147176\n",
      "          Validation Loss (standardized): 1.2724896042050782\n",
      "Epoch: 31, Loss (standarized): 1.1911970604076192\n",
      "          Validation Loss (standardized): 1.2347902366093058\n",
      "Epoch: 36, Loss (standarized): 1.13266333212217\n",
      "          Validation Loss (standardized): 1.1949521705190937\n",
      "Epoch: 41, Loss (standarized): 1.0633068154841887\n",
      "          Validation Loss (standardized): 1.1308232161810008\n",
      "Epoch: 46, Loss (standarized): 0.9874714897211863\n",
      "          Validation Loss (standardized): 1.0648396625686285\n",
      "Epoch: 51, Loss (standarized): 0.9120664539358023\n",
      "          Validation Loss (standardized): 0.9965194746999332\n",
      "Epoch: 56, Loss (standarized): 0.83986113221734\n",
      "          Validation Loss (standardized): 0.9408889159954028\n",
      "Epoch: 61, Loss (standarized): 0.7718233608023195\n",
      "          Validation Loss (standardized): 0.8900947557165837\n",
      "Epoch: 66, Loss (standarized): 0.7084666375910644\n",
      "          Validation Loss (standardized): 0.8478838292709714\n",
      "Epoch: 71, Loss (standarized): 0.6513821251041213\n",
      "          Validation Loss (standardized): 0.8163238250380598\n",
      "Epoch: 76, Loss (standarized): 0.6026431919226836\n",
      "          Validation Loss (standardized): 0.7889234003612087\n",
      "Epoch: 81, Loss (standarized): 0.560608597040849\n",
      "          Validation Loss (standardized): 0.7646283168484608\n",
      "Epoch: 86, Loss (standarized): 0.5242160925164057\n",
      "          Validation Loss (standardized): 0.743293344618415\n",
      "Epoch: 91, Loss (standarized): 0.49365015311891397\n",
      "          Validation Loss (standardized): 0.7255648791671092\n",
      "Epoch: 96, Loss (standarized): 0.46720635610765443\n",
      "          Validation Loss (standardized): 0.7102019332213324\n",
      "Final epoch: 100, Final loss (standarized): 0.44798299688139487\n",
      "Epoch: 1, Loss (standarized): 1.7210850636345452\n",
      "          Validation Loss (standardized): 1.664704106589387\n",
      "Epoch: 6, Loss (standarized): 1.417161953367372\n",
      "          Validation Loss (standardized): 1.480030051716678\n",
      "Epoch: 11, Loss (standarized): 1.334028904781115\n",
      "          Validation Loss (standardized): 1.3867720089935047\n",
      "Epoch: 16, Loss (standarized): 1.3081459756510991\n",
      "          Validation Loss (standardized): 1.3508588528465484\n",
      "Epoch: 21, Loss (standarized): 1.2826968864377977\n",
      "          Validation Loss (standardized): 1.32427789556168\n",
      "Epoch: 26, Loss (standarized): 1.242727768537777\n",
      "          Validation Loss (standardized): 1.2819664753509254\n",
      "Epoch: 31, Loss (standarized): 1.192030010551032\n",
      "          Validation Loss (standardized): 1.2353969407161132\n",
      "Epoch: 36, Loss (standarized): 1.1365063216325761\n",
      "          Validation Loss (standardized): 1.1861391728048178\n",
      "Epoch: 41, Loss (standarized): 1.0734454430360405\n",
      "          Validation Loss (standardized): 1.1304137859609484\n",
      "Epoch: 46, Loss (standarized): 1.0097811218064647\n",
      "          Validation Loss (standardized): 1.0744753064794106\n",
      "Epoch: 51, Loss (standarized): 0.951990292995865\n",
      "          Validation Loss (standardized): 1.022995851091927\n",
      "Epoch: 56, Loss (standarized): 0.8954126212096921\n",
      "          Validation Loss (standardized): 0.9755914733401259\n",
      "Epoch: 61, Loss (standarized): 0.8389418361073434\n",
      "          Validation Loss (standardized): 0.93345046386625\n",
      "Epoch: 66, Loss (standarized): 0.7811053965458945\n",
      "          Validation Loss (standardized): 0.8909126591092856\n",
      "Epoch: 71, Loss (standarized): 0.7236355605429453\n",
      "          Validation Loss (standardized): 0.853885129897609\n",
      "Epoch: 76, Loss (standarized): 0.6691943859635135\n",
      "          Validation Loss (standardized): 0.8235201005592889\n",
      "Epoch: 81, Loss (standarized): 0.6181334248525734\n",
      "          Validation Loss (standardized): 0.7918887098145704\n",
      "Epoch: 86, Loss (standarized): 0.5706337883966757\n",
      "          Validation Loss (standardized): 0.7578692639241943\n",
      "Epoch: 91, Loss (standarized): 0.5267731627076537\n",
      "          Validation Loss (standardized): 0.7235562663354015\n",
      "Epoch: 96, Loss (standarized): 0.48733261810171524\n",
      "          Validation Loss (standardized): 0.6941803871650161\n",
      "Final epoch: 100, Final loss (standarized): 0.45879698176547407\n",
      "Epoch: 1, Loss (standarized): 2.237999019029267\n",
      "Epoch: 6, Loss (standarized): 1.4541692356773075\n",
      "Epoch: 11, Loss (standarized): 1.2773549772529458\n",
      "Epoch: 16, Loss (standarized): 1.2374251246343553\n",
      "Epoch: 21, Loss (standarized): 1.1867325703367837\n",
      "Epoch: 26, Loss (standarized): 1.129688461909328\n",
      "Epoch: 31, Loss (standarized): 1.0760971797411727\n",
      "Epoch: 36, Loss (standarized): 1.0325056507133987\n",
      "Epoch: 41, Loss (standarized): 0.9898173870483444\n",
      "Epoch: 46, Loss (standarized): 0.9447150602093741\n",
      "Epoch: 51, Loss (standarized): 0.8952415280510142\n",
      "Epoch: 56, Loss (standarized): 0.8423989942927474\n",
      "Epoch: 61, Loss (standarized): 0.7887255593790721\n",
      "Epoch: 66, Loss (standarized): 0.7325770188618644\n",
      "Epoch: 71, Loss (standarized): 0.6750576244192671\n",
      "Epoch: 76, Loss (standarized): 0.6105028836604349\n",
      "Epoch: 81, Loss (standarized): 0.5492519286696945\n",
      "Epoch: 86, Loss (standarized): 0.4931499929735905\n",
      "Epoch: 91, Loss (standarized): 0.4412812736975434\n",
      "Epoch: 96, Loss (standarized): 0.39730741454962143\n",
      "Final epoch: 100, Final loss (standarized): 0.3674136595981258\n",
      "Epoch: 1, Loss (standarized): 1.830003757150437\n",
      "Epoch: 6, Loss (standarized): 1.3838199110518576\n",
      "Epoch: 11, Loss (standarized): 1.2619597351796006\n",
      "Epoch: 16, Loss (standarized): 1.2092874708450412\n",
      "Epoch: 21, Loss (standarized): 1.1505461793799874\n",
      "Epoch: 26, Loss (standarized): 1.093703761263876\n",
      "Epoch: 31, Loss (standarized): 1.0449140018038994\n",
      "Epoch: 36, Loss (standarized): 0.9961574227373622\n",
      "Epoch: 41, Loss (standarized): 0.9458781615200803\n",
      "Epoch: 46, Loss (standarized): 0.8947511089134723\n",
      "Epoch: 51, Loss (standarized): 0.8415875290054964\n",
      "Epoch: 56, Loss (standarized): 0.7888118602423491\n",
      "Epoch: 61, Loss (standarized): 0.7351165108139575\n",
      "Epoch: 66, Loss (standarized): 0.682060430695336\n",
      "Epoch: 71, Loss (standarized): 0.6345226194105745\n",
      "Epoch: 76, Loss (standarized): 0.5915857731037543\n",
      "Epoch: 81, Loss (standarized): 0.5545868451956639\n",
      "Epoch: 86, Loss (standarized): 0.5231648349886359\n",
      "Epoch: 91, Loss (standarized): 0.49685115916211\n",
      "Epoch: 96, Loss (standarized): 0.4757757779813595\n",
      "Final epoch: 100, Final loss (standarized): 0.4610277402682465\n",
      "Epoch: 1, Loss (standarized): 1.8288117286736145\n",
      "Epoch: 6, Loss (standarized): 1.4034741529171066\n",
      "Epoch: 11, Loss (standarized): 1.3021445618523728\n",
      "Epoch: 16, Loss (standarized): 1.1977459987612868\n",
      "Epoch: 21, Loss (standarized): 1.121259833415787\n",
      "Epoch: 26, Loss (standarized): 1.0512977645402075\n",
      "Epoch: 31, Loss (standarized): 0.9919697926691501\n",
      "Epoch: 36, Loss (standarized): 0.9373236917140355\n",
      "Epoch: 41, Loss (standarized): 0.8835760079743014\n",
      "Epoch: 46, Loss (standarized): 0.827855113896002\n",
      "Epoch: 51, Loss (standarized): 0.7711255201712303\n",
      "Epoch: 56, Loss (standarized): 0.715542389555586\n",
      "Epoch: 61, Loss (standarized): 0.6615831845614123\n",
      "Epoch: 66, Loss (standarized): 0.6120448489226628\n",
      "Epoch: 71, Loss (standarized): 0.5652022197876166\n",
      "Epoch: 76, Loss (standarized): 0.523009359974979\n",
      "Epoch: 81, Loss (standarized): 0.48419903290624206\n",
      "Epoch: 86, Loss (standarized): 0.448367274295006\n",
      "Epoch: 91, Loss (standarized): 0.41606798223740055\n",
      "Epoch: 96, Loss (standarized): 0.38678999985735224\n",
      "Final epoch: 100, Final loss (standarized): 0.3661818063019466\n",
      "Epoch: 1, Loss (standarized): 1.8127034582181905\n",
      "Epoch: 6, Loss (standarized): 1.3546389291668157\n",
      "Epoch: 11, Loss (standarized): 1.2311210427467365\n",
      "Epoch: 16, Loss (standarized): 1.1586939120360191\n",
      "Epoch: 21, Loss (standarized): 1.0992833391045516\n",
      "Epoch: 26, Loss (standarized): 1.0439154846839207\n",
      "Epoch: 31, Loss (standarized): 0.9897364556550738\n",
      "Epoch: 36, Loss (standarized): 0.9387546147062316\n",
      "Epoch: 41, Loss (standarized): 0.882824945105221\n",
      "Epoch: 46, Loss (standarized): 0.824745617419541\n",
      "Epoch: 51, Loss (standarized): 0.7642581570902988\n",
      "Epoch: 56, Loss (standarized): 0.7003029577053616\n",
      "Epoch: 61, Loss (standarized): 0.6353582241767901\n",
      "Epoch: 66, Loss (standarized): 0.5743902744133339\n",
      "Epoch: 71, Loss (standarized): 0.5175933288474155\n",
      "Epoch: 76, Loss (standarized): 0.4646310726408824\n",
      "Epoch: 81, Loss (standarized): 0.4183525041042492\n",
      "Epoch: 86, Loss (standarized): 0.37692797843788434\n",
      "Epoch: 91, Loss (standarized): 0.3416049677333113\n",
      "Epoch: 96, Loss (standarized): 0.3126398447039064\n",
      "Final epoch: 100, Final loss (standarized): 0.29277360252992995\n",
      "Epoch: 1, Loss (standarized): 3.4522159368425656\n",
      "Epoch: 6, Loss (standarized): 1.9715546983345298\n",
      "Epoch: 11, Loss (standarized): 1.4383081643626752\n",
      "Epoch: 16, Loss (standarized): 1.2935722298386287\n",
      "Epoch: 21, Loss (standarized): 1.2302668207655498\n",
      "Epoch: 26, Loss (standarized): 1.1848307089024048\n",
      "Epoch: 31, Loss (standarized): 1.1519797825966156\n",
      "Epoch: 36, Loss (standarized): 1.1225059404223325\n",
      "Epoch: 41, Loss (standarized): 1.0981517843795925\n",
      "Epoch: 46, Loss (standarized): 1.0750894925720316\n",
      "Epoch: 51, Loss (standarized): 1.0527665608641028\n",
      "Epoch: 56, Loss (standarized): 1.0283961531294223\n",
      "Epoch: 61, Loss (standarized): 1.002330624574645\n",
      "Epoch: 66, Loss (standarized): 0.9751754112260688\n",
      "Epoch: 71, Loss (standarized): 0.9488660110893349\n",
      "Epoch: 76, Loss (standarized): 0.9229095785423428\n",
      "Epoch: 81, Loss (standarized): 0.8969438886917945\n",
      "Epoch: 86, Loss (standarized): 0.8702876575299259\n",
      "Epoch: 91, Loss (standarized): 0.8440724739228748\n",
      "Epoch: 96, Loss (standarized): 0.8184234199503001\n",
      "Final epoch: 100, Final loss (standarized): 0.7984494190539262\n",
      "Epoch: 1, Loss (standarized): 1.9378931805663777\n",
      "Epoch: 6, Loss (standarized): 1.385436058547194\n",
      "Epoch: 11, Loss (standarized): 1.301378874499391\n",
      "Epoch: 16, Loss (standarized): 1.2343172291277291\n",
      "Epoch: 21, Loss (standarized): 1.1987887386523521\n",
      "Epoch: 26, Loss (standarized): 1.1764317216112206\n",
      "Epoch: 31, Loss (standarized): 1.1602516447732092\n",
      "Epoch: 36, Loss (standarized): 1.1480469426246096\n",
      "Epoch: 41, Loss (standarized): 1.1366570544932824\n",
      "Epoch: 46, Loss (standarized): 1.1274678787504222\n",
      "Epoch: 51, Loss (standarized): 1.1180885987537523\n",
      "Epoch: 56, Loss (standarized): 1.1081023955021296\n",
      "Epoch: 61, Loss (standarized): 1.0982971194557571\n",
      "Epoch: 66, Loss (standarized): 1.087635305063801\n",
      "Epoch: 71, Loss (standarized): 1.0768167526135377\n",
      "Epoch: 76, Loss (standarized): 1.0674662954377883\n",
      "Epoch: 81, Loss (standarized): 1.0587537389683304\n",
      "Epoch: 86, Loss (standarized): 1.0488355344121991\n",
      "Epoch: 91, Loss (standarized): 1.0382093460246409\n",
      "Epoch: 96, Loss (standarized): 1.026281390479757\n",
      "Final epoch: 100, Final loss (standarized): 1.0167163409611488\n",
      "Epoch: 1, Loss (standarized): 1.9173675621758013\n",
      "Epoch: 6, Loss (standarized): 1.3416875298169362\n",
      "Epoch: 11, Loss (standarized): 1.2630704114856177\n",
      "Epoch: 16, Loss (standarized): 1.1922806306148248\n",
      "Epoch: 21, Loss (standarized): 1.1675635573066985\n",
      "Epoch: 26, Loss (standarized): 1.1267116496339915\n",
      "Epoch: 31, Loss (standarized): 1.1060558259343456\n",
      "Epoch: 36, Loss (standarized): 1.0805498641531068\n",
      "Epoch: 41, Loss (standarized): 1.0609798451192172\n",
      "Epoch: 46, Loss (standarized): 1.036546748471215\n",
      "Epoch: 51, Loss (standarized): 1.0107661380583643\n",
      "Epoch: 56, Loss (standarized): 0.9822038003364091\n",
      "Epoch: 61, Loss (standarized): 0.9539261458399474\n",
      "Epoch: 66, Loss (standarized): 0.9260401754336297\n",
      "Epoch: 71, Loss (standarized): 0.8956004147106736\n",
      "Epoch: 76, Loss (standarized): 0.8648110440770768\n",
      "Epoch: 81, Loss (standarized): 0.8327970914961869\n",
      "Epoch: 86, Loss (standarized): 0.800673522834492\n",
      "Epoch: 91, Loss (standarized): 0.7697875448085799\n",
      "Epoch: 96, Loss (standarized): 0.7392634799739654\n",
      "Final epoch: 100, Final loss (standarized): 0.7148934228779982\n",
      "Epoch: 1, Loss (standarized): 1.563533196821588\n",
      "Epoch: 6, Loss (standarized): 1.3234080870568488\n",
      "Epoch: 11, Loss (standarized): 1.235908911309856\n",
      "Epoch: 16, Loss (standarized): 1.1915134003484111\n",
      "Epoch: 21, Loss (standarized): 1.1554852733419576\n",
      "Epoch: 26, Loss (standarized): 1.1289477237177103\n",
      "Epoch: 31, Loss (standarized): 1.1045880179612382\n",
      "Epoch: 36, Loss (standarized): 1.0824536179859303\n",
      "Epoch: 41, Loss (standarized): 1.0612357694049726\n",
      "Epoch: 46, Loss (standarized): 1.0406001466621155\n",
      "Epoch: 51, Loss (standarized): 1.02001277858388\n",
      "Epoch: 56, Loss (standarized): 1.0008381176863441\n",
      "Epoch: 61, Loss (standarized): 0.9829290387990518\n",
      "Epoch: 66, Loss (standarized): 0.9642732323409869\n",
      "Epoch: 71, Loss (standarized): 0.9453414664782887\n",
      "Epoch: 76, Loss (standarized): 0.9249874021473221\n",
      "Epoch: 81, Loss (standarized): 0.9037597723970191\n",
      "Epoch: 86, Loss (standarized): 0.8799330048829934\n",
      "Epoch: 91, Loss (standarized): 0.8550644627269622\n",
      "Epoch: 96, Loss (standarized): 0.829379829812199\n",
      "Final epoch: 100, Final loss (standarized): 0.8080117080933956\n",
      "Epoch: 1, Loss (standarized): 2.020891829881444\n",
      "Epoch: 6, Loss (standarized): 1.4233289583159974\n",
      "Epoch: 11, Loss (standarized): 1.2947789478974507\n",
      "Epoch: 16, Loss (standarized): 1.2162293267450215\n",
      "Epoch: 21, Loss (standarized): 1.163859783442502\n",
      "Epoch: 26, Loss (standarized): 1.1166770258718801\n",
      "Epoch: 31, Loss (standarized): 1.0639206609886562\n",
      "Epoch: 36, Loss (standarized): 1.0186186460781277\n",
      "Epoch: 41, Loss (standarized): 0.9674185194501871\n",
      "Epoch: 46, Loss (standarized): 0.9218857532517362\n",
      "Epoch: 51, Loss (standarized): 0.8723741225091214\n",
      "Epoch: 56, Loss (standarized): 0.8188128904616875\n",
      "Epoch: 61, Loss (standarized): 0.7627959556449616\n",
      "Epoch: 66, Loss (standarized): 0.7045036301033696\n",
      "Epoch: 71, Loss (standarized): 0.6465383563064815\n",
      "Epoch: 76, Loss (standarized): 0.5926172326882866\n",
      "Epoch: 81, Loss (standarized): 0.5415666622110454\n",
      "Epoch: 86, Loss (standarized): 0.49501186659512747\n",
      "Epoch: 91, Loss (standarized): 0.452992142635972\n",
      "Epoch: 96, Loss (standarized): 0.41410271636386853\n",
      "Final epoch: 100, Final loss (standarized): 0.38565941816411964\n",
      "Epoch: 1, Loss (standarized): 1.9852486114387824\n",
      "Epoch: 6, Loss (standarized): 1.4531582366028812\n",
      "Epoch: 11, Loss (standarized): 1.3417919703045667\n",
      "Epoch: 16, Loss (standarized): 1.2813984181552676\n",
      "Epoch: 21, Loss (standarized): 1.2193507302259305\n",
      "Epoch: 26, Loss (standarized): 1.1671451590114628\n",
      "Epoch: 31, Loss (standarized): 1.1190490445511145\n",
      "Epoch: 36, Loss (standarized): 1.0804246031982243\n",
      "Epoch: 41, Loss (standarized): 1.0420328528672431\n",
      "Epoch: 46, Loss (standarized): 1.0061490906233712\n",
      "Epoch: 51, Loss (standarized): 0.9690533822634433\n",
      "Epoch: 56, Loss (standarized): 0.9292791620844131\n",
      "Epoch: 61, Loss (standarized): 0.8879202372976641\n",
      "Epoch: 66, Loss (standarized): 0.8440770311717003\n",
      "Epoch: 71, Loss (standarized): 0.7967352845351873\n",
      "Epoch: 76, Loss (standarized): 0.7486868679545757\n",
      "Epoch: 81, Loss (standarized): 0.7027217996461951\n",
      "Epoch: 86, Loss (standarized): 0.6589234743096025\n",
      "Epoch: 91, Loss (standarized): 0.6192479925538611\n",
      "Epoch: 96, Loss (standarized): 0.5842338541598344\n",
      "Final epoch: 100, Final loss (standarized): 0.5598019555401789\n",
      "Epoch: 1, Loss (standarized): 1.8736516776924832\n",
      "Epoch: 6, Loss (standarized): 1.390814044913252\n",
      "Epoch: 11, Loss (standarized): 1.242857500961372\n",
      "Epoch: 16, Loss (standarized): 1.175986409370485\n",
      "Epoch: 21, Loss (standarized): 1.124068921092091\n",
      "Epoch: 26, Loss (standarized): 1.0731514201166503\n",
      "Epoch: 31, Loss (standarized): 1.0325606390126305\n",
      "Epoch: 36, Loss (standarized): 0.9958714352734944\n",
      "Epoch: 41, Loss (standarized): 0.9586128571863155\n",
      "Epoch: 46, Loss (standarized): 0.920853280665251\n",
      "Epoch: 51, Loss (standarized): 0.8791216344007107\n",
      "Epoch: 56, Loss (standarized): 0.8347530067369178\n",
      "Epoch: 61, Loss (standarized): 0.7845364875356874\n",
      "Epoch: 66, Loss (standarized): 0.7266481417446111\n",
      "Epoch: 71, Loss (standarized): 0.6616960520865157\n",
      "Epoch: 76, Loss (standarized): 0.5993630369602851\n",
      "Epoch: 81, Loss (standarized): 0.539899472964541\n",
      "Epoch: 86, Loss (standarized): 0.4872347830798453\n",
      "Epoch: 91, Loss (standarized): 0.44083503408356495\n",
      "Epoch: 96, Loss (standarized): 0.40019895600351385\n",
      "Final epoch: 100, Final loss (standarized): 0.37208888498767634\n",
      "Epoch: 1, Loss (standarized): 2.070779862651964\n",
      "Epoch: 6, Loss (standarized): 1.444787976550382\n",
      "Epoch: 11, Loss (standarized): 1.2850932060535343\n",
      "Epoch: 16, Loss (standarized): 1.2192294458741364\n",
      "Epoch: 21, Loss (standarized): 1.1653123737451574\n",
      "Epoch: 26, Loss (standarized): 1.1101792269463584\n",
      "Epoch: 31, Loss (standarized): 1.0593203987643816\n",
      "Epoch: 36, Loss (standarized): 1.0067682810079288\n",
      "Epoch: 41, Loss (standarized): 0.953248460208086\n",
      "Epoch: 46, Loss (standarized): 0.9007591223408323\n",
      "Epoch: 51, Loss (standarized): 0.844018905326686\n",
      "Epoch: 56, Loss (standarized): 0.7889405117515611\n",
      "Epoch: 61, Loss (standarized): 0.7338676567249037\n",
      "Epoch: 66, Loss (standarized): 0.6788810692276018\n",
      "Epoch: 71, Loss (standarized): 0.6258067232150301\n",
      "Epoch: 76, Loss (standarized): 0.5749843050648603\n",
      "Epoch: 81, Loss (standarized): 0.5279369751581457\n",
      "Epoch: 86, Loss (standarized): 0.48482949766920425\n",
      "Epoch: 91, Loss (standarized): 0.4439216781571981\n",
      "Epoch: 96, Loss (standarized): 0.40694858298668535\n",
      "Final epoch: 100, Final loss (standarized): 0.3792434434486081\n",
      "Epoch: 1, Loss (standarized): 2.543912708851538\n",
      "Epoch: 6, Loss (standarized): 1.5536039388517906\n",
      "Epoch: 11, Loss (standarized): 1.3929962462763188\n",
      "Epoch: 16, Loss (standarized): 1.3090238075136742\n",
      "Epoch: 21, Loss (standarized): 1.241950258817699\n",
      "Epoch: 26, Loss (standarized): 1.1955273513249045\n",
      "Epoch: 31, Loss (standarized): 1.141583872083509\n",
      "Epoch: 36, Loss (standarized): 1.1003485200813368\n",
      "Epoch: 41, Loss (standarized): 1.0624166359190932\n",
      "Epoch: 46, Loss (standarized): 1.0191522190503384\n",
      "Epoch: 51, Loss (standarized): 0.9766196962550174\n",
      "Epoch: 56, Loss (standarized): 0.9299447712339085\n",
      "Epoch: 61, Loss (standarized): 0.8743856727174105\n",
      "Epoch: 66, Loss (standarized): 0.8143290704943246\n",
      "Epoch: 71, Loss (standarized): 0.7484558890081658\n",
      "Epoch: 76, Loss (standarized): 0.684331948982626\n",
      "Epoch: 81, Loss (standarized): 0.6230185387959589\n",
      "Epoch: 86, Loss (standarized): 0.5614054796943653\n",
      "Epoch: 91, Loss (standarized): 0.5043114510891704\n",
      "Epoch: 96, Loss (standarized): 0.4519705452855486\n",
      "Final epoch: 100, Final loss (standarized): 0.4140240652060032\n",
      "Epoch: 1, Loss (standarized): 1.7873029724305687\n",
      "Epoch: 6, Loss (standarized): 1.384274115931629\n",
      "Epoch: 11, Loss (standarized): 1.2941602075670238\n",
      "Epoch: 16, Loss (standarized): 1.2400702763125617\n",
      "Epoch: 21, Loss (standarized): 1.1836822222123562\n",
      "Epoch: 26, Loss (standarized): 1.144911719905786\n",
      "Epoch: 31, Loss (standarized): 1.1130121324965296\n",
      "Epoch: 36, Loss (standarized): 1.075284481520038\n",
      "Epoch: 41, Loss (standarized): 1.0358342414586617\n",
      "Epoch: 46, Loss (standarized): 0.99573123733318\n",
      "Epoch: 51, Loss (standarized): 0.9516457346643574\n",
      "Epoch: 56, Loss (standarized): 0.9016954084096366\n",
      "Epoch: 61, Loss (standarized): 0.8476020755256688\n",
      "Epoch: 66, Loss (standarized): 0.790667116048191\n",
      "Epoch: 71, Loss (standarized): 0.7347491530879424\n",
      "Epoch: 76, Loss (standarized): 0.6805297340358871\n",
      "Epoch: 81, Loss (standarized): 0.6297472889399327\n",
      "Epoch: 86, Loss (standarized): 0.5843225049832955\n",
      "Epoch: 91, Loss (standarized): 0.5452375514767351\n",
      "Epoch: 96, Loss (standarized): 0.5119005908483912\n",
      "Final epoch: 100, Final loss (standarized): 0.48864601079861325\n",
      "Epoch: 1, Loss (standarized): 1.6564226722033217\n",
      "Epoch: 6, Loss (standarized): 1.3143492236232461\n",
      "Epoch: 11, Loss (standarized): 1.182253926196254\n",
      "Epoch: 16, Loss (standarized): 1.1094696840610225\n",
      "Epoch: 21, Loss (standarized): 1.049742368041773\n",
      "Epoch: 26, Loss (standarized): 0.9917776060972068\n",
      "Epoch: 31, Loss (standarized): 0.9398019225984497\n",
      "Epoch: 36, Loss (standarized): 0.8902687473638912\n",
      "Epoch: 41, Loss (standarized): 0.8411029745682419\n",
      "Epoch: 46, Loss (standarized): 0.7886077513632475\n",
      "Epoch: 51, Loss (standarized): 0.7315979402844612\n",
      "Epoch: 56, Loss (standarized): 0.6708851652884055\n",
      "Epoch: 61, Loss (standarized): 0.6085582532581489\n",
      "Epoch: 66, Loss (standarized): 0.5462799885452018\n",
      "Epoch: 71, Loss (standarized): 0.4861716953244511\n",
      "Epoch: 76, Loss (standarized): 0.4298216837988666\n",
      "Epoch: 81, Loss (standarized): 0.3826210018386742\n",
      "Epoch: 86, Loss (standarized): 0.3426973643965489\n",
      "Epoch: 91, Loss (standarized): 0.3113927027273779\n",
      "Epoch: 96, Loss (standarized): 0.28592737780078875\n",
      "Final epoch: 100, Final loss (standarized): 0.2685726644949414\n",
      "Epoch: 1, Loss (standarized): 2.393963732816138\n",
      "Epoch: 6, Loss (standarized): 1.5747140029943258\n",
      "Epoch: 11, Loss (standarized): 1.3171933433282335\n",
      "Epoch: 16, Loss (standarized): 1.2143842914614784\n",
      "Epoch: 21, Loss (standarized): 1.1527334971015397\n",
      "Epoch: 26, Loss (standarized): 1.100297541824712\n",
      "Epoch: 31, Loss (standarized): 1.0528730118185914\n",
      "Epoch: 36, Loss (standarized): 1.0077727383824753\n",
      "Epoch: 41, Loss (standarized): 0.9641757949418153\n",
      "Epoch: 46, Loss (standarized): 0.9235094869095545\n",
      "Epoch: 51, Loss (standarized): 0.8809358820010382\n",
      "Epoch: 56, Loss (standarized): 0.8353368258422142\n",
      "Epoch: 61, Loss (standarized): 0.788857552465502\n",
      "Epoch: 66, Loss (standarized): 0.7452576551939961\n",
      "Epoch: 71, Loss (standarized): 0.7036058442059399\n",
      "Epoch: 76, Loss (standarized): 0.6613168211318111\n",
      "Epoch: 81, Loss (standarized): 0.6196611137452126\n",
      "Epoch: 86, Loss (standarized): 0.580074254240383\n",
      "Epoch: 91, Loss (standarized): 0.5410163629108328\n",
      "Epoch: 96, Loss (standarized): 0.5064511012469495\n",
      "Final epoch: 100, Final loss (standarized): 0.480614140250863\n",
      "Epoch: 1, Loss (standarized): 3.2822579565130288\n",
      "          Validation Loss (standardized): 3.496809209780465\n",
      "Epoch: 6, Loss (standarized): 1.886068586846048\n",
      "          Validation Loss (standardized): 1.8552522001585525\n",
      "Epoch: 11, Loss (standarized): 1.469677883807284\n",
      "          Validation Loss (standardized): 1.4225958753441468\n",
      "Epoch: 16, Loss (standarized): 1.331891652556626\n",
      "          Validation Loss (standardized): 1.3929739652047266\n",
      "Epoch: 21, Loss (standarized): 1.2385711692402521\n",
      "          Validation Loss (standardized): 1.330687175854085\n",
      "Epoch: 26, Loss (standarized): 1.1597353240093553\n",
      "          Validation Loss (standardized): 1.224793852867579\n",
      "Epoch: 31, Loss (standarized): 1.1111047518909078\n",
      "          Validation Loss (standardized): 1.2066368969204673\n",
      "Epoch: 36, Loss (standarized): 1.0699313928231675\n",
      "          Validation Loss (standardized): 1.2264256441595687\n",
      "Epoch: 41, Loss (standarized): 1.0351530607306803\n",
      "          Validation Loss (standardized): 1.171478548316854\n",
      "Epoch: 46, Loss (standarized): 0.9987943362832646\n",
      "          Validation Loss (standardized): 1.113428221289339\n",
      "Epoch: 51, Loss (standarized): 0.966221989010175\n",
      "          Validation Loss (standardized): 1.0987032916257862\n",
      "Epoch: 56, Loss (standarized): 0.9333518676351288\n",
      "          Validation Loss (standardized): 1.0827475665232613\n",
      "Epoch: 61, Loss (standarized): 0.8983978581529022\n",
      "          Validation Loss (standardized): 1.0449842673553422\n",
      "Epoch: 66, Loss (standarized): 0.8631636763507038\n",
      "          Validation Loss (standardized): 1.0256279543657498\n",
      "Epoch: 71, Loss (standarized): 0.8271223646642554\n",
      "          Validation Loss (standardized): 0.9948556353500225\n",
      "Epoch: 76, Loss (standarized): 0.7899291811914197\n",
      "          Validation Loss (standardized): 0.9624621057096014\n",
      "Epoch: 81, Loss (standarized): 0.7515162076249823\n",
      "          Validation Loss (standardized): 0.9338725722010096\n",
      "Epoch: 86, Loss (standarized): 0.7114161760065215\n",
      "          Validation Loss (standardized): 0.8934216426576824\n",
      "Epoch: 91, Loss (standarized): 0.6692694256214062\n",
      "          Validation Loss (standardized): 0.8551484137112716\n",
      "Epoch: 96, Loss (standarized): 0.625272418054243\n",
      "          Validation Loss (standardized): 0.8162978770914511\n",
      "Final epoch: 100, Final loss (standarized): 0.5918598972586108\n",
      "Epoch: 1, Loss (standarized): 2.512022697037977\n",
      "          Validation Loss (standardized): 2.546841097119547\n",
      "Epoch: 6, Loss (standarized): 1.4398416566451646\n",
      "          Validation Loss (standardized): 1.3907823740253433\n",
      "Epoch: 11, Loss (standarized): 1.2540942635572163\n",
      "          Validation Loss (standardized): 1.2006468551789196\n",
      "Epoch: 16, Loss (standarized): 1.1935294067673285\n",
      "          Validation Loss (standardized): 1.2110428502355886\n",
      "Epoch: 21, Loss (standarized): 1.1449968918434212\n",
      "          Validation Loss (standardized): 1.2107882642258991\n",
      "Epoch: 26, Loss (standarized): 1.1014356505000782\n",
      "          Validation Loss (standardized): 1.1737487647044382\n",
      "Epoch: 31, Loss (standarized): 1.071660226712714\n",
      "          Validation Loss (standardized): 1.131933655338062\n",
      "Epoch: 36, Loss (standarized): 1.0465109120638463\n",
      "          Validation Loss (standardized): 1.1002285263044052\n",
      "Epoch: 41, Loss (standarized): 1.0199327848745134\n",
      "          Validation Loss (standardized): 1.0840034614859595\n",
      "Epoch: 46, Loss (standarized): 0.9943315099993003\n",
      "          Validation Loss (standardized): 1.064823752783253\n",
      "Epoch: 51, Loss (standarized): 0.9683026420551013\n",
      "          Validation Loss (standardized): 1.041066755591586\n",
      "Epoch: 56, Loss (standarized): 0.9402489918277098\n",
      "          Validation Loss (standardized): 1.0173570901721196\n",
      "Epoch: 61, Loss (standarized): 0.9099221981846226\n",
      "          Validation Loss (standardized): 0.9933155331893332\n",
      "Epoch: 66, Loss (standarized): 0.8763361608544068\n",
      "          Validation Loss (standardized): 0.9680495585345136\n",
      "Epoch: 71, Loss (standarized): 0.8375199023419097\n",
      "          Validation Loss (standardized): 0.9352880617528112\n",
      "Epoch: 76, Loss (standarized): 0.7963027427199811\n",
      "          Validation Loss (standardized): 0.9004839753977139\n",
      "Epoch: 81, Loss (standarized): 0.7538384491872185\n",
      "          Validation Loss (standardized): 0.8703653047256669\n",
      "Epoch: 86, Loss (standarized): 0.711602172306512\n",
      "          Validation Loss (standardized): 0.829558838479443\n",
      "Epoch: 91, Loss (standarized): 0.6709519841474859\n",
      "          Validation Loss (standardized): 0.7995293811382495\n",
      "Epoch: 96, Loss (standarized): 0.6325389527786104\n",
      "          Validation Loss (standardized): 0.7670299020170344\n",
      "Final epoch: 100, Final loss (standarized): 0.6042433900982178\n",
      "Epoch: 1, Loss (standarized): 1.8669314349373216\n",
      "          Validation Loss (standardized): 1.5971681612755348\n",
      "Epoch: 6, Loss (standarized): 1.4436021287777543\n",
      "          Validation Loss (standardized): 1.43248347392658\n",
      "Epoch: 11, Loss (standarized): 1.3496122104317676\n",
      "          Validation Loss (standardized): 1.35719825521097\n",
      "Epoch: 16, Loss (standarized): 1.2377626761680225\n",
      "          Validation Loss (standardized): 1.2645303110147095\n",
      "Epoch: 21, Loss (standarized): 1.1456170457966035\n",
      "          Validation Loss (standardized): 1.1751765858117615\n",
      "Epoch: 26, Loss (standarized): 1.07731970917491\n",
      "          Validation Loss (standardized): 1.1256291218632295\n",
      "Epoch: 31, Loss (standarized): 1.020859766481682\n",
      "          Validation Loss (standardized): 1.1031630110996007\n",
      "Epoch: 36, Loss (standarized): 0.970211814080877\n",
      "          Validation Loss (standardized): 1.0637214710444511\n",
      "Epoch: 41, Loss (standarized): 0.9180828628178499\n",
      "          Validation Loss (standardized): 1.0052861144751455\n",
      "Epoch: 46, Loss (standarized): 0.868955875319551\n",
      "          Validation Loss (standardized): 0.9656020774424968\n",
      "Epoch: 51, Loss (standarized): 0.8164269325553629\n",
      "          Validation Loss (standardized): 0.9135187637269668\n",
      "Epoch: 56, Loss (standarized): 0.7607507617858696\n",
      "          Validation Loss (standardized): 0.8705409867136991\n",
      "Epoch: 61, Loss (standarized): 0.7051594401768259\n",
      "          Validation Loss (standardized): 0.8217050679707022\n",
      "Epoch: 66, Loss (standarized): 0.6497175893376557\n",
      "          Validation Loss (standardized): 0.7793719796785806\n",
      "Epoch: 71, Loss (standarized): 0.5980471754383027\n",
      "          Validation Loss (standardized): 0.7366456291045346\n",
      "Epoch: 76, Loss (standarized): 0.5492128984480502\n",
      "          Validation Loss (standardized): 0.6970333378835073\n",
      "Epoch: 81, Loss (standarized): 0.502098493439192\n",
      "          Validation Loss (standardized): 0.658055179161073\n",
      "Epoch: 86, Loss (standarized): 0.4579439015670897\n",
      "          Validation Loss (standardized): 0.6214900113244934\n",
      "Epoch: 91, Loss (standarized): 0.4203442155317014\n",
      "          Validation Loss (standardized): 0.5944896182847589\n",
      "Epoch: 96, Loss (standarized): 0.38783694589607853\n",
      "          Validation Loss (standardized): 0.577855044587819\n",
      "Final epoch: 100, Final loss (standarized): 0.3653701991823132\n",
      "Epoch: 1, Loss (standarized): 2.1501788226974674\n",
      "          Validation Loss (standardized): 1.7590944845279815\n",
      "Epoch: 6, Loss (standarized): 1.4297539492224882\n",
      "          Validation Loss (standardized): 1.360041958154628\n",
      "Epoch: 11, Loss (standarized): 1.258184669731035\n",
      "          Validation Loss (standardized): 1.2963180463161517\n",
      "Epoch: 16, Loss (standarized): 1.19658344448382\n",
      "          Validation Loss (standardized): 1.2590096625498939\n",
      "Epoch: 21, Loss (standarized): 1.1572748587557178\n",
      "          Validation Loss (standardized): 1.1775340026462273\n",
      "Epoch: 26, Loss (standarized): 1.1101911840209966\n",
      "          Validation Loss (standardized): 1.1182118786980713\n",
      "Epoch: 31, Loss (standarized): 1.0634771091122492\n",
      "          Validation Loss (standardized): 1.1254737821944976\n",
      "Epoch: 36, Loss (standarized): 1.0250273637308356\n",
      "          Validation Loss (standardized): 1.0869904431434254\n",
      "Epoch: 41, Loss (standarized): 0.9815531437957615\n",
      "          Validation Loss (standardized): 1.0350905536502941\n",
      "Epoch: 46, Loss (standarized): 0.9399170504776206\n",
      "          Validation Loss (standardized): 1.0037578741828397\n",
      "Epoch: 51, Loss (standarized): 0.8930357700861166\n",
      "          Validation Loss (standardized): 0.9636273388148593\n",
      "Epoch: 56, Loss (standarized): 0.8423891694367797\n",
      "          Validation Loss (standardized): 0.9288555075429453\n",
      "Epoch: 61, Loss (standarized): 0.7854978703566367\n",
      "          Validation Loss (standardized): 0.8844210982142128\n",
      "Epoch: 66, Loss (standarized): 0.7295762810461057\n",
      "          Validation Loss (standardized): 0.8443675671858321\n",
      "Epoch: 71, Loss (standarized): 0.6704867528246305\n",
      "          Validation Loss (standardized): 0.8018094911468445\n",
      "Epoch: 76, Loss (standarized): 0.6155937138565898\n",
      "          Validation Loss (standardized): 0.7593825239414396\n",
      "Epoch: 81, Loss (standarized): 0.5608829480447076\n",
      "          Validation Loss (standardized): 0.7236342823231005\n",
      "Epoch: 86, Loss (standarized): 0.5117206696383403\n",
      "          Validation Loss (standardized): 0.693665865039604\n",
      "Epoch: 91, Loss (standarized): 0.4673795238204565\n",
      "          Validation Loss (standardized): 0.6631440268197961\n",
      "Epoch: 96, Loss (standarized): 0.427181976807328\n",
      "          Validation Loss (standardized): 0.6406108863736669\n",
      "Final epoch: 100, Final loss (standarized): 0.3979963949214141\n",
      "Epoch: 1, Loss (standarized): 2.323517616219785\n",
      "          Validation Loss (standardized): 2.216598326199625\n",
      "Epoch: 6, Loss (standarized): 1.4608335683825464\n",
      "          Validation Loss (standardized): 1.4531344206344992\n",
      "Epoch: 11, Loss (standarized): 1.3845375349747264\n",
      "          Validation Loss (standardized): 1.3624264739740906\n",
      "Epoch: 16, Loss (standarized): 1.3046959401671716\n",
      "          Validation Loss (standardized): 1.2848795702816387\n",
      "Epoch: 21, Loss (standarized): 1.2516747104683945\n",
      "          Validation Loss (standardized): 1.2529473123510648\n",
      "Epoch: 26, Loss (standarized): 1.2145825565643822\n",
      "          Validation Loss (standardized): 1.2315253098810173\n",
      "Epoch: 31, Loss (standarized): 1.1846751804009055\n",
      "          Validation Loss (standardized): 1.2156947050596763\n",
      "Epoch: 36, Loss (standarized): 1.162663112841888\n",
      "          Validation Loss (standardized): 1.200488250743793\n",
      "Epoch: 41, Loss (standarized): 1.1438908795153653\n",
      "          Validation Loss (standardized): 1.1787677218334378\n",
      "Epoch: 46, Loss (standarized): 1.1270895599322395\n",
      "          Validation Loss (standardized): 1.1608134538648915\n",
      "Epoch: 51, Loss (standarized): 1.1120707048185579\n",
      "          Validation Loss (standardized): 1.1527882067050024\n",
      "Epoch: 56, Loss (standarized): 1.097303575931914\n",
      "          Validation Loss (standardized): 1.1399783543045123\n",
      "Epoch: 61, Loss (standarized): 1.0821288720653532\n",
      "          Validation Loss (standardized): 1.1258779250931188\n",
      "Epoch: 66, Loss (standarized): 1.0664913043005226\n",
      "          Validation Loss (standardized): 1.1051739564610235\n",
      "Epoch: 71, Loss (standarized): 1.051468319777361\n",
      "          Validation Loss (standardized): 1.0888885498583694\n",
      "Epoch: 76, Loss (standarized): 1.0360959984434883\n",
      "          Validation Loss (standardized): 1.0832927990683756\n",
      "Epoch: 81, Loss (standarized): 1.0200062383879334\n",
      "          Validation Loss (standardized): 1.06574570765405\n",
      "Epoch: 86, Loss (standarized): 1.0048591583159592\n",
      "          Validation Loss (standardized): 1.050785198785846\n",
      "Epoch: 91, Loss (standarized): 0.9893091588847145\n",
      "          Validation Loss (standardized): 1.0355035431566555\n",
      "Epoch: 96, Loss (standarized): 0.9733032202439584\n",
      "          Validation Loss (standardized): 1.0176602227862033\n",
      "Final epoch: 100, Final loss (standarized): 0.9601098778827288\n",
      "Epoch: 1, Loss (standarized): 1.848031843764478\n",
      "          Validation Loss (standardized): 1.7369500412321\n",
      "Epoch: 6, Loss (standarized): 1.4462485946421573\n",
      "          Validation Loss (standardized): 1.4470847471956116\n",
      "Epoch: 11, Loss (standarized): 1.31880459921953\n",
      "          Validation Loss (standardized): 1.355924886789211\n",
      "Epoch: 16, Loss (standarized): 1.2444943855035893\n",
      "          Validation Loss (standardized): 1.294401287757119\n",
      "Epoch: 21, Loss (standarized): 1.2065046207054397\n",
      "          Validation Loss (standardized): 1.2659642992943008\n",
      "Epoch: 26, Loss (standarized): 1.1758071359450366\n",
      "          Validation Loss (standardized): 1.2517126275677437\n",
      "Epoch: 31, Loss (standarized): 1.151180308151699\n",
      "          Validation Loss (standardized): 1.2321776094106407\n",
      "Epoch: 36, Loss (standarized): 1.1302604251710355\n",
      "          Validation Loss (standardized): 1.1969449987331833\n",
      "Epoch: 41, Loss (standarized): 1.1100368976592152\n",
      "          Validation Loss (standardized): 1.1783979035882628\n",
      "Epoch: 46, Loss (standarized): 1.0873766141031564\n",
      "          Validation Loss (standardized): 1.1684441241571522\n",
      "Epoch: 51, Loss (standarized): 1.0679543386175347\n",
      "          Validation Loss (standardized): 1.1493619937635293\n",
      "Epoch: 56, Loss (standarized): 1.049359479784898\n",
      "          Validation Loss (standardized): 1.130625154412077\n",
      "Epoch: 61, Loss (standarized): 1.0335438918987299\n",
      "          Validation Loss (standardized): 1.1059388621608017\n",
      "Epoch: 66, Loss (standarized): 1.0197968600244562\n",
      "          Validation Loss (standardized): 1.0939682941151891\n",
      "Epoch: 71, Loss (standarized): 1.0071843448473894\n",
      "          Validation Loss (standardized): 1.0856600203879139\n",
      "Epoch: 76, Loss (standarized): 0.9947576206145956\n",
      "          Validation Loss (standardized): 1.0698837917059774\n",
      "Epoch: 81, Loss (standarized): 0.982626063216855\n",
      "          Validation Loss (standardized): 1.0605706079487214\n",
      "Epoch: 86, Loss (standarized): 0.969428605246936\n",
      "          Validation Loss (standardized): 1.05020909162275\n",
      "Epoch: 91, Loss (standarized): 0.9538803760002367\n",
      "          Validation Loss (standardized): 1.0396994527663301\n",
      "Epoch: 96, Loss (standarized): 0.9357116176442224\n",
      "          Validation Loss (standardized): 1.0208837335037557\n",
      "Final epoch: 100, Final loss (standarized): 0.9176354287785403\n",
      "Epoch: 1, Loss (standarized): 2.7407510333724794\n",
      "          Validation Loss (standardized): 2.8931421265371458\n",
      "Epoch: 6, Loss (standarized): 1.727460720898418\n",
      "          Validation Loss (standardized): 1.9499786550909057\n",
      "Epoch: 11, Loss (standarized): 1.440442310002058\n",
      "          Validation Loss (standardized): 1.5902484190427812\n",
      "Epoch: 16, Loss (standarized): 1.330996790448856\n",
      "          Validation Loss (standardized): 1.4033352337966907\n",
      "Epoch: 21, Loss (standarized): 1.2569498676543962\n",
      "          Validation Loss (standardized): 1.2941610482191659\n",
      "Epoch: 26, Loss (standarized): 1.204033289392898\n",
      "          Validation Loss (standardized): 1.239710370553923\n",
      "Epoch: 31, Loss (standarized): 1.1708045561047122\n",
      "          Validation Loss (standardized): 1.2178291868104045\n",
      "Epoch: 36, Loss (standarized): 1.138433174099089\n",
      "          Validation Loss (standardized): 1.203690787940497\n",
      "Epoch: 41, Loss (standarized): 1.116585187900734\n",
      "          Validation Loss (standardized): 1.1866862436594035\n",
      "Epoch: 46, Loss (standarized): 1.0970893836110682\n",
      "          Validation Loss (standardized): 1.1675752094770737\n",
      "Epoch: 51, Loss (standarized): 1.0767865269083117\n",
      "          Validation Loss (standardized): 1.1536872576715804\n",
      "Epoch: 56, Loss (standarized): 1.0536454874188232\n",
      "          Validation Loss (standardized): 1.1401617560564252\n",
      "Epoch: 61, Loss (standarized): 1.03074416708729\n",
      "          Validation Loss (standardized): 1.1185925396939491\n",
      "Epoch: 66, Loss (standarized): 1.0064959245233362\n",
      "          Validation Loss (standardized): 1.0961789477283492\n",
      "Epoch: 71, Loss (standarized): 0.9800078874270551\n",
      "          Validation Loss (standardized): 1.0712129450379568\n",
      "Epoch: 76, Loss (standarized): 0.9532102455922018\n",
      "          Validation Loss (standardized): 1.0458757545214277\n",
      "Epoch: 81, Loss (standarized): 0.9256801927720631\n",
      "          Validation Loss (standardized): 1.0234515843731078\n",
      "Epoch: 86, Loss (standarized): 0.8976844311704459\n",
      "          Validation Loss (standardized): 0.9976517519665901\n",
      "Epoch: 91, Loss (standarized): 0.8699664941189621\n",
      "          Validation Loss (standardized): 0.9716775466846398\n",
      "Epoch: 96, Loss (standarized): 0.842894519177191\n",
      "          Validation Loss (standardized): 0.9466412554831803\n",
      "Final epoch: 100, Final loss (standarized): 0.822680547198534\n",
      "Epoch: 1, Loss (standarized): 2.2434472870097677\n",
      "          Validation Loss (standardized): 2.1751429403897125\n",
      "Epoch: 6, Loss (standarized): 1.502792087475723\n",
      "          Validation Loss (standardized): 1.3984206306716642\n",
      "Epoch: 11, Loss (standarized): 1.341575898670983\n",
      "          Validation Loss (standardized): 1.2542277693544286\n",
      "Epoch: 16, Loss (standarized): 1.230985798853366\n",
      "          Validation Loss (standardized): 1.235907279210131\n",
      "Epoch: 21, Loss (standarized): 1.1851734346564655\n",
      "          Validation Loss (standardized): 1.2583355907137774\n",
      "Epoch: 26, Loss (standarized): 1.1541294239499218\n",
      "          Validation Loss (standardized): 1.2105677626148488\n",
      "Epoch: 31, Loss (standarized): 1.1245478299335594\n",
      "          Validation Loss (standardized): 1.1513679271274193\n",
      "Epoch: 36, Loss (standarized): 1.1052191879322464\n",
      "          Validation Loss (standardized): 1.1364538231246322\n",
      "Epoch: 41, Loss (standarized): 1.0858588696737417\n",
      "          Validation Loss (standardized): 1.1465026644347438\n",
      "Epoch: 46, Loss (standarized): 1.069858464664323\n",
      "          Validation Loss (standardized): 1.1424848016979512\n",
      "Epoch: 51, Loss (standarized): 1.0550602564814615\n",
      "          Validation Loss (standardized): 1.1192044164431951\n",
      "Epoch: 56, Loss (standarized): 1.04066650631136\n",
      "          Validation Loss (standardized): 1.0995397022425504\n",
      "Epoch: 61, Loss (standarized): 1.0233695111758119\n",
      "          Validation Loss (standardized): 1.0955786202970357\n",
      "Epoch: 66, Loss (standarized): 1.0077005849624883\n",
      "          Validation Loss (standardized): 1.083111800165346\n",
      "Epoch: 71, Loss (standarized): 0.9927479775396862\n",
      "          Validation Loss (standardized): 1.0658098260351956\n",
      "Epoch: 76, Loss (standarized): 0.9778929885920121\n",
      "          Validation Loss (standardized): 1.0551309164256955\n",
      "Epoch: 81, Loss (standarized): 0.9633413756668253\n",
      "          Validation Loss (standardized): 1.044602799247258\n",
      "Epoch: 86, Loss (standarized): 0.9485743050919999\n",
      "          Validation Loss (standardized): 1.029949265319393\n",
      "Epoch: 91, Loss (standarized): 0.9341777258301518\n",
      "          Validation Loss (standardized): 1.0185573296808816\n",
      "Epoch: 96, Loss (standarized): 0.9194117873588324\n",
      "          Validation Loss (standardized): 1.0038936158025002\n",
      "Final epoch: 100, Final loss (standarized): 0.907076579540432\n",
      "Epoch: 1, Loss (standarized): 2.152165856597705\n",
      "          Validation Loss (standardized): 2.20441841889301\n",
      "Epoch: 6, Loss (standarized): 1.4532923119833407\n",
      "          Validation Loss (standardized): 1.488786932515497\n",
      "Epoch: 11, Loss (standarized): 1.275502922542948\n",
      "          Validation Loss (standardized): 1.2926654109822762\n",
      "Epoch: 16, Loss (standarized): 1.1852451359452896\n",
      "          Validation Loss (standardized): 1.2189425052292622\n",
      "Epoch: 21, Loss (standarized): 1.1385673680248447\n",
      "          Validation Loss (standardized): 1.2084349083053916\n",
      "Epoch: 26, Loss (standarized): 1.0949370509563137\n",
      "          Validation Loss (standardized): 1.1562177197328491\n",
      "Epoch: 31, Loss (standarized): 1.0564684990398248\n",
      "          Validation Loss (standardized): 1.1090356466658127\n",
      "Epoch: 36, Loss (standarized): 1.0156533613977168\n",
      "          Validation Loss (standardized): 1.091800036553883\n",
      "Epoch: 41, Loss (standarized): 0.9770578285250315\n",
      "          Validation Loss (standardized): 1.0605362506811007\n",
      "Epoch: 46, Loss (standarized): 0.9393561487113594\n",
      "          Validation Loss (standardized): 1.024957847457812\n",
      "Epoch: 51, Loss (standarized): 0.900013234094001\n",
      "          Validation Loss (standardized): 0.9911293708711146\n",
      "Epoch: 56, Loss (standarized): 0.8570368440135948\n",
      "          Validation Loss (standardized): 0.9571925012036423\n",
      "Epoch: 61, Loss (standarized): 0.8103631020885271\n",
      "          Validation Loss (standardized): 0.918019762229298\n",
      "Epoch: 66, Loss (standarized): 0.7613703465583421\n",
      "          Validation Loss (standardized): 0.8767558250115514\n",
      "Epoch: 71, Loss (standarized): 0.7102028564183565\n",
      "          Validation Loss (standardized): 0.8324748895314171\n",
      "Epoch: 76, Loss (standarized): 0.6564823271828597\n",
      "          Validation Loss (standardized): 0.7876731495834445\n",
      "Epoch: 81, Loss (standarized): 0.6032678436369328\n",
      "          Validation Loss (standardized): 0.742366756538948\n",
      "Epoch: 86, Loss (standarized): 0.5533750049440804\n",
      "          Validation Loss (standardized): 0.6983703643136872\n",
      "Epoch: 91, Loss (standarized): 0.5057577630318438\n",
      "          Validation Loss (standardized): 0.6544513395094059\n",
      "Epoch: 96, Loss (standarized): 0.46072413298250886\n",
      "          Validation Loss (standardized): 0.6138222965896566\n",
      "Final epoch: 100, Final loss (standarized): 0.4266280795882133\n",
      "Epoch: 1, Loss (standarized): 2.0189720772059037\n",
      "          Validation Loss (standardized): 1.8423573485759266\n",
      "Epoch: 6, Loss (standarized): 1.4409859361930024\n",
      "          Validation Loss (standardized): 1.4192751844435134\n",
      "Epoch: 11, Loss (standarized): 1.317648377336726\n",
      "          Validation Loss (standardized): 1.2589232625990703\n",
      "Epoch: 16, Loss (standarized): 1.2606305378022362\n",
      "          Validation Loss (standardized): 1.2027786419670716\n",
      "Epoch: 21, Loss (standarized): 1.2175153767293594\n",
      "          Validation Loss (standardized): 1.1793786223790352\n",
      "Epoch: 26, Loss (standarized): 1.1777884700257124\n",
      "          Validation Loss (standardized): 1.164795454928033\n",
      "Epoch: 31, Loss (standarized): 1.1458481444424669\n",
      "          Validation Loss (standardized): 1.1527253497655283\n",
      "Epoch: 36, Loss (standarized): 1.1157742491966642\n",
      "          Validation Loss (standardized): 1.1308713376925534\n",
      "Epoch: 41, Loss (standarized): 1.0863808170186875\n",
      "          Validation Loss (standardized): 1.108533656603025\n",
      "Epoch: 46, Loss (standarized): 1.0582500036363767\n",
      "          Validation Loss (standardized): 1.092509643695216\n",
      "Epoch: 51, Loss (standarized): 1.028435852976216\n",
      "          Validation Loss (standardized): 1.0724635934595355\n",
      "Epoch: 56, Loss (standarized): 0.9973970559957509\n",
      "          Validation Loss (standardized): 1.049309624132955\n",
      "Epoch: 61, Loss (standarized): 0.9663565620928678\n",
      "          Validation Loss (standardized): 1.0263020927774456\n",
      "Epoch: 66, Loss (standarized): 0.9319599748317706\n",
      "          Validation Loss (standardized): 1.0009356972894103\n",
      "Epoch: 71, Loss (standarized): 0.892980749129571\n",
      "          Validation Loss (standardized): 0.9752861558319631\n",
      "Epoch: 76, Loss (standarized): 0.8533944116366251\n",
      "          Validation Loss (standardized): 0.9476425541796789\n",
      "Epoch: 81, Loss (standarized): 0.8099416742919534\n",
      "          Validation Loss (standardized): 0.9177396670445521\n",
      "Epoch: 86, Loss (standarized): 0.7657536692311757\n",
      "          Validation Loss (standardized): 0.8788423565896042\n",
      "Epoch: 91, Loss (standarized): 0.7195209348204091\n",
      "          Validation Loss (standardized): 0.8404672003747492\n",
      "Epoch: 96, Loss (standarized): 0.6726998774052442\n",
      "          Validation Loss (standardized): 0.8033879949084524\n",
      "Final epoch: 100, Final loss (standarized): 0.6376304436167127\n",
      "Epoch: 1, Loss (standarized): 1.821737435629375\n",
      "          Validation Loss (standardized): 1.64510034429725\n",
      "Epoch: 6, Loss (standarized): 1.3907498338859243\n",
      "          Validation Loss (standardized): 1.4227411155786853\n",
      "Epoch: 11, Loss (standarized): 1.2612897393488423\n",
      "          Validation Loss (standardized): 1.3213020954312082\n",
      "Epoch: 16, Loss (standarized): 1.1849034856385396\n",
      "          Validation Loss (standardized): 1.2220000674491525\n",
      "Epoch: 21, Loss (standarized): 1.1259957186014615\n",
      "          Validation Loss (standardized): 1.170143505822156\n",
      "Epoch: 26, Loss (standarized): 1.0763212196713947\n",
      "          Validation Loss (standardized): 1.1632901340590283\n",
      "Epoch: 31, Loss (standarized): 1.0260251604150983\n",
      "          Validation Loss (standardized): 1.0985760083536713\n",
      "Epoch: 36, Loss (standarized): 0.9711159810049996\n",
      "          Validation Loss (standardized): 1.0571643094026946\n",
      "Epoch: 41, Loss (standarized): 0.9081855351736107\n",
      "          Validation Loss (standardized): 1.0173717735080152\n",
      "Epoch: 46, Loss (standarized): 0.8450174139574175\n",
      "          Validation Loss (standardized): 0.9667732328492775\n",
      "Epoch: 51, Loss (standarized): 0.7829305904485256\n",
      "          Validation Loss (standardized): 0.9144418974020712\n",
      "Epoch: 56, Loss (standarized): 0.7232282834443235\n",
      "          Validation Loss (standardized): 0.8582164551902185\n",
      "Epoch: 61, Loss (standarized): 0.6655335684976248\n",
      "          Validation Loss (standardized): 0.8048976168809088\n",
      "Epoch: 66, Loss (standarized): 0.6085287198080959\n",
      "          Validation Loss (standardized): 0.756987486283249\n",
      "Epoch: 71, Loss (standarized): 0.555659074218334\n",
      "          Validation Loss (standardized): 0.7111132772765343\n",
      "Epoch: 76, Loss (standarized): 0.5074033585980507\n",
      "          Validation Loss (standardized): 0.6738668820955215\n",
      "Epoch: 81, Loss (standarized): 0.4660043641097675\n",
      "          Validation Loss (standardized): 0.6347152899285952\n",
      "Epoch: 86, Loss (standarized): 0.4299693775248617\n",
      "          Validation Loss (standardized): 0.60866412525403\n",
      "Epoch: 91, Loss (standarized): 0.39765636483039174\n",
      "          Validation Loss (standardized): 0.5796633725078268\n",
      "Epoch: 96, Loss (standarized): 0.3691484675867847\n",
      "          Validation Loss (standardized): 0.5541812617845169\n",
      "Final epoch: 100, Final loss (standarized): 0.3491924022629041\n",
      "Epoch: 1, Loss (standarized): 1.9241044614163534\n",
      "          Validation Loss (standardized): 1.5981330721841411\n",
      "Epoch: 6, Loss (standarized): 1.4069796777258745\n",
      "          Validation Loss (standardized): 1.505687075008304\n",
      "Epoch: 11, Loss (standarized): 1.239934787599998\n",
      "          Validation Loss (standardized): 1.3223851734580554\n",
      "Epoch: 16, Loss (standarized): 1.1805750848604972\n",
      "          Validation Loss (standardized): 1.234977433033833\n",
      "Epoch: 21, Loss (standarized): 1.1240401689039148\n",
      "          Validation Loss (standardized): 1.1809139092268315\n",
      "Epoch: 26, Loss (standarized): 1.0767829602241958\n",
      "          Validation Loss (standardized): 1.1826359349782714\n",
      "Epoch: 31, Loss (standarized): 1.0269547156646253\n",
      "          Validation Loss (standardized): 1.1147988845193766\n",
      "Epoch: 36, Loss (standarized): 0.9840152888909245\n",
      "          Validation Loss (standardized): 1.065331340133801\n",
      "Epoch: 41, Loss (standarized): 0.9352647034113258\n",
      "          Validation Loss (standardized): 1.0393950329388626\n",
      "Epoch: 46, Loss (standarized): 0.8828560964590849\n",
      "          Validation Loss (standardized): 0.9907018557451449\n",
      "Epoch: 51, Loss (standarized): 0.8318162394467535\n",
      "          Validation Loss (standardized): 0.953558554876186\n",
      "Epoch: 56, Loss (standarized): 0.7763446477856193\n",
      "          Validation Loss (standardized): 0.9148244747943518\n",
      "Epoch: 61, Loss (standarized): 0.7202374141773703\n",
      "          Validation Loss (standardized): 0.860851138256796\n",
      "Epoch: 66, Loss (standarized): 0.6672342326020755\n",
      "          Validation Loss (standardized): 0.8240030929806232\n",
      "Epoch: 71, Loss (standarized): 0.6161606776179834\n",
      "          Validation Loss (standardized): 0.7719657947334417\n",
      "Epoch: 76, Loss (standarized): 0.5683189704138532\n",
      "          Validation Loss (standardized): 0.7325643438874875\n",
      "Epoch: 81, Loss (standarized): 0.5234273696317905\n",
      "          Validation Loss (standardized): 0.6967746652331607\n",
      "Epoch: 86, Loss (standarized): 0.48134617603952845\n",
      "          Validation Loss (standardized): 0.6564084989105016\n",
      "Epoch: 91, Loss (standarized): 0.4435896582836351\n",
      "          Validation Loss (standardized): 0.6223471703997602\n",
      "Epoch: 96, Loss (standarized): 0.4099376590281983\n",
      "          Validation Loss (standardized): 0.593668349856448\n",
      "Final epoch: 100, Final loss (standarized): 0.38543698289161993\n",
      "Epoch: 1, Loss (standarized): 1.8040463267413815\n",
      "          Validation Loss (standardized): 1.5129238731988393\n",
      "Epoch: 6, Loss (standarized): 1.2673390899527732\n",
      "          Validation Loss (standardized): 1.3063208744728172\n",
      "Epoch: 11, Loss (standarized): 1.2103323985015177\n",
      "          Validation Loss (standardized): 1.2352563760878825\n",
      "Epoch: 16, Loss (standarized): 1.1430230436409823\n",
      "          Validation Loss (standardized): 1.197020626915693\n",
      "Epoch: 21, Loss (standarized): 1.0823751237285764\n",
      "          Validation Loss (standardized): 1.1409873055123265\n",
      "Epoch: 26, Loss (standarized): 1.0219142583821235\n",
      "          Validation Loss (standardized): 1.108686192276075\n",
      "Epoch: 31, Loss (standarized): 0.9481186613339625\n",
      "          Validation Loss (standardized): 1.0466651653428196\n",
      "Epoch: 36, Loss (standarized): 0.8851100624996954\n",
      "          Validation Loss (standardized): 1.0242246098070809\n",
      "Epoch: 41, Loss (standarized): 0.822496425806269\n",
      "          Validation Loss (standardized): 0.9736908730295467\n",
      "Epoch: 46, Loss (standarized): 0.764800944465841\n",
      "          Validation Loss (standardized): 0.9254369034518568\n",
      "Epoch: 51, Loss (standarized): 0.7114901673572812\n",
      "          Validation Loss (standardized): 0.880982235474828\n",
      "Epoch: 56, Loss (standarized): 0.6616032283406519\n",
      "          Validation Loss (standardized): 0.8453927505118439\n",
      "Epoch: 61, Loss (standarized): 0.613065910889648\n",
      "          Validation Loss (standardized): 0.8059937514579739\n",
      "Epoch: 66, Loss (standarized): 0.5662350931852349\n",
      "          Validation Loss (standardized): 0.7649353683214207\n",
      "Epoch: 71, Loss (standarized): 0.5189202444564489\n",
      "          Validation Loss (standardized): 0.7247634902853716\n",
      "Epoch: 76, Loss (standarized): 0.4730897064021273\n",
      "          Validation Loss (standardized): 0.6827327723690314\n",
      "Epoch: 81, Loss (standarized): 0.4282198050073879\n",
      "          Validation Loss (standardized): 0.6438897969233217\n",
      "Epoch: 86, Loss (standarized): 0.3855735475032679\n",
      "          Validation Loss (standardized): 0.6101180478071347\n",
      "Epoch: 91, Loss (standarized): 0.34823231273698674\n",
      "          Validation Loss (standardized): 0.5763945274071561\n",
      "Epoch: 96, Loss (standarized): 0.31402307847338706\n",
      "          Validation Loss (standardized): 0.5482842461849132\n",
      "Final epoch: 100, Final loss (standarized): 0.2917554477891872\n",
      "Epoch: 1, Loss (standarized): 2.431613787674922\n",
      "          Validation Loss (standardized): 1.7723761941993652\n",
      "Epoch: 6, Loss (standarized): 1.636374924222431\n",
      "          Validation Loss (standardized): 1.4359526639809248\n",
      "Epoch: 11, Loss (standarized): 1.3449281294812827\n",
      "          Validation Loss (standardized): 1.2907147540223045\n",
      "Epoch: 16, Loss (standarized): 1.2480249258486154\n",
      "          Validation Loss (standardized): 1.2235323608491526\n",
      "Epoch: 21, Loss (standarized): 1.1675760338581767\n",
      "          Validation Loss (standardized): 1.1979539144105957\n",
      "Epoch: 26, Loss (standarized): 1.097749095003208\n",
      "          Validation Loss (standardized): 1.1798936721056834\n",
      "Epoch: 31, Loss (standarized): 1.0402622089785034\n",
      "          Validation Loss (standardized): 1.1309591577126408\n",
      "Epoch: 36, Loss (standarized): 0.9842576816124171\n",
      "          Validation Loss (standardized): 1.085122970234292\n",
      "Epoch: 41, Loss (standarized): 0.9279901230373917\n",
      "          Validation Loss (standardized): 1.0395854137657092\n",
      "Epoch: 46, Loss (standarized): 0.87755732708531\n",
      "          Validation Loss (standardized): 0.9883555838208199\n",
      "Epoch: 51, Loss (standarized): 0.8289476017423817\n",
      "          Validation Loss (standardized): 0.9479380177523443\n",
      "Epoch: 56, Loss (standarized): 0.7803635676081643\n",
      "          Validation Loss (standardized): 0.9040474667800771\n",
      "Epoch: 61, Loss (standarized): 0.7347153035220713\n",
      "          Validation Loss (standardized): 0.8735427504090417\n",
      "Epoch: 66, Loss (standarized): 0.6908159918897738\n",
      "          Validation Loss (standardized): 0.8338617554302257\n",
      "Epoch: 71, Loss (standarized): 0.6500946152484159\n",
      "          Validation Loss (standardized): 0.7987162632146299\n",
      "Epoch: 76, Loss (standarized): 0.6102594198107942\n",
      "          Validation Loss (standardized): 0.7645265364167354\n",
      "Epoch: 81, Loss (standarized): 0.5747591646801626\n",
      "          Validation Loss (standardized): 0.733317886900821\n",
      "Epoch: 86, Loss (standarized): 0.542656130093915\n",
      "          Validation Loss (standardized): 0.7015405173320507\n",
      "Epoch: 91, Loss (standarized): 0.5134700859137246\n",
      "          Validation Loss (standardized): 0.6766876163669805\n",
      "Epoch: 96, Loss (standarized): 0.4881061061697631\n",
      "          Validation Loss (standardized): 0.6550358052401205\n",
      "Final epoch: 100, Final loss (standarized): 0.47079400704091945\n",
      "Epoch: 1, Loss (standarized): 2.2209854307496393\n",
      "          Validation Loss (standardized): 1.8857518911269395\n",
      "Epoch: 6, Loss (standarized): 1.4773244295676176\n",
      "          Validation Loss (standardized): 1.3873877906998346\n",
      "Epoch: 11, Loss (standarized): 1.2152097890045932\n",
      "          Validation Loss (standardized): 1.4003755198668428\n",
      "Epoch: 16, Loss (standarized): 1.155193784852392\n",
      "          Validation Loss (standardized): 1.2501253175122755\n",
      "Epoch: 21, Loss (standarized): 1.088479130239372\n",
      "          Validation Loss (standardized): 1.135630331787655\n",
      "Epoch: 26, Loss (standarized): 1.0481765048290934\n",
      "          Validation Loss (standardized): 1.1417357533177381\n",
      "Epoch: 31, Loss (standarized): 1.0019839448105923\n",
      "          Validation Loss (standardized): 1.1046646815694754\n",
      "Epoch: 36, Loss (standarized): 0.9626445402647087\n",
      "          Validation Loss (standardized): 1.0712388353015816\n",
      "Epoch: 41, Loss (standarized): 0.9231972831116515\n",
      "          Validation Loss (standardized): 1.0283755520902178\n",
      "Epoch: 46, Loss (standarized): 0.8853097081772694\n",
      "          Validation Loss (standardized): 1.0025421642788206\n",
      "Epoch: 51, Loss (standarized): 0.8455501667452602\n",
      "          Validation Loss (standardized): 0.985433415212458\n",
      "Epoch: 56, Loss (standarized): 0.8045180862046637\n",
      "          Validation Loss (standardized): 0.9468838806378312\n",
      "Epoch: 61, Loss (standarized): 0.7612113197750691\n",
      "          Validation Loss (standardized): 0.9230227123173536\n",
      "Epoch: 66, Loss (standarized): 0.718409556089647\n",
      "          Validation Loss (standardized): 0.8835009801144017\n",
      "Epoch: 71, Loss (standarized): 0.6750719435728534\n",
      "          Validation Loss (standardized): 0.8508163233003967\n",
      "Epoch: 76, Loss (standarized): 0.6298075226609241\n",
      "          Validation Loss (standardized): 0.818065408603219\n",
      "Epoch: 81, Loss (standarized): 0.585305759687331\n",
      "          Validation Loss (standardized): 0.7823007004926033\n",
      "Epoch: 86, Loss (standarized): 0.5414527671128767\n",
      "          Validation Loss (standardized): 0.741109762997522\n",
      "Epoch: 91, Loss (standarized): 0.49855232224221496\n",
      "          Validation Loss (standardized): 0.7084025593301133\n",
      "Epoch: 96, Loss (standarized): 0.45901796640332293\n",
      "          Validation Loss (standardized): 0.6678677173363511\n",
      "Final epoch: 100, Final loss (standarized): 0.43068532868603326\n",
      "Epoch: 1, Loss (standarized): 1.6744279760964298\n",
      "          Validation Loss (standardized): 1.485518272352664\n",
      "Epoch: 6, Loss (standarized): 1.3308577965988357\n",
      "          Validation Loss (standardized): 1.2428342345217902\n",
      "Epoch: 11, Loss (standarized): 1.265326235126173\n",
      "          Validation Loss (standardized): 1.173185635171024\n",
      "Epoch: 16, Loss (standarized): 1.1912805498676773\n",
      "          Validation Loss (standardized): 1.1938732442500168\n",
      "Epoch: 21, Loss (standarized): 1.1284769322758494\n",
      "          Validation Loss (standardized): 1.1443414577770818\n",
      "Epoch: 26, Loss (standarized): 1.0770889404108017\n",
      "          Validation Loss (standardized): 1.0850822266838436\n",
      "Epoch: 31, Loss (standarized): 1.0276343694251293\n",
      "          Validation Loss (standardized): 1.0587671664429426\n",
      "Epoch: 36, Loss (standarized): 0.9742361622372725\n",
      "          Validation Loss (standardized): 1.0097057530970264\n",
      "Epoch: 41, Loss (standarized): 0.9185795511793162\n",
      "          Validation Loss (standardized): 0.9759680416338103\n",
      "Epoch: 46, Loss (standarized): 0.8574857116909811\n",
      "          Validation Loss (standardized): 0.9407036249857665\n",
      "Epoch: 51, Loss (standarized): 0.7961166892428495\n",
      "          Validation Loss (standardized): 0.904549246809455\n",
      "Epoch: 56, Loss (standarized): 0.7344869939727132\n",
      "          Validation Loss (standardized): 0.8620414233627564\n",
      "Epoch: 61, Loss (standarized): 0.6719028748020389\n",
      "          Validation Loss (standardized): 0.8224405341185093\n",
      "Epoch: 66, Loss (standarized): 0.6094936946751088\n",
      "          Validation Loss (standardized): 0.7729689153033755\n",
      "Epoch: 71, Loss (standarized): 0.5494524306912352\n",
      "          Validation Loss (standardized): 0.7294253888100939\n",
      "Epoch: 76, Loss (standarized): 0.4915297855520443\n",
      "          Validation Loss (standardized): 0.6789443077731699\n",
      "Epoch: 81, Loss (standarized): 0.4396517582507288\n",
      "          Validation Loss (standardized): 0.635096036680449\n",
      "Epoch: 86, Loss (standarized): 0.3947911147944966\n",
      "          Validation Loss (standardized): 0.6010817457581223\n",
      "Epoch: 91, Loss (standarized): 0.3557928987182018\n",
      "          Validation Loss (standardized): 0.5714975809531063\n",
      "Epoch: 96, Loss (standarized): 0.32077805092771755\n",
      "          Validation Loss (standardized): 0.5503344317238512\n",
      "Final epoch: 100, Final loss (standarized): 0.2956194083102284\n",
      "Epoch: 1, Loss (standarized): 2.0558044289814914\n",
      "          Validation Loss (standardized): 2.0679368027729232\n",
      "Epoch: 6, Loss (standarized): 1.508152296090306\n",
      "          Validation Loss (standardized): 1.643085363805256\n",
      "Epoch: 11, Loss (standarized): 1.330535309622187\n",
      "          Validation Loss (standardized): 1.4163933167130003\n",
      "Epoch: 16, Loss (standarized): 1.2320995938044204\n",
      "          Validation Loss (standardized): 1.2900036102568655\n",
      "Epoch: 21, Loss (standarized): 1.169548605928348\n",
      "          Validation Loss (standardized): 1.2140324069343584\n",
      "Epoch: 26, Loss (standarized): 1.1165288098641366\n",
      "          Validation Loss (standardized): 1.1750302758643916\n",
      "Epoch: 31, Loss (standarized): 1.0615896186019618\n",
      "          Validation Loss (standardized): 1.1254686663982776\n",
      "Epoch: 36, Loss (standarized): 1.0082693164361338\n",
      "          Validation Loss (standardized): 1.0573115060659408\n",
      "Epoch: 41, Loss (standarized): 0.9548211163858611\n",
      "          Validation Loss (standardized): 1.0233454068270385\n",
      "Epoch: 46, Loss (standarized): 0.8988074495725757\n",
      "          Validation Loss (standardized): 0.9850965889958053\n",
      "Epoch: 51, Loss (standarized): 0.8419220930559785\n",
      "          Validation Loss (standardized): 0.9485377065467925\n",
      "Epoch: 56, Loss (standarized): 0.7833340286850978\n",
      "          Validation Loss (standardized): 0.9020380466145259\n",
      "Epoch: 61, Loss (standarized): 0.7255012750860433\n",
      "          Validation Loss (standardized): 0.8707415724296409\n",
      "Epoch: 66, Loss (standarized): 0.6682821705998895\n",
      "          Validation Loss (standardized): 0.8258758802871368\n",
      "Epoch: 71, Loss (standarized): 0.6122273041181149\n",
      "          Validation Loss (standardized): 0.784741092316395\n",
      "Epoch: 76, Loss (standarized): 0.5602270610378152\n",
      "          Validation Loss (standardized): 0.7549166331940259\n",
      "Epoch: 81, Loss (standarized): 0.5128678233842463\n",
      "          Validation Loss (standardized): 0.711758063207614\n",
      "Epoch: 86, Loss (standarized): 0.47022930416424147\n",
      "          Validation Loss (standardized): 0.6768570876553102\n",
      "Epoch: 91, Loss (standarized): 0.43141728495040865\n",
      "          Validation Loss (standardized): 0.6448689193094701\n",
      "Epoch: 96, Loss (standarized): 0.39675946852522787\n",
      "          Validation Loss (standardized): 0.6178645092967749\n",
      "Final epoch: 100, Final loss (standarized): 0.3711972926772893\n",
      "Epoch: 1, Loss (standarized): 2.3869011622837926\n",
      "          Validation Loss (standardized): 2.08335658408255\n",
      "Epoch: 6, Loss (standarized): 1.4548748812343757\n",
      "          Validation Loss (standardized): 1.4582224024387487\n",
      "Epoch: 11, Loss (standarized): 1.2455063008904093\n",
      "          Validation Loss (standardized): 1.31269789321287\n",
      "Epoch: 16, Loss (standarized): 1.1668996993598966\n",
      "          Validation Loss (standardized): 1.2216086691985888\n",
      "Epoch: 21, Loss (standarized): 1.117703628563561\n",
      "          Validation Loss (standardized): 1.1616973309813445\n",
      "Epoch: 26, Loss (standarized): 1.0641857779175685\n",
      "          Validation Loss (standardized): 1.155483460033905\n",
      "Epoch: 31, Loss (standarized): 1.009994366975523\n",
      "          Validation Loss (standardized): 1.1093701157411313\n",
      "Epoch: 36, Loss (standarized): 0.9689042455210222\n",
      "          Validation Loss (standardized): 1.0663317963133416\n",
      "Epoch: 41, Loss (standarized): 0.923566217099863\n",
      "          Validation Loss (standardized): 1.0270825415074087\n",
      "Epoch: 46, Loss (standarized): 0.8784964518444951\n",
      "          Validation Loss (standardized): 0.9883608008405154\n",
      "Epoch: 51, Loss (standarized): 0.8314923773122531\n",
      "          Validation Loss (standardized): 0.9440449831596861\n",
      "Epoch: 56, Loss (standarized): 0.7823972089332359\n",
      "          Validation Loss (standardized): 0.9015529061825822\n",
      "Epoch: 61, Loss (standarized): 0.7324973446649296\n",
      "          Validation Loss (standardized): 0.8613630858462686\n",
      "Epoch: 66, Loss (standarized): 0.6847071021511201\n",
      "          Validation Loss (standardized): 0.8114720890657554\n",
      "Epoch: 71, Loss (standarized): 0.6404320133048098\n",
      "          Validation Loss (standardized): 0.7798497890424804\n",
      "Epoch: 76, Loss (standarized): 0.5996977232600392\n",
      "          Validation Loss (standardized): 0.7387278741883483\n",
      "Epoch: 81, Loss (standarized): 0.5629398194049747\n",
      "          Validation Loss (standardized): 0.7093063951773528\n",
      "Epoch: 86, Loss (standarized): 0.5311267118591328\n",
      "          Validation Loss (standardized): 0.6807642838053106\n",
      "Epoch: 91, Loss (standarized): 0.5039427224924674\n",
      "          Validation Loss (standardized): 0.6568028089983227\n",
      "Epoch: 96, Loss (standarized): 0.4813352295227783\n",
      "          Validation Loss (standardized): 0.6379723635821841\n",
      "Final epoch: 100, Final loss (standarized): 0.46610577697191835\n",
      "Epoch: 1, Loss (standarized): 1.591705385345536\n",
      "          Validation Loss (standardized): 1.4697201727641973\n",
      "Epoch: 6, Loss (standarized): 1.3358943848494682\n",
      "          Validation Loss (standardized): 1.3161131828429176\n",
      "Epoch: 11, Loss (standarized): 1.2296728032445137\n",
      "          Validation Loss (standardized): 1.2334673120106476\n",
      "Epoch: 16, Loss (standarized): 1.1557425973625342\n",
      "          Validation Loss (standardized): 1.163183686634156\n",
      "Epoch: 21, Loss (standarized): 1.1009219680009568\n",
      "          Validation Loss (standardized): 1.16380686683176\n",
      "Epoch: 26, Loss (standarized): 1.0488706493577808\n",
      "          Validation Loss (standardized): 1.1027771866670364\n",
      "Epoch: 31, Loss (standarized): 0.9892762541998996\n",
      "          Validation Loss (standardized): 1.0559997815342081\n",
      "Epoch: 36, Loss (standarized): 0.9282165069070366\n",
      "          Validation Loss (standardized): 1.0014859053724314\n",
      "Epoch: 41, Loss (standarized): 0.8628590888132163\n",
      "          Validation Loss (standardized): 0.9593691977907102\n",
      "Epoch: 46, Loss (standarized): 0.7917453698502033\n",
      "          Validation Loss (standardized): 0.9059338913605284\n",
      "Epoch: 51, Loss (standarized): 0.7143007787703882\n",
      "          Validation Loss (standardized): 0.8495192346084808\n",
      "Epoch: 56, Loss (standarized): 0.6321184315993907\n",
      "          Validation Loss (standardized): 0.7958256845470865\n",
      "Epoch: 61, Loss (standarized): 0.5585188260213725\n",
      "          Validation Loss (standardized): 0.7276343293042166\n",
      "Epoch: 66, Loss (standarized): 0.49110420340248095\n",
      "          Validation Loss (standardized): 0.6659531520099855\n",
      "Epoch: 71, Loss (standarized): 0.4329496208500527\n",
      "          Validation Loss (standardized): 0.6113681335849344\n",
      "Epoch: 76, Loss (standarized): 0.3818229040363717\n",
      "          Validation Loss (standardized): 0.5589793461875743\n",
      "Epoch: 81, Loss (standarized): 0.33994112567763635\n",
      "          Validation Loss (standardized): 0.5213306490571045\n",
      "Epoch: 86, Loss (standarized): 0.3051120656664336\n",
      "          Validation Loss (standardized): 0.48988958988327236\n",
      "Epoch: 91, Loss (standarized): 0.2750565073063735\n",
      "          Validation Loss (standardized): 0.4714029055718575\n",
      "Epoch: 96, Loss (standarized): 0.249606200296575\n",
      "          Validation Loss (standardized): 0.45874173495036336\n",
      "Final epoch: 100, Final loss (standarized): 0.23257982463739957\n",
      "Epoch: 1, Loss (standarized): 1.683584225014294\n",
      "          Validation Loss (standardized): 1.684592277633168\n",
      "Epoch: 6, Loss (standarized): 1.2981946827096231\n",
      "          Validation Loss (standardized): 1.3373800620245573\n",
      "Epoch: 11, Loss (standarized): 1.2013663938327068\n",
      "          Validation Loss (standardized): 1.2119854819169555\n",
      "Epoch: 16, Loss (standarized): 1.1411870459287545\n",
      "          Validation Loss (standardized): 1.1756081283116193\n",
      "Epoch: 21, Loss (standarized): 1.0909033499022394\n",
      "          Validation Loss (standardized): 1.1664973776531529\n",
      "Epoch: 26, Loss (standarized): 1.0399354918759827\n",
      "          Validation Loss (standardized): 1.1220384319953873\n",
      "Epoch: 31, Loss (standarized): 0.9914967009370439\n",
      "          Validation Loss (standardized): 1.0788271677441716\n",
      "Epoch: 36, Loss (standarized): 0.9410275701316951\n",
      "          Validation Loss (standardized): 1.0303133897288668\n",
      "Epoch: 41, Loss (standarized): 0.8846402370119499\n",
      "          Validation Loss (standardized): 0.9939293240729231\n",
      "Epoch: 46, Loss (standarized): 0.821894947086982\n",
      "          Validation Loss (standardized): 0.940207147981876\n",
      "Epoch: 51, Loss (standarized): 0.7512121171440468\n",
      "          Validation Loss (standardized): 0.8775943465621284\n",
      "Epoch: 56, Loss (standarized): 0.673795737688755\n",
      "          Validation Loss (standardized): 0.8239874251433751\n",
      "Epoch: 61, Loss (standarized): 0.594386004949869\n",
      "          Validation Loss (standardized): 0.7612031516619279\n",
      "Epoch: 66, Loss (standarized): 0.520062062793149\n",
      "          Validation Loss (standardized): 0.7069585427440057\n",
      "Epoch: 71, Loss (standarized): 0.45565953500851175\n",
      "          Validation Loss (standardized): 0.6608882295443236\n",
      "Epoch: 76, Loss (standarized): 0.4009252795636032\n",
      "          Validation Loss (standardized): 0.6127959075658459\n",
      "Epoch: 81, Loss (standarized): 0.3538883178927993\n",
      "          Validation Loss (standardized): 0.5741456938471003\n",
      "Epoch: 86, Loss (standarized): 0.31331110587452043\n",
      "          Validation Loss (standardized): 0.5404743052365115\n",
      "Epoch: 91, Loss (standarized): 0.2821859592381228\n",
      "          Validation Loss (standardized): 0.5189364472825687\n",
      "Epoch: 96, Loss (standarized): 0.2558137079276576\n",
      "          Validation Loss (standardized): 0.4982803727538429\n",
      "Final epoch: 100, Final loss (standarized): 0.23791382222196852\n",
      "Epoch: 1, Loss (standarized): 1.8240087832578737\n",
      "          Validation Loss (standardized): 1.941230462879292\n",
      "Epoch: 6, Loss (standarized): 1.4032476487131351\n",
      "          Validation Loss (standardized): 1.4526751244612377\n",
      "Epoch: 11, Loss (standarized): 1.2983628947970727\n",
      "          Validation Loss (standardized): 1.2756776716179712\n",
      "Epoch: 16, Loss (standarized): 1.2294449672798828\n",
      "          Validation Loss (standardized): 1.2472615225802401\n",
      "Epoch: 21, Loss (standarized): 1.1881826503565787\n",
      "          Validation Loss (standardized): 1.2319676524845902\n",
      "Epoch: 26, Loss (standarized): 1.149853598338423\n",
      "          Validation Loss (standardized): 1.176051139462428\n",
      "Epoch: 31, Loss (standarized): 1.118279840457365\n",
      "          Validation Loss (standardized): 1.148132988194598\n",
      "Epoch: 36, Loss (standarized): 1.0926901954874741\n",
      "          Validation Loss (standardized): 1.140186555389605\n",
      "Epoch: 41, Loss (standarized): 1.065321848890635\n",
      "          Validation Loss (standardized): 1.1171988128416055\n",
      "Epoch: 46, Loss (standarized): 1.0364075602594665\n",
      "          Validation Loss (standardized): 1.1011106027981052\n",
      "Epoch: 51, Loss (standarized): 1.0079770677729163\n",
      "          Validation Loss (standardized): 1.0756215027701548\n",
      "Epoch: 56, Loss (standarized): 0.9767461256186379\n",
      "          Validation Loss (standardized): 1.043127922440104\n",
      "Epoch: 61, Loss (standarized): 0.94400005109132\n",
      "          Validation Loss (standardized): 1.0156372000229148\n",
      "Epoch: 66, Loss (standarized): 0.9101629813348073\n",
      "          Validation Loss (standardized): 0.9851831173580571\n",
      "Epoch: 71, Loss (standarized): 0.8776886554422342\n",
      "          Validation Loss (standardized): 0.9513745041340943\n",
      "Epoch: 76, Loss (standarized): 0.8450600141811015\n",
      "          Validation Loss (standardized): 0.9242857096824094\n",
      "Epoch: 81, Loss (standarized): 0.8130253122299237\n",
      "          Validation Loss (standardized): 0.8960075674667785\n",
      "Epoch: 86, Loss (standarized): 0.781758773525053\n",
      "          Validation Loss (standardized): 0.8732819529589674\n",
      "Epoch: 91, Loss (standarized): 0.7497112587292963\n",
      "          Validation Loss (standardized): 0.8435528321346409\n",
      "Epoch: 96, Loss (standarized): 0.7175880145727206\n",
      "          Validation Loss (standardized): 0.8183349874712881\n",
      "Final epoch: 100, Final loss (standarized): 0.6931759908975644\n",
      "Epoch: 1, Loss (standarized): 2.8077003764466557\n",
      "          Validation Loss (standardized): 2.6793313624222\n",
      "Epoch: 6, Loss (standarized): 1.7095072493932613\n",
      "          Validation Loss (standardized): 1.6849414054461644\n",
      "Epoch: 11, Loss (standarized): 1.4508525438622228\n",
      "          Validation Loss (standardized): 1.3862103458859933\n",
      "Epoch: 16, Loss (standarized): 1.337613313172481\n",
      "          Validation Loss (standardized): 1.3008340867426564\n",
      "Epoch: 21, Loss (standarized): 1.2890721711197317\n",
      "          Validation Loss (standardized): 1.2975735426819952\n",
      "Epoch: 26, Loss (standarized): 1.2564012592832396\n",
      "          Validation Loss (standardized): 1.290651910690591\n",
      "Epoch: 31, Loss (standarized): 1.233294354869857\n",
      "          Validation Loss (standardized): 1.2703490990042565\n",
      "Epoch: 36, Loss (standarized): 1.2172187128670648\n",
      "          Validation Loss (standardized): 1.2536712735184836\n",
      "Epoch: 41, Loss (standarized): 1.2014353622209801\n",
      "          Validation Loss (standardized): 1.2446255469974907\n",
      "Epoch: 46, Loss (standarized): 1.1886058898253369\n",
      "          Validation Loss (standardized): 1.236820350158494\n",
      "Epoch: 51, Loss (standarized): 1.1757559115512912\n",
      "          Validation Loss (standardized): 1.2261510554686492\n",
      "Epoch: 56, Loss (standarized): 1.160907791588067\n",
      "          Validation Loss (standardized): 1.210037438573584\n",
      "Epoch: 61, Loss (standarized): 1.1461067950958777\n",
      "          Validation Loss (standardized): 1.1946295291637894\n",
      "Epoch: 66, Loss (standarized): 1.130976499919768\n",
      "          Validation Loss (standardized): 1.1844607331686603\n",
      "Epoch: 71, Loss (standarized): 1.117194841417995\n",
      "          Validation Loss (standardized): 1.1703865872678598\n",
      "Epoch: 76, Loss (standarized): 1.103910744885189\n",
      "          Validation Loss (standardized): 1.154211530257989\n",
      "Epoch: 81, Loss (standarized): 1.0905113942572255\n",
      "          Validation Loss (standardized): 1.1440756872301105\n",
      "Epoch: 86, Loss (standarized): 1.078163240029725\n",
      "          Validation Loss (standardized): 1.1361452747934901\n",
      "Epoch: 91, Loss (standarized): 1.0658785133933806\n",
      "          Validation Loss (standardized): 1.126722309879509\n",
      "Epoch: 96, Loss (standarized): 1.0545799101482047\n",
      "          Validation Loss (standardized): 1.1194461689668334\n",
      "Final epoch: 100, Final loss (standarized): 1.0455255528527794\n",
      "Epoch: 1, Loss (standarized): 2.3390598764157122\n",
      "          Validation Loss (standardized): 2.2322304581484156\n",
      "Epoch: 6, Loss (standarized): 1.6081409160220128\n",
      "          Validation Loss (standardized): 1.474273952785818\n",
      "Epoch: 11, Loss (standarized): 1.4268603707398624\n",
      "          Validation Loss (standardized): 1.3024615808295903\n",
      "Epoch: 16, Loss (standarized): 1.3156963010768918\n",
      "          Validation Loss (standardized): 1.2560318296781499\n",
      "Epoch: 21, Loss (standarized): 1.2570171028959556\n",
      "          Validation Loss (standardized): 1.2590668596516055\n",
      "Epoch: 26, Loss (standarized): 1.2081809827067016\n",
      "          Validation Loss (standardized): 1.226407245304476\n",
      "Epoch: 31, Loss (standarized): 1.1567880364837497\n",
      "          Validation Loss (standardized): 1.1926183585879926\n",
      "Epoch: 36, Loss (standarized): 1.1250235855472919\n",
      "          Validation Loss (standardized): 1.1832342402147202\n",
      "Epoch: 41, Loss (standarized): 1.100583689854445\n",
      "          Validation Loss (standardized): 1.1633781493229653\n",
      "Epoch: 46, Loss (standarized): 1.0787412320666983\n",
      "          Validation Loss (standardized): 1.1407017246326272\n",
      "Epoch: 51, Loss (standarized): 1.059766207208426\n",
      "          Validation Loss (standardized): 1.115199928370828\n",
      "Epoch: 56, Loss (standarized): 1.0427188726581962\n",
      "          Validation Loss (standardized): 1.1027000396018878\n",
      "Epoch: 61, Loss (standarized): 1.0258621734656248\n",
      "          Validation Loss (standardized): 1.0948537207420637\n",
      "Epoch: 66, Loss (standarized): 1.0075370934014953\n",
      "          Validation Loss (standardized): 1.0777084571103457\n",
      "Epoch: 71, Loss (standarized): 0.9876699185043463\n",
      "          Validation Loss (standardized): 1.0564549823904446\n",
      "Epoch: 76, Loss (standarized): 0.9671808748751974\n",
      "          Validation Loss (standardized): 1.039952642573311\n",
      "Epoch: 81, Loss (standarized): 0.9439787047269587\n",
      "          Validation Loss (standardized): 1.0207258474542362\n",
      "Epoch: 86, Loss (standarized): 0.9171769299282052\n",
      "          Validation Loss (standardized): 0.9907519698750921\n",
      "Epoch: 91, Loss (standarized): 0.8881146823261418\n",
      "          Validation Loss (standardized): 0.96923589830388\n",
      "Epoch: 96, Loss (standarized): 0.8586545869678807\n",
      "          Validation Loss (standardized): 0.9484003407146387\n",
      "Final epoch: 100, Final loss (standarized): 0.8338658270475832\n",
      "Epoch: 1, Loss (standarized): 2.025181078019668\n",
      "          Validation Loss (standardized): 1.4891674923011355\n",
      "Epoch: 6, Loss (standarized): 1.4857822041176945\n",
      "          Validation Loss (standardized): 1.4344269348384078\n",
      "Epoch: 11, Loss (standarized): 1.3645734148227546\n",
      "          Validation Loss (standardized): 1.3944569463694907\n",
      "Epoch: 16, Loss (standarized): 1.321540673097926\n",
      "          Validation Loss (standardized): 1.3599634709579145\n",
      "Epoch: 21, Loss (standarized): 1.270035121767281\n",
      "          Validation Loss (standardized): 1.3015263014552907\n",
      "Epoch: 26, Loss (standarized): 1.2329606634156625\n",
      "          Validation Loss (standardized): 1.2581619962368769\n",
      "Epoch: 31, Loss (standarized): 1.2048602828040202\n",
      "          Validation Loss (standardized): 1.2276318724696085\n",
      "Epoch: 36, Loss (standarized): 1.181127006954215\n",
      "          Validation Loss (standardized): 1.2138246333279912\n",
      "Epoch: 41, Loss (standarized): 1.1573367137671138\n",
      "          Validation Loss (standardized): 1.2073450637683512\n",
      "Epoch: 46, Loss (standarized): 1.1320389904000705\n",
      "          Validation Loss (standardized): 1.184249460679839\n",
      "Epoch: 51, Loss (standarized): 1.104453353026007\n",
      "          Validation Loss (standardized): 1.158573188413965\n",
      "Epoch: 56, Loss (standarized): 1.0770135317800866\n",
      "          Validation Loss (standardized): 1.1285979233997454\n",
      "Epoch: 61, Loss (standarized): 1.0469595037491535\n",
      "          Validation Loss (standardized): 1.1024952974592441\n",
      "Epoch: 66, Loss (standarized): 1.0148442409276526\n",
      "          Validation Loss (standardized): 1.0757191371367711\n",
      "Epoch: 71, Loss (standarized): 0.9811950009408636\n",
      "          Validation Loss (standardized): 1.0426479181790091\n",
      "Epoch: 76, Loss (standarized): 0.9487795776466477\n",
      "          Validation Loss (standardized): 1.0114558399516853\n",
      "Epoch: 81, Loss (standarized): 0.9173449069343141\n",
      "          Validation Loss (standardized): 0.9885977914906625\n",
      "Epoch: 86, Loss (standarized): 0.8845462844264697\n",
      "          Validation Loss (standardized): 0.9638757016310051\n",
      "Epoch: 91, Loss (standarized): 0.8524045271367552\n",
      "          Validation Loss (standardized): 0.9391136387828312\n",
      "Epoch: 96, Loss (standarized): 0.8212964539781273\n",
      "          Validation Loss (standardized): 0.9107179005866671\n",
      "Final epoch: 100, Final loss (standarized): 0.7960826595970992\n",
      "Epoch: 1, Loss (standarized): 1.8730783635936206\n",
      "          Validation Loss (standardized): 1.7287120130607896\n",
      "Epoch: 6, Loss (standarized): 1.4404233597877925\n",
      "          Validation Loss (standardized): 1.3410534641229337\n",
      "Epoch: 11, Loss (standarized): 1.3337582254652651\n",
      "          Validation Loss (standardized): 1.3495286439220557\n",
      "Epoch: 16, Loss (standarized): 1.2791629182324495\n",
      "          Validation Loss (standardized): 1.3313777064818597\n",
      "Epoch: 21, Loss (standarized): 1.2236189131185518\n",
      "          Validation Loss (standardized): 1.2652263817889702\n",
      "Epoch: 26, Loss (standarized): 1.1752477277693465\n",
      "          Validation Loss (standardized): 1.2046867207224592\n",
      "Epoch: 31, Loss (standarized): 1.1279371849112443\n",
      "          Validation Loss (standardized): 1.167661668862309\n",
      "Epoch: 36, Loss (standarized): 1.0819338571328665\n",
      "          Validation Loss (standardized): 1.131764792371595\n",
      "Epoch: 41, Loss (standarized): 1.03020291160166\n",
      "          Validation Loss (standardized): 1.099347566252399\n",
      "Epoch: 46, Loss (standarized): 0.9709977767000495\n",
      "          Validation Loss (standardized): 1.0530417181851481\n",
      "Epoch: 51, Loss (standarized): 0.9055288572429435\n",
      "          Validation Loss (standardized): 0.9918874972554317\n",
      "Epoch: 56, Loss (standarized): 0.8348326348639259\n",
      "          Validation Loss (standardized): 0.9318637548561037\n",
      "Epoch: 61, Loss (standarized): 0.7595115400816426\n",
      "          Validation Loss (standardized): 0.8696137348758625\n",
      "Epoch: 66, Loss (standarized): 0.6846520364602217\n",
      "          Validation Loss (standardized): 0.8086487064535158\n",
      "Epoch: 71, Loss (standarized): 0.6148255164110781\n",
      "          Validation Loss (standardized): 0.7556534370002539\n",
      "Epoch: 76, Loss (standarized): 0.5520874490095453\n",
      "          Validation Loss (standardized): 0.7083162822962075\n",
      "Epoch: 81, Loss (standarized): 0.4986654958880273\n",
      "          Validation Loss (standardized): 0.6680829992487334\n",
      "Epoch: 86, Loss (standarized): 0.45262960637802424\n",
      "          Validation Loss (standardized): 0.6334820970426119\n",
      "Epoch: 91, Loss (standarized): 0.41352614608938054\n",
      "          Validation Loss (standardized): 0.6044721196801455\n",
      "Epoch: 96, Loss (standarized): 0.37944253090716773\n",
      "          Validation Loss (standardized): 0.5747327213162271\n",
      "Final epoch: 100, Final loss (standarized): 0.3549830137925995\n",
      "Epoch: 1, Loss (standarized): 2.077403684763719\n",
      "          Validation Loss (standardized): 1.7272745290510452\n",
      "Epoch: 6, Loss (standarized): 1.4504682692149755\n",
      "          Validation Loss (standardized): 1.3931695832226079\n",
      "Epoch: 11, Loss (standarized): 1.2874874236116873\n",
      "          Validation Loss (standardized): 1.3140115475485137\n",
      "Epoch: 16, Loss (standarized): 1.2194744416539922\n",
      "          Validation Loss (standardized): 1.2505062342493056\n",
      "Epoch: 21, Loss (standarized): 1.1832448713090222\n",
      "          Validation Loss (standardized): 1.2170528417836113\n",
      "Epoch: 26, Loss (standarized): 1.150415590561623\n",
      "          Validation Loss (standardized): 1.2020265435595512\n",
      "Epoch: 31, Loss (standarized): 1.1217158063200892\n",
      "          Validation Loss (standardized): 1.1708586571336723\n",
      "Epoch: 36, Loss (standarized): 1.0915537303859362\n",
      "          Validation Loss (standardized): 1.147341517613248\n",
      "Epoch: 41, Loss (standarized): 1.0607459134823345\n",
      "          Validation Loss (standardized): 1.1204361074325295\n",
      "Epoch: 46, Loss (standarized): 1.0292859654958386\n",
      "          Validation Loss (standardized): 1.0896003643951995\n",
      "Epoch: 51, Loss (standarized): 0.9943546316623808\n",
      "          Validation Loss (standardized): 1.0599912066248525\n",
      "Epoch: 56, Loss (standarized): 0.9554624139899349\n",
      "          Validation Loss (standardized): 1.0260824475119212\n",
      "Epoch: 61, Loss (standarized): 0.9138188388985634\n",
      "          Validation Loss (standardized): 0.9905197473590833\n",
      "Epoch: 66, Loss (standarized): 0.8711750266530041\n",
      "          Validation Loss (standardized): 0.9515821869951501\n",
      "Epoch: 71, Loss (standarized): 0.8279504539027708\n",
      "          Validation Loss (standardized): 0.9162718168836571\n",
      "Epoch: 76, Loss (standarized): 0.7872896339350446\n",
      "          Validation Loss (standardized): 0.8805235845679529\n",
      "Epoch: 81, Loss (standarized): 0.74795341994163\n",
      "          Validation Loss (standardized): 0.8514067320176298\n",
      "Epoch: 86, Loss (standarized): 0.7108846702488855\n",
      "          Validation Loss (standardized): 0.8177640702567651\n",
      "Epoch: 91, Loss (standarized): 0.6769872591534397\n",
      "          Validation Loss (standardized): 0.7921617475338362\n",
      "Epoch: 96, Loss (standarized): 0.6461030903444055\n",
      "          Validation Loss (standardized): 0.769335557392034\n",
      "Final epoch: 100, Final loss (standarized): 0.6235300367766728\n",
      "Epoch: 1, Loss (standarized): 2.306871012450967\n",
      "          Validation Loss (standardized): 2.032056394742165\n",
      "Epoch: 6, Loss (standarized): 1.4140561405657621\n",
      "          Validation Loss (standardized): 1.4048936213938286\n",
      "Epoch: 11, Loss (standarized): 1.3090107715698536\n",
      "          Validation Loss (standardized): 1.3292016559736712\n",
      "Epoch: 16, Loss (standarized): 1.229893173889638\n",
      "          Validation Loss (standardized): 1.2504245182667004\n",
      "Epoch: 21, Loss (standarized): 1.1708056090503525\n",
      "          Validation Loss (standardized): 1.1889945483488233\n",
      "Epoch: 26, Loss (standarized): 1.1224806753055436\n",
      "          Validation Loss (standardized): 1.1612775908232795\n",
      "Epoch: 31, Loss (standarized): 1.0787177917777924\n",
      "          Validation Loss (standardized): 1.1328502198135701\n",
      "Epoch: 36, Loss (standarized): 1.034970820049573\n",
      "          Validation Loss (standardized): 1.1092427381426628\n",
      "Epoch: 41, Loss (standarized): 0.9913256774215747\n",
      "          Validation Loss (standardized): 1.0846941347533652\n",
      "Epoch: 46, Loss (standarized): 0.9450148981692983\n",
      "          Validation Loss (standardized): 1.0508907916830204\n",
      "Epoch: 51, Loss (standarized): 0.8981075807731866\n",
      "          Validation Loss (standardized): 1.0127999950218312\n",
      "Epoch: 56, Loss (standarized): 0.8528274871453942\n",
      "          Validation Loss (standardized): 0.9759105926691759\n",
      "Epoch: 61, Loss (standarized): 0.8080876752351993\n",
      "          Validation Loss (standardized): 0.9455852650215687\n",
      "Epoch: 66, Loss (standarized): 0.7605847817161512\n",
      "          Validation Loss (standardized): 0.9119833497354639\n",
      "Epoch: 71, Loss (standarized): 0.7144071784455935\n",
      "          Validation Loss (standardized): 0.8732106149279949\n",
      "Epoch: 76, Loss (standarized): 0.6673176046467614\n",
      "          Validation Loss (standardized): 0.8355763948995851\n",
      "Epoch: 81, Loss (standarized): 0.6195833611807591\n",
      "          Validation Loss (standardized): 0.7836870822892172\n",
      "Epoch: 86, Loss (standarized): 0.5749046760689587\n",
      "          Validation Loss (standardized): 0.7425238581885785\n",
      "Epoch: 91, Loss (standarized): 0.534806161981905\n",
      "          Validation Loss (standardized): 0.7039668571344462\n",
      "Epoch: 96, Loss (standarized): 0.49699984601176284\n",
      "          Validation Loss (standardized): 0.6676926144451167\n",
      "Final epoch: 100, Final loss (standarized): 0.4683923700373322\n",
      "Epoch: 1, Loss (standarized): 3.23346386948477\n",
      "          Validation Loss (standardized): 2.4978606493199114\n",
      "Epoch: 6, Loss (standarized): 1.6349974784328465\n",
      "          Validation Loss (standardized): 1.6449759453418797\n",
      "Epoch: 11, Loss (standarized): 1.4120811299367495\n",
      "          Validation Loss (standardized): 1.4762472494446743\n",
      "Epoch: 16, Loss (standarized): 1.349961076335498\n",
      "          Validation Loss (standardized): 1.3677694338360173\n",
      "Epoch: 21, Loss (standarized): 1.2777912904668345\n",
      "          Validation Loss (standardized): 1.2990846195329853\n",
      "Epoch: 26, Loss (standarized): 1.2317334971900875\n",
      "          Validation Loss (standardized): 1.2550822921145657\n",
      "Epoch: 31, Loss (standarized): 1.1835112623233295\n",
      "          Validation Loss (standardized): 1.2125363503623139\n",
      "Epoch: 36, Loss (standarized): 1.1340914860124278\n",
      "          Validation Loss (standardized): 1.1911601589578806\n",
      "Epoch: 41, Loss (standarized): 1.0947425332086214\n",
      "          Validation Loss (standardized): 1.1756259534181417\n",
      "Epoch: 46, Loss (standarized): 1.0504145610636393\n",
      "          Validation Loss (standardized): 1.1232649472061493\n",
      "Epoch: 51, Loss (standarized): 1.0117579224751543\n",
      "          Validation Loss (standardized): 1.0894465415845305\n",
      "Epoch: 56, Loss (standarized): 0.9709431170171228\n",
      "          Validation Loss (standardized): 1.0868401604450633\n",
      "Epoch: 61, Loss (standarized): 0.9314659541139477\n",
      "          Validation Loss (standardized): 1.053371894047524\n",
      "Epoch: 66, Loss (standarized): 0.89089400042244\n",
      "          Validation Loss (standardized): 1.0250655135870361\n",
      "Epoch: 71, Loss (standarized): 0.8501124338612908\n",
      "          Validation Loss (standardized): 0.9991832667330797\n",
      "Epoch: 76, Loss (standarized): 0.8099509156163129\n",
      "          Validation Loss (standardized): 0.9683297926985249\n",
      "Epoch: 81, Loss (standarized): 0.7704677971822348\n",
      "          Validation Loss (standardized): 0.9363035864495088\n",
      "Epoch: 86, Loss (standarized): 0.7339855771538915\n",
      "          Validation Loss (standardized): 0.910999402953793\n",
      "Epoch: 91, Loss (standarized): 0.6981279977801984\n",
      "          Validation Loss (standardized): 0.8795973742207978\n",
      "Epoch: 96, Loss (standarized): 0.6611022296064327\n",
      "          Validation Loss (standardized): 0.851324598738322\n",
      "Final epoch: 100, Final loss (standarized): 0.6330279295737884\n",
      "Epoch: 1, Loss (standarized): 2.215841927330449\n",
      "          Validation Loss (standardized): 1.7547398906976253\n",
      "Epoch: 6, Loss (standarized): 1.4841448578784082\n",
      "          Validation Loss (standardized): 1.4108645199994407\n",
      "Epoch: 11, Loss (standarized): 1.3110177535448568\n",
      "          Validation Loss (standardized): 1.328293083053249\n",
      "Epoch: 16, Loss (standarized): 1.2177448219103744\n",
      "          Validation Loss (standardized): 1.2587362712364245\n",
      "Epoch: 21, Loss (standarized): 1.1437080384723801\n",
      "          Validation Loss (standardized): 1.204533804567846\n",
      "Epoch: 26, Loss (standarized): 1.088218085144701\n",
      "          Validation Loss (standardized): 1.1748869591591025\n",
      "Epoch: 31, Loss (standarized): 1.04097832613966\n",
      "          Validation Loss (standardized): 1.1511885148956136\n",
      "Epoch: 36, Loss (standarized): 1.001513517104166\n",
      "          Validation Loss (standardized): 1.1204739050378747\n",
      "Epoch: 41, Loss (standarized): 0.9526691807012306\n",
      "          Validation Loss (standardized): 1.0820614239743467\n",
      "Epoch: 46, Loss (standarized): 0.9012528427729309\n",
      "          Validation Loss (standardized): 1.0485261316982637\n",
      "Epoch: 51, Loss (standarized): 0.8548676375354638\n",
      "          Validation Loss (standardized): 1.0244364896252482\n",
      "Epoch: 56, Loss (standarized): 0.808339830732042\n",
      "          Validation Loss (standardized): 0.9910622572145243\n",
      "Epoch: 61, Loss (standarized): 0.7586396427941468\n",
      "          Validation Loss (standardized): 0.9453116048323732\n",
      "Epoch: 66, Loss (standarized): 0.7093331704966772\n",
      "          Validation Loss (standardized): 0.9053404962914672\n",
      "Epoch: 71, Loss (standarized): 0.6592923922152104\n",
      "          Validation Loss (standardized): 0.8647484641101848\n",
      "Epoch: 76, Loss (standarized): 0.6095916855847937\n",
      "          Validation Loss (standardized): 0.8189128384455895\n",
      "Epoch: 81, Loss (standarized): 0.5582762672099313\n",
      "          Validation Loss (standardized): 0.7687891251646569\n",
      "Epoch: 86, Loss (standarized): 0.5062327159437197\n",
      "          Validation Loss (standardized): 0.7174581988717156\n",
      "Epoch: 91, Loss (standarized): 0.45782917423355923\n",
      "          Validation Loss (standardized): 0.6694769012522932\n",
      "Epoch: 96, Loss (standarized): 0.4123899486657619\n",
      "          Validation Loss (standardized): 0.6259903737044238\n",
      "Final epoch: 100, Final loss (standarized): 0.3766448053367138\n",
      "Epoch: 1, Loss (standarized): 2.4412030797384396\n",
      "          Validation Loss (standardized): 2.163731994079667\n",
      "Epoch: 6, Loss (standarized): 1.4553803540649102\n",
      "          Validation Loss (standardized): 1.453979521156946\n",
      "Epoch: 11, Loss (standarized): 1.3220113732093142\n",
      "          Validation Loss (standardized): 1.2732283521373753\n",
      "Epoch: 16, Loss (standarized): 1.2459068328332463\n",
      "          Validation Loss (standardized): 1.1922357899391778\n",
      "Epoch: 21, Loss (standarized): 1.178921329779432\n",
      "          Validation Loss (standardized): 1.2125005262203934\n",
      "Epoch: 26, Loss (standarized): 1.1279390489400583\n",
      "          Validation Loss (standardized): 1.2196517495303556\n",
      "Epoch: 31, Loss (standarized): 1.0861545843828853\n",
      "          Validation Loss (standardized): 1.1740644093204997\n",
      "Epoch: 36, Loss (standarized): 1.0480921401924561\n",
      "          Validation Loss (standardized): 1.1231868062799426\n",
      "Epoch: 41, Loss (standarized): 1.0094814683144104\n",
      "          Validation Loss (standardized): 1.0890237992006533\n",
      "Epoch: 46, Loss (standarized): 0.9695541838564975\n",
      "          Validation Loss (standardized): 1.0605790677604203\n",
      "Epoch: 51, Loss (standarized): 0.9296480234279002\n",
      "          Validation Loss (standardized): 1.0264584661517624\n",
      "Epoch: 56, Loss (standarized): 0.8894774854289662\n",
      "          Validation Loss (standardized): 0.9898681104873419\n",
      "Epoch: 61, Loss (standarized): 0.8492095850713127\n",
      "          Validation Loss (standardized): 0.9642601207116703\n",
      "Epoch: 66, Loss (standarized): 0.8092981455457597\n",
      "          Validation Loss (standardized): 0.9375182142251192\n",
      "Epoch: 71, Loss (standarized): 0.7703379415070459\n",
      "          Validation Loss (standardized): 0.9038876447115922\n",
      "Epoch: 76, Loss (standarized): 0.7333782302219626\n",
      "          Validation Loss (standardized): 0.8788803613389162\n",
      "Epoch: 81, Loss (standarized): 0.6987107098864869\n",
      "          Validation Loss (standardized): 0.8488851699825429\n",
      "Epoch: 86, Loss (standarized): 0.6670521318293428\n",
      "          Validation Loss (standardized): 0.8270184509269443\n",
      "Epoch: 91, Loss (standarized): 0.6368578355530852\n",
      "          Validation Loss (standardized): 0.7997987159034\n",
      "Epoch: 96, Loss (standarized): 0.6083664004803352\n",
      "          Validation Loss (standardized): 0.7770061964161126\n",
      "Final epoch: 100, Final loss (standarized): 0.586324701301908\n",
      "Epoch: 1, Loss (standarized): 1.9739904249054603\n",
      "          Validation Loss (standardized): 1.498632708910984\n",
      "Epoch: 6, Loss (standarized): 1.409250571479225\n",
      "          Validation Loss (standardized): 1.3537160127119217\n",
      "Epoch: 11, Loss (standarized): 1.25227481231939\n",
      "          Validation Loss (standardized): 1.2521630433799809\n",
      "Epoch: 16, Loss (standarized): 1.1605930644723428\n",
      "          Validation Loss (standardized): 1.1767643268853094\n",
      "Epoch: 21, Loss (standarized): 1.1118718600652893\n",
      "          Validation Loss (standardized): 1.1433387439703082\n",
      "Epoch: 26, Loss (standarized): 1.0617213990020118\n",
      "          Validation Loss (standardized): 1.0990257733900897\n",
      "Epoch: 31, Loss (standarized): 1.0174770276167124\n",
      "          Validation Loss (standardized): 1.0835525750925001\n",
      "Epoch: 36, Loss (standarized): 0.9692293654032249\n",
      "          Validation Loss (standardized): 1.03116812601442\n",
      "Epoch: 41, Loss (standarized): 0.9179104851822841\n",
      "          Validation Loss (standardized): 0.9851314570864206\n",
      "Epoch: 46, Loss (standarized): 0.8586221194602248\n",
      "          Validation Loss (standardized): 0.9417254101838357\n",
      "Epoch: 51, Loss (standarized): 0.7939548741599921\n",
      "          Validation Loss (standardized): 0.8845291801936938\n",
      "Epoch: 56, Loss (standarized): 0.7302527541815718\n",
      "          Validation Loss (standardized): 0.8294815452736953\n",
      "Epoch: 61, Loss (standarized): 0.6688458817639353\n",
      "          Validation Loss (standardized): 0.7747363559514905\n",
      "Epoch: 66, Loss (standarized): 0.6101293133585642\n",
      "          Validation Loss (standardized): 0.719610715730695\n",
      "Epoch: 71, Loss (standarized): 0.5537578602656003\n",
      "          Validation Loss (standardized): 0.6654791356862171\n",
      "Epoch: 76, Loss (standarized): 0.49936751989455913\n",
      "          Validation Loss (standardized): 0.621383835431134\n",
      "Epoch: 81, Loss (standarized): 0.44964925576833975\n",
      "          Validation Loss (standardized): 0.5823054527462925\n",
      "Epoch: 86, Loss (standarized): 0.40310183813729195\n",
      "          Validation Loss (standardized): 0.5462679910447485\n",
      "Epoch: 91, Loss (standarized): 0.36250241551516865\n",
      "          Validation Loss (standardized): 0.5113605356486076\n",
      "Epoch: 96, Loss (standarized): 0.32671410673926465\n",
      "          Validation Loss (standardized): 0.485461172435124\n",
      "Final epoch: 100, Final loss (standarized): 0.30140649154095855\n",
      "Epoch: 1, Loss (standarized): 1.8892517092883383\n",
      "          Validation Loss (standardized): 1.6653638992302318\n",
      "Epoch: 6, Loss (standarized): 1.4107665534394311\n",
      "          Validation Loss (standardized): 1.341273158965681\n",
      "Epoch: 11, Loss (standarized): 1.2904046780426979\n",
      "          Validation Loss (standardized): 1.3240961656956443\n",
      "Epoch: 16, Loss (standarized): 1.2027540103544718\n",
      "          Validation Loss (standardized): 1.2575828769386959\n",
      "Epoch: 21, Loss (standarized): 1.1313747850292213\n",
      "          Validation Loss (standardized): 1.2422832590474868\n",
      "Epoch: 26, Loss (standarized): 1.0843320647437615\n",
      "          Validation Loss (standardized): 1.2231302226357765\n",
      "Epoch: 31, Loss (standarized): 1.0350259277982095\n",
      "          Validation Loss (standardized): 1.1720961917381183\n",
      "Epoch: 36, Loss (standarized): 0.9889061728522143\n",
      "          Validation Loss (standardized): 1.141300312384184\n",
      "Epoch: 41, Loss (standarized): 0.9404307876325578\n",
      "          Validation Loss (standardized): 1.1063454299072684\n",
      "Epoch: 46, Loss (standarized): 0.8908057464364404\n",
      "          Validation Loss (standardized): 1.071615631320235\n",
      "Epoch: 51, Loss (standarized): 0.8391953836719853\n",
      "          Validation Loss (standardized): 1.0175576541493243\n",
      "Epoch: 56, Loss (standarized): 0.7896681632339935\n",
      "          Validation Loss (standardized): 0.9713136991992621\n",
      "Epoch: 61, Loss (standarized): 0.7405841397499303\n",
      "          Validation Loss (standardized): 0.9292316349456544\n",
      "Epoch: 66, Loss (standarized): 0.690965372956221\n",
      "          Validation Loss (standardized): 0.8768759348311382\n",
      "Epoch: 71, Loss (standarized): 0.6406536411868821\n",
      "          Validation Loss (standardized): 0.8293907019454541\n",
      "Epoch: 76, Loss (standarized): 0.5920185211783504\n",
      "          Validation Loss (standardized): 0.7870766916080074\n",
      "Epoch: 81, Loss (standarized): 0.5459540372042505\n",
      "          Validation Loss (standardized): 0.7431833620197297\n",
      "Epoch: 86, Loss (standarized): 0.5031614289460816\n",
      "          Validation Loss (standardized): 0.6999284028705058\n",
      "Epoch: 91, Loss (standarized): 0.4634922151754839\n",
      "          Validation Loss (standardized): 0.6608122646520389\n",
      "Epoch: 96, Loss (standarized): 0.42416146195731513\n",
      "          Validation Loss (standardized): 0.6246720579755152\n",
      "Final epoch: 100, Final loss (standarized): 0.3955034384298308\n",
      "Epoch: 1, Loss (standarized): 2.3293333447731315\n",
      "          Validation Loss (standardized): 2.329307629238964\n",
      "Epoch: 6, Loss (standarized): 1.562537872490823\n",
      "          Validation Loss (standardized): 1.5565038878194013\n",
      "Epoch: 11, Loss (standarized): 1.373797316216112\n",
      "          Validation Loss (standardized): 1.3391971708860668\n",
      "Epoch: 16, Loss (standarized): 1.266507535586382\n",
      "          Validation Loss (standardized): 1.265946185136423\n",
      "Epoch: 21, Loss (standarized): 1.204257239169883\n",
      "          Validation Loss (standardized): 1.232721444609865\n",
      "Epoch: 26, Loss (standarized): 1.1467365569769101\n",
      "          Validation Loss (standardized): 1.1939461143648151\n",
      "Epoch: 31, Loss (standarized): 1.1061587443393888\n",
      "          Validation Loss (standardized): 1.1529356704365628\n",
      "Epoch: 36, Loss (standarized): 1.0604979974993285\n",
      "          Validation Loss (standardized): 1.1276589806857227\n",
      "Epoch: 41, Loss (standarized): 1.0109819065458532\n",
      "          Validation Loss (standardized): 1.0947085751564747\n",
      "Epoch: 46, Loss (standarized): 0.9585173431796172\n",
      "          Validation Loss (standardized): 1.0423184344135097\n",
      "Epoch: 51, Loss (standarized): 0.9037536785117061\n",
      "          Validation Loss (standardized): 1.0116922518671265\n",
      "Epoch: 56, Loss (standarized): 0.8495522890547114\n",
      "          Validation Loss (standardized): 0.9870732913603184\n",
      "Epoch: 61, Loss (standarized): 0.7950694648288303\n",
      "          Validation Loss (standardized): 0.9288240246283197\n",
      "Epoch: 66, Loss (standarized): 0.7429468198094064\n",
      "          Validation Loss (standardized): 0.8928604890160843\n",
      "Epoch: 71, Loss (standarized): 0.691514676414466\n",
      "          Validation Loss (standardized): 0.8504691056529446\n",
      "Epoch: 76, Loss (standarized): 0.6419915768045334\n",
      "          Validation Loss (standardized): 0.8109379247866327\n",
      "Epoch: 81, Loss (standarized): 0.5923243843319099\n",
      "          Validation Loss (standardized): 0.766484389806139\n",
      "Epoch: 86, Loss (standarized): 0.5444353485878598\n",
      "          Validation Loss (standardized): 0.7264119871080539\n",
      "Epoch: 91, Loss (standarized): 0.4987275014655978\n",
      "          Validation Loss (standardized): 0.6863627052495872\n",
      "Epoch: 96, Loss (standarized): 0.45722710583137427\n",
      "          Validation Loss (standardized): 0.6537162768697802\n",
      "Final epoch: 100, Final loss (standarized): 0.4275169288085891\n",
      "Epoch: 1, Loss (standarized): 2.249219574414355\n",
      "          Validation Loss (standardized): 1.8586543786567613\n",
      "Epoch: 6, Loss (standarized): 1.4221050325160929\n",
      "          Validation Loss (standardized): 1.3991093368615852\n",
      "Epoch: 11, Loss (standarized): 1.2200518990609392\n",
      "          Validation Loss (standardized): 1.256339452708432\n",
      "Epoch: 16, Loss (standarized): 1.1809038851161084\n",
      "          Validation Loss (standardized): 1.235665293126428\n",
      "Epoch: 21, Loss (standarized): 1.1190085933568485\n",
      "          Validation Loss (standardized): 1.1921683299413184\n",
      "Epoch: 26, Loss (standarized): 1.080385712820963\n",
      "          Validation Loss (standardized): 1.1370631288949464\n",
      "Epoch: 31, Loss (standarized): 1.038782832514305\n",
      "          Validation Loss (standardized): 1.102911863486289\n",
      "Epoch: 36, Loss (standarized): 0.9953624840639727\n",
      "          Validation Loss (standardized): 1.074214520010115\n",
      "Epoch: 41, Loss (standarized): 0.954035224285964\n",
      "          Validation Loss (standardized): 1.046629801338574\n",
      "Epoch: 46, Loss (standarized): 0.9126275577480399\n",
      "          Validation Loss (standardized): 1.021397477374666\n",
      "Epoch: 51, Loss (standarized): 0.8716485180193012\n",
      "          Validation Loss (standardized): 0.9829607088988446\n",
      "Epoch: 56, Loss (standarized): 0.8302486781546159\n",
      "          Validation Loss (standardized): 0.943361701998305\n",
      "Epoch: 61, Loss (standarized): 0.7879368014852537\n",
      "          Validation Loss (standardized): 0.9081768486083841\n",
      "Epoch: 66, Loss (standarized): 0.7476923792325775\n",
      "          Validation Loss (standardized): 0.8779001865343037\n",
      "Epoch: 71, Loss (standarized): 0.7081398801970383\n",
      "          Validation Loss (standardized): 0.8428001289415945\n",
      "Epoch: 76, Loss (standarized): 0.6713135600491807\n",
      "          Validation Loss (standardized): 0.8150129049429099\n",
      "Epoch: 81, Loss (standarized): 0.6376130932700012\n",
      "          Validation Loss (standardized): 0.7829934762461159\n",
      "Epoch: 86, Loss (standarized): 0.6068779117628459\n",
      "          Validation Loss (standardized): 0.7613984556730398\n",
      "Epoch: 91, Loss (standarized): 0.5791037048207364\n",
      "          Validation Loss (standardized): 0.7344148585760106\n",
      "Epoch: 96, Loss (standarized): 0.5544855779356277\n",
      "          Validation Loss (standardized): 0.7165271371826762\n",
      "Final epoch: 100, Final loss (standarized): 0.5366136690440817\n",
      "Epoch: 1, Loss (standarized): 2.930615494763164\n",
      "          Validation Loss (standardized): 2.4337724723802143\n",
      "Epoch: 6, Loss (standarized): 1.5482681360798227\n",
      "          Validation Loss (standardized): 1.4844907750436092\n",
      "Epoch: 11, Loss (standarized): 1.257172759460842\n",
      "          Validation Loss (standardized): 1.2245808299359606\n",
      "Epoch: 16, Loss (standarized): 1.2051154699941389\n",
      "          Validation Loss (standardized): 1.2323792809695537\n",
      "Epoch: 21, Loss (standarized): 1.1810716157914363\n",
      "          Validation Loss (standardized): 1.2815936585091448\n",
      "Epoch: 26, Loss (standarized): 1.1332425509739128\n",
      "          Validation Loss (standardized): 1.2098922759153756\n",
      "Epoch: 31, Loss (standarized): 1.0873291453486278\n",
      "          Validation Loss (standardized): 1.149842785583456\n",
      "Epoch: 36, Loss (standarized): 1.0497394753233917\n",
      "          Validation Loss (standardized): 1.1092232126358328\n",
      "Epoch: 41, Loss (standarized): 1.0141176364439963\n",
      "          Validation Loss (standardized): 1.0745600782915194\n",
      "Epoch: 46, Loss (standarized): 0.9767660480464719\n",
      "          Validation Loss (standardized): 1.0449066007628558\n",
      "Epoch: 51, Loss (standarized): 0.935574716207827\n",
      "          Validation Loss (standardized): 1.0186238345719445\n",
      "Epoch: 56, Loss (standarized): 0.8873783518953589\n",
      "          Validation Loss (standardized): 0.9810395998241768\n",
      "Epoch: 61, Loss (standarized): 0.8348353973898017\n",
      "          Validation Loss (standardized): 0.9533089017944081\n",
      "Epoch: 66, Loss (standarized): 0.7840647156586468\n",
      "          Validation Loss (standardized): 0.9099704183256245\n",
      "Epoch: 71, Loss (standarized): 0.7365911608893887\n",
      "          Validation Loss (standardized): 0.8691879346457707\n",
      "Epoch: 76, Loss (standarized): 0.6906008182755546\n",
      "          Validation Loss (standardized): 0.8317308915165789\n",
      "Epoch: 81, Loss (standarized): 0.6457256273748694\n",
      "          Validation Loss (standardized): 0.7932137368362581\n",
      "Epoch: 86, Loss (standarized): 0.6013706969536499\n",
      "          Validation Loss (standardized): 0.7512951333704152\n",
      "Epoch: 91, Loss (standarized): 0.5584276768006557\n",
      "          Validation Loss (standardized): 0.7137403039843855\n",
      "Epoch: 96, Loss (standarized): 0.5179180649718005\n",
      "          Validation Loss (standardized): 0.6774266165445636\n",
      "Final epoch: 100, Final loss (standarized): 0.48728411431098434\n",
      "Epoch: 1, Loss (standarized): 1.6583038586182786\n",
      "          Validation Loss (standardized): 1.5057219546565443\n",
      "Epoch: 6, Loss (standarized): 1.2907516868852946\n",
      "          Validation Loss (standardized): 1.2700333978127065\n",
      "Epoch: 11, Loss (standarized): 1.17131246812022\n",
      "          Validation Loss (standardized): 1.2263546608054507\n",
      "Epoch: 16, Loss (standarized): 1.1153222048221867\n",
      "          Validation Loss (standardized): 1.1806012481742667\n",
      "Epoch: 21, Loss (standarized): 1.0566293336335553\n",
      "          Validation Loss (standardized): 1.1334105319173855\n",
      "Epoch: 26, Loss (standarized): 1.0020847887485633\n",
      "          Validation Loss (standardized): 1.110646590963055\n",
      "Epoch: 31, Loss (standarized): 0.9490391801445947\n",
      "          Validation Loss (standardized): 1.077833971933484\n",
      "Epoch: 36, Loss (standarized): 0.8898876414016957\n",
      "          Validation Loss (standardized): 1.0232446106658548\n",
      "Epoch: 41, Loss (standarized): 0.8281475806209232\n",
      "          Validation Loss (standardized): 0.9788484790360371\n",
      "Epoch: 46, Loss (standarized): 0.7606209039721997\n",
      "          Validation Loss (standardized): 0.9200491184638467\n",
      "Epoch: 51, Loss (standarized): 0.689292779709124\n",
      "          Validation Loss (standardized): 0.8570993680078945\n",
      "Epoch: 56, Loss (standarized): 0.61587721260273\n",
      "          Validation Loss (standardized): 0.7879667477281311\n",
      "Epoch: 61, Loss (standarized): 0.5451956104888365\n",
      "          Validation Loss (standardized): 0.7199198494881722\n",
      "Epoch: 66, Loss (standarized): 0.4803666825322977\n",
      "          Validation Loss (standardized): 0.648394921236115\n",
      "Epoch: 71, Loss (standarized): 0.4244043472260694\n",
      "          Validation Loss (standardized): 0.5918185307681576\n",
      "Epoch: 76, Loss (standarized): 0.3742152036453594\n",
      "          Validation Loss (standardized): 0.5495758379129968\n",
      "Epoch: 81, Loss (standarized): 0.3346168131004189\n",
      "          Validation Loss (standardized): 0.5163467760720148\n",
      "Epoch: 86, Loss (standarized): 0.30234926609545104\n",
      "          Validation Loss (standardized): 0.49219539373144744\n",
      "Epoch: 91, Loss (standarized): 0.2752401639338472\n",
      "          Validation Loss (standardized): 0.4783139179844853\n",
      "Epoch: 96, Loss (standarized): 0.2517080463633572\n",
      "          Validation Loss (standardized): 0.46957164191112544\n",
      "Final epoch: 100, Final loss (standarized): 0.23560102962741333\n",
      "Epoch: 1, Loss (standarized): 2.13277589322369\n",
      "          Validation Loss (standardized): 1.9542979384554335\n",
      "Epoch: 6, Loss (standarized): 1.5540608075817948\n",
      "          Validation Loss (standardized): 1.507299508184708\n",
      "Epoch: 11, Loss (standarized): 1.383404260061606\n",
      "          Validation Loss (standardized): 1.4070422858877796\n",
      "Epoch: 16, Loss (standarized): 1.2959334098302033\n",
      "          Validation Loss (standardized): 1.3181742962061853\n",
      "Epoch: 21, Loss (standarized): 1.2418619986455823\n",
      "          Validation Loss (standardized): 1.2814306977707952\n",
      "Epoch: 26, Loss (standarized): 1.2083773476957342\n",
      "          Validation Loss (standardized): 1.2526016949012442\n",
      "Epoch: 31, Loss (standarized): 1.180574909491925\n",
      "          Validation Loss (standardized): 1.2171010253741705\n",
      "Epoch: 36, Loss (standarized): 1.1525801006605183\n",
      "          Validation Loss (standardized): 1.1962399799879349\n",
      "Epoch: 41, Loss (standarized): 1.1254967627328394\n",
      "          Validation Loss (standardized): 1.1803218798556727\n",
      "Epoch: 46, Loss (standarized): 1.1008343737347113\n",
      "          Validation Loss (standardized): 1.1516803318395614\n",
      "Epoch: 51, Loss (standarized): 1.0750355692595466\n",
      "          Validation Loss (standardized): 1.1206225942885413\n",
      "Epoch: 56, Loss (standarized): 1.0509771511571526\n",
      "          Validation Loss (standardized): 1.099603504459999\n",
      "Epoch: 61, Loss (standarized): 1.0273213513512944\n",
      "          Validation Loss (standardized): 1.0827503810998387\n",
      "Epoch: 66, Loss (standarized): 1.0048220091654476\n",
      "          Validation Loss (standardized): 1.0552109995692092\n",
      "Epoch: 71, Loss (standarized): 0.9828876811484397\n",
      "          Validation Loss (standardized): 1.0333771969057994\n",
      "Epoch: 76, Loss (standarized): 0.9609428110258597\n",
      "          Validation Loss (standardized): 1.0163598198436221\n",
      "Epoch: 81, Loss (standarized): 0.9400673267687252\n",
      "          Validation Loss (standardized): 0.9997450999735161\n",
      "Epoch: 86, Loss (standarized): 0.9184501062698825\n",
      "          Validation Loss (standardized): 0.9783205360451581\n",
      "Epoch: 91, Loss (standarized): 0.8963188942092465\n",
      "          Validation Loss (standardized): 0.961833804462316\n",
      "Epoch: 96, Loss (standarized): 0.8743202528263941\n",
      "          Validation Loss (standardized): 0.9399595327158168\n",
      "Final epoch: 100, Final loss (standarized): 0.8566392525307512\n",
      "Epoch: 1, Loss (standarized): 1.7323551726584254\n",
      "          Validation Loss (standardized): 1.51759209413225\n",
      "Epoch: 6, Loss (standarized): 1.3744100328817144\n",
      "          Validation Loss (standardized): 1.4173459428787265\n",
      "Epoch: 11, Loss (standarized): 1.2783560279587098\n",
      "          Validation Loss (standardized): 1.3344234391157765\n",
      "Epoch: 16, Loss (standarized): 1.22994171359169\n",
      "          Validation Loss (standardized): 1.2375839181582402\n",
      "Epoch: 21, Loss (standarized): 1.2060347946583732\n",
      "          Validation Loss (standardized): 1.202714710289304\n",
      "Epoch: 26, Loss (standarized): 1.180247388319983\n",
      "          Validation Loss (standardized): 1.2085025105234257\n",
      "Epoch: 31, Loss (standarized): 1.1652484485952512\n",
      "          Validation Loss (standardized): 1.2160296034121456\n",
      "Epoch: 36, Loss (standarized): 1.1510401851006835\n",
      "          Validation Loss (standardized): 1.199972199680377\n",
      "Epoch: 41, Loss (standarized): 1.1359821727545807\n",
      "          Validation Loss (standardized): 1.179680533789631\n",
      "Epoch: 46, Loss (standarized): 1.1198757594311508\n",
      "          Validation Loss (standardized): 1.1690225681546031\n",
      "Epoch: 51, Loss (standarized): 1.1037562408468269\n",
      "          Validation Loss (standardized): 1.1605547131717162\n",
      "Epoch: 56, Loss (standarized): 1.0884636588171894\n",
      "          Validation Loss (standardized): 1.1458271376451583\n",
      "Epoch: 61, Loss (standarized): 1.0717780285112377\n",
      "          Validation Loss (standardized): 1.1315497550317437\n",
      "Epoch: 66, Loss (standarized): 1.05532246616846\n",
      "          Validation Loss (standardized): 1.1163402463112706\n",
      "Epoch: 71, Loss (standarized): 1.038964419697911\n",
      "          Validation Loss (standardized): 1.099430442458394\n",
      "Epoch: 76, Loss (standarized): 1.0229077714036787\n",
      "          Validation Loss (standardized): 1.0848241331931392\n",
      "Epoch: 81, Loss (standarized): 1.0051267462873197\n",
      "          Validation Loss (standardized): 1.0679178112450909\n",
      "Epoch: 86, Loss (standarized): 0.9865286898030101\n",
      "          Validation Loss (standardized): 1.0532956851723765\n",
      "Epoch: 91, Loss (standarized): 0.9675720399205523\n",
      "          Validation Loss (standardized): 1.03497890896881\n",
      "Epoch: 96, Loss (standarized): 0.9482819701783255\n",
      "          Validation Loss (standardized): 1.0163929585318203\n",
      "Final epoch: 100, Final loss (standarized): 0.9327857600791164\n",
      "Epoch: 1, Loss (standarized): 1.7824437552245882\n",
      "          Validation Loss (standardized): 1.579267519609714\n",
      "Epoch: 6, Loss (standarized): 1.4444896033123975\n",
      "          Validation Loss (standardized): 1.3992843627378215\n",
      "Epoch: 11, Loss (standarized): 1.3414153980692274\n",
      "          Validation Loss (standardized): 1.3848564638647263\n",
      "Epoch: 16, Loss (standarized): 1.2801519672517279\n",
      "          Validation Loss (standardized): 1.3451588667357446\n",
      "Epoch: 21, Loss (standarized): 1.2388571727381443\n",
      "          Validation Loss (standardized): 1.2862141793124053\n",
      "Epoch: 26, Loss (standarized): 1.2076033456903381\n",
      "          Validation Loss (standardized): 1.2465190165042785\n",
      "Epoch: 31, Loss (standarized): 1.1764854867562127\n",
      "          Validation Loss (standardized): 1.2381278961846351\n",
      "Epoch: 36, Loss (standarized): 1.1445605374318983\n",
      "          Validation Loss (standardized): 1.2176288406554767\n",
      "Epoch: 41, Loss (standarized): 1.1152010236092826\n",
      "          Validation Loss (standardized): 1.1774151557563843\n",
      "Epoch: 46, Loss (standarized): 1.087955432580151\n",
      "          Validation Loss (standardized): 1.1532501294291377\n",
      "Epoch: 51, Loss (standarized): 1.062247536886407\n",
      "          Validation Loss (standardized): 1.1342310889986598\n",
      "Epoch: 56, Loss (standarized): 1.0385000979321304\n",
      "          Validation Loss (standardized): 1.1091447498449098\n",
      "Epoch: 61, Loss (standarized): 1.0121329616757242\n",
      "          Validation Loss (standardized): 1.0856428460431498\n",
      "Epoch: 66, Loss (standarized): 0.9859837525431422\n",
      "          Validation Loss (standardized): 1.0592421688404383\n",
      "Epoch: 71, Loss (standarized): 0.9606257975936103\n",
      "          Validation Loss (standardized): 1.0371837480578259\n",
      "Epoch: 76, Loss (standarized): 0.935017136355005\n",
      "          Validation Loss (standardized): 1.018790293002031\n",
      "Epoch: 81, Loss (standarized): 0.9103655691208274\n",
      "          Validation Loss (standardized): 0.9991624324859634\n",
      "Epoch: 86, Loss (standarized): 0.8857795317077694\n",
      "          Validation Loss (standardized): 0.979011388072018\n",
      "Epoch: 91, Loss (standarized): 0.861867885575888\n",
      "          Validation Loss (standardized): 0.9603915092232467\n",
      "Epoch: 96, Loss (standarized): 0.8372469846003354\n",
      "          Validation Loss (standardized): 0.9463912551647111\n",
      "Final epoch: 100, Final loss (standarized): 0.8169659320016422\n",
      "Epoch: 1, Loss (standarized): 1.9092470144021911\n",
      "          Validation Loss (standardized): 1.7069658777896728\n",
      "Epoch: 6, Loss (standarized): 1.4715670861858192\n",
      "          Validation Loss (standardized): 1.4327990755222721\n",
      "Epoch: 11, Loss (standarized): 1.3246929018306577\n",
      "          Validation Loss (standardized): 1.3098824899644683\n",
      "Epoch: 16, Loss (standarized): 1.232132181658299\n",
      "          Validation Loss (standardized): 1.2563591530177058\n",
      "Epoch: 21, Loss (standarized): 1.1803871645545956\n",
      "          Validation Loss (standardized): 1.239545824887941\n",
      "Epoch: 26, Loss (standarized): 1.1511983368613607\n",
      "          Validation Loss (standardized): 1.223229677777625\n",
      "Epoch: 31, Loss (standarized): 1.1296156325464606\n",
      "          Validation Loss (standardized): 1.1919850058423953\n",
      "Epoch: 36, Loss (standarized): 1.111587041477687\n",
      "          Validation Loss (standardized): 1.1588285459042111\n",
      "Epoch: 41, Loss (standarized): 1.0916584507848437\n",
      "          Validation Loss (standardized): 1.145814091772706\n",
      "Epoch: 46, Loss (standarized): 1.075458496823976\n",
      "          Validation Loss (standardized): 1.1391369186406155\n",
      "Epoch: 51, Loss (standarized): 1.0558503861143549\n",
      "          Validation Loss (standardized): 1.1234725307049958\n",
      "Epoch: 56, Loss (standarized): 1.0353426352802884\n",
      "          Validation Loss (standardized): 1.108248776358938\n",
      "Epoch: 61, Loss (standarized): 1.014025357667419\n",
      "          Validation Loss (standardized): 1.0864653909035114\n",
      "Epoch: 66, Loss (standarized): 0.9920314452626247\n",
      "          Validation Loss (standardized): 1.0641381719736482\n",
      "Epoch: 71, Loss (standarized): 0.9704074303089851\n",
      "          Validation Loss (standardized): 1.0471454602841495\n",
      "Epoch: 76, Loss (standarized): 0.9493672507463344\n",
      "          Validation Loss (standardized): 1.0275239286952527\n",
      "Epoch: 81, Loss (standarized): 0.9286242492525506\n",
      "          Validation Loss (standardized): 1.0089662442037366\n",
      "Epoch: 86, Loss (standarized): 0.9064670132889031\n",
      "          Validation Loss (standardized): 0.9932241306623742\n",
      "Epoch: 91, Loss (standarized): 0.8824954188601584\n",
      "          Validation Loss (standardized): 0.9712819955208499\n",
      "Epoch: 96, Loss (standarized): 0.8577625628000078\n",
      "          Validation Loss (standardized): 0.9513701125598827\n",
      "Final epoch: 100, Final loss (standarized): 0.8360324835025225\n",
      "Epoch: 1, Loss (standarized): 2.913005284194136\n",
      "          Validation Loss (standardized): 2.5256417813041128\n",
      "Epoch: 6, Loss (standarized): 1.6864205582775509\n",
      "          Validation Loss (standardized): 1.5720992687417124\n",
      "Epoch: 11, Loss (standarized): 1.395323003625615\n",
      "          Validation Loss (standardized): 1.339131788305731\n",
      "Epoch: 16, Loss (standarized): 1.335319709292274\n",
      "          Validation Loss (standardized): 1.247496860164677\n",
      "Epoch: 21, Loss (standarized): 1.2611650058940247\n",
      "          Validation Loss (standardized): 1.2097238090457456\n",
      "Epoch: 26, Loss (standarized): 1.2007691811000691\n",
      "          Validation Loss (standardized): 1.2127895904986112\n",
      "Epoch: 31, Loss (standarized): 1.1597759479585903\n",
      "          Validation Loss (standardized): 1.2196531229459504\n",
      "Epoch: 36, Loss (standarized): 1.1168326656804237\n",
      "          Validation Loss (standardized): 1.1942110491278817\n",
      "Epoch: 41, Loss (standarized): 1.068905394063538\n",
      "          Validation Loss (standardized): 1.1503124496559645\n",
      "Epoch: 46, Loss (standarized): 1.0231369806333073\n",
      "          Validation Loss (standardized): 1.114552760278822\n",
      "Epoch: 51, Loss (standarized): 0.9768935615482306\n",
      "          Validation Loss (standardized): 1.0779108415988998\n",
      "Epoch: 56, Loss (standarized): 0.9254981294769077\n",
      "          Validation Loss (standardized): 1.0387178738399296\n",
      "Epoch: 61, Loss (standarized): 0.8699873025201802\n",
      "          Validation Loss (standardized): 0.9875771770555348\n",
      "Epoch: 66, Loss (standarized): 0.8159980065108041\n",
      "          Validation Loss (standardized): 0.9478120961722357\n",
      "Epoch: 71, Loss (standarized): 0.7644845935724298\n",
      "          Validation Loss (standardized): 0.9113207581096394\n",
      "Epoch: 76, Loss (standarized): 0.7151198230789819\n",
      "          Validation Loss (standardized): 0.8775200262683128\n",
      "Epoch: 81, Loss (standarized): 0.6665250513802334\n",
      "          Validation Loss (standardized): 0.8368787129136838\n",
      "Epoch: 86, Loss (standarized): 0.6184352504456887\n",
      "          Validation Loss (standardized): 0.7926010700551749\n",
      "Epoch: 91, Loss (standarized): 0.5732980710603525\n",
      "          Validation Loss (standardized): 0.7467950533219258\n",
      "Epoch: 96, Loss (standarized): 0.5310851674794899\n",
      "          Validation Loss (standardized): 0.7047394242676904\n",
      "Final epoch: 100, Final loss (standarized): 0.49946814357976577\n",
      "Epoch: 1, Loss (standarized): 2.107668444766105\n",
      "          Validation Loss (standardized): 2.1383650207604052\n",
      "Epoch: 6, Loss (standarized): 1.4820693451105913\n",
      "          Validation Loss (standardized): 1.561210608419667\n",
      "Epoch: 11, Loss (standarized): 1.2887125228787408\n",
      "          Validation Loss (standardized): 1.288942265944132\n",
      "Epoch: 16, Loss (standarized): 1.209630838669033\n",
      "          Validation Loss (standardized): 1.2080461097976594\n",
      "Epoch: 21, Loss (standarized): 1.151968782525958\n",
      "          Validation Loss (standardized): 1.2022402461970447\n",
      "Epoch: 26, Loss (standarized): 1.11975087062552\n",
      "          Validation Loss (standardized): 1.1966635770240681\n",
      "Epoch: 31, Loss (standarized): 1.0884754821829778\n",
      "          Validation Loss (standardized): 1.1767020925918814\n",
      "Epoch: 36, Loss (standarized): 1.0599119944696012\n",
      "          Validation Loss (standardized): 1.1409741676991767\n",
      "Epoch: 41, Loss (standarized): 1.027164155999558\n",
      "          Validation Loss (standardized): 1.1005574811931615\n",
      "Epoch: 46, Loss (standarized): 0.9964569547887595\n",
      "          Validation Loss (standardized): 1.085486863036807\n",
      "Epoch: 51, Loss (standarized): 0.963048615859702\n",
      "          Validation Loss (standardized): 1.0596450641209427\n",
      "Epoch: 56, Loss (standarized): 0.9277799598810303\n",
      "          Validation Loss (standardized): 1.028092912194898\n",
      "Epoch: 61, Loss (standarized): 0.8900766710077651\n",
      "          Validation Loss (standardized): 0.9979169281012783\n",
      "Epoch: 66, Loss (standarized): 0.8503790476820079\n",
      "          Validation Loss (standardized): 0.9616346259535019\n",
      "Epoch: 71, Loss (standarized): 0.8089116561562278\n",
      "          Validation Loss (standardized): 0.9288889862367337\n",
      "Epoch: 76, Loss (standarized): 0.7664601462946317\n",
      "          Validation Loss (standardized): 0.8908449952340104\n",
      "Epoch: 81, Loss (standarized): 0.7245408045312718\n",
      "          Validation Loss (standardized): 0.8544209905304326\n",
      "Epoch: 86, Loss (standarized): 0.6831572914312342\n",
      "          Validation Loss (standardized): 0.8163975192876146\n",
      "Epoch: 91, Loss (standarized): 0.6439580784287301\n",
      "          Validation Loss (standardized): 0.7803874924107002\n",
      "Epoch: 96, Loss (standarized): 0.6076404819013428\n",
      "          Validation Loss (standardized): 0.7452180121484753\n",
      "Final epoch: 100, Final loss (standarized): 0.582076057998277\n",
      "Epoch: 1, Loss (standarized): 2.0934222537771263\n",
      "          Validation Loss (standardized): 1.6075083635869227\n",
      "Epoch: 6, Loss (standarized): 1.4005678238050205\n",
      "          Validation Loss (standardized): 1.3361512888805738\n",
      "Epoch: 11, Loss (standarized): 1.2737197645268648\n",
      "          Validation Loss (standardized): 1.3394392589226216\n",
      "Epoch: 16, Loss (standarized): 1.2015214341875105\n",
      "          Validation Loss (standardized): 1.2558823791835925\n",
      "Epoch: 21, Loss (standarized): 1.153934158157606\n",
      "          Validation Loss (standardized): 1.1960186586560075\n",
      "Epoch: 26, Loss (standarized): 1.1126964812905016\n",
      "          Validation Loss (standardized): 1.1832863507595661\n",
      "Epoch: 31, Loss (standarized): 1.0675900653198136\n",
      "          Validation Loss (standardized): 1.1476842431891472\n",
      "Epoch: 36, Loss (standarized): 1.0246986673684615\n",
      "          Validation Loss (standardized): 1.1038841487906343\n",
      "Epoch: 41, Loss (standarized): 0.9839518235700289\n",
      "          Validation Loss (standardized): 1.092208342412717\n",
      "Epoch: 46, Loss (standarized): 0.94367956676548\n",
      "          Validation Loss (standardized): 1.0593482084634374\n",
      "Epoch: 51, Loss (standarized): 0.8990703916596735\n",
      "          Validation Loss (standardized): 1.0179763916250524\n",
      "Epoch: 56, Loss (standarized): 0.8501160978062106\n",
      "          Validation Loss (standardized): 0.9777302553628879\n",
      "Epoch: 61, Loss (standarized): 0.8015813584817253\n",
      "          Validation Loss (standardized): 0.9394478384458926\n",
      "Epoch: 66, Loss (standarized): 0.7506970035558405\n",
      "          Validation Loss (standardized): 0.8933838219326203\n",
      "Epoch: 71, Loss (standarized): 0.6990868145228859\n",
      "          Validation Loss (standardized): 0.854279575312577\n",
      "Epoch: 76, Loss (standarized): 0.6494446808834957\n",
      "          Validation Loss (standardized): 0.8138135425103141\n",
      "Epoch: 81, Loss (standarized): 0.6027627390209206\n",
      "          Validation Loss (standardized): 0.7754765364418501\n",
      "Epoch: 86, Loss (standarized): 0.5577776911161014\n",
      "          Validation Loss (standardized): 0.7372320986359171\n",
      "Epoch: 91, Loss (standarized): 0.5160097300471521\n",
      "          Validation Loss (standardized): 0.7065152394768069\n",
      "Epoch: 96, Loss (standarized): 0.47930935095729266\n",
      "          Validation Loss (standardized): 0.673335849375979\n",
      "Final epoch: 100, Final loss (standarized): 0.452366778005258\n",
      "Epoch: 1, Loss (standarized): 2.1383334659876136\n",
      "          Validation Loss (standardized): 2.0553441465320357\n",
      "Epoch: 6, Loss (standarized): 1.4997752106874145\n",
      "          Validation Loss (standardized): 1.4948434584651382\n",
      "Epoch: 11, Loss (standarized): 1.3674580836891963\n",
      "          Validation Loss (standardized): 1.2837704665542462\n",
      "Epoch: 16, Loss (standarized): 1.2860051618192097\n",
      "          Validation Loss (standardized): 1.1760341323074477\n",
      "Epoch: 21, Loss (standarized): 1.2076738834086678\n",
      "          Validation Loss (standardized): 1.2186290237151531\n",
      "Epoch: 26, Loss (standarized): 1.1622516091821098\n",
      "          Validation Loss (standardized): 1.2203241885623533\n",
      "Epoch: 31, Loss (standarized): 1.124334777548496\n",
      "          Validation Loss (standardized): 1.196759000090563\n",
      "Epoch: 36, Loss (standarized): 1.0851834122633106\n",
      "          Validation Loss (standardized): 1.1564379989819777\n",
      "Epoch: 41, Loss (standarized): 1.046555236598779\n",
      "          Validation Loss (standardized): 1.0942326574347765\n",
      "Epoch: 46, Loss (standarized): 1.007021600424803\n",
      "          Validation Loss (standardized): 1.0723997942804793\n",
      "Epoch: 51, Loss (standarized): 0.967588731349123\n",
      "          Validation Loss (standardized): 1.0427439146362925\n",
      "Epoch: 56, Loss (standarized): 0.9232793220030864\n",
      "          Validation Loss (standardized): 1.0018876562029277\n",
      "Epoch: 61, Loss (standarized): 0.8749038171844097\n",
      "          Validation Loss (standardized): 0.9625583321329834\n",
      "Epoch: 66, Loss (standarized): 0.8229695084463319\n",
      "          Validation Loss (standardized): 0.9240987288015913\n",
      "Epoch: 71, Loss (standarized): 0.7710230889223143\n",
      "          Validation Loss (standardized): 0.8797945698492406\n",
      "Epoch: 76, Loss (standarized): 0.7185774951548823\n",
      "          Validation Loss (standardized): 0.8364224858103259\n",
      "Epoch: 81, Loss (standarized): 0.6653296721016295\n",
      "          Validation Loss (standardized): 0.7892075674032971\n",
      "Epoch: 86, Loss (standarized): 0.6111572000327327\n",
      "          Validation Loss (standardized): 0.7443159594729433\n",
      "Epoch: 91, Loss (standarized): 0.5579548988092209\n",
      "          Validation Loss (standardized): 0.6941370567363444\n",
      "Epoch: 96, Loss (standarized): 0.5083636114604567\n",
      "          Validation Loss (standardized): 0.6484219810846615\n",
      "Final epoch: 100, Final loss (standarized): 0.47199472630724043\n",
      "Epoch: 1, Loss (standarized): 1.9282088204066552\n",
      "          Validation Loss (standardized): 1.8644587944906599\n",
      "Epoch: 6, Loss (standarized): 1.3999411739976466\n",
      "          Validation Loss (standardized): 1.4754514244122157\n",
      "Epoch: 11, Loss (standarized): 1.2818216393256654\n",
      "          Validation Loss (standardized): 1.2806495301890124\n",
      "Epoch: 16, Loss (standarized): 1.2273731091594784\n",
      "          Validation Loss (standardized): 1.204068785229233\n",
      "Epoch: 21, Loss (standarized): 1.1740514268259448\n",
      "          Validation Loss (standardized): 1.2046944762406455\n",
      "Epoch: 26, Loss (standarized): 1.1231098419492656\n",
      "          Validation Loss (standardized): 1.1646783505258453\n",
      "Epoch: 31, Loss (standarized): 1.075418829910993\n",
      "          Validation Loss (standardized): 1.1096171794200962\n",
      "Epoch: 36, Loss (standarized): 1.0223217013890187\n",
      "          Validation Loss (standardized): 1.0838721627075465\n",
      "Epoch: 41, Loss (standarized): 0.9706194542557207\n",
      "          Validation Loss (standardized): 1.043507153240542\n",
      "Epoch: 46, Loss (standarized): 0.9151284734157049\n",
      "          Validation Loss (standardized): 1.0005723994772733\n",
      "Epoch: 51, Loss (standarized): 0.8600658750351857\n",
      "          Validation Loss (standardized): 0.9646174853721697\n",
      "Epoch: 56, Loss (standarized): 0.8031521603598432\n",
      "          Validation Loss (standardized): 0.9241938586319095\n",
      "Epoch: 61, Loss (standarized): 0.7445609128648921\n",
      "          Validation Loss (standardized): 0.8700834344447966\n",
      "Epoch: 66, Loss (standarized): 0.6862816975563371\n",
      "          Validation Loss (standardized): 0.8262403012381129\n",
      "Epoch: 71, Loss (standarized): 0.6299664723900927\n",
      "          Validation Loss (standardized): 0.7784287036120413\n",
      "Epoch: 76, Loss (standarized): 0.5772334863654421\n",
      "          Validation Loss (standardized): 0.7347088551818137\n",
      "Epoch: 81, Loss (standarized): 0.5276135560020919\n",
      "          Validation Loss (standardized): 0.6949651314485941\n",
      "Epoch: 86, Loss (standarized): 0.48313757430066656\n",
      "          Validation Loss (standardized): 0.6520446389014611\n",
      "Epoch: 91, Loss (standarized): 0.44385006956804796\n",
      "          Validation Loss (standardized): 0.623360473796128\n",
      "Epoch: 96, Loss (standarized): 0.40846641112805115\n",
      "          Validation Loss (standardized): 0.5972317486959257\n",
      "Final epoch: 100, Final loss (standarized): 0.3821451921630667\n",
      "Epoch: 1, Loss (standarized): 3.606388563030444\n",
      "          Validation Loss (standardized): 3.8232610172514985\n",
      "Epoch: 6, Loss (standarized): 1.9407996759125328\n",
      "          Validation Loss (standardized): 2.1373849829387948\n",
      "Epoch: 11, Loss (standarized): 1.4663009380736651\n",
      "          Validation Loss (standardized): 1.4966873431770127\n",
      "Epoch: 16, Loss (standarized): 1.3168797442072877\n",
      "          Validation Loss (standardized): 1.2734786214254146\n",
      "Epoch: 21, Loss (standarized): 1.2711892981924462\n",
      "          Validation Loss (standardized): 1.2676295108307039\n",
      "Epoch: 26, Loss (standarized): 1.2349449279600377\n",
      "          Validation Loss (standardized): 1.26683708094158\n",
      "Epoch: 31, Loss (standarized): 1.1949653284563606\n",
      "          Validation Loss (standardized): 1.228988825000732\n",
      "Epoch: 36, Loss (standarized): 1.1656507977647028\n",
      "          Validation Loss (standardized): 1.1942305940546212\n",
      "Epoch: 41, Loss (standarized): 1.1379969449651475\n",
      "          Validation Loss (standardized): 1.1744457478611052\n",
      "Epoch: 46, Loss (standarized): 1.1114007590630481\n",
      "          Validation Loss (standardized): 1.155241218847229\n",
      "Epoch: 51, Loss (standarized): 1.0884804774639378\n",
      "          Validation Loss (standardized): 1.141447424780206\n",
      "Epoch: 56, Loss (standarized): 1.0648049263513244\n",
      "          Validation Loss (standardized): 1.117193681922554\n",
      "Epoch: 61, Loss (standarized): 1.0386285939179247\n",
      "          Validation Loss (standardized): 1.095453483770769\n",
      "Epoch: 66, Loss (standarized): 1.0127210838865146\n",
      "          Validation Loss (standardized): 1.071180472369911\n",
      "Epoch: 71, Loss (standarized): 0.9847554386916775\n",
      "          Validation Loss (standardized): 1.0443433278236103\n",
      "Epoch: 76, Loss (standarized): 0.9544234886430888\n",
      "          Validation Loss (standardized): 1.0188815009295789\n",
      "Epoch: 81, Loss (standarized): 0.9221430855968629\n",
      "          Validation Loss (standardized): 0.9942264689797241\n",
      "Epoch: 86, Loss (standarized): 0.8884978080447155\n",
      "          Validation Loss (standardized): 0.9689372540362826\n",
      "Epoch: 91, Loss (standarized): 0.8530093744596813\n",
      "          Validation Loss (standardized): 0.9430079041899915\n",
      "Epoch: 96, Loss (standarized): 0.8150834882570637\n",
      "          Validation Loss (standardized): 0.9126161288476408\n",
      "Final epoch: 100, Final loss (standarized): 0.7823016438121863\n",
      "Epoch: 1, Loss (standarized): 1.9861954727783069\n",
      "          Validation Loss (standardized): 1.905271478374765\n",
      "Epoch: 6, Loss (standarized): 1.4044041873601918\n",
      "          Validation Loss (standardized): 1.3616992134092536\n",
      "Epoch: 11, Loss (standarized): 1.265981134355626\n",
      "          Validation Loss (standardized): 1.2713968761246706\n",
      "Epoch: 16, Loss (standarized): 1.170908124738179\n",
      "          Validation Loss (standardized): 1.2227209423806826\n",
      "Epoch: 21, Loss (standarized): 1.0995088089526428\n",
      "          Validation Loss (standardized): 1.1815154951105538\n",
      "Epoch: 26, Loss (standarized): 1.0436022740650654\n",
      "          Validation Loss (standardized): 1.1390456025233342\n",
      "Epoch: 31, Loss (standarized): 0.9942488717321218\n",
      "          Validation Loss (standardized): 1.0942486793194612\n",
      "Epoch: 36, Loss (standarized): 0.9527732952680465\n",
      "          Validation Loss (standardized): 1.0699889643222376\n",
      "Epoch: 41, Loss (standarized): 0.9140293972634749\n",
      "          Validation Loss (standardized): 1.0530570681117988\n",
      "Epoch: 46, Loss (standarized): 0.8753216643355114\n",
      "          Validation Loss (standardized): 1.0188583393762591\n",
      "Epoch: 51, Loss (standarized): 0.8355033595788908\n",
      "          Validation Loss (standardized): 0.9855198564862013\n",
      "Epoch: 56, Loss (standarized): 0.7934656620245886\n",
      "          Validation Loss (standardized): 0.9556049640597388\n",
      "Epoch: 61, Loss (standarized): 0.7452835796176223\n",
      "          Validation Loss (standardized): 0.9152975898076736\n",
      "Epoch: 66, Loss (standarized): 0.6951386627078625\n",
      "          Validation Loss (standardized): 0.8788691343492602\n",
      "Epoch: 71, Loss (standarized): 0.6412092691114702\n",
      "          Validation Loss (standardized): 0.8387899535638391\n",
      "Epoch: 76, Loss (standarized): 0.5896983163970875\n",
      "          Validation Loss (standardized): 0.8014306500018573\n",
      "Epoch: 81, Loss (standarized): 0.5401035949885993\n",
      "          Validation Loss (standardized): 0.7645729816405219\n",
      "Epoch: 86, Loss (standarized): 0.4941611838114136\n",
      "          Validation Loss (standardized): 0.722088555053474\n",
      "Epoch: 91, Loss (standarized): 0.4529926184622866\n",
      "          Validation Loss (standardized): 0.6832861583224357\n",
      "Epoch: 96, Loss (standarized): 0.41657312172436883\n",
      "          Validation Loss (standardized): 0.6417839522154215\n",
      "Final epoch: 100, Final loss (standarized): 0.3909998083095797\n",
      "Epoch: 1, Loss (standarized): 2.1222156277602933\n",
      "          Validation Loss (standardized): 1.6760178648640562\n",
      "Epoch: 6, Loss (standarized): 1.4659046235233604\n",
      "          Validation Loss (standardized): 1.3998204012931337\n",
      "Epoch: 11, Loss (standarized): 1.3133555941452477\n",
      "          Validation Loss (standardized): 1.3548104221132986\n",
      "Epoch: 16, Loss (standarized): 1.2327771126187759\n",
      "          Validation Loss (standardized): 1.273345587674205\n",
      "Epoch: 21, Loss (standarized): 1.1719243395064922\n",
      "          Validation Loss (standardized): 1.2104020635074275\n",
      "Epoch: 26, Loss (standarized): 1.1232354111404548\n",
      "          Validation Loss (standardized): 1.1709164593223744\n",
      "Epoch: 31, Loss (standarized): 1.07951504180047\n",
      "          Validation Loss (standardized): 1.1512917347016178\n",
      "Epoch: 36, Loss (standarized): 1.0359716034970052\n",
      "          Validation Loss (standardized): 1.1168782217240398\n",
      "Epoch: 41, Loss (standarized): 0.9899658986985014\n",
      "          Validation Loss (standardized): 1.0699980540189822\n",
      "Epoch: 46, Loss (standarized): 0.9485316283907004\n",
      "          Validation Loss (standardized): 1.0407303303314355\n",
      "Epoch: 51, Loss (standarized): 0.9040635395233025\n",
      "          Validation Loss (standardized): 1.0158440841149206\n",
      "Epoch: 56, Loss (standarized): 0.8549517115618825\n",
      "          Validation Loss (standardized): 0.9768282989656624\n",
      "Epoch: 61, Loss (standarized): 0.7988895482681082\n",
      "          Validation Loss (standardized): 0.9396319263838858\n",
      "Epoch: 66, Loss (standarized): 0.7396506489673853\n",
      "          Validation Loss (standardized): 0.9026264357275721\n",
      "Epoch: 71, Loss (standarized): 0.677536593026459\n",
      "          Validation Loss (standardized): 0.8620286950914734\n",
      "Epoch: 76, Loss (standarized): 0.6166985730414574\n",
      "          Validation Loss (standardized): 0.820835202829283\n",
      "Epoch: 81, Loss (standarized): 0.5583211919396581\n",
      "          Validation Loss (standardized): 0.7779330506260586\n",
      "Epoch: 86, Loss (standarized): 0.5077097253893292\n",
      "          Validation Loss (standardized): 0.7348569297648555\n",
      "Epoch: 91, Loss (standarized): 0.4606507979892012\n",
      "          Validation Loss (standardized): 0.6937549631911502\n",
      "Epoch: 96, Loss (standarized): 0.4168179531703511\n",
      "          Validation Loss (standardized): 0.6649648063729643\n",
      "Final epoch: 100, Final loss (standarized): 0.3855425731360833\n",
      "Epoch: 1, Loss (standarized): 2.460790353038383\n",
      "          Validation Loss (standardized): 1.9849652354588316\n",
      "Epoch: 6, Loss (standarized): 1.5365933795991236\n",
      "          Validation Loss (standardized): 1.3609147961470325\n",
      "Epoch: 11, Loss (standarized): 1.3797771861188715\n",
      "          Validation Loss (standardized): 1.3678731401361146\n",
      "Epoch: 16, Loss (standarized): 1.3243944680640607\n",
      "          Validation Loss (standardized): 1.3601843787005736\n",
      "Epoch: 21, Loss (standarized): 1.2817904350718032\n",
      "          Validation Loss (standardized): 1.3470704679057985\n",
      "Epoch: 26, Loss (standarized): 1.259770556412092\n",
      "          Validation Loss (standardized): 1.32774336748172\n",
      "Epoch: 31, Loss (standarized): 1.2275805416127994\n",
      "          Validation Loss (standardized): 1.2826294262372282\n",
      "Epoch: 36, Loss (standarized): 1.1859475545689855\n",
      "          Validation Loss (standardized): 1.2357391831620197\n",
      "Epoch: 41, Loss (standarized): 1.141966838871947\n",
      "          Validation Loss (standardized): 1.1944174160943428\n",
      "Epoch: 46, Loss (standarized): 1.1007405137797825\n",
      "          Validation Loss (standardized): 1.159858446095427\n",
      "Epoch: 51, Loss (standarized): 1.0593702213554301\n",
      "          Validation Loss (standardized): 1.139615199377238\n",
      "Epoch: 56, Loss (standarized): 1.0220198951382349\n",
      "          Validation Loss (standardized): 1.125774561837932\n",
      "Epoch: 61, Loss (standarized): 0.9862527513823565\n",
      "          Validation Loss (standardized): 1.1041569031509748\n",
      "Epoch: 66, Loss (standarized): 0.9505313241462082\n",
      "          Validation Loss (standardized): 1.0753758027914697\n",
      "Epoch: 71, Loss (standarized): 0.9140085318613377\n",
      "          Validation Loss (standardized): 1.0473861214062203\n",
      "Epoch: 76, Loss (standarized): 0.8741186231210568\n",
      "          Validation Loss (standardized): 1.0229439006402508\n",
      "Epoch: 81, Loss (standarized): 0.8324563126563373\n",
      "          Validation Loss (standardized): 0.9906721775867725\n",
      "Epoch: 86, Loss (standarized): 0.7898126351854395\n",
      "          Validation Loss (standardized): 0.950588345007948\n",
      "Epoch: 91, Loss (standarized): 0.7415805962506212\n",
      "          Validation Loss (standardized): 0.8999787494217768\n",
      "Epoch: 96, Loss (standarized): 0.6913954478731859\n",
      "          Validation Loss (standardized): 0.8577427922568741\n",
      "Final epoch: 100, Final loss (standarized): 0.6510357491325209\n",
      "Epoch: 1, Loss (standarized): 1.8913482803266555\n",
      "          Validation Loss (standardized): 1.8547574246306027\n",
      "Epoch: 6, Loss (standarized): 1.3074323955705243\n",
      "          Validation Loss (standardized): 1.2658982317254932\n",
      "Epoch: 11, Loss (standarized): 1.1698271747917885\n",
      "          Validation Loss (standardized): 1.25992109021838\n",
      "Epoch: 16, Loss (standarized): 1.1209697547843047\n",
      "          Validation Loss (standardized): 1.2606432970786219\n",
      "Epoch: 21, Loss (standarized): 1.060902666342483\n",
      "          Validation Loss (standardized): 1.148105400779043\n",
      "Epoch: 26, Loss (standarized): 1.0106230163209526\n",
      "          Validation Loss (standardized): 1.124529518460363\n",
      "Epoch: 31, Loss (standarized): 0.965332729790469\n",
      "          Validation Loss (standardized): 1.0816148773286018\n",
      "Epoch: 36, Loss (standarized): 0.9220969297423429\n",
      "          Validation Loss (standardized): 1.0308632198830658\n",
      "Epoch: 41, Loss (standarized): 0.8779758420504303\n",
      "          Validation Loss (standardized): 1.0073524994214065\n",
      "Epoch: 46, Loss (standarized): 0.8319497894441826\n",
      "          Validation Loss (standardized): 0.9638920008336054\n",
      "Epoch: 51, Loss (standarized): 0.783012652195655\n",
      "          Validation Loss (standardized): 0.9166911713881664\n",
      "Epoch: 56, Loss (standarized): 0.7360116800625169\n",
      "          Validation Loss (standardized): 0.8759682267918331\n",
      "Epoch: 61, Loss (standarized): 0.6878679275027713\n",
      "          Validation Loss (standardized): 0.8302780877705875\n",
      "Epoch: 66, Loss (standarized): 0.6436254426603218\n",
      "          Validation Loss (standardized): 0.7891372718744909\n",
      "Epoch: 71, Loss (standarized): 0.6006707794545464\n",
      "          Validation Loss (standardized): 0.7519935880464483\n",
      "Epoch: 76, Loss (standarized): 0.5622479721206941\n",
      "          Validation Loss (standardized): 0.7183848665483435\n",
      "Epoch: 81, Loss (standarized): 0.5286093772294675\n",
      "          Validation Loss (standardized): 0.6843231688744384\n",
      "Epoch: 86, Loss (standarized): 0.5010779352144139\n",
      "          Validation Loss (standardized): 0.6554291780883685\n",
      "Epoch: 91, Loss (standarized): 0.47784467736098823\n",
      "          Validation Loss (standardized): 0.6341190792082769\n",
      "Epoch: 96, Loss (standarized): 0.45833774505762337\n",
      "          Validation Loss (standardized): 0.6159048253975073\n",
      "Final epoch: 100, Final loss (standarized): 0.445347672946414\n",
      "Epoch: 1, Loss (standarized): 1.7633439392456354\n",
      "          Validation Loss (standardized): 1.5951000830502087\n",
      "Epoch: 6, Loss (standarized): 1.3339330368115927\n",
      "          Validation Loss (standardized): 1.3542369489385984\n",
      "Epoch: 11, Loss (standarized): 1.2087690049460513\n",
      "          Validation Loss (standardized): 1.253432261523878\n",
      "Epoch: 16, Loss (standarized): 1.1456524350843464\n",
      "          Validation Loss (standardized): 1.2033827682724756\n",
      "Epoch: 21, Loss (standarized): 1.080075931024002\n",
      "          Validation Loss (standardized): 1.1546976650979541\n",
      "Epoch: 26, Loss (standarized): 1.0137866293237296\n",
      "          Validation Loss (standardized): 1.095509768426964\n",
      "Epoch: 31, Loss (standarized): 0.9429709685852304\n",
      "          Validation Loss (standardized): 1.0418974628482738\n",
      "Epoch: 36, Loss (standarized): 0.8710103237579548\n",
      "          Validation Loss (standardized): 0.9863109563059504\n",
      "Epoch: 41, Loss (standarized): 0.7987287999772699\n",
      "          Validation Loss (standardized): 0.92196762730451\n",
      "Epoch: 46, Loss (standarized): 0.7305771325927793\n",
      "          Validation Loss (standardized): 0.8746806978475179\n",
      "Epoch: 51, Loss (standarized): 0.6669724085289619\n",
      "          Validation Loss (standardized): 0.8174205068424831\n",
      "Epoch: 56, Loss (standarized): 0.6074865011448111\n",
      "          Validation Loss (standardized): 0.7547422013593998\n",
      "Epoch: 61, Loss (standarized): 0.5526035826605856\n",
      "          Validation Loss (standardized): 0.7096329247179265\n",
      "Epoch: 66, Loss (standarized): 0.5021741266959767\n",
      "          Validation Loss (standardized): 0.6647156504662722\n",
      "Epoch: 71, Loss (standarized): 0.45581289597613195\n",
      "          Validation Loss (standardized): 0.6234447530535528\n",
      "Epoch: 76, Loss (standarized): 0.41463035049203734\n",
      "          Validation Loss (standardized): 0.5885487201924028\n",
      "Epoch: 81, Loss (standarized): 0.3787816082244492\n",
      "          Validation Loss (standardized): 0.5530472820194352\n",
      "Epoch: 86, Loss (standarized): 0.34647556000826896\n",
      "          Validation Loss (standardized): 0.5283979903852237\n",
      "Epoch: 91, Loss (standarized): 0.31830631058468173\n",
      "          Validation Loss (standardized): 0.5073887928149152\n",
      "Epoch: 96, Loss (standarized): 0.2942407523637088\n",
      "          Validation Loss (standardized): 0.49136806893735396\n",
      "Final epoch: 100, Final loss (standarized): 0.2771231572673674\n",
      "Epoch: 1, Loss (standarized): 2.785143134712969\n",
      "          Validation Loss (standardized): 2.6002018636484436\n",
      "Epoch: 6, Loss (standarized): 1.580117717602285\n",
      "          Validation Loss (standardized): 1.5242774540659483\n",
      "Epoch: 11, Loss (standarized): 1.3771874818247527\n",
      "          Validation Loss (standardized): 1.2659161131356755\n",
      "Epoch: 16, Loss (standarized): 1.2690634156749114\n",
      "          Validation Loss (standardized): 1.2899156994708614\n",
      "Epoch: 21, Loss (standarized): 1.2228831425706428\n",
      "          Validation Loss (standardized): 1.3055617563407265\n",
      "Epoch: 26, Loss (standarized): 1.1673304817127599\n",
      "          Validation Loss (standardized): 1.2302318752690167\n",
      "Epoch: 31, Loss (standarized): 1.1200704700103068\n",
      "          Validation Loss (standardized): 1.162499062649947\n",
      "Epoch: 36, Loss (standarized): 1.0821056019813755\n",
      "          Validation Loss (standardized): 1.1068674250189747\n",
      "Epoch: 41, Loss (standarized): 1.0412331112560398\n",
      "          Validation Loss (standardized): 1.0935085133372955\n",
      "Epoch: 46, Loss (standarized): 1.0031235077071374\n",
      "          Validation Loss (standardized): 1.0734968389812507\n",
      "Epoch: 51, Loss (standarized): 0.9654018962332299\n",
      "          Validation Loss (standardized): 1.0291297796288146\n",
      "Epoch: 56, Loss (standarized): 0.9260728931188027\n",
      "          Validation Loss (standardized): 0.9977185583658106\n",
      "Epoch: 61, Loss (standarized): 0.8866557835209288\n",
      "          Validation Loss (standardized): 0.9598209910121994\n",
      "Epoch: 66, Loss (standarized): 0.8451185882208324\n",
      "          Validation Loss (standardized): 0.9311718736631044\n",
      "Epoch: 71, Loss (standarized): 0.8010653771303118\n",
      "          Validation Loss (standardized): 0.8950631240162896\n",
      "Epoch: 76, Loss (standarized): 0.7546716878834752\n",
      "          Validation Loss (standardized): 0.8531730090603094\n",
      "Epoch: 81, Loss (standarized): 0.7075660639270529\n",
      "          Validation Loss (standardized): 0.8116347720648167\n",
      "Epoch: 86, Loss (standarized): 0.6604498043306818\n",
      "          Validation Loss (standardized): 0.7746619922337329\n",
      "Epoch: 91, Loss (standarized): 0.6155713310680159\n",
      "          Validation Loss (standardized): 0.7343965183111382\n",
      "Epoch: 96, Loss (standarized): 0.5709152774854858\n",
      "          Validation Loss (standardized): 0.7012502225975081\n",
      "Final epoch: 100, Final loss (standarized): 0.5396397514920518\n",
      "Epoch: 1, Loss (standarized): 2.261367307373647\n",
      "          Validation Loss (standardized): 1.720079067498934\n",
      "Epoch: 6, Loss (standarized): 1.4059174739826474\n",
      "          Validation Loss (standardized): 1.3551668664237695\n",
      "Epoch: 11, Loss (standarized): 1.3075653951884056\n",
      "          Validation Loss (standardized): 1.314633260776908\n",
      "Epoch: 16, Loss (standarized): 1.2130549896518295\n",
      "          Validation Loss (standardized): 1.2462139147733424\n",
      "Epoch: 21, Loss (standarized): 1.1648459943006244\n",
      "          Validation Loss (standardized): 1.222898914500381\n",
      "Epoch: 26, Loss (standarized): 1.130813966089953\n",
      "          Validation Loss (standardized): 1.1863060467682565\n",
      "Epoch: 31, Loss (standarized): 1.1029807796985533\n",
      "          Validation Loss (standardized): 1.1672380839877283\n",
      "Epoch: 36, Loss (standarized): 1.0795603872632824\n",
      "          Validation Loss (standardized): 1.1521071874319264\n",
      "Epoch: 41, Loss (standarized): 1.057513208140829\n",
      "          Validation Loss (standardized): 1.1313199504509681\n",
      "Epoch: 46, Loss (standarized): 1.03964666073462\n",
      "          Validation Loss (standardized): 1.1145598231608276\n",
      "Epoch: 51, Loss (standarized): 1.0215323376952323\n",
      "          Validation Loss (standardized): 1.1095975799204767\n",
      "Epoch: 56, Loss (standarized): 1.003417412290913\n",
      "          Validation Loss (standardized): 1.082540585326515\n",
      "Epoch: 61, Loss (standarized): 0.9874729626575178\n",
      "          Validation Loss (standardized): 1.0636910233187782\n",
      "Epoch: 66, Loss (standarized): 0.9717612556620374\n",
      "          Validation Loss (standardized): 1.0572647064888716\n",
      "Epoch: 71, Loss (standarized): 0.9557747873836584\n",
      "          Validation Loss (standardized): 1.0449694115452834\n",
      "Epoch: 76, Loss (standarized): 0.9397358319136621\n",
      "          Validation Loss (standardized): 1.032990982289618\n",
      "Epoch: 81, Loss (standarized): 0.9234861760791933\n",
      "          Validation Loss (standardized): 1.01360169399009\n",
      "Epoch: 86, Loss (standarized): 0.9065856239601393\n",
      "          Validation Loss (standardized): 1.00096224756833\n",
      "Epoch: 91, Loss (standarized): 0.8876527023787593\n",
      "          Validation Loss (standardized): 0.9776787067601267\n",
      "Epoch: 96, Loss (standarized): 0.8683116454730162\n",
      "          Validation Loss (standardized): 0.9614821470292925\n",
      "Final epoch: 100, Final loss (standarized): 0.8517918014382927\n",
      "Epoch: 1, Loss (standarized): 1.7576032773779253\n",
      "          Validation Loss (standardized): 1.5161330943028806\n",
      "Epoch: 6, Loss (standarized): 1.4330846299458102\n",
      "          Validation Loss (standardized): 1.4031621718371592\n",
      "Epoch: 11, Loss (standarized): 1.3269082614738819\n",
      "          Validation Loss (standardized): 1.3247341363965097\n",
      "Epoch: 16, Loss (standarized): 1.257165411497777\n",
      "          Validation Loss (standardized): 1.2627132205532894\n",
      "Epoch: 21, Loss (standarized): 1.2082253778847063\n",
      "          Validation Loss (standardized): 1.2337177021536105\n",
      "Epoch: 26, Loss (standarized): 1.1783141077077477\n",
      "          Validation Loss (standardized): 1.2208272393770512\n",
      "Epoch: 31, Loss (standarized): 1.1584922004707892\n",
      "          Validation Loss (standardized): 1.2001104072987074\n",
      "Epoch: 36, Loss (standarized): 1.1414408292927873\n",
      "          Validation Loss (standardized): 1.17710674907539\n",
      "Epoch: 41, Loss (standarized): 1.1254443053711418\n",
      "          Validation Loss (standardized): 1.165574291724079\n",
      "Epoch: 46, Loss (standarized): 1.1117090067112783\n",
      "          Validation Loss (standardized): 1.161423391848584\n",
      "Epoch: 51, Loss (standarized): 1.0981858386322827\n",
      "          Validation Loss (standardized): 1.1579941474667184\n",
      "Epoch: 56, Loss (standarized): 1.0839169375793547\n",
      "          Validation Loss (standardized): 1.1474230467435746\n",
      "Epoch: 61, Loss (standarized): 1.067847557224163\n",
      "          Validation Loss (standardized): 1.1377525124954653\n",
      "Epoch: 66, Loss (standarized): 1.0523016994629248\n",
      "          Validation Loss (standardized): 1.1229293377735838\n",
      "Epoch: 71, Loss (standarized): 1.036461615623349\n",
      "          Validation Loss (standardized): 1.10955248111581\n",
      "Epoch: 76, Loss (standarized): 1.019870705213789\n",
      "          Validation Loss (standardized): 1.097009394793066\n",
      "Epoch: 81, Loss (standarized): 1.0047407055790911\n",
      "          Validation Loss (standardized): 1.0846194203559854\n",
      "Epoch: 86, Loss (standarized): 0.9909951761236064\n",
      "          Validation Loss (standardized): 1.07925513991345\n",
      "Epoch: 91, Loss (standarized): 0.9766804866534923\n",
      "          Validation Loss (standardized): 1.0673694167700167\n",
      "Epoch: 96, Loss (standarized): 0.962213408672895\n",
      "          Validation Loss (standardized): 1.055425607577793\n",
      "Final epoch: 100, Final loss (standarized): 0.9506585618188751\n",
      "Epoch: 1, Loss (standarized): 1.8832124345959596\n",
      "          Validation Loss (standardized): 1.801947999649418\n",
      "Epoch: 6, Loss (standarized): 1.3932188715375537\n",
      "          Validation Loss (standardized): 1.3732148354149785\n",
      "Epoch: 11, Loss (standarized): 1.274382577674975\n",
      "          Validation Loss (standardized): 1.2482685555516178\n",
      "Epoch: 16, Loss (standarized): 1.2073468399873877\n",
      "          Validation Loss (standardized): 1.2337077961315008\n",
      "Epoch: 21, Loss (standarized): 1.174561543066878\n",
      "          Validation Loss (standardized): 1.2543247217027336\n",
      "Epoch: 26, Loss (standarized): 1.1461290461585316\n",
      "          Validation Loss (standardized): 1.219036016432861\n",
      "Epoch: 31, Loss (standarized): 1.1185623072973232\n",
      "          Validation Loss (standardized): 1.1818440920087756\n",
      "Epoch: 36, Loss (standarized): 1.0994561844665969\n",
      "          Validation Loss (standardized): 1.169554283806384\n",
      "Epoch: 41, Loss (standarized): 1.082584968686299\n",
      "          Validation Loss (standardized): 1.158920894467047\n",
      "Epoch: 46, Loss (standarized): 1.0641609535400365\n",
      "          Validation Loss (standardized): 1.142390374511888\n",
      "Epoch: 51, Loss (standarized): 1.0456788312100571\n",
      "          Validation Loss (standardized): 1.1289838220921484\n",
      "Epoch: 56, Loss (standarized): 1.0266015371957553\n",
      "          Validation Loss (standardized): 1.1120843719205011\n",
      "Epoch: 61, Loss (standarized): 1.0107861530192448\n",
      "          Validation Loss (standardized): 1.0985045275900753\n",
      "Epoch: 66, Loss (standarized): 0.9937706956442806\n",
      "          Validation Loss (standardized): 1.0870029885934334\n",
      "Epoch: 71, Loss (standarized): 0.9773187260489045\n",
      "          Validation Loss (standardized): 1.072816744603172\n",
      "Epoch: 76, Loss (standarized): 0.9615536703652972\n",
      "          Validation Loss (standardized): 1.061738997993838\n",
      "Epoch: 81, Loss (standarized): 0.9444351536947759\n",
      "          Validation Loss (standardized): 1.0447796310117883\n",
      "Epoch: 86, Loss (standarized): 0.9263506212324643\n",
      "          Validation Loss (standardized): 1.031887793878265\n",
      "Epoch: 91, Loss (standarized): 0.9077393563635278\n",
      "          Validation Loss (standardized): 1.0127005016777118\n",
      "Epoch: 96, Loss (standarized): 0.8884138189719056\n",
      "          Validation Loss (standardized): 0.9968462193785199\n",
      "Final epoch: 100, Final loss (standarized): 0.8732725506430715\n",
      "Epoch: 1, Loss (standarized): 1.6096960157121032\n",
      "          Validation Loss (standardized): 1.6106712702570034\n",
      "Epoch: 6, Loss (standarized): 1.3729702305366018\n",
      "          Validation Loss (standardized): 1.3868711629422459\n",
      "Epoch: 11, Loss (standarized): 1.2859047727573454\n",
      "          Validation Loss (standardized): 1.2950063150880913\n",
      "Epoch: 16, Loss (standarized): 1.2319472131354117\n",
      "          Validation Loss (standardized): 1.232295949662825\n",
      "Epoch: 21, Loss (standarized): 1.1897282908373326\n",
      "          Validation Loss (standardized): 1.2000701692508142\n",
      "Epoch: 26, Loss (standarized): 1.1579376875506047\n",
      "          Validation Loss (standardized): 1.1897575553090913\n",
      "Epoch: 31, Loss (standarized): 1.1314058126113713\n",
      "          Validation Loss (standardized): 1.1697902442040504\n",
      "Epoch: 36, Loss (standarized): 1.108919413364309\n",
      "          Validation Loss (standardized): 1.1555833146258805\n",
      "Epoch: 41, Loss (standarized): 1.0873754286071806\n",
      "          Validation Loss (standardized): 1.1337968573401949\n",
      "Epoch: 46, Loss (standarized): 1.0647636578354425\n",
      "          Validation Loss (standardized): 1.1183087070770885\n",
      "Epoch: 51, Loss (standarized): 1.0445317190731376\n",
      "          Validation Loss (standardized): 1.0983126297056631\n",
      "Epoch: 56, Loss (standarized): 1.0236437608164382\n",
      "          Validation Loss (standardized): 1.0833044129504865\n",
      "Epoch: 61, Loss (standarized): 1.0018040908046515\n",
      "          Validation Loss (standardized): 1.0584689279766168\n",
      "Epoch: 66, Loss (standarized): 0.9803821700101628\n",
      "          Validation Loss (standardized): 1.046563887362623\n",
      "Epoch: 71, Loss (standarized): 0.9616051847641914\n",
      "          Validation Loss (standardized): 1.0321132621263132\n",
      "Epoch: 76, Loss (standarized): 0.9439460671686244\n",
      "          Validation Loss (standardized): 1.013739349804638\n",
      "Epoch: 81, Loss (standarized): 0.9274745130792439\n",
      "          Validation Loss (standardized): 1.00338369295278\n",
      "Epoch: 86, Loss (standarized): 0.9128050658191279\n",
      "          Validation Loss (standardized): 0.9907144916627947\n",
      "Epoch: 91, Loss (standarized): 0.898751515295147\n",
      "          Validation Loss (standardized): 0.9816332020806889\n",
      "Epoch: 96, Loss (standarized): 0.8860102619618331\n",
      "          Validation Loss (standardized): 0.9717738651939938\n",
      "Final epoch: 100, Final loss (standarized): 0.8764769248759517\n",
      "Epoch: 1, Loss (standarized): 2.1692632565590073\n",
      "          Validation Loss (standardized): 2.0329774123742435\n",
      "Epoch: 6, Loss (standarized): 1.4939438430983305\n",
      "          Validation Loss (standardized): 1.452693465958856\n",
      "Epoch: 11, Loss (standarized): 1.3526854035416873\n",
      "          Validation Loss (standardized): 1.3316480534066422\n",
      "Epoch: 16, Loss (standarized): 1.2837928358624604\n",
      "          Validation Loss (standardized): 1.3008177086707604\n",
      "Epoch: 21, Loss (standarized): 1.2088924430727732\n",
      "          Validation Loss (standardized): 1.2399199087041857\n",
      "Epoch: 26, Loss (standarized): 1.159891317632017\n",
      "          Validation Loss (standardized): 1.2089788218568283\n",
      "Epoch: 31, Loss (standarized): 1.1200614723767757\n",
      "          Validation Loss (standardized): 1.1960259258736583\n",
      "Epoch: 36, Loss (standarized): 1.0784724062329492\n",
      "          Validation Loss (standardized): 1.1631893103405901\n",
      "Epoch: 41, Loss (standarized): 1.0429945685339894\n",
      "          Validation Loss (standardized): 1.1159307032667276\n",
      "Epoch: 46, Loss (standarized): 1.0098297653038193\n",
      "          Validation Loss (standardized): 1.0881843059002843\n",
      "Epoch: 51, Loss (standarized): 0.9762262862355775\n",
      "          Validation Loss (standardized): 1.0755997786639722\n",
      "Epoch: 56, Loss (standarized): 0.9427036599118924\n",
      "          Validation Loss (standardized): 1.0445363689695806\n",
      "Epoch: 61, Loss (standarized): 0.9064507874631594\n",
      "          Validation Loss (standardized): 1.0096691814062082\n",
      "Epoch: 66, Loss (standarized): 0.8686488240390853\n",
      "          Validation Loss (standardized): 0.9790637417638333\n",
      "Epoch: 71, Loss (standarized): 0.8280037266630177\n",
      "          Validation Loss (standardized): 0.9458808881665323\n",
      "Epoch: 76, Loss (standarized): 0.7845907371027675\n",
      "          Validation Loss (standardized): 0.8997940934266997\n",
      "Epoch: 81, Loss (standarized): 0.7388408297658178\n",
      "          Validation Loss (standardized): 0.8737646890051078\n",
      "Epoch: 86, Loss (standarized): 0.6926727584039222\n",
      "          Validation Loss (standardized): 0.83986357519996\n",
      "Epoch: 91, Loss (standarized): 0.6457803340200702\n",
      "          Validation Loss (standardized): 0.8047907972883287\n",
      "Epoch: 96, Loss (standarized): 0.6018059162443175\n",
      "          Validation Loss (standardized): 0.7705748543495956\n",
      "Final epoch: 100, Final loss (standarized): 0.5684403843705946\n",
      "Epoch: 1, Loss (standarized): 2.987141756097423\n",
      "          Validation Loss (standardized): 2.642210009404925\n",
      "Epoch: 6, Loss (standarized): 1.7329637898547956\n",
      "          Validation Loss (standardized): 1.6092225637717261\n",
      "Epoch: 11, Loss (standarized): 1.3740442287502057\n",
      "          Validation Loss (standardized): 1.3426205071934392\n",
      "Epoch: 16, Loss (standarized): 1.2889228589099162\n",
      "          Validation Loss (standardized): 1.302650349281333\n",
      "Epoch: 21, Loss (standarized): 1.230820732264869\n",
      "          Validation Loss (standardized): 1.2746005883265257\n",
      "Epoch: 26, Loss (standarized): 1.1901105833647938\n",
      "          Validation Loss (standardized): 1.2714824655832107\n",
      "Epoch: 31, Loss (standarized): 1.1544895176695777\n",
      "          Validation Loss (standardized): 1.2562297615070523\n",
      "Epoch: 36, Loss (standarized): 1.125317475512643\n",
      "          Validation Loss (standardized): 1.2171779065985\n",
      "Epoch: 41, Loss (standarized): 1.0990557905930285\n",
      "          Validation Loss (standardized): 1.1874561835034552\n",
      "Epoch: 46, Loss (standarized): 1.0744002447232652\n",
      "          Validation Loss (standardized): 1.1713326338789296\n",
      "Epoch: 51, Loss (standarized): 1.0491677009540428\n",
      "          Validation Loss (standardized): 1.1451372282260663\n",
      "Epoch: 56, Loss (standarized): 1.0237745168778947\n",
      "          Validation Loss (standardized): 1.114342642011754\n",
      "Epoch: 61, Loss (standarized): 0.9967125494471714\n",
      "          Validation Loss (standardized): 1.0932277577079303\n",
      "Epoch: 66, Loss (standarized): 0.9683490915838704\n",
      "          Validation Loss (standardized): 1.0694757106389303\n",
      "Epoch: 71, Loss (standarized): 0.9386595247529003\n",
      "          Validation Loss (standardized): 1.048310867272615\n",
      "Epoch: 76, Loss (standarized): 0.9072497537653326\n",
      "          Validation Loss (standardized): 1.0158759579739933\n",
      "Epoch: 81, Loss (standarized): 0.8736957234686108\n",
      "          Validation Loss (standardized): 0.9876524268146664\n",
      "Epoch: 86, Loss (standarized): 0.8370785852698106\n",
      "          Validation Loss (standardized): 0.9630863360475722\n",
      "Epoch: 91, Loss (standarized): 0.7995516260383064\n",
      "          Validation Loss (standardized): 0.9232855750492699\n",
      "Epoch: 96, Loss (standarized): 0.7622376746958222\n",
      "          Validation Loss (standardized): 0.8923868987687497\n",
      "Final epoch: 100, Final loss (standarized): 0.7331277639391903\n",
      "Epoch: 1, Loss (standarized): 2.5251407872668987\n",
      "          Validation Loss (standardized): 1.9669594234033836\n",
      "Epoch: 6, Loss (standarized): 1.6147151052911977\n",
      "          Validation Loss (standardized): 1.5309401120201227\n",
      "Epoch: 11, Loss (standarized): 1.3780822451548371\n",
      "          Validation Loss (standardized): 1.4114296564571656\n",
      "Epoch: 16, Loss (standarized): 1.2801987787152478\n",
      "          Validation Loss (standardized): 1.2743901996342875\n",
      "Epoch: 21, Loss (standarized): 1.208701359915924\n",
      "          Validation Loss (standardized): 1.202208320333192\n",
      "Epoch: 26, Loss (standarized): 1.1628435064717595\n",
      "          Validation Loss (standardized): 1.2083116045582245\n",
      "Epoch: 31, Loss (standarized): 1.1135663785317356\n",
      "          Validation Loss (standardized): 1.2184551922174223\n",
      "Epoch: 36, Loss (standarized): 1.0761667247057236\n",
      "          Validation Loss (standardized): 1.1793034972530676\n",
      "Epoch: 41, Loss (standarized): 1.0390330859815142\n",
      "          Validation Loss (standardized): 1.120950462044667\n",
      "Epoch: 46, Loss (standarized): 1.0048431459684477\n",
      "          Validation Loss (standardized): 1.0959538360874534\n",
      "Epoch: 51, Loss (standarized): 0.9714176151713134\n",
      "          Validation Loss (standardized): 1.0872734536497728\n",
      "Epoch: 56, Loss (standarized): 0.9375747204657477\n",
      "          Validation Loss (standardized): 1.0463952851766085\n",
      "Epoch: 61, Loss (standarized): 0.9006924013183744\n",
      "          Validation Loss (standardized): 1.0180803158744287\n",
      "Epoch: 66, Loss (standarized): 0.8621273061777412\n",
      "          Validation Loss (standardized): 0.985554865599086\n",
      "Epoch: 71, Loss (standarized): 0.8227161098083426\n",
      "          Validation Loss (standardized): 0.949431595159705\n",
      "Epoch: 76, Loss (standarized): 0.7786826569684053\n",
      "          Validation Loss (standardized): 0.9210715687581428\n",
      "Epoch: 81, Loss (standarized): 0.7340051795113658\n",
      "          Validation Loss (standardized): 0.8882187276606153\n",
      "Epoch: 86, Loss (standarized): 0.6899338183180385\n",
      "          Validation Loss (standardized): 0.8614390600394394\n",
      "Epoch: 91, Loss (standarized): 0.6469191875288226\n",
      "          Validation Loss (standardized): 0.8268688915372534\n",
      "Epoch: 96, Loss (standarized): 0.6038431998925021\n",
      "          Validation Loss (standardized): 0.7978694212549656\n",
      "Final epoch: 100, Final loss (standarized): 0.5712851508984526\n",
      "Epoch: 1, Loss (standarized): 1.6107760056580542\n",
      "          Validation Loss (standardized): 1.4987298968885718\n",
      "Epoch: 6, Loss (standarized): 1.2560753381971133\n",
      "          Validation Loss (standardized): 1.1665980858754816\n",
      "Epoch: 11, Loss (standarized): 1.1621015119329734\n",
      "          Validation Loss (standardized): 1.1635737673372777\n",
      "Epoch: 16, Loss (standarized): 1.1164223997353298\n",
      "          Validation Loss (standardized): 1.1952022016301436\n",
      "Epoch: 21, Loss (standarized): 1.0696310511855645\n",
      "          Validation Loss (standardized): 1.1244455497488752\n",
      "Epoch: 26, Loss (standarized): 1.027979106534363\n",
      "          Validation Loss (standardized): 1.0708815977061055\n",
      "Epoch: 31, Loss (standarized): 0.991061042085865\n",
      "          Validation Loss (standardized): 1.0731645145209736\n",
      "Epoch: 36, Loss (standarized): 0.9516581278240609\n",
      "          Validation Loss (standardized): 1.02268652453252\n",
      "Epoch: 41, Loss (standarized): 0.9099169080789892\n",
      "          Validation Loss (standardized): 0.9980868306899557\n",
      "Epoch: 46, Loss (standarized): 0.8621086042644734\n",
      "          Validation Loss (standardized): 0.9481055354106238\n",
      "Epoch: 51, Loss (standarized): 0.8116176700118859\n",
      "          Validation Loss (standardized): 0.9027501628029361\n",
      "Epoch: 56, Loss (standarized): 0.7558757452401292\n",
      "          Validation Loss (standardized): 0.8516840445870222\n",
      "Epoch: 61, Loss (standarized): 0.6968564865677718\n",
      "          Validation Loss (standardized): 0.8003623957269842\n",
      "Epoch: 66, Loss (standarized): 0.634812278300653\n",
      "          Validation Loss (standardized): 0.7493070880171144\n",
      "Epoch: 71, Loss (standarized): 0.5716455182738861\n",
      "          Validation Loss (standardized): 0.6945478434919284\n",
      "Epoch: 76, Loss (standarized): 0.5119630921709626\n",
      "          Validation Loss (standardized): 0.6469768358901247\n",
      "Epoch: 81, Loss (standarized): 0.45579139738181995\n",
      "          Validation Loss (standardized): 0.5999872036328816\n",
      "Epoch: 86, Loss (standarized): 0.40674546611572526\n",
      "          Validation Loss (standardized): 0.5619095665156107\n",
      "Epoch: 91, Loss (standarized): 0.3647372532829746\n",
      "          Validation Loss (standardized): 0.5319981151206361\n",
      "Epoch: 96, Loss (standarized): 0.32966862843005657\n",
      "          Validation Loss (standardized): 0.49926674696984513\n",
      "Final epoch: 100, Final loss (standarized): 0.30672851751856317\n",
      "Epoch: 1, Loss (standarized): 3.479492302301734\n",
      "          Validation Loss (standardized): 2.9785907473589304\n",
      "Epoch: 6, Loss (standarized): 1.9737262372353355\n",
      "          Validation Loss (standardized): 1.7731303753129992\n",
      "Epoch: 11, Loss (standarized): 1.4015203533283898\n",
      "          Validation Loss (standardized): 1.4017742792602685\n",
      "Epoch: 16, Loss (standarized): 1.2515041798424855\n",
      "          Validation Loss (standardized): 1.3774143075994385\n",
      "Epoch: 21, Loss (standarized): 1.2016929889309262\n",
      "          Validation Loss (standardized): 1.3711562923064426\n",
      "Epoch: 26, Loss (standarized): 1.1357205437093134\n",
      "          Validation Loss (standardized): 1.287631383124497\n",
      "Epoch: 31, Loss (standarized): 1.0726063185056953\n",
      "          Validation Loss (standardized): 1.2194332418979708\n",
      "Epoch: 36, Loss (standarized): 1.0135055892992428\n",
      "          Validation Loss (standardized): 1.1587489444304448\n",
      "Epoch: 41, Loss (standarized): 0.9608536664083958\n",
      "          Validation Loss (standardized): 1.1117438239743813\n",
      "Epoch: 46, Loss (standarized): 0.9103083545218599\n",
      "          Validation Loss (standardized): 1.0563245325059467\n",
      "Epoch: 51, Loss (standarized): 0.8625764586905285\n",
      "          Validation Loss (standardized): 1.013478711869168\n",
      "Epoch: 56, Loss (standarized): 0.8143043593895868\n",
      "          Validation Loss (standardized): 0.9646537649785776\n",
      "Epoch: 61, Loss (standarized): 0.7631243897051202\n",
      "          Validation Loss (standardized): 0.9108787699935412\n",
      "Epoch: 66, Loss (standarized): 0.7095567422423005\n",
      "          Validation Loss (standardized): 0.8425363727934405\n",
      "Epoch: 71, Loss (standarized): 0.6590515514076918\n",
      "          Validation Loss (standardized): 0.7926636750923615\n",
      "Epoch: 76, Loss (standarized): 0.6132123583397445\n",
      "          Validation Loss (standardized): 0.7398594183389877\n",
      "Epoch: 81, Loss (standarized): 0.5703712641779881\n",
      "          Validation Loss (standardized): 0.689651554759514\n",
      "Epoch: 86, Loss (standarized): 0.5300458367434027\n",
      "          Validation Loss (standardized): 0.6505899042969886\n",
      "Epoch: 91, Loss (standarized): 0.49213844649594257\n",
      "          Validation Loss (standardized): 0.6144493844719153\n",
      "Epoch: 96, Loss (standarized): 0.45715203930769177\n",
      "          Validation Loss (standardized): 0.5858322042852001\n",
      "Final epoch: 100, Final loss (standarized): 0.4309683118334871\n",
      "Epoch: 1, Loss (standarized): 1.7950894880099788\n",
      "          Validation Loss (standardized): 1.6149647506535774\n",
      "Epoch: 6, Loss (standarized): 1.2992094427484755\n",
      "          Validation Loss (standardized): 1.3140044730044897\n",
      "Epoch: 11, Loss (standarized): 1.2220565283378815\n",
      "          Validation Loss (standardized): 1.2603602984422437\n",
      "Epoch: 16, Loss (standarized): 1.162028786426671\n",
      "          Validation Loss (standardized): 1.193281460829337\n",
      "Epoch: 21, Loss (standarized): 1.1074843671891692\n",
      "          Validation Loss (standardized): 1.1631792445856153\n",
      "Epoch: 26, Loss (standarized): 1.0672488110371898\n",
      "          Validation Loss (standardized): 1.1387151195095693\n",
      "Epoch: 31, Loss (standarized): 1.0251759022841238\n",
      "          Validation Loss (standardized): 1.1035945160506484\n",
      "Epoch: 36, Loss (standarized): 0.9829937121209591\n",
      "          Validation Loss (standardized): 1.0685097953770009\n",
      "Epoch: 41, Loss (standarized): 0.940823670662362\n",
      "          Validation Loss (standardized): 1.028840100212669\n",
      "Epoch: 46, Loss (standarized): 0.8938008758533431\n",
      "          Validation Loss (standardized): 0.9842103911799086\n",
      "Epoch: 51, Loss (standarized): 0.8459645281865136\n",
      "          Validation Loss (standardized): 0.9512307825887127\n",
      "Epoch: 56, Loss (standarized): 0.7971423367346097\n",
      "          Validation Loss (standardized): 0.9102509972660949\n",
      "Epoch: 61, Loss (standarized): 0.7496103557544432\n",
      "          Validation Loss (standardized): 0.8714583061916559\n",
      "Epoch: 66, Loss (standarized): 0.7045063239598734\n",
      "          Validation Loss (standardized): 0.8380912898552059\n",
      "Epoch: 71, Loss (standarized): 0.6635785668339151\n",
      "          Validation Loss (standardized): 0.8015734458791222\n",
      "Epoch: 76, Loss (standarized): 0.6252982637040944\n",
      "          Validation Loss (standardized): 0.7716861653161159\n",
      "Epoch: 81, Loss (standarized): 0.5912600212299212\n",
      "          Validation Loss (standardized): 0.7427421636522007\n",
      "Epoch: 86, Loss (standarized): 0.5606629970650222\n",
      "          Validation Loss (standardized): 0.7124854745070458\n",
      "Epoch: 91, Loss (standarized): 0.5333409801715879\n",
      "          Validation Loss (standardized): 0.6886584447976613\n",
      "Epoch: 96, Loss (standarized): 0.5095561242796992\n",
      "          Validation Loss (standardized): 0.6648269976248533\n",
      "Final epoch: 100, Final loss (standarized): 0.49266536890814266\n",
      "Epoch: 1, Loss (standarized): 2.2230945695820004\n",
      "          Validation Loss (standardized): 2.2295623005207252\n",
      "Epoch: 6, Loss (standarized): 1.4508696506546093\n",
      "          Validation Loss (standardized): 1.4534249834768298\n",
      "Epoch: 11, Loss (standarized): 1.2699372252014016\n",
      "          Validation Loss (standardized): 1.2495578101535778\n",
      "Epoch: 16, Loss (standarized): 1.1874534468614275\n",
      "          Validation Loss (standardized): 1.187766872736961\n",
      "Epoch: 21, Loss (standarized): 1.1552447438392\n",
      "          Validation Loss (standardized): 1.1819306273126167\n",
      "Epoch: 26, Loss (standarized): 1.106635168308601\n",
      "          Validation Loss (standardized): 1.1624885144351513\n",
      "Epoch: 31, Loss (standarized): 1.0565704651685173\n",
      "          Validation Loss (standardized): 1.1202764418930755\n",
      "Epoch: 36, Loss (standarized): 1.0118832557508426\n",
      "          Validation Loss (standardized): 1.07584250334561\n",
      "Epoch: 41, Loss (standarized): 0.965720806867369\n",
      "          Validation Loss (standardized): 1.0606697032099441\n",
      "Epoch: 46, Loss (standarized): 0.9198039252774618\n",
      "          Validation Loss (standardized): 1.0348363583944993\n",
      "Epoch: 51, Loss (standarized): 0.8691886373502632\n",
      "          Validation Loss (standardized): 0.9915381718240033\n",
      "Epoch: 56, Loss (standarized): 0.8182219306007485\n",
      "          Validation Loss (standardized): 0.9652754062119006\n",
      "Epoch: 61, Loss (standarized): 0.7643967465176169\n",
      "          Validation Loss (standardized): 0.9238502428310278\n",
      "Epoch: 66, Loss (standarized): 0.7108537671264736\n",
      "          Validation Loss (standardized): 0.8834548272718676\n",
      "Epoch: 71, Loss (standarized): 0.6604732756509146\n",
      "          Validation Loss (standardized): 0.8407020150987098\n",
      "Epoch: 76, Loss (standarized): 0.611327413936941\n",
      "          Validation Loss (standardized): 0.8038453232786817\n",
      "Epoch: 81, Loss (standarized): 0.5657878918244066\n",
      "          Validation Loss (standardized): 0.7673009662796392\n",
      "Epoch: 86, Loss (standarized): 0.5251983840463916\n",
      "          Validation Loss (standardized): 0.7403998944304325\n",
      "Epoch: 91, Loss (standarized): 0.48493368115693924\n",
      "          Validation Loss (standardized): 0.7002664338732666\n",
      "Epoch: 96, Loss (standarized): 0.4468548916606859\n",
      "          Validation Loss (standardized): 0.667336396848961\n",
      "Final epoch: 100, Final loss (standarized): 0.41905199960785616\n",
      "Epoch: 1, Loss (standarized): 1.8962631709901723\n",
      "          Validation Loss (standardized): 1.6160818065070301\n",
      "Epoch: 6, Loss (standarized): 1.3483213054700645\n",
      "          Validation Loss (standardized): 1.320631254950637\n",
      "Epoch: 11, Loss (standarized): 1.2353116760420442\n",
      "          Validation Loss (standardized): 1.2324473444584192\n",
      "Epoch: 16, Loss (standarized): 1.1827683362993284\n",
      "          Validation Loss (standardized): 1.1951592659575083\n",
      "Epoch: 21, Loss (standarized): 1.1347435254121714\n",
      "          Validation Loss (standardized): 1.2113650627986063\n",
      "Epoch: 26, Loss (standarized): 1.0921172623907973\n",
      "          Validation Loss (standardized): 1.1731098754370801\n",
      "Epoch: 31, Loss (standarized): 1.0540175764929767\n",
      "          Validation Loss (standardized): 1.1409268710652047\n",
      "Epoch: 36, Loss (standarized): 1.0180432046400958\n",
      "          Validation Loss (standardized): 1.1292347744468618\n",
      "Epoch: 41, Loss (standarized): 0.9787787274657856\n",
      "          Validation Loss (standardized): 1.0915436179269253\n",
      "Epoch: 46, Loss (standarized): 0.9394609305892044\n",
      "          Validation Loss (standardized): 1.0579472769431462\n",
      "Epoch: 51, Loss (standarized): 0.8965264281732136\n",
      "          Validation Loss (standardized): 1.0250246097668119\n",
      "Epoch: 56, Loss (standarized): 0.8441788456668832\n",
      "          Validation Loss (standardized): 0.9721795166128995\n",
      "Epoch: 61, Loss (standarized): 0.7887901933081514\n",
      "          Validation Loss (standardized): 0.9386767009809628\n",
      "Epoch: 66, Loss (standarized): 0.7311209253233159\n",
      "          Validation Loss (standardized): 0.8875162609374196\n",
      "Epoch: 71, Loss (standarized): 0.6724347646872443\n",
      "          Validation Loss (standardized): 0.8309685384040927\n",
      "Epoch: 76, Loss (standarized): 0.6176132386696769\n",
      "          Validation Loss (standardized): 0.7855594948771987\n",
      "Epoch: 81, Loss (standarized): 0.5653371788088976\n",
      "          Validation Loss (standardized): 0.7394100043128713\n",
      "Epoch: 86, Loss (standarized): 0.5156796954567846\n",
      "          Validation Loss (standardized): 0.7088939677084247\n",
      "Epoch: 91, Loss (standarized): 0.4715333850038259\n",
      "          Validation Loss (standardized): 0.674155863836338\n",
      "Epoch: 96, Loss (standarized): 0.4314918072758027\n",
      "          Validation Loss (standardized): 0.6392381042783718\n",
      "Final epoch: 100, Final loss (standarized): 0.4018112550948508\n",
      "Epoch: 1, Loss (standarized): 2.408589512332832\n",
      "Epoch: 6, Loss (standarized): 1.535183498206182\n",
      "Epoch: 11, Loss (standarized): 1.3612802712619416\n",
      "Epoch: 16, Loss (standarized): 1.2647125360140326\n",
      "Epoch: 21, Loss (standarized): 1.2206469902307113\n",
      "Epoch: 26, Loss (standarized): 1.1849982053305177\n",
      "Epoch: 31, Loss (standarized): 1.1450789911952584\n",
      "Epoch: 36, Loss (standarized): 1.1091248569975567\n",
      "Epoch: 41, Loss (standarized): 1.070359269357628\n",
      "Epoch: 46, Loss (standarized): 1.0290244885235937\n",
      "Epoch: 51, Loss (standarized): 0.9833202850756325\n",
      "Epoch: 56, Loss (standarized): 0.9342875891538601\n",
      "Epoch: 61, Loss (standarized): 0.8817201734186092\n",
      "Epoch: 66, Loss (standarized): 0.8277596547777841\n",
      "Epoch: 71, Loss (standarized): 0.7747546438521836\n",
      "Epoch: 76, Loss (standarized): 0.722315643590443\n",
      "Epoch: 81, Loss (standarized): 0.6727851527295536\n",
      "Epoch: 86, Loss (standarized): 0.6263060215076764\n",
      "Epoch: 91, Loss (standarized): 0.5833812935291617\n",
      "Epoch: 96, Loss (standarized): 0.5446238460876898\n",
      "Final epoch: 100, Final loss (standarized): 0.5153409611755492\n",
      "Epoch: 1, Loss (standarized): 3.7925555176690118\n",
      "Epoch: 6, Loss (standarized): 1.7534930025444297\n",
      "Epoch: 11, Loss (standarized): 1.5880933524518972\n",
      "Epoch: 16, Loss (standarized): 1.4850083005464925\n",
      "Epoch: 21, Loss (standarized): 1.3516300463883175\n",
      "Epoch: 26, Loss (standarized): 1.2601310873323108\n",
      "Epoch: 31, Loss (standarized): 1.2213061459280237\n",
      "Epoch: 36, Loss (standarized): 1.1833176089612911\n",
      "Epoch: 41, Loss (standarized): 1.1529316175080908\n",
      "Epoch: 46, Loss (standarized): 1.1247655075857466\n",
      "Epoch: 51, Loss (standarized): 1.0996686528996693\n",
      "Epoch: 56, Loss (standarized): 1.0747701386818118\n",
      "Epoch: 61, Loss (standarized): 1.0507464817161527\n",
      "Epoch: 66, Loss (standarized): 1.0259488562137902\n",
      "Epoch: 71, Loss (standarized): 0.9995427896634077\n",
      "Epoch: 76, Loss (standarized): 0.9704894069132812\n",
      "Epoch: 81, Loss (standarized): 0.9370507634815227\n",
      "Epoch: 86, Loss (standarized): 0.898964689517843\n",
      "Epoch: 91, Loss (standarized): 0.8568112408218344\n",
      "Epoch: 96, Loss (standarized): 0.8134420118781429\n",
      "Final epoch: 100, Final loss (standarized): 0.7787967174147653\n",
      "Epoch: 1, Loss (standarized): 2.260091309999724\n",
      "Epoch: 6, Loss (standarized): 1.4483305911317421\n",
      "Epoch: 11, Loss (standarized): 1.3300645838678276\n",
      "Epoch: 16, Loss (standarized): 1.2513811872781984\n",
      "Epoch: 21, Loss (standarized): 1.2038754019758913\n",
      "Epoch: 26, Loss (standarized): 1.1387887115968016\n",
      "Epoch: 31, Loss (standarized): 1.0875567373275112\n",
      "Epoch: 36, Loss (standarized): 1.0333034189018533\n",
      "Epoch: 41, Loss (standarized): 0.9788852114446938\n",
      "Epoch: 46, Loss (standarized): 0.932728521249486\n",
      "Epoch: 51, Loss (standarized): 0.8842929626486515\n",
      "Epoch: 56, Loss (standarized): 0.8352648406565367\n",
      "Epoch: 61, Loss (standarized): 0.7845478053933715\n",
      "Epoch: 66, Loss (standarized): 0.7301325874203317\n",
      "Epoch: 71, Loss (standarized): 0.6768698860801362\n",
      "Epoch: 76, Loss (standarized): 0.6242452336163762\n",
      "Epoch: 81, Loss (standarized): 0.5742466620908213\n",
      "Epoch: 86, Loss (standarized): 0.5259106445295747\n",
      "Epoch: 91, Loss (standarized): 0.4822764651213681\n",
      "Epoch: 96, Loss (standarized): 0.4418052518268314\n",
      "Final epoch: 100, Final loss (standarized): 0.41165154827527817\n",
      "Epoch: 1, Loss (standarized): 2.3328333416429463\n",
      "Epoch: 6, Loss (standarized): 1.5451878588810946\n",
      "Epoch: 11, Loss (standarized): 1.3383293117064525\n",
      "Epoch: 16, Loss (standarized): 1.2636170486234939\n",
      "Epoch: 21, Loss (standarized): 1.2177019365260116\n",
      "Epoch: 26, Loss (standarized): 1.1591329804020818\n",
      "Epoch: 31, Loss (standarized): 1.1118174826531604\n",
      "Epoch: 36, Loss (standarized): 1.0701345405961333\n",
      "Epoch: 41, Loss (standarized): 1.0226646587658326\n",
      "Epoch: 46, Loss (standarized): 0.9752726518850884\n",
      "Epoch: 51, Loss (standarized): 0.9274325474408903\n",
      "Epoch: 56, Loss (standarized): 0.8763407886326088\n",
      "Epoch: 61, Loss (standarized): 0.821778219778372\n",
      "Epoch: 66, Loss (standarized): 0.7662125607601709\n",
      "Epoch: 71, Loss (standarized): 0.7104677746233381\n",
      "Epoch: 76, Loss (standarized): 0.6567258350566979\n",
      "Epoch: 81, Loss (standarized): 0.6031419249958972\n",
      "Epoch: 86, Loss (standarized): 0.5486537639350222\n",
      "Epoch: 91, Loss (standarized): 0.5030025164660702\n",
      "Epoch: 96, Loss (standarized): 0.4642914517829566\n",
      "Final epoch: 100, Final loss (standarized): 0.4354013182243149\n",
      "Epoch: 1, Loss (standarized): 2.923838808406157\n",
      "Epoch: 6, Loss (standarized): 1.6499713022986646\n",
      "Epoch: 11, Loss (standarized): 1.4171664664739587\n",
      "Epoch: 16, Loss (standarized): 1.3125803072690063\n",
      "Epoch: 21, Loss (standarized): 1.2579004672680665\n",
      "Epoch: 26, Loss (standarized): 1.2234957843707182\n",
      "Epoch: 31, Loss (standarized): 1.1903191363875334\n",
      "Epoch: 36, Loss (standarized): 1.1617814441421328\n",
      "Epoch: 41, Loss (standarized): 1.1408335145919477\n",
      "Epoch: 46, Loss (standarized): 1.122805527472334\n",
      "Epoch: 51, Loss (standarized): 1.1075597215403592\n",
      "Epoch: 56, Loss (standarized): 1.094395036303314\n",
      "Epoch: 61, Loss (standarized): 1.079563643919897\n",
      "Epoch: 66, Loss (standarized): 1.064963778254212\n",
      "Epoch: 71, Loss (standarized): 1.0498086516043792\n",
      "Epoch: 76, Loss (standarized): 1.0349076030761315\n",
      "Epoch: 81, Loss (standarized): 1.0184495887914715\n",
      "Epoch: 86, Loss (standarized): 1.0040377565475285\n",
      "Epoch: 91, Loss (standarized): 0.9910203113473287\n",
      "Epoch: 96, Loss (standarized): 0.9789500298851734\n",
      "Final epoch: 100, Final loss (standarized): 0.969408972450568\n",
      "Epoch: 1, Loss (standarized): 2.0734609651190525\n",
      "Epoch: 6, Loss (standarized): 1.5292287694259767\n",
      "Epoch: 11, Loss (standarized): 1.3758644344098336\n",
      "Epoch: 16, Loss (standarized): 1.31158864515443\n",
      "Epoch: 21, Loss (standarized): 1.2787748892400543\n",
      "Epoch: 26, Loss (standarized): 1.2594222570173574\n",
      "Epoch: 31, Loss (standarized): 1.242573919203695\n",
      "Epoch: 36, Loss (standarized): 1.2323341500601284\n",
      "Epoch: 41, Loss (standarized): 1.2230669355438268\n",
      "Epoch: 46, Loss (standarized): 1.2101784157732212\n",
      "Epoch: 51, Loss (standarized): 1.1982842260693185\n",
      "Epoch: 56, Loss (standarized): 1.1821443715490145\n",
      "Epoch: 61, Loss (standarized): 1.1655442120874722\n",
      "Epoch: 66, Loss (standarized): 1.14936180382492\n",
      "Epoch: 71, Loss (standarized): 1.1327613287411495\n",
      "Epoch: 76, Loss (standarized): 1.1147019652011758\n",
      "Epoch: 81, Loss (standarized): 1.0978491654689324\n",
      "Epoch: 86, Loss (standarized): 1.080308318800212\n",
      "Epoch: 91, Loss (standarized): 1.0612767984360365\n",
      "Epoch: 96, Loss (standarized): 1.0428950810530373\n",
      "Final epoch: 100, Final loss (standarized): 1.027959941489081\n",
      "Epoch: 1, Loss (standarized): 1.8845710108396105\n",
      "Epoch: 6, Loss (standarized): 1.4046372518799313\n",
      "Epoch: 11, Loss (standarized): 1.2949019853376202\n",
      "Epoch: 16, Loss (standarized): 1.245209858739866\n",
      "Epoch: 21, Loss (standarized): 1.2163822432296942\n",
      "Epoch: 26, Loss (standarized): 1.1914213887646088\n",
      "Epoch: 31, Loss (standarized): 1.1744854837372278\n",
      "Epoch: 36, Loss (standarized): 1.1598972468700197\n",
      "Epoch: 41, Loss (standarized): 1.1451797331324174\n",
      "Epoch: 46, Loss (standarized): 1.1271498559168935\n",
      "Epoch: 51, Loss (standarized): 1.1098867751836716\n",
      "Epoch: 56, Loss (standarized): 1.092734078480655\n",
      "Epoch: 61, Loss (standarized): 1.0745424255667095\n",
      "Epoch: 66, Loss (standarized): 1.0562148654835868\n",
      "Epoch: 71, Loss (standarized): 1.0359996134841845\n",
      "Epoch: 76, Loss (standarized): 1.0152590399454453\n",
      "Epoch: 81, Loss (standarized): 0.9945290456067234\n",
      "Epoch: 86, Loss (standarized): 0.9736555708962098\n",
      "Epoch: 91, Loss (standarized): 0.9513211304853243\n",
      "Epoch: 96, Loss (standarized): 0.9285208775184318\n",
      "Final epoch: 100, Final loss (standarized): 0.9104927919241825\n",
      "Epoch: 1, Loss (standarized): 2.06046841174771\n",
      "Epoch: 6, Loss (standarized): 1.4433474935970225\n",
      "Epoch: 11, Loss (standarized): 1.3078608436622465\n",
      "Epoch: 16, Loss (standarized): 1.2546101026423568\n",
      "Epoch: 21, Loss (standarized): 1.2242142519764931\n",
      "Epoch: 26, Loss (standarized): 1.1903597090871278\n",
      "Epoch: 31, Loss (standarized): 1.167469640365095\n",
      "Epoch: 36, Loss (standarized): 1.1464905902864548\n",
      "Epoch: 41, Loss (standarized): 1.1292858487446478\n",
      "Epoch: 46, Loss (standarized): 1.111378156589486\n",
      "Epoch: 51, Loss (standarized): 1.0935813147787832\n",
      "Epoch: 56, Loss (standarized): 1.0778415187746087\n",
      "Epoch: 61, Loss (standarized): 1.0609669571900278\n",
      "Epoch: 66, Loss (standarized): 1.0427365921055005\n",
      "Epoch: 71, Loss (standarized): 1.0234257600050671\n",
      "Epoch: 76, Loss (standarized): 1.0050735904274797\n",
      "Epoch: 81, Loss (standarized): 0.986109326647298\n",
      "Epoch: 86, Loss (standarized): 0.9650805126515236\n",
      "Epoch: 91, Loss (standarized): 0.9424560485333567\n",
      "Epoch: 96, Loss (standarized): 0.9176784435562096\n",
      "Final epoch: 100, Final loss (standarized): 0.898099461008456\n",
      "Epoch: 1, Loss (standarized): 2.207964304025955\n",
      "Epoch: 6, Loss (standarized): 1.441857571852255\n",
      "Epoch: 11, Loss (standarized): 1.2568978768405983\n",
      "Epoch: 16, Loss (standarized): 1.1828084411843014\n",
      "Epoch: 21, Loss (standarized): 1.127405926625205\n",
      "Epoch: 26, Loss (standarized): 1.075425491541121\n",
      "Epoch: 31, Loss (standarized): 1.02960002947915\n",
      "Epoch: 36, Loss (standarized): 0.9862730240953133\n",
      "Epoch: 41, Loss (standarized): 0.9426436880911382\n",
      "Epoch: 46, Loss (standarized): 0.900420239471417\n",
      "Epoch: 51, Loss (standarized): 0.8572088136156764\n",
      "Epoch: 56, Loss (standarized): 0.8128312557872968\n",
      "Epoch: 61, Loss (standarized): 0.7678349529991537\n",
      "Epoch: 66, Loss (standarized): 0.7229641464766801\n",
      "Epoch: 71, Loss (standarized): 0.6793239777258985\n",
      "Epoch: 76, Loss (standarized): 0.6354639578546784\n",
      "Epoch: 81, Loss (standarized): 0.5924030532277962\n",
      "Epoch: 86, Loss (standarized): 0.5504360267165186\n",
      "Epoch: 91, Loss (standarized): 0.5116428693547147\n",
      "Epoch: 96, Loss (standarized): 0.47516961500642557\n",
      "Final epoch: 100, Final loss (standarized): 0.4478168199484053\n",
      "Epoch: 1, Loss (standarized): 2.0832079793568457\n",
      "Epoch: 6, Loss (standarized): 1.438814731589663\n",
      "Epoch: 11, Loss (standarized): 1.2997095850057654\n",
      "Epoch: 16, Loss (standarized): 1.2330994032847813\n",
      "Epoch: 21, Loss (standarized): 1.1750685463196027\n",
      "Epoch: 26, Loss (standarized): 1.1327725210250117\n",
      "Epoch: 31, Loss (standarized): 1.095402608985313\n",
      "Epoch: 36, Loss (standarized): 1.059991661913411\n",
      "Epoch: 41, Loss (standarized): 1.0301496444060345\n",
      "Epoch: 46, Loss (standarized): 0.9971000963227009\n",
      "Epoch: 51, Loss (standarized): 0.9636307284813558\n",
      "Epoch: 56, Loss (standarized): 0.9277490448542273\n",
      "Epoch: 61, Loss (standarized): 0.8904606793840931\n",
      "Epoch: 66, Loss (standarized): 0.8516930135370095\n",
      "Epoch: 71, Loss (standarized): 0.8129550380066226\n",
      "Epoch: 76, Loss (standarized): 0.7752569320323961\n",
      "Epoch: 81, Loss (standarized): 0.7377838978135646\n",
      "Epoch: 86, Loss (standarized): 0.702133979794219\n",
      "Epoch: 91, Loss (standarized): 0.6676512642409572\n",
      "Epoch: 96, Loss (standarized): 0.6347899797733663\n",
      "Final epoch: 100, Final loss (standarized): 0.6098190881241868\n",
      "Epoch: 1, Loss (standarized): 2.1320299462175636\n",
      "Epoch: 6, Loss (standarized): 1.4942466691545675\n",
      "Epoch: 11, Loss (standarized): 1.3248598937228289\n",
      "Epoch: 16, Loss (standarized): 1.231822849505287\n",
      "Epoch: 21, Loss (standarized): 1.1477462726074157\n",
      "Epoch: 26, Loss (standarized): 1.0834212147661861\n",
      "Epoch: 31, Loss (standarized): 1.02821242177194\n",
      "Epoch: 36, Loss (standarized): 0.9756240154788186\n",
      "Epoch: 41, Loss (standarized): 0.9242357357298868\n",
      "Epoch: 46, Loss (standarized): 0.8761465737688561\n",
      "Epoch: 51, Loss (standarized): 0.8271837968146692\n",
      "Epoch: 56, Loss (standarized): 0.7779539886252667\n",
      "Epoch: 61, Loss (standarized): 0.7284874766725732\n",
      "Epoch: 66, Loss (standarized): 0.6790520101074846\n",
      "Epoch: 71, Loss (standarized): 0.6304161260548885\n",
      "Epoch: 76, Loss (standarized): 0.5837484345420084\n",
      "Epoch: 81, Loss (standarized): 0.5395733662199099\n",
      "Epoch: 86, Loss (standarized): 0.5007602566625519\n",
      "Epoch: 91, Loss (standarized): 0.46653670126771873\n",
      "Epoch: 96, Loss (standarized): 0.43668289333110316\n",
      "Final epoch: 100, Final loss (standarized): 0.41567583279681486\n",
      "Epoch: 1, Loss (standarized): 1.8563405485981648\n",
      "Epoch: 6, Loss (standarized): 1.343554589163005\n",
      "Epoch: 11, Loss (standarized): 1.2081196462124706\n",
      "Epoch: 16, Loss (standarized): 1.1466817896684096\n",
      "Epoch: 21, Loss (standarized): 1.0957469705919238\n",
      "Epoch: 26, Loss (standarized): 1.043204095537878\n",
      "Epoch: 31, Loss (standarized): 0.9912180339845136\n",
      "Epoch: 36, Loss (standarized): 0.9384112657757326\n",
      "Epoch: 41, Loss (standarized): 0.8797468271699797\n",
      "Epoch: 46, Loss (standarized): 0.8225004630901995\n",
      "Epoch: 51, Loss (standarized): 0.7644274470657753\n",
      "Epoch: 56, Loss (standarized): 0.7061272120202845\n",
      "Epoch: 61, Loss (standarized): 0.6493953406589423\n",
      "Epoch: 66, Loss (standarized): 0.5955319939774282\n",
      "Epoch: 71, Loss (standarized): 0.5446571844416864\n",
      "Epoch: 76, Loss (standarized): 0.4964935438648663\n",
      "Epoch: 81, Loss (standarized): 0.45194711762950407\n",
      "Epoch: 86, Loss (standarized): 0.40935412318389724\n",
      "Epoch: 91, Loss (standarized): 0.3728008611274295\n",
      "Epoch: 96, Loss (standarized): 0.33987233252179183\n",
      "Final epoch: 100, Final loss (standarized): 0.316174076924353\n",
      "Epoch: 1, Loss (standarized): 1.762397335553058\n",
      "Epoch: 6, Loss (standarized): 1.3998352211833844\n",
      "Epoch: 11, Loss (standarized): 1.2518593941029013\n",
      "Epoch: 16, Loss (standarized): 1.1578064662238992\n",
      "Epoch: 21, Loss (standarized): 1.084170410924061\n",
      "Epoch: 26, Loss (standarized): 1.0210731335364687\n",
      "Epoch: 31, Loss (standarized): 0.9641101906618047\n",
      "Epoch: 36, Loss (standarized): 0.9055182668650423\n",
      "Epoch: 41, Loss (standarized): 0.8457107296301508\n",
      "Epoch: 46, Loss (standarized): 0.7875159389140001\n",
      "Epoch: 51, Loss (standarized): 0.7282519882140748\n",
      "Epoch: 56, Loss (standarized): 0.6703170363970127\n",
      "Epoch: 61, Loss (standarized): 0.615109249394891\n",
      "Epoch: 66, Loss (standarized): 0.5627620293873247\n",
      "Epoch: 71, Loss (standarized): 0.5140817489677507\n",
      "Epoch: 76, Loss (standarized): 0.46888253947008507\n",
      "Epoch: 81, Loss (standarized): 0.42746081137225617\n",
      "Epoch: 86, Loss (standarized): 0.39160714673561586\n",
      "Epoch: 91, Loss (standarized): 0.3591234768731958\n",
      "Epoch: 96, Loss (standarized): 0.3308017099191457\n",
      "Final epoch: 100, Final loss (standarized): 0.3101304171440594\n",
      "Epoch: 1, Loss (standarized): 2.5505882857066036\n",
      "Epoch: 6, Loss (standarized): 1.6012866012098417\n",
      "Epoch: 11, Loss (standarized): 1.445418506428838\n",
      "Epoch: 16, Loss (standarized): 1.3684922026172257\n",
      "Epoch: 21, Loss (standarized): 1.2943645315514474\n",
      "Epoch: 26, Loss (standarized): 1.2251999956536834\n",
      "Epoch: 31, Loss (standarized): 1.1659850449946076\n",
      "Epoch: 36, Loss (standarized): 1.1051584347486416\n",
      "Epoch: 41, Loss (standarized): 1.0533266133366979\n",
      "Epoch: 46, Loss (standarized): 1.0099386740983467\n",
      "Epoch: 51, Loss (standarized): 0.9704336003654213\n",
      "Epoch: 56, Loss (standarized): 0.9360003223433014\n",
      "Epoch: 61, Loss (standarized): 0.9040606762988466\n",
      "Epoch: 66, Loss (standarized): 0.8726273600888755\n",
      "Epoch: 71, Loss (standarized): 0.8395527362889347\n",
      "Epoch: 76, Loss (standarized): 0.8029482207057517\n",
      "Epoch: 81, Loss (standarized): 0.7669345931751039\n",
      "Epoch: 86, Loss (standarized): 0.7252190670298421\n",
      "Epoch: 91, Loss (standarized): 0.6829928151606421\n",
      "Epoch: 96, Loss (standarized): 0.6401107557992103\n",
      "Final epoch: 100, Final loss (standarized): 0.6061590783445253\n",
      "Epoch: 1, Loss (standarized): 1.9187139890580494\n",
      "Epoch: 6, Loss (standarized): 1.4213337924806648\n",
      "Epoch: 11, Loss (standarized): 1.290897845915573\n",
      "Epoch: 16, Loss (standarized): 1.1668387474908977\n",
      "Epoch: 21, Loss (standarized): 1.1018319546612148\n",
      "Epoch: 26, Loss (standarized): 1.0306616960274855\n",
      "Epoch: 31, Loss (standarized): 0.9679214828333761\n",
      "Epoch: 36, Loss (standarized): 0.9057551681372442\n",
      "Epoch: 41, Loss (standarized): 0.8431053570159331\n",
      "Epoch: 46, Loss (standarized): 0.7832762272553478\n",
      "Epoch: 51, Loss (standarized): 0.7263187563733743\n",
      "Epoch: 56, Loss (standarized): 0.669278450429269\n",
      "Epoch: 61, Loss (standarized): 0.6123310402389092\n",
      "Epoch: 66, Loss (standarized): 0.5569559619536796\n",
      "Epoch: 71, Loss (standarized): 0.505353122438409\n",
      "Epoch: 76, Loss (standarized): 0.4586818283072109\n",
      "Epoch: 81, Loss (standarized): 0.4160809832519137\n",
      "Epoch: 86, Loss (standarized): 0.37761987102596206\n",
      "Epoch: 91, Loss (standarized): 0.34405346651261703\n",
      "Epoch: 96, Loss (standarized): 0.3153309515961395\n",
      "Final epoch: 100, Final loss (standarized): 0.29361105597205\n",
      "Epoch: 1, Loss (standarized): 2.200338829686008\n",
      "Epoch: 6, Loss (standarized): 1.5029992288254022\n",
      "Epoch: 11, Loss (standarized): 1.322312355541051\n",
      "Epoch: 16, Loss (standarized): 1.2193358629751512\n",
      "Epoch: 21, Loss (standarized): 1.1531923743307204\n",
      "Epoch: 26, Loss (standarized): 1.0987028587004328\n",
      "Epoch: 31, Loss (standarized): 1.0575074810580238\n",
      "Epoch: 36, Loss (standarized): 1.0105573679737052\n",
      "Epoch: 41, Loss (standarized): 0.9651502964541477\n",
      "Epoch: 46, Loss (standarized): 0.9162511230076769\n",
      "Epoch: 51, Loss (standarized): 0.8675560084340816\n",
      "Epoch: 56, Loss (standarized): 0.8156673166765215\n",
      "Epoch: 61, Loss (standarized): 0.7595305016658606\n",
      "Epoch: 66, Loss (standarized): 0.7018474176010246\n",
      "Epoch: 71, Loss (standarized): 0.6431911925521148\n",
      "Epoch: 76, Loss (standarized): 0.5894974447331882\n",
      "Epoch: 81, Loss (standarized): 0.5381566389746062\n",
      "Epoch: 86, Loss (standarized): 0.4905509864365439\n",
      "Epoch: 91, Loss (standarized): 0.445478467689425\n",
      "Epoch: 96, Loss (standarized): 0.40462337853281694\n",
      "Final epoch: 100, Final loss (standarized): 0.37521675043812736\n",
      "Epoch: 1, Loss (standarized): 3.298100345502395\n",
      "          Validation Loss (standardized): 2.0465849680885673\n",
      "Epoch: 6, Loss (standarized): 2.0673654131283916\n",
      "          Validation Loss (standardized): 1.570577217700256\n",
      "Epoch: 11, Loss (standarized): 1.402251968781038\n",
      "          Validation Loss (standardized): 1.3040358668132586\n",
      "Epoch: 16, Loss (standarized): 1.2056664120250118\n",
      "          Validation Loss (standardized): 1.2712290282978105\n",
      "Epoch: 21, Loss (standarized): 1.1494990051872673\n",
      "          Validation Loss (standardized): 1.270563229662802\n",
      "Epoch: 26, Loss (standarized): 1.0880420891799667\n",
      "          Validation Loss (standardized): 1.2092741087063779\n",
      "Epoch: 31, Loss (standarized): 1.011929253242408\n",
      "          Validation Loss (standardized): 1.129295650544643\n",
      "Epoch: 36, Loss (standarized): 0.9568994681098009\n",
      "          Validation Loss (standardized): 1.0641052621797857\n",
      "Epoch: 41, Loss (standarized): 0.9029967939377903\n",
      "          Validation Loss (standardized): 1.016809725253324\n",
      "Epoch: 46, Loss (standarized): 0.8553527717675173\n",
      "          Validation Loss (standardized): 0.9802254853087383\n",
      "Epoch: 51, Loss (standarized): 0.8081214944295937\n",
      "          Validation Loss (standardized): 0.9289899836237776\n",
      "Epoch: 56, Loss (standarized): 0.7595068416592703\n",
      "          Validation Loss (standardized): 0.898417831578595\n",
      "Epoch: 61, Loss (standarized): 0.7129063843418315\n",
      "          Validation Loss (standardized): 0.8636203299347261\n",
      "Epoch: 66, Loss (standarized): 0.6659496416162469\n",
      "          Validation Loss (standardized): 0.8294345604494715\n",
      "Epoch: 71, Loss (standarized): 0.618872422307942\n",
      "          Validation Loss (standardized): 0.7879936703556243\n",
      "Epoch: 76, Loss (standarized): 0.5687009151909844\n",
      "          Validation Loss (standardized): 0.7522703736570174\n",
      "Epoch: 81, Loss (standarized): 0.519377580598572\n",
      "          Validation Loss (standardized): 0.7144653774913665\n",
      "Epoch: 86, Loss (standarized): 0.47092455021097934\n",
      "          Validation Loss (standardized): 0.664996076928906\n",
      "Epoch: 91, Loss (standarized): 0.4227503147316001\n",
      "          Validation Loss (standardized): 0.6234690470421688\n",
      "Epoch: 96, Loss (standarized): 0.38062390202003876\n",
      "          Validation Loss (standardized): 0.5880434377641047\n",
      "Final epoch: 100, Final loss (standarized): 0.3519548559586796\n",
      "Epoch: 1, Loss (standarized): 2.5199777897528386\n",
      "          Validation Loss (standardized): 2.774327360167904\n",
      "Epoch: 6, Loss (standarized): 1.5429835703700787\n",
      "          Validation Loss (standardized): 1.570326349102279\n",
      "Epoch: 11, Loss (standarized): 1.292427313116378\n",
      "          Validation Loss (standardized): 1.2874267709990896\n",
      "Epoch: 16, Loss (standarized): 1.2105783293589218\n",
      "          Validation Loss (standardized): 1.2436948238237233\n",
      "Epoch: 21, Loss (standarized): 1.166261476803721\n",
      "          Validation Loss (standardized): 1.2030295980175834\n",
      "Epoch: 26, Loss (standarized): 1.1330955317460283\n",
      "          Validation Loss (standardized): 1.1865190714978244\n",
      "Epoch: 31, Loss (standarized): 1.10447816040741\n",
      "          Validation Loss (standardized): 1.1742180137497613\n",
      "Epoch: 36, Loss (standarized): 1.0771709196377794\n",
      "          Validation Loss (standardized): 1.139016058342817\n",
      "Epoch: 41, Loss (standarized): 1.0549466049479397\n",
      "          Validation Loss (standardized): 1.115867457424966\n",
      "Epoch: 46, Loss (standarized): 1.0306387266384178\n",
      "          Validation Loss (standardized): 1.0934878725406427\n",
      "Epoch: 51, Loss (standarized): 1.0050621037765213\n",
      "          Validation Loss (standardized): 1.0668717810648156\n",
      "Epoch: 56, Loss (standarized): 0.9765456148396293\n",
      "          Validation Loss (standardized): 1.0356256796091816\n",
      "Epoch: 61, Loss (standarized): 0.9452154990965278\n",
      "          Validation Loss (standardized): 1.017196060548502\n",
      "Epoch: 66, Loss (standarized): 0.9116184357849272\n",
      "          Validation Loss (standardized): 0.9838491793943411\n",
      "Epoch: 71, Loss (standarized): 0.8768238163215701\n",
      "          Validation Loss (standardized): 0.955234381175003\n",
      "Epoch: 76, Loss (standarized): 0.8382008502041879\n",
      "          Validation Loss (standardized): 0.9236759924765533\n",
      "Epoch: 81, Loss (standarized): 0.7960331297444136\n",
      "          Validation Loss (standardized): 0.8888036619115188\n",
      "Epoch: 86, Loss (standarized): 0.7533150242274733\n",
      "          Validation Loss (standardized): 0.8613801872680926\n",
      "Epoch: 91, Loss (standarized): 0.710388006838214\n",
      "          Validation Loss (standardized): 0.8193352386695898\n",
      "Epoch: 96, Loss (standarized): 0.6688681513977887\n",
      "          Validation Loss (standardized): 0.7873791811787141\n",
      "Final epoch: 100, Final loss (standarized): 0.637749779784654\n",
      "Epoch: 1, Loss (standarized): 2.0364664473777805\n",
      "          Validation Loss (standardized): 1.728370465213704\n",
      "Epoch: 6, Loss (standarized): 1.3923735252555844\n",
      "          Validation Loss (standardized): 1.4391189302890242\n",
      "Epoch: 11, Loss (standarized): 1.3093548093528316\n",
      "          Validation Loss (standardized): 1.3453382420449884\n",
      "Epoch: 16, Loss (standarized): 1.2545368145190041\n",
      "          Validation Loss (standardized): 1.3074651022893717\n",
      "Epoch: 21, Loss (standarized): 1.1975208687602388\n",
      "          Validation Loss (standardized): 1.243602062464943\n",
      "Epoch: 26, Loss (standarized): 1.1524554730642282\n",
      "          Validation Loss (standardized): 1.1737103671054225\n",
      "Epoch: 31, Loss (standarized): 1.0999227406072214\n",
      "          Validation Loss (standardized): 1.1304966986395133\n",
      "Epoch: 36, Loss (standarized): 1.049044006498619\n",
      "          Validation Loss (standardized): 1.0899499389101301\n",
      "Epoch: 41, Loss (standarized): 1.0020852901420831\n",
      "          Validation Loss (standardized): 1.0551524408891417\n",
      "Epoch: 46, Loss (standarized): 0.9580321009085193\n",
      "          Validation Loss (standardized): 1.0327175832591637\n",
      "Epoch: 51, Loss (standarized): 0.9113760560361166\n",
      "          Validation Loss (standardized): 0.9819746871526982\n",
      "Epoch: 56, Loss (standarized): 0.86204920060897\n",
      "          Validation Loss (standardized): 0.9518822903545413\n",
      "Epoch: 61, Loss (standarized): 0.8101472067642602\n",
      "          Validation Loss (standardized): 0.9091023163799766\n",
      "Epoch: 66, Loss (standarized): 0.7559216187746468\n",
      "          Validation Loss (standardized): 0.8602859901590516\n",
      "Epoch: 71, Loss (standarized): 0.6997977615150397\n",
      "          Validation Loss (standardized): 0.8162428579126825\n",
      "Epoch: 76, Loss (standarized): 0.6437519424043638\n",
      "          Validation Loss (standardized): 0.7767435430264015\n",
      "Epoch: 81, Loss (standarized): 0.5904757341507424\n",
      "          Validation Loss (standardized): 0.7386675928692751\n",
      "Epoch: 86, Loss (standarized): 0.5396380944480782\n",
      "          Validation Loss (standardized): 0.7089570450601639\n",
      "Epoch: 91, Loss (standarized): 0.49390791516003746\n",
      "          Validation Loss (standardized): 0.6741661393980832\n",
      "Epoch: 96, Loss (standarized): 0.453486391164293\n",
      "          Validation Loss (standardized): 0.6473523371409954\n",
      "Final epoch: 100, Final loss (standarized): 0.4249600010252634\n",
      "Epoch: 1, Loss (standarized): 2.7891931111683754\n",
      "          Validation Loss (standardized): 2.3161612781498735\n",
      "Epoch: 6, Loss (standarized): 1.6143181599209182\n",
      "          Validation Loss (standardized): 1.5624930941926682\n",
      "Epoch: 11, Loss (standarized): 1.3984966575580893\n",
      "          Validation Loss (standardized): 1.4040967867255991\n",
      "Epoch: 16, Loss (standarized): 1.3262960200544653\n",
      "          Validation Loss (standardized): 1.2745412600844865\n",
      "Epoch: 21, Loss (standarized): 1.275028599121739\n",
      "          Validation Loss (standardized): 1.2458743601129714\n",
      "Epoch: 26, Loss (standarized): 1.2364451205037603\n",
      "          Validation Loss (standardized): 1.246560968924432\n",
      "Epoch: 31, Loss (standarized): 1.214459461996541\n",
      "          Validation Loss (standardized): 1.2384533006144125\n",
      "Epoch: 36, Loss (standarized): 1.1767405123710448\n",
      "          Validation Loss (standardized): 1.1971629724592492\n",
      "Epoch: 41, Loss (standarized): 1.141633072757101\n",
      "          Validation Loss (standardized): 1.1659915908022236\n",
      "Epoch: 46, Loss (standarized): 1.1058361921643773\n",
      "          Validation Loss (standardized): 1.1499147357925577\n",
      "Epoch: 51, Loss (standarized): 1.0699536270563692\n",
      "          Validation Loss (standardized): 1.146554573852108\n",
      "Epoch: 56, Loss (standarized): 1.0275110669771679\n",
      "          Validation Loss (standardized): 1.0879293778644523\n",
      "Epoch: 61, Loss (standarized): 0.9814488169303212\n",
      "          Validation Loss (standardized): 1.062796134781082\n",
      "Epoch: 66, Loss (standarized): 0.9285768224536775\n",
      "          Validation Loss (standardized): 1.0312394904630133\n",
      "Epoch: 71, Loss (standarized): 0.8735047946191767\n",
      "          Validation Loss (standardized): 0.9749783108588549\n",
      "Epoch: 76, Loss (standarized): 0.8154325161991174\n",
      "          Validation Loss (standardized): 0.9365976336876742\n",
      "Epoch: 81, Loss (standarized): 0.7577035124126232\n",
      "          Validation Loss (standardized): 0.8858473104507691\n",
      "Epoch: 86, Loss (standarized): 0.6998546676425083\n",
      "          Validation Loss (standardized): 0.8245175086128143\n",
      "Epoch: 91, Loss (standarized): 0.632224370806267\n",
      "          Validation Loss (standardized): 0.7566252259787192\n",
      "Epoch: 96, Loss (standarized): 0.5763777705163458\n",
      "          Validation Loss (standardized): 0.7158942698884462\n",
      "Final epoch: 100, Final loss (standarized): 0.5305114490800448\n",
      "Epoch: 1, Loss (standarized): 2.0809120544682616\n",
      "          Validation Loss (standardized): 2.004298443255892\n",
      "Epoch: 6, Loss (standarized): 1.4138902377985516\n",
      "          Validation Loss (standardized): 1.5100053145451102\n",
      "Epoch: 11, Loss (standarized): 1.2570484081185234\n",
      "          Validation Loss (standardized): 1.3065160608682231\n",
      "Epoch: 16, Loss (standarized): 1.1845657699781575\n",
      "          Validation Loss (standardized): 1.22865353765294\n",
      "Epoch: 21, Loss (standarized): 1.1386928249952064\n",
      "          Validation Loss (standardized): 1.2028183327524908\n",
      "Epoch: 26, Loss (standarized): 1.108941580153253\n",
      "          Validation Loss (standardized): 1.183418019122766\n",
      "Epoch: 31, Loss (standarized): 1.0817004844312323\n",
      "          Validation Loss (standardized): 1.1493777905789866\n",
      "Epoch: 36, Loss (standarized): 1.0589154129803144\n",
      "          Validation Loss (standardized): 1.134639570182438\n",
      "Epoch: 41, Loss (standarized): 1.0387521222068374\n",
      "          Validation Loss (standardized): 1.12198544725889\n",
      "Epoch: 46, Loss (standarized): 1.0197561506972317\n",
      "          Validation Loss (standardized): 1.0998720326690632\n",
      "Epoch: 51, Loss (standarized): 1.0020515145635023\n",
      "          Validation Loss (standardized): 1.0840055893473532\n",
      "Epoch: 56, Loss (standarized): 0.9825717672789538\n",
      "          Validation Loss (standardized): 1.0611967446220512\n",
      "Epoch: 61, Loss (standarized): 0.9618886214233882\n",
      "          Validation Loss (standardized): 1.0450073828096555\n",
      "Epoch: 66, Loss (standarized): 0.9411334203711118\n",
      "          Validation Loss (standardized): 1.0297686570377487\n",
      "Epoch: 71, Loss (standarized): 0.920953627511277\n",
      "          Validation Loss (standardized): 1.0110632467268592\n",
      "Epoch: 76, Loss (standarized): 0.9007613046042215\n",
      "          Validation Loss (standardized): 0.993332304768031\n",
      "Epoch: 81, Loss (standarized): 0.880074610033252\n",
      "          Validation Loss (standardized): 0.9781779400644702\n",
      "Epoch: 86, Loss (standarized): 0.8590332425643672\n",
      "          Validation Loss (standardized): 0.9569331317234214\n",
      "Epoch: 91, Loss (standarized): 0.8383758157629971\n",
      "          Validation Loss (standardized): 0.939454124120097\n",
      "Epoch: 96, Loss (standarized): 0.8164420720151093\n",
      "          Validation Loss (standardized): 0.917906698418897\n",
      "Final epoch: 100, Final loss (standarized): 0.79735326089865\n",
      "Epoch: 1, Loss (standarized): 1.967784340689288\n",
      "          Validation Loss (standardized): 1.7373384552171505\n",
      "Epoch: 6, Loss (standarized): 1.5343988688985046\n",
      "          Validation Loss (standardized): 1.4151690366494414\n",
      "Epoch: 11, Loss (standarized): 1.4292304067482644\n",
      "          Validation Loss (standardized): 1.319052836172118\n",
      "Epoch: 16, Loss (standarized): 1.3793059731374253\n",
      "          Validation Loss (standardized): 1.300457746258094\n",
      "Epoch: 21, Loss (standarized): 1.3380937905195065\n",
      "          Validation Loss (standardized): 1.2822597837644027\n",
      "Epoch: 26, Loss (standarized): 1.3027268741476903\n",
      "          Validation Loss (standardized): 1.2526098975141087\n",
      "Epoch: 31, Loss (standarized): 1.2689531740294362\n",
      "          Validation Loss (standardized): 1.2383723253789607\n",
      "Epoch: 36, Loss (standarized): 1.2366695801767766\n",
      "          Validation Loss (standardized): 1.2342305492816485\n",
      "Epoch: 41, Loss (standarized): 1.206524098553666\n",
      "          Validation Loss (standardized): 1.2192513665201883\n",
      "Epoch: 46, Loss (standarized): 1.180634939420109\n",
      "          Validation Loss (standardized): 1.2002360729597334\n",
      "Epoch: 51, Loss (standarized): 1.161465264422395\n",
      "          Validation Loss (standardized): 1.1914503340784326\n",
      "Epoch: 56, Loss (standarized): 1.1451815229768492\n",
      "          Validation Loss (standardized): 1.1799731286541069\n",
      "Epoch: 61, Loss (standarized): 1.130186651599816\n",
      "          Validation Loss (standardized): 1.1679764520518505\n",
      "Epoch: 66, Loss (standarized): 1.1170490717923294\n",
      "          Validation Loss (standardized): 1.1584530584492003\n",
      "Epoch: 71, Loss (standarized): 1.1029614731962303\n",
      "          Validation Loss (standardized): 1.1551618499538425\n",
      "Epoch: 76, Loss (standarized): 1.087618737793835\n",
      "          Validation Loss (standardized): 1.14202173484885\n",
      "Epoch: 81, Loss (standarized): 1.072556434020799\n",
      "          Validation Loss (standardized): 1.124919806812044\n",
      "Epoch: 86, Loss (standarized): 1.0573166665642182\n",
      "          Validation Loss (standardized): 1.1139338105967858\n",
      "Epoch: 91, Loss (standarized): 1.041563352201841\n",
      "          Validation Loss (standardized): 1.0989916332548637\n",
      "Epoch: 96, Loss (standarized): 1.0255386028834907\n",
      "          Validation Loss (standardized): 1.0884333934287642\n",
      "Final epoch: 100, Final loss (standarized): 1.0117141885731271\n",
      "Epoch: 1, Loss (standarized): 2.4581900194101243\n",
      "          Validation Loss (standardized): 2.2545991467786126\n",
      "Epoch: 6, Loss (standarized): 1.6010639245252802\n",
      "          Validation Loss (standardized): 1.461255915401228\n",
      "Epoch: 11, Loss (standarized): 1.363909300617618\n",
      "          Validation Loss (standardized): 1.2955626010689474\n",
      "Epoch: 16, Loss (standarized): 1.313311165653361\n",
      "          Validation Loss (standardized): 1.2857482222088439\n",
      "Epoch: 21, Loss (standarized): 1.2736489750351456\n",
      "          Validation Loss (standardized): 1.2555189840884842\n",
      "Epoch: 26, Loss (standarized): 1.2309292989935547\n",
      "          Validation Loss (standardized): 1.2238534853252656\n",
      "Epoch: 31, Loss (standarized): 1.2014121788767562\n",
      "          Validation Loss (standardized): 1.2188699511010948\n",
      "Epoch: 36, Loss (standarized): 1.179875515622754\n",
      "          Validation Loss (standardized): 1.2206716169820513\n",
      "Epoch: 41, Loss (standarized): 1.1598887885059244\n",
      "          Validation Loss (standardized): 1.193412466878725\n",
      "Epoch: 46, Loss (standarized): 1.1400958524163236\n",
      "          Validation Loss (standardized): 1.168200471416518\n",
      "Epoch: 51, Loss (standarized): 1.118660098785575\n",
      "          Validation Loss (standardized): 1.161381034498248\n",
      "Epoch: 56, Loss (standarized): 1.097393477136761\n",
      "          Validation Loss (standardized): 1.1375483418657764\n",
      "Epoch: 61, Loss (standarized): 1.0780158203618786\n",
      "          Validation Loss (standardized): 1.1211930697411694\n",
      "Epoch: 66, Loss (standarized): 1.0589769887078853\n",
      "          Validation Loss (standardized): 1.1112142472371855\n",
      "Epoch: 71, Loss (standarized): 1.0410572144397443\n",
      "          Validation Loss (standardized): 1.102129969275663\n",
      "Epoch: 76, Loss (standarized): 1.0230171740629503\n",
      "          Validation Loss (standardized): 1.0888624541665821\n",
      "Epoch: 81, Loss (standarized): 1.0056107909866736\n",
      "          Validation Loss (standardized): 1.0755847715788545\n",
      "Epoch: 86, Loss (standarized): 0.9875614682935173\n",
      "          Validation Loss (standardized): 1.0661440376570517\n",
      "Epoch: 91, Loss (standarized): 0.9695313992347782\n",
      "          Validation Loss (standardized): 1.050451450925382\n",
      "Epoch: 96, Loss (standarized): 0.9519985366276049\n",
      "          Validation Loss (standardized): 1.0371490980574207\n",
      "Final epoch: 100, Final loss (standarized): 0.9376007560091392\n",
      "Epoch: 1, Loss (standarized): 1.8772598454611795\n",
      "          Validation Loss (standardized): 1.8456869037144983\n",
      "Epoch: 6, Loss (standarized): 1.4565598877301675\n",
      "          Validation Loss (standardized): 1.378437809977883\n",
      "Epoch: 11, Loss (standarized): 1.3196296240442578\n",
      "          Validation Loss (standardized): 1.2995616030905188\n",
      "Epoch: 16, Loss (standarized): 1.2575716517150932\n",
      "          Validation Loss (standardized): 1.2801817503837614\n",
      "Epoch: 21, Loss (standarized): 1.2121705668744978\n",
      "          Validation Loss (standardized): 1.2263597532464832\n",
      "Epoch: 26, Loss (standarized): 1.1770671201979834\n",
      "          Validation Loss (standardized): 1.1930019343567833\n",
      "Epoch: 31, Loss (standarized): 1.1523301617192399\n",
      "          Validation Loss (standardized): 1.1845270234244658\n",
      "Epoch: 36, Loss (standarized): 1.1278138493002343\n",
      "          Validation Loss (standardized): 1.1589135456880921\n",
      "Epoch: 41, Loss (standarized): 1.1062617030283852\n",
      "          Validation Loss (standardized): 1.130829605000053\n",
      "Epoch: 46, Loss (standarized): 1.0838789283267254\n",
      "          Validation Loss (standardized): 1.1172777760445334\n",
      "Epoch: 51, Loss (standarized): 1.061014666459306\n",
      "          Validation Loss (standardized): 1.095815858783584\n",
      "Epoch: 56, Loss (standarized): 1.0365558942931754\n",
      "          Validation Loss (standardized): 1.0831662439578873\n",
      "Epoch: 61, Loss (standarized): 1.012512774352018\n",
      "          Validation Loss (standardized): 1.0655826435062332\n",
      "Epoch: 66, Loss (standarized): 0.9857184715549479\n",
      "          Validation Loss (standardized): 1.0410119981427601\n",
      "Epoch: 71, Loss (standarized): 0.9570228209293242\n",
      "          Validation Loss (standardized): 1.0241859599027807\n",
      "Epoch: 76, Loss (standarized): 0.9280344259135999\n",
      "          Validation Loss (standardized): 0.9951611747564737\n",
      "Epoch: 81, Loss (standarized): 0.8985026971860526\n",
      "          Validation Loss (standardized): 0.9742405887356215\n",
      "Epoch: 86, Loss (standarized): 0.8682098093093217\n",
      "          Validation Loss (standardized): 0.9445328536595508\n",
      "Epoch: 91, Loss (standarized): 0.8356569105830277\n",
      "          Validation Loss (standardized): 0.9183915564001753\n",
      "Epoch: 96, Loss (standarized): 0.8020876168597946\n",
      "          Validation Loss (standardized): 0.8899533352066065\n",
      "Final epoch: 100, Final loss (standarized): 0.775597060761348\n",
      "Epoch: 1, Loss (standarized): 2.132529486702838\n",
      "          Validation Loss (standardized): 1.9879541864559522\n",
      "Epoch: 6, Loss (standarized): 1.3808688986320248\n",
      "          Validation Loss (standardized): 1.292863666127841\n",
      "Epoch: 11, Loss (standarized): 1.2364521543005278\n",
      "          Validation Loss (standardized): 1.2798621708504534\n",
      "Epoch: 16, Loss (standarized): 1.1344132979053936\n",
      "          Validation Loss (standardized): 1.2181418744271433\n",
      "Epoch: 21, Loss (standarized): 1.097784868083751\n",
      "          Validation Loss (standardized): 1.1648857088481537\n",
      "Epoch: 26, Loss (standarized): 1.0472302510989804\n",
      "          Validation Loss (standardized): 1.1186397638947208\n",
      "Epoch: 31, Loss (standarized): 1.013288266273809\n",
      "          Validation Loss (standardized): 1.11485467249373\n",
      "Epoch: 36, Loss (standarized): 0.9672192791203174\n",
      "          Validation Loss (standardized): 1.0789235088097053\n",
      "Epoch: 41, Loss (standarized): 0.9217615251948453\n",
      "          Validation Loss (standardized): 1.0437385780596238\n",
      "Epoch: 46, Loss (standarized): 0.877358340162389\n",
      "          Validation Loss (standardized): 1.014589920378657\n",
      "Epoch: 51, Loss (standarized): 0.8340716299172702\n",
      "          Validation Loss (standardized): 0.9860964979221024\n",
      "Epoch: 56, Loss (standarized): 0.7906719408881515\n",
      "          Validation Loss (standardized): 0.9451800640262882\n",
      "Epoch: 61, Loss (standarized): 0.7451298579656622\n",
      "          Validation Loss (standardized): 0.9127888700874994\n",
      "Epoch: 66, Loss (standarized): 0.6978553539545089\n",
      "          Validation Loss (standardized): 0.877695319643773\n",
      "Epoch: 71, Loss (standarized): 0.6511776969061477\n",
      "          Validation Loss (standardized): 0.836772028719003\n",
      "Epoch: 76, Loss (standarized): 0.6070694628140599\n",
      "          Validation Loss (standardized): 0.7972429032490053\n",
      "Epoch: 81, Loss (standarized): 0.5641941362241608\n",
      "          Validation Loss (standardized): 0.7622055461639929\n",
      "Epoch: 86, Loss (standarized): 0.5242480467023845\n",
      "          Validation Loss (standardized): 0.7240169804258407\n",
      "Epoch: 91, Loss (standarized): 0.4869107304873457\n",
      "          Validation Loss (standardized): 0.6903389787984646\n",
      "Epoch: 96, Loss (standarized): 0.45232212831195484\n",
      "          Validation Loss (standardized): 0.6645568746384509\n",
      "Final epoch: 100, Final loss (standarized): 0.4262776986544737\n",
      "Epoch: 1, Loss (standarized): 2.343725056308484\n",
      "          Validation Loss (standardized): 1.7962363804564567\n",
      "Epoch: 6, Loss (standarized): 1.398195416471221\n",
      "          Validation Loss (standardized): 1.3519447032039666\n",
      "Epoch: 11, Loss (standarized): 1.251073212788849\n",
      "          Validation Loss (standardized): 1.3058513532855398\n",
      "Epoch: 16, Loss (standarized): 1.1710905537937386\n",
      "          Validation Loss (standardized): 1.2609714166303339\n",
      "Epoch: 21, Loss (standarized): 1.1202218407908169\n",
      "          Validation Loss (standardized): 1.1677456449023016\n",
      "Epoch: 26, Loss (standarized): 1.0831524106879085\n",
      "          Validation Loss (standardized): 1.1517483582264594\n",
      "Epoch: 31, Loss (standarized): 1.0437941084880236\n",
      "          Validation Loss (standardized): 1.1331230583946847\n",
      "Epoch: 36, Loss (standarized): 1.0095958798457159\n",
      "          Validation Loss (standardized): 1.0886807280498478\n",
      "Epoch: 41, Loss (standarized): 0.9787848642890792\n",
      "          Validation Loss (standardized): 1.06748745708856\n",
      "Epoch: 46, Loss (standarized): 0.9452009945055813\n",
      "          Validation Loss (standardized): 1.0362440796552173\n",
      "Epoch: 51, Loss (standarized): 0.9064183032350607\n",
      "          Validation Loss (standardized): 1.0027956252115469\n",
      "Epoch: 56, Loss (standarized): 0.8670415491406175\n",
      "          Validation Loss (standardized): 0.9728265414873278\n",
      "Epoch: 61, Loss (standarized): 0.8256339341785214\n",
      "          Validation Loss (standardized): 0.9361000342702908\n",
      "Epoch: 66, Loss (standarized): 0.7803087140738867\n",
      "          Validation Loss (standardized): 0.8894655720540027\n",
      "Epoch: 71, Loss (standarized): 0.7365776784458512\n",
      "          Validation Loss (standardized): 0.8551654010073839\n",
      "Epoch: 76, Loss (standarized): 0.6943302053964774\n",
      "          Validation Loss (standardized): 0.8216877641155325\n",
      "Epoch: 81, Loss (standarized): 0.6551375400806697\n",
      "          Validation Loss (standardized): 0.7876462350994771\n",
      "Epoch: 86, Loss (standarized): 0.618867427578516\n",
      "          Validation Loss (standardized): 0.7534177427011246\n",
      "Epoch: 91, Loss (standarized): 0.5861810377392785\n",
      "          Validation Loss (standardized): 0.7239964167228758\n",
      "Epoch: 96, Loss (standarized): 0.5574280508953734\n",
      "          Validation Loss (standardized): 0.705780106822007\n",
      "Final epoch: 100, Final loss (standarized): 0.5373100609577084\n",
      "Epoch: 1, Loss (standarized): 2.5800379589215003\n",
      "          Validation Loss (standardized): 2.263570108442715\n",
      "Epoch: 6, Loss (standarized): 1.6565265586009428\n",
      "          Validation Loss (standardized): 1.654092838048274\n",
      "Epoch: 11, Loss (standarized): 1.427068010228105\n",
      "          Validation Loss (standardized): 1.464845906053954\n",
      "Epoch: 16, Loss (standarized): 1.315823456290285\n",
      "          Validation Loss (standardized): 1.3638372374309076\n",
      "Epoch: 21, Loss (standarized): 1.2431731718326668\n",
      "          Validation Loss (standardized): 1.2592211577121286\n",
      "Epoch: 26, Loss (standarized): 1.1842037716664922\n",
      "          Validation Loss (standardized): 1.2128824943862628\n",
      "Epoch: 31, Loss (standarized): 1.1410620942305059\n",
      "          Validation Loss (standardized): 1.1939501699239468\n",
      "Epoch: 36, Loss (standarized): 1.093310936187472\n",
      "          Validation Loss (standardized): 1.1451928999037788\n",
      "Epoch: 41, Loss (standarized): 1.0522645472813357\n",
      "          Validation Loss (standardized): 1.118972324894769\n",
      "Epoch: 46, Loss (standarized): 1.0081455332568514\n",
      "          Validation Loss (standardized): 1.085405358846864\n",
      "Epoch: 51, Loss (standarized): 0.9647836816738716\n",
      "          Validation Loss (standardized): 1.0577842375905697\n",
      "Epoch: 56, Loss (standarized): 0.9192386213846874\n",
      "          Validation Loss (standardized): 1.0275435746679864\n",
      "Epoch: 61, Loss (standarized): 0.8747998777555039\n",
      "          Validation Loss (standardized): 0.9983660831821554\n",
      "Epoch: 66, Loss (standarized): 0.8304098038824993\n",
      "          Validation Loss (standardized): 0.9591845002021504\n",
      "Epoch: 71, Loss (standarized): 0.7860006615459324\n",
      "          Validation Loss (standardized): 0.9180647948009857\n",
      "Epoch: 76, Loss (standarized): 0.7364352064582542\n",
      "          Validation Loss (standardized): 0.8753769099124877\n",
      "Epoch: 81, Loss (standarized): 0.6861799695850098\n",
      "          Validation Loss (standardized): 0.8257661070680242\n",
      "Epoch: 86, Loss (standarized): 0.6335978882069879\n",
      "          Validation Loss (standardized): 0.7880778046030429\n",
      "Epoch: 91, Loss (standarized): 0.5825247533836567\n",
      "          Validation Loss (standardized): 0.7431064298954697\n",
      "Epoch: 96, Loss (standarized): 0.5327849170226168\n",
      "          Validation Loss (standardized): 0.6966763246793111\n",
      "Final epoch: 100, Final loss (standarized): 0.4945601902406079\n",
      "Epoch: 1, Loss (standarized): 2.1582193511915757\n",
      "          Validation Loss (standardized): 1.7909014566048405\n",
      "Epoch: 6, Loss (standarized): 1.4529244564863097\n",
      "          Validation Loss (standardized): 1.5000950797122046\n",
      "Epoch: 11, Loss (standarized): 1.3165520527679417\n",
      "          Validation Loss (standardized): 1.4059450127793103\n",
      "Epoch: 16, Loss (standarized): 1.250389259980145\n",
      "          Validation Loss (standardized): 1.3348339552927724\n",
      "Epoch: 21, Loss (standarized): 1.2035055896144062\n",
      "          Validation Loss (standardized): 1.298991871372259\n",
      "Epoch: 26, Loss (standarized): 1.148603196691559\n",
      "          Validation Loss (standardized): 1.2551821270329993\n",
      "Epoch: 31, Loss (standarized): 1.1022607239316653\n",
      "          Validation Loss (standardized): 1.1808514182164986\n",
      "Epoch: 36, Loss (standarized): 1.0588022045784589\n",
      "          Validation Loss (standardized): 1.147144332822526\n",
      "Epoch: 41, Loss (standarized): 1.0101540526210433\n",
      "          Validation Loss (standardized): 1.1245361883116372\n",
      "Epoch: 46, Loss (standarized): 0.9558636786125976\n",
      "          Validation Loss (standardized): 1.0775391850716747\n",
      "Epoch: 51, Loss (standarized): 0.9057291339509583\n",
      "          Validation Loss (standardized): 1.0506719977499301\n",
      "Epoch: 56, Loss (standarized): 0.8539502160812327\n",
      "          Validation Loss (standardized): 1.0054502898219186\n",
      "Epoch: 61, Loss (standarized): 0.8039850019992235\n",
      "          Validation Loss (standardized): 0.9674681928354177\n",
      "Epoch: 66, Loss (standarized): 0.7578680507493503\n",
      "          Validation Loss (standardized): 0.938669891047587\n",
      "Epoch: 71, Loss (standarized): 0.7134369014749873\n",
      "          Validation Loss (standardized): 0.9026594154584516\n",
      "Epoch: 76, Loss (standarized): 0.6716809212409959\n",
      "          Validation Loss (standardized): 0.8704238784786614\n",
      "Epoch: 81, Loss (standarized): 0.632084393268068\n",
      "          Validation Loss (standardized): 0.8315490151029201\n",
      "Epoch: 86, Loss (standarized): 0.5957251260274421\n",
      "          Validation Loss (standardized): 0.800139222987731\n",
      "Epoch: 91, Loss (standarized): 0.5622763741717204\n",
      "          Validation Loss (standardized): 0.7686911375174098\n",
      "Epoch: 96, Loss (standarized): 0.5312769911278272\n",
      "          Validation Loss (standardized): 0.7410284095298598\n",
      "Final epoch: 100, Final loss (standarized): 0.5077210251057083\n",
      "Epoch: 1, Loss (standarized): 2.5257157027936743\n",
      "          Validation Loss (standardized): 2.367173365702327\n",
      "Epoch: 6, Loss (standarized): 1.517686925646354\n",
      "          Validation Loss (standardized): 1.7612747543172358\n",
      "Epoch: 11, Loss (standarized): 1.3438044363210837\n",
      "          Validation Loss (standardized): 1.5260354120971014\n",
      "Epoch: 16, Loss (standarized): 1.2181804279819335\n",
      "          Validation Loss (standardized): 1.2917701994507724\n",
      "Epoch: 21, Loss (standarized): 1.135538282126366\n",
      "          Validation Loss (standardized): 1.1792479984549444\n",
      "Epoch: 26, Loss (standarized): 1.087091152213283\n",
      "          Validation Loss (standardized): 1.192544480968249\n",
      "Epoch: 31, Loss (standarized): 1.0507825632931476\n",
      "          Validation Loss (standardized): 1.1783592592414958\n",
      "Epoch: 36, Loss (standarized): 1.0149132892449848\n",
      "          Validation Loss (standardized): 1.1436815442761508\n",
      "Epoch: 41, Loss (standarized): 0.9772787432007461\n",
      "          Validation Loss (standardized): 1.0988947501997985\n",
      "Epoch: 46, Loss (standarized): 0.9392816763454528\n",
      "          Validation Loss (standardized): 1.0680421015281931\n",
      "Epoch: 51, Loss (standarized): 0.9001108695845048\n",
      "          Validation Loss (standardized): 1.0334156606892786\n",
      "Epoch: 56, Loss (standarized): 0.8578649980723668\n",
      "          Validation Loss (standardized): 1.005392902882523\n",
      "Epoch: 61, Loss (standarized): 0.8174723575685539\n",
      "          Validation Loss (standardized): 0.9724627480732834\n",
      "Epoch: 66, Loss (standarized): 0.7742801949699083\n",
      "          Validation Loss (standardized): 0.9292326283262148\n",
      "Epoch: 71, Loss (standarized): 0.7298215039404573\n",
      "          Validation Loss (standardized): 0.8944367312742972\n",
      "Epoch: 76, Loss (standarized): 0.6850728229721355\n",
      "          Validation Loss (standardized): 0.8588612337859067\n",
      "Epoch: 81, Loss (standarized): 0.6409313962294203\n",
      "          Validation Loss (standardized): 0.8208443092092094\n",
      "Epoch: 86, Loss (standarized): 0.5972377780232664\n",
      "          Validation Loss (standardized): 0.7774520626777897\n",
      "Epoch: 91, Loss (standarized): 0.554797350008739\n",
      "          Validation Loss (standardized): 0.7421372978162556\n",
      "Epoch: 96, Loss (standarized): 0.5138424636983429\n",
      "          Validation Loss (standardized): 0.7111655354246712\n",
      "Final epoch: 100, Final loss (standarized): 0.48245037341754426\n",
      "Epoch: 1, Loss (standarized): 2.2807247266665738\n",
      "          Validation Loss (standardized): 1.9701631761135652\n",
      "Epoch: 6, Loss (standarized): 1.510575052664209\n",
      "          Validation Loss (standardized): 1.4919740830178965\n",
      "Epoch: 11, Loss (standarized): 1.3264170914617808\n",
      "          Validation Loss (standardized): 1.3751286960367972\n",
      "Epoch: 16, Loss (standarized): 1.228315064975172\n",
      "          Validation Loss (standardized): 1.302289625832957\n",
      "Epoch: 21, Loss (standarized): 1.1704572485008762\n",
      "          Validation Loss (standardized): 1.2363647076709754\n",
      "Epoch: 26, Loss (standarized): 1.122800337703883\n",
      "          Validation Loss (standardized): 1.2097434819554203\n",
      "Epoch: 31, Loss (standarized): 1.0706806351879359\n",
      "          Validation Loss (standardized): 1.1765635661496825\n",
      "Epoch: 36, Loss (standarized): 1.0191171439801805\n",
      "          Validation Loss (standardized): 1.1185265763498915\n",
      "Epoch: 41, Loss (standarized): 0.9665157589261549\n",
      "          Validation Loss (standardized): 1.0845389301345212\n",
      "Epoch: 46, Loss (standarized): 0.916967686196461\n",
      "          Validation Loss (standardized): 1.0337127562179957\n",
      "Epoch: 51, Loss (standarized): 0.8688001886885676\n",
      "          Validation Loss (standardized): 0.986939922960531\n",
      "Epoch: 56, Loss (standarized): 0.820465604529019\n",
      "          Validation Loss (standardized): 0.9543171063007996\n",
      "Epoch: 61, Loss (standarized): 0.773388567205759\n",
      "          Validation Loss (standardized): 0.9025526479017018\n",
      "Epoch: 66, Loss (standarized): 0.7270461114789589\n",
      "          Validation Loss (standardized): 0.8632922729250017\n",
      "Epoch: 71, Loss (standarized): 0.6823397938999386\n",
      "          Validation Loss (standardized): 0.822888318555142\n",
      "Epoch: 76, Loss (standarized): 0.6415321112571963\n",
      "          Validation Loss (standardized): 0.7801506136947541\n",
      "Epoch: 81, Loss (standarized): 0.6050741062770113\n",
      "          Validation Loss (standardized): 0.7495122753847208\n",
      "Epoch: 86, Loss (standarized): 0.5713956533590843\n",
      "          Validation Loss (standardized): 0.7173147921042619\n",
      "Epoch: 91, Loss (standarized): 0.5427522514140948\n",
      "          Validation Loss (standardized): 0.6876024513421889\n",
      "Epoch: 96, Loss (standarized): 0.5181816998966984\n",
      "          Validation Loss (standardized): 0.6637768671444426\n",
      "Final epoch: 100, Final loss (standarized): 0.5012089712509014\n",
      "Epoch: 1, Loss (standarized): 2.108279004075862\n",
      "          Validation Loss (standardized): 1.9100151267583285\n",
      "Epoch: 6, Loss (standarized): 1.4809169794025103\n",
      "          Validation Loss (standardized): 1.3894732862545707\n",
      "Epoch: 11, Loss (standarized): 1.2910665583603427\n",
      "          Validation Loss (standardized): 1.301963399585818\n",
      "Epoch: 16, Loss (standarized): 1.2012619357905054\n",
      "          Validation Loss (standardized): 1.2533319620370902\n",
      "Epoch: 21, Loss (standarized): 1.1246857667398544\n",
      "          Validation Loss (standardized): 1.217386091448073\n",
      "Epoch: 26, Loss (standarized): 1.057883592652594\n",
      "          Validation Loss (standardized): 1.168421277143213\n",
      "Epoch: 31, Loss (standarized): 1.0030608412235236\n",
      "          Validation Loss (standardized): 1.1022578715914655\n",
      "Epoch: 36, Loss (standarized): 0.9399387486094497\n",
      "          Validation Loss (standardized): 1.0418922850574204\n",
      "Epoch: 41, Loss (standarized): 0.8769468262969474\n",
      "          Validation Loss (standardized): 0.9961608905916943\n",
      "Epoch: 46, Loss (standarized): 0.8080425697907859\n",
      "          Validation Loss (standardized): 0.947178814437373\n",
      "Epoch: 51, Loss (standarized): 0.7443157352329404\n",
      "          Validation Loss (standardized): 0.8876190375701201\n",
      "Epoch: 56, Loss (standarized): 0.6808163989976624\n",
      "          Validation Loss (standardized): 0.8366974825882475\n",
      "Epoch: 61, Loss (standarized): 0.6216499511238649\n",
      "          Validation Loss (standardized): 0.7844499499277362\n",
      "Epoch: 66, Loss (standarized): 0.5664902554187795\n",
      "          Validation Loss (standardized): 0.7268289283134179\n",
      "Epoch: 71, Loss (standarized): 0.5173598861433072\n",
      "          Validation Loss (standardized): 0.6824043229451066\n",
      "Epoch: 76, Loss (standarized): 0.4741160363754765\n",
      "          Validation Loss (standardized): 0.6481785143549176\n",
      "Epoch: 81, Loss (standarized): 0.43581816016508557\n",
      "          Validation Loss (standardized): 0.6199465844279496\n",
      "Epoch: 86, Loss (standarized): 0.40150763744896933\n",
      "          Validation Loss (standardized): 0.5911826221973105\n",
      "Epoch: 91, Loss (standarized): 0.3704876925267556\n",
      "          Validation Loss (standardized): 0.5700047505538002\n",
      "Epoch: 96, Loss (standarized): 0.341085704402015\n",
      "          Validation Loss (standardized): 0.5508785967515251\n",
      "Final epoch: 100, Final loss (standarized): 0.3198345566948379\n",
      "Epoch: 1, Loss (standarized): 3.13288340908279\n",
      "          Validation Loss (standardized): 2.7481077962882754\n",
      "Epoch: 6, Loss (standarized): 1.637270751532133\n",
      "          Validation Loss (standardized): 1.57660232767746\n",
      "Epoch: 11, Loss (standarized): 1.3917477419432602\n",
      "          Validation Loss (standardized): 1.3754233945594339\n",
      "Epoch: 16, Loss (standarized): 1.2160207092435449\n",
      "          Validation Loss (standardized): 1.2800707335594939\n",
      "Epoch: 21, Loss (standarized): 1.1695629701312944\n",
      "          Validation Loss (standardized): 1.2639538181079655\n",
      "Epoch: 26, Loss (standarized): 1.1137205801630015\n",
      "          Validation Loss (standardized): 1.1836482086032722\n",
      "Epoch: 31, Loss (standarized): 1.075364470332203\n",
      "          Validation Loss (standardized): 1.1567393678678342\n",
      "Epoch: 36, Loss (standarized): 1.0347284310443887\n",
      "          Validation Loss (standardized): 1.1192737270727888\n",
      "Epoch: 41, Loss (standarized): 0.9877810255542329\n",
      "          Validation Loss (standardized): 1.0696536553571345\n",
      "Epoch: 46, Loss (standarized): 0.9376443918979931\n",
      "          Validation Loss (standardized): 1.0376746280238214\n",
      "Epoch: 51, Loss (standarized): 0.8890828919595322\n",
      "          Validation Loss (standardized): 1.003413302230655\n",
      "Epoch: 56, Loss (standarized): 0.8416671414219138\n",
      "          Validation Loss (standardized): 0.9625310577146529\n",
      "Epoch: 61, Loss (standarized): 0.792822688775834\n",
      "          Validation Loss (standardized): 0.9286154362761578\n",
      "Epoch: 66, Loss (standarized): 0.7443572169813422\n",
      "          Validation Loss (standardized): 0.8859359427627812\n",
      "Epoch: 71, Loss (standarized): 0.6951944664645626\n",
      "          Validation Loss (standardized): 0.8479051566073961\n",
      "Epoch: 76, Loss (standarized): 0.6484186583936163\n",
      "          Validation Loss (standardized): 0.8115511976661638\n",
      "Epoch: 81, Loss (standarized): 0.6018240679597475\n",
      "          Validation Loss (standardized): 0.7655528758377358\n",
      "Epoch: 86, Loss (standarized): 0.5555386786130349\n",
      "          Validation Loss (standardized): 0.7235432335115599\n",
      "Epoch: 91, Loss (standarized): 0.5104751256708099\n",
      "          Validation Loss (standardized): 0.6812273207245487\n",
      "Epoch: 96, Loss (standarized): 0.46680688304218165\n",
      "          Validation Loss (standardized): 0.6356481979434161\n",
      "Final epoch: 100, Final loss (standarized): 0.434079892302518\n",
      "Epoch: 1, Loss (standarized): 2.167167943751683\n",
      "          Validation Loss (standardized): 2.128817267986194\n",
      "Epoch: 6, Loss (standarized): 1.442753041981007\n",
      "          Validation Loss (standardized): 1.4309039333127664\n",
      "Epoch: 11, Loss (standarized): 1.2828451194864356\n",
      "          Validation Loss (standardized): 1.2497266910929639\n",
      "Epoch: 16, Loss (standarized): 1.2270932108380719\n",
      "          Validation Loss (standardized): 1.216901670659691\n",
      "Epoch: 21, Loss (standarized): 1.1725312947205573\n",
      "          Validation Loss (standardized): 1.1781478810596326\n",
      "Epoch: 26, Loss (standarized): 1.1075020843654308\n",
      "          Validation Loss (standardized): 1.1439014914761312\n",
      "Epoch: 31, Loss (standarized): 1.0649964046935718\n",
      "          Validation Loss (standardized): 1.1212066486411523\n",
      "Epoch: 36, Loss (standarized): 1.0311746634972712\n",
      "          Validation Loss (standardized): 1.1054246591390418\n",
      "Epoch: 41, Loss (standarized): 0.9890989788141442\n",
      "          Validation Loss (standardized): 1.0728188408168762\n",
      "Epoch: 46, Loss (standarized): 0.9485210764807612\n",
      "          Validation Loss (standardized): 1.0168719923040588\n",
      "Epoch: 51, Loss (standarized): 0.9072154363269928\n",
      "          Validation Loss (standardized): 0.9776354294548611\n",
      "Epoch: 56, Loss (standarized): 0.8630200916342274\n",
      "          Validation Loss (standardized): 0.9513266447247618\n",
      "Epoch: 61, Loss (standarized): 0.8135996481481537\n",
      "          Validation Loss (standardized): 0.9073608313573875\n",
      "Epoch: 66, Loss (standarized): 0.7568296668350287\n",
      "          Validation Loss (standardized): 0.8619778601202789\n",
      "Epoch: 71, Loss (standarized): 0.6982632979145726\n",
      "          Validation Loss (standardized): 0.8096656782543967\n",
      "Epoch: 76, Loss (standarized): 0.6388757157240739\n",
      "          Validation Loss (standardized): 0.7918402134646785\n",
      "Epoch: 81, Loss (standarized): 0.5833578752225709\n",
      "          Validation Loss (standardized): 0.7609453442416017\n",
      "Epoch: 86, Loss (standarized): 0.5309011971093394\n",
      "          Validation Loss (standardized): 0.726684536879732\n",
      "Epoch: 91, Loss (standarized): 0.4813994255263293\n",
      "          Validation Loss (standardized): 0.699502053842111\n",
      "Epoch: 96, Loss (standarized): 0.43993593180895785\n",
      "          Validation Loss (standardized): 0.6699430950620979\n",
      "Final epoch: 100, Final loss (standarized): 0.40934838129267104\n",
      "Epoch: 1, Loss (standarized): 2.3084965230438024\n",
      "          Validation Loss (standardized): 2.0294423860483906\n",
      "Epoch: 6, Loss (standarized): 1.5891781851675955\n",
      "          Validation Loss (standardized): 1.5450714076224776\n",
      "Epoch: 11, Loss (standarized): 1.4086692257701907\n",
      "          Validation Loss (standardized): 1.3989484129758447\n",
      "Epoch: 16, Loss (standarized): 1.3233996338499616\n",
      "          Validation Loss (standardized): 1.3240517519728776\n",
      "Epoch: 21, Loss (standarized): 1.2418023864611087\n",
      "          Validation Loss (standardized): 1.2442197735771174\n",
      "Epoch: 26, Loss (standarized): 1.1764090653250179\n",
      "          Validation Loss (standardized): 1.1946299099561384\n",
      "Epoch: 31, Loss (standarized): 1.119537812275145\n",
      "          Validation Loss (standardized): 1.181201515337887\n",
      "Epoch: 36, Loss (standarized): 1.066459330173943\n",
      "          Validation Loss (standardized): 1.1517720832452916\n",
      "Epoch: 41, Loss (standarized): 1.016139380815996\n",
      "          Validation Loss (standardized): 1.0953543464387225\n",
      "Epoch: 46, Loss (standarized): 0.9728025681178787\n",
      "          Validation Loss (standardized): 1.056671002625896\n",
      "Epoch: 51, Loss (standarized): 0.9305169741975767\n",
      "          Validation Loss (standardized): 1.0275291978071133\n",
      "Epoch: 56, Loss (standarized): 0.8864594554985357\n",
      "          Validation Loss (standardized): 0.9865072124972439\n",
      "Epoch: 61, Loss (standarized): 0.8411099341177813\n",
      "          Validation Loss (standardized): 0.9402642403678164\n",
      "Epoch: 66, Loss (standarized): 0.7951127651144038\n",
      "          Validation Loss (standardized): 0.9042912874686896\n",
      "Epoch: 71, Loss (standarized): 0.7486328559739003\n",
      "          Validation Loss (standardized): 0.8578376853301907\n",
      "Epoch: 76, Loss (standarized): 0.7008761272239431\n",
      "          Validation Loss (standardized): 0.8156310009941792\n",
      "Epoch: 81, Loss (standarized): 0.6564068930734865\n",
      "          Validation Loss (standardized): 0.7810839538994099\n",
      "Epoch: 86, Loss (standarized): 0.615290900955942\n",
      "          Validation Loss (standardized): 0.7474874371250735\n",
      "Epoch: 91, Loss (standarized): 0.5784771189291839\n",
      "          Validation Loss (standardized): 0.71924276232667\n",
      "Epoch: 96, Loss (standarized): 0.5457892683002131\n",
      "          Validation Loss (standardized): 0.6958948411284848\n",
      "Final epoch: 100, Final loss (standarized): 0.5220670435988668\n",
      "Epoch: 1, Loss (standarized): 2.0767183664021744\n",
      "          Validation Loss (standardized): 1.5181111099361368\n",
      "Epoch: 6, Loss (standarized): 1.4366658882894834\n",
      "          Validation Loss (standardized): 1.3998847145693685\n",
      "Epoch: 11, Loss (standarized): 1.2715772363751905\n",
      "          Validation Loss (standardized): 1.3094354269900728\n",
      "Epoch: 16, Loss (standarized): 1.2046118191750952\n",
      "          Validation Loss (standardized): 1.2453573175238417\n",
      "Epoch: 21, Loss (standarized): 1.1551229037129054\n",
      "          Validation Loss (standardized): 1.2314996349529017\n",
      "Epoch: 26, Loss (standarized): 1.1031304521054892\n",
      "          Validation Loss (standardized): 1.1885201173833626\n",
      "Epoch: 31, Loss (standarized): 1.059585430105497\n",
      "          Validation Loss (standardized): 1.128072299084256\n",
      "Epoch: 36, Loss (standarized): 1.01559512124268\n",
      "          Validation Loss (standardized): 1.0705413865844715\n",
      "Epoch: 41, Loss (standarized): 0.9707739929780763\n",
      "          Validation Loss (standardized): 1.0456207554114407\n",
      "Epoch: 46, Loss (standarized): 0.9230626915949123\n",
      "          Validation Loss (standardized): 1.0197050232864773\n",
      "Epoch: 51, Loss (standarized): 0.8807386043737381\n",
      "          Validation Loss (standardized): 0.9748585153611317\n",
      "Epoch: 56, Loss (standarized): 0.8351363774771872\n",
      "          Validation Loss (standardized): 0.9410955589159147\n",
      "Epoch: 61, Loss (standarized): 0.7843935270640163\n",
      "          Validation Loss (standardized): 0.9059238189527452\n",
      "Epoch: 66, Loss (standarized): 0.730241143957129\n",
      "          Validation Loss (standardized): 0.8563527581466092\n",
      "Epoch: 71, Loss (standarized): 0.6746736507543645\n",
      "          Validation Loss (standardized): 0.8144346903878094\n",
      "Epoch: 76, Loss (standarized): 0.6176194073994355\n",
      "          Validation Loss (standardized): 0.7600224445453769\n",
      "Epoch: 81, Loss (standarized): 0.5597778267324137\n",
      "          Validation Loss (standardized): 0.7130157066983527\n",
      "Epoch: 86, Loss (standarized): 0.5062240598610728\n",
      "          Validation Loss (standardized): 0.671320904468346\n",
      "Epoch: 91, Loss (standarized): 0.45556339460471734\n",
      "          Validation Loss (standardized): 0.6221493187016431\n",
      "Epoch: 96, Loss (standarized): 0.41331410051212475\n",
      "          Validation Loss (standardized): 0.5877798636419334\n",
      "Final epoch: 100, Final loss (standarized): 0.3843554664230537\n",
      "Epoch: 1, Loss (standarized): 2.3928543480560944\n",
      "          Validation Loss (standardized): 1.8746976141836302\n",
      "Epoch: 6, Loss (standarized): 1.5446229329232033\n",
      "          Validation Loss (standardized): 1.5027482288602805\n",
      "Epoch: 11, Loss (standarized): 1.3807211241175184\n",
      "          Validation Loss (standardized): 1.4644974483811097\n",
      "Epoch: 16, Loss (standarized): 1.2577264141569269\n",
      "          Validation Loss (standardized): 1.3331489816954867\n",
      "Epoch: 21, Loss (standarized): 1.2023233462883705\n",
      "          Validation Loss (standardized): 1.2303361333864835\n",
      "Epoch: 26, Loss (standarized): 1.1446254202191037\n",
      "          Validation Loss (standardized): 1.1778289374427442\n",
      "Epoch: 31, Loss (standarized): 1.0930344486386199\n",
      "          Validation Loss (standardized): 1.1708306080154838\n",
      "Epoch: 36, Loss (standarized): 1.0421722709969725\n",
      "          Validation Loss (standardized): 1.12055483008502\n",
      "Epoch: 41, Loss (standarized): 0.9945140486561477\n",
      "          Validation Loss (standardized): 1.0841265628025716\n",
      "Epoch: 46, Loss (standarized): 0.9466880697493358\n",
      "          Validation Loss (standardized): 1.066819854630281\n",
      "Epoch: 51, Loss (standarized): 0.896726685937161\n",
      "          Validation Loss (standardized): 1.0231509285188092\n",
      "Epoch: 56, Loss (standarized): 0.845719858817462\n",
      "          Validation Loss (standardized): 0.9957197364322051\n",
      "Epoch: 61, Loss (standarized): 0.7943375202950043\n",
      "          Validation Loss (standardized): 0.963883151277455\n",
      "Epoch: 66, Loss (standarized): 0.7437374228171746\n",
      "          Validation Loss (standardized): 0.9272285431253281\n",
      "Epoch: 71, Loss (standarized): 0.6948354738237839\n",
      "          Validation Loss (standardized): 0.8985130697841526\n",
      "Epoch: 76, Loss (standarized): 0.646313880884197\n",
      "          Validation Loss (standardized): 0.8565151605655908\n",
      "Epoch: 81, Loss (standarized): 0.5965523354036041\n",
      "          Validation Loss (standardized): 0.812865418661791\n",
      "Epoch: 86, Loss (standarized): 0.5510075265122493\n",
      "          Validation Loss (standardized): 0.7777254049051809\n",
      "Epoch: 91, Loss (standarized): 0.5088178095267747\n",
      "          Validation Loss (standardized): 0.7408708319383561\n",
      "Epoch: 96, Loss (standarized): 0.47108828241615813\n",
      "          Validation Loss (standardized): 0.7068525383366038\n",
      "Final epoch: 100, Final loss (standarized): 0.4443702857001564\n",
      "Epoch: 1, Loss (standarized): 2.237174471583933\n",
      "          Validation Loss (standardized): 1.9827586071520937\n",
      "Epoch: 6, Loss (standarized): 1.4761717421198695\n",
      "          Validation Loss (standardized): 1.3918402310339204\n",
      "Epoch: 11, Loss (standarized): 1.3154458427643498\n",
      "          Validation Loss (standardized): 1.3107967768204243\n",
      "Epoch: 16, Loss (standarized): 1.2541554334653833\n",
      "          Validation Loss (standardized): 1.3036266356648383\n",
      "Epoch: 21, Loss (standarized): 1.2190991119243693\n",
      "          Validation Loss (standardized): 1.285163481013358\n",
      "Epoch: 26, Loss (standarized): 1.1958860175813841\n",
      "          Validation Loss (standardized): 1.2353762554453624\n",
      "Epoch: 31, Loss (standarized): 1.1759395752877382\n",
      "          Validation Loss (standardized): 1.2066216393788503\n",
      "Epoch: 36, Loss (standarized): 1.150474903937777\n",
      "          Validation Loss (standardized): 1.2158715987466149\n",
      "Epoch: 41, Loss (standarized): 1.1326929172761107\n",
      "          Validation Loss (standardized): 1.2141539732157645\n",
      "Epoch: 46, Loss (standarized): 1.1139495706291778\n",
      "          Validation Loss (standardized): 1.1840864065677974\n",
      "Epoch: 51, Loss (standarized): 1.0972630808628268\n",
      "          Validation Loss (standardized): 1.1764841276808664\n",
      "Epoch: 56, Loss (standarized): 1.0797686269569666\n",
      "          Validation Loss (standardized): 1.1621773230402412\n",
      "Epoch: 61, Loss (standarized): 1.0595243010493394\n",
      "          Validation Loss (standardized): 1.1324538792073422\n",
      "Epoch: 66, Loss (standarized): 1.0379414592823597\n",
      "          Validation Loss (standardized): 1.1214112640219223\n",
      "Epoch: 71, Loss (standarized): 1.0161029866414817\n",
      "          Validation Loss (standardized): 1.103882164728885\n",
      "Epoch: 76, Loss (standarized): 0.9936412242888443\n",
      "          Validation Loss (standardized): 1.0834392807192048\n",
      "Epoch: 81, Loss (standarized): 0.9710786651350227\n",
      "          Validation Loss (standardized): 1.0672830833797107\n",
      "Epoch: 86, Loss (standarized): 0.9480225725732991\n",
      "          Validation Loss (standardized): 1.0450952423327287\n",
      "Epoch: 91, Loss (standarized): 0.924605955222807\n",
      "          Validation Loss (standardized): 1.0250287184328601\n",
      "Epoch: 96, Loss (standarized): 0.8996043763289195\n",
      "          Validation Loss (standardized): 1.0058379915032736\n",
      "Final epoch: 100, Final loss (standarized): 0.8793094252072258\n",
      "Epoch: 1, Loss (standarized): 2.8907054399689787\n",
      "          Validation Loss (standardized): 2.9985170022789007\n",
      "Epoch: 6, Loss (standarized): 1.8239635804151624\n",
      "          Validation Loss (standardized): 1.7950976202063917\n",
      "Epoch: 11, Loss (standarized): 1.4816842445833538\n",
      "          Validation Loss (standardized): 1.4486228944176809\n",
      "Epoch: 16, Loss (standarized): 1.3546530086019875\n",
      "          Validation Loss (standardized): 1.336041395803259\n",
      "Epoch: 21, Loss (standarized): 1.2841105288694123\n",
      "          Validation Loss (standardized): 1.3103012800563287\n",
      "Epoch: 26, Loss (standarized): 1.233443654603697\n",
      "          Validation Loss (standardized): 1.2929729812583355\n",
      "Epoch: 31, Loss (standarized): 1.1948700275080253\n",
      "          Validation Loss (standardized): 1.2597186985802877\n",
      "Epoch: 36, Loss (standarized): 1.1716667961351626\n",
      "          Validation Loss (standardized): 1.2208206210251975\n",
      "Epoch: 41, Loss (standarized): 1.1539666281210283\n",
      "          Validation Loss (standardized): 1.1936161720357459\n",
      "Epoch: 46, Loss (standarized): 1.1395167565276132\n",
      "          Validation Loss (standardized): 1.1901065335482655\n",
      "Epoch: 51, Loss (standarized): 1.1262980678340475\n",
      "          Validation Loss (standardized): 1.1934171967500173\n",
      "Epoch: 56, Loss (standarized): 1.116334876408778\n",
      "          Validation Loss (standardized): 1.1871010988081165\n",
      "Epoch: 61, Loss (standarized): 1.1096499679734242\n",
      "          Validation Loss (standardized): 1.173654053915114\n",
      "Epoch: 66, Loss (standarized): 1.1027041602241823\n",
      "          Validation Loss (standardized): 1.1627122177142752\n",
      "Epoch: 71, Loss (standarized): 1.0946295718064252\n",
      "          Validation Loss (standardized): 1.1580795593259854\n",
      "Epoch: 76, Loss (standarized): 1.0870926079831529\n",
      "          Validation Loss (standardized): 1.157718557697402\n",
      "Epoch: 81, Loss (standarized): 1.080264266032443\n",
      "          Validation Loss (standardized): 1.1501318835189525\n",
      "Epoch: 86, Loss (standarized): 1.0735884507333864\n",
      "          Validation Loss (standardized): 1.1432287647100055\n",
      "Epoch: 91, Loss (standarized): 1.0669028474674898\n",
      "          Validation Loss (standardized): 1.134256972993592\n",
      "Epoch: 96, Loss (standarized): 1.059649729646269\n",
      "          Validation Loss (standardized): 1.1267718934410897\n",
      "Final epoch: 100, Final loss (standarized): 1.054024728582026\n",
      "Epoch: 1, Loss (standarized): 2.5402495768849573\n",
      "          Validation Loss (standardized): 1.8095688877422977\n",
      "Epoch: 6, Loss (standarized): 1.689907235599698\n",
      "          Validation Loss (standardized): 1.4990262070263283\n",
      "Epoch: 11, Loss (standarized): 1.3902075816566042\n",
      "          Validation Loss (standardized): 1.473429930803602\n",
      "Epoch: 16, Loss (standarized): 1.3002370170772104\n",
      "          Validation Loss (standardized): 1.4130867927359412\n",
      "Epoch: 21, Loss (standarized): 1.2126164062133824\n",
      "          Validation Loss (standardized): 1.3013698691094868\n",
      "Epoch: 26, Loss (standarized): 1.1759699573082671\n",
      "          Validation Loss (standardized): 1.2378023286652304\n",
      "Epoch: 31, Loss (standarized): 1.14736541820337\n",
      "          Validation Loss (standardized): 1.193676824476303\n",
      "Epoch: 36, Loss (standarized): 1.122337227976656\n",
      "          Validation Loss (standardized): 1.185947338983935\n",
      "Epoch: 41, Loss (standarized): 1.109022194772941\n",
      "          Validation Loss (standardized): 1.1805848920785031\n",
      "Epoch: 46, Loss (standarized): 1.0921054150015868\n",
      "          Validation Loss (standardized): 1.160617064366524\n",
      "Epoch: 51, Loss (standarized): 1.075052192151887\n",
      "          Validation Loss (standardized): 1.1409510469174675\n",
      "Epoch: 56, Loss (standarized): 1.0604875232961513\n",
      "          Validation Loss (standardized): 1.130978657560979\n",
      "Epoch: 61, Loss (standarized): 1.046934213339196\n",
      "          Validation Loss (standardized): 1.1262701854988213\n",
      "Epoch: 66, Loss (standarized): 1.0341047418539404\n",
      "          Validation Loss (standardized): 1.1161117696336065\n",
      "Epoch: 71, Loss (standarized): 1.020796428593071\n",
      "          Validation Loss (standardized): 1.103310803389831\n",
      "Epoch: 76, Loss (standarized): 1.0066536634487946\n",
      "          Validation Loss (standardized): 1.0913274532185786\n",
      "Epoch: 81, Loss (standarized): 0.9914198410689585\n",
      "          Validation Loss (standardized): 1.0764662010911203\n",
      "Epoch: 86, Loss (standarized): 0.9754637683795019\n",
      "          Validation Loss (standardized): 1.0605723022915208\n",
      "Epoch: 91, Loss (standarized): 0.9582288220113321\n",
      "          Validation Loss (standardized): 1.0446189115673181\n",
      "Epoch: 96, Loss (standarized): 0.9397525748850645\n",
      "          Validation Loss (standardized): 1.0314920192967054\n",
      "Final epoch: 100, Final loss (standarized): 0.9241956401415243\n",
      "Epoch: 1, Loss (standarized): 2.0255602381284445\n",
      "          Validation Loss (standardized): 1.876283075796719\n",
      "Epoch: 6, Loss (standarized): 1.461503213120293\n",
      "          Validation Loss (standardized): 1.4830649259909852\n",
      "Epoch: 11, Loss (standarized): 1.3690683774004686\n",
      "          Validation Loss (standardized): 1.410545138089263\n",
      "Epoch: 16, Loss (standarized): 1.2947411782346003\n",
      "          Validation Loss (standardized): 1.2859005047243304\n",
      "Epoch: 21, Loss (standarized): 1.2524022295880126\n",
      "          Validation Loss (standardized): 1.234671179371222\n",
      "Epoch: 26, Loss (standarized): 1.2129619780829486\n",
      "          Validation Loss (standardized): 1.2253083139447885\n",
      "Epoch: 31, Loss (standarized): 1.1812945425023702\n",
      "          Validation Loss (standardized): 1.208519633732722\n",
      "Epoch: 36, Loss (standarized): 1.1501393157599435\n",
      "          Validation Loss (standardized): 1.1742912118330808\n",
      "Epoch: 41, Loss (standarized): 1.122848062791164\n",
      "          Validation Loss (standardized): 1.1502828699347083\n",
      "Epoch: 46, Loss (standarized): 1.0980250796152855\n",
      "          Validation Loss (standardized): 1.1364793008262446\n",
      "Epoch: 51, Loss (standarized): 1.0725419193051757\n",
      "          Validation Loss (standardized): 1.1181325363248547\n",
      "Epoch: 56, Loss (standarized): 1.0475694215485405\n",
      "          Validation Loss (standardized): 1.1006140525992016\n",
      "Epoch: 61, Loss (standarized): 1.0236353606442816\n",
      "          Validation Loss (standardized): 1.0877230465536405\n",
      "Epoch: 66, Loss (standarized): 0.9978672298739761\n",
      "          Validation Loss (standardized): 1.0591941975364376\n",
      "Epoch: 71, Loss (standarized): 0.9718805652175591\n",
      "          Validation Loss (standardized): 1.0394063039946417\n",
      "Epoch: 76, Loss (standarized): 0.9457201028326415\n",
      "          Validation Loss (standardized): 1.0230714157714111\n",
      "Epoch: 81, Loss (standarized): 0.9198537442835348\n",
      "          Validation Loss (standardized): 1.0025570506665755\n",
      "Epoch: 86, Loss (standarized): 0.8949502792771723\n",
      "          Validation Loss (standardized): 0.9821912267111588\n",
      "Epoch: 91, Loss (standarized): 0.8704200359669136\n",
      "          Validation Loss (standardized): 0.9637952632533351\n",
      "Epoch: 96, Loss (standarized): 0.8452172948711106\n",
      "          Validation Loss (standardized): 0.9412382858399951\n",
      "Final epoch: 100, Final loss (standarized): 0.8252954796912308\n",
      "Epoch: 1, Loss (standarized): 2.0180644810414248\n",
      "          Validation Loss (standardized): 1.6351051744181628\n",
      "Epoch: 6, Loss (standarized): 1.399880547097494\n",
      "          Validation Loss (standardized): 1.3470318222378834\n",
      "Epoch: 11, Loss (standarized): 1.268930112189905\n",
      "          Validation Loss (standardized): 1.2792717895815717\n",
      "Epoch: 16, Loss (standarized): 1.1967771309324626\n",
      "          Validation Loss (standardized): 1.2138377880336615\n",
      "Epoch: 21, Loss (standarized): 1.1325533499040459\n",
      "          Validation Loss (standardized): 1.1396438353062468\n",
      "Epoch: 26, Loss (standarized): 1.0840389423964114\n",
      "          Validation Loss (standardized): 1.1194417739007632\n",
      "Epoch: 31, Loss (standarized): 1.0343262535913404\n",
      "          Validation Loss (standardized): 1.1087801796283308\n",
      "Epoch: 36, Loss (standarized): 0.9849961781696525\n",
      "          Validation Loss (standardized): 1.0689891201043784\n",
      "Epoch: 41, Loss (standarized): 0.9335901381744435\n",
      "          Validation Loss (standardized): 1.0342945045226657\n",
      "Epoch: 46, Loss (standarized): 0.8788857003045065\n",
      "          Validation Loss (standardized): 0.9819164660172232\n",
      "Epoch: 51, Loss (standarized): 0.8196358285033127\n",
      "          Validation Loss (standardized): 0.9308233812909369\n",
      "Epoch: 56, Loss (standarized): 0.7601250536200551\n",
      "          Validation Loss (standardized): 0.8860799046845641\n",
      "Epoch: 61, Loss (standarized): 0.6998983546778522\n",
      "          Validation Loss (standardized): 0.833659837395581\n",
      "Epoch: 66, Loss (standarized): 0.6413865383897379\n",
      "          Validation Loss (standardized): 0.7833059268632097\n",
      "Epoch: 71, Loss (standarized): 0.5867944020917024\n",
      "          Validation Loss (standardized): 0.7319530255450107\n",
      "Epoch: 76, Loss (standarized): 0.5343415720935275\n",
      "          Validation Loss (standardized): 0.6870286819234912\n",
      "Epoch: 81, Loss (standarized): 0.48565892423906865\n",
      "          Validation Loss (standardized): 0.6496196350169577\n",
      "Epoch: 86, Loss (standarized): 0.44061975683658583\n",
      "          Validation Loss (standardized): 0.6048533437240502\n",
      "Epoch: 91, Loss (standarized): 0.4001145347713393\n",
      "          Validation Loss (standardized): 0.5696515054681691\n",
      "Epoch: 96, Loss (standarized): 0.364902235115864\n",
      "          Validation Loss (standardized): 0.5436835347953708\n",
      "Final epoch: 100, Final loss (standarized): 0.3406257718042315\n",
      "Epoch: 1, Loss (standarized): 1.86678807440184\n",
      "          Validation Loss (standardized): 1.6162483329518778\n",
      "Epoch: 6, Loss (standarized): 1.3779034987882286\n",
      "          Validation Loss (standardized): 1.3183069381416956\n",
      "Epoch: 11, Loss (standarized): 1.2758030279919554\n",
      "          Validation Loss (standardized): 1.2896112935213186\n",
      "Epoch: 16, Loss (standarized): 1.2146327561478203\n",
      "          Validation Loss (standardized): 1.2592269179798006\n",
      "Epoch: 21, Loss (standarized): 1.1612827271894455\n",
      "          Validation Loss (standardized): 1.215370317544223\n",
      "Epoch: 26, Loss (standarized): 1.1216780852781698\n",
      "          Validation Loss (standardized): 1.1713697341639397\n",
      "Epoch: 31, Loss (standarized): 1.0850699880629742\n",
      "          Validation Loss (standardized): 1.1349780581678346\n",
      "Epoch: 36, Loss (standarized): 1.0537347139181255\n",
      "          Validation Loss (standardized): 1.1163707432542924\n",
      "Epoch: 41, Loss (standarized): 1.0250163844249178\n",
      "          Validation Loss (standardized): 1.1007639039298842\n",
      "Epoch: 46, Loss (standarized): 0.9964551525470459\n",
      "          Validation Loss (standardized): 1.0749930353947457\n",
      "Epoch: 51, Loss (standarized): 0.9663223978486727\n",
      "          Validation Loss (standardized): 1.046202532012872\n",
      "Epoch: 56, Loss (standarized): 0.9324828652665171\n",
      "          Validation Loss (standardized): 1.0178600224031915\n",
      "Epoch: 61, Loss (standarized): 0.8971190886553349\n",
      "          Validation Loss (standardized): 0.9913700582458628\n",
      "Epoch: 66, Loss (standarized): 0.8596438990313466\n",
      "          Validation Loss (standardized): 0.9616416340546061\n",
      "Epoch: 71, Loss (standarized): 0.8189579812070434\n",
      "          Validation Loss (standardized): 0.9289577931755331\n",
      "Epoch: 76, Loss (standarized): 0.7768177009015167\n",
      "          Validation Loss (standardized): 0.8930544168213275\n",
      "Epoch: 81, Loss (standarized): 0.7354061444068124\n",
      "          Validation Loss (standardized): 0.8582093725267452\n",
      "Epoch: 86, Loss (standarized): 0.6948942431677119\n",
      "          Validation Loss (standardized): 0.8192077609072268\n",
      "Epoch: 91, Loss (standarized): 0.6560398292358007\n",
      "          Validation Loss (standardized): 0.7870979865573605\n",
      "Epoch: 96, Loss (standarized): 0.6207209376639691\n",
      "          Validation Loss (standardized): 0.754207065462094\n",
      "Final epoch: 100, Final loss (standarized): 0.5955027213639652\n",
      "Epoch: 1, Loss (standarized): 2.0428662284296943\n",
      "          Validation Loss (standardized): 2.0761610330916613\n",
      "Epoch: 6, Loss (standarized): 1.3975143733977275\n",
      "          Validation Loss (standardized): 1.4426106419172533\n",
      "Epoch: 11, Loss (standarized): 1.2480763699166366\n",
      "          Validation Loss (standardized): 1.230458621937542\n",
      "Epoch: 16, Loss (standarized): 1.1812590579388784\n",
      "          Validation Loss (standardized): 1.1829035965004313\n",
      "Epoch: 21, Loss (standarized): 1.1255565837050339\n",
      "          Validation Loss (standardized): 1.1473963635952158\n",
      "Epoch: 26, Loss (standarized): 1.0802726838744843\n",
      "          Validation Loss (standardized): 1.135053099380958\n",
      "Epoch: 31, Loss (standarized): 1.0387621706940593\n",
      "          Validation Loss (standardized): 1.0918017289437716\n",
      "Epoch: 36, Loss (standarized): 1.00218305974421\n",
      "          Validation Loss (standardized): 1.0609746964868951\n",
      "Epoch: 41, Loss (standarized): 0.9662371565962071\n",
      "          Validation Loss (standardized): 1.0428196348536165\n",
      "Epoch: 46, Loss (standarized): 0.9304011092813974\n",
      "          Validation Loss (standardized): 1.0240405797736158\n",
      "Epoch: 51, Loss (standarized): 0.891514126833203\n",
      "          Validation Loss (standardized): 0.9853250954477051\n",
      "Epoch: 56, Loss (standarized): 0.851229219586291\n",
      "          Validation Loss (standardized): 0.965748042261533\n",
      "Epoch: 61, Loss (standarized): 0.8082174617373041\n",
      "          Validation Loss (standardized): 0.9314406563104535\n",
      "Epoch: 66, Loss (standarized): 0.7635115124999174\n",
      "          Validation Loss (standardized): 0.8920419314918904\n",
      "Epoch: 71, Loss (standarized): 0.7179148718825183\n",
      "          Validation Loss (standardized): 0.8584432281666275\n",
      "Epoch: 76, Loss (standarized): 0.670578931560373\n",
      "          Validation Loss (standardized): 0.8173911490573433\n",
      "Epoch: 81, Loss (standarized): 0.6219792226659538\n",
      "          Validation Loss (standardized): 0.77440143478966\n",
      "Epoch: 86, Loss (standarized): 0.5749460656334221\n",
      "          Validation Loss (standardized): 0.7320788231022911\n",
      "Epoch: 91, Loss (standarized): 0.5304210074094772\n",
      "          Validation Loss (standardized): 0.6904717040641827\n",
      "Epoch: 96, Loss (standarized): 0.4889760257401515\n",
      "          Validation Loss (standardized): 0.6478895582386142\n",
      "Final epoch: 100, Final loss (standarized): 0.4587287761485351\n",
      "Epoch: 1, Loss (standarized): 2.257937915429465\n",
      "          Validation Loss (standardized): 2.3597677826801617\n",
      "Epoch: 6, Loss (standarized): 1.3907992986444817\n",
      "          Validation Loss (standardized): 1.4013423855786415\n",
      "Epoch: 11, Loss (standarized): 1.250526554591286\n",
      "          Validation Loss (standardized): 1.1897198429462756\n",
      "Epoch: 16, Loss (standarized): 1.1966719677755615\n",
      "          Validation Loss (standardized): 1.1536956162753902\n",
      "Epoch: 21, Loss (standarized): 1.1327507771556298\n",
      "          Validation Loss (standardized): 1.1837165950054804\n",
      "Epoch: 26, Loss (standarized): 1.0987026128682778\n",
      "          Validation Loss (standardized): 1.2088375211576767\n",
      "Epoch: 31, Loss (standarized): 1.0614265482555978\n",
      "          Validation Loss (standardized): 1.164029726029573\n",
      "Epoch: 36, Loss (standarized): 1.0197455906442165\n",
      "          Validation Loss (standardized): 1.0906889356056404\n",
      "Epoch: 41, Loss (standarized): 0.9859235384100102\n",
      "          Validation Loss (standardized): 1.0628459939160722\n",
      "Epoch: 46, Loss (standarized): 0.9488812518403009\n",
      "          Validation Loss (standardized): 1.063874295330733\n",
      "Epoch: 51, Loss (standarized): 0.9107152996733712\n",
      "          Validation Loss (standardized): 1.0308535232586205\n",
      "Epoch: 56, Loss (standarized): 0.8686015092618868\n",
      "          Validation Loss (standardized): 0.985239676111238\n",
      "Epoch: 61, Loss (standarized): 0.8249441954749623\n",
      "          Validation Loss (standardized): 0.9520961591404125\n",
      "Epoch: 66, Loss (standarized): 0.780825327033414\n",
      "          Validation Loss (standardized): 0.9248022709852187\n",
      "Epoch: 71, Loss (standarized): 0.7378029304689064\n",
      "          Validation Loss (standardized): 0.8822305198939311\n",
      "Epoch: 76, Loss (standarized): 0.6954315449300963\n",
      "          Validation Loss (standardized): 0.83536278737703\n",
      "Epoch: 81, Loss (standarized): 0.6549492978086152\n",
      "          Validation Loss (standardized): 0.8056089915057824\n",
      "Epoch: 86, Loss (standarized): 0.6159207134633842\n",
      "          Validation Loss (standardized): 0.7666768368962807\n",
      "Epoch: 91, Loss (standarized): 0.5794961037754723\n",
      "          Validation Loss (standardized): 0.72940543638738\n",
      "Epoch: 96, Loss (standarized): 0.5448707792843158\n",
      "          Validation Loss (standardized): 0.699125537113785\n",
      "Final epoch: 100, Final loss (standarized): 0.5178957582460175\n",
      "Epoch: 1, Loss (standarized): 3.0480959023817245\n",
      "          Validation Loss (standardized): 2.493809067897738\n",
      "Epoch: 6, Loss (standarized): 1.6716967793915642\n",
      "          Validation Loss (standardized): 1.5160727063213328\n",
      "Epoch: 11, Loss (standarized): 1.3781062350777469\n",
      "          Validation Loss (standardized): 1.3521920759417203\n",
      "Epoch: 16, Loss (standarized): 1.3048526230284123\n",
      "          Validation Loss (standardized): 1.2736161848102148\n",
      "Epoch: 21, Loss (standarized): 1.236179994259201\n",
      "          Validation Loss (standardized): 1.2282669712080738\n",
      "Epoch: 26, Loss (standarized): 1.1802453460453597\n",
      "          Validation Loss (standardized): 1.1997672336889977\n",
      "Epoch: 31, Loss (standarized): 1.1294310169748416\n",
      "          Validation Loss (standardized): 1.185121685798754\n",
      "Epoch: 36, Loss (standarized): 1.0856605711773717\n",
      "          Validation Loss (standardized): 1.1582353975231017\n",
      "Epoch: 41, Loss (standarized): 1.041545440617829\n",
      "          Validation Loss (standardized): 1.1193935946227824\n",
      "Epoch: 46, Loss (standarized): 0.9975908089891433\n",
      "          Validation Loss (standardized): 1.0809180948602721\n",
      "Epoch: 51, Loss (standarized): 0.9541099953140469\n",
      "          Validation Loss (standardized): 1.0487213907180777\n",
      "Epoch: 56, Loss (standarized): 0.9113909353747447\n",
      "          Validation Loss (standardized): 1.031286335210205\n",
      "Epoch: 61, Loss (standarized): 0.8701922700230691\n",
      "          Validation Loss (standardized): 1.004156330862368\n",
      "Epoch: 66, Loss (standarized): 0.8293877506523493\n",
      "          Validation Loss (standardized): 0.9738189804216532\n",
      "Epoch: 71, Loss (standarized): 0.7874872190371874\n",
      "          Validation Loss (standardized): 0.9380028283967344\n",
      "Epoch: 76, Loss (standarized): 0.7485457654275135\n",
      "          Validation Loss (standardized): 0.9082276071303369\n",
      "Epoch: 81, Loss (standarized): 0.7075970419619381\n",
      "          Validation Loss (standardized): 0.8732735733768734\n",
      "Epoch: 86, Loss (standarized): 0.6681629698063862\n",
      "          Validation Loss (standardized): 0.8397097711891889\n",
      "Epoch: 91, Loss (standarized): 0.6302810419854211\n",
      "          Validation Loss (standardized): 0.8062793481623824\n",
      "Epoch: 96, Loss (standarized): 0.5940154341620054\n",
      "          Validation Loss (standardized): 0.7736698667183867\n",
      "Final epoch: 100, Final loss (standarized): 0.563138086387014\n",
      "Epoch: 1, Loss (standarized): 1.7558402512413047\n",
      "          Validation Loss (standardized): 1.482565031215604\n",
      "Epoch: 6, Loss (standarized): 1.3535900200540545\n",
      "          Validation Loss (standardized): 1.407862902520674\n",
      "Epoch: 11, Loss (standarized): 1.2629257337849409\n",
      "          Validation Loss (standardized): 1.3684894234705307\n",
      "Epoch: 16, Loss (standarized): 1.1925321113716227\n",
      "          Validation Loss (standardized): 1.2866460282553602\n",
      "Epoch: 21, Loss (standarized): 1.1381133333668962\n",
      "          Validation Loss (standardized): 1.209932265727851\n",
      "Epoch: 26, Loss (standarized): 1.0924358457748837\n",
      "          Validation Loss (standardized): 1.1632561193042983\n",
      "Epoch: 31, Loss (standarized): 1.0464866453736186\n",
      "          Validation Loss (standardized): 1.1364657116399763\n",
      "Epoch: 36, Loss (standarized): 0.9996475245500791\n",
      "          Validation Loss (standardized): 1.0905849341013003\n",
      "Epoch: 41, Loss (standarized): 0.9506652986087283\n",
      "          Validation Loss (standardized): 1.0500812258813714\n",
      "Epoch: 46, Loss (standarized): 0.8970997172432408\n",
      "          Validation Loss (standardized): 1.000229640465761\n",
      "Epoch: 51, Loss (standarized): 0.8364141125662372\n",
      "          Validation Loss (standardized): 0.9392948748800488\n",
      "Epoch: 56, Loss (standarized): 0.7730044362983236\n",
      "          Validation Loss (standardized): 0.8763978169846376\n",
      "Epoch: 61, Loss (standarized): 0.7151899361792562\n",
      "          Validation Loss (standardized): 0.824362804415648\n",
      "Epoch: 66, Loss (standarized): 0.6619296010775519\n",
      "          Validation Loss (standardized): 0.7822476722644667\n",
      "Epoch: 71, Loss (standarized): 0.6128180018427829\n",
      "          Validation Loss (standardized): 0.7347861836683715\n",
      "Epoch: 76, Loss (standarized): 0.5696509369827156\n",
      "          Validation Loss (standardized): 0.6972924037948157\n",
      "Epoch: 81, Loss (standarized): 0.5334135655457604\n",
      "          Validation Loss (standardized): 0.6676477961288056\n",
      "Epoch: 86, Loss (standarized): 0.503587313567683\n",
      "          Validation Loss (standardized): 0.6406802013604305\n",
      "Epoch: 91, Loss (standarized): 0.47919135169551924\n",
      "          Validation Loss (standardized): 0.6221154129263283\n",
      "Epoch: 96, Loss (standarized): 0.45905647613431083\n",
      "          Validation Loss (standardized): 0.6057943270919488\n",
      "Final epoch: 100, Final loss (standarized): 0.4446612978057971\n",
      "Epoch: 1, Loss (standarized): 2.318296996687202\n",
      "          Validation Loss (standardized): 2.0757685021107934\n",
      "Epoch: 6, Loss (standarized): 1.528965024755338\n",
      "          Validation Loss (standardized): 1.3445643650698793\n",
      "Epoch: 11, Loss (standarized): 1.3031182700219057\n",
      "          Validation Loss (standardized): 1.2596308261238929\n",
      "Epoch: 16, Loss (standarized): 1.2178463704274467\n",
      "          Validation Loss (standardized): 1.3157616879955454\n",
      "Epoch: 21, Loss (standarized): 1.1560249671334752\n",
      "          Validation Loss (standardized): 1.2441722126232355\n",
      "Epoch: 26, Loss (standarized): 1.1060967124193033\n",
      "          Validation Loss (standardized): 1.1851157630669606\n",
      "Epoch: 31, Loss (standarized): 1.060842283318833\n",
      "          Validation Loss (standardized): 1.1702741732897397\n",
      "Epoch: 36, Loss (standarized): 1.0199622557114376\n",
      "          Validation Loss (standardized): 1.1344583142369702\n",
      "Epoch: 41, Loss (standarized): 0.9729239576843576\n",
      "          Validation Loss (standardized): 1.0871574746337545\n",
      "Epoch: 46, Loss (standarized): 0.9220553719641259\n",
      "          Validation Loss (standardized): 1.0479703338013289\n",
      "Epoch: 51, Loss (standarized): 0.8709858153465384\n",
      "          Validation Loss (standardized): 1.0029527371294924\n",
      "Epoch: 56, Loss (standarized): 0.8180583318269058\n",
      "          Validation Loss (standardized): 0.9604686981843537\n",
      "Epoch: 61, Loss (standarized): 0.7643573510639528\n",
      "          Validation Loss (standardized): 0.9094166767100366\n",
      "Epoch: 66, Loss (standarized): 0.7092928518712366\n",
      "          Validation Loss (standardized): 0.8708982877074388\n",
      "Epoch: 71, Loss (standarized): 0.6536524174484587\n",
      "          Validation Loss (standardized): 0.8127648714451211\n",
      "Epoch: 76, Loss (standarized): 0.5988383038225181\n",
      "          Validation Loss (standardized): 0.7647848357748424\n",
      "Epoch: 81, Loss (standarized): 0.5469552258721664\n",
      "          Validation Loss (standardized): 0.7170344171430081\n",
      "Epoch: 86, Loss (standarized): 0.500764838623601\n",
      "          Validation Loss (standardized): 0.6705024660716427\n",
      "Epoch: 91, Loss (standarized): 0.4610585076545398\n",
      "          Validation Loss (standardized): 0.6353609864127697\n",
      "Epoch: 96, Loss (standarized): 0.4254102426948795\n",
      "          Validation Loss (standardized): 0.6015296597393958\n",
      "Final epoch: 100, Final loss (standarized): 0.40052846261870967\n",
      "Epoch: 1, Loss (standarized): 1.7706998404775722\n",
      "          Validation Loss (standardized): 1.5188344861511227\n",
      "Epoch: 6, Loss (standarized): 1.444997247880375\n",
      "          Validation Loss (standardized): 1.4303826629200136\n",
      "Epoch: 11, Loss (standarized): 1.310602641710089\n",
      "          Validation Loss (standardized): 1.3457539752838212\n",
      "Epoch: 16, Loss (standarized): 1.2146726669821617\n",
      "          Validation Loss (standardized): 1.2603755854201577\n",
      "Epoch: 21, Loss (standarized): 1.1474422295984608\n",
      "          Validation Loss (standardized): 1.2300120922291886\n",
      "Epoch: 26, Loss (standarized): 1.0817434705865\n",
      "          Validation Loss (standardized): 1.1754466418868332\n",
      "Epoch: 31, Loss (standarized): 1.0184302893954966\n",
      "          Validation Loss (standardized): 1.1335645797244038\n",
      "Epoch: 36, Loss (standarized): 0.9456889924771125\n",
      "          Validation Loss (standardized): 1.0812942043727762\n",
      "Epoch: 41, Loss (standarized): 0.8614108906139755\n",
      "          Validation Loss (standardized): 1.0123164477186324\n",
      "Epoch: 46, Loss (standarized): 0.7887418117725485\n",
      "          Validation Loss (standardized): 0.9555587543059066\n",
      "Epoch: 51, Loss (standarized): 0.7211630354298814\n",
      "          Validation Loss (standardized): 0.9165551783210414\n",
      "Epoch: 56, Loss (standarized): 0.6528455860680661\n",
      "          Validation Loss (standardized): 0.8490723292863253\n",
      "Epoch: 61, Loss (standarized): 0.5828885814129002\n",
      "          Validation Loss (standardized): 0.7948537452533205\n",
      "Epoch: 66, Loss (standarized): 0.512989774797293\n",
      "          Validation Loss (standardized): 0.7427489055968863\n",
      "Epoch: 71, Loss (standarized): 0.45143576829044446\n",
      "          Validation Loss (standardized): 0.6849990525869878\n",
      "Epoch: 76, Loss (standarized): 0.400209203574959\n",
      "          Validation Loss (standardized): 0.6536235204429693\n",
      "Epoch: 81, Loss (standarized): 0.3560896954862683\n",
      "          Validation Loss (standardized): 0.616763000410502\n",
      "Epoch: 86, Loss (standarized): 0.32000208056044754\n",
      "          Validation Loss (standardized): 0.5819092660807132\n",
      "Epoch: 91, Loss (standarized): 0.28979142692251686\n",
      "          Validation Loss (standardized): 0.5603683406569089\n",
      "Epoch: 96, Loss (standarized): 0.26535904086065276\n",
      "          Validation Loss (standardized): 0.5362386538780494\n",
      "Final epoch: 100, Final loss (standarized): 0.24847948708855658\n",
      "Epoch: 1, Loss (standarized): 1.8608909629507226\n",
      "          Validation Loss (standardized): 1.8392440258279525\n",
      "Epoch: 6, Loss (standarized): 1.3799131547702013\n",
      "          Validation Loss (standardized): 1.3348646709630962\n",
      "Epoch: 11, Loss (standarized): 1.2745054903757782\n",
      "          Validation Loss (standardized): 1.2867663007935795\n",
      "Epoch: 16, Loss (standarized): 1.2067351208553903\n",
      "          Validation Loss (standardized): 1.2546061999757447\n",
      "Epoch: 21, Loss (standarized): 1.148134287162163\n",
      "          Validation Loss (standardized): 1.220109445811344\n",
      "Epoch: 26, Loss (standarized): 1.095991359754135\n",
      "          Validation Loss (standardized): 1.166347091306366\n",
      "Epoch: 31, Loss (standarized): 1.043466303759383\n",
      "          Validation Loss (standardized): 1.1071716822863706\n",
      "Epoch: 36, Loss (standarized): 0.985951343542482\n",
      "          Validation Loss (standardized): 1.0536711262152523\n",
      "Epoch: 41, Loss (standarized): 0.9301999738353746\n",
      "          Validation Loss (standardized): 1.0094034326009478\n",
      "Epoch: 46, Loss (standarized): 0.872490950594106\n",
      "          Validation Loss (standardized): 0.9474024207004329\n",
      "Epoch: 51, Loss (standarized): 0.8097075305296744\n",
      "          Validation Loss (standardized): 0.8960927871639081\n",
      "Epoch: 56, Loss (standarized): 0.743590378097317\n",
      "          Validation Loss (standardized): 0.8363678437136604\n",
      "Epoch: 61, Loss (standarized): 0.6748000130543061\n",
      "          Validation Loss (standardized): 0.7779071798180149\n",
      "Epoch: 66, Loss (standarized): 0.6089095451577963\n",
      "          Validation Loss (standardized): 0.7195991485924662\n",
      "Epoch: 71, Loss (standarized): 0.5467681471924863\n",
      "          Validation Loss (standardized): 0.6673768458281755\n",
      "Epoch: 76, Loss (standarized): 0.48636137195838897\n",
      "          Validation Loss (standardized): 0.6185328057549768\n",
      "Epoch: 81, Loss (standarized): 0.4332043528618054\n",
      "          Validation Loss (standardized): 0.5733587811043397\n",
      "Epoch: 86, Loss (standarized): 0.387389629533166\n",
      "          Validation Loss (standardized): 0.5395997334681469\n",
      "Epoch: 91, Loss (standarized): 0.3481559726312633\n",
      "          Validation Loss (standardized): 0.5148007666166261\n",
      "Epoch: 96, Loss (standarized): 0.3161064370820658\n",
      "          Validation Loss (standardized): 0.49131839732458044\n",
      "Final epoch: 100, Final loss (standarized): 0.2934880692454059\n",
      "Epoch: 1, Loss (standarized): 2.078264721398177\n",
      "          Validation Loss (standardized): 1.7463046473614026\n",
      "Epoch: 6, Loss (standarized): 1.382145794805113\n",
      "          Validation Loss (standardized): 1.4762449786596197\n",
      "Epoch: 11, Loss (standarized): 1.2644568874178193\n",
      "          Validation Loss (standardized): 1.347663876783793\n",
      "Epoch: 16, Loss (standarized): 1.1557392069096246\n",
      "          Validation Loss (standardized): 1.2252172294322872\n",
      "Epoch: 21, Loss (standarized): 1.0993156195912737\n",
      "          Validation Loss (standardized): 1.1673082975543434\n",
      "Epoch: 26, Loss (standarized): 1.0493425265296437\n",
      "          Validation Loss (standardized): 1.1503803021885126\n",
      "Epoch: 31, Loss (standarized): 1.0042392375464855\n",
      "          Validation Loss (standardized): 1.1140729060882202\n",
      "Epoch: 36, Loss (standarized): 0.9690940831106382\n",
      "          Validation Loss (standardized): 1.082340670344373\n",
      "Epoch: 41, Loss (standarized): 0.9329940041420138\n",
      "          Validation Loss (standardized): 1.052507703132564\n",
      "Epoch: 46, Loss (standarized): 0.8982604633935373\n",
      "          Validation Loss (standardized): 1.0280478478480044\n",
      "Epoch: 51, Loss (standarized): 0.8640580050824931\n",
      "          Validation Loss (standardized): 1.0090023189493218\n",
      "Epoch: 56, Loss (standarized): 0.8299573860805057\n",
      "          Validation Loss (standardized): 0.9825062460352745\n",
      "Epoch: 61, Loss (standarized): 0.7961394987049938\n",
      "          Validation Loss (standardized): 0.9500472921023103\n",
      "Epoch: 66, Loss (standarized): 0.7631138570513013\n",
      "          Validation Loss (standardized): 0.9212061322234772\n",
      "Epoch: 71, Loss (standarized): 0.7292637739004397\n",
      "          Validation Loss (standardized): 0.8866805530874055\n",
      "Epoch: 76, Loss (standarized): 0.6923114725490148\n",
      "          Validation Loss (standardized): 0.8454858258733888\n",
      "Epoch: 81, Loss (standarized): 0.6548212622845915\n",
      "          Validation Loss (standardized): 0.8142524945824225\n",
      "Epoch: 86, Loss (standarized): 0.6176497577047114\n",
      "          Validation Loss (standardized): 0.7755945099362287\n",
      "Epoch: 91, Loss (standarized): 0.5817339407733472\n",
      "          Validation Loss (standardized): 0.7441553265960991\n",
      "Epoch: 96, Loss (standarized): 0.5485487981059766\n",
      "          Validation Loss (standardized): 0.7123650436182584\n",
      "Final epoch: 100, Final loss (standarized): 0.5241277141993411\n",
      "Epoch: 1, Loss (standarized): 2.0791238381453008\n",
      "          Validation Loss (standardized): 1.747382089239985\n",
      "Epoch: 6, Loss (standarized): 1.462289392361442\n",
      "          Validation Loss (standardized): 1.286089130037028\n",
      "Epoch: 11, Loss (standarized): 1.3313531610210185\n",
      "          Validation Loss (standardized): 1.2734085645383695\n",
      "Epoch: 16, Loss (standarized): 1.2663986827195148\n",
      "          Validation Loss (standardized): 1.300723112919393\n",
      "Epoch: 21, Loss (standarized): 1.2130256339651861\n",
      "          Validation Loss (standardized): 1.2513177551073136\n",
      "Epoch: 26, Loss (standarized): 1.1709265569881346\n",
      "          Validation Loss (standardized): 1.213515745645952\n",
      "Epoch: 31, Loss (standarized): 1.1251629392766689\n",
      "          Validation Loss (standardized): 1.2149431409132918\n",
      "Epoch: 36, Loss (standarized): 1.080662240704354\n",
      "          Validation Loss (standardized): 1.1800205439994949\n",
      "Epoch: 41, Loss (standarized): 1.034562340680837\n",
      "          Validation Loss (standardized): 1.1255471154836607\n",
      "Epoch: 46, Loss (standarized): 0.9883485313758688\n",
      "          Validation Loss (standardized): 1.1084726027352114\n",
      "Epoch: 51, Loss (standarized): 0.9371754939135051\n",
      "          Validation Loss (standardized): 1.0598801708141439\n",
      "Epoch: 56, Loss (standarized): 0.8809788002865475\n",
      "          Validation Loss (standardized): 1.0089268544932242\n",
      "Epoch: 61, Loss (standarized): 0.824580863607261\n",
      "          Validation Loss (standardized): 0.9800470865585174\n",
      "Epoch: 66, Loss (standarized): 0.7687732025746759\n",
      "          Validation Loss (standardized): 0.9401747631720807\n",
      "Epoch: 71, Loss (standarized): 0.7134898049436663\n",
      "          Validation Loss (standardized): 0.9147029929629938\n",
      "Epoch: 76, Loss (standarized): 0.6567606771242461\n",
      "          Validation Loss (standardized): 0.8651124122274291\n",
      "Epoch: 81, Loss (standarized): 0.6017966794602273\n",
      "          Validation Loss (standardized): 0.8279947382007444\n",
      "Epoch: 86, Loss (standarized): 0.5498679007550392\n",
      "          Validation Loss (standardized): 0.7848297123374315\n",
      "Epoch: 91, Loss (standarized): 0.5020167251087889\n",
      "          Validation Loss (standardized): 0.7479551929022762\n",
      "Epoch: 96, Loss (standarized): 0.4578102491056619\n",
      "          Validation Loss (standardized): 0.7007389184325398\n",
      "Final epoch: 100, Final loss (standarized): 0.4246645283546162\n",
      "Epoch: 1, Loss (standarized): 2.0856122499629195\n",
      "          Validation Loss (standardized): 1.7469392293039092\n",
      "Epoch: 6, Loss (standarized): 1.5019289072415212\n",
      "          Validation Loss (standardized): 1.3639847016089213\n",
      "Epoch: 11, Loss (standarized): 1.2936442577468057\n",
      "          Validation Loss (standardized): 1.3484313058865245\n",
      "Epoch: 16, Loss (standarized): 1.2039161517817352\n",
      "          Validation Loss (standardized): 1.3156447619668348\n",
      "Epoch: 21, Loss (standarized): 1.1479930044062485\n",
      "          Validation Loss (standardized): 1.199753672304148\n",
      "Epoch: 26, Loss (standarized): 1.0883886973986077\n",
      "          Validation Loss (standardized): 1.1575733032663311\n",
      "Epoch: 31, Loss (standarized): 1.0380676488992213\n",
      "          Validation Loss (standardized): 1.1537584252127748\n",
      "Epoch: 36, Loss (standarized): 0.9792285881479029\n",
      "          Validation Loss (standardized): 1.0856763362644637\n",
      "Epoch: 41, Loss (standarized): 0.9246926402014444\n",
      "          Validation Loss (standardized): 1.052264437308122\n",
      "Epoch: 46, Loss (standarized): 0.8702471422346718\n",
      "          Validation Loss (standardized): 1.0184020373578413\n",
      "Epoch: 51, Loss (standarized): 0.8140195091382836\n",
      "          Validation Loss (standardized): 0.9605329175408422\n",
      "Epoch: 56, Loss (standarized): 0.7575237893397123\n",
      "          Validation Loss (standardized): 0.9131019300094174\n",
      "Epoch: 61, Loss (standarized): 0.6969214181922493\n",
      "          Validation Loss (standardized): 0.8633235239306348\n",
      "Epoch: 66, Loss (standarized): 0.6356843195418072\n",
      "          Validation Loss (standardized): 0.8027371008150748\n",
      "Epoch: 71, Loss (standarized): 0.5762424484080095\n",
      "          Validation Loss (standardized): 0.7579243723968967\n",
      "Epoch: 76, Loss (standarized): 0.5197496859436066\n",
      "          Validation Loss (standardized): 0.7145580602879791\n",
      "Epoch: 81, Loss (standarized): 0.4696520557035085\n",
      "          Validation Loss (standardized): 0.6694537903506326\n",
      "Epoch: 86, Loss (standarized): 0.42615255311124983\n",
      "          Validation Loss (standardized): 0.6332484492041803\n",
      "Epoch: 91, Loss (standarized): 0.38617389910074024\n",
      "          Validation Loss (standardized): 0.6068750002600029\n",
      "Epoch: 96, Loss (standarized): 0.35307128446088326\n",
      "          Validation Loss (standardized): 0.5722116334274691\n",
      "Final epoch: 100, Final loss (standarized): 0.32964000514593134\n",
      "Epoch: 1, Loss (standarized): 1.8649971919619999\n",
      "          Validation Loss (standardized): 1.7183805963537715\n",
      "Epoch: 6, Loss (standarized): 1.3742113136655811\n",
      "          Validation Loss (standardized): 1.401177149471392\n",
      "Epoch: 11, Loss (standarized): 1.2696696143109645\n",
      "          Validation Loss (standardized): 1.325036221709876\n",
      "Epoch: 16, Loss (standarized): 1.2145551383918576\n",
      "          Validation Loss (standardized): 1.2680942692647865\n",
      "Epoch: 21, Loss (standarized): 1.1656920371121728\n",
      "          Validation Loss (standardized): 1.2142620928749153\n",
      "Epoch: 26, Loss (standarized): 1.1301926884226037\n",
      "          Validation Loss (standardized): 1.1822779202523217\n",
      "Epoch: 31, Loss (standarized): 1.1037928445006466\n",
      "          Validation Loss (standardized): 1.166964687470677\n",
      "Epoch: 36, Loss (standarized): 1.0818089071018564\n",
      "          Validation Loss (standardized): 1.1438123044227566\n",
      "Epoch: 41, Loss (standarized): 1.0612158470890898\n",
      "          Validation Loss (standardized): 1.1178957812105323\n",
      "Epoch: 46, Loss (standarized): 1.040933327703772\n",
      "          Validation Loss (standardized): 1.1008417040386513\n",
      "Epoch: 51, Loss (standarized): 1.024299134588938\n",
      "          Validation Loss (standardized): 1.093998360889074\n",
      "Epoch: 56, Loss (standarized): 1.0082597265048456\n",
      "          Validation Loss (standardized): 1.0810517854740067\n",
      "Epoch: 61, Loss (standarized): 0.9934148389081787\n",
      "          Validation Loss (standardized): 1.068715731613999\n",
      "Epoch: 66, Loss (standarized): 0.9775376215945676\n",
      "          Validation Loss (standardized): 1.0573163405736359\n",
      "Epoch: 71, Loss (standarized): 0.9621430767171201\n",
      "          Validation Loss (standardized): 1.0429050162755584\n",
      "Epoch: 76, Loss (standarized): 0.9463181984473892\n",
      "          Validation Loss (standardized): 1.0295905078542298\n",
      "Epoch: 81, Loss (standarized): 0.9308096158310986\n",
      "          Validation Loss (standardized): 1.0189861264808378\n",
      "Epoch: 86, Loss (standarized): 0.9155728581557981\n",
      "          Validation Loss (standardized): 1.0085190438692093\n",
      "Epoch: 91, Loss (standarized): 0.9004382337970562\n",
      "          Validation Loss (standardized): 0.9904536149224906\n",
      "Epoch: 96, Loss (standarized): 0.8853900114643543\n",
      "          Validation Loss (standardized): 0.9843366403738874\n",
      "Final epoch: 100, Final loss (standarized): 0.8729686622490008\n",
      "Epoch: 1, Loss (standarized): 2.6750096981846965\n",
      "          Validation Loss (standardized): 2.3801815822647385\n",
      "Epoch: 6, Loss (standarized): 1.5601268811998137\n",
      "          Validation Loss (standardized): 1.4818622971705686\n",
      "Epoch: 11, Loss (standarized): 1.456426431727662\n",
      "          Validation Loss (standardized): 1.4044455491382453\n",
      "Epoch: 16, Loss (standarized): 1.3876953559012752\n",
      "          Validation Loss (standardized): 1.2663114514122307\n",
      "Epoch: 21, Loss (standarized): 1.3227161333184057\n",
      "          Validation Loss (standardized): 1.2349463162267398\n",
      "Epoch: 26, Loss (standarized): 1.2820985676201513\n",
      "          Validation Loss (standardized): 1.2637053811819212\n",
      "Epoch: 31, Loss (standarized): 1.2453215887212088\n",
      "          Validation Loss (standardized): 1.2569891187638946\n",
      "Epoch: 36, Loss (standarized): 1.2082247218240305\n",
      "          Validation Loss (standardized): 1.2278906433111318\n",
      "Epoch: 41, Loss (standarized): 1.1796076923470116\n",
      "          Validation Loss (standardized): 1.202015512756752\n",
      "Epoch: 46, Loss (standarized): 1.1598782169453241\n",
      "          Validation Loss (standardized): 1.194738796903533\n",
      "Epoch: 51, Loss (standarized): 1.143644185549\n",
      "          Validation Loss (standardized): 1.1943793916513734\n",
      "Epoch: 56, Loss (standarized): 1.1281686113412008\n",
      "          Validation Loss (standardized): 1.179894066941774\n",
      "Epoch: 61, Loss (standarized): 1.113354263674769\n",
      "          Validation Loss (standardized): 1.1608135801330906\n",
      "Epoch: 66, Loss (standarized): 1.100493965113718\n",
      "          Validation Loss (standardized): 1.149218892052864\n",
      "Epoch: 71, Loss (standarized): 1.0878697796905588\n",
      "          Validation Loss (standardized): 1.1405640024546326\n",
      "Epoch: 76, Loss (standarized): 1.0760063972729452\n",
      "          Validation Loss (standardized): 1.1347935506802287\n",
      "Epoch: 81, Loss (standarized): 1.0639013814073137\n",
      "          Validation Loss (standardized): 1.1245571906414384\n",
      "Epoch: 86, Loss (standarized): 1.0507644070918938\n",
      "          Validation Loss (standardized): 1.1099359767660804\n",
      "Epoch: 91, Loss (standarized): 1.0370650158378185\n",
      "          Validation Loss (standardized): 1.0978854130199416\n",
      "Epoch: 96, Loss (standarized): 1.0236802123525808\n",
      "          Validation Loss (standardized): 1.083619622084815\n",
      "Final epoch: 100, Final loss (standarized): 1.0123507357776063\n",
      "Epoch: 1, Loss (standarized): 1.7439482811949636\n",
      "          Validation Loss (standardized): 1.8585984688733843\n",
      "Epoch: 6, Loss (standarized): 1.3164446141574513\n",
      "          Validation Loss (standardized): 1.30518906332007\n",
      "Epoch: 11, Loss (standarized): 1.2441508806957866\n",
      "          Validation Loss (standardized): 1.2089263173151574\n",
      "Epoch: 16, Loss (standarized): 1.1913839834380513\n",
      "          Validation Loss (standardized): 1.1967844023390621\n",
      "Epoch: 21, Loss (standarized): 1.1589568230923242\n",
      "          Validation Loss (standardized): 1.2120688286036216\n",
      "Epoch: 26, Loss (standarized): 1.1354952519739963\n",
      "          Validation Loss (standardized): 1.19922023850245\n",
      "Epoch: 31, Loss (standarized): 1.1129461081917176\n",
      "          Validation Loss (standardized): 1.1613910210898621\n",
      "Epoch: 36, Loss (standarized): 1.0918689773054107\n",
      "          Validation Loss (standardized): 1.1425848373993908\n",
      "Epoch: 41, Loss (standarized): 1.0707095589819609\n",
      "          Validation Loss (standardized): 1.1324928112903256\n",
      "Epoch: 46, Loss (standarized): 1.0475587856388962\n",
      "          Validation Loss (standardized): 1.1201200521154187\n",
      "Epoch: 51, Loss (standarized): 1.0238038200325184\n",
      "          Validation Loss (standardized): 1.0924327032364953\n",
      "Epoch: 56, Loss (standarized): 0.9995468797737976\n",
      "          Validation Loss (standardized): 1.0677026554146958\n",
      "Epoch: 61, Loss (standarized): 0.9731658250975664\n",
      "          Validation Loss (standardized): 1.04426753816462\n",
      "Epoch: 66, Loss (standarized): 0.9446468346404779\n",
      "          Validation Loss (standardized): 1.0258572914968587\n",
      "Epoch: 71, Loss (standarized): 0.9156407943928195\n",
      "          Validation Loss (standardized): 1.004377209793623\n",
      "Epoch: 76, Loss (standarized): 0.887068107316462\n",
      "          Validation Loss (standardized): 0.9817407394089857\n",
      "Epoch: 81, Loss (standarized): 0.8604906901169561\n",
      "          Validation Loss (standardized): 0.9610194552649572\n",
      "Epoch: 86, Loss (standarized): 0.8347989452905148\n",
      "          Validation Loss (standardized): 0.9401474923218734\n",
      "Epoch: 91, Loss (standarized): 0.8085825162847654\n",
      "          Validation Loss (standardized): 0.9243821811926218\n",
      "Epoch: 96, Loss (standarized): 0.7826789235474026\n",
      "          Validation Loss (standardized): 0.9049482604193035\n",
      "Final epoch: 100, Final loss (standarized): 0.7617267577864859\n",
      "Epoch: 1, Loss (standarized): 1.8699070301099738\n",
      "          Validation Loss (standardized): 1.4666331991437769\n",
      "Epoch: 6, Loss (standarized): 1.3969801680068736\n",
      "          Validation Loss (standardized): 1.4012720132279777\n",
      "Epoch: 11, Loss (standarized): 1.2718221124697522\n",
      "          Validation Loss (standardized): 1.3297135805953415\n",
      "Epoch: 16, Loss (standarized): 1.2035633188958303\n",
      "          Validation Loss (standardized): 1.258087977032017\n",
      "Epoch: 21, Loss (standarized): 1.1665353784855246\n",
      "          Validation Loss (standardized): 1.232681867402097\n",
      "Epoch: 26, Loss (standarized): 1.1420559078725439\n",
      "          Validation Loss (standardized): 1.2374158073690031\n",
      "Epoch: 31, Loss (standarized): 1.1264400469133533\n",
      "          Validation Loss (standardized): 1.2159873325806052\n",
      "Epoch: 36, Loss (standarized): 1.1112595329275603\n",
      "          Validation Loss (standardized): 1.1861645642708003\n",
      "Epoch: 41, Loss (standarized): 1.0991825451378248\n",
      "          Validation Loss (standardized): 1.1782549590715286\n",
      "Epoch: 46, Loss (standarized): 1.087285598150197\n",
      "          Validation Loss (standardized): 1.1718256313023894\n",
      "Epoch: 51, Loss (standarized): 1.0696718664803937\n",
      "          Validation Loss (standardized): 1.1479669440340914\n",
      "Epoch: 56, Loss (standarized): 1.053358695471503\n",
      "          Validation Loss (standardized): 1.1314469087954522\n",
      "Epoch: 61, Loss (standarized): 1.036354043039491\n",
      "          Validation Loss (standardized): 1.1121489311514356\n",
      "Epoch: 66, Loss (standarized): 1.0193413328838141\n",
      "          Validation Loss (standardized): 1.1011854879054985\n",
      "Epoch: 71, Loss (standarized): 1.0019468787501178\n",
      "          Validation Loss (standardized): 1.089884551587746\n",
      "Epoch: 76, Loss (standarized): 0.9830913323130949\n",
      "          Validation Loss (standardized): 1.071363942162784\n",
      "Epoch: 81, Loss (standarized): 0.9632631074917932\n",
      "          Validation Loss (standardized): 1.0514020205144512\n",
      "Epoch: 86, Loss (standarized): 0.9432578980762817\n",
      "          Validation Loss (standardized): 1.0311907537491802\n",
      "Epoch: 91, Loss (standarized): 0.9219633084279952\n",
      "          Validation Loss (standardized): 1.010232746384441\n",
      "Epoch: 96, Loss (standarized): 0.8992016445751893\n",
      "          Validation Loss (standardized): 0.9890363692926291\n",
      "Final epoch: 100, Final loss (standarized): 0.8799240589353217\n",
      "Epoch: 1, Loss (standarized): 2.0484904296738735\n",
      "          Validation Loss (standardized): 2.2012249465395453\n",
      "Epoch: 6, Loss (standarized): 1.3835191374535072\n",
      "          Validation Loss (standardized): 1.3976752056221526\n",
      "Epoch: 11, Loss (standarized): 1.2724837555159263\n",
      "          Validation Loss (standardized): 1.2383567239072926\n",
      "Epoch: 16, Loss (standarized): 1.197475747039453\n",
      "          Validation Loss (standardized): 1.238232593113185\n",
      "Epoch: 21, Loss (standarized): 1.1389864185004783\n",
      "          Validation Loss (standardized): 1.2135511239883618\n",
      "Epoch: 26, Loss (standarized): 1.082784333719382\n",
      "          Validation Loss (standardized): 1.1604642340589781\n",
      "Epoch: 31, Loss (standarized): 1.0339865835233626\n",
      "          Validation Loss (standardized): 1.0867349242703488\n",
      "Epoch: 36, Loss (standarized): 0.9845244152613242\n",
      "          Validation Loss (standardized): 1.0620164535855392\n",
      "Epoch: 41, Loss (standarized): 0.9356367797179993\n",
      "          Validation Loss (standardized): 1.036803102783007\n",
      "Epoch: 46, Loss (standarized): 0.8843172895046267\n",
      "          Validation Loss (standardized): 0.9910482440490521\n",
      "Epoch: 51, Loss (standarized): 0.8317170203315662\n",
      "          Validation Loss (standardized): 0.9398161773264504\n",
      "Epoch: 56, Loss (standarized): 0.7760815441591207\n",
      "          Validation Loss (standardized): 0.8983757769007107\n",
      "Epoch: 61, Loss (standarized): 0.719438607102104\n",
      "          Validation Loss (standardized): 0.8470810682615051\n",
      "Epoch: 66, Loss (standarized): 0.6632879635393891\n",
      "          Validation Loss (standardized): 0.7951156957989612\n",
      "Epoch: 71, Loss (standarized): 0.6104412893535337\n",
      "          Validation Loss (standardized): 0.7514168861735325\n",
      "Epoch: 76, Loss (standarized): 0.5604679182879804\n",
      "          Validation Loss (standardized): 0.7073716257099252\n",
      "Epoch: 81, Loss (standarized): 0.5161714996140196\n",
      "          Validation Loss (standardized): 0.6708488223778373\n",
      "Epoch: 86, Loss (standarized): 0.47695709513011963\n",
      "          Validation Loss (standardized): 0.6384924252789627\n",
      "Epoch: 91, Loss (standarized): 0.4420199880202388\n",
      "          Validation Loss (standardized): 0.6083857043077828\n",
      "Epoch: 96, Loss (standarized): 0.4105798604652918\n",
      "          Validation Loss (standardized): 0.5821383223065781\n",
      "Final epoch: 100, Final loss (standarized): 0.38782766710775923\n",
      "Epoch: 1, Loss (standarized): 2.180554184676962\n",
      "          Validation Loss (standardized): 1.70724471262714\n",
      "Epoch: 6, Loss (standarized): 1.4940530090417257\n",
      "          Validation Loss (standardized): 1.3938882848286585\n",
      "Epoch: 11, Loss (standarized): 1.3297709536570768\n",
      "          Validation Loss (standardized): 1.3494319133822468\n",
      "Epoch: 16, Loss (standarized): 1.2384944494985972\n",
      "          Validation Loss (standardized): 1.2786936628766292\n",
      "Epoch: 21, Loss (standarized): 1.191899952712532\n",
      "          Validation Loss (standardized): 1.230819056154286\n",
      "Epoch: 26, Loss (standarized): 1.1478144086176658\n",
      "          Validation Loss (standardized): 1.201834974660709\n",
      "Epoch: 31, Loss (standarized): 1.1100316326987723\n",
      "          Validation Loss (standardized): 1.1772499146348105\n",
      "Epoch: 36, Loss (standarized): 1.0752373642351347\n",
      "          Validation Loss (standardized): 1.1522017795626593\n",
      "Epoch: 41, Loss (standarized): 1.0441530099164955\n",
      "          Validation Loss (standardized): 1.1134099966252042\n",
      "Epoch: 46, Loss (standarized): 1.0089373531743657\n",
      "          Validation Loss (standardized): 1.0808238991407157\n",
      "Epoch: 51, Loss (standarized): 0.9750468766526734\n",
      "          Validation Loss (standardized): 1.0535427916180435\n",
      "Epoch: 56, Loss (standarized): 0.9400423203637581\n",
      "          Validation Loss (standardized): 1.0247476854139244\n",
      "Epoch: 61, Loss (standarized): 0.9034831989953644\n",
      "          Validation Loss (standardized): 0.9853192534742549\n",
      "Epoch: 66, Loss (standarized): 0.8657113431830341\n",
      "          Validation Loss (standardized): 0.955884194004065\n",
      "Epoch: 71, Loss (standarized): 0.8270562649540176\n",
      "          Validation Loss (standardized): 0.914295417232091\n",
      "Epoch: 76, Loss (standarized): 0.788867526549677\n",
      "          Validation Loss (standardized): 0.87974472942912\n",
      "Epoch: 81, Loss (standarized): 0.7491875352988108\n",
      "          Validation Loss (standardized): 0.8433426712593552\n",
      "Epoch: 86, Loss (standarized): 0.7086976676539806\n",
      "          Validation Loss (standardized): 0.8017009852266651\n",
      "Epoch: 91, Loss (standarized): 0.6709784280755674\n",
      "          Validation Loss (standardized): 0.766499668266491\n",
      "Epoch: 96, Loss (standarized): 0.636654467937777\n",
      "          Validation Loss (standardized): 0.7302195519084651\n",
      "Final epoch: 100, Final loss (standarized): 0.6108407011861167\n",
      "Epoch: 1, Loss (standarized): 1.8731285912943327\n",
      "          Validation Loss (standardized): 1.8291207053249705\n",
      "Epoch: 6, Loss (standarized): 1.3767660462949873\n",
      "          Validation Loss (standardized): 1.394669152866808\n",
      "Epoch: 11, Loss (standarized): 1.246079904646025\n",
      "          Validation Loss (standardized): 1.3026396568155036\n",
      "Epoch: 16, Loss (standarized): 1.158309723839431\n",
      "          Validation Loss (standardized): 1.2398913247253889\n",
      "Epoch: 21, Loss (standarized): 1.110083528027674\n",
      "          Validation Loss (standardized): 1.1806514195343953\n",
      "Epoch: 26, Loss (standarized): 1.0610655282638024\n",
      "          Validation Loss (standardized): 1.1520338267373127\n",
      "Epoch: 31, Loss (standarized): 1.01257299323628\n",
      "          Validation Loss (standardized): 1.1121168052822528\n",
      "Epoch: 36, Loss (standarized): 0.9611229777231359\n",
      "          Validation Loss (standardized): 1.0673439613412545\n",
      "Epoch: 41, Loss (standarized): 0.9083050536705728\n",
      "          Validation Loss (standardized): 1.0328453376620461\n",
      "Epoch: 46, Loss (standarized): 0.8530555721948377\n",
      "          Validation Loss (standardized): 0.9751430924166558\n",
      "Epoch: 51, Loss (standarized): 0.7983121487128948\n",
      "          Validation Loss (standardized): 0.9280099350173814\n",
      "Epoch: 56, Loss (standarized): 0.7418663060788028\n",
      "          Validation Loss (standardized): 0.867315849230446\n",
      "Epoch: 61, Loss (standarized): 0.6911681377045414\n",
      "          Validation Loss (standardized): 0.8296760020303195\n",
      "Epoch: 66, Loss (standarized): 0.6431242430078811\n",
      "          Validation Loss (standardized): 0.7887586427138065\n",
      "Epoch: 71, Loss (standarized): 0.5984302655705908\n",
      "          Validation Loss (standardized): 0.7455554841095521\n",
      "Epoch: 76, Loss (standarized): 0.5552201707257172\n",
      "          Validation Loss (standardized): 0.7116791068670121\n",
      "Epoch: 81, Loss (standarized): 0.5159771880251076\n",
      "          Validation Loss (standardized): 0.679623518283915\n",
      "Epoch: 86, Loss (standarized): 0.4798960473500843\n",
      "          Validation Loss (standardized): 0.6517591030499447\n",
      "Epoch: 91, Loss (standarized): 0.44665567079330104\n",
      "          Validation Loss (standardized): 0.622520207517403\n",
      "Epoch: 96, Loss (standarized): 0.4162471702488503\n",
      "          Validation Loss (standardized): 0.6016230604107056\n",
      "Final epoch: 100, Final loss (standarized): 0.39475232506184793\n",
      "Epoch: 1, Loss (standarized): 2.0942178323088667\n",
      "          Validation Loss (standardized): 1.579635411265419\n",
      "Epoch: 6, Loss (standarized): 1.3592184592419716\n",
      "          Validation Loss (standardized): 1.2935295123403703\n",
      "Epoch: 11, Loss (standarized): 1.2026339701545519\n",
      "          Validation Loss (standardized): 1.2638799349223422\n",
      "Epoch: 16, Loss (standarized): 1.1494333818590448\n",
      "          Validation Loss (standardized): 1.236622895635231\n",
      "Epoch: 21, Loss (standarized): 1.1047954508870452\n",
      "          Validation Loss (standardized): 1.2046835959313797\n",
      "Epoch: 26, Loss (standarized): 1.0565993040305168\n",
      "          Validation Loss (standardized): 1.1760151809118593\n",
      "Epoch: 31, Loss (standarized): 1.0131988354097492\n",
      "          Validation Loss (standardized): 1.1132462540873649\n",
      "Epoch: 36, Loss (standarized): 0.9700588321210395\n",
      "          Validation Loss (standardized): 1.0724783182145288\n",
      "Epoch: 41, Loss (standarized): 0.9253543093669776\n",
      "          Validation Loss (standardized): 1.0449713629514352\n",
      "Epoch: 46, Loss (standarized): 0.8760426919476407\n",
      "          Validation Loss (standardized): 1.0129178553394889\n",
      "Epoch: 51, Loss (standarized): 0.8281966269809504\n",
      "          Validation Loss (standardized): 0.9718725260385065\n",
      "Epoch: 56, Loss (standarized): 0.7822119958687245\n",
      "          Validation Loss (standardized): 0.9410752784225621\n",
      "Epoch: 61, Loss (standarized): 0.7369966528861324\n",
      "          Validation Loss (standardized): 0.8967609093520922\n",
      "Epoch: 66, Loss (standarized): 0.6935907074599938\n",
      "          Validation Loss (standardized): 0.8606751777921278\n",
      "Epoch: 71, Loss (standarized): 0.6505957148723845\n",
      "          Validation Loss (standardized): 0.8244326921640863\n",
      "Epoch: 76, Loss (standarized): 0.6057700976190199\n",
      "          Validation Loss (standardized): 0.7814731101891567\n",
      "Epoch: 81, Loss (standarized): 0.564646165597834\n",
      "          Validation Loss (standardized): 0.7456403889384373\n",
      "Epoch: 86, Loss (standarized): 0.5249805656138515\n",
      "          Validation Loss (standardized): 0.7123819855011357\n",
      "Epoch: 91, Loss (standarized): 0.48683027423608094\n",
      "          Validation Loss (standardized): 0.6854045852925524\n",
      "Epoch: 96, Loss (standarized): 0.4513392987180261\n",
      "          Validation Loss (standardized): 0.6577378802643612\n",
      "Final epoch: 100, Final loss (standarized): 0.42531698345072966\n",
      "Epoch: 1, Loss (standarized): 2.4282046219194537\n",
      "          Validation Loss (standardized): 1.6147614308392713\n",
      "Epoch: 6, Loss (standarized): 1.5065744204718987\n",
      "          Validation Loss (standardized): 1.3710256726469905\n",
      "Epoch: 11, Loss (standarized): 1.327456406788881\n",
      "          Validation Loss (standardized): 1.4014674090169055\n",
      "Epoch: 16, Loss (standarized): 1.2446235805607275\n",
      "          Validation Loss (standardized): 1.326163873714569\n",
      "Epoch: 21, Loss (standarized): 1.1870189902918327\n",
      "          Validation Loss (standardized): 1.2187601064440665\n",
      "Epoch: 26, Loss (standarized): 1.1342498750037322\n",
      "          Validation Loss (standardized): 1.126839299048755\n",
      "Epoch: 31, Loss (standarized): 1.0881548772908491\n",
      "          Validation Loss (standardized): 1.0893287965707783\n",
      "Epoch: 36, Loss (standarized): 1.0406519971619097\n",
      "          Validation Loss (standardized): 1.0910838673942562\n",
      "Epoch: 41, Loss (standarized): 0.9985297127687209\n",
      "          Validation Loss (standardized): 1.075211955522333\n",
      "Epoch: 46, Loss (standarized): 0.9544778925561473\n",
      "          Validation Loss (standardized): 1.0257826198756743\n",
      "Epoch: 51, Loss (standarized): 0.908927098931529\n",
      "          Validation Loss (standardized): 0.984153677684502\n",
      "Epoch: 56, Loss (standarized): 0.8613637101602467\n",
      "          Validation Loss (standardized): 0.9601874717937323\n",
      "Epoch: 61, Loss (standarized): 0.811954065537897\n",
      "          Validation Loss (standardized): 0.9293325140020615\n",
      "Epoch: 66, Loss (standarized): 0.7626158709297911\n",
      "          Validation Loss (standardized): 0.8827331029557511\n",
      "Epoch: 71, Loss (standarized): 0.7126829229511894\n",
      "          Validation Loss (standardized): 0.848048263207344\n",
      "Epoch: 76, Loss (standarized): 0.6594973105567203\n",
      "          Validation Loss (standardized): 0.8045277904720585\n",
      "Epoch: 81, Loss (standarized): 0.6082279078387424\n",
      "          Validation Loss (standardized): 0.7640057795620169\n",
      "Epoch: 86, Loss (standarized): 0.5598198381123387\n",
      "          Validation Loss (standardized): 0.7242380406597118\n",
      "Epoch: 91, Loss (standarized): 0.5115539683835549\n",
      "          Validation Loss (standardized): 0.6816236051688965\n",
      "Epoch: 96, Loss (standarized): 0.46600130828400466\n",
      "          Validation Loss (standardized): 0.6447280473931067\n",
      "Final epoch: 100, Final loss (standarized): 0.4275415417904215\n",
      "Epoch: 1, Loss (standarized): 2.397632967202211\n",
      "          Validation Loss (standardized): 2.003449384934591\n",
      "Epoch: 6, Loss (standarized): 1.5415945964815176\n",
      "          Validation Loss (standardized): 1.3260660366209664\n",
      "Epoch: 11, Loss (standarized): 1.2985133735221712\n",
      "          Validation Loss (standardized): 1.2471857720706094\n",
      "Epoch: 16, Loss (standarized): 1.2530273816209871\n",
      "          Validation Loss (standardized): 1.226593030801991\n",
      "Epoch: 21, Loss (standarized): 1.1730342918482604\n",
      "          Validation Loss (standardized): 1.1593459273181383\n",
      "Epoch: 26, Loss (standarized): 1.1365128518039214\n",
      "          Validation Loss (standardized): 1.164573040095849\n",
      "Epoch: 31, Loss (standarized): 1.0922689918579076\n",
      "          Validation Loss (standardized): 1.1529758425062893\n",
      "Epoch: 36, Loss (standarized): 1.052831218207545\n",
      "          Validation Loss (standardized): 1.1019189659284943\n",
      "Epoch: 41, Loss (standarized): 1.0218864776758882\n",
      "          Validation Loss (standardized): 1.0844345510723175\n",
      "Epoch: 46, Loss (standarized): 0.9894303318385776\n",
      "          Validation Loss (standardized): 1.0764395409645995\n",
      "Epoch: 51, Loss (standarized): 0.9555790365077312\n",
      "          Validation Loss (standardized): 1.0387377457392664\n",
      "Epoch: 56, Loss (standarized): 0.9192781447936816\n",
      "          Validation Loss (standardized): 1.0168395006993554\n",
      "Epoch: 61, Loss (standarized): 0.8802745516528865\n",
      "          Validation Loss (standardized): 0.9803779532873509\n",
      "Epoch: 66, Loss (standarized): 0.8394240375649875\n",
      "          Validation Loss (standardized): 0.9475310165395376\n",
      "Epoch: 71, Loss (standarized): 0.7996471503190651\n",
      "          Validation Loss (standardized): 0.9181929485704055\n",
      "Epoch: 76, Loss (standarized): 0.7607162199221525\n",
      "          Validation Loss (standardized): 0.8889883048752759\n",
      "Epoch: 81, Loss (standarized): 0.722787661986886\n",
      "          Validation Loss (standardized): 0.8584054043814822\n",
      "Epoch: 86, Loss (standarized): 0.6867522810955515\n",
      "          Validation Loss (standardized): 0.8334853918004625\n",
      "Epoch: 91, Loss (standarized): 0.6536814483616132\n",
      "          Validation Loss (standardized): 0.8080812448143504\n",
      "Epoch: 96, Loss (standarized): 0.6234393565523423\n",
      "          Validation Loss (standardized): 0.7872686721049817\n",
      "Final epoch: 100, Final loss (standarized): 0.6006147246219998\n",
      "Epoch: 1, Loss (standarized): 1.9485602166219613\n",
      "          Validation Loss (standardized): 1.5851444296299584\n",
      "Epoch: 6, Loss (standarized): 1.3549076484626852\n",
      "          Validation Loss (standardized): 1.2735848654770532\n",
      "Epoch: 11, Loss (standarized): 1.203502281385305\n",
      "          Validation Loss (standardized): 1.1874884265537942\n",
      "Epoch: 16, Loss (standarized): 1.1404278947197475\n",
      "          Validation Loss (standardized): 1.1721400725979456\n",
      "Epoch: 21, Loss (standarized): 1.093311741789658\n",
      "          Validation Loss (standardized): 1.157189219256913\n",
      "Epoch: 26, Loss (standarized): 1.0525002136152752\n",
      "          Validation Loss (standardized): 1.1175870716172274\n",
      "Epoch: 31, Loss (standarized): 1.004581457910582\n",
      "          Validation Loss (standardized): 1.0799216556352094\n",
      "Epoch: 36, Loss (standarized): 0.9547239447181974\n",
      "          Validation Loss (standardized): 1.0383590102031008\n",
      "Epoch: 41, Loss (standarized): 0.9003673944175605\n",
      "          Validation Loss (standardized): 0.9977536666856607\n",
      "Epoch: 46, Loss (standarized): 0.8423047609774386\n",
      "          Validation Loss (standardized): 0.9541727236275942\n",
      "Epoch: 51, Loss (standarized): 0.7829621031229749\n",
      "          Validation Loss (standardized): 0.9132933002420075\n",
      "Epoch: 56, Loss (standarized): 0.7243295583645966\n",
      "          Validation Loss (standardized): 0.8662918530483131\n",
      "Epoch: 61, Loss (standarized): 0.6690454923979611\n",
      "          Validation Loss (standardized): 0.8222684452780801\n",
      "Epoch: 66, Loss (standarized): 0.6171574917617917\n",
      "          Validation Loss (standardized): 0.7795672968765427\n",
      "Epoch: 71, Loss (standarized): 0.5679383016856137\n",
      "          Validation Loss (standardized): 0.735049947708769\n",
      "Epoch: 76, Loss (standarized): 0.5221467644614868\n",
      "          Validation Loss (standardized): 0.6949052983946399\n",
      "Epoch: 81, Loss (standarized): 0.48027696433102807\n",
      "          Validation Loss (standardized): 0.6677380853673404\n",
      "Epoch: 86, Loss (standarized): 0.4363224141881332\n",
      "          Validation Loss (standardized): 0.623457893080891\n",
      "Epoch: 91, Loss (standarized): 0.39699775400320464\n",
      "          Validation Loss (standardized): 0.5883675831914422\n",
      "Epoch: 96, Loss (standarized): 0.3639755104496645\n",
      "          Validation Loss (standardized): 0.5608486159001722\n",
      "Final epoch: 100, Final loss (standarized): 0.33992077833888273\n",
      "Epoch: 1, Loss (standarized): 2.9767061550746248\n",
      "          Validation Loss (standardized): 2.3751475033008225\n",
      "Epoch: 6, Loss (standarized): 1.7242380464227969\n",
      "          Validation Loss (standardized): 1.6768599568475728\n",
      "Epoch: 11, Loss (standarized): 1.396572290954976\n",
      "          Validation Loss (standardized): 1.4530284900611745\n",
      "Epoch: 16, Loss (standarized): 1.283413190406986\n",
      "          Validation Loss (standardized): 1.287988596828384\n",
      "Epoch: 21, Loss (standarized): 1.2289916617346788\n",
      "          Validation Loss (standardized): 1.1892501714626258\n",
      "Epoch: 26, Loss (standarized): 1.176957720377317\n",
      "          Validation Loss (standardized): 1.1559006753552838\n",
      "Epoch: 31, Loss (standarized): 1.131515536848443\n",
      "          Validation Loss (standardized): 1.1597405151893327\n",
      "Epoch: 36, Loss (standarized): 1.0867785863914252\n",
      "          Validation Loss (standardized): 1.1237403686511593\n",
      "Epoch: 41, Loss (standarized): 1.0474096185538722\n",
      "          Validation Loss (standardized): 1.0862707405705456\n",
      "Epoch: 46, Loss (standarized): 1.008987263431106\n",
      "          Validation Loss (standardized): 1.061495120684308\n",
      "Epoch: 51, Loss (standarized): 0.9701869627808964\n",
      "          Validation Loss (standardized): 1.0394569063188341\n",
      "Epoch: 56, Loss (standarized): 0.9306651034239747\n",
      "          Validation Loss (standardized): 1.0037890762434658\n",
      "Epoch: 61, Loss (standarized): 0.8902806169270906\n",
      "          Validation Loss (standardized): 0.9708565458077006\n",
      "Epoch: 66, Loss (standarized): 0.8475129779145809\n",
      "          Validation Loss (standardized): 0.9404549209595228\n",
      "Epoch: 71, Loss (standarized): 0.8021324136982423\n",
      "          Validation Loss (standardized): 0.9126318119595866\n",
      "Epoch: 76, Loss (standarized): 0.7542602878700333\n",
      "          Validation Loss (standardized): 0.8820993261702043\n",
      "Epoch: 81, Loss (standarized): 0.703346971329226\n",
      "          Validation Loss (standardized): 0.8401778373348613\n",
      "Epoch: 86, Loss (standarized): 0.6527405768290658\n",
      "          Validation Loss (standardized): 0.8069171362961522\n",
      "Epoch: 91, Loss (standarized): 0.6012850991446251\n",
      "          Validation Loss (standardized): 0.7658417042780378\n",
      "Epoch: 96, Loss (standarized): 0.5486541403888325\n",
      "          Validation Loss (standardized): 0.7329085638928599\n",
      "Final epoch: 100, Final loss (standarized): 0.5083291497768522\n",
      "Epoch: 1, Loss (standarized): 1.5856621364480497\n",
      "          Validation Loss (standardized): 1.555004599018759\n",
      "Epoch: 6, Loss (standarized): 1.3066956122396198\n",
      "          Validation Loss (standardized): 1.3094625365377268\n",
      "Epoch: 11, Loss (standarized): 1.1946664454744123\n",
      "          Validation Loss (standardized): 1.230574804615934\n",
      "Epoch: 16, Loss (standarized): 1.134027915688111\n",
      "          Validation Loss (standardized): 1.2381763980618679\n",
      "Epoch: 21, Loss (standarized): 1.0730837942714497\n",
      "          Validation Loss (standardized): 1.1856180199316881\n",
      "Epoch: 26, Loss (standarized): 1.0164750142874697\n",
      "          Validation Loss (standardized): 1.1206229523782736\n",
      "Epoch: 31, Loss (standarized): 0.9603721078913402\n",
      "          Validation Loss (standardized): 1.0665194440992336\n",
      "Epoch: 36, Loss (standarized): 0.9037503474669557\n",
      "          Validation Loss (standardized): 1.0223294175941393\n",
      "Epoch: 41, Loss (standarized): 0.8410837108546844\n",
      "          Validation Loss (standardized): 0.9785989382161447\n",
      "Epoch: 46, Loss (standarized): 0.7769831459908393\n",
      "          Validation Loss (standardized): 0.9305594183598962\n",
      "Epoch: 51, Loss (standarized): 0.7102625721001979\n",
      "          Validation Loss (standardized): 0.8700060705177991\n",
      "Epoch: 56, Loss (standarized): 0.6426872866469937\n",
      "          Validation Loss (standardized): 0.8166893624167132\n",
      "Epoch: 61, Loss (standarized): 0.5770110927044058\n",
      "          Validation Loss (standardized): 0.7625058037826989\n",
      "Epoch: 66, Loss (standarized): 0.5148967078300352\n",
      "          Validation Loss (standardized): 0.7017645918186284\n",
      "Epoch: 71, Loss (standarized): 0.45808988006594276\n",
      "          Validation Loss (standardized): 0.6522837621338572\n",
      "Epoch: 76, Loss (standarized): 0.4070343895130975\n",
      "          Validation Loss (standardized): 0.6035592054754879\n",
      "Epoch: 81, Loss (standarized): 0.36142184943527467\n",
      "          Validation Loss (standardized): 0.5696737193606541\n",
      "Epoch: 86, Loss (standarized): 0.3219415110004955\n",
      "          Validation Loss (standardized): 0.5454951404021272\n",
      "Epoch: 91, Loss (standarized): 0.2877593993162563\n",
      "          Validation Loss (standardized): 0.5318114086910666\n",
      "Epoch: 96, Loss (standarized): 0.26048477472729764\n",
      "          Validation Loss (standardized): 0.5327617744873503\n",
      "Final epoch: 100, Final loss (standarized): 0.2420213087731379\n",
      "Epoch: 1, Loss (standarized): 2.382635184395556\n",
      "          Validation Loss (standardized): 2.4593625231856477\n",
      "Epoch: 6, Loss (standarized): 1.5750135406699002\n",
      "          Validation Loss (standardized): 1.6423382617937907\n",
      "Epoch: 11, Loss (standarized): 1.3781897356922825\n",
      "          Validation Loss (standardized): 1.349084375642195\n",
      "Epoch: 16, Loss (standarized): 1.2878626670859261\n",
      "          Validation Loss (standardized): 1.2748832074429597\n",
      "Epoch: 21, Loss (standarized): 1.2226843639592917\n",
      "          Validation Loss (standardized): 1.2564692607875052\n",
      "Epoch: 26, Loss (standarized): 1.1755706294795245\n",
      "          Validation Loss (standardized): 1.195546940671616\n",
      "Epoch: 31, Loss (standarized): 1.1351109754516004\n",
      "          Validation Loss (standardized): 1.1298239181476621\n",
      "Epoch: 36, Loss (standarized): 1.0992299414850892\n",
      "          Validation Loss (standardized): 1.100026017543844\n",
      "Epoch: 41, Loss (standarized): 1.062580180218512\n",
      "          Validation Loss (standardized): 1.0883870215083584\n",
      "Epoch: 46, Loss (standarized): 1.0228245856400526\n",
      "          Validation Loss (standardized): 1.0615223879059927\n",
      "Epoch: 51, Loss (standarized): 0.9808289161240475\n",
      "          Validation Loss (standardized): 1.0296209426647203\n",
      "Epoch: 56, Loss (standarized): 0.9345715095994234\n",
      "          Validation Loss (standardized): 1.0041021038844102\n",
      "Epoch: 61, Loss (standarized): 0.8860310618369428\n",
      "          Validation Loss (standardized): 0.9613082228623832\n",
      "Epoch: 66, Loss (standarized): 0.8423047452391783\n",
      "          Validation Loss (standardized): 0.9293718137017176\n",
      "Epoch: 71, Loss (standarized): 0.7963378796039785\n",
      "          Validation Loss (standardized): 0.8890551900186172\n",
      "Epoch: 76, Loss (standarized): 0.7526833992529908\n",
      "          Validation Loss (standardized): 0.8516400504336528\n",
      "Epoch: 81, Loss (standarized): 0.7122657829035245\n",
      "          Validation Loss (standardized): 0.8213085575563774\n",
      "Epoch: 86, Loss (standarized): 0.675938526996856\n",
      "          Validation Loss (standardized): 0.7879247783477283\n",
      "Epoch: 91, Loss (standarized): 0.6421120503324044\n",
      "          Validation Loss (standardized): 0.7548309548934988\n",
      "Epoch: 96, Loss (standarized): 0.6091184653413083\n",
      "          Validation Loss (standardized): 0.7183182786736434\n",
      "Final epoch: 100, Final loss (standarized): 0.5847876840778855\n",
      "Epoch: 1, Loss (standarized): 1.9388008852166825\n",
      "          Validation Loss (standardized): 1.5891676721957622\n",
      "Epoch: 6, Loss (standarized): 1.387331873731403\n",
      "          Validation Loss (standardized): 1.4393426399174076\n",
      "Epoch: 11, Loss (standarized): 1.2730428852131355\n",
      "          Validation Loss (standardized): 1.3713204335887463\n",
      "Epoch: 16, Loss (standarized): 1.1850860403223893\n",
      "          Validation Loss (standardized): 1.2296340136268031\n",
      "Epoch: 21, Loss (standarized): 1.1335102524620937\n",
      "          Validation Loss (standardized): 1.1446867504883904\n",
      "Epoch: 26, Loss (standarized): 1.0812693661412276\n",
      "          Validation Loss (standardized): 1.1201043270495825\n",
      "Epoch: 31, Loss (standarized): 1.0355395481009682\n",
      "          Validation Loss (standardized): 1.097913799877876\n",
      "Epoch: 36, Loss (standarized): 0.9866390510370968\n",
      "          Validation Loss (standardized): 1.0488705976337829\n",
      "Epoch: 41, Loss (standarized): 0.9360093385650518\n",
      "          Validation Loss (standardized): 1.0096239805464098\n",
      "Epoch: 46, Loss (standarized): 0.883470438105252\n",
      "          Validation Loss (standardized): 0.9723455328751746\n",
      "Epoch: 51, Loss (standarized): 0.8279680201415361\n",
      "          Validation Loss (standardized): 0.9214747236265721\n",
      "Epoch: 56, Loss (standarized): 0.7691324641991857\n",
      "          Validation Loss (standardized): 0.8759540558779031\n",
      "Epoch: 61, Loss (standarized): 0.7094133232405541\n",
      "          Validation Loss (standardized): 0.820134060741806\n",
      "Epoch: 66, Loss (standarized): 0.645709372223967\n",
      "          Validation Loss (standardized): 0.7710468531199577\n",
      "Epoch: 71, Loss (standarized): 0.5792762899809021\n",
      "          Validation Loss (standardized): 0.7079595201267831\n",
      "Epoch: 76, Loss (standarized): 0.5233151259005153\n",
      "          Validation Loss (standardized): 0.6685111745199733\n",
      "Epoch: 81, Loss (standarized): 0.472309391775639\n",
      "          Validation Loss (standardized): 0.6226799929540775\n",
      "Epoch: 86, Loss (standarized): 0.42888820536214906\n",
      "          Validation Loss (standardized): 0.5895758675635071\n",
      "Epoch: 91, Loss (standarized): 0.3901490999209545\n",
      "          Validation Loss (standardized): 0.5546986275264228\n",
      "Epoch: 96, Loss (standarized): 0.356949593300169\n",
      "          Validation Loss (standardized): 0.5340330572897483\n",
      "Final epoch: 100, Final loss (standarized): 0.33437939293052793\n",
      "Epoch: 1, Loss (standarized): 3.0358546832795295\n",
      "          Validation Loss (standardized): 2.7992444647107475\n",
      "Epoch: 6, Loss (standarized): 1.6516614220229207\n",
      "          Validation Loss (standardized): 1.4560646912734212\n",
      "Epoch: 11, Loss (standarized): 1.406812453784367\n",
      "          Validation Loss (standardized): 1.2821037660100616\n",
      "Epoch: 16, Loss (standarized): 1.2776206520748128\n",
      "          Validation Loss (standardized): 1.265022118669687\n",
      "Epoch: 21, Loss (standarized): 1.1977562944535487\n",
      "          Validation Loss (standardized): 1.273823944996922\n",
      "Epoch: 26, Loss (standarized): 1.1590191325298338\n",
      "          Validation Loss (standardized): 1.2373995637789243\n",
      "Epoch: 31, Loss (standarized): 1.107119449282024\n",
      "          Validation Loss (standardized): 1.2158929089034318\n",
      "Epoch: 36, Loss (standarized): 1.0634125954314064\n",
      "          Validation Loss (standardized): 1.1633916661509056\n",
      "Epoch: 41, Loss (standarized): 1.0224970378918068\n",
      "          Validation Loss (standardized): 1.1149211812617623\n",
      "Epoch: 46, Loss (standarized): 0.9805472130830392\n",
      "          Validation Loss (standardized): 1.110861675232415\n",
      "Epoch: 51, Loss (standarized): 0.9401848996545067\n",
      "          Validation Loss (standardized): 1.0854032100669764\n",
      "Epoch: 56, Loss (standarized): 0.9023747857591414\n",
      "          Validation Loss (standardized): 1.066065854904459\n",
      "Epoch: 61, Loss (standarized): 0.8593622064151467\n",
      "          Validation Loss (standardized): 1.02381630677001\n",
      "Epoch: 66, Loss (standarized): 0.8175611834396644\n",
      "          Validation Loss (standardized): 1.0003183408174536\n",
      "Epoch: 71, Loss (standarized): 0.7775665748507774\n",
      "          Validation Loss (standardized): 0.9643681061123809\n",
      "Epoch: 76, Loss (standarized): 0.7359512139206518\n",
      "          Validation Loss (standardized): 0.9286464496102557\n",
      "Epoch: 81, Loss (standarized): 0.6932649504432543\n",
      "          Validation Loss (standardized): 0.8871877033907389\n",
      "Epoch: 86, Loss (standarized): 0.6466420761277645\n",
      "          Validation Loss (standardized): 0.8467244664907552\n",
      "Epoch: 91, Loss (standarized): 0.5978608381163465\n",
      "          Validation Loss (standardized): 0.7996185971286802\n",
      "Epoch: 96, Loss (standarized): 0.5494450269674083\n",
      "          Validation Loss (standardized): 0.7534078506676745\n",
      "Final epoch: 100, Final loss (standarized): 0.5152875861395294\n",
      "Epoch: 1, Loss (standarized): 2.2869257706997366\n",
      "          Validation Loss (standardized): 2.00000271637524\n",
      "Epoch: 6, Loss (standarized): 1.4101499958318369\n",
      "          Validation Loss (standardized): 1.4326586276292883\n",
      "Epoch: 11, Loss (standarized): 1.3071285610683199\n",
      "          Validation Loss (standardized): 1.3135837579586447\n",
      "Epoch: 16, Loss (standarized): 1.2399984035703278\n",
      "          Validation Loss (standardized): 1.2829858199425026\n",
      "Epoch: 21, Loss (standarized): 1.1923815254645\n",
      "          Validation Loss (standardized): 1.2461229742655082\n",
      "Epoch: 26, Loss (standarized): 1.159512505058283\n",
      "          Validation Loss (standardized): 1.198258429713124\n",
      "Epoch: 31, Loss (standarized): 1.1347210923894142\n",
      "          Validation Loss (standardized): 1.1859739633034734\n",
      "Epoch: 36, Loss (standarized): 1.1138802038696185\n",
      "          Validation Loss (standardized): 1.1781455625992536\n",
      "Epoch: 41, Loss (standarized): 1.0918026105777683\n",
      "          Validation Loss (standardized): 1.1538670386403191\n",
      "Epoch: 46, Loss (standarized): 1.069401357189741\n",
      "          Validation Loss (standardized): 1.1479822182730695\n",
      "Epoch: 51, Loss (standarized): 1.0469686896206882\n",
      "          Validation Loss (standardized): 1.1354638442225549\n",
      "Epoch: 56, Loss (standarized): 1.0222652500713871\n",
      "          Validation Loss (standardized): 1.0998304106257446\n",
      "Epoch: 61, Loss (standarized): 0.9954515214433018\n",
      "          Validation Loss (standardized): 1.0772597694495452\n",
      "Epoch: 66, Loss (standarized): 0.9669342136219324\n",
      "          Validation Loss (standardized): 1.05378434907617\n",
      "Epoch: 71, Loss (standarized): 0.9398778279060227\n",
      "          Validation Loss (standardized): 1.0291437024600696\n",
      "Epoch: 76, Loss (standarized): 0.9133565747073985\n",
      "          Validation Loss (standardized): 1.0088289172880762\n",
      "Epoch: 81, Loss (standarized): 0.8858774781773957\n",
      "          Validation Loss (standardized): 0.9789130933082084\n",
      "Epoch: 86, Loss (standarized): 0.8579284978450804\n",
      "          Validation Loss (standardized): 0.9635996136283291\n",
      "Epoch: 91, Loss (standarized): 0.8293475498861079\n",
      "          Validation Loss (standardized): 0.932663735114417\n",
      "Epoch: 96, Loss (standarized): 0.8003432460884777\n",
      "          Validation Loss (standardized): 0.9133891809376341\n",
      "Final epoch: 100, Final loss (standarized): 0.777376576750346\n",
      "Epoch: 1, Loss (standarized): 2.502738799917927\n",
      "          Validation Loss (standardized): 2.551782289356003\n",
      "Epoch: 6, Loss (standarized): 1.5726262676589058\n",
      "          Validation Loss (standardized): 1.6397627735261937\n",
      "Epoch: 11, Loss (standarized): 1.3998655539831553\n",
      "          Validation Loss (standardized): 1.4563279628600625\n",
      "Epoch: 16, Loss (standarized): 1.311727657498704\n",
      "          Validation Loss (standardized): 1.3624051969380326\n",
      "Epoch: 21, Loss (standarized): 1.2772634901454945\n",
      "          Validation Loss (standardized): 1.309068920777331\n",
      "Epoch: 26, Loss (standarized): 1.2400365193612257\n",
      "          Validation Loss (standardized): 1.2646411780669762\n",
      "Epoch: 31, Loss (standarized): 1.2230193438417962\n",
      "          Validation Loss (standardized): 1.2430652894981087\n",
      "Epoch: 36, Loss (standarized): 1.207292092752851\n",
      "          Validation Loss (standardized): 1.233229523434383\n",
      "Epoch: 41, Loss (standarized): 1.1943558403623258\n",
      "          Validation Loss (standardized): 1.2222197705857414\n",
      "Epoch: 46, Loss (standarized): 1.179334282477641\n",
      "          Validation Loss (standardized): 1.2007607418020998\n",
      "Epoch: 51, Loss (standarized): 1.1653597890560494\n",
      "          Validation Loss (standardized): 1.1887614981834704\n",
      "Epoch: 56, Loss (standarized): 1.1528259346468104\n",
      "          Validation Loss (standardized): 1.1813122587932043\n",
      "Epoch: 61, Loss (standarized): 1.140968600452\n",
      "          Validation Loss (standardized): 1.1698298500806048\n",
      "Epoch: 66, Loss (standarized): 1.1281402059407584\n",
      "          Validation Loss (standardized): 1.1625731367638457\n",
      "Epoch: 71, Loss (standarized): 1.1156529235253279\n",
      "          Validation Loss (standardized): 1.155803616967963\n",
      "Epoch: 76, Loss (standarized): 1.1028429125265955\n",
      "          Validation Loss (standardized): 1.143988703623725\n",
      "Epoch: 81, Loss (standarized): 1.0892589229689247\n",
      "          Validation Loss (standardized): 1.1339038530023744\n",
      "Epoch: 86, Loss (standarized): 1.0748811876345996\n",
      "          Validation Loss (standardized): 1.1209587704223718\n",
      "Epoch: 91, Loss (standarized): 1.0600232415882134\n",
      "          Validation Loss (standardized): 1.106761440484234\n",
      "Epoch: 96, Loss (standarized): 1.0453587743753168\n",
      "          Validation Loss (standardized): 1.0937966640752785\n",
      "Final epoch: 100, Final loss (standarized): 1.0336848524366784\n",
      "Epoch: 1, Loss (standarized): 2.2468101710140367\n",
      "          Validation Loss (standardized): 1.6851644465694153\n",
      "Epoch: 6, Loss (standarized): 1.434243080447461\n",
      "          Validation Loss (standardized): 1.3497397685983767\n",
      "Epoch: 11, Loss (standarized): 1.2664289580549515\n",
      "          Validation Loss (standardized): 1.326416498603329\n",
      "Epoch: 16, Loss (standarized): 1.2256413345671473\n",
      "          Validation Loss (standardized): 1.2815667257650571\n",
      "Epoch: 21, Loss (standarized): 1.174794175008853\n",
      "          Validation Loss (standardized): 1.2061478107448294\n",
      "Epoch: 26, Loss (standarized): 1.1333815831299723\n",
      "          Validation Loss (standardized): 1.1598872119927057\n",
      "Epoch: 31, Loss (standarized): 1.1017168582574939\n",
      "          Validation Loss (standardized): 1.1580376546705538\n",
      "Epoch: 36, Loss (standarized): 1.0774297987771226\n",
      "          Validation Loss (standardized): 1.1597258285606773\n",
      "Epoch: 41, Loss (standarized): 1.052146442418095\n",
      "          Validation Loss (standardized): 1.1353580674746486\n",
      "Epoch: 46, Loss (standarized): 1.028064902873948\n",
      "          Validation Loss (standardized): 1.0960439988312451\n",
      "Epoch: 51, Loss (standarized): 1.0077463933006217\n",
      "          Validation Loss (standardized): 1.077997153666111\n",
      "Epoch: 56, Loss (standarized): 0.9880440255140538\n",
      "          Validation Loss (standardized): 1.0636286302653002\n",
      "Epoch: 61, Loss (standarized): 0.9686619089997904\n",
      "          Validation Loss (standardized): 1.0497337665882283\n",
      "Epoch: 66, Loss (standarized): 0.9466699165341111\n",
      "          Validation Loss (standardized): 1.023678867893393\n",
      "Epoch: 71, Loss (standarized): 0.9239480801420844\n",
      "          Validation Loss (standardized): 0.9980347828735733\n",
      "Epoch: 76, Loss (standarized): 0.9016878335683159\n",
      "          Validation Loss (standardized): 0.9848925511867663\n",
      "Epoch: 81, Loss (standarized): 0.8796121277828103\n",
      "          Validation Loss (standardized): 0.9637635575589427\n",
      "Epoch: 86, Loss (standarized): 0.8579843714305355\n",
      "          Validation Loss (standardized): 0.9470891291500965\n",
      "Epoch: 91, Loss (standarized): 0.8385292913627922\n",
      "          Validation Loss (standardized): 0.9347731675950058\n",
      "Epoch: 96, Loss (standarized): 0.8195618473844999\n",
      "          Validation Loss (standardized): 0.9212559721200382\n",
      "Final epoch: 100, Final loss (standarized): 0.8043405587824608\n",
      "Epoch: 1, Loss (standarized): 3.0571896771437985\n",
      "          Validation Loss (standardized): 2.8305488544223407\n",
      "Epoch: 6, Loss (standarized): 1.6392231153522274\n",
      "          Validation Loss (standardized): 1.6716386829255652\n",
      "Epoch: 11, Loss (standarized): 1.3737696717781154\n",
      "          Validation Loss (standardized): 1.4517704226712476\n",
      "Epoch: 16, Loss (standarized): 1.3197682763985028\n",
      "          Validation Loss (standardized): 1.3417228208197862\n",
      "Epoch: 21, Loss (standarized): 1.2383312450322848\n",
      "          Validation Loss (standardized): 1.2702050692021571\n",
      "Epoch: 26, Loss (standarized): 1.1820973517272655\n",
      "          Validation Loss (standardized): 1.2300753043667787\n",
      "Epoch: 31, Loss (standarized): 1.1616433956281291\n",
      "          Validation Loss (standardized): 1.2086763162428906\n",
      "Epoch: 36, Loss (standarized): 1.1407711495891701\n",
      "          Validation Loss (standardized): 1.185737262911257\n",
      "Epoch: 41, Loss (standarized): 1.1206445594021872\n",
      "          Validation Loss (standardized): 1.1632101170832625\n",
      "Epoch: 46, Loss (standarized): 1.1012101840729838\n",
      "          Validation Loss (standardized): 1.161888947726487\n",
      "Epoch: 51, Loss (standarized): 1.0829892501992842\n",
      "          Validation Loss (standardized): 1.1639195974466316\n",
      "Epoch: 56, Loss (standarized): 1.0645893502881052\n",
      "          Validation Loss (standardized): 1.1411438924547592\n",
      "Epoch: 61, Loss (standarized): 1.0464432854477599\n",
      "          Validation Loss (standardized): 1.1165122780866572\n",
      "Epoch: 66, Loss (standarized): 1.0303672998966298\n",
      "          Validation Loss (standardized): 1.1092278679362484\n",
      "Epoch: 71, Loss (standarized): 1.0138426156436682\n",
      "          Validation Loss (standardized): 1.096339748516933\n",
      "Epoch: 76, Loss (standarized): 0.9974941365787106\n",
      "          Validation Loss (standardized): 1.0814296658353788\n",
      "Epoch: 81, Loss (standarized): 0.9805589985445531\n",
      "          Validation Loss (standardized): 1.0708766925082904\n",
      "Epoch: 86, Loss (standarized): 0.9641813310260726\n",
      "          Validation Loss (standardized): 1.0559238990979503\n",
      "Epoch: 91, Loss (standarized): 0.9488460163461656\n",
      "          Validation Loss (standardized): 1.0403456012959378\n",
      "Epoch: 96, Loss (standarized): 0.9327574796382812\n",
      "          Validation Loss (standardized): 1.0257465775163312\n",
      "Final epoch: 100, Final loss (standarized): 0.9200102780637027\n",
      "Epoch: 1, Loss (standarized): 2.093984130621497\n",
      "          Validation Loss (standardized): 2.057033684441615\n",
      "Epoch: 6, Loss (standarized): 1.5148679003734917\n",
      "          Validation Loss (standardized): 1.5858170080216591\n",
      "Epoch: 11, Loss (standarized): 1.3554907616016834\n",
      "          Validation Loss (standardized): 1.3882875040561395\n",
      "Epoch: 16, Loss (standarized): 1.2560676094515422\n",
      "          Validation Loss (standardized): 1.2754984700515448\n",
      "Epoch: 21, Loss (standarized): 1.1911025983754706\n",
      "          Validation Loss (standardized): 1.2016379308884393\n",
      "Epoch: 26, Loss (standarized): 1.1377184863558338\n",
      "          Validation Loss (standardized): 1.1799739075584508\n",
      "Epoch: 31, Loss (standarized): 1.0838699943810715\n",
      "          Validation Loss (standardized): 1.147892471593364\n",
      "Epoch: 36, Loss (standarized): 1.0283800921349828\n",
      "          Validation Loss (standardized): 1.117400533557644\n",
      "Epoch: 41, Loss (standarized): 0.9714084226521402\n",
      "          Validation Loss (standardized): 1.0730334145369036\n",
      "Epoch: 46, Loss (standarized): 0.9124823389629176\n",
      "          Validation Loss (standardized): 1.0122241082106336\n",
      "Epoch: 51, Loss (standarized): 0.85264147921344\n",
      "          Validation Loss (standardized): 0.9721051138978305\n",
      "Epoch: 56, Loss (standarized): 0.7909179023657148\n",
      "          Validation Loss (standardized): 0.9180931998910218\n",
      "Epoch: 61, Loss (standarized): 0.7331806405880351\n",
      "          Validation Loss (standardized): 0.8650123735422305\n",
      "Epoch: 66, Loss (standarized): 0.6742397703253229\n",
      "          Validation Loss (standardized): 0.8080311989854265\n",
      "Epoch: 71, Loss (standarized): 0.6138882526430807\n",
      "          Validation Loss (standardized): 0.7547879753701009\n",
      "Epoch: 76, Loss (standarized): 0.5556259289475975\n",
      "          Validation Loss (standardized): 0.7190231900822469\n",
      "Epoch: 81, Loss (standarized): 0.5039719551910434\n",
      "          Validation Loss (standardized): 0.6773051595173908\n",
      "Epoch: 86, Loss (standarized): 0.45803634625028494\n",
      "          Validation Loss (standardized): 0.6351279409128265\n",
      "Epoch: 91, Loss (standarized): 0.4185299354973421\n",
      "          Validation Loss (standardized): 0.6008016681630614\n",
      "Epoch: 96, Loss (standarized): 0.38302272336982524\n",
      "          Validation Loss (standardized): 0.5704253226775011\n",
      "Final epoch: 100, Final loss (standarized): 0.3573396206174864\n",
      "Epoch: 1, Loss (standarized): 2.5907628342166924\n",
      "          Validation Loss (standardized): 1.9025080804005716\n",
      "Epoch: 6, Loss (standarized): 1.4878851611117534\n",
      "          Validation Loss (standardized): 1.4706368875816516\n",
      "Epoch: 11, Loss (standarized): 1.3571159262825085\n",
      "          Validation Loss (standardized): 1.5505631719966217\n",
      "Epoch: 16, Loss (standarized): 1.2601750708700243\n",
      "          Validation Loss (standardized): 1.3240829034730681\n",
      "Epoch: 21, Loss (standarized): 1.2110052045973319\n",
      "          Validation Loss (standardized): 1.1916308690777229\n",
      "Epoch: 26, Loss (standarized): 1.1592118088357826\n",
      "          Validation Loss (standardized): 1.1863275058255067\n",
      "Epoch: 31, Loss (standarized): 1.1216846601797357\n",
      "          Validation Loss (standardized): 1.2105993455784543\n",
      "Epoch: 36, Loss (standarized): 1.0876598930431158\n",
      "          Validation Loss (standardized): 1.1701668390899675\n",
      "Epoch: 41, Loss (standarized): 1.057442286862436\n",
      "          Validation Loss (standardized): 1.1241283931077986\n",
      "Epoch: 46, Loss (standarized): 1.0225373153405852\n",
      "          Validation Loss (standardized): 1.0982083559146896\n",
      "Epoch: 51, Loss (standarized): 0.98906553395619\n",
      "          Validation Loss (standardized): 1.072985684735876\n",
      "Epoch: 56, Loss (standarized): 0.9545671400989286\n",
      "          Validation Loss (standardized): 1.0399626838122022\n",
      "Epoch: 61, Loss (standarized): 0.9178573794894771\n",
      "          Validation Loss (standardized): 1.018045627428453\n",
      "Epoch: 66, Loss (standarized): 0.8821231339824223\n",
      "          Validation Loss (standardized): 0.9894034655088242\n",
      "Epoch: 71, Loss (standarized): 0.8474979664648419\n",
      "          Validation Loss (standardized): 0.9529311216309864\n",
      "Epoch: 76, Loss (standarized): 0.8117704287381966\n",
      "          Validation Loss (standardized): 0.9241725450320168\n",
      "Epoch: 81, Loss (standarized): 0.7744982204089511\n",
      "          Validation Loss (standardized): 0.8880783909833379\n",
      "Epoch: 86, Loss (standarized): 0.7380556580412017\n",
      "          Validation Loss (standardized): 0.8554227187181682\n",
      "Epoch: 91, Loss (standarized): 0.7026040980016022\n",
      "          Validation Loss (standardized): 0.8216876332128602\n",
      "Epoch: 96, Loss (standarized): 0.6690165181143561\n",
      "          Validation Loss (standardized): 0.7880038224265827\n",
      "Final epoch: 100, Final loss (standarized): 0.6439403253051126\n",
      "Epoch: 1, Loss (standarized): 2.2166831526783723\n",
      "          Validation Loss (standardized): 2.4136589541855917\n",
      "Epoch: 6, Loss (standarized): 1.431741057231058\n",
      "          Validation Loss (standardized): 1.433946277776336\n",
      "Epoch: 11, Loss (standarized): 1.3338193969343433\n",
      "          Validation Loss (standardized): 1.3100092693740781\n",
      "Epoch: 16, Loss (standarized): 1.2687738604523575\n",
      "          Validation Loss (standardized): 1.3230782183448964\n",
      "Epoch: 21, Loss (standarized): 1.2247689419755645\n",
      "          Validation Loss (standardized): 1.2809561751045022\n",
      "Epoch: 26, Loss (standarized): 1.1734527350846269\n",
      "          Validation Loss (standardized): 1.197823353258747\n",
      "Epoch: 31, Loss (standarized): 1.1323852172770072\n",
      "          Validation Loss (standardized): 1.1551625302267292\n",
      "Epoch: 36, Loss (standarized): 1.093005283520648\n",
      "          Validation Loss (standardized): 1.159492190741508\n",
      "Epoch: 41, Loss (standarized): 1.0571087450211125\n",
      "          Validation Loss (standardized): 1.1492770255668083\n",
      "Epoch: 46, Loss (standarized): 1.0154165046235273\n",
      "          Validation Loss (standardized): 1.0992311110346995\n",
      "Epoch: 51, Loss (standarized): 0.9763078571424968\n",
      "          Validation Loss (standardized): 1.0638597569718835\n",
      "Epoch: 56, Loss (standarized): 0.9341089161183541\n",
      "          Validation Loss (standardized): 1.040249740504601\n",
      "Epoch: 61, Loss (standarized): 0.8908287111043363\n",
      "          Validation Loss (standardized): 1.001381940430223\n",
      "Epoch: 66, Loss (standarized): 0.8449540850927157\n",
      "          Validation Loss (standardized): 0.9606912798784634\n",
      "Epoch: 71, Loss (standarized): 0.7958312673364943\n",
      "          Validation Loss (standardized): 0.9221959424358831\n",
      "Epoch: 76, Loss (standarized): 0.7441507992373673\n",
      "          Validation Loss (standardized): 0.8778585492509494\n",
      "Epoch: 81, Loss (standarized): 0.689869674585808\n",
      "          Validation Loss (standardized): 0.8337131670592448\n",
      "Epoch: 86, Loss (standarized): 0.6357805359913482\n",
      "          Validation Loss (standardized): 0.7866852920802827\n",
      "Epoch: 91, Loss (standarized): 0.5861285565766461\n",
      "          Validation Loss (standardized): 0.7462042920295802\n",
      "Epoch: 96, Loss (standarized): 0.5398191030852879\n",
      "          Validation Loss (standardized): 0.7037608872826395\n",
      "Final epoch: 100, Final loss (standarized): 0.5053985350334752\n",
      "Epoch: 1, Loss (standarized): 1.7636520616564002\n",
      "          Validation Loss (standardized): 1.5515708353318969\n",
      "Epoch: 6, Loss (standarized): 1.4177991353945185\n",
      "          Validation Loss (standardized): 1.335925461050979\n",
      "Epoch: 11, Loss (standarized): 1.2818387302669358\n",
      "          Validation Loss (standardized): 1.3824631714653026\n",
      "Epoch: 16, Loss (standarized): 1.2015710011163605\n",
      "          Validation Loss (standardized): 1.2804247192673621\n",
      "Epoch: 21, Loss (standarized): 1.1418428818310273\n",
      "          Validation Loss (standardized): 1.1760534307781811\n",
      "Epoch: 26, Loss (standarized): 1.0826952840294082\n",
      "          Validation Loss (standardized): 1.1569856333377513\n",
      "Epoch: 31, Loss (standarized): 1.025399725683212\n",
      "          Validation Loss (standardized): 1.1063197291651488\n",
      "Epoch: 36, Loss (standarized): 0.9686062874434553\n",
      "          Validation Loss (standardized): 1.058173174752468\n",
      "Epoch: 41, Loss (standarized): 0.9095886119906953\n",
      "          Validation Loss (standardized): 1.011765640524882\n",
      "Epoch: 46, Loss (standarized): 0.8505955137876865\n",
      "          Validation Loss (standardized): 0.9622838961061877\n",
      "Epoch: 51, Loss (standarized): 0.7903993156370492\n",
      "          Validation Loss (standardized): 0.9119093198792887\n",
      "Epoch: 56, Loss (standarized): 0.7297927106664605\n",
      "          Validation Loss (standardized): 0.859263020303618\n",
      "Epoch: 61, Loss (standarized): 0.6737606708614475\n",
      "          Validation Loss (standardized): 0.8175148090262346\n",
      "Epoch: 66, Loss (standarized): 0.6209165316546279\n",
      "          Validation Loss (standardized): 0.7778662516088802\n",
      "Epoch: 71, Loss (standarized): 0.5704522168344041\n",
      "          Validation Loss (standardized): 0.7364206147670823\n",
      "Epoch: 76, Loss (standarized): 0.5247945332681978\n",
      "          Validation Loss (standardized): 0.7032233497758502\n",
      "Epoch: 81, Loss (standarized): 0.48274616826345346\n",
      "          Validation Loss (standardized): 0.6696309087731162\n",
      "Epoch: 86, Loss (standarized): 0.44398526404972694\n",
      "          Validation Loss (standardized): 0.6368753911993321\n",
      "Epoch: 91, Loss (standarized): 0.4085255110350631\n",
      "          Validation Loss (standardized): 0.6016675039102808\n",
      "Epoch: 96, Loss (standarized): 0.37535230063424263\n",
      "          Validation Loss (standardized): 0.5674046649529336\n",
      "Final epoch: 100, Final loss (standarized): 0.3510280162516915\n",
      "Epoch: 1, Loss (standarized): 3.393114394278162\n",
      "          Validation Loss (standardized): 3.2916528922147403\n",
      "Epoch: 6, Loss (standarized): 1.8726685488004058\n",
      "          Validation Loss (standardized): 1.7613282578886242\n",
      "Epoch: 11, Loss (standarized): 1.440999411963632\n",
      "          Validation Loss (standardized): 1.3767138749701193\n",
      "Epoch: 16, Loss (standarized): 1.3199543564138885\n",
      "          Validation Loss (standardized): 1.3192247616784576\n",
      "Epoch: 21, Loss (standarized): 1.2573486699201284\n",
      "          Validation Loss (standardized): 1.3081969057938185\n",
      "Epoch: 26, Loss (standarized): 1.2018058442772352\n",
      "          Validation Loss (standardized): 1.2744619703287268\n",
      "Epoch: 31, Loss (standarized): 1.1582155061035437\n",
      "          Validation Loss (standardized): 1.216287490199322\n",
      "Epoch: 36, Loss (standarized): 1.1126422582033775\n",
      "          Validation Loss (standardized): 1.1928708091340157\n",
      "Epoch: 41, Loss (standarized): 1.065111946201197\n",
      "          Validation Loss (standardized): 1.174094657629651\n",
      "Epoch: 46, Loss (standarized): 1.0121142881519645\n",
      "          Validation Loss (standardized): 1.1194165602342843\n",
      "Epoch: 51, Loss (standarized): 0.959522876729103\n",
      "          Validation Loss (standardized): 1.0855726307015234\n",
      "Epoch: 56, Loss (standarized): 0.9068287986916903\n",
      "          Validation Loss (standardized): 1.058611978641855\n",
      "Epoch: 61, Loss (standarized): 0.8559679351270049\n",
      "          Validation Loss (standardized): 1.0121471153085606\n",
      "Epoch: 66, Loss (standarized): 0.806601725781791\n",
      "          Validation Loss (standardized): 0.9738162848430141\n",
      "Epoch: 71, Loss (standarized): 0.7565748623967323\n",
      "          Validation Loss (standardized): 0.9263705713445066\n",
      "Epoch: 76, Loss (standarized): 0.706788788717125\n",
      "          Validation Loss (standardized): 0.8756117849484796\n",
      "Epoch: 81, Loss (standarized): 0.6594256439956889\n",
      "          Validation Loss (standardized): 0.8353343669537061\n",
      "Epoch: 86, Loss (standarized): 0.6140873356472242\n",
      "          Validation Loss (standardized): 0.7997996716524313\n",
      "Epoch: 91, Loss (standarized): 0.5706949926880478\n",
      "          Validation Loss (standardized): 0.7579078751271391\n",
      "Epoch: 96, Loss (standarized): 0.5306928136847681\n",
      "          Validation Loss (standardized): 0.7279504685414979\n",
      "Final epoch: 100, Final loss (standarized): 0.5011370702259217\n",
      "Epoch: 1, Loss (standarized): 3.194974585635821\n",
      "          Validation Loss (standardized): 2.742949300717643\n",
      "Epoch: 6, Loss (standarized): 1.6565432734571623\n",
      "          Validation Loss (standardized): 1.4823321347617038\n",
      "Epoch: 11, Loss (standarized): 1.4498412646422414\n",
      "          Validation Loss (standardized): 1.360654503944562\n",
      "Epoch: 16, Loss (standarized): 1.348208971327141\n",
      "          Validation Loss (standardized): 1.3456143105112652\n",
      "Epoch: 21, Loss (standarized): 1.2394903084799425\n",
      "          Validation Loss (standardized): 1.3547285781505993\n",
      "Epoch: 26, Loss (standarized): 1.2019586655301193\n",
      "          Validation Loss (standardized): 1.3216212483762024\n",
      "Epoch: 31, Loss (standarized): 1.1586262795492015\n",
      "          Validation Loss (standardized): 1.216890535760001\n",
      "Epoch: 36, Loss (standarized): 1.1331086336650626\n",
      "          Validation Loss (standardized): 1.1603040292856313\n",
      "Epoch: 41, Loss (standarized): 1.0956260698075029\n",
      "          Validation Loss (standardized): 1.1515971123766557\n",
      "Epoch: 46, Loss (standarized): 1.056459225603679\n",
      "          Validation Loss (standardized): 1.117660554976342\n",
      "Epoch: 51, Loss (standarized): 1.0154864101129106\n",
      "          Validation Loss (standardized): 1.0871481217056287\n",
      "Epoch: 56, Loss (standarized): 0.9725780878843137\n",
      "          Validation Loss (standardized): 1.0460643555103588\n",
      "Epoch: 61, Loss (standarized): 0.9287132732532248\n",
      "          Validation Loss (standardized): 1.0063398610394023\n",
      "Epoch: 66, Loss (standarized): 0.8853017426992089\n",
      "          Validation Loss (standardized): 0.9788025141152347\n",
      "Epoch: 71, Loss (standarized): 0.8441503560962118\n",
      "          Validation Loss (standardized): 0.94225942738464\n",
      "Epoch: 76, Loss (standarized): 0.8050594990100544\n",
      "          Validation Loss (standardized): 0.9101357756166799\n",
      "Epoch: 81, Loss (standarized): 0.7674603453708491\n",
      "          Validation Loss (standardized): 0.8750258660615631\n",
      "Epoch: 86, Loss (standarized): 0.7319582143409693\n",
      "          Validation Loss (standardized): 0.8480995547753261\n",
      "Epoch: 91, Loss (standarized): 0.6989357082181055\n",
      "          Validation Loss (standardized): 0.8233909798584202\n",
      "Epoch: 96, Loss (standarized): 0.6689493583562718\n",
      "          Validation Loss (standardized): 0.8009894517169722\n",
      "Final epoch: 100, Final loss (standarized): 0.646964358769373\n",
      "Epoch: 1, Loss (standarized): 2.3948049223450805\n",
      "          Validation Loss (standardized): 2.3241177668139534\n",
      "Epoch: 6, Loss (standarized): 1.4885350206440409\n",
      "          Validation Loss (standardized): 1.3955153513920642\n",
      "Epoch: 11, Loss (standarized): 1.2935622745026232\n",
      "          Validation Loss (standardized): 1.2477996962181632\n",
      "Epoch: 16, Loss (standarized): 1.2104847852461535\n",
      "          Validation Loss (standardized): 1.217549542798966\n",
      "Epoch: 21, Loss (standarized): 1.1816293207422162\n",
      "          Validation Loss (standardized): 1.1791250652198377\n",
      "Epoch: 26, Loss (standarized): 1.1308780230062982\n",
      "          Validation Loss (standardized): 1.1370477765683167\n",
      "Epoch: 31, Loss (standarized): 1.0884894750294374\n",
      "          Validation Loss (standardized): 1.1151052709165987\n",
      "Epoch: 36, Loss (standarized): 1.0553062062758278\n",
      "          Validation Loss (standardized): 1.093330809110343\n",
      "Epoch: 41, Loss (standarized): 1.0167179089270173\n",
      "          Validation Loss (standardized): 1.065788772420119\n",
      "Epoch: 46, Loss (standarized): 0.9754990926834475\n",
      "          Validation Loss (standardized): 1.0318188662261487\n",
      "Epoch: 51, Loss (standarized): 0.9344897474886631\n",
      "          Validation Loss (standardized): 1.009771373330504\n",
      "Epoch: 56, Loss (standarized): 0.8881193677838358\n",
      "          Validation Loss (standardized): 0.9756164931430449\n",
      "Epoch: 61, Loss (standarized): 0.8386765135868101\n",
      "          Validation Loss (standardized): 0.9266280858438923\n",
      "Epoch: 66, Loss (standarized): 0.7896197381127237\n",
      "          Validation Loss (standardized): 0.8963044681465112\n",
      "Epoch: 71, Loss (standarized): 0.738838976746489\n",
      "          Validation Loss (standardized): 0.8623843359758457\n",
      "Epoch: 76, Loss (standarized): 0.6897860621206248\n",
      "          Validation Loss (standardized): 0.8289828116291703\n",
      "Epoch: 81, Loss (standarized): 0.6453122683900392\n",
      "          Validation Loss (standardized): 0.7992443758888644\n",
      "Epoch: 86, Loss (standarized): 0.6045265911954469\n",
      "          Validation Loss (standardized): 0.7782599033847091\n",
      "Epoch: 91, Loss (standarized): 0.5667759620051617\n",
      "          Validation Loss (standardized): 0.7522830455609932\n",
      "Epoch: 96, Loss (standarized): 0.5320277347372475\n",
      "          Validation Loss (standardized): 0.7318623020535316\n",
      "Final epoch: 100, Final loss (standarized): 0.506515826246087\n",
      "Epoch: 1, Loss (standarized): 2.1104766640720642\n",
      "          Validation Loss (standardized): 1.9619621374692562\n",
      "Epoch: 6, Loss (standarized): 1.5321499813114594\n",
      "          Validation Loss (standardized): 1.5072852735254403\n",
      "Epoch: 11, Loss (standarized): 1.311317892224916\n",
      "          Validation Loss (standardized): 1.2566924435388738\n",
      "Epoch: 16, Loss (standarized): 1.1761883669718\n",
      "          Validation Loss (standardized): 1.1855184621062493\n",
      "Epoch: 21, Loss (standarized): 1.1065125951648473\n",
      "          Validation Loss (standardized): 1.1716258002047228\n",
      "Epoch: 26, Loss (standarized): 1.0592655631154173\n",
      "          Validation Loss (standardized): 1.1322500179704307\n",
      "Epoch: 31, Loss (standarized): 0.9999610238600738\n",
      "          Validation Loss (standardized): 1.0801239064857255\n",
      "Epoch: 36, Loss (standarized): 0.9361813632608846\n",
      "          Validation Loss (standardized): 1.031852969459164\n",
      "Epoch: 41, Loss (standarized): 0.868385858399677\n",
      "          Validation Loss (standardized): 0.979191756883631\n",
      "Epoch: 46, Loss (standarized): 0.8081946680038751\n",
      "          Validation Loss (standardized): 0.9313236908244951\n",
      "Epoch: 51, Loss (standarized): 0.7512243481189046\n",
      "          Validation Loss (standardized): 0.8864856028553081\n",
      "Epoch: 56, Loss (standarized): 0.6990475209026588\n",
      "          Validation Loss (standardized): 0.8448529210751248\n",
      "Epoch: 61, Loss (standarized): 0.6483678657701408\n",
      "          Validation Loss (standardized): 0.7919748014994944\n",
      "Epoch: 66, Loss (standarized): 0.6015977043806182\n",
      "          Validation Loss (standardized): 0.7449594472167834\n",
      "Epoch: 71, Loss (standarized): 0.5549378674786388\n",
      "          Validation Loss (standardized): 0.7047959681717896\n",
      "Epoch: 76, Loss (standarized): 0.5090954598029331\n",
      "          Validation Loss (standardized): 0.6582409494187982\n",
      "Epoch: 81, Loss (standarized): 0.46601067464606105\n",
      "          Validation Loss (standardized): 0.6192484746652753\n",
      "Epoch: 86, Loss (standarized): 0.4249151780764314\n",
      "          Validation Loss (standardized): 0.5813397636013751\n",
      "Epoch: 91, Loss (standarized): 0.38761932110141734\n",
      "          Validation Loss (standardized): 0.5510639386904919\n",
      "Epoch: 96, Loss (standarized): 0.3539571709656106\n",
      "          Validation Loss (standardized): 0.5243482451428072\n",
      "Final epoch: 100, Final loss (standarized): 0.32886634417104516\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "archs = [[2, 20, 20, 5]]\n",
    "funs = [sigmoid, tanh, relu, leaky_relu]\n",
    "fun_derivs = [sigmoid_deriv, tanh_deriv, relu_deriv, leaky_relu_deriv]\n",
    "dropouts = [0] # Testy dropout'u usunąłem\n",
    "early_stops = [0, 50, 100, 200, 500]  # Patience = 1 jest za mały tak samo = 5 oraz 10 i 20, więc usunąłem\n",
    "l1_vals = [0, 0.01, 0.001, 0.0001]\n",
    "l2_vals = [0, 0.01, 0.001, 0.0001]\n",
    "initialization = [\"xavier\", \"xavier\", \"he\", \"he\"]\n",
    "results = { \"Arch\": [],\n",
    "            \"Fun\": [],\n",
    "            \"Train_results\": [], \n",
    "            \"Dropout\": [],\n",
    "            \"Patience\": [],\n",
    "            \"Net\": [],\n",
    "            \"L1\": [],\n",
    "            \"L2\": [],\n",
    "            \"Fscore\": []}\n",
    "\n",
    "for arch in archs:\n",
    "    for i in range(len(funs)):\n",
    "        for dropout in dropouts:\n",
    "            for early_stop in early_stops:\n",
    "                for l1 in l1_vals:\n",
    "                    for l2 in l2_vals:\n",
    "                        net = MLP(arch, act_fun=funs[i], act_derivative=fun_derivs[i], out_fun=softmax, out_derivative=linear_deriv, init_type=initialization[i], dropout_rate=dropout)\n",
    "                        curr_result = net.train_classify(x = x_train, y = y_train, loss_fun=cross_entropy, epochs = 5000, optimizer=Adam(), batch_size=None, early_stopping_patience=early_stop, val_x=x_test, val_y=y_test, l1_lambda=l1, l2_lambda=l2)\n",
    "                        y_pred = net.predict(x_test)\n",
    "                        y_pred = from_one_hot_to_label(one_hot_from_probabilities(y_pred))\n",
    "                        fscore = f1_score(from_one_hot_to_label(y_test), y_pred)\n",
    "                        results[\"Arch\"].append(arch)\n",
    "                        results[\"Fun\"].append(funs[i])\n",
    "                        results[\"Fscore\"].append(fscore)\n",
    "                        results[\"Train_results\"].append(curr_result)\n",
    "                        results[\"Dropout\"].append(dropout)\n",
    "                        results[\"Patience\"].append(early_stop)\n",
    "                        results[\"Net\"].append(net)\n",
    "                        results[\"L1\"].append(l1)\n",
    "                        results[\"L2\"].append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a7f2bcc9-d26f-4f2c-8bd3-d8d01bd976d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>Fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.6909743737820657, 1.6538820695495264, 1.630...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01938AA0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.687406860356348, 1.644932707824799, 1.61963...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04AF8920&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[2.0079465943642436, 1.872891111904214, 1.7724...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E013C3260&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.7217866141885876, 1.679868746251545, 1.6498...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04E4B620&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.713329755559914, 1.6679501364972802, 1.6375...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0810C770&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.7877092605158345, 1.716686825854878, 1.6673...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E039E2C00&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.7537996444391082, 1.7002271637184148, 1.661...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79FDF500&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.6918160033086542, 1.6588727941627965, 1.636...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04E4B410&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.8316692422534349, 1.745952132685198, 1.6909...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05F14F20&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.041898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.6361728166896898, 1.6141962286547715, 1.605...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04B41F70&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.041898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.8671441229560608, 1.796256889493788, 1.7415...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04E481D0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.041898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.7839498309050048, 1.7174357144146666, 1.671...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A375C0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.053229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[2.011322672861445, 1.9149516823385218, 1.8329...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E7E235A30&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.053229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.6865070378277423, 1.6589537589424, 1.639385...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04AF8170&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.101270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.778917647946804, 1.6939651237472027, 1.6404...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E039C3770&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.101270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[2.136535367349408, 2.023020516559518, 1.92071...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A7B830&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.101270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.6460152109751758, 1.6264170569117806, 1.616...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04C66C90&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.101270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[2.0092469193639038, 1.8837037203606253, 1.790...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E039C0620&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.101937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.6355951292937365, 1.6188617734286614, 1.611...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05F4CB30&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.101937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>[1.8988415833215564, 1.813058965780387, 1.7495...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A7A270&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.101937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Arch                                       Fun  \\\n",
       "38  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "20  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "36  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "6   [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "22  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "23  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "68  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "53  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "39  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "5   [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "55  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "21  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "70  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "52  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "4   [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "71  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "69  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "7   [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "37  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "54  [2, 20, 20, 5]  <function sigmoid at 0x0000029E017B67A0>   \n",
       "\n",
       "                                        Train_results  Dropout  Patience  \\\n",
       "38  [1.6909743737820657, 1.6538820695495264, 1.630...        0       100   \n",
       "20  [1.687406860356348, 1.644932707824799, 1.61963...        0        50   \n",
       "36  [2.0079465943642436, 1.872891111904214, 1.7724...        0       100   \n",
       "6   [1.7217866141885876, 1.679868746251545, 1.6498...        0         0   \n",
       "22  [1.713329755559914, 1.6679501364972802, 1.6375...        0        50   \n",
       "23  [1.7877092605158345, 1.716686825854878, 1.6673...        0        50   \n",
       "68  [1.7537996444391082, 1.7002271637184148, 1.661...        0       500   \n",
       "53  [1.6918160033086542, 1.6588727941627965, 1.636...        0       200   \n",
       "39  [1.8316692422534349, 1.745952132685198, 1.6909...        0       100   \n",
       "5   [1.6361728166896898, 1.6141962286547715, 1.605...        0         0   \n",
       "55  [1.8671441229560608, 1.796256889493788, 1.7415...        0       200   \n",
       "21  [1.7839498309050048, 1.7174357144146666, 1.671...        0        50   \n",
       "70  [2.011322672861445, 1.9149516823385218, 1.8329...        0       500   \n",
       "52  [1.6865070378277423, 1.6589537589424, 1.639385...        0       200   \n",
       "4   [1.778917647946804, 1.6939651237472027, 1.6404...        0         0   \n",
       "71  [2.136535367349408, 2.023020516559518, 1.92071...        0       500   \n",
       "69  [1.6460152109751758, 1.6264170569117806, 1.616...        0       500   \n",
       "7   [2.0092469193639038, 1.8837037203606253, 1.790...        0         0   \n",
       "37  [1.6355951292937365, 1.6188617734286614, 1.611...        0       100   \n",
       "54  [1.8988415833215564, 1.813058965780387, 1.7495...        0       200   \n",
       "\n",
       "                                            Net    L1      L2    Fscore  \n",
       "38  <__main__.MLP object at 0x0000029E01938AA0>  0.01  0.0010  0.018503  \n",
       "20  <__main__.MLP object at 0x0000029E04AF8920>  0.01  0.0000  0.018503  \n",
       "36  <__main__.MLP object at 0x0000029E013C3260>  0.01  0.0000  0.018503  \n",
       "6   <__main__.MLP object at 0x0000029E04E4B620>  0.01  0.0010  0.018503  \n",
       "22  <__main__.MLP object at 0x0000029E0810C770>  0.01  0.0010  0.018503  \n",
       "23  <__main__.MLP object at 0x0000029E039E2C00>  0.01  0.0001  0.018503  \n",
       "68  <__main__.MLP object at 0x0000029E79FDF500>  0.01  0.0000  0.018503  \n",
       "53  <__main__.MLP object at 0x0000029E04E4B410>  0.01  0.0100  0.018503  \n",
       "39  <__main__.MLP object at 0x0000029E05F14F20>  0.01  0.0001  0.041898  \n",
       "5   <__main__.MLP object at 0x0000029E04B41F70>  0.01  0.0100  0.041898  \n",
       "55  <__main__.MLP object at 0x0000029E04E481D0>  0.01  0.0001  0.041898  \n",
       "21  <__main__.MLP object at 0x0000029E03A375C0>  0.01  0.0100  0.053229  \n",
       "70  <__main__.MLP object at 0x0000029E7E235A30>  0.01  0.0010  0.053229  \n",
       "52  <__main__.MLP object at 0x0000029E04AF8170>  0.01  0.0000  0.101270  \n",
       "4   <__main__.MLP object at 0x0000029E039C3770>  0.01  0.0000  0.101270  \n",
       "71  <__main__.MLP object at 0x0000029E03A7B830>  0.01  0.0001  0.101270  \n",
       "69  <__main__.MLP object at 0x0000029E04C66C90>  0.01  0.0100  0.101270  \n",
       "7   <__main__.MLP object at 0x0000029E039C0620>  0.01  0.0001  0.101937  \n",
       "37  <__main__.MLP object at 0x0000029E05F4CB30>  0.01  0.0100  0.101937  \n",
       "54  <__main__.MLP object at 0x0000029E03A7A270>  0.01  0.0010  0.101937  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(\"Fscore\")\n",
    "results_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e588bfb2-c047-45b8-bc2c-c25d643e75bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>Fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.821737435629375, 1.663853443805862, 1.54869...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE43B0&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.776273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[2.237999019029267, 2.0058532754510834, 1.8127...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A78EC0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.778219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.8040463267413815, 1.612487975169887, 1.4724...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE44A0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.778300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>[2.318296996687202, 2.047113850451435, 1.84020...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE4FB0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.778758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>[2.0180644810414248, 1.7645302730272305, 1.598...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05FFF710&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.782583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.7873029724305687, 1.6433370197666242, 1.539...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE4A10&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.784083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[2.543912708851538, 2.2368225683941017, 1.9863...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE7560&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.784691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>[2.0767183664021744, 1.8339690896738619, 1.660...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE6C60&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.784937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.7633439392456354, 1.6177789128262028, 1.508...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE5670&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.790273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.8127034582181905, 1.6318184850495476, 1.521...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05F4DCD0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.790919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>[1.7706998404775722, 1.6584859058561998, 1.579...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05F4F530&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.792059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.6583038586182786, 1.5100085888897388, 1.412...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE4350&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.799847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>[1.8563405485981648, 1.6687013987125432, 1.537...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04ACED50&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.800627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>[1.8608909629507226, 1.708715161148891, 1.5876...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04E48650&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.802845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.683584225014294, 1.5462611663451826, 1.4665...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04C676E0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.804506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.9739904249054603, 1.7860725463149865, 1.647...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04ACD0A0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.805677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>[2.1104766640720642, 1.9348404604847076, 1.808...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E013C23F0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.806359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.6107760056580542, 1.4744449968742401, 1.384...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E039D4320&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.810324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>[1.591705385345536, 1.500300897962085, 1.44105...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04ACFBF0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.811484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>[2, 20, 20, 5]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>[1.9187139890580494, 1.7555446981283698, 1.627...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05F6D580&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.815022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Arch                                          Fun  \\\n",
       "186  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "160  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "188  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "286  [2, 20, 20, 5]  <function leaky_relu at 0x0000029E039CE980>   \n",
       "280  [2, 20, 20, 5]  <function leaky_relu at 0x0000029E039CE980>   \n",
       "173  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "172  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "274  [2, 20, 20, 5]  <function leaky_relu at 0x0000029E039CE980>   \n",
       "226  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "163  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "287  [2, 20, 20, 5]  <function leaky_relu at 0x0000029E039CE980>   \n",
       "211  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "251  [2, 20, 20, 5]  <function leaky_relu at 0x0000029E039CE980>   \n",
       "288  [2, 20, 20, 5]  <function leaky_relu at 0x0000029E039CE980>   \n",
       "195  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "206  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "319  [2, 20, 20, 5]  <function leaky_relu at 0x0000029E039CE980>   \n",
       "235  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "194  [2, 20, 20, 5]        <function relu at 0x0000029E039CF2E0>   \n",
       "254  [2, 20, 20, 5]  <function leaky_relu at 0x0000029E039CE980>   \n",
       "\n",
       "                                         Train_results  Dropout  Patience  \\\n",
       "186  [1.821737435629375, 1.663853443805862, 1.54869...        0        50   \n",
       "160  [2.237999019029267, 2.0058532754510834, 1.8127...        0         0   \n",
       "188  [1.8040463267413815, 1.612487975169887, 1.4724...        0        50   \n",
       "286  [2.318296996687202, 2.047113850451435, 1.84020...        0       100   \n",
       "280  [2.0180644810414248, 1.7645302730272305, 1.598...        0       100   \n",
       "173  [1.7873029724305687, 1.6433370197666242, 1.539...        0         0   \n",
       "172  [2.543912708851538, 2.2368225683941017, 1.9863...        0         0   \n",
       "274  [2.0767183664021744, 1.8339690896738619, 1.660...        0       100   \n",
       "226  [1.7633439392456354, 1.6177789128262028, 1.508...        0       500   \n",
       "163  [1.8127034582181905, 1.6318184850495476, 1.521...        0         0   \n",
       "287  [1.7706998404775722, 1.6584859058561998, 1.579...        0       100   \n",
       "211  [1.6583038586182786, 1.5100085888897388, 1.412...        0       200   \n",
       "251  [1.8563405485981648, 1.6687013987125432, 1.537...        0         0   \n",
       "288  [1.8608909629507226, 1.708715161148891, 1.5876...        0       200   \n",
       "195  [1.683584225014294, 1.5462611663451826, 1.4665...        0       100   \n",
       "206  [1.9739904249054603, 1.7860725463149865, 1.647...        0       100   \n",
       "319  [2.1104766640720642, 1.9348404604847076, 1.808...        0       500   \n",
       "235  [1.6107760056580542, 1.4744449968742401, 1.384...        0       500   \n",
       "194  [1.591705385345536, 1.500300897962085, 1.44105...        0       100   \n",
       "254  [1.9187139890580494, 1.7555446981283698, 1.627...        0         0   \n",
       "\n",
       "                                             Net      L1      L2    Fscore  \n",
       "186  <__main__.MLP object at 0x0000029E04BE43B0>  0.0010  0.0010  0.776273  \n",
       "160  <__main__.MLP object at 0x0000029E03A78EC0>  0.0000  0.0000  0.778219  \n",
       "188  <__main__.MLP object at 0x0000029E04BE44A0>  0.0001  0.0000  0.778300  \n",
       "286  <__main__.MLP object at 0x0000029E04BE4FB0>  0.0001  0.0010  0.778758  \n",
       "280  <__main__.MLP object at 0x0000029E05FFF710>  0.0010  0.0000  0.782583  \n",
       "173  <__main__.MLP object at 0x0000029E04BE4A10>  0.0001  0.0100  0.784083  \n",
       "172  <__main__.MLP object at 0x0000029E04BE7560>  0.0001  0.0000  0.784691  \n",
       "274  <__main__.MLP object at 0x0000029E04BE6C60>  0.0000  0.0010  0.784937  \n",
       "226  <__main__.MLP object at 0x0000029E04BE5670>  0.0000  0.0010  0.790273  \n",
       "163  <__main__.MLP object at 0x0000029E05F4DCD0>  0.0000  0.0001  0.790919  \n",
       "287  <__main__.MLP object at 0x0000029E05F4F530>  0.0001  0.0001  0.792059  \n",
       "211  <__main__.MLP object at 0x0000029E04BE4350>  0.0000  0.0001  0.799847  \n",
       "251  <__main__.MLP object at 0x0000029E04ACED50>  0.0010  0.0001  0.800627  \n",
       "288  <__main__.MLP object at 0x0000029E04E48650>  0.0000  0.0000  0.802845  \n",
       "195  <__main__.MLP object at 0x0000029E04C676E0>  0.0000  0.0001  0.804506  \n",
       "206  <__main__.MLP object at 0x0000029E04ACD0A0>  0.0001  0.0010  0.805677  \n",
       "319  <__main__.MLP object at 0x0000029E013C23F0>  0.0001  0.0001  0.806359  \n",
       "235  <__main__.MLP object at 0x0000029E039D4320>  0.0010  0.0001  0.810324  \n",
       "194  <__main__.MLP object at 0x0000029E04ACFBF0>  0.0000  0.0010  0.811484  \n",
       "254  <__main__.MLP object at 0x0000029E05F6D580>  0.0001  0.0010  0.815022  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27b576-068a-4d66-a733-583b6c94e1a1",
   "metadata": {},
   "source": [
    "## Dane rings3-balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e55fca-9ab6-4641-a90b-d0cbec510eff",
   "metadata": {},
   "source": [
    "### Pobranie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "297660b8-dd8e-4874-a78e-0f8ef42f73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobieramy dane\n",
    "data_train = pd.read_csv(\"../Data/classification/rings3-balance-training.csv\").to_numpy()\n",
    "x_train = data_train[:, 0:2].reshape(-1, 2)\n",
    "y_train = one_hot(np.int64(data_train[:, 2]))\n",
    "\n",
    "data_test = pd.read_csv(\"../Data/classification/rings3-balance-test.csv\").to_numpy()\n",
    "x_test = data_test[:, 0:2].reshape(-1, 2)\n",
    "y_test = one_hot(np.int64(data_test[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a08c1aad-287b-4952-b897-41b640623e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-51.44441002,  96.40676617,   0.        ],\n",
       "       [ 35.5127634 ,  11.8805334 ,   0.        ],\n",
       "       [  3.50474045,  16.61240323,   0.        ],\n",
       "       ...,\n",
       "       [ 52.08190489, -85.68621627,   2.        ],\n",
       "       [-21.63032037,  61.7781024 ,   2.        ],\n",
       "       [-21.77091497,  77.73783407,   2.        ]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9040f20b-cf81-4fd7-820b-6eb4d7cf7ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2060, 3)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "600c7e02-7552-4640-8df2-f977ab59e156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train[:, 0], x_train[:, 1], c = data_train[:, 2], s = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec968332-5516-4258-b958-47ad44053401",
   "metadata": {},
   "source": [
    "### Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dc94f75b-fd8b-43ae-8765-6dbeb669a553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss (standarized): 1.0251299204145154\n",
      "Epoch: 6, Loss (standarized): 0.8319856037316221\n",
      "Epoch: 11, Loss (standarized): 0.7995738633390642\n",
      "Epoch: 16, Loss (standarized): 0.7823581519159262\n",
      "Epoch: 21, Loss (standarized): 0.7584577096394733\n",
      "Epoch: 26, Loss (standarized): 0.7269142732319708\n",
      "Epoch: 31, Loss (standarized): 0.6934404543371943\n",
      "Epoch: 36, Loss (standarized): 0.667469033775727\n",
      "Epoch: 41, Loss (standarized): 0.6559763419309883\n",
      "Epoch: 46, Loss (standarized): 0.6560548004731844\n",
      "Epoch: 51, Loss (standarized): 0.6576937362051067\n",
      "Epoch: 56, Loss (standarized): 0.6558700169778899\n",
      "Epoch: 61, Loss (standarized): 0.6527895441262023\n",
      "Epoch: 66, Loss (standarized): 0.6511821549019648\n",
      "Epoch: 71, Loss (standarized): 0.6508383739498315\n",
      "Epoch: 76, Loss (standarized): 0.650409513546997\n",
      "Epoch: 81, Loss (standarized): 0.649582058519075\n",
      "Epoch: 86, Loss (standarized): 0.6488206125554539\n",
      "Epoch: 91, Loss (standarized): 0.6482854161269135\n",
      "Epoch: 96, Loss (standarized): 0.6477776939766321\n",
      "Final epoch: 100, Final loss (standarized): 0.647341790191972\n",
      "Epoch: 1, Loss (standarized): 1.4184368683005248\n",
      "Epoch: 6, Loss (standarized): 0.8939024016273449\n",
      "Epoch: 11, Loss (standarized): 0.7851654630891416\n",
      "Epoch: 16, Loss (standarized): 0.7670652127390999\n",
      "Epoch: 21, Loss (standarized): 0.7593581588241604\n",
      "Epoch: 26, Loss (standarized): 0.7493654496032591\n",
      "Epoch: 31, Loss (standarized): 0.7355566766577023\n",
      "Epoch: 36, Loss (standarized): 0.7199604512608683\n",
      "Epoch: 41, Loss (standarized): 0.7053872700603913\n",
      "Epoch: 46, Loss (standarized): 0.6937449199772584\n",
      "Epoch: 51, Loss (standarized): 0.6852696101288631\n",
      "Epoch: 56, Loss (standarized): 0.6793105479676822\n",
      "Epoch: 61, Loss (standarized): 0.6747773976408059\n",
      "Epoch: 66, Loss (standarized): 0.6716434685442985\n",
      "Epoch: 71, Loss (standarized): 0.6696777326411837\n",
      "Epoch: 76, Loss (standarized): 0.6684945616489238\n",
      "Epoch: 81, Loss (standarized): 0.6674831016187758\n",
      "Epoch: 86, Loss (standarized): 0.6664139130106215\n",
      "Epoch: 91, Loss (standarized): 0.6652727968237687\n",
      "Epoch: 96, Loss (standarized): 0.6642576151110753\n",
      "Final epoch: 100, Final loss (standarized): 0.6635937035778153\n",
      "Epoch: 1, Loss (standarized): 1.1004452098008584\n",
      "Epoch: 6, Loss (standarized): 0.8226469486451127\n",
      "Epoch: 11, Loss (standarized): 0.7785167654365954\n",
      "Epoch: 16, Loss (standarized): 0.7691405324760263\n",
      "Epoch: 21, Loss (standarized): 0.7538517467018748\n",
      "Epoch: 26, Loss (standarized): 0.7306465151069363\n",
      "Epoch: 31, Loss (standarized): 0.7042805543601239\n",
      "Epoch: 36, Loss (standarized): 0.6805315113589708\n",
      "Epoch: 41, Loss (standarized): 0.664236799373668\n",
      "Epoch: 46, Loss (standarized): 0.6568805576917923\n",
      "Epoch: 51, Loss (standarized): 0.6553762707665169\n",
      "Epoch: 56, Loss (standarized): 0.6548685858857038\n",
      "Epoch: 61, Loss (standarized): 0.653169001729526\n",
      "Epoch: 66, Loss (standarized): 0.6512701109945593\n",
      "Epoch: 71, Loss (standarized): 0.650473125743792\n",
      "Epoch: 76, Loss (standarized): 0.6503386281055509\n",
      "Epoch: 81, Loss (standarized): 0.6498036409054799\n",
      "Epoch: 86, Loss (standarized): 0.6488950152935986\n",
      "Epoch: 91, Loss (standarized): 0.6481500053275474\n",
      "Epoch: 96, Loss (standarized): 0.6476427361399546\n",
      "Final epoch: 100, Final loss (standarized): 0.647302415460196\n",
      "Epoch: 1, Loss (standarized): 1.762256667491119\n",
      "Epoch: 6, Loss (standarized): 1.0706146973342148\n",
      "Epoch: 11, Loss (standarized): 0.8315194019332874\n",
      "Epoch: 16, Loss (standarized): 0.782429625933391\n",
      "Epoch: 21, Loss (standarized): 0.7532869069580019\n",
      "Epoch: 26, Loss (standarized): 0.7409988869047396\n",
      "Epoch: 31, Loss (standarized): 0.7225293995155238\n",
      "Epoch: 36, Loss (standarized): 0.7042183619188331\n",
      "Epoch: 41, Loss (standarized): 0.6858729106835815\n",
      "Epoch: 46, Loss (standarized): 0.6703624531593554\n",
      "Epoch: 51, Loss (standarized): 0.6609784313689546\n",
      "Epoch: 56, Loss (standarized): 0.6564379056146838\n",
      "Epoch: 61, Loss (standarized): 0.6552396816191682\n",
      "Epoch: 66, Loss (standarized): 0.6549614307923302\n",
      "Epoch: 71, Loss (standarized): 0.6543932776896426\n",
      "Epoch: 76, Loss (standarized): 0.6535671382143053\n",
      "Epoch: 81, Loss (standarized): 0.652725914741276\n",
      "Epoch: 86, Loss (standarized): 0.6520829737425212\n",
      "Epoch: 91, Loss (standarized): 0.6516401105238994\n",
      "Epoch: 96, Loss (standarized): 0.6512732251532843\n",
      "Final epoch: 100, Final loss (standarized): 0.6509771265515141\n",
      "Epoch: 1, Loss (standarized): 1.586399508793111\n",
      "Epoch: 6, Loss (standarized): 0.9913160370339112\n",
      "Epoch: 11, Loss (standarized): 0.8270400195917857\n",
      "Epoch: 16, Loss (standarized): 0.7907806421000679\n",
      "Epoch: 21, Loss (standarized): 0.7893626246434919\n",
      "Epoch: 26, Loss (standarized): 0.7907915680778674\n",
      "Epoch: 31, Loss (standarized): 0.7954865053682264\n",
      "Epoch: 36, Loss (standarized): 0.7981640486691108\n",
      "Epoch: 41, Loss (standarized): 0.8014863280010702\n",
      "Epoch: 46, Loss (standarized): 0.8041509355586512\n",
      "Epoch: 51, Loss (standarized): 0.8052342655528569\n",
      "Epoch: 56, Loss (standarized): 0.8062387506383184\n",
      "Epoch: 61, Loss (standarized): 0.8073255366481559\n",
      "Epoch: 66, Loss (standarized): 0.8071352933963412\n",
      "Epoch: 71, Loss (standarized): 0.8070459568007435\n",
      "Epoch: 76, Loss (standarized): 0.8069880414134967\n",
      "Epoch: 81, Loss (standarized): 0.8068771325571468\n",
      "Epoch: 86, Loss (standarized): 0.8065614559522446\n",
      "Epoch: 91, Loss (standarized): 0.8063939679622754\n",
      "Epoch: 96, Loss (standarized): 0.8064030865969231\n",
      "Final epoch: 100, Final loss (standarized): 0.8062979129862535\n",
      "Epoch: 1, Loss (standarized): 1.8047496845383273\n",
      "Epoch: 6, Loss (standarized): 1.1405854557384758\n",
      "Epoch: 11, Loss (standarized): 0.8881305885497405\n",
      "Epoch: 16, Loss (standarized): 0.8273795135319573\n",
      "Epoch: 21, Loss (standarized): 0.8070465410700648\n",
      "Epoch: 26, Loss (standarized): 0.8049789771585764\n",
      "Epoch: 31, Loss (standarized): 0.8036598142419363\n",
      "Epoch: 36, Loss (standarized): 0.805475915242071\n",
      "Epoch: 41, Loss (standarized): 0.8059765152195507\n",
      "Epoch: 46, Loss (standarized): 0.8065866096991253\n",
      "Epoch: 51, Loss (standarized): 0.8070331188840558\n",
      "Epoch: 56, Loss (standarized): 0.8074803358921562\n",
      "Epoch: 61, Loss (standarized): 0.8081320629403823\n",
      "Epoch: 66, Loss (standarized): 0.8084945431510941\n",
      "Epoch: 71, Loss (standarized): 0.8085650470971832\n",
      "Epoch: 76, Loss (standarized): 0.8084224705065549\n",
      "Epoch: 81, Loss (standarized): 0.8081990572670988\n",
      "Epoch: 86, Loss (standarized): 0.8081672509403545\n",
      "Epoch: 91, Loss (standarized): 0.8081033818324944\n",
      "Epoch: 96, Loss (standarized): 0.8081235074696619\n",
      "Final epoch: 100, Final loss (standarized): 0.8082190402530481\n",
      "Epoch: 1, Loss (standarized): 0.9655826707994906\n",
      "Epoch: 6, Loss (standarized): 0.8254787493761101\n",
      "Epoch: 11, Loss (standarized): 0.8068218718498092\n",
      "Epoch: 16, Loss (standarized): 0.8047523361053398\n",
      "Epoch: 21, Loss (standarized): 0.8045472909751686\n",
      "Epoch: 26, Loss (standarized): 0.8047806578523703\n",
      "Epoch: 31, Loss (standarized): 0.8055439152083809\n",
      "Epoch: 36, Loss (standarized): 0.8067704648367188\n",
      "Epoch: 41, Loss (standarized): 0.807521583722902\n",
      "Epoch: 46, Loss (standarized): 0.8075479835443713\n",
      "Epoch: 51, Loss (standarized): 0.8077566689659801\n",
      "Epoch: 56, Loss (standarized): 0.8081993259243921\n",
      "Epoch: 61, Loss (standarized): 0.8082875023310832\n",
      "Epoch: 66, Loss (standarized): 0.8076835282020908\n",
      "Epoch: 71, Loss (standarized): 0.807242384796094\n",
      "Epoch: 76, Loss (standarized): 0.807008200849899\n",
      "Epoch: 81, Loss (standarized): 0.8070519763320562\n",
      "Epoch: 86, Loss (standarized): 0.8070988696489906\n",
      "Epoch: 91, Loss (standarized): 0.8071595286306323\n",
      "Epoch: 96, Loss (standarized): 0.8070833690567654\n",
      "Final epoch: 100, Final loss (standarized): 0.8072007943932352\n",
      "Epoch: 1, Loss (standarized): 0.9293391806694632\n",
      "Epoch: 6, Loss (standarized): 0.8320297968054414\n",
      "Epoch: 11, Loss (standarized): 0.8098579630184529\n",
      "Epoch: 16, Loss (standarized): 0.80753369395455\n",
      "Epoch: 21, Loss (standarized): 0.8064069599934613\n",
      "Epoch: 26, Loss (standarized): 0.8054926177941856\n",
      "Epoch: 31, Loss (standarized): 0.8053175195725721\n",
      "Epoch: 36, Loss (standarized): 0.8066214567019029\n",
      "Epoch: 41, Loss (standarized): 0.8075806810102955\n",
      "Epoch: 46, Loss (standarized): 0.807422972100248\n",
      "Epoch: 51, Loss (standarized): 0.807438512253229\n",
      "Epoch: 56, Loss (standarized): 0.8075508434422622\n",
      "Epoch: 61, Loss (standarized): 0.808168361057856\n",
      "Epoch: 66, Loss (standarized): 0.8083701866826519\n",
      "Epoch: 71, Loss (standarized): 0.8080644193109402\n",
      "Epoch: 76, Loss (standarized): 0.807789761868862\n",
      "Epoch: 81, Loss (standarized): 0.8079447629889552\n",
      "Epoch: 86, Loss (standarized): 0.8077052622544836\n",
      "Epoch: 91, Loss (standarized): 0.8073699295833145\n",
      "Epoch: 96, Loss (standarized): 0.8072042782226624\n",
      "Final epoch: 100, Final loss (standarized): 0.8073666871801605\n",
      "Epoch: 1, Loss (standarized): 0.9578959133837953\n",
      "Epoch: 6, Loss (standarized): 0.803171203465305\n",
      "Epoch: 11, Loss (standarized): 0.7968704628556452\n",
      "Epoch: 16, Loss (standarized): 0.7931347275356988\n",
      "Epoch: 21, Loss (standarized): 0.7786798689273212\n",
      "Epoch: 26, Loss (standarized): 0.7580231955262589\n",
      "Epoch: 31, Loss (standarized): 0.7358075873202324\n",
      "Epoch: 36, Loss (standarized): 0.7115914257457014\n",
      "Epoch: 41, Loss (standarized): 0.6851855251872774\n",
      "Epoch: 46, Loss (standarized): 0.6643446579691925\n",
      "Epoch: 51, Loss (standarized): 0.6549463681078975\n",
      "Epoch: 56, Loss (standarized): 0.6530177448762686\n",
      "Epoch: 61, Loss (standarized): 0.6524469205921544\n",
      "Epoch: 66, Loss (standarized): 0.6521506207963624\n",
      "Epoch: 71, Loss (standarized): 0.6528560713314775\n",
      "Epoch: 76, Loss (standarized): 0.6538028932956805\n",
      "Epoch: 81, Loss (standarized): 0.6538628972673587\n",
      "Epoch: 86, Loss (standarized): 0.6531503074019324\n",
      "Epoch: 91, Loss (standarized): 0.6522576174364005\n",
      "Epoch: 96, Loss (standarized): 0.6516647025177581\n",
      "Final epoch: 100, Final loss (standarized): 0.6514602455243758\n",
      "Epoch: 1, Loss (standarized): 1.1162141735356494\n",
      "Epoch: 6, Loss (standarized): 0.8458527496883734\n",
      "Epoch: 11, Loss (standarized): 0.7920059679018212\n",
      "Epoch: 16, Loss (standarized): 0.7878701092877759\n",
      "Epoch: 21, Loss (standarized): 0.7790294755868314\n",
      "Epoch: 26, Loss (standarized): 0.7733258346271101\n",
      "Epoch: 31, Loss (standarized): 0.7657862231719649\n",
      "Epoch: 36, Loss (standarized): 0.7583465157927551\n",
      "Epoch: 41, Loss (standarized): 0.752610307707837\n",
      "Epoch: 46, Loss (standarized): 0.7466553568215683\n",
      "Epoch: 51, Loss (standarized): 0.7395000859405091\n",
      "Epoch: 56, Loss (standarized): 0.731751387486281\n",
      "Epoch: 61, Loss (standarized): 0.7236010754136016\n",
      "Epoch: 66, Loss (standarized): 0.7150729149207058\n",
      "Epoch: 71, Loss (standarized): 0.7069531584657633\n",
      "Epoch: 76, Loss (standarized): 0.6994774788150572\n",
      "Epoch: 81, Loss (standarized): 0.6931138644335758\n",
      "Epoch: 86, Loss (standarized): 0.6880163703635648\n",
      "Epoch: 91, Loss (standarized): 0.684205338977133\n",
      "Epoch: 96, Loss (standarized): 0.6814202923172673\n",
      "Final epoch: 100, Final loss (standarized): 0.6797786871129166\n",
      "Epoch: 1, Loss (standarized): 1.0037396059302497\n",
      "Epoch: 6, Loss (standarized): 0.8138739341220543\n",
      "Epoch: 11, Loss (standarized): 0.7945723442630048\n",
      "Epoch: 16, Loss (standarized): 0.7917580672875718\n",
      "Epoch: 21, Loss (standarized): 0.7794990464776145\n",
      "Epoch: 26, Loss (standarized): 0.7593295925434937\n",
      "Epoch: 31, Loss (standarized): 0.7352554412809075\n",
      "Epoch: 36, Loss (standarized): 0.7101697825822394\n",
      "Epoch: 41, Loss (standarized): 0.6859726832847064\n",
      "Epoch: 46, Loss (standarized): 0.6666193787736705\n",
      "Epoch: 51, Loss (standarized): 0.6563649892414009\n",
      "Epoch: 56, Loss (standarized): 0.6533165207836541\n",
      "Epoch: 61, Loss (standarized): 0.652583414825863\n",
      "Epoch: 66, Loss (standarized): 0.6526286014492871\n",
      "Epoch: 71, Loss (standarized): 0.6537055999779802\n",
      "Epoch: 76, Loss (standarized): 0.6549750534008942\n",
      "Epoch: 81, Loss (standarized): 0.6552350096197019\n",
      "Epoch: 86, Loss (standarized): 0.6545278418855389\n",
      "Epoch: 91, Loss (standarized): 0.6535999889969968\n",
      "Epoch: 96, Loss (standarized): 0.6529263193003683\n",
      "Final epoch: 100, Final loss (standarized): 0.6526531401589257\n",
      "Epoch: 1, Loss (standarized): 0.9881662043372474\n",
      "Epoch: 6, Loss (standarized): 0.8351688137316742\n",
      "Epoch: 11, Loss (standarized): 0.8023475311014062\n",
      "Epoch: 16, Loss (standarized): 0.7958967006716196\n",
      "Epoch: 21, Loss (standarized): 0.7740557392414885\n",
      "Epoch: 26, Loss (standarized): 0.7649447882192256\n",
      "Epoch: 31, Loss (standarized): 0.7475524887359405\n",
      "Epoch: 36, Loss (standarized): 0.7347382612150454\n",
      "Epoch: 41, Loss (standarized): 0.7167637684408616\n",
      "Epoch: 46, Loss (standarized): 0.7012278145217348\n",
      "Epoch: 51, Loss (standarized): 0.6861460657210164\n",
      "Epoch: 56, Loss (standarized): 0.6736856967506439\n",
      "Epoch: 61, Loss (standarized): 0.665106055385071\n",
      "Epoch: 66, Loss (standarized): 0.6598978068694018\n",
      "Epoch: 71, Loss (standarized): 0.6571993076540427\n",
      "Epoch: 76, Loss (standarized): 0.6560205915265392\n",
      "Epoch: 81, Loss (standarized): 0.655535075680553\n",
      "Epoch: 86, Loss (standarized): 0.6553895168038014\n",
      "Epoch: 91, Loss (standarized): 0.6554548629204693\n",
      "Epoch: 96, Loss (standarized): 0.6555915555341897\n",
      "Final epoch: 100, Final loss (standarized): 0.6557869689178524\n",
      "Epoch: 1, Loss (standarized): 1.044634790255931\n",
      "Epoch: 6, Loss (standarized): 0.8153980489332014\n",
      "Epoch: 11, Loss (standarized): 0.7837709921173\n",
      "Epoch: 16, Loss (standarized): 0.7749161762496309\n",
      "Epoch: 21, Loss (standarized): 0.7593769543250249\n",
      "Epoch: 26, Loss (standarized): 0.7352482271244287\n",
      "Epoch: 31, Loss (standarized): 0.7067399813081523\n",
      "Epoch: 36, Loss (standarized): 0.6811054754316181\n",
      "Epoch: 41, Loss (standarized): 0.6654849527335797\n",
      "Epoch: 46, Loss (standarized): 0.6611070524511733\n",
      "Epoch: 51, Loss (standarized): 0.6612893926902584\n",
      "Epoch: 56, Loss (standarized): 0.6594869646281453\n",
      "Epoch: 61, Loss (standarized): 0.6559031551043685\n",
      "Epoch: 66, Loss (standarized): 0.6537390404133763\n",
      "Epoch: 71, Loss (standarized): 0.6529121136497489\n",
      "Epoch: 76, Loss (standarized): 0.6517813444480369\n",
      "Epoch: 81, Loss (standarized): 0.6503700948230811\n",
      "Epoch: 86, Loss (standarized): 0.6492305975786533\n",
      "Epoch: 91, Loss (standarized): 0.6482630225918886\n",
      "Epoch: 96, Loss (standarized): 0.6473249183324176\n",
      "Final epoch: 100, Final loss (standarized): 0.6466590670575119\n",
      "Epoch: 1, Loss (standarized): 1.0166698759518065\n",
      "Epoch: 6, Loss (standarized): 0.8096209448517964\n",
      "Epoch: 11, Loss (standarized): 0.7811172424831542\n",
      "Epoch: 16, Loss (standarized): 0.7759502871205736\n",
      "Epoch: 21, Loss (standarized): 0.7656571422941335\n",
      "Epoch: 26, Loss (standarized): 0.7495757017796714\n",
      "Epoch: 31, Loss (standarized): 0.7311074487479645\n",
      "Epoch: 36, Loss (standarized): 0.7125712921543909\n",
      "Epoch: 41, Loss (standarized): 0.6942242322536197\n",
      "Epoch: 46, Loss (standarized): 0.6776575505766854\n",
      "Epoch: 51, Loss (standarized): 0.6663609147042225\n",
      "Epoch: 56, Loss (standarized): 0.6611792215304351\n",
      "Epoch: 61, Loss (standarized): 0.660246453998272\n",
      "Epoch: 66, Loss (standarized): 0.6615670906352806\n",
      "Epoch: 71, Loss (standarized): 0.6631391804664886\n",
      "Epoch: 76, Loss (standarized): 0.6632815257981296\n",
      "Epoch: 81, Loss (standarized): 0.6619172441386242\n",
      "Epoch: 86, Loss (standarized): 0.6602360084643203\n",
      "Epoch: 91, Loss (standarized): 0.659266494258769\n",
      "Epoch: 96, Loss (standarized): 0.6591888699428504\n",
      "Final epoch: 100, Final loss (standarized): 0.6594669476574377\n",
      "Epoch: 1, Loss (standarized): 0.9181574634566269\n",
      "Epoch: 6, Loss (standarized): 0.8099239150610137\n",
      "Epoch: 11, Loss (standarized): 0.7926546499003685\n",
      "Epoch: 16, Loss (standarized): 0.7771946369365964\n",
      "Epoch: 21, Loss (standarized): 0.7562256700118984\n",
      "Epoch: 26, Loss (standarized): 0.7317757896679699\n",
      "Epoch: 31, Loss (standarized): 0.7084832636103991\n",
      "Epoch: 36, Loss (standarized): 0.6858289109438722\n",
      "Epoch: 41, Loss (standarized): 0.6682318838497318\n",
      "Epoch: 46, Loss (standarized): 0.6602228694156078\n",
      "Epoch: 51, Loss (standarized): 0.6582622835723748\n",
      "Epoch: 56, Loss (standarized): 0.6571414157202465\n",
      "Epoch: 61, Loss (standarized): 0.6555077413289695\n",
      "Epoch: 66, Loss (standarized): 0.6541037625743193\n",
      "Epoch: 71, Loss (standarized): 0.6534163120160115\n",
      "Epoch: 76, Loss (standarized): 0.6531538761703696\n",
      "Epoch: 81, Loss (standarized): 0.6526802226014026\n",
      "Epoch: 86, Loss (standarized): 0.6518434631642249\n",
      "Epoch: 91, Loss (standarized): 0.6509725499988034\n",
      "Epoch: 96, Loss (standarized): 0.6502685057505071\n",
      "Final epoch: 100, Final loss (standarized): 0.6498454637280221\n",
      "Epoch: 1, Loss (standarized): 0.8481657872631883\n",
      "Epoch: 6, Loss (standarized): 0.7743779381747551\n",
      "Epoch: 11, Loss (standarized): 0.7528190549169836\n",
      "Epoch: 16, Loss (standarized): 0.7275878697252641\n",
      "Epoch: 21, Loss (standarized): 0.6960773306410994\n",
      "Epoch: 26, Loss (standarized): 0.6688237055647872\n",
      "Epoch: 31, Loss (standarized): 0.6551858923786609\n",
      "Epoch: 36, Loss (standarized): 0.6538647555488613\n",
      "Epoch: 41, Loss (standarized): 0.6553636374057612\n",
      "Epoch: 46, Loss (standarized): 0.65388362052113\n",
      "Epoch: 51, Loss (standarized): 0.6512980148320662\n",
      "Epoch: 56, Loss (standarized): 0.6502057909089823\n",
      "Epoch: 61, Loss (standarized): 0.6501675854773608\n",
      "Epoch: 66, Loss (standarized): 0.649827356033082\n",
      "Epoch: 71, Loss (standarized): 0.6490022480257727\n",
      "Epoch: 76, Loss (standarized): 0.648235484412893\n",
      "Epoch: 81, Loss (standarized): 0.6477284441619158\n",
      "Epoch: 86, Loss (standarized): 0.6473192323281446\n",
      "Epoch: 91, Loss (standarized): 0.6469438624494295\n",
      "Epoch: 96, Loss (standarized): 0.646628173986397\n",
      "Final epoch: 100, Final loss (standarized): 0.6463938909605419\n",
      "Epoch: 1, Loss (standarized): 1.0226634267624117\n",
      "          Validation Loss (standardized): 1.2495857999473552\n",
      "Epoch: 6, Loss (standarized): 0.8343910342895556\n",
      "          Validation Loss (standardized): 1.6025636211016137\n",
      "Epoch: 11, Loss (standarized): 0.7959901093143733\n",
      "          Validation Loss (standardized): 1.8993455701496138\n",
      "Epoch: 16, Loss (standarized): 0.7959723281943902\n",
      "          Validation Loss (standardized): 2.053990410697224\n",
      "Epoch: 21, Loss (standarized): 0.7794448921723464\n",
      "          Validation Loss (standardized): 2.0727813761518736\n",
      "Epoch: 26, Loss (standarized): 0.7620566903797674\n",
      "          Validation Loss (standardized): 1.98263508521598\n",
      "Epoch: 31, Loss (standarized): 0.740487129543059\n",
      "          Validation Loss (standardized): 1.8515855872857254\n",
      "Epoch: 36, Loss (standarized): 0.7170131452248758\n",
      "          Validation Loss (standardized): 1.7339691525920566\n",
      "Epoch: 41, Loss (standarized): 0.6960910979145075\n",
      "          Validation Loss (standardized): 1.6566608948689505\n",
      "Epoch: 46, Loss (standarized): 0.6771831252645484\n",
      "          Validation Loss (standardized): 1.6323403019131129\n",
      "Epoch: 51, Loss (standarized): 0.6630842862941009\n",
      "          Validation Loss (standardized): 1.6539799702697737\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6563086424952873\n",
      "          Validation Loss (standardized): 1.6926945648831206\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6550441858428726\n",
      "          Validation Loss (standardized): 1.7230316086210973\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6554633684292295\n",
      "          Validation Loss (standardized): 1.7343467965578339\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6551998090897018\n",
      "          Validation Loss (standardized): 1.723887154245232\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6540476076286215\n",
      "          Validation Loss (standardized): 1.7058802980644905\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.652790768953249\n",
      "          Validation Loss (standardized): 1.6914819156185572\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6519303194758613\n",
      "          Validation Loss (standardized): 1.6854326122895764\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6514166207675295\n",
      "          Validation Loss (standardized): 1.688367071985365\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6510012805806877\n",
      "          Validation Loss (standardized): 1.6936449944543577\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6506354401287455\n",
      "Epoch: 1, Loss (standarized): 0.943995376573208\n",
      "          Validation Loss (standardized): 1.4954349422087474\n",
      "Epoch: 6, Loss (standarized): 0.8261321429567873\n",
      "          Validation Loss (standardized): 1.8727077322134007\n",
      "Epoch: 11, Loss (standarized): 0.7850311542470427\n",
      "          Validation Loss (standardized): 1.8594025042557827\n",
      "Epoch: 16, Loss (standarized): 0.7872225857694156\n",
      "          Validation Loss (standardized): 1.7918947307743802\n",
      "Epoch: 21, Loss (standarized): 0.7684203000279917\n",
      "          Validation Loss (standardized): 1.7373594494881726\n",
      "Epoch: 26, Loss (standarized): 0.7618142080357543\n",
      "          Validation Loss (standardized): 1.694944592125214\n",
      "Epoch: 31, Loss (standarized): 0.7505974338955619\n",
      "          Validation Loss (standardized): 1.696451152743993\n",
      "Epoch: 36, Loss (standarized): 0.7384684798184052\n",
      "          Validation Loss (standardized): 1.7372841396087928\n",
      "Epoch: 41, Loss (standarized): 0.7276991467065342\n",
      "          Validation Loss (standardized): 1.74913228904737\n",
      "Epoch: 46, Loss (standarized): 0.7157967834555999\n",
      "          Validation Loss (standardized): 1.7159027769450272\n",
      "Epoch: 51, Loss (standarized): 0.7051038772946541\n",
      "          Validation Loss (standardized): 1.6932998395542558\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6950897341778804\n",
      "          Validation Loss (standardized): 1.6893494163166187\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6865283581600373\n",
      "          Validation Loss (standardized): 1.6894964065554319\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6799856218850812\n",
      "          Validation Loss (standardized): 1.6943240936370725\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6753488551154527\n",
      "          Validation Loss (standardized): 1.6917598018610085\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6724098995491036\n",
      "          Validation Loss (standardized): 1.6832501651318847\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6705669710590396\n",
      "          Validation Loss (standardized): 1.6817877078187708\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6694543567876085\n",
      "          Validation Loss (standardized): 1.6828001717025254\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6686906933871456\n",
      "          Validation Loss (standardized): 1.6849054536420514\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6679765865855868\n",
      "          Validation Loss (standardized): 1.6852467913849276\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6673856763374633\n",
      "Epoch: 1, Loss (standarized): 1.1943250038032687\n",
      "          Validation Loss (standardized): 1.1251378412096282\n",
      "Epoch: 6, Loss (standarized): 0.8449596379064735\n",
      "          Validation Loss (standardized): 1.4124543749965492\n",
      "Epoch: 11, Loss (standarized): 0.7899788623349839\n",
      "          Validation Loss (standardized): 1.7359767254894791\n",
      "Epoch: 16, Loss (standarized): 0.7827182088915269\n",
      "          Validation Loss (standardized): 1.9543976820953253\n",
      "Epoch: 21, Loss (standarized): 0.7751223723062695\n",
      "          Validation Loss (standardized): 2.046959440637743\n",
      "Epoch: 26, Loss (standarized): 0.7595173364856422\n",
      "          Validation Loss (standardized): 2.032396146248869\n",
      "Epoch: 31, Loss (standarized): 0.7369654705754951\n",
      "          Validation Loss (standardized): 1.9739421075349002\n",
      "Epoch: 36, Loss (standarized): 0.7103827337210255\n",
      "          Validation Loss (standardized): 1.899562720816974\n",
      "Epoch: 41, Loss (standarized): 0.6850909548602179\n",
      "          Validation Loss (standardized): 1.8245718307818226\n",
      "Epoch: 46, Loss (standarized): 0.6674772103864838\n",
      "          Validation Loss (standardized): 1.7745586412371002\n",
      "Epoch: 51, Loss (standarized): 0.6599198770012753\n",
      "          Validation Loss (standardized): 1.7436485696853923\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6585275201959041\n",
      "          Validation Loss (standardized): 1.719738805969852\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6578284675609545\n",
      "          Validation Loss (standardized): 1.701136207026172\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.656098421694437\n",
      "          Validation Loss (standardized): 1.6841196596954573\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6544968005148452\n",
      "          Validation Loss (standardized): 1.6787828639500404\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6537237474035665\n",
      "          Validation Loss (standardized): 1.6838551593249456\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6532307343017602\n",
      "          Validation Loss (standardized): 1.695760031537578\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6524201696582795\n",
      "          Validation Loss (standardized): 1.7074779972164256\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6513897975222731\n",
      "          Validation Loss (standardized): 1.7145992935746752\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6505013275521528\n",
      "          Validation Loss (standardized): 1.715106290414376\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6499631163518914\n",
      "Epoch: 1, Loss (standarized): 1.366710551481157\n",
      "          Validation Loss (standardized): 1.091182466717314\n",
      "Epoch: 6, Loss (standarized): 0.9043464179785048\n",
      "          Validation Loss (standardized): 1.2699535860126887\n",
      "Epoch: 11, Loss (standarized): 0.8043631176512009\n",
      "          Validation Loss (standardized): 1.6554929629383233\n",
      "Epoch: 16, Loss (standarized): 0.7857005699586511\n",
      "          Validation Loss (standardized): 1.9366666143336662\n",
      "Epoch: 21, Loss (standarized): 0.7832624608684038\n",
      "          Validation Loss (standardized): 2.086849831257379\n",
      "Epoch: 26, Loss (standarized): 0.7746929342653979\n",
      "          Validation Loss (standardized): 2.137073039338754\n",
      "Epoch: 31, Loss (standarized): 0.7593103813272881\n",
      "          Validation Loss (standardized): 2.118051589257755\n",
      "Epoch: 36, Loss (standarized): 0.7389437215804324\n",
      "          Validation Loss (standardized): 2.054263102960832\n",
      "Epoch: 41, Loss (standarized): 0.7141002146544033\n",
      "          Validation Loss (standardized): 1.9640415218798792\n",
      "Epoch: 46, Loss (standarized): 0.6896673826652507\n",
      "          Validation Loss (standardized): 1.8659828948021517\n",
      "Epoch: 51, Loss (standarized): 0.6709603111305363\n",
      "          Validation Loss (standardized): 1.776780797709114\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6611269267097998\n",
      "          Validation Loss (standardized): 1.7109380462762618\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6588043460337372\n",
      "          Validation Loss (standardized): 1.6733355952307565\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6588270592375627\n",
      "          Validation Loss (standardized): 1.6588505273046947\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6576248548392749\n",
      "          Validation Loss (standardized): 1.6598317475582671\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6551903864883067\n",
      "          Validation Loss (standardized): 1.6700688765333502\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6531469497449172\n",
      "          Validation Loss (standardized): 1.6845477524872707\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6522035473895264\n",
      "          Validation Loss (standardized): 1.697026515817523\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6516404802909784\n",
      "          Validation Loss (standardized): 1.7033032041236849\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6508335704847438\n",
      "          Validation Loss (standardized): 1.7028167861993888\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6501006479327629\n",
      "Epoch: 1, Loss (standarized): 0.9411144394490603\n",
      "          Validation Loss (standardized): 1.389237103398972\n",
      "Epoch: 6, Loss (standarized): 0.8275575691336072\n",
      "          Validation Loss (standardized): 1.4954360512717135\n",
      "Epoch: 11, Loss (standarized): 0.8076914080635881\n",
      "          Validation Loss (standardized): 1.6933138588449796\n",
      "Epoch: 16, Loss (standarized): 0.8079781707637658\n",
      "          Validation Loss (standardized): 1.804895884948593\n",
      "Epoch: 21, Loss (standarized): 0.8049617351644551\n",
      "          Validation Loss (standardized): 1.7892319213352563\n",
      "Epoch: 26, Loss (standarized): 0.8061615677225905\n",
      "          Validation Loss (standardized): 1.750633653777259\n",
      "Epoch: 31, Loss (standarized): 0.8052317486013273\n",
      "          Validation Loss (standardized): 1.732388856451958\n",
      "Epoch: 36, Loss (standarized): 0.8064348457433957\n",
      "          Validation Loss (standardized): 1.7114559703657033\n",
      "Epoch: 41, Loss (standarized): 0.8064483966100802\n",
      "          Validation Loss (standardized): 1.686129924629572\n",
      "Epoch: 46, Loss (standarized): 0.8064229417306092\n",
      "          Validation Loss (standardized): 1.68985865739129\n",
      "Epoch: 51, Loss (standarized): 0.8063117237240476\n",
      "          Validation Loss (standardized): 1.6986680001430854\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.80611742433279\n",
      "          Validation Loss (standardized): 1.6964206065094953\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.8066012847936971\n",
      "          Validation Loss (standardized): 1.679989480359386\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.8070118696433469\n",
      "          Validation Loss (standardized): 1.6694268159516872\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.8076021853277009\n",
      "          Validation Loss (standardized): 1.6559010149207956\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.8077633493985925\n",
      "          Validation Loss (standardized): 1.6537222978440167\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.8076392579171042\n",
      "          Validation Loss (standardized): 1.6573437963167013\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.807519569208734\n",
      "          Validation Loss (standardized): 1.6599016802611082\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.8077179352538711\n",
      "          Validation Loss (standardized): 1.655305918079311\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.8081567670283835\n",
      "          Validation Loss (standardized): 1.6487053853546134\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.8084712892678401\n",
      "Epoch: 1, Loss (standarized): 1.1493315827710644\n",
      "          Validation Loss (standardized): 1.08702945964538\n",
      "Epoch: 6, Loss (standarized): 0.8603635909445302\n",
      "          Validation Loss (standardized): 1.3612545811376735\n",
      "Epoch: 11, Loss (standarized): 0.8113371309398998\n",
      "          Validation Loss (standardized): 1.618017886531648\n",
      "Epoch: 16, Loss (standarized): 0.8023992339271028\n",
      "          Validation Loss (standardized): 1.7523524203344945\n",
      "Epoch: 21, Loss (standarized): 0.801918275687429\n",
      "          Validation Loss (standardized): 1.78825130535545\n",
      "Epoch: 26, Loss (standarized): 0.8032914911428167\n",
      "          Validation Loss (standardized): 1.768555923129472\n",
      "Epoch: 31, Loss (standarized): 0.8043524284663107\n",
      "          Validation Loss (standardized): 1.725474440912274\n",
      "Epoch: 36, Loss (standarized): 0.8055550135947119\n",
      "          Validation Loss (standardized): 1.687841941026498\n",
      "Epoch: 41, Loss (standarized): 0.8071936727985461\n",
      "          Validation Loss (standardized): 1.6613352836805615\n",
      "Epoch: 46, Loss (standarized): 0.8081052381006355\n",
      "          Validation Loss (standardized): 1.6470655785786117\n",
      "Epoch: 51, Loss (standarized): 0.8085255003079824\n",
      "          Validation Loss (standardized): 1.637061174920891\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.8092383900742239\n",
      "          Validation Loss (standardized): 1.6250733390664986\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.8096976879306317\n",
      "          Validation Loss (standardized): 1.6186545875091305\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.8095339358278376\n",
      "          Validation Loss (standardized): 1.6214976601087734\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.8096201968207415\n",
      "          Validation Loss (standardized): 1.6271889814347127\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.8088891995646885\n",
      "          Validation Loss (standardized): 1.6325080796130154\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.8089093276504916\n",
      "          Validation Loss (standardized): 1.6354480072735742\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.8087302406419333\n",
      "          Validation Loss (standardized): 1.6349051191135113\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.8088420818938081\n",
      "          Validation Loss (standardized): 1.6319587471788932\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.8091464435873319\n",
      "          Validation Loss (standardized): 1.625264300431158\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.8094175358093727\n",
      "Epoch: 1, Loss (standarized): 1.252426265734988\n",
      "          Validation Loss (standardized): 1.0686729135838278\n",
      "Epoch: 6, Loss (standarized): 0.8757074225177829\n",
      "          Validation Loss (standardized): 1.3324191126786027\n",
      "Epoch: 11, Loss (standarized): 0.8087604064966984\n",
      "          Validation Loss (standardized): 1.6402185614987528\n",
      "Epoch: 16, Loss (standarized): 0.8013252616437594\n",
      "          Validation Loss (standardized): 1.8116021690509727\n",
      "Epoch: 21, Loss (standarized): 0.8022935664987686\n",
      "          Validation Loss (standardized): 1.8654224798000332\n",
      "Epoch: 26, Loss (standarized): 0.802915757079283\n",
      "          Validation Loss (standardized): 1.8500728929734618\n",
      "Epoch: 31, Loss (standarized): 0.8038525074323138\n",
      "          Validation Loss (standardized): 1.8054486852240206\n",
      "Epoch: 36, Loss (standarized): 0.8043708636284678\n",
      "          Validation Loss (standardized): 1.7536379750103626\n",
      "Epoch: 41, Loss (standarized): 0.8055751958408894\n",
      "          Validation Loss (standardized): 1.7114103368205178\n",
      "Epoch: 46, Loss (standarized): 0.806574548903993\n",
      "          Validation Loss (standardized): 1.6846274156043881\n",
      "Epoch: 51, Loss (standarized): 0.8072939767895762\n",
      "          Validation Loss (standardized): 1.667418922005279\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.8074605314700627\n",
      "          Validation Loss (standardized): 1.6595502601986982\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.8075757870349237\n",
      "          Validation Loss (standardized): 1.6605422402316499\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.8075894552624359\n",
      "          Validation Loss (standardized): 1.6597753606760473\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.8075794713573866\n",
      "          Validation Loss (standardized): 1.6597445066567162\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.8074608143168175\n",
      "          Validation Loss (standardized): 1.6608300431234817\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.8074609868930724\n",
      "          Validation Loss (standardized): 1.66022840866267\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.8077350670483412\n",
      "          Validation Loss (standardized): 1.6532912598645206\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.8079480257702906\n",
      "          Validation Loss (standardized): 1.6496806868470837\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.8079114653142409\n",
      "          Validation Loss (standardized): 1.6501268590295777\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.8079014602182131\n",
      "Epoch: 1, Loss (standarized): 1.1475048943837576\n",
      "          Validation Loss (standardized): 1.852146567976109\n",
      "Epoch: 6, Loss (standarized): 0.7943702658660544\n",
      "          Validation Loss (standardized): 1.5820851689983415\n",
      "Epoch: 11, Loss (standarized): 0.8164500067134152\n",
      "          Validation Loss (standardized): 1.6994778404596087\n",
      "Epoch: 16, Loss (standarized): 0.7838509055825702\n",
      "          Validation Loss (standardized): 1.7462376068513226\n",
      "Epoch: 21, Loss (standarized): 0.7880602098301837\n",
      "          Validation Loss (standardized): 1.7547439784906118\n",
      "Epoch: 26, Loss (standarized): 0.7897798170774971\n",
      "          Validation Loss (standardized): 1.6892714151007069\n",
      "Epoch: 31, Loss (standarized): 0.7864443664389124\n",
      "          Validation Loss (standardized): 1.6287287863539441\n",
      "Epoch: 36, Loss (standarized): 0.7906491303430613\n",
      "          Validation Loss (standardized): 1.6235626901752067\n",
      "Epoch: 41, Loss (standarized): 0.7914930493503011\n",
      "          Validation Loss (standardized): 1.6595377091067798\n",
      "Epoch: 46, Loss (standarized): 0.7936510680665385\n",
      "          Validation Loss (standardized): 1.6614511560772616\n",
      "Epoch: 51, Loss (standarized): 0.7958654691453405\n",
      "          Validation Loss (standardized): 1.6370114704737728\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.7975708733699162\n",
      "          Validation Loss (standardized): 1.6397867894306841\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.7989700606893096\n",
      "          Validation Loss (standardized): 1.6447495494292603\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.8002805192921268\n",
      "          Validation Loss (standardized): 1.6487683160251139\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.8015458758305368\n",
      "          Validation Loss (standardized): 1.6487544238720613\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.8029392369320533\n",
      "          Validation Loss (standardized): 1.652684403053287\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.8037800321128066\n",
      "          Validation Loss (standardized): 1.659992273518733\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.8051474348542149\n",
      "          Validation Loss (standardized): 1.656833671717914\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.8058891606271961\n",
      "          Validation Loss (standardized): 1.6648678012475935\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.8065589183457575\n",
      "          Validation Loss (standardized): 1.6652281083987295\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.8069006695603385\n",
      "Epoch: 1, Loss (standarized): 1.1556690905183495\n",
      "          Validation Loss (standardized): 1.2218569241685524\n",
      "Epoch: 6, Loss (standarized): 0.860348609608813\n",
      "          Validation Loss (standardized): 1.3973880082446855\n",
      "Epoch: 11, Loss (standarized): 0.804880905611358\n",
      "          Validation Loss (standardized): 1.705395954383208\n",
      "Epoch: 16, Loss (standarized): 0.7963897602565942\n",
      "          Validation Loss (standardized): 1.955336516323852\n",
      "Epoch: 21, Loss (standarized): 0.7930791008552575\n",
      "          Validation Loss (standardized): 2.0234351641189736\n",
      "Epoch: 26, Loss (standarized): 0.7862235241371933\n",
      "          Validation Loss (standardized): 2.0202075997969766\n",
      "Epoch: 31, Loss (standarized): 0.7743591915935528\n",
      "          Validation Loss (standardized): 1.9783538820875015\n",
      "Epoch: 36, Loss (standarized): 0.7588000775372651\n",
      "          Validation Loss (standardized): 1.887620032952268\n",
      "Epoch: 41, Loss (standarized): 0.7407767029751893\n",
      "          Validation Loss (standardized): 1.8160824386599566\n",
      "Epoch: 46, Loss (standarized): 0.7205117488789745\n",
      "          Validation Loss (standardized): 1.7625022379879332\n",
      "Epoch: 51, Loss (standarized): 0.6991440606769181\n",
      "          Validation Loss (standardized): 1.7231392498648597\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6804075255287421\n",
      "          Validation Loss (standardized): 1.7170963251746008\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6677242319709086\n",
      "          Validation Loss (standardized): 1.720403047710444\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6618891414227119\n",
      "          Validation Loss (standardized): 1.7367206657258958\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6599732749161001\n",
      "          Validation Loss (standardized): 1.7424354064079945\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6590615179418289\n",
      "          Validation Loss (standardized): 1.738601827958601\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6584379609775266\n",
      "          Validation Loss (standardized): 1.726740121552338\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6583382345943463\n",
      "          Validation Loss (standardized): 1.7184134100680526\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6583782684940248\n",
      "          Validation Loss (standardized): 1.711390294456201\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6581818362611714\n",
      "          Validation Loss (standardized): 1.7096945737113005\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6577626587729495\n",
      "Epoch: 1, Loss (standarized): 1.4931898751089656\n",
      "          Validation Loss (standardized): 1.0920411338028804\n",
      "Epoch: 6, Loss (standarized): 0.9368800877828183\n",
      "          Validation Loss (standardized): 1.197249867587902\n",
      "Epoch: 11, Loss (standarized): 0.7986737035639248\n",
      "          Validation Loss (standardized): 1.5422501847215044\n",
      "Epoch: 16, Loss (standarized): 0.7757774195695684\n",
      "          Validation Loss (standardized): 1.799996136446331\n",
      "Epoch: 21, Loss (standarized): 0.7721890007023844\n",
      "          Validation Loss (standardized): 1.9219477886519547\n",
      "Epoch: 26, Loss (standarized): 0.7675298884489159\n",
      "          Validation Loss (standardized): 1.9426380238783478\n",
      "Epoch: 31, Loss (standarized): 0.7591722047628071\n",
      "          Validation Loss (standardized): 1.8961736783372465\n",
      "Epoch: 36, Loss (standarized): 0.7494880287481505\n",
      "          Validation Loss (standardized): 1.8094697647240474\n",
      "Epoch: 41, Loss (standarized): 0.7400425118474605\n",
      "          Validation Loss (standardized): 1.7226653280755697\n",
      "Epoch: 46, Loss (standarized): 0.7312754009076714\n",
      "          Validation Loss (standardized): 1.658773850072876\n",
      "Epoch: 51, Loss (standarized): 0.7224477749764319\n",
      "          Validation Loss (standardized): 1.6245012928691274\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.7134779900977928\n",
      "          Validation Loss (standardized): 1.6182048771545121\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.7050540127455492\n",
      "          Validation Loss (standardized): 1.6241926978742363\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6979131053117487\n",
      "          Validation Loss (standardized): 1.634032498144677\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6923256905737758\n",
      "          Validation Loss (standardized): 1.6439059917566605\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6880478844175127\n",
      "          Validation Loss (standardized): 1.651880311686748\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6847986228978777\n",
      "          Validation Loss (standardized): 1.6585947397360865\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6823816921652416\n",
      "          Validation Loss (standardized): 1.6608377480718304\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.680518225482058\n",
      "          Validation Loss (standardized): 1.660895774983854\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6789399843524376\n",
      "          Validation Loss (standardized): 1.6615158915094963\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6779163008045744\n",
      "Epoch: 1, Loss (standarized): 1.1534208514822988\n",
      "          Validation Loss (standardized): 1.1116912882463958\n",
      "Epoch: 6, Loss (standarized): 0.8259667172084448\n",
      "          Validation Loss (standardized): 1.4821518684349393\n",
      "Epoch: 11, Loss (standarized): 0.7772437816993975\n",
      "          Validation Loss (standardized): 1.8697668676375152\n",
      "Epoch: 16, Loss (standarized): 0.7636337814501329\n",
      "          Validation Loss (standardized): 2.055294857703729\n",
      "Epoch: 21, Loss (standarized): 0.744660743317861\n",
      "          Validation Loss (standardized): 2.0893587654477286\n",
      "Epoch: 26, Loss (standarized): 0.7189316063568635\n",
      "          Validation Loss (standardized): 2.017420906006787\n",
      "Epoch: 31, Loss (standarized): 0.692382358264071\n",
      "          Validation Loss (standardized): 1.9021765455823467\n",
      "Epoch: 36, Loss (standarized): 0.6716585521961013\n",
      "          Validation Loss (standardized): 1.7878106187502742\n",
      "Epoch: 41, Loss (standarized): 0.6598674343309678\n",
      "          Validation Loss (standardized): 1.6986057971206256\n",
      "Epoch: 46, Loss (standarized): 0.6554017869084302\n",
      "          Validation Loss (standardized): 1.6502575384129277\n",
      "Epoch: 51, Loss (standarized): 0.6541331279444461\n",
      "          Validation Loss (standardized): 1.633220207823884\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6536256926116267\n",
      "          Validation Loss (standardized): 1.6406922957210264\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6534819232174668\n",
      "          Validation Loss (standardized): 1.6532785298619908\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6539517825315231\n",
      "          Validation Loss (standardized): 1.6684850673698692\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6547599420865631\n",
      "          Validation Loss (standardized): 1.6774847824383547\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6553720355463856\n",
      "          Validation Loss (standardized): 1.6848385257866916\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6553705504548364\n",
      "          Validation Loss (standardized): 1.6890025038623577\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6548870010097663\n",
      "          Validation Loss (standardized): 1.6889185223400158\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6542710003793323\n",
      "          Validation Loss (standardized): 1.6868470536235483\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6537448794174194\n",
      "          Validation Loss (standardized): 1.6851768351416292\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6534691131073737\n",
      "Epoch: 1, Loss (standarized): 0.9266047520035299\n",
      "          Validation Loss (standardized): 1.2946564542717913\n",
      "Epoch: 6, Loss (standarized): 0.7988067437735792\n",
      "          Validation Loss (standardized): 1.7701680554201416\n",
      "Epoch: 11, Loss (standarized): 0.7852334176148137\n",
      "          Validation Loss (standardized): 2.0427174807123505\n",
      "Epoch: 16, Loss (standarized): 0.7708911411864144\n",
      "          Validation Loss (standardized): 2.07120720102193\n",
      "Epoch: 21, Loss (standarized): 0.7463587916925147\n",
      "          Validation Loss (standardized): 1.9509610036702365\n",
      "Epoch: 26, Loss (standarized): 0.7175020969669974\n",
      "          Validation Loss (standardized): 1.7788772609485155\n",
      "Epoch: 31, Loss (standarized): 0.6913422223907533\n",
      "          Validation Loss (standardized): 1.6424802565343517\n",
      "Epoch: 36, Loss (standarized): 0.6707187387917948\n",
      "          Validation Loss (standardized): 1.5995084152203953\n",
      "Epoch: 41, Loss (standarized): 0.6575280932534666\n",
      "          Validation Loss (standardized): 1.6389904077014408\n",
      "Epoch: 46, Loss (standarized): 0.6530910584511361\n",
      "          Validation Loss (standardized): 1.6959732953476883\n",
      "Epoch: 51, Loss (standarized): 0.6523775846318443\n",
      "          Validation Loss (standardized): 1.7167515302591227\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6519212974888514\n",
      "          Validation Loss (standardized): 1.6990133590774912\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6522757513067747\n",
      "          Validation Loss (standardized): 1.6755644790215924\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6532729183217512\n",
      "          Validation Loss (standardized): 1.6679386302705232\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.653610108482408\n",
      "          Validation Loss (standardized): 1.6709435501432899\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6530796572580808\n",
      "          Validation Loss (standardized): 1.6795250067945926\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6523178102044387\n",
      "          Validation Loss (standardized): 1.6872291797696082\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6517468503659333\n",
      "          Validation Loss (standardized): 1.6886664472114725\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6514521868636839\n",
      "          Validation Loss (standardized): 1.6839946879237389\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.651266638391324\n",
      "          Validation Loss (standardized): 1.6794463290501402\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.651154134693002\n",
      "Epoch: 1, Loss (standarized): 1.0782608748337492\n",
      "          Validation Loss (standardized): 1.2234368425533777\n",
      "Epoch: 6, Loss (standarized): 0.8135531756776005\n",
      "          Validation Loss (standardized): 1.552570506530828\n",
      "Epoch: 11, Loss (standarized): 0.7837862420108063\n",
      "          Validation Loss (standardized): 1.942894711767846\n",
      "Epoch: 16, Loss (standarized): 0.7755847267125631\n",
      "          Validation Loss (standardized): 2.1200992079399352\n",
      "Epoch: 21, Loss (standarized): 0.7551064763560424\n",
      "          Validation Loss (standardized): 2.140434504674318\n",
      "Epoch: 26, Loss (standarized): 0.7228716649120174\n",
      "          Validation Loss (standardized): 2.0628661908443875\n",
      "Epoch: 31, Loss (standarized): 0.6885882400910951\n",
      "          Validation Loss (standardized): 1.9517436763288174\n",
      "Epoch: 36, Loss (standarized): 0.6654558802996875\n",
      "          Validation Loss (standardized): 1.8574560608128259\n",
      "Epoch: 41, Loss (standarized): 0.659024081422181\n",
      "          Validation Loss (standardized): 1.7986219143306816\n",
      "Epoch: 46, Loss (standarized): 0.6608035832591095\n",
      "          Validation Loss (standardized): 1.7629170792537026\n",
      "Epoch: 51, Loss (standarized): 0.6603408012940011\n",
      "          Validation Loss (standardized): 1.7347591887339715\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6570760394289915\n",
      "          Validation Loss (standardized): 1.722505586836124\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6546979069590808\n",
      "          Validation Loss (standardized): 1.7292370704803812\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6539563728496227\n",
      "          Validation Loss (standardized): 1.7492271086745923\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6533536635731312\n",
      "          Validation Loss (standardized): 1.7690276437979087\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6523453923064667\n",
      "          Validation Loss (standardized): 1.7775011369310805\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6514147954441838\n",
      "          Validation Loss (standardized): 1.7712867377396522\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6507201962923121\n",
      "          Validation Loss (standardized): 1.7540292413776564\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6501173418104075\n",
      "          Validation Loss (standardized): 1.7347973997982864\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6495889013943728\n",
      "          Validation Loss (standardized): 1.722650345527623\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6492043030138386\n",
      "Epoch: 1, Loss (standarized): 1.3585641013848626\n",
      "          Validation Loss (standardized): 1.0987715079599911\n",
      "Epoch: 6, Loss (standarized): 0.8538741216800895\n",
      "          Validation Loss (standardized): 1.4283031288458006\n",
      "Epoch: 11, Loss (standarized): 0.7958096891035049\n",
      "          Validation Loss (standardized): 1.8181306914638962\n",
      "Epoch: 16, Loss (standarized): 0.7958560962010924\n",
      "          Validation Loss (standardized): 2.031123222894741\n",
      "Epoch: 21, Loss (standarized): 0.7959190699116566\n",
      "          Validation Loss (standardized): 2.1068493546826135\n",
      "Epoch: 26, Loss (standarized): 0.791821650061154\n",
      "          Validation Loss (standardized): 2.077830065669088\n",
      "Epoch: 31, Loss (standarized): 0.7842704701782739\n",
      "          Validation Loss (standardized): 1.9817226821462308\n",
      "Epoch: 36, Loss (standarized): 0.7759175914834955\n",
      "          Validation Loss (standardized): 1.8643187232760774\n",
      "Epoch: 41, Loss (standarized): 0.7682631606809172\n",
      "          Validation Loss (standardized): 1.754037195360171\n",
      "Epoch: 46, Loss (standarized): 0.7613441174519273\n",
      "          Validation Loss (standardized): 1.6687049290061646\n",
      "Epoch: 51, Loss (standarized): 0.7531564146054823\n",
      "          Validation Loss (standardized): 1.624947901993486\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.7419506285041226\n",
      "          Validation Loss (standardized): 1.6232792494823196\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.7283551904177992\n",
      "          Validation Loss (standardized): 1.6454893853040156\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.7142608741770013\n",
      "          Validation Loss (standardized): 1.67365329347056\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.7012481888407882\n",
      "          Validation Loss (standardized): 1.6950278609218932\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6903364462504\n",
      "          Validation Loss (standardized): 1.7014860139424148\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6820678813209762\n",
      "          Validation Loss (standardized): 1.6973966239302007\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6764251945878275\n",
      "          Validation Loss (standardized): 1.6895134968999268\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.672889270382424\n",
      "          Validation Loss (standardized): 1.6827044536072902\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6707236562338392\n",
      "          Validation Loss (standardized): 1.6806573144209034\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6695223196554052\n",
      "Epoch: 1, Loss (standarized): 0.9042872974945013\n",
      "          Validation Loss (standardized): 1.45187602980248\n",
      "Epoch: 6, Loss (standarized): 0.8167713742399457\n",
      "          Validation Loss (standardized): 1.758805399934541\n",
      "Epoch: 11, Loss (standarized): 0.7868735756496064\n",
      "          Validation Loss (standardized): 1.949598375846893\n",
      "Epoch: 16, Loss (standarized): 0.7741580616459661\n",
      "          Validation Loss (standardized): 1.9601579705369085\n",
      "Epoch: 21, Loss (standarized): 0.7571516488377661\n",
      "          Validation Loss (standardized): 1.8606839901979217\n",
      "Epoch: 26, Loss (standarized): 0.734442904541866\n",
      "          Validation Loss (standardized): 1.7282539326859299\n",
      "Epoch: 31, Loss (standarized): 0.7141599634519131\n",
      "          Validation Loss (standardized): 1.6597476905479314\n",
      "Epoch: 36, Loss (standarized): 0.6920566501794118\n",
      "          Validation Loss (standardized): 1.6674664377744417\n",
      "Epoch: 41, Loss (standarized): 0.6716428495911952\n",
      "          Validation Loss (standardized): 1.7059087490981737\n",
      "Epoch: 46, Loss (standarized): 0.6585858805660983\n",
      "          Validation Loss (standardized): 1.736612670679519\n",
      "Epoch: 51, Loss (standarized): 0.6530925068015283\n",
      "          Validation Loss (standardized): 1.7291327972496944\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6520626687533189\n",
      "          Validation Loss (standardized): 1.6990683478229274\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6520720965929167\n",
      "          Validation Loss (standardized): 1.6789831226499323\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.651445209667292\n",
      "          Validation Loss (standardized): 1.6770902538472214\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6506892769022997\n",
      "          Validation Loss (standardized): 1.691925634281639\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6504333586230672\n",
      "          Validation Loss (standardized): 1.6987495404237911\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6505298416325154\n",
      "          Validation Loss (standardized): 1.6951172304394226\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6505171562525743\n",
      "          Validation Loss (standardized): 1.6864948790050163\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6501942099516187\n",
      "          Validation Loss (standardized): 1.6859479209493051\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6496508610700213\n",
      "          Validation Loss (standardized): 1.6886738829916148\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6492097228338293\n",
      "Epoch: 1, Loss (standarized): 1.1237445407560362\n",
      "          Validation Loss (standardized): 1.1710790244193836\n",
      "Epoch: 6, Loss (standarized): 0.8231994290416894\n",
      "          Validation Loss (standardized): 1.5556196403984428\n",
      "Epoch: 11, Loss (standarized): 0.7914943565031796\n",
      "          Validation Loss (standardized): 1.8584347660067055\n",
      "Epoch: 16, Loss (standarized): 0.7853776205066587\n",
      "          Validation Loss (standardized): 2.0653228464082294\n",
      "Epoch: 21, Loss (standarized): 0.7767941254522348\n",
      "          Validation Loss (standardized): 2.114195409992736\n",
      "Epoch: 26, Loss (standarized): 0.7600304132608711\n",
      "          Validation Loss (standardized): 2.0712025424063762\n",
      "Epoch: 31, Loss (standarized): 0.7361868241503565\n",
      "          Validation Loss (standardized): 2.007229779542999\n",
      "Epoch: 36, Loss (standarized): 0.7090955679208193\n",
      "          Validation Loss (standardized): 1.9009962774224918\n",
      "Epoch: 41, Loss (standarized): 0.684044640782442\n",
      "          Validation Loss (standardized): 1.8062618446092924\n",
      "Epoch: 46, Loss (standarized): 0.6667906067558466\n",
      "          Validation Loss (standardized): 1.7473866263925764\n",
      "Epoch: 51, Loss (standarized): 0.6595552539653606\n",
      "          Validation Loss (standardized): 1.7164389691942534\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6589826780838335\n",
      "          Validation Loss (standardized): 1.7253874293388625\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6593281375883672\n",
      "          Validation Loss (standardized): 1.7357364540999947\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6580418328452325\n",
      "          Validation Loss (standardized): 1.7501593905210944\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6560842496490595\n",
      "          Validation Loss (standardized): 1.7535533428015149\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6547924249102031\n",
      "          Validation Loss (standardized): 1.7545042820212453\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6542075652709578\n",
      "          Validation Loss (standardized): 1.748408900330207\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6537211082928569\n",
      "          Validation Loss (standardized): 1.741707938154684\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6530189619094335\n",
      "          Validation Loss (standardized): 1.7328911338406228\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6522319684875718\n",
      "          Validation Loss (standardized): 1.7265709313204316\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6516634368609105\n",
      "Epoch: 1, Loss (standarized): 1.2795790489397925\n",
      "          Validation Loss (standardized): 1.0952126134633886\n",
      "Epoch: 6, Loss (standarized): 0.8803347055511892\n",
      "          Validation Loss (standardized): 1.311101272345336\n",
      "Epoch: 11, Loss (standarized): 0.7992907025442213\n",
      "          Validation Loss (standardized): 1.6586440334314192\n",
      "Epoch: 16, Loss (standarized): 0.7784975446982585\n",
      "          Validation Loss (standardized): 1.8889253269616306\n",
      "Epoch: 21, Loss (standarized): 0.7694625105358526\n",
      "          Validation Loss (standardized): 2.00768406367891\n",
      "Epoch: 26, Loss (standarized): 0.755252863680726\n",
      "          Validation Loss (standardized): 2.0420741567518377\n",
      "Epoch: 31, Loss (standarized): 0.733744790876389\n",
      "          Validation Loss (standardized): 2.0099658234176325\n",
      "Epoch: 36, Loss (standarized): 0.7091415166827861\n",
      "          Validation Loss (standardized): 1.9459861092238027\n",
      "Epoch: 41, Loss (standarized): 0.6845879369174345\n",
      "          Validation Loss (standardized): 1.870840805093537\n",
      "Epoch: 46, Loss (standarized): 0.6664765126093127\n",
      "          Validation Loss (standardized): 1.7980250672517573\n",
      "Epoch: 51, Loss (standarized): 0.6577850078120492\n",
      "          Validation Loss (standardized): 1.7434952902789522\n",
      "Epoch: 56, Loss (standarized): 0.656035468251345\n",
      "          Validation Loss (standardized): 1.7076602815011805\n",
      "Epoch: 61, Loss (standarized): 0.6565228231151488\n",
      "          Validation Loss (standardized): 1.683437385153251\n",
      "Epoch: 66, Loss (standarized): 0.656218419193746\n",
      "          Validation Loss (standardized): 1.670057240029153\n",
      "Epoch: 71, Loss (standarized): 0.6548260761814628\n",
      "          Validation Loss (standardized): 1.6644948608452592\n",
      "Epoch: 76, Loss (standarized): 0.6532704577404174\n",
      "          Validation Loss (standardized): 1.6659207856102909\n",
      "Epoch: 81, Loss (standarized): 0.6521761759591856\n",
      "          Validation Loss (standardized): 1.6731525382677457\n",
      "Epoch: 86, Loss (standarized): 0.6514969883906\n",
      "          Validation Loss (standardized): 1.6819927369780425\n",
      "Epoch: 91, Loss (standarized): 0.6509264478643885\n",
      "          Validation Loss (standardized): 1.690360456778529\n",
      "Epoch: 96, Loss (standarized): 0.6502972324042885\n",
      "          Validation Loss (standardized): 1.6958913684846464\n",
      "Final epoch: 100, Final loss (standarized): 0.6497673868789847\n",
      "Epoch: 1, Loss (standarized): 1.4189936876623894\n",
      "          Validation Loss (standardized): 1.094089637473477\n",
      "Epoch: 6, Loss (standarized): 0.8828406242510597\n",
      "          Validation Loss (standardized): 1.3065707797236705\n",
      "Epoch: 11, Loss (standarized): 0.7897906808800281\n",
      "          Validation Loss (standardized): 1.6746549017648322\n",
      "Epoch: 16, Loss (standarized): 0.7766895341024997\n",
      "          Validation Loss (standardized): 1.919684303339455\n",
      "Epoch: 21, Loss (standarized): 0.7709638046379781\n",
      "          Validation Loss (standardized): 2.0328017298881167\n",
      "Epoch: 26, Loss (standarized): 0.7632501841478629\n",
      "          Validation Loss (standardized): 2.0521342464160446\n",
      "Epoch: 31, Loss (standarized): 0.751497298605886\n",
      "          Validation Loss (standardized): 2.008898800639366\n",
      "Epoch: 36, Loss (standarized): 0.7372293219536454\n",
      "          Validation Loss (standardized): 1.928134632928022\n",
      "Epoch: 41, Loss (standarized): 0.7222778869746592\n",
      "          Validation Loss (standardized): 1.8351285316006019\n",
      "Epoch: 46, Loss (standarized): 0.7082115722501451\n",
      "          Validation Loss (standardized): 1.7490833498477518\n",
      "Epoch: 51, Loss (standarized): 0.6962705717652414\n",
      "          Validation Loss (standardized): 1.6807871496764355\n",
      "Epoch: 56, Loss (standarized): 0.6870255137772872\n",
      "          Validation Loss (standardized): 1.6385555852997273\n",
      "Epoch: 61, Loss (standarized): 0.6803122767367492\n",
      "          Validation Loss (standardized): 1.6212151749816408\n",
      "Epoch: 66, Loss (standarized): 0.6756394267124\n",
      "          Validation Loss (standardized): 1.6227670124202664\n",
      "Epoch: 71, Loss (standarized): 0.6725881150355034\n",
      "          Validation Loss (standardized): 1.6357046268201012\n",
      "Epoch: 76, Loss (standarized): 0.6705917482696703\n",
      "          Validation Loss (standardized): 1.650789746502859\n",
      "Epoch: 81, Loss (standarized): 0.6691465274310517\n",
      "          Validation Loss (standardized): 1.6635467047249404\n",
      "Epoch: 86, Loss (standarized): 0.6678001814504201\n",
      "          Validation Loss (standardized): 1.6708746727687815\n",
      "Epoch: 91, Loss (standarized): 0.6664524254818541\n",
      "          Validation Loss (standardized): 1.6738518675794918\n",
      "Epoch: 96, Loss (standarized): 0.6651815951588546\n",
      "          Validation Loss (standardized): 1.6736891121800532\n",
      "Final epoch: 100, Final loss (standarized): 0.6643274529108111\n",
      "Epoch: 1, Loss (standarized): 0.99191886651257\n",
      "          Validation Loss (standardized): 1.2236091691274529\n",
      "Epoch: 6, Loss (standarized): 0.8001485866762612\n",
      "          Validation Loss (standardized): 1.61181567879963\n",
      "Epoch: 11, Loss (standarized): 0.7734587436932784\n",
      "          Validation Loss (standardized): 1.9726585052343384\n",
      "Epoch: 16, Loss (standarized): 0.7579781699704641\n",
      "          Validation Loss (standardized): 2.103820595399681\n",
      "Epoch: 21, Loss (standarized): 0.7300421259537678\n",
      "          Validation Loss (standardized): 2.0661028848850482\n",
      "Epoch: 26, Loss (standarized): 0.6960691182882984\n",
      "          Validation Loss (standardized): 1.943952016221604\n",
      "Epoch: 31, Loss (standarized): 0.6692520340345689\n",
      "          Validation Loss (standardized): 1.8163815597888955\n",
      "Epoch: 36, Loss (standarized): 0.6580844109492906\n",
      "          Validation Loss (standardized): 1.7381477521859392\n",
      "Epoch: 41, Loss (standarized): 0.6578147447648303\n",
      "          Validation Loss (standardized): 1.708569056078829\n",
      "Epoch: 46, Loss (standarized): 0.6579646348582758\n",
      "          Validation Loss (standardized): 1.7100677334073588\n",
      "Epoch: 51, Loss (standarized): 0.6554567305300936\n",
      "          Validation Loss (standardized): 1.7233316129622318\n",
      "Epoch: 56, Loss (standarized): 0.6532654683319088\n",
      "          Validation Loss (standardized): 1.7405927887021198\n",
      "Epoch: 61, Loss (standarized): 0.6528065765880041\n",
      "          Validation Loss (standardized): 1.754377290506474\n",
      "Epoch: 66, Loss (standarized): 0.652697358207239\n",
      "          Validation Loss (standardized): 1.7567902026882285\n",
      "Epoch: 71, Loss (standarized): 0.6518774995544278\n",
      "          Validation Loss (standardized): 1.7485454306274526\n",
      "Epoch: 76, Loss (standarized): 0.6507723489866969\n",
      "          Validation Loss (standardized): 1.7361781775727623\n",
      "Epoch: 81, Loss (standarized): 0.6499565843822692\n",
      "          Validation Loss (standardized): 1.72556159516842\n",
      "Epoch: 86, Loss (standarized): 0.6494037635481221\n",
      "          Validation Loss (standardized): 1.7195172261269596\n",
      "Epoch: 91, Loss (standarized): 0.6489475671357936\n",
      "          Validation Loss (standardized): 1.7180990978951565\n",
      "Epoch: 96, Loss (standarized): 0.6485767537920347\n",
      "          Validation Loss (standardized): 1.7193067681355476\n",
      "Final epoch: 100, Final loss (standarized): 0.6483233723713996\n",
      "Epoch: 1, Loss (standarized): 0.9757183393908953\n",
      "          Validation Loss (standardized): 1.2488653537076597\n",
      "Epoch: 6, Loss (standarized): 0.8148109145313128\n",
      "          Validation Loss (standardized): 1.6846234002848268\n",
      "Epoch: 11, Loss (standarized): 0.7857577421771916\n",
      "          Validation Loss (standardized): 1.9948012033296545\n",
      "Epoch: 16, Loss (standarized): 0.7650134192921114\n",
      "          Validation Loss (standardized): 2.091889373844115\n",
      "Epoch: 21, Loss (standarized): 0.7356827923018138\n",
      "          Validation Loss (standardized): 2.0305786596312734\n",
      "Epoch: 26, Loss (standarized): 0.7020468963652173\n",
      "          Validation Loss (standardized): 1.9025417880479154\n",
      "Epoch: 31, Loss (standarized): 0.6729811112103999\n",
      "          Validation Loss (standardized): 1.7663567758747958\n",
      "Epoch: 36, Loss (standarized): 0.6560928220632644\n",
      "          Validation Loss (standardized): 1.6797347552006963\n",
      "Epoch: 41, Loss (standarized): 0.6518347294457777\n",
      "          Validation Loss (standardized): 1.6517415499829011\n",
      "Epoch: 46, Loss (standarized): 0.6533590116466648\n",
      "          Validation Loss (standardized): 1.665916286738256\n",
      "Epoch: 51, Loss (standarized): 0.6538397952304592\n",
      "          Validation Loss (standardized): 1.6861458450487972\n",
      "Epoch: 56, Loss (standarized): 0.6519552470429757\n",
      "          Validation Loss (standardized): 1.6994649124518013\n",
      "Epoch: 61, Loss (standarized): 0.649906685842644\n",
      "          Validation Loss (standardized): 1.701727413705069\n",
      "Epoch: 66, Loss (standarized): 0.6490578324894484\n",
      "          Validation Loss (standardized): 1.7010272527447383\n",
      "Epoch: 71, Loss (standarized): 0.6489030763128405\n",
      "          Validation Loss (standardized): 1.7000026402864388\n",
      "Epoch: 76, Loss (standarized): 0.6486101474470214\n",
      "          Validation Loss (standardized): 1.7003588394009606\n",
      "Epoch: 81, Loss (standarized): 0.6480526668420841\n",
      "          Validation Loss (standardized): 1.7008381605882001\n",
      "Epoch: 86, Loss (standarized): 0.6475107417083822\n",
      "          Validation Loss (standardized): 1.6993885823017745\n",
      "Epoch: 91, Loss (standarized): 0.647105242391512\n",
      "          Validation Loss (standardized): 1.6961877093111775\n",
      "Epoch: 96, Loss (standarized): 0.6467506443122613\n",
      "          Validation Loss (standardized): 1.6923019883188262\n",
      "Final epoch: 100, Final loss (standarized): 0.646459802422008\n",
      "Epoch: 1, Loss (standarized): 1.016583566600321\n",
      "          Validation Loss (standardized): 1.3575141682526164\n",
      "Epoch: 6, Loss (standarized): 0.8445294289233117\n",
      "          Validation Loss (standardized): 1.4007908712218973\n",
      "Epoch: 11, Loss (standarized): 0.8171034763145316\n",
      "          Validation Loss (standardized): 1.6091575918475651\n",
      "Epoch: 16, Loss (standarized): 0.8031124633875059\n",
      "          Validation Loss (standardized): 1.772429484902563\n",
      "Epoch: 21, Loss (standarized): 0.804850683666461\n",
      "          Validation Loss (standardized): 1.8168619891698907\n",
      "Epoch: 26, Loss (standarized): 0.8036294979022801\n",
      "          Validation Loss (standardized): 1.7863697645092966\n",
      "Epoch: 31, Loss (standarized): 0.8049891079819241\n",
      "          Validation Loss (standardized): 1.7490853909368866\n",
      "Epoch: 36, Loss (standarized): 0.8051866193261344\n",
      "          Validation Loss (standardized): 1.713010924669215\n",
      "Epoch: 41, Loss (standarized): 0.8067783255666707\n",
      "          Validation Loss (standardized): 1.6697960991064096\n",
      "Epoch: 46, Loss (standarized): 0.8084456468613053\n",
      "          Validation Loss (standardized): 1.6352380791758017\n",
      "Epoch: 51, Loss (standarized): 0.8088095221078736\n",
      "          Validation Loss (standardized): 1.633694394523437\n",
      "Epoch: 56, Loss (standarized): 0.8087079432958317\n",
      "          Validation Loss (standardized): 1.6362982837356166\n",
      "Epoch: 61, Loss (standarized): 0.8085548651024009\n",
      "          Validation Loss (standardized): 1.638370331752467\n",
      "Epoch: 66, Loss (standarized): 0.8079866448883164\n",
      "          Validation Loss (standardized): 1.6512763584952768\n",
      "Epoch: 71, Loss (standarized): 0.8075111854348945\n",
      "          Validation Loss (standardized): 1.6607432530154465\n",
      "Epoch: 76, Loss (standarized): 0.8076573138800386\n",
      "          Validation Loss (standardized): 1.6539390947005146\n",
      "Epoch: 81, Loss (standarized): 0.8080594755413663\n",
      "          Validation Loss (standardized): 1.6473773580241045\n",
      "Epoch: 86, Loss (standarized): 0.808075609008249\n",
      "          Validation Loss (standardized): 1.647001046270133\n",
      "Epoch: 91, Loss (standarized): 0.8081020908670391\n",
      "          Validation Loss (standardized): 1.6461701815754586\n",
      "Epoch: 96, Loss (standarized): 0.8083334840354596\n",
      "          Validation Loss (standardized): 1.6408114317792466\n",
      "Final epoch: 100, Final loss (standarized): 0.8084551424732181\n",
      "Epoch: 1, Loss (standarized): 1.0707162573606717\n",
      "          Validation Loss (standardized): 1.1770712283866074\n",
      "Epoch: 6, Loss (standarized): 0.8664619047231973\n",
      "          Validation Loss (standardized): 1.3677549904804451\n",
      "Epoch: 11, Loss (standarized): 0.813750312915577\n",
      "          Validation Loss (standardized): 1.5715725461573442\n",
      "Epoch: 16, Loss (standarized): 0.802785862972417\n",
      "          Validation Loss (standardized): 1.761679381300146\n",
      "Epoch: 21, Loss (standarized): 0.8027265877491039\n",
      "          Validation Loss (standardized): 1.8453266851304926\n",
      "Epoch: 26, Loss (standarized): 0.8041109005354323\n",
      "          Validation Loss (standardized): 1.8467358001952459\n",
      "Epoch: 31, Loss (standarized): 0.8040158824711446\n",
      "          Validation Loss (standardized): 1.8164811102278609\n",
      "Epoch: 36, Loss (standarized): 0.8042787073421318\n",
      "          Validation Loss (standardized): 1.7572501066027972\n",
      "Epoch: 41, Loss (standarized): 0.8058316541606448\n",
      "          Validation Loss (standardized): 1.6885263732011\n",
      "Epoch: 46, Loss (standarized): 0.8078884723738677\n",
      "          Validation Loss (standardized): 1.6421579205710457\n",
      "Epoch: 51, Loss (standarized): 0.8092165863739466\n",
      "          Validation Loss (standardized): 1.6226078349407458\n",
      "Epoch: 56, Loss (standarized): 0.8092767658409167\n",
      "          Validation Loss (standardized): 1.624982492963102\n",
      "Epoch: 61, Loss (standarized): 0.8090130213275778\n",
      "          Validation Loss (standardized): 1.6290573469736873\n",
      "Epoch: 66, Loss (standarized): 0.8091200645382977\n",
      "          Validation Loss (standardized): 1.6274877369818663\n",
      "Epoch: 71, Loss (standarized): 0.8092378159496274\n",
      "          Validation Loss (standardized): 1.6251418978298822\n",
      "Epoch: 76, Loss (standarized): 0.8091272394495992\n",
      "          Validation Loss (standardized): 1.6278514300044287\n",
      "Epoch: 81, Loss (standarized): 0.80903523952141\n",
      "          Validation Loss (standardized): 1.6277476489827698\n",
      "Epoch: 86, Loss (standarized): 0.8091636478310241\n",
      "          Validation Loss (standardized): 1.6272041376920223\n",
      "Epoch: 91, Loss (standarized): 0.8089493142833348\n",
      "          Validation Loss (standardized): 1.6318741394955973\n",
      "Epoch: 96, Loss (standarized): 0.8089568429957461\n",
      "          Validation Loss (standardized): 1.6382987387143189\n",
      "Final epoch: 100, Final loss (standarized): 0.8086447486654816\n",
      "Epoch: 1, Loss (standarized): 1.0725154212058088\n",
      "          Validation Loss (standardized): 1.2199615774185495\n",
      "Epoch: 6, Loss (standarized): 0.8342655911414049\n",
      "          Validation Loss (standardized): 1.426884860514468\n",
      "Epoch: 11, Loss (standarized): 0.7963670956158136\n",
      "          Validation Loss (standardized): 1.7160957178309506\n",
      "Epoch: 16, Loss (standarized): 0.7939584271154136\n",
      "          Validation Loss (standardized): 1.838008294524303\n",
      "Epoch: 21, Loss (standarized): 0.7956931919518706\n",
      "          Validation Loss (standardized): 1.8459037665518618\n",
      "Epoch: 26, Loss (standarized): 0.7962125098934768\n",
      "          Validation Loss (standardized): 1.8143644969678308\n",
      "Epoch: 31, Loss (standarized): 0.7987773455298597\n",
      "          Validation Loss (standardized): 1.7505642492157607\n",
      "Epoch: 36, Loss (standarized): 0.8018636833325021\n",
      "          Validation Loss (standardized): 1.7032658177884554\n",
      "Epoch: 41, Loss (standarized): 0.8053007809653601\n",
      "          Validation Loss (standardized): 1.6521638756142614\n",
      "Epoch: 46, Loss (standarized): 0.8085363669143384\n",
      "          Validation Loss (standardized): 1.6156354940666906\n",
      "Epoch: 51, Loss (standarized): 0.8097856956648829\n",
      "          Validation Loss (standardized): 1.607275935468253\n",
      "Epoch: 56, Loss (standarized): 0.8099635175903317\n",
      "          Validation Loss (standardized): 1.612024266142029\n",
      "Epoch: 61, Loss (standarized): 0.8092889799463793\n",
      "          Validation Loss (standardized): 1.6270626091126597\n",
      "Epoch: 66, Loss (standarized): 0.8082981176724038\n",
      "          Validation Loss (standardized): 1.6461918623768734\n",
      "Epoch: 71, Loss (standarized): 0.8077414746327897\n",
      "          Validation Loss (standardized): 1.6563651501991228\n",
      "Epoch: 76, Loss (standarized): 0.807374930477062\n",
      "          Validation Loss (standardized): 1.6643825975460844\n",
      "Epoch: 81, Loss (standarized): 0.8070162791503622\n",
      "          Validation Loss (standardized): 1.6749460941295864\n",
      "Epoch: 86, Loss (standarized): 0.8070883808748843\n",
      "          Validation Loss (standardized): 1.670208682759883\n",
      "Epoch: 91, Loss (standarized): 0.807192874839397\n",
      "          Validation Loss (standardized): 1.666211215123601\n",
      "Epoch: 96, Loss (standarized): 0.8071534199259316\n",
      "          Validation Loss (standardized): 1.6684814623225306\n",
      "Final epoch: 100, Final loss (standarized): 0.8072396576023589\n",
      "Epoch: 1, Loss (standarized): 1.1128782493420428\n",
      "          Validation Loss (standardized): 1.3698286286825292\n",
      "Epoch: 6, Loss (standarized): 0.8600964835938376\n",
      "          Validation Loss (standardized): 1.3682534001924436\n",
      "Epoch: 11, Loss (standarized): 0.8209991765852833\n",
      "          Validation Loss (standardized): 1.576793129559657\n",
      "Epoch: 16, Loss (standarized): 0.7998528707948214\n",
      "          Validation Loss (standardized): 1.7508051295975755\n",
      "Epoch: 21, Loss (standarized): 0.7979150509772046\n",
      "          Validation Loss (standardized): 1.800012335762759\n",
      "Epoch: 26, Loss (standarized): 0.7959181781538582\n",
      "          Validation Loss (standardized): 1.7947945989553744\n",
      "Epoch: 31, Loss (standarized): 0.7964601716151936\n",
      "          Validation Loss (standardized): 1.7872425743561817\n",
      "Epoch: 36, Loss (standarized): 0.7974714915212615\n",
      "          Validation Loss (standardized): 1.769840981054364\n",
      "Epoch: 41, Loss (standarized): 0.7988631110621669\n",
      "          Validation Loss (standardized): 1.7291520151712712\n",
      "Epoch: 46, Loss (standarized): 0.8011106957713574\n",
      "          Validation Loss (standardized): 1.6913756491116696\n",
      "Epoch: 51, Loss (standarized): 0.8032099978194179\n",
      "          Validation Loss (standardized): 1.6681417778866912\n",
      "Epoch: 56, Loss (standarized): 0.8049396474662632\n",
      "          Validation Loss (standardized): 1.6589790894322216\n",
      "Epoch: 61, Loss (standarized): 0.8053997705554437\n",
      "          Validation Loss (standardized): 1.6605074729807163\n",
      "Epoch: 66, Loss (standarized): 0.8055582668831702\n",
      "          Validation Loss (standardized): 1.6668214219718784\n",
      "Epoch: 71, Loss (standarized): 0.805791651895595\n",
      "          Validation Loss (standardized): 1.6741860415503955\n",
      "Epoch: 76, Loss (standarized): 0.8060322639033121\n",
      "          Validation Loss (standardized): 1.6753260280972317\n",
      "Epoch: 81, Loss (standarized): 0.8065611949183751\n",
      "          Validation Loss (standardized): 1.6672016880264764\n",
      "Epoch: 86, Loss (standarized): 0.8071489841786836\n",
      "          Validation Loss (standardized): 1.6596543448874577\n",
      "Epoch: 91, Loss (standarized): 0.8077835945604231\n",
      "          Validation Loss (standardized): 1.647461533099386\n",
      "Epoch: 96, Loss (standarized): 0.8084418844726345\n",
      "          Validation Loss (standardized): 1.6390228192707281\n",
      "Final epoch: 100, Final loss (standarized): 0.808648687850114\n",
      "Epoch: 1, Loss (standarized): 1.3721229851149734\n",
      "          Validation Loss (standardized): 1.0769234160224475\n",
      "Epoch: 6, Loss (standarized): 0.8942545109370229\n",
      "          Validation Loss (standardized): 1.2904442581422908\n",
      "Epoch: 11, Loss (standarized): 0.791714119554276\n",
      "          Validation Loss (standardized): 1.649474086255318\n",
      "Epoch: 16, Loss (standarized): 0.7790878822967366\n",
      "          Validation Loss (standardized): 1.9082155077567953\n",
      "Epoch: 21, Loss (standarized): 0.7701862988462197\n",
      "          Validation Loss (standardized): 2.0325255780313953\n",
      "Epoch: 26, Loss (standarized): 0.7601586275121849\n",
      "          Validation Loss (standardized): 2.063691181732257\n",
      "Epoch: 31, Loss (standarized): 0.7453890520970448\n",
      "          Validation Loss (standardized): 2.030079887865659\n",
      "Epoch: 36, Loss (standarized): 0.7262857765548797\n",
      "          Validation Loss (standardized): 1.9521502802345312\n",
      "Epoch: 41, Loss (standarized): 0.7067275568415646\n",
      "          Validation Loss (standardized): 1.8615246197381248\n",
      "Epoch: 46, Loss (standarized): 0.6888919252329208\n",
      "          Validation Loss (standardized): 1.7768929009205394\n",
      "Epoch: 51, Loss (standarized): 0.6749619774538761\n",
      "          Validation Loss (standardized): 1.7087930574071921\n",
      "Epoch: 56, Loss (standarized): 0.6660815938491246\n",
      "          Validation Loss (standardized): 1.667017854112702\n",
      "Epoch: 61, Loss (standarized): 0.6614564357538831\n",
      "          Validation Loss (standardized): 1.646778605022661\n",
      "Epoch: 66, Loss (standarized): 0.6594783833009215\n",
      "          Validation Loss (standardized): 1.6414572387919193\n",
      "Epoch: 71, Loss (standarized): 0.6585923763930561\n",
      "          Validation Loss (standardized): 1.6478275819944983\n",
      "Epoch: 76, Loss (standarized): 0.6580566385523595\n",
      "          Validation Loss (standardized): 1.6555036080516834\n",
      "Epoch: 81, Loss (standarized): 0.6576447503037632\n",
      "          Validation Loss (standardized): 1.6642493623113301\n",
      "Epoch: 86, Loss (standarized): 0.6573936383577484\n",
      "          Validation Loss (standardized): 1.6702747638610085\n",
      "Epoch: 91, Loss (standarized): 0.6571952998193078\n",
      "          Validation Loss (standardized): 1.6723985343727001\n",
      "Epoch: 96, Loss (standarized): 0.6569304592917223\n",
      "          Validation Loss (standardized): 1.6734683250308948\n",
      "Final epoch: 100, Final loss (standarized): 0.6566457090676654\n",
      "Epoch: 1, Loss (standarized): 1.1450011807648546\n",
      "          Validation Loss (standardized): 1.2281646428219246\n",
      "Epoch: 6, Loss (standarized): 0.8558217301084563\n",
      "          Validation Loss (standardized): 1.3780868018779615\n",
      "Epoch: 11, Loss (standarized): 0.7999958356398529\n",
      "          Validation Loss (standardized): 1.705629874793699\n",
      "Epoch: 16, Loss (standarized): 0.7952819633376884\n",
      "          Validation Loss (standardized): 1.9264699443023001\n",
      "Epoch: 21, Loss (standarized): 0.7949089491359786\n",
      "          Validation Loss (standardized): 1.9870855062792165\n",
      "Epoch: 26, Loss (standarized): 0.7926546395190766\n",
      "          Validation Loss (standardized): 1.9808476560376937\n",
      "Epoch: 31, Loss (standarized): 0.7888802924237306\n",
      "          Validation Loss (standardized): 1.9113232538970535\n",
      "Epoch: 36, Loss (standarized): 0.7852541922755522\n",
      "          Validation Loss (standardized): 1.8092917846068974\n",
      "Epoch: 41, Loss (standarized): 0.7836433073088866\n",
      "          Validation Loss (standardized): 1.7361197345342292\n",
      "Epoch: 46, Loss (standarized): 0.7827104366903564\n",
      "          Validation Loss (standardized): 1.692034838638603\n",
      "Epoch: 51, Loss (standarized): 0.7805477161599326\n",
      "          Validation Loss (standardized): 1.690439752484561\n",
      "Epoch: 56, Loss (standarized): 0.7770514808139606\n",
      "          Validation Loss (standardized): 1.7142255004946427\n",
      "Epoch: 61, Loss (standarized): 0.7727821612490218\n",
      "          Validation Loss (standardized): 1.73885211223253\n",
      "Epoch: 66, Loss (standarized): 0.7679321389861032\n",
      "          Validation Loss (standardized): 1.7555949437653797\n",
      "Epoch: 71, Loss (standarized): 0.7621373182997782\n",
      "          Validation Loss (standardized): 1.7553353937915022\n",
      "Epoch: 76, Loss (standarized): 0.7551526755847344\n",
      "          Validation Loss (standardized): 1.7505786977773623\n",
      "Epoch: 81, Loss (standarized): 0.7468581147169671\n",
      "          Validation Loss (standardized): 1.7430542028561093\n",
      "Epoch: 86, Loss (standarized): 0.7373819832283777\n",
      "          Validation Loss (standardized): 1.7353502158245753\n",
      "Epoch: 91, Loss (standarized): 0.727041571883159\n",
      "          Validation Loss (standardized): 1.725086138277424\n",
      "Epoch: 96, Loss (standarized): 0.716559859889301\n",
      "          Validation Loss (standardized): 1.7179070029688837\n",
      "Final epoch: 100, Final loss (standarized): 0.7087190605010271\n",
      "Epoch: 1, Loss (standarized): 1.5702844918841836\n",
      "          Validation Loss (standardized): 1.0905263782828358\n",
      "Epoch: 6, Loss (standarized): 0.9425915186833291\n",
      "          Validation Loss (standardized): 1.2314250932282926\n",
      "Epoch: 11, Loss (standarized): 0.8056386191972433\n",
      "          Validation Loss (standardized): 1.6110781081172367\n",
      "Epoch: 16, Loss (standarized): 0.7826897504554917\n",
      "          Validation Loss (standardized): 1.8793592100460108\n",
      "Epoch: 21, Loss (standarized): 0.7712351644667518\n",
      "          Validation Loss (standardized): 2.015957686968552\n",
      "Epoch: 26, Loss (standarized): 0.7558464250713459\n",
      "          Validation Loss (standardized): 2.06519566643483\n",
      "Epoch: 31, Loss (standarized): 0.7356660124037827\n",
      "          Validation Loss (standardized): 2.04641493135288\n",
      "Epoch: 36, Loss (standarized): 0.712809640494184\n",
      "          Validation Loss (standardized): 1.980466898571955\n",
      "Epoch: 41, Loss (standarized): 0.6912499243479676\n",
      "          Validation Loss (standardized): 1.9016967374388183\n",
      "Epoch: 46, Loss (standarized): 0.6744758717605747\n",
      "          Validation Loss (standardized): 1.8210287464422972\n",
      "Epoch: 51, Loss (standarized): 0.6641408815287001\n",
      "          Validation Loss (standardized): 1.7503682016647824\n",
      "Epoch: 56, Loss (standarized): 0.6594071430686284\n",
      "          Validation Loss (standardized): 1.7019218377961929\n",
      "Epoch: 61, Loss (standarized): 0.657737529090233\n",
      "          Validation Loss (standardized): 1.6681812175054196\n",
      "Epoch: 66, Loss (standarized): 0.6571751437578635\n",
      "          Validation Loss (standardized): 1.65076728005422\n",
      "Epoch: 71, Loss (standarized): 0.6570222465814618\n",
      "          Validation Loss (standardized): 1.647677135834916\n",
      "Epoch: 76, Loss (standarized): 0.6571572741398815\n",
      "          Validation Loss (standardized): 1.6511497842893321\n",
      "Epoch: 81, Loss (standarized): 0.6574602818111606\n",
      "          Validation Loss (standardized): 1.6583797059109278\n",
      "Epoch: 86, Loss (standarized): 0.6576397760672513\n",
      "          Validation Loss (standardized): 1.6638139175817659\n",
      "Epoch: 91, Loss (standarized): 0.6575233023570439\n",
      "          Validation Loss (standardized): 1.6680393889611385\n",
      "Epoch: 96, Loss (standarized): 0.6570661221331259\n",
      "          Validation Loss (standardized): 1.6706403960445644\n",
      "Final epoch: 100, Final loss (standarized): 0.6565686110363492\n",
      "Epoch: 1, Loss (standarized): 1.3277961807853473\n",
      "          Validation Loss (standardized): 1.1857339306688832\n",
      "Epoch: 6, Loss (standarized): 0.8990241853610568\n",
      "          Validation Loss (standardized): 1.2733321682121903\n",
      "Epoch: 11, Loss (standarized): 0.8321573442281491\n",
      "          Validation Loss (standardized): 1.5577079476103823\n",
      "Epoch: 16, Loss (standarized): 0.7759204959291108\n",
      "          Validation Loss (standardized): 1.738419152351954\n",
      "Epoch: 21, Loss (standarized): 0.77359841039279\n",
      "          Validation Loss (standardized): 1.8742419360200042\n",
      "Epoch: 26, Loss (standarized): 0.7546165870627062\n",
      "          Validation Loss (standardized): 1.940166051480759\n",
      "Epoch: 31, Loss (standarized): 0.7460370600934801\n",
      "          Validation Loss (standardized): 1.949807531217699\n",
      "Epoch: 36, Loss (standarized): 0.7281285267773598\n",
      "          Validation Loss (standardized): 1.9036055859645618\n",
      "Epoch: 41, Loss (standarized): 0.7138462873498559\n",
      "          Validation Loss (standardized): 1.8451285693286668\n",
      "Epoch: 46, Loss (standarized): 0.6981257842715919\n",
      "          Validation Loss (standardized): 1.7870134326874072\n",
      "Epoch: 51, Loss (standarized): 0.6853515503703747\n",
      "          Validation Loss (standardized): 1.731513072239788\n",
      "Epoch: 56, Loss (standarized): 0.6751616044594887\n",
      "          Validation Loss (standardized): 1.6910897813132406\n",
      "Epoch: 61, Loss (standarized): 0.6676812093008299\n",
      "          Validation Loss (standardized): 1.6716497444913407\n",
      "Epoch: 66, Loss (standarized): 0.663059937808677\n",
      "          Validation Loss (standardized): 1.6640764512346868\n",
      "Epoch: 71, Loss (standarized): 0.6603303083414999\n",
      "          Validation Loss (standardized): 1.6651672687025185\n",
      "Epoch: 76, Loss (standarized): 0.6588200723685109\n",
      "          Validation Loss (standardized): 1.672100675177267\n",
      "Epoch: 81, Loss (standarized): 0.6581051529136018\n",
      "          Validation Loss (standardized): 1.6770845159092238\n",
      "Epoch: 86, Loss (standarized): 0.6577470188910829\n",
      "          Validation Loss (standardized): 1.679378757530699\n",
      "Epoch: 91, Loss (standarized): 0.6575724349504457\n",
      "          Validation Loss (standardized): 1.6821507561425142\n",
      "Epoch: 96, Loss (standarized): 0.6575572934238892\n",
      "          Validation Loss (standardized): 1.6825186092425097\n",
      "Final epoch: 100, Final loss (standarized): 0.6576043575858596\n",
      "Epoch: 1, Loss (standarized): 1.1049513594896567\n",
      "          Validation Loss (standardized): 1.3000239058302172\n",
      "Epoch: 6, Loss (standarized): 0.8563139907429557\n",
      "          Validation Loss (standardized): 1.398173984401678\n",
      "Epoch: 11, Loss (standarized): 0.7978084326625079\n",
      "          Validation Loss (standardized): 1.731244000263018\n",
      "Epoch: 16, Loss (standarized): 0.7914053786355889\n",
      "          Validation Loss (standardized): 1.9664657644370953\n",
      "Epoch: 21, Loss (standarized): 0.7783139137283536\n",
      "          Validation Loss (standardized): 2.0051322567292607\n",
      "Epoch: 26, Loss (standarized): 0.7683817942481181\n",
      "          Validation Loss (standardized): 2.0044031916523366\n",
      "Epoch: 31, Loss (standarized): 0.7509278571252175\n",
      "          Validation Loss (standardized): 1.9737794329216796\n",
      "Epoch: 36, Loss (standarized): 0.7304125827046469\n",
      "          Validation Loss (standardized): 1.8756153848098756\n",
      "Epoch: 41, Loss (standarized): 0.7095798441297919\n",
      "          Validation Loss (standardized): 1.7852734155008734\n",
      "Epoch: 46, Loss (standarized): 0.689136703565043\n",
      "          Validation Loss (standardized): 1.7346960295792992\n",
      "Epoch: 51, Loss (standarized): 0.6726345482007946\n",
      "          Validation Loss (standardized): 1.6945243150535\n",
      "Epoch: 56, Loss (standarized): 0.6619410089438043\n",
      "          Validation Loss (standardized): 1.6887828704851016\n",
      "Epoch: 61, Loss (standarized): 0.6571316257107322\n",
      "          Validation Loss (standardized): 1.7141902027436267\n",
      "Epoch: 66, Loss (standarized): 0.6561965883259456\n",
      "          Validation Loss (standardized): 1.731362629086984\n",
      "Epoch: 71, Loss (standarized): 0.6560987100302323\n",
      "          Validation Loss (standardized): 1.7463830787747099\n",
      "Epoch: 76, Loss (standarized): 0.6552191001176779\n",
      "          Validation Loss (standardized): 1.7499393208267302\n",
      "Epoch: 81, Loss (standarized): 0.6537881008864205\n",
      "          Validation Loss (standardized): 1.7395258072568458\n",
      "Epoch: 86, Loss (standarized): 0.6525423647002412\n",
      "          Validation Loss (standardized): 1.7307531726031786\n",
      "Epoch: 91, Loss (standarized): 0.6517298080838181\n",
      "          Validation Loss (standardized): 1.720022451658439\n",
      "Epoch: 96, Loss (standarized): 0.6511501053657116\n",
      "          Validation Loss (standardized): 1.713767654659645\n",
      "Final epoch: 100, Final loss (standarized): 0.6506913841217645\n",
      "Epoch: 1, Loss (standarized): 1.697462621890352\n",
      "          Validation Loss (standardized): 1.1324503662140644\n",
      "Epoch: 6, Loss (standarized): 1.0712639559301895\n",
      "          Validation Loss (standardized): 1.1640272633301254\n",
      "Epoch: 11, Loss (standarized): 0.8372692630271342\n",
      "          Validation Loss (standardized): 1.4472220192746694\n",
      "Epoch: 16, Loss (standarized): 0.8116811967547789\n",
      "          Validation Loss (standardized): 1.7638284874173198\n",
      "Epoch: 21, Loss (standarized): 0.7910140696057146\n",
      "          Validation Loss (standardized): 1.9444801529292408\n",
      "Epoch: 26, Loss (standarized): 0.7950890178013168\n",
      "          Validation Loss (standardized): 2.0230327253233034\n",
      "Epoch: 31, Loss (standarized): 0.7871696451043332\n",
      "          Validation Loss (standardized): 2.005650696851766\n",
      "Epoch: 36, Loss (standarized): 0.782823605540029\n",
      "          Validation Loss (standardized): 1.9440859259574803\n",
      "Epoch: 41, Loss (standarized): 0.7747117955133956\n",
      "          Validation Loss (standardized): 1.8585619321974716\n",
      "Epoch: 46, Loss (standarized): 0.7683068443213315\n",
      "          Validation Loss (standardized): 1.775324715726769\n",
      "Epoch: 51, Loss (standarized): 0.7617305601733619\n",
      "          Validation Loss (standardized): 1.7050958575995117\n",
      "Epoch: 56, Loss (standarized): 0.7551131929885004\n",
      "          Validation Loss (standardized): 1.66232363018898\n",
      "Epoch: 61, Loss (standarized): 0.7471085872826505\n",
      "          Validation Loss (standardized): 1.6482716911077533\n",
      "Epoch: 66, Loss (standarized): 0.7381337223389494\n",
      "          Validation Loss (standardized): 1.6526506005782005\n",
      "Epoch: 71, Loss (standarized): 0.7282952617822931\n",
      "          Validation Loss (standardized): 1.6629773878199845\n",
      "Epoch: 76, Loss (standarized): 0.7184896744797681\n",
      "          Validation Loss (standardized): 1.6731078520083973\n",
      "Epoch: 81, Loss (standarized): 0.7090072335845538\n",
      "          Validation Loss (standardized): 1.677577115617019\n",
      "Epoch: 86, Loss (standarized): 0.7002697244409264\n",
      "          Validation Loss (standardized): 1.674844444131465\n",
      "Epoch: 91, Loss (standarized): 0.6926740728172135\n",
      "          Validation Loss (standardized): 1.6692792862676045\n",
      "Epoch: 96, Loss (standarized): 0.6864312090394353\n",
      "          Validation Loss (standardized): 1.6642703070810498\n",
      "Final epoch: 100, Final loss (standarized): 0.6824143126961457\n",
      "Epoch: 1, Loss (standarized): 1.1325975074654098\n",
      "          Validation Loss (standardized): 1.2319002651404185\n",
      "Epoch: 6, Loss (standarized): 0.8204178218880267\n",
      "          Validation Loss (standardized): 1.4904374360384003\n",
      "Epoch: 11, Loss (standarized): 0.7779527613847521\n",
      "          Validation Loss (standardized): 1.9307638673632188\n",
      "Epoch: 16, Loss (standarized): 0.7704583527229878\n",
      "          Validation Loss (standardized): 2.109311009263058\n",
      "Epoch: 21, Loss (standarized): 0.7547186335477989\n",
      "          Validation Loss (standardized): 2.123299483187787\n",
      "Epoch: 26, Loss (standarized): 0.7294200279372073\n",
      "          Validation Loss (standardized): 2.070520208437083\n",
      "Epoch: 31, Loss (standarized): 0.7013342248347824\n",
      "          Validation Loss (standardized): 1.9335720573752753\n",
      "Epoch: 36, Loss (standarized): 0.6773992328057828\n",
      "          Validation Loss (standardized): 1.8108206836481853\n",
      "Epoch: 41, Loss (standarized): 0.6620571506969871\n",
      "          Validation Loss (standardized): 1.7245802878409335\n",
      "Epoch: 46, Loss (standarized): 0.6555781755673594\n",
      "          Validation Loss (standardized): 1.6723811719346249\n",
      "Epoch: 51, Loss (standarized): 0.6541463851392517\n",
      "          Validation Loss (standardized): 1.677696721294349\n",
      "Epoch: 56, Loss (standarized): 0.6538984262390306\n",
      "          Validation Loss (standardized): 1.6950836599065007\n",
      "Epoch: 61, Loss (standarized): 0.6531646300927181\n",
      "          Validation Loss (standardized): 1.7198880267831251\n",
      "Epoch: 66, Loss (standarized): 0.6521664876668191\n",
      "          Validation Loss (standardized): 1.7377496613053063\n",
      "Epoch: 71, Loss (standarized): 0.6515339286355906\n",
      "          Validation Loss (standardized): 1.7410607406369722\n",
      "Epoch: 76, Loss (standarized): 0.6513550490159419\n",
      "          Validation Loss (standardized): 1.7385561180267397\n",
      "Epoch: 81, Loss (standarized): 0.6513070333675122\n",
      "          Validation Loss (standardized): 1.727537549214888\n",
      "Epoch: 86, Loss (standarized): 0.6510910718908739\n",
      "          Validation Loss (standardized): 1.7190156961011727\n",
      "Epoch: 91, Loss (standarized): 0.6506680819104863\n",
      "          Validation Loss (standardized): 1.7115302730686621\n",
      "Epoch: 96, Loss (standarized): 0.6501623854398861\n",
      "          Validation Loss (standardized): 1.7099492183352545\n",
      "Final epoch: 100, Final loss (standarized): 0.6497856024108626\n",
      "Epoch: 1, Loss (standarized): 1.1773696471565123\n",
      "          Validation Loss (standardized): 1.195058972674085\n",
      "Epoch: 6, Loss (standarized): 0.835482849128701\n",
      "          Validation Loss (standardized): 1.4237513272629512\n",
      "Epoch: 11, Loss (standarized): 0.7826252783640553\n",
      "          Validation Loss (standardized): 1.7882477916864403\n",
      "Epoch: 16, Loss (standarized): 0.7719332517068073\n",
      "          Validation Loss (standardized): 2.0489756845196796\n",
      "Epoch: 21, Loss (standarized): 0.7582548115213769\n",
      "          Validation Loss (standardized): 2.0923298501696572\n",
      "Epoch: 26, Loss (standarized): 0.7370874745361827\n",
      "          Validation Loss (standardized): 2.077416655323973\n",
      "Epoch: 31, Loss (standarized): 0.710653727795761\n",
      "          Validation Loss (standardized): 1.9978932718606475\n",
      "Epoch: 36, Loss (standarized): 0.6848414963914529\n",
      "          Validation Loss (standardized): 1.8892759077112478\n",
      "Epoch: 41, Loss (standarized): 0.6663231190095358\n",
      "          Validation Loss (standardized): 1.8189923965065236\n",
      "Epoch: 46, Loss (standarized): 0.6583354281817225\n",
      "          Validation Loss (standardized): 1.7581910734119026\n",
      "Epoch: 51, Loss (standarized): 0.6576495051645953\n",
      "          Validation Loss (standardized): 1.734237009265919\n",
      "Epoch: 56, Loss (standarized): 0.658272280894105\n",
      "          Validation Loss (standardized): 1.7245285499393472\n",
      "Epoch: 61, Loss (standarized): 0.6572371806902351\n",
      "          Validation Loss (standardized): 1.7196706091789882\n",
      "Epoch: 66, Loss (standarized): 0.6553566128456378\n",
      "          Validation Loss (standardized): 1.7271978546315834\n",
      "Epoch: 71, Loss (standarized): 0.6540444657834625\n",
      "          Validation Loss (standardized): 1.731873143724179\n",
      "Epoch: 76, Loss (standarized): 0.6534855871996353\n",
      "          Validation Loss (standardized): 1.7413752547633325\n",
      "Epoch: 81, Loss (standarized): 0.6531008947420389\n",
      "          Validation Loss (standardized): 1.7440702709483036\n",
      "Epoch: 86, Loss (standarized): 0.6525389650643844\n",
      "          Validation Loss (standardized): 1.7453627596265047\n",
      "Epoch: 91, Loss (standarized): 0.6518715161165889\n",
      "          Validation Loss (standardized): 1.7407119833079745\n",
      "Epoch: 96, Loss (standarized): 0.6512769924503736\n",
      "          Validation Loss (standardized): 1.7354040531976334\n",
      "Final epoch: 100, Final loss (standarized): 0.6508794732364316\n",
      "Epoch: 1, Loss (standarized): 1.223998046432116\n",
      "          Validation Loss (standardized): 1.2418155694937605\n",
      "Epoch: 6, Loss (standarized): 0.8691773706964299\n",
      "          Validation Loss (standardized): 1.3394227041897973\n",
      "Epoch: 11, Loss (standarized): 0.7942778251226452\n",
      "          Validation Loss (standardized): 1.6554136705654778\n",
      "Epoch: 16, Loss (standarized): 0.7791180989246994\n",
      "          Validation Loss (standardized): 1.9516925148433253\n",
      "Epoch: 21, Loss (standarized): 0.7704177151722176\n",
      "          Validation Loss (standardized): 2.0465886965256193\n",
      "Epoch: 26, Loss (standarized): 0.7554350115249686\n",
      "          Validation Loss (standardized): 2.053721914626422\n",
      "Epoch: 31, Loss (standarized): 0.7321616604266293\n",
      "          Validation Loss (standardized): 2.024253586766204\n",
      "Epoch: 36, Loss (standarized): 0.7058315411361852\n",
      "          Validation Loss (standardized): 1.9322729630533586\n",
      "Epoch: 41, Loss (standarized): 0.6825528073877194\n",
      "          Validation Loss (standardized): 1.8539731826827102\n",
      "Epoch: 46, Loss (standarized): 0.6672374954755158\n",
      "          Validation Loss (standardized): 1.8075956638073833\n",
      "Epoch: 51, Loss (standarized): 0.6612372461002543\n",
      "          Validation Loss (standardized): 1.770699254467556\n",
      "Epoch: 56, Loss (standarized): 0.6608143871761213\n",
      "          Validation Loss (standardized): 1.7656373249447839\n",
      "Epoch: 61, Loss (standarized): 0.6608130035982729\n",
      "          Validation Loss (standardized): 1.7603711503289996\n",
      "Epoch: 66, Loss (standarized): 0.659144326376852\n",
      "          Validation Loss (standardized): 1.752499597033392\n",
      "Epoch: 71, Loss (standarized): 0.6568243092833919\n",
      "          Validation Loss (standardized): 1.7509467306438486\n",
      "Epoch: 76, Loss (standarized): 0.6551471769487986\n",
      "          Validation Loss (standardized): 1.7466771263350898\n",
      "Epoch: 81, Loss (standarized): 0.6541977375567474\n",
      "          Validation Loss (standardized): 1.7499787304009742\n",
      "Epoch: 86, Loss (standarized): 0.653425872511033\n",
      "          Validation Loss (standardized): 1.7515927051301974\n",
      "Epoch: 91, Loss (standarized): 0.6525464959161348\n",
      "          Validation Loss (standardized): 1.7539807133993905\n",
      "Epoch: 96, Loss (standarized): 0.6516621342329263\n",
      "          Validation Loss (standardized): 1.7529122121697904\n",
      "Final epoch: 100, Final loss (standarized): 0.6510388546772665\n",
      "Epoch: 1, Loss (standarized): 1.3260902407926736\n",
      "          Validation Loss (standardized): 1.1052151267865997\n",
      "Epoch: 6, Loss (standarized): 0.8463741683731919\n",
      "          Validation Loss (standardized): 1.4410823994677213\n",
      "Epoch: 11, Loss (standarized): 0.7891574609457737\n",
      "          Validation Loss (standardized): 1.8532344989165594\n",
      "Epoch: 16, Loss (standarized): 0.7865864283543126\n",
      "          Validation Loss (standardized): 2.0836073415015224\n",
      "Epoch: 21, Loss (standarized): 0.7818719558388261\n",
      "          Validation Loss (standardized): 2.1462899577151737\n",
      "Epoch: 26, Loss (standarized): 0.7704424565681396\n",
      "          Validation Loss (standardized): 2.0866149961631444\n",
      "Epoch: 31, Loss (standarized): 0.7548352109240363\n",
      "          Validation Loss (standardized): 1.968468101552788\n",
      "Epoch: 36, Loss (standarized): 0.7384936417670448\n",
      "          Validation Loss (standardized): 1.832563340583468\n",
      "Epoch: 41, Loss (standarized): 0.7238421352929731\n",
      "          Validation Loss (standardized): 1.711874881197652\n",
      "Epoch: 46, Loss (standarized): 0.7106913163167349\n",
      "          Validation Loss (standardized): 1.6377536128277888\n",
      "Epoch: 51, Loss (standarized): 0.6978025700750395\n",
      "          Validation Loss (standardized): 1.6132236901446912\n",
      "Epoch: 56, Loss (standarized): 0.6857655444708718\n",
      "          Validation Loss (standardized): 1.6257725283839717\n",
      "Epoch: 61, Loss (standarized): 0.6764917573061986\n",
      "          Validation Loss (standardized): 1.6577556875094466\n",
      "Epoch: 66, Loss (standarized): 0.6706877601787453\n",
      "          Validation Loss (standardized): 1.6851825080867953\n",
      "Epoch: 71, Loss (standarized): 0.6676220368178488\n",
      "          Validation Loss (standardized): 1.6983714949143658\n",
      "Epoch: 76, Loss (standarized): 0.6662534794851923\n",
      "          Validation Loss (standardized): 1.6967278017321858\n",
      "Epoch: 81, Loss (standarized): 0.6657403567360732\n",
      "          Validation Loss (standardized): 1.6866605512197475\n",
      "Epoch: 86, Loss (standarized): 0.6654392251384329\n",
      "          Validation Loss (standardized): 1.6769088961693406\n",
      "Epoch: 91, Loss (standarized): 0.6649406170468443\n",
      "          Validation Loss (standardized): 1.6718556092795471\n",
      "Epoch: 96, Loss (standarized): 0.6641581085374855\n",
      "          Validation Loss (standardized): 1.6728345731941983\n",
      "Final epoch: 100, Final loss (standarized): 0.6634336129409223\n",
      "Epoch: 1, Loss (standarized): 1.4807223181080402\n",
      "          Validation Loss (standardized): 1.1213142191391567\n",
      "Epoch: 6, Loss (standarized): 0.9080587734611107\n",
      "          Validation Loss (standardized): 1.296345351281221\n",
      "Epoch: 11, Loss (standarized): 0.7948745791835838\n",
      "          Validation Loss (standardized): 1.6313523015188458\n",
      "Epoch: 16, Loss (standarized): 0.7786069921551981\n",
      "          Validation Loss (standardized): 1.8830201680208452\n",
      "Epoch: 21, Loss (standarized): 0.7705185421556513\n",
      "          Validation Loss (standardized): 2.0369300774891737\n",
      "Epoch: 26, Loss (standarized): 0.7589012267590616\n",
      "          Validation Loss (standardized): 2.08677046730679\n",
      "Epoch: 31, Loss (standarized): 0.7404424659081359\n",
      "          Validation Loss (standardized): 2.0628547896777802\n",
      "Epoch: 36, Loss (standarized): 0.7173379194069366\n",
      "          Validation Loss (standardized): 2.012482950771859\n",
      "Epoch: 41, Loss (standarized): 0.6935979115846478\n",
      "          Validation Loss (standardized): 1.94407632994921\n",
      "Epoch: 46, Loss (standarized): 0.6744114081476321\n",
      "          Validation Loss (standardized): 1.8671251076512734\n",
      "Epoch: 51, Loss (standarized): 0.6631888844294933\n",
      "          Validation Loss (standardized): 1.8087037696514026\n",
      "Epoch: 56, Loss (standarized): 0.6589954954128757\n",
      "          Validation Loss (standardized): 1.7647231877405873\n",
      "Epoch: 61, Loss (standarized): 0.6580945955519686\n",
      "          Validation Loss (standardized): 1.7287981807732207\n",
      "Epoch: 66, Loss (standarized): 0.6574915430259375\n",
      "          Validation Loss (standardized): 1.7064810840328013\n",
      "Epoch: 71, Loss (standarized): 0.6564173420907383\n",
      "          Validation Loss (standardized): 1.6919465603579584\n",
      "Epoch: 76, Loss (standarized): 0.6553150380607488\n",
      "          Validation Loss (standardized): 1.6872395873593264\n",
      "Epoch: 81, Loss (standarized): 0.6545390042607331\n",
      "          Validation Loss (standardized): 1.6927705056497022\n",
      "Epoch: 86, Loss (standarized): 0.653984554422318\n",
      "          Validation Loss (standardized): 1.7017548376535487\n",
      "Epoch: 91, Loss (standarized): 0.6534140940139881\n",
      "          Validation Loss (standardized): 1.712639331666858\n",
      "Epoch: 96, Loss (standarized): 0.6527461465827683\n",
      "          Validation Loss (standardized): 1.720444511423309\n",
      "Final epoch: 100, Final loss (standarized): 0.6521904384243209\n",
      "Epoch: 1, Loss (standarized): 1.0721821524539763\n",
      "          Validation Loss (standardized): 1.1678899938107408\n",
      "Epoch: 6, Loss (standarized): 0.8080138212603987\n",
      "          Validation Loss (standardized): 1.5538746151591742\n",
      "Epoch: 11, Loss (standarized): 0.775617913980011\n",
      "          Validation Loss (standardized): 1.9443483173131673\n",
      "Epoch: 16, Loss (standarized): 0.766162210885386\n",
      "          Validation Loss (standardized): 2.1516492688026636\n",
      "Epoch: 21, Loss (standarized): 0.7465714395187866\n",
      "          Validation Loss (standardized): 2.1487733084126073\n",
      "Epoch: 26, Loss (standarized): 0.7180129553320057\n",
      "          Validation Loss (standardized): 2.0661228731565937\n",
      "Epoch: 31, Loss (standarized): 0.6886646610751381\n",
      "          Validation Loss (standardized): 1.925473893459675\n",
      "Epoch: 36, Loss (standarized): 0.6672669240706083\n",
      "          Validation Loss (standardized): 1.8105716602232185\n",
      "Epoch: 41, Loss (standarized): 0.6578018237050974\n",
      "          Validation Loss (standardized): 1.7369307953917514\n",
      "Epoch: 46, Loss (standarized): 0.6568448919660201\n",
      "          Validation Loss (standardized): 1.7084568575856813\n",
      "Epoch: 51, Loss (standarized): 0.6577071519708075\n",
      "          Validation Loss (standardized): 1.7105211358219186\n",
      "Epoch: 56, Loss (standarized): 0.6567030659091612\n",
      "          Validation Loss (standardized): 1.718522037233423\n",
      "Epoch: 61, Loss (standarized): 0.6544730812271757\n",
      "          Validation Loss (standardized): 1.7315351996788872\n",
      "Epoch: 66, Loss (standarized): 0.6527531638941135\n",
      "          Validation Loss (standardized): 1.738780416359036\n",
      "Epoch: 71, Loss (standarized): 0.6519699233821579\n",
      "          Validation Loss (standardized): 1.7442156489386285\n",
      "Epoch: 76, Loss (standarized): 0.6515195658597849\n",
      "          Validation Loss (standardized): 1.7429382768859407\n",
      "Epoch: 81, Loss (standarized): 0.6509212696473506\n",
      "          Validation Loss (standardized): 1.738776570086051\n",
      "Epoch: 86, Loss (standarized): 0.6502044365034825\n",
      "          Validation Loss (standardized): 1.7320293178494726\n",
      "Epoch: 91, Loss (standarized): 0.649566991087169\n",
      "          Validation Loss (standardized): 1.7253663597563633\n",
      "Epoch: 96, Loss (standarized): 0.6490504462861171\n",
      "          Validation Loss (standardized): 1.719974031853828\n",
      "Final epoch: 100, Final loss (standarized): 0.6486725511443261\n",
      "Epoch: 1, Loss (standarized): 1.260099449756772\n",
      "          Validation Loss (standardized): 1.0632323059492175\n",
      "Epoch: 6, Loss (standarized): 0.9109949262282562\n",
      "          Validation Loss (standardized): 1.2604609960932285\n",
      "Epoch: 11, Loss (standarized): 0.823342098967908\n",
      "          Validation Loss (standardized): 1.4964667928254491\n",
      "Epoch: 16, Loss (standarized): 0.8068863758737259\n",
      "          Validation Loss (standardized): 1.6762222875343917\n",
      "Epoch: 21, Loss (standarized): 0.8016463021761528\n",
      "          Validation Loss (standardized): 1.7808518898124934\n",
      "Epoch: 26, Loss (standarized): 0.8023337012094481\n",
      "          Validation Loss (standardized): 1.8219249665581136\n",
      "Epoch: 31, Loss (standarized): 0.8033349079278276\n",
      "          Validation Loss (standardized): 1.8142664152317016\n",
      "Epoch: 36, Loss (standarized): 0.8033031858315088\n",
      "          Validation Loss (standardized): 1.7823679197006743\n",
      "Epoch: 41, Loss (standarized): 0.8041375010611477\n",
      "          Validation Loss (standardized): 1.7462320550690391\n",
      "Epoch: 46, Loss (standarized): 0.8051692038400995\n",
      "          Validation Loss (standardized): 1.7150175806424415\n",
      "Epoch: 51, Loss (standarized): 0.8061112810310362\n",
      "          Validation Loss (standardized): 1.688393479807109\n",
      "Epoch: 56, Loss (standarized): 0.806842121870372\n",
      "          Validation Loss (standardized): 1.67623304829764\n",
      "Epoch: 61, Loss (standarized): 0.8068764426993137\n",
      "          Validation Loss (standardized): 1.680495328559342\n",
      "Epoch: 66, Loss (standarized): 0.8065251488667201\n",
      "          Validation Loss (standardized): 1.6872782456154258\n",
      "Epoch: 71, Loss (standarized): 0.8063004211065261\n",
      "          Validation Loss (standardized): 1.6935276028333652\n",
      "Epoch: 76, Loss (standarized): 0.8063102081676792\n",
      "          Validation Loss (standardized): 1.6914378666134622\n",
      "Epoch: 81, Loss (standarized): 0.8064599223715343\n",
      "          Validation Loss (standardized): 1.6864927143806914\n",
      "Epoch: 86, Loss (standarized): 0.8067814852801002\n",
      "          Validation Loss (standardized): 1.6774529688555881\n",
      "Epoch: 91, Loss (standarized): 0.8074246001023891\n",
      "          Validation Loss (standardized): 1.665185935316774\n",
      "Epoch: 96, Loss (standarized): 0.8077884546584635\n",
      "          Validation Loss (standardized): 1.652128997014044\n",
      "Final epoch: 100, Final loss (standarized): 0.8081611209503285\n",
      "Epoch: 1, Loss (standarized): 1.3295464030813786\n",
      "          Validation Loss (standardized): 1.068495010462001\n",
      "Epoch: 6, Loss (standarized): 0.8941408552143715\n",
      "          Validation Loss (standardized): 1.30515091491384\n",
      "Epoch: 11, Loss (standarized): 0.8168005697735775\n",
      "          Validation Loss (standardized): 1.590300176871412\n",
      "Epoch: 16, Loss (standarized): 0.8028720432728896\n",
      "          Validation Loss (standardized): 1.7385126338295835\n",
      "Epoch: 21, Loss (standarized): 0.8009395080280619\n",
      "          Validation Loss (standardized): 1.7789378964374305\n",
      "Epoch: 26, Loss (standarized): 0.8003959110026065\n",
      "          Validation Loss (standardized): 1.7651090991977776\n",
      "Epoch: 31, Loss (standarized): 0.8024814376387489\n",
      "          Validation Loss (standardized): 1.7408825832527282\n",
      "Epoch: 36, Loss (standarized): 0.8030177850625273\n",
      "          Validation Loss (standardized): 1.7125262072504221\n",
      "Epoch: 41, Loss (standarized): 0.8044727357478939\n",
      "          Validation Loss (standardized): 1.6852623840969272\n",
      "Epoch: 46, Loss (standarized): 0.8064733983867737\n",
      "          Validation Loss (standardized): 1.6612884115379023\n",
      "Epoch: 51, Loss (standarized): 0.807336565647494\n",
      "          Validation Loss (standardized): 1.6444606625791853\n",
      "Epoch: 56, Loss (standarized): 0.8080916653359063\n",
      "          Validation Loss (standardized): 1.6348894670151033\n",
      "Epoch: 61, Loss (standarized): 0.8091378671778532\n",
      "          Validation Loss (standardized): 1.6246262951151655\n",
      "Epoch: 66, Loss (standarized): 0.8096278464521478\n",
      "          Validation Loss (standardized): 1.6181795774280718\n",
      "Epoch: 71, Loss (standarized): 0.8099948377199765\n",
      "          Validation Loss (standardized): 1.6151129733276564\n",
      "Epoch: 76, Loss (standarized): 0.8097541596353919\n",
      "          Validation Loss (standardized): 1.6181079148136772\n",
      "Epoch: 81, Loss (standarized): 0.8095537590139195\n",
      "          Validation Loss (standardized): 1.6222028488116236\n",
      "Epoch: 86, Loss (standarized): 0.8091803327717175\n",
      "          Validation Loss (standardized): 1.6281643504572216\n",
      "Epoch: 91, Loss (standarized): 0.809002767029104\n",
      "          Validation Loss (standardized): 1.6300272274129661\n",
      "Epoch: 96, Loss (standarized): 0.8089505724919621\n",
      "          Validation Loss (standardized): 1.6302253504057245\n",
      "Final epoch: 100, Final loss (standarized): 0.8090196417831255\n",
      "Epoch: 1, Loss (standarized): 1.2446938336290851\n",
      "          Validation Loss (standardized): 1.1209428541133817\n",
      "Epoch: 6, Loss (standarized): 0.8530242509799975\n",
      "          Validation Loss (standardized): 1.43838140373569\n",
      "Epoch: 11, Loss (standarized): 0.8059271129978801\n",
      "          Validation Loss (standardized): 1.7099680491649434\n",
      "Epoch: 16, Loss (standarized): 0.8037293979592037\n",
      "          Validation Loss (standardized): 1.8366607684148715\n",
      "Epoch: 21, Loss (standarized): 0.8037358592159043\n",
      "          Validation Loss (standardized): 1.8523867951491422\n",
      "Epoch: 26, Loss (standarized): 0.8039195992615695\n",
      "          Validation Loss (standardized): 1.7830423616760922\n",
      "Epoch: 31, Loss (standarized): 0.8050653347885217\n",
      "          Validation Loss (standardized): 1.7057013727235704\n",
      "Epoch: 36, Loss (standarized): 0.8063997401366585\n",
      "          Validation Loss (standardized): 1.6717556774143438\n",
      "Epoch: 41, Loss (standarized): 0.8072425294357318\n",
      "          Validation Loss (standardized): 1.6656829751393734\n",
      "Epoch: 46, Loss (standarized): 0.807371536679498\n",
      "          Validation Loss (standardized): 1.6604994467535357\n",
      "Epoch: 51, Loss (standarized): 0.8074565527732848\n",
      "          Validation Loss (standardized): 1.6581205462759392\n",
      "Epoch: 56, Loss (standarized): 0.8077618413679123\n",
      "          Validation Loss (standardized): 1.6544954366398548\n",
      "Epoch: 61, Loss (standarized): 0.8077039097273387\n",
      "          Validation Loss (standardized): 1.6565568530675479\n",
      "Epoch: 66, Loss (standarized): 0.8073253544411153\n",
      "          Validation Loss (standardized): 1.666283939428066\n",
      "Epoch: 71, Loss (standarized): 0.807067893637456\n",
      "          Validation Loss (standardized): 1.671924791860005\n",
      "Epoch: 76, Loss (standarized): 0.8069322785595904\n",
      "          Validation Loss (standardized): 1.6759380208267196\n",
      "Epoch: 81, Loss (standarized): 0.80678661240928\n",
      "          Validation Loss (standardized): 1.6816390425167722\n",
      "Epoch: 86, Loss (standarized): 0.8067791230921307\n",
      "          Validation Loss (standardized): 1.677099837707282\n",
      "Epoch: 91, Loss (standarized): 0.807210722823654\n",
      "          Validation Loss (standardized): 1.664014435179624\n",
      "Epoch: 96, Loss (standarized): 0.8076266202452259\n",
      "          Validation Loss (standardized): 1.655267748826274\n",
      "Final epoch: 100, Final loss (standarized): 0.8078921677327854\n",
      "Epoch: 1, Loss (standarized): 1.9641363201226434\n",
      "          Validation Loss (standardized): 1.2752753104823316\n",
      "Epoch: 6, Loss (standarized): 1.1762459718509186\n",
      "          Validation Loss (standardized): 1.102095723375699\n",
      "Epoch: 11, Loss (standarized): 0.9119753998432301\n",
      "          Validation Loss (standardized): 1.249573089433316\n",
      "Epoch: 16, Loss (standarized): 0.8345370623895269\n",
      "          Validation Loss (standardized): 1.439593855419934\n",
      "Epoch: 21, Loss (standarized): 0.8121006538551248\n",
      "          Validation Loss (standardized): 1.581483197454084\n",
      "Epoch: 26, Loss (standarized): 0.8054420658979871\n",
      "          Validation Loss (standardized): 1.6720599638044824\n",
      "Epoch: 31, Loss (standarized): 0.8043789712661835\n",
      "          Validation Loss (standardized): 1.7216863470159214\n",
      "Epoch: 36, Loss (standarized): 0.8047089816342113\n",
      "          Validation Loss (standardized): 1.7341612177064751\n",
      "Epoch: 41, Loss (standarized): 0.8050631391378973\n",
      "          Validation Loss (standardized): 1.7360157590591514\n",
      "Epoch: 46, Loss (standarized): 0.8053699210264903\n",
      "          Validation Loss (standardized): 1.7309062435892104\n",
      "Epoch: 51, Loss (standarized): 0.805654723279281\n",
      "          Validation Loss (standardized): 1.7170827789308492\n",
      "Epoch: 56, Loss (standarized): 0.8061142729739611\n",
      "          Validation Loss (standardized): 1.6969795812318367\n",
      "Epoch: 61, Loss (standarized): 0.8066316478391219\n",
      "          Validation Loss (standardized): 1.6807903115534748\n",
      "Epoch: 66, Loss (standarized): 0.8072870936844946\n",
      "          Validation Loss (standardized): 1.6649110891266237\n",
      "Epoch: 71, Loss (standarized): 0.8075834834455219\n",
      "          Validation Loss (standardized): 1.6574137324695153\n",
      "Epoch: 76, Loss (standarized): 0.807645134973529\n",
      "          Validation Loss (standardized): 1.656384590561013\n",
      "Epoch: 81, Loss (standarized): 0.8076222807347069\n",
      "          Validation Loss (standardized): 1.6588233836081707\n",
      "Epoch: 86, Loss (standarized): 0.8074088606087901\n",
      "          Validation Loss (standardized): 1.6622529463585014\n",
      "Epoch: 91, Loss (standarized): 0.8073092980768763\n",
      "          Validation Loss (standardized): 1.6650036038814797\n",
      "Epoch: 96, Loss (standarized): 0.8071479599107314\n",
      "          Validation Loss (standardized): 1.6699173871217445\n",
      "Final epoch: 100, Final loss (standarized): 0.8069553024368233\n",
      "Epoch: 1, Loss (standarized): 1.2441903881715028\n",
      "          Validation Loss (standardized): 1.2436490769582227\n",
      "Epoch: 6, Loss (standarized): 0.8913436729260541\n",
      "          Validation Loss (standardized): 1.2964512683184513\n",
      "Epoch: 11, Loss (standarized): 0.7981701869647684\n",
      "          Validation Loss (standardized): 1.606800474453507\n",
      "Epoch: 16, Loss (standarized): 0.7755227651353483\n",
      "          Validation Loss (standardized): 1.8726105847487098\n",
      "Epoch: 21, Loss (standarized): 0.762611056178543\n",
      "          Validation Loss (standardized): 1.974158765733764\n",
      "Epoch: 26, Loss (standarized): 0.7460895495382273\n",
      "          Validation Loss (standardized): 2.0044420393897893\n",
      "Epoch: 31, Loss (standarized): 0.7243310986955978\n",
      "          Validation Loss (standardized): 1.9701243869577965\n",
      "Epoch: 36, Loss (standarized): 0.7003206128709847\n",
      "          Validation Loss (standardized): 1.891618005876027\n",
      "Epoch: 41, Loss (standarized): 0.6793250705072182\n",
      "          Validation Loss (standardized): 1.8286694634938347\n",
      "Epoch: 46, Loss (standarized): 0.6654844219493761\n",
      "          Validation Loss (standardized): 1.7725122514945455\n",
      "Epoch: 51, Loss (standarized): 0.6593644595908187\n",
      "          Validation Loss (standardized): 1.744773944247048\n",
      "Epoch: 56, Loss (standarized): 0.6578826893018694\n",
      "          Validation Loss (standardized): 1.7313304404658192\n",
      "Epoch: 61, Loss (standarized): 0.6576051632216897\n",
      "          Validation Loss (standardized): 1.7244350091721852\n",
      "Epoch: 66, Loss (standarized): 0.657331980439444\n",
      "          Validation Loss (standardized): 1.724301716755982\n",
      "Epoch: 71, Loss (standarized): 0.6573624548485056\n",
      "          Validation Loss (standardized): 1.7271571012593603\n",
      "Epoch: 76, Loss (standarized): 0.6578161440046482\n",
      "          Validation Loss (standardized): 1.731356654647313\n",
      "Epoch: 81, Loss (standarized): 0.6582662031529324\n",
      "          Validation Loss (standardized): 1.7320439643898118\n",
      "Epoch: 86, Loss (standarized): 0.6583353500584673\n",
      "          Validation Loss (standardized): 1.7338888107963162\n",
      "Epoch: 91, Loss (standarized): 0.6579925383458096\n",
      "          Validation Loss (standardized): 1.7363179367141128\n",
      "Epoch: 96, Loss (standarized): 0.6575125224048419\n",
      "          Validation Loss (standardized): 1.7371921472109684\n",
      "Final epoch: 100, Final loss (standarized): 0.6571565343558503\n",
      "Epoch: 1, Loss (standarized): 1.4902893186396817\n",
      "          Validation Loss (standardized): 1.0655590813772158\n",
      "Epoch: 6, Loss (standarized): 0.8723862196669179\n",
      "          Validation Loss (standardized): 1.365903841054657\n",
      "Epoch: 11, Loss (standarized): 0.799293451205954\n",
      "          Validation Loss (standardized): 1.8180739257253375\n",
      "Epoch: 16, Loss (standarized): 0.7925987453214877\n",
      "          Validation Loss (standardized): 2.0468936011845584\n",
      "Epoch: 21, Loss (standarized): 0.7930793033195676\n",
      "          Validation Loss (standardized): 2.12878218802421\n",
      "Epoch: 26, Loss (standarized): 0.786432945513379\n",
      "          Validation Loss (standardized): 2.11460379662098\n",
      "Epoch: 31, Loss (standarized): 0.7786129417707948\n",
      "          Validation Loss (standardized): 2.0309716838002023\n",
      "Epoch: 36, Loss (standarized): 0.7707440840504755\n",
      "          Validation Loss (standardized): 1.9231034479058033\n",
      "Epoch: 41, Loss (standarized): 0.7642414901909309\n",
      "          Validation Loss (standardized): 1.827861159482482\n",
      "Epoch: 46, Loss (standarized): 0.7597104844851432\n",
      "          Validation Loss (standardized): 1.7526166901589029\n",
      "Epoch: 51, Loss (standarized): 0.7562598127438682\n",
      "          Validation Loss (standardized): 1.7026295731376537\n",
      "Epoch: 56, Loss (standarized): 0.7525198276067299\n",
      "          Validation Loss (standardized): 1.6843390707593398\n",
      "Epoch: 61, Loss (standarized): 0.7477915740980474\n",
      "          Validation Loss (standardized): 1.6867170861275704\n",
      "Epoch: 66, Loss (standarized): 0.7425345473159352\n",
      "          Validation Loss (standardized): 1.6953535480632949\n",
      "Epoch: 71, Loss (standarized): 0.7368899680148199\n",
      "          Validation Loss (standardized): 1.7054602988061267\n",
      "Epoch: 76, Loss (standarized): 0.730961530957901\n",
      "          Validation Loss (standardized): 1.7110409928499088\n",
      "Epoch: 81, Loss (standarized): 0.7248395424967058\n",
      "          Validation Loss (standardized): 1.7116771881275217\n",
      "Epoch: 86, Loss (standarized): 0.7186432807355554\n",
      "          Validation Loss (standardized): 1.7100062869549562\n",
      "Epoch: 91, Loss (standarized): 0.7125361889994314\n",
      "          Validation Loss (standardized): 1.7078362293222447\n",
      "Epoch: 96, Loss (standarized): 0.706684568114961\n",
      "          Validation Loss (standardized): 1.7051684916434406\n",
      "Final epoch: 100, Final loss (standarized): 0.7023275710247177\n",
      "Epoch: 1, Loss (standarized): 1.4645453173576324\n",
      "          Validation Loss (standardized): 1.164608643003351\n",
      "Epoch: 6, Loss (standarized): 0.9070212782565854\n",
      "          Validation Loss (standardized): 1.3169714939170336\n",
      "Epoch: 11, Loss (standarized): 0.8058439741078463\n",
      "          Validation Loss (standardized): 1.6511569764908467\n",
      "Epoch: 16, Loss (standarized): 0.7936131765623429\n",
      "          Validation Loss (standardized): 1.912689459722446\n",
      "Epoch: 21, Loss (standarized): 0.7907450560173636\n",
      "          Validation Loss (standardized): 2.054626006530804\n",
      "Epoch: 26, Loss (standarized): 0.784286127419018\n",
      "          Validation Loss (standardized): 2.071529831679179\n",
      "Epoch: 31, Loss (standarized): 0.7741382757624359\n",
      "          Validation Loss (standardized): 2.028354789761742\n",
      "Epoch: 36, Loss (standarized): 0.7598202847738942\n",
      "          Validation Loss (standardized): 1.960838616192448\n",
      "Epoch: 41, Loss (standarized): 0.743502014564058\n",
      "          Validation Loss (standardized): 1.870126406062472\n",
      "Epoch: 46, Loss (standarized): 0.7259223294043394\n",
      "          Validation Loss (standardized): 1.780041450017403\n",
      "Epoch: 51, Loss (standarized): 0.708360177260778\n",
      "          Validation Loss (standardized): 1.7172647511746542\n",
      "Epoch: 56, Loss (standarized): 0.6918745703464789\n",
      "          Validation Loss (standardized): 1.6774734601854482\n",
      "Epoch: 61, Loss (standarized): 0.6779300297753723\n",
      "          Validation Loss (standardized): 1.6593679043206204\n",
      "Epoch: 66, Loss (standarized): 0.6680613588450688\n",
      "          Validation Loss (standardized): 1.6641830186110937\n",
      "Epoch: 71, Loss (standarized): 0.6623810168287266\n",
      "          Validation Loss (standardized): 1.6744248075622594\n",
      "Epoch: 76, Loss (standarized): 0.6596662857696415\n",
      "          Validation Loss (standardized): 1.6843945983070032\n",
      "Epoch: 81, Loss (standarized): 0.6584622114729758\n",
      "          Validation Loss (standardized): 1.6901039687506323\n",
      "Epoch: 86, Loss (standarized): 0.6579071973005347\n",
      "          Validation Loss (standardized): 1.690456174586039\n",
      "Epoch: 91, Loss (standarized): 0.6578079879692258\n",
      "          Validation Loss (standardized): 1.6900768458013775\n",
      "Epoch: 96, Loss (standarized): 0.6579711299054141\n",
      "          Validation Loss (standardized): 1.6863656634461404\n",
      "Final epoch: 100, Final loss (standarized): 0.658096509101622\n",
      "Epoch: 1, Loss (standarized): 1.0100146155208982\n",
      "          Validation Loss (standardized): 1.6379541618946107\n",
      "Epoch: 6, Loss (standarized): 0.824896326946073\n",
      "          Validation Loss (standardized): 1.718236931990145\n",
      "Epoch: 11, Loss (standarized): 0.8098422521752221\n",
      "          Validation Loss (standardized): 1.8700507776417845\n",
      "Epoch: 16, Loss (standarized): 0.7961070772054633\n",
      "          Validation Loss (standardized): 1.9288881309345676\n",
      "Epoch: 21, Loss (standarized): 0.7847673621060997\n",
      "          Validation Loss (standardized): 1.8291150107668148\n",
      "Epoch: 26, Loss (standarized): 0.7721928456346\n",
      "          Validation Loss (standardized): 1.7278167314619954\n",
      "Epoch: 31, Loss (standarized): 0.7622598050643811\n",
      "          Validation Loss (standardized): 1.7006184961970834\n",
      "Epoch: 36, Loss (standarized): 0.7497063384412874\n",
      "          Validation Loss (standardized): 1.727442789960415\n",
      "Epoch: 41, Loss (standarized): 0.7358293133130848\n",
      "          Validation Loss (standardized): 1.7398195860886203\n",
      "Epoch: 46, Loss (standarized): 0.7210070857040368\n",
      "          Validation Loss (standardized): 1.7339176167264905\n",
      "Epoch: 51, Loss (standarized): 0.7054745536885544\n",
      "          Validation Loss (standardized): 1.7299749678366312\n",
      "Epoch: 56, Loss (standarized): 0.6911742150563516\n",
      "          Validation Loss (standardized): 1.7146420292724052\n",
      "Epoch: 61, Loss (standarized): 0.6781471709867002\n",
      "          Validation Loss (standardized): 1.6946400107758919\n",
      "Epoch: 66, Loss (standarized): 0.6685849094198961\n",
      "          Validation Loss (standardized): 1.694606026146614\n",
      "Epoch: 71, Loss (standarized): 0.6625220406872548\n",
      "          Validation Loss (standardized): 1.6950401803968358\n",
      "Epoch: 76, Loss (standarized): 0.6590978806599785\n",
      "          Validation Loss (standardized): 1.6907402477370164\n",
      "Epoch: 81, Loss (standarized): 0.6575205572590245\n",
      "          Validation Loss (standardized): 1.6907164460467887\n",
      "Epoch: 86, Loss (standarized): 0.6567847110328175\n",
      "          Validation Loss (standardized): 1.686601030781235\n",
      "Epoch: 91, Loss (standarized): 0.6564213446956894\n",
      "          Validation Loss (standardized): 1.6813267769892593\n",
      "Epoch: 96, Loss (standarized): 0.6563148417446835\n",
      "          Validation Loss (standardized): 1.680246972376362\n",
      "Final epoch: 100, Final loss (standarized): 0.6563795753937135\n",
      "Epoch: 1, Loss (standarized): 1.1903591295447145\n",
      "          Validation Loss (standardized): 1.0877747176355546\n",
      "Epoch: 6, Loss (standarized): 0.8365244446205645\n",
      "          Validation Loss (standardized): 1.483431421129714\n",
      "Epoch: 11, Loss (standarized): 0.790822360638638\n",
      "          Validation Loss (standardized): 1.8511869778191883\n",
      "Epoch: 16, Loss (standarized): 0.781036759426076\n",
      "          Validation Loss (standardized): 2.055398332692842\n",
      "Epoch: 21, Loss (standarized): 0.766479770761014\n",
      "          Validation Loss (standardized): 2.1351326755299223\n",
      "Epoch: 26, Loss (standarized): 0.7445290857780645\n",
      "          Validation Loss (standardized): 2.114953252140845\n",
      "Epoch: 31, Loss (standarized): 0.7168977392209746\n",
      "          Validation Loss (standardized): 2.0384591647248116\n",
      "Epoch: 36, Loss (standarized): 0.6888543468028386\n",
      "          Validation Loss (standardized): 1.9426445684335025\n",
      "Epoch: 41, Loss (standarized): 0.6681840900960909\n",
      "          Validation Loss (standardized): 1.8459376423374405\n",
      "Epoch: 46, Loss (standarized): 0.6587458756182075\n",
      "          Validation Loss (standardized): 1.77279217116769\n",
      "Epoch: 51, Loss (standarized): 0.6574931753645992\n",
      "          Validation Loss (standardized): 1.7214269377937066\n",
      "Epoch: 56, Loss (standarized): 0.6582479747983293\n",
      "          Validation Loss (standardized): 1.6874137083064071\n",
      "Epoch: 61, Loss (standarized): 0.6575729094201015\n",
      "          Validation Loss (standardized): 1.6720722304946132\n",
      "Epoch: 66, Loss (standarized): 0.655761933107354\n",
      "          Validation Loss (standardized): 1.6707613296862713\n",
      "Epoch: 71, Loss (standarized): 0.6541789120928834\n",
      "          Validation Loss (standardized): 1.6838753663961896\n",
      "Epoch: 76, Loss (standarized): 0.6533596492729924\n",
      "          Validation Loss (standardized): 1.7013038737978206\n",
      "Epoch: 81, Loss (standarized): 0.6529148683899122\n",
      "          Validation Loss (standardized): 1.7173146005315605\n",
      "Epoch: 86, Loss (standarized): 0.6523552337022271\n",
      "          Validation Loss (standardized): 1.7251367959484762\n",
      "Epoch: 91, Loss (standarized): 0.6516258356205464\n",
      "          Validation Loss (standardized): 1.7253944661678986\n",
      "Epoch: 96, Loss (standarized): 0.6509207017369684\n",
      "          Validation Loss (standardized): 1.7196385363263997\n",
      "Final epoch: 100, Final loss (standarized): 0.6504429437152733\n",
      "Epoch: 1, Loss (standarized): 1.54393383119157\n",
      "          Validation Loss (standardized): 1.0977581474556146\n",
      "Epoch: 6, Loss (standarized): 0.9161024472950945\n",
      "          Validation Loss (standardized): 1.2378774693114019\n",
      "Epoch: 11, Loss (standarized): 0.79262696734241\n",
      "          Validation Loss (standardized): 1.593072392511333\n",
      "Epoch: 16, Loss (standarized): 0.7750407885248797\n",
      "          Validation Loss (standardized): 1.839470286371378\n",
      "Epoch: 21, Loss (standarized): 0.7699625879619171\n",
      "          Validation Loss (standardized): 1.9602179402560864\n",
      "Epoch: 26, Loss (standarized): 0.7625823016666734\n",
      "          Validation Loss (standardized): 1.987299966322449\n",
      "Epoch: 31, Loss (standarized): 0.7521013087270731\n",
      "          Validation Loss (standardized): 1.9542093541820553\n",
      "Epoch: 36, Loss (standarized): 0.7399833595243125\n",
      "          Validation Loss (standardized): 1.894160965143507\n",
      "Epoch: 41, Loss (standarized): 0.7274681870939014\n",
      "          Validation Loss (standardized): 1.831141239522211\n",
      "Epoch: 46, Loss (standarized): 0.7156039989669154\n",
      "          Validation Loss (standardized): 1.775891577251421\n",
      "Epoch: 51, Loss (standarized): 0.7054104584346161\n",
      "          Validation Loss (standardized): 1.7327831188984446\n",
      "Epoch: 56, Loss (standarized): 0.6974424266356214\n",
      "          Validation Loss (standardized): 1.7023418643425137\n",
      "Epoch: 61, Loss (standarized): 0.6915227249039441\n",
      "          Validation Loss (standardized): 1.6815514441276496\n",
      "Epoch: 66, Loss (standarized): 0.6870776716463118\n",
      "          Validation Loss (standardized): 1.668456356326214\n",
      "Epoch: 71, Loss (standarized): 0.6835769579644296\n",
      "          Validation Loss (standardized): 1.6618652761813888\n",
      "Epoch: 76, Loss (standarized): 0.6806861048568011\n",
      "          Validation Loss (standardized): 1.6602334604625277\n",
      "Epoch: 81, Loss (standarized): 0.6782417693724301\n",
      "          Validation Loss (standardized): 1.662444323605645\n",
      "Epoch: 86, Loss (standarized): 0.6761462434050239\n",
      "          Validation Loss (standardized): 1.6661313134495963\n",
      "Epoch: 91, Loss (standarized): 0.6743117586622236\n",
      "          Validation Loss (standardized): 1.6699021201861473\n",
      "Epoch: 96, Loss (standarized): 0.6726795030544478\n",
      "          Validation Loss (standardized): 1.672790325916661\n",
      "Final epoch: 100, Final loss (standarized): 0.6715128681441748\n",
      "Epoch: 1, Loss (standarized): 0.8391521182199365\n",
      "          Validation Loss (standardized): 1.4795238239050945\n",
      "Epoch: 6, Loss (standarized): 0.7933198627972048\n",
      "          Validation Loss (standardized): 1.8811648206456029\n",
      "Epoch: 11, Loss (standarized): 0.7777149321886263\n",
      "          Validation Loss (standardized): 1.9652338024111968\n",
      "Epoch: 16, Loss (standarized): 0.7510331592606058\n",
      "          Validation Loss (standardized): 1.8677007434803654\n",
      "Epoch: 21, Loss (standarized): 0.7173147670521307\n",
      "          Validation Loss (standardized): 1.717325623843367\n",
      "Epoch: 26, Loss (standarized): 0.6829410556658652\n",
      "          Validation Loss (standardized): 1.6475131780211454\n",
      "Epoch: 31, Loss (standarized): 0.6570888248240747\n",
      "          Validation Loss (standardized): 1.6824675681087307\n",
      "Epoch: 36, Loss (standarized): 0.650314688228756\n",
      "          Validation Loss (standardized): 1.7452809175011823\n",
      "Epoch: 41, Loss (standarized): 0.6521989015468994\n",
      "          Validation Loss (standardized): 1.7572950175805826\n",
      "Epoch: 46, Loss (standarized): 0.650455433275077\n",
      "          Validation Loss (standardized): 1.7134599317276338\n",
      "Epoch: 51, Loss (standarized): 0.6486070856480685\n",
      "          Validation Loss (standardized): 1.6764590822296241\n",
      "Epoch: 56, Loss (standarized): 0.6492586694973704\n",
      "          Validation Loss (standardized): 1.6830445048201368\n",
      "Epoch: 61, Loss (standarized): 0.6499232177886441\n",
      "          Validation Loss (standardized): 1.7048203862931068\n",
      "Epoch: 66, Loss (standarized): 0.6490574124779377\n",
      "          Validation Loss (standardized): 1.706688439556374\n",
      "Epoch: 71, Loss (standarized): 0.6477422437721524\n",
      "          Validation Loss (standardized): 1.693093765909199\n",
      "Epoch: 76, Loss (standarized): 0.647027812807832\n",
      "          Validation Loss (standardized): 1.685557880950681\n",
      "Epoch: 81, Loss (standarized): 0.6466987399313686\n",
      "          Validation Loss (standardized): 1.6893482587036046\n",
      "Epoch: 86, Loss (standarized): 0.646573213193331\n",
      "          Validation Loss (standardized): 1.69363204649448\n",
      "Epoch: 91, Loss (standarized): 0.646576590155773\n",
      "          Validation Loss (standardized): 1.6912743871046578\n",
      "Epoch: 96, Loss (standarized): 0.6464553918691884\n",
      "          Validation Loss (standardized): 1.6869653705425243\n",
      "Final epoch: 100, Final loss (standarized): 0.6462126031510353\n",
      "Epoch: 1, Loss (standarized): 0.8831793048489093\n",
      "          Validation Loss (standardized): 1.740304196224334\n",
      "Epoch: 6, Loss (standarized): 0.8257111491529059\n",
      "          Validation Loss (standardized): 1.8622518643080521\n",
      "Epoch: 11, Loss (standarized): 0.7930223295655524\n",
      "          Validation Loss (standardized): 1.7590159766857545\n",
      "Epoch: 16, Loss (standarized): 0.779054662842559\n",
      "          Validation Loss (standardized): 1.7955716782165658\n",
      "Epoch: 21, Loss (standarized): 0.7644986963167342\n",
      "          Validation Loss (standardized): 1.780229837148416\n",
      "Epoch: 26, Loss (standarized): 0.7429982669003283\n",
      "          Validation Loss (standardized): 1.7576083436572316\n",
      "Epoch: 31, Loss (standarized): 0.7230851163148246\n",
      "          Validation Loss (standardized): 1.7488959256302088\n",
      "Epoch: 36, Loss (standarized): 0.6996962589779584\n",
      "          Validation Loss (standardized): 1.7316371676975413\n",
      "Epoch: 41, Loss (standarized): 0.6774217776446475\n",
      "          Validation Loss (standardized): 1.7203145485615066\n",
      "Epoch: 46, Loss (standarized): 0.6616688580301594\n",
      "          Validation Loss (standardized): 1.6995957551218959\n",
      "Epoch: 51, Loss (standarized): 0.6541271132310683\n",
      "          Validation Loss (standardized): 1.7048886317961789\n",
      "Epoch: 56, Loss (standarized): 0.6529000505039235\n",
      "          Validation Loss (standardized): 1.696824949008841\n",
      "Epoch: 61, Loss (standarized): 0.6534688160037655\n",
      "          Validation Loss (standardized): 1.698225916917261\n",
      "Epoch: 66, Loss (standarized): 0.6530558661002916\n",
      "          Validation Loss (standardized): 1.7008387087253622\n",
      "Epoch: 71, Loss (standarized): 0.6518441851984589\n",
      "          Validation Loss (standardized): 1.6902323529856709\n",
      "Epoch: 76, Loss (standarized): 0.6508929516528627\n",
      "          Validation Loss (standardized): 1.697993059152399\n",
      "Epoch: 81, Loss (standarized): 0.6505358434253359\n",
      "          Validation Loss (standardized): 1.687512544689017\n",
      "Epoch: 86, Loss (standarized): 0.6503832402693142\n",
      "          Validation Loss (standardized): 1.6954496400948007\n",
      "Epoch: 91, Loss (standarized): 0.6500939794887084\n",
      "          Validation Loss (standardized): 1.687412274972618\n",
      "Epoch: 96, Loss (standarized): 0.6496334160247453\n",
      "          Validation Loss (standardized): 1.692477310562402\n",
      "Final epoch: 100, Final loss (standarized): 0.6492431479521197\n",
      "Epoch: 1, Loss (standarized): 1.215904510575461\n",
      "          Validation Loss (standardized): 1.0839622140716998\n",
      "Epoch: 6, Loss (standarized): 0.8607553692917801\n",
      "          Validation Loss (standardized): 1.3652928732322787\n",
      "Epoch: 11, Loss (standarized): 0.7879858365967852\n",
      "          Validation Loss (standardized): 1.7278880561985899\n",
      "Epoch: 16, Loss (standarized): 0.7717310880746435\n",
      "          Validation Loss (standardized): 1.955116546143745\n",
      "Epoch: 21, Loss (standarized): 0.7546282255981492\n",
      "          Validation Loss (standardized): 2.0506947766436348\n",
      "Epoch: 26, Loss (standarized): 0.7296015553070441\n",
      "          Validation Loss (standardized): 2.0511649227876014\n",
      "Epoch: 31, Loss (standarized): 0.7003468442449915\n",
      "          Validation Loss (standardized): 1.9958569186071413\n",
      "Epoch: 36, Loss (standarized): 0.6745870486861065\n",
      "          Validation Loss (standardized): 1.9168808486904414\n",
      "Epoch: 41, Loss (standarized): 0.6593114994136975\n",
      "          Validation Loss (standardized): 1.8385119773307117\n",
      "Epoch: 46, Loss (standarized): 0.6548075143837419\n",
      "          Validation Loss (standardized): 1.7713226930604147\n",
      "Epoch: 51, Loss (standarized): 0.6548309761333445\n",
      "          Validation Loss (standardized): 1.713981467869362\n",
      "Epoch: 56, Loss (standarized): 0.6538017155899118\n",
      "          Validation Loss (standardized): 1.667997032665361\n",
      "Epoch: 61, Loss (standarized): 0.6514505436784371\n",
      "          Validation Loss (standardized): 1.6381843179980673\n",
      "Epoch: 66, Loss (standarized): 0.6499089999225947\n",
      "          Validation Loss (standardized): 1.6300585732981272\n",
      "Epoch: 71, Loss (standarized): 0.6493089006506655\n",
      "          Validation Loss (standardized): 1.6411267262627867\n",
      "Epoch: 76, Loss (standarized): 0.6485572600997299\n",
      "          Validation Loss (standardized): 1.6625720814223142\n",
      "Epoch: 81, Loss (standarized): 0.6476055469619677\n",
      "          Validation Loss (standardized): 1.6845440821332454\n",
      "Epoch: 86, Loss (standarized): 0.6468633609133755\n",
      "          Validation Loss (standardized): 1.6995030550980732\n",
      "Epoch: 91, Loss (standarized): 0.6462660311400653\n",
      "          Validation Loss (standardized): 1.7040945517387187\n",
      "Epoch: 96, Loss (standarized): 0.6455987593083079\n",
      "          Validation Loss (standardized): 1.6997612401667266\n",
      "Final epoch: 100, Final loss (standarized): 0.6450466817158161\n",
      "Epoch: 1, Loss (standarized): 1.7013113162561633\n",
      "          Validation Loss (standardized): 1.2435806759830803\n",
      "Epoch: 6, Loss (standarized): 1.011899018914726\n",
      "          Validation Loss (standardized): 1.231316245150769\n",
      "Epoch: 11, Loss (standarized): 0.8286318567234617\n",
      "          Validation Loss (standardized): 1.4447290115794849\n",
      "Epoch: 16, Loss (standarized): 0.7968720202088153\n",
      "          Validation Loss (standardized): 1.663039642042863\n",
      "Epoch: 21, Loss (standarized): 0.7850316382754778\n",
      "          Validation Loss (standardized): 1.8276863898757745\n",
      "Epoch: 26, Loss (standarized): 0.7808155687991112\n",
      "          Validation Loss (standardized): 1.9106090889213\n",
      "Epoch: 31, Loss (standarized): 0.7734969839690728\n",
      "          Validation Loss (standardized): 1.907457488943326\n",
      "Epoch: 36, Loss (standarized): 0.7650387262691146\n",
      "          Validation Loss (standardized): 1.8713869092733733\n",
      "Epoch: 41, Loss (standarized): 0.7536906949841525\n",
      "          Validation Loss (standardized): 1.8297288361176374\n",
      "Epoch: 46, Loss (standarized): 0.7416537509527742\n",
      "          Validation Loss (standardized): 1.7737045939979597\n",
      "Epoch: 51, Loss (standarized): 0.7289354729502807\n",
      "          Validation Loss (standardized): 1.710692546478853\n",
      "Epoch: 56, Loss (standarized): 0.716655565992241\n",
      "          Validation Loss (standardized): 1.670674217947662\n",
      "Epoch: 61, Loss (standarized): 0.705082765166121\n",
      "          Validation Loss (standardized): 1.6535531453555865\n",
      "Epoch: 66, Loss (standarized): 0.694745303076929\n",
      "          Validation Loss (standardized): 1.646805928338619\n",
      "Epoch: 71, Loss (standarized): 0.6863682246899635\n",
      "          Validation Loss (standardized): 1.655236211089351\n",
      "Epoch: 76, Loss (standarized): 0.6801939236157758\n",
      "          Validation Loss (standardized): 1.670298117708332\n",
      "Epoch: 81, Loss (standarized): 0.6759453060782787\n",
      "          Validation Loss (standardized): 1.6796860228509896\n",
      "Epoch: 86, Loss (standarized): 0.673187101857775\n",
      "          Validation Loss (standardized): 1.6872024511982835\n",
      "Epoch: 91, Loss (standarized): 0.6713378466338901\n",
      "          Validation Loss (standardized): 1.6884276511700675\n",
      "Epoch: 96, Loss (standarized): 0.6699470014464957\n",
      "          Validation Loss (standardized): 1.6859765591956553\n",
      "Final epoch: 100, Final loss (standarized): 0.6690096211685866\n",
      "Epoch: 1, Loss (standarized): 0.9554713055759855\n",
      "          Validation Loss (standardized): 1.2813437055228314\n",
      "Epoch: 6, Loss (standarized): 0.8244571028838271\n",
      "          Validation Loss (standardized): 1.6088074420578224\n",
      "Epoch: 11, Loss (standarized): 0.7874157799796574\n",
      "          Validation Loss (standardized): 1.8548120904482261\n",
      "Epoch: 16, Loss (standarized): 0.7831214280350596\n",
      "          Validation Loss (standardized): 1.9887760161752863\n",
      "Epoch: 21, Loss (standarized): 0.7669596311940332\n",
      "          Validation Loss (standardized): 2.00181281867498\n",
      "Epoch: 26, Loss (standarized): 0.744291756241942\n",
      "          Validation Loss (standardized): 1.8983546041319277\n",
      "Epoch: 31, Loss (standarized): 0.7200434493989911\n",
      "          Validation Loss (standardized): 1.7779353796454047\n",
      "Epoch: 36, Loss (standarized): 0.6945145269475745\n",
      "          Validation Loss (standardized): 1.6932728819304803\n",
      "Epoch: 41, Loss (standarized): 0.6729577487255398\n",
      "          Validation Loss (standardized): 1.6504672709885386\n",
      "Epoch: 46, Loss (standarized): 0.6597367645702609\n",
      "          Validation Loss (standardized): 1.6645902909612897\n",
      "Epoch: 51, Loss (standarized): 0.6553358411469824\n",
      "          Validation Loss (standardized): 1.704053867736396\n",
      "Epoch: 56, Loss (standarized): 0.6552314910889648\n",
      "          Validation Loss (standardized): 1.72434919751343\n",
      "Epoch: 61, Loss (standarized): 0.6546081679950865\n",
      "          Validation Loss (standardized): 1.725160449248915\n",
      "Epoch: 66, Loss (standarized): 0.6530136936539039\n",
      "          Validation Loss (standardized): 1.7050708422080711\n",
      "Epoch: 71, Loss (standarized): 0.6519569312870622\n",
      "          Validation Loss (standardized): 1.688606232171214\n",
      "Epoch: 76, Loss (standarized): 0.6517488465438778\n",
      "          Validation Loss (standardized): 1.682971704003823\n",
      "Epoch: 81, Loss (standarized): 0.6516364217490853\n",
      "          Validation Loss (standardized): 1.6877033753872133\n",
      "Epoch: 86, Loss (standarized): 0.651134277041269\n",
      "          Validation Loss (standardized): 1.695518946682461\n",
      "Epoch: 91, Loss (standarized): 0.6503585363789993\n",
      "          Validation Loss (standardized): 1.6990732484799758\n",
      "Epoch: 96, Loss (standarized): 0.6496277321979227\n",
      "          Validation Loss (standardized): 1.6973744476803936\n",
      "Final epoch: 100, Final loss (standarized): 0.6491735348865181\n",
      "Epoch: 1, Loss (standarized): 1.1893142936354064\n",
      "          Validation Loss (standardized): 1.2167259597540327\n",
      "Epoch: 6, Loss (standarized): 0.8548109091455792\n",
      "          Validation Loss (standardized): 1.3944576822958137\n",
      "Epoch: 11, Loss (standarized): 0.8242279645947994\n",
      "          Validation Loss (standardized): 1.680506270539862\n",
      "Epoch: 16, Loss (standarized): 0.7795979934944021\n",
      "          Validation Loss (standardized): 1.8430458491307307\n",
      "Epoch: 21, Loss (standarized): 0.7814132720537564\n",
      "          Validation Loss (standardized): 1.951683377809747\n",
      "Epoch: 26, Loss (standarized): 0.7596939869159173\n",
      "          Validation Loss (standardized): 1.9836496942630089\n",
      "Epoch: 31, Loss (standarized): 0.7475434712843524\n",
      "          Validation Loss (standardized): 1.9588037722196199\n",
      "Epoch: 36, Loss (standarized): 0.7247704335695174\n",
      "          Validation Loss (standardized): 1.885685716436139\n",
      "Epoch: 41, Loss (standarized): 0.7056701292308745\n",
      "          Validation Loss (standardized): 1.814450703884695\n",
      "Epoch: 46, Loss (standarized): 0.685143825667709\n",
      "          Validation Loss (standardized): 1.7590218648843787\n",
      "Epoch: 51, Loss (standarized): 0.670030917615836\n",
      "          Validation Loss (standardized): 1.7183667054797942\n",
      "Epoch: 56, Loss (standarized): 0.6601208987146812\n",
      "          Validation Loss (standardized): 1.6956157755107055\n",
      "Epoch: 61, Loss (standarized): 0.6559045378766959\n",
      "          Validation Loss (standardized): 1.6953325135659116\n",
      "Epoch: 66, Loss (standarized): 0.6552314075270428\n",
      "          Validation Loss (standardized): 1.703178997519963\n",
      "Epoch: 71, Loss (standarized): 0.6554090856209117\n",
      "          Validation Loss (standardized): 1.7055084958271691\n",
      "Epoch: 76, Loss (standarized): 0.6552393705997872\n",
      "          Validation Loss (standardized): 1.706510855248097\n",
      "Epoch: 81, Loss (standarized): 0.6544507146225764\n",
      "          Validation Loss (standardized): 1.7062338784600235\n",
      "Epoch: 86, Loss (standarized): 0.6535627054962699\n",
      "          Validation Loss (standardized): 1.702496255309147\n",
      "Epoch: 91, Loss (standarized): 0.652918171020362\n",
      "          Validation Loss (standardized): 1.7007124650416428\n",
      "Epoch: 96, Loss (standarized): 0.6524921296669356\n",
      "          Validation Loss (standardized): 1.7016037904968597\n",
      "Final epoch: 100, Final loss (standarized): 0.6522206366701149\n",
      "Epoch: 1, Loss (standarized): 1.073455400453543\n",
      "          Validation Loss (standardized): 1.1247604583346344\n",
      "Epoch: 6, Loss (standarized): 0.8294467175007008\n",
      "          Validation Loss (standardized): 1.459192114231129\n",
      "Epoch: 11, Loss (standarized): 0.7979069559606825\n",
      "          Validation Loss (standardized): 1.7258814120251569\n",
      "Epoch: 16, Loss (standarized): 0.7981993389988151\n",
      "          Validation Loss (standardized): 1.858074654756244\n",
      "Epoch: 21, Loss (standarized): 0.800532266385444\n",
      "          Validation Loss (standardized): 1.8978910167670273\n",
      "Epoch: 26, Loss (standarized): 0.8021654189037651\n",
      "          Validation Loss (standardized): 1.870953350246947\n",
      "Epoch: 31, Loss (standarized): 0.8028542518940496\n",
      "          Validation Loss (standardized): 1.8138759646940352\n",
      "Epoch: 36, Loss (standarized): 0.8036826306159107\n",
      "          Validation Loss (standardized): 1.7541300238114141\n",
      "Epoch: 41, Loss (standarized): 0.8053405128477191\n",
      "          Validation Loss (standardized): 1.695500062575027\n",
      "Epoch: 46, Loss (standarized): 0.807399376232289\n",
      "          Validation Loss (standardized): 1.6554946694113033\n",
      "Epoch: 51, Loss (standarized): 0.8084457526072663\n",
      "          Validation Loss (standardized): 1.6360005141044824\n",
      "Epoch: 56, Loss (standarized): 0.8091892965156582\n",
      "          Validation Loss (standardized): 1.624283755397997\n",
      "Epoch: 61, Loss (standarized): 0.8094292537278097\n",
      "          Validation Loss (standardized): 1.6237696476781607\n",
      "Epoch: 66, Loss (standarized): 0.8091367541614775\n",
      "          Validation Loss (standardized): 1.6287638766244454\n",
      "Epoch: 71, Loss (standarized): 0.8087091516959078\n",
      "          Validation Loss (standardized): 1.6385452271467436\n",
      "Epoch: 76, Loss (standarized): 0.8082516332486953\n",
      "          Validation Loss (standardized): 1.6464957682045536\n",
      "Epoch: 81, Loss (standarized): 0.8080757676226676\n",
      "          Validation Loss (standardized): 1.6502416052044704\n",
      "Epoch: 86, Loss (standarized): 0.8078838228941665\n",
      "          Validation Loss (standardized): 1.6529736149358754\n",
      "Epoch: 91, Loss (standarized): 0.8075705590146074\n",
      "          Validation Loss (standardized): 1.6595903094164284\n",
      "Epoch: 96, Loss (standarized): 0.8079102504757002\n",
      "          Validation Loss (standardized): 1.6484783090493564\n",
      "Final epoch: 100, Final loss (standarized): 0.8081513356353699\n",
      "Epoch: 1, Loss (standarized): 1.4260659311028612\n",
      "          Validation Loss (standardized): 1.8954502659793202\n",
      "Epoch: 6, Loss (standarized): 0.8603269955622352\n",
      "          Validation Loss (standardized): 1.570547825957203\n",
      "Epoch: 11, Loss (standarized): 0.8333010997891619\n",
      "          Validation Loss (standardized): 1.68389244248265\n",
      "Epoch: 16, Loss (standarized): 0.8387058911128826\n",
      "          Validation Loss (standardized): 1.7094903090370626\n",
      "Epoch: 21, Loss (standarized): 0.8058209659567402\n",
      "          Validation Loss (standardized): 1.67904628288138\n",
      "Epoch: 26, Loss (standarized): 0.8171819147612258\n",
      "          Validation Loss (standardized): 1.6616773696827103\n",
      "Epoch: 31, Loss (standarized): 0.8177521173506208\n",
      "          Validation Loss (standardized): 1.616620941598146\n",
      "Epoch: 36, Loss (standarized): 0.8119027450914802\n",
      "          Validation Loss (standardized): 1.5898684114694823\n",
      "Epoch: 41, Loss (standarized): 0.8125548093354887\n",
      "          Validation Loss (standardized): 1.5934366264049802\n",
      "Epoch: 46, Loss (standarized): 0.8106443838086581\n",
      "          Validation Loss (standardized): 1.61060131022419\n",
      "Epoch: 51, Loss (standarized): 0.8097252236343029\n",
      "          Validation Loss (standardized): 1.6262626172020833\n",
      "Epoch: 56, Loss (standarized): 0.8091116961084015\n",
      "          Validation Loss (standardized): 1.6294202311671113\n",
      "Epoch: 61, Loss (standarized): 0.8093965354730043\n",
      "          Validation Loss (standardized): 1.6209670206179239\n",
      "Epoch: 66, Loss (standarized): 0.809695147342696\n",
      "          Validation Loss (standardized): 1.6167233552458058\n",
      "Epoch: 71, Loss (standarized): 0.8096300789949624\n",
      "          Validation Loss (standardized): 1.6169795998704777\n",
      "Epoch: 76, Loss (standarized): 0.8095239757792216\n",
      "          Validation Loss (standardized): 1.6206799151154396\n",
      "Epoch: 81, Loss (standarized): 0.8092677640708403\n",
      "          Validation Loss (standardized): 1.6248136744535095\n",
      "Epoch: 86, Loss (standarized): 0.8093304296252635\n",
      "          Validation Loss (standardized): 1.6236617295096807\n",
      "Epoch: 91, Loss (standarized): 0.8093381751380144\n",
      "          Validation Loss (standardized): 1.6230947012171273\n",
      "Epoch: 96, Loss (standarized): 0.8092180490753935\n",
      "          Validation Loss (standardized): 1.6251627353537026\n",
      "Final epoch: 100, Final loss (standarized): 0.8090148332758386\n",
      "Epoch: 1, Loss (standarized): 1.3851567661285107\n",
      "          Validation Loss (standardized): 1.6419271363085173\n",
      "Epoch: 6, Loss (standarized): 0.8871919837745107\n",
      "          Validation Loss (standardized): 1.3017906105522854\n",
      "Epoch: 11, Loss (standarized): 0.8614434053767565\n",
      "          Validation Loss (standardized): 1.4826382241273603\n",
      "Epoch: 16, Loss (standarized): 0.8156658893281957\n",
      "          Validation Loss (standardized): 1.6549932680427737\n",
      "Epoch: 21, Loss (standarized): 0.8020681311989527\n",
      "          Validation Loss (standardized): 1.7959355557452537\n",
      "Epoch: 26, Loss (standarized): 0.8065332587557739\n",
      "          Validation Loss (standardized): 1.819335718859098\n",
      "Epoch: 31, Loss (standarized): 0.8012139890674043\n",
      "          Validation Loss (standardized): 1.7783965778202266\n",
      "Epoch: 36, Loss (standarized): 0.8044661613631636\n",
      "          Validation Loss (standardized): 1.7518606979145959\n",
      "Epoch: 41, Loss (standarized): 0.8032325377164671\n",
      "          Validation Loss (standardized): 1.7506660797333453\n",
      "Epoch: 46, Loss (standarized): 0.8047472214205538\n",
      "          Validation Loss (standardized): 1.727125827287498\n",
      "Epoch: 51, Loss (standarized): 0.8059677751266697\n",
      "          Validation Loss (standardized): 1.6819101978447175\n",
      "Epoch: 56, Loss (standarized): 0.8072905894921705\n",
      "          Validation Loss (standardized): 1.6622666971765907\n",
      "Epoch: 61, Loss (standarized): 0.8076345202763938\n",
      "          Validation Loss (standardized): 1.6598755593004464\n",
      "Epoch: 66, Loss (standarized): 0.8077265984585419\n",
      "          Validation Loss (standardized): 1.6563196301297645\n",
      "Epoch: 71, Loss (standarized): 0.8078979434754\n",
      "          Validation Loss (standardized): 1.651130034541804\n",
      "Epoch: 76, Loss (standarized): 0.8080901341535528\n",
      "          Validation Loss (standardized): 1.6465769226949027\n",
      "Epoch: 81, Loss (standarized): 0.8083458058091841\n",
      "          Validation Loss (standardized): 1.6420988578666242\n",
      "Epoch: 86, Loss (standarized): 0.8083347249139171\n",
      "          Validation Loss (standardized): 1.645116694288607\n",
      "Epoch: 91, Loss (standarized): 0.8080966819843626\n",
      "          Validation Loss (standardized): 1.6507471147970973\n",
      "Epoch: 96, Loss (standarized): 0.8080131507706831\n",
      "          Validation Loss (standardized): 1.6505885968496354\n",
      "Final epoch: 100, Final loss (standarized): 0.8081365714129727\n",
      "Epoch: 1, Loss (standarized): 1.4937864491457113\n",
      "          Validation Loss (standardized): 1.0809075395123313\n",
      "Epoch: 6, Loss (standarized): 0.994403504989445\n",
      "          Validation Loss (standardized): 1.1675132913238195\n",
      "Epoch: 11, Loss (standarized): 0.8512384422167625\n",
      "          Validation Loss (standardized): 1.3962390239366282\n",
      "Epoch: 16, Loss (standarized): 0.8165001373142025\n",
      "          Validation Loss (standardized): 1.598155182184074\n",
      "Epoch: 21, Loss (standarized): 0.8102710424637171\n",
      "          Validation Loss (standardized): 1.7183467187724424\n",
      "Epoch: 26, Loss (standarized): 0.8046278793067059\n",
      "          Validation Loss (standardized): 1.766315708842569\n",
      "Epoch: 31, Loss (standarized): 0.8046141544275514\n",
      "          Validation Loss (standardized): 1.7841797751014141\n",
      "Epoch: 36, Loss (standarized): 0.8045030624562064\n",
      "          Validation Loss (standardized): 1.7864893915859104\n",
      "Epoch: 41, Loss (standarized): 0.8052093408281529\n",
      "          Validation Loss (standardized): 1.7813985583065\n",
      "Epoch: 46, Loss (standarized): 0.8049956704045976\n",
      "          Validation Loss (standardized): 1.7612868454991577\n",
      "Epoch: 51, Loss (standarized): 0.8052090166705241\n",
      "          Validation Loss (standardized): 1.7360268360714366\n",
      "Epoch: 56, Loss (standarized): 0.8057362386690263\n",
      "          Validation Loss (standardized): 1.714766527792655\n",
      "Epoch: 61, Loss (standarized): 0.8064291058853534\n",
      "          Validation Loss (standardized): 1.6936805020625065\n",
      "Epoch: 66, Loss (standarized): 0.806786400772976\n",
      "          Validation Loss (standardized): 1.6770242063512433\n",
      "Epoch: 71, Loss (standarized): 0.8072568071584146\n",
      "          Validation Loss (standardized): 1.6647322484617892\n",
      "Epoch: 76, Loss (standarized): 0.8079269975732186\n",
      "          Validation Loss (standardized): 1.654117424495657\n",
      "Epoch: 81, Loss (standarized): 0.8080869699745823\n",
      "          Validation Loss (standardized): 1.6476001822662931\n",
      "Epoch: 86, Loss (standarized): 0.8081701174485432\n",
      "          Validation Loss (standardized): 1.645889230332051\n",
      "Epoch: 91, Loss (standarized): 0.8083466695641194\n",
      "          Validation Loss (standardized): 1.6419536113346311\n",
      "Epoch: 96, Loss (standarized): 0.808477629196765\n",
      "          Validation Loss (standardized): 1.6396023619801172\n",
      "Final epoch: 100, Final loss (standarized): 0.8085797707776647\n",
      "Epoch: 1, Loss (standarized): 0.9524114285462605\n",
      "          Validation Loss (standardized): 1.2460427628152944\n",
      "Epoch: 6, Loss (standarized): 0.7949591263901693\n",
      "          Validation Loss (standardized): 1.7306919331793906\n",
      "Epoch: 11, Loss (standarized): 0.7738468466843984\n",
      "          Validation Loss (standardized): 2.0325182805585946\n",
      "Epoch: 16, Loss (standarized): 0.7541333233211404\n",
      "          Validation Loss (standardized): 2.0800491819756224\n",
      "Epoch: 21, Loss (standarized): 0.7247408058103461\n",
      "          Validation Loss (standardized): 1.9694307262703046\n",
      "Epoch: 26, Loss (standarized): 0.6932095025442722\n",
      "          Validation Loss (standardized): 1.7992435963695625\n",
      "Epoch: 31, Loss (standarized): 0.6694231413760598\n",
      "          Validation Loss (standardized): 1.6564815519769696\n",
      "Epoch: 36, Loss (standarized): 0.6572326836934059\n",
      "          Validation Loss (standardized): 1.597674577722765\n",
      "Epoch: 41, Loss (standarized): 0.6528136047562799\n",
      "          Validation Loss (standardized): 1.6187176926627709\n",
      "Epoch: 46, Loss (standarized): 0.6515979888486403\n",
      "          Validation Loss (standardized): 1.6657523324809331\n",
      "Epoch: 51, Loss (standarized): 0.6510858770275937\n",
      "          Validation Loss (standardized): 1.6885070668066091\n",
      "Epoch: 56, Loss (standarized): 0.6513005426789997\n",
      "          Validation Loss (standardized): 1.681003020042891\n",
      "Epoch: 61, Loss (standarized): 0.6522922455657927\n",
      "          Validation Loss (standardized): 1.6665284390277408\n",
      "Epoch: 66, Loss (standarized): 0.6528376339833695\n",
      "          Validation Loss (standardized): 1.662871605315407\n",
      "Epoch: 71, Loss (standarized): 0.6524557836920463\n",
      "          Validation Loss (standardized): 1.665784778381358\n",
      "Epoch: 76, Loss (standarized): 0.6516280029351255\n",
      "          Validation Loss (standardized): 1.670647178728274\n",
      "Epoch: 81, Loss (standarized): 0.6509854837623419\n",
      "          Validation Loss (standardized): 1.6731000092357795\n",
      "Epoch: 86, Loss (standarized): 0.6505909135210004\n",
      "          Validation Loss (standardized): 1.6750088736048427\n",
      "Epoch: 91, Loss (standarized): 0.6502867288342333\n",
      "          Validation Loss (standardized): 1.6709167325021812\n",
      "Epoch: 96, Loss (standarized): 0.6500708675148141\n",
      "          Validation Loss (standardized): 1.6704801094118147\n",
      "Final epoch: 100, Final loss (standarized): 0.6499261076727578\n",
      "Epoch: 1, Loss (standarized): 1.2226803179066474\n",
      "          Validation Loss (standardized): 1.2234299826027055\n",
      "Epoch: 6, Loss (standarized): 0.8518372973334752\n",
      "          Validation Loss (standardized): 1.3960185967165175\n",
      "Epoch: 11, Loss (standarized): 0.7999539397934115\n",
      "          Validation Loss (standardized): 1.739854724478258\n",
      "Epoch: 16, Loss (standarized): 0.795560685640626\n",
      "          Validation Loss (standardized): 1.9595228346646505\n",
      "Epoch: 21, Loss (standarized): 0.7935198202830263\n",
      "          Validation Loss (standardized): 1.9843690794858735\n",
      "Epoch: 26, Loss (standarized): 0.7893414560853578\n",
      "          Validation Loss (standardized): 1.963225016381722\n",
      "Epoch: 31, Loss (standarized): 0.783220836421563\n",
      "          Validation Loss (standardized): 1.8945609296448647\n",
      "Epoch: 36, Loss (standarized): 0.7764004757720245\n",
      "          Validation Loss (standardized): 1.7924789675812838\n",
      "Epoch: 41, Loss (standarized): 0.7707148012783732\n",
      "          Validation Loss (standardized): 1.7252460695207923\n",
      "Epoch: 46, Loss (standarized): 0.7655713415273103\n",
      "          Validation Loss (standardized): 1.6717758325752015\n",
      "Epoch: 51, Loss (standarized): 0.7595763425391934\n",
      "          Validation Loss (standardized): 1.6510494704326404\n",
      "Epoch: 56, Loss (standarized): 0.7522821987668133\n",
      "          Validation Loss (standardized): 1.6621726400957804\n",
      "Epoch: 61, Loss (standarized): 0.7436710705817471\n",
      "          Validation Loss (standardized): 1.6788503480179524\n",
      "Epoch: 66, Loss (standarized): 0.7345270869934072\n",
      "          Validation Loss (standardized): 1.701926268633922\n",
      "Epoch: 71, Loss (standarized): 0.7248988256439807\n",
      "          Validation Loss (standardized): 1.7129404114318663\n",
      "Epoch: 76, Loss (standarized): 0.7152086631180244\n",
      "          Validation Loss (standardized): 1.7175241503817225\n",
      "Epoch: 81, Loss (standarized): 0.7057000745615933\n",
      "          Validation Loss (standardized): 1.711987388162572\n",
      "Epoch: 86, Loss (standarized): 0.697157662870134\n",
      "          Validation Loss (standardized): 1.7060124856801127\n",
      "Epoch: 91, Loss (standarized): 0.6901027273309392\n",
      "          Validation Loss (standardized): 1.699252273848597\n",
      "Epoch: 96, Loss (standarized): 0.6849359897199345\n",
      "          Validation Loss (standardized): 1.6945621988887023\n",
      "Final epoch: 100, Final loss (standarized): 0.6821002147702627\n",
      "Epoch: 1, Loss (standarized): 0.8906904826643743\n",
      "          Validation Loss (standardized): 1.349424600893194\n",
      "Epoch: 6, Loss (standarized): 0.7975763113952142\n",
      "          Validation Loss (standardized): 1.7632525873655245\n",
      "Epoch: 11, Loss (standarized): 0.782742054777691\n",
      "          Validation Loss (standardized): 1.9970615324368275\n",
      "Epoch: 16, Loss (standarized): 0.7672120298209631\n",
      "          Validation Loss (standardized): 1.9991079521684851\n",
      "Epoch: 21, Loss (standarized): 0.7432739388608696\n",
      "          Validation Loss (standardized): 1.8924661086323422\n",
      "Epoch: 26, Loss (standarized): 0.7157855668449261\n",
      "          Validation Loss (standardized): 1.7571189028844258\n",
      "Epoch: 31, Loss (standarized): 0.688994911331971\n",
      "          Validation Loss (standardized): 1.683271158922369\n",
      "Epoch: 36, Loss (standarized): 0.667130575603814\n",
      "          Validation Loss (standardized): 1.6847584162367153\n",
      "Epoch: 41, Loss (standarized): 0.6557207464823059\n",
      "          Validation Loss (standardized): 1.7235686927510259\n",
      "Epoch: 46, Loss (standarized): 0.6529815386222511\n",
      "          Validation Loss (standardized): 1.74624797080267\n",
      "Epoch: 51, Loss (standarized): 0.6527793474555318\n",
      "          Validation Loss (standardized): 1.7301407312853154\n",
      "Epoch: 56, Loss (standarized): 0.6538528779875928\n",
      "          Validation Loss (standardized): 1.7014652022113803\n",
      "Epoch: 61, Loss (standarized): 0.6558700532757544\n",
      "          Validation Loss (standardized): 1.6911670122663238\n",
      "Epoch: 66, Loss (standarized): 0.656688026655887\n",
      "          Validation Loss (standardized): 1.700077427158696\n",
      "Epoch: 71, Loss (standarized): 0.6560156684373186\n",
      "          Validation Loss (standardized): 1.7131350758084956\n",
      "Epoch: 76, Loss (standarized): 0.6547958172806781\n",
      "          Validation Loss (standardized): 1.7165369915825355\n",
      "Epoch: 81, Loss (standarized): 0.6539257067717587\n",
      "          Validation Loss (standardized): 1.7127394511783514\n",
      "Epoch: 86, Loss (standarized): 0.6536180877196698\n",
      "          Validation Loss (standardized): 1.7092106255853672\n",
      "Epoch: 91, Loss (standarized): 0.6535572860996731\n",
      "          Validation Loss (standardized): 1.7078839463029212\n",
      "Epoch: 96, Loss (standarized): 0.6535680061826424\n",
      "          Validation Loss (standardized): 1.7043059340466602\n",
      "Final epoch: 100, Final loss (standarized): 0.6534165411785838\n",
      "Epoch: 1, Loss (standarized): 1.5403216547790761\n",
      "          Validation Loss (standardized): 1.0808552372528157\n",
      "Epoch: 6, Loss (standarized): 0.8957502526773473\n",
      "          Validation Loss (standardized): 1.3466374478640373\n",
      "Epoch: 11, Loss (standarized): 0.8081606442162348\n",
      "          Validation Loss (standardized): 1.8181045077502762\n",
      "Epoch: 16, Loss (standarized): 0.7996046764891738\n",
      "          Validation Loss (standardized): 2.0816982980914647\n",
      "Epoch: 21, Loss (standarized): 0.8016832854212318\n",
      "          Validation Loss (standardized): 2.2126485262580937\n",
      "Epoch: 26, Loss (standarized): 0.7954272342418542\n",
      "          Validation Loss (standardized): 2.250699223105138\n",
      "Epoch: 31, Loss (standarized): 0.7863512414504826\n",
      "          Validation Loss (standardized): 2.1987402807055005\n",
      "Epoch: 36, Loss (standarized): 0.7737862721640857\n",
      "          Validation Loss (standardized): 2.099012627009361\n",
      "Epoch: 41, Loss (standarized): 0.7594995745777829\n",
      "          Validation Loss (standardized): 1.9931496645351776\n",
      "Epoch: 46, Loss (standarized): 0.7450507712327921\n",
      "          Validation Loss (standardized): 1.8866082648066564\n",
      "Epoch: 51, Loss (standarized): 0.7305545789914702\n",
      "          Validation Loss (standardized): 1.790456578372317\n",
      "Epoch: 56, Loss (standarized): 0.7161832403934756\n",
      "          Validation Loss (standardized): 1.7265009354585845\n",
      "Epoch: 61, Loss (standarized): 0.7017707194302847\n",
      "          Validation Loss (standardized): 1.6937785678284853\n",
      "Epoch: 66, Loss (standarized): 0.688210919214127\n",
      "          Validation Loss (standardized): 1.6813946872288557\n",
      "Epoch: 71, Loss (standarized): 0.6769841496600867\n",
      "          Validation Loss (standardized): 1.6892663626859703\n",
      "Epoch: 76, Loss (standarized): 0.6690708233806009\n",
      "          Validation Loss (standardized): 1.7066994998801024\n",
      "Epoch: 81, Loss (standarized): 0.6644488728903278\n",
      "          Validation Loss (standardized): 1.7212477203066663\n",
      "Epoch: 86, Loss (standarized): 0.6621329683889002\n",
      "          Validation Loss (standardized): 1.7322106275672036\n",
      "Epoch: 91, Loss (standarized): 0.6610579490706\n",
      "          Validation Loss (standardized): 1.7372035117471023\n",
      "Epoch: 96, Loss (standarized): 0.6605114379949072\n",
      "          Validation Loss (standardized): 1.7364607689904565\n",
      "Final epoch: 100, Final loss (standarized): 0.6603085857376949\n",
      "Epoch: 1, Loss (standarized): 0.9930669270605066\n",
      "          Validation Loss (standardized): 1.3831034822568682\n",
      "Epoch: 6, Loss (standarized): 0.8301477229220892\n",
      "          Validation Loss (standardized): 1.556977381958317\n",
      "Epoch: 11, Loss (standarized): 0.7917870577894883\n",
      "          Validation Loss (standardized): 1.8993310004354707\n",
      "Epoch: 16, Loss (standarized): 0.7886452149140456\n",
      "          Validation Loss (standardized): 2.042704808795833\n",
      "Epoch: 21, Loss (standarized): 0.7706725354803452\n",
      "          Validation Loss (standardized): 1.9953950106216538\n",
      "Epoch: 26, Loss (standarized): 0.7500088102696216\n",
      "          Validation Loss (standardized): 1.9282822077836226\n",
      "Epoch: 31, Loss (standarized): 0.7268853894940046\n",
      "          Validation Loss (standardized): 1.8349730321042335\n",
      "Epoch: 36, Loss (standarized): 0.7016605678110003\n",
      "          Validation Loss (standardized): 1.7155437530736197\n",
      "Epoch: 41, Loss (standarized): 0.6801848946100006\n",
      "          Validation Loss (standardized): 1.6675739579845203\n",
      "Epoch: 46, Loss (standarized): 0.6642192501342805\n",
      "          Validation Loss (standardized): 1.6775811438353843\n",
      "Epoch: 51, Loss (standarized): 0.6560916866758236\n",
      "          Validation Loss (standardized): 1.7015151187731499\n",
      "Epoch: 56, Loss (standarized): 0.654783571784585\n",
      "          Validation Loss (standardized): 1.750240697007578\n",
      "Epoch: 61, Loss (standarized): 0.655394228183547\n",
      "          Validation Loss (standardized): 1.7697316483701633\n",
      "Epoch: 66, Loss (standarized): 0.6546959192686157\n",
      "          Validation Loss (standardized): 1.759521817139661\n",
      "Epoch: 71, Loss (standarized): 0.6530500123591964\n",
      "          Validation Loss (standardized): 1.7412655071488563\n",
      "Epoch: 76, Loss (standarized): 0.6517651768866746\n",
      "          Validation Loss (standardized): 1.714422627408111\n",
      "Epoch: 81, Loss (standarized): 0.6511742318363917\n",
      "          Validation Loss (standardized): 1.7026748760679087\n",
      "Epoch: 86, Loss (standarized): 0.6508211238043335\n",
      "          Validation Loss (standardized): 1.6976617769324414\n",
      "Epoch: 91, Loss (standarized): 0.6503584758938235\n",
      "          Validation Loss (standardized): 1.7006055244107081\n",
      "Epoch: 96, Loss (standarized): 0.6497844106214101\n",
      "          Validation Loss (standardized): 1.7031319171888708\n",
      "Final epoch: 100, Final loss (standarized): 0.6493355051635304\n",
      "Epoch: 1, Loss (standarized): 1.1612177262286516\n",
      "          Validation Loss (standardized): 1.3704582059791612\n",
      "Epoch: 6, Loss (standarized): 0.8151257162953611\n",
      "          Validation Loss (standardized): 1.6080504669443199\n",
      "Epoch: 11, Loss (standarized): 0.8417757902045514\n",
      "          Validation Loss (standardized): 1.8858230853899758\n",
      "Epoch: 16, Loss (standarized): 0.7898725765244272\n",
      "          Validation Loss (standardized): 1.8779888058456744\n",
      "Epoch: 21, Loss (standarized): 0.7955367308666563\n",
      "          Validation Loss (standardized): 1.8473451088205926\n",
      "Epoch: 26, Loss (standarized): 0.7817129678293361\n",
      "          Validation Loss (standardized): 1.7903222850038107\n",
      "Epoch: 31, Loss (standarized): 0.7727318540658522\n",
      "          Validation Loss (standardized): 1.7579712313434652\n",
      "Epoch: 36, Loss (standarized): 0.768984926983224\n",
      "          Validation Loss (standardized): 1.7255062475053864\n",
      "Epoch: 41, Loss (standarized): 0.7604213050956996\n",
      "          Validation Loss (standardized): 1.7076666586161546\n",
      "Epoch: 46, Loss (standarized): 0.7550024513774775\n",
      "          Validation Loss (standardized): 1.7246584301405632\n",
      "Epoch: 51, Loss (standarized): 0.746149244427178\n",
      "          Validation Loss (standardized): 1.7498703913738416\n",
      "Epoch: 56, Loss (standarized): 0.7387083783761448\n",
      "          Validation Loss (standardized): 1.7495426448456586\n",
      "Epoch: 61, Loss (standarized): 0.7302178364453203\n",
      "          Validation Loss (standardized): 1.725672420422824\n",
      "Epoch: 66, Loss (standarized): 0.7219892552570208\n",
      "          Validation Loss (standardized): 1.7113090278073686\n",
      "Epoch: 71, Loss (standarized): 0.7131972820876955\n",
      "          Validation Loss (standardized): 1.7109216015708195\n",
      "Epoch: 76, Loss (standarized): 0.7049239186709022\n",
      "          Validation Loss (standardized): 1.7092290410354425\n",
      "Epoch: 81, Loss (standarized): 0.6974241959916453\n",
      "          Validation Loss (standardized): 1.7075007612789606\n",
      "Epoch: 86, Loss (standarized): 0.6908263991136911\n",
      "          Validation Loss (standardized): 1.7085916504702778\n",
      "Epoch: 91, Loss (standarized): 0.6854840830846214\n",
      "          Validation Loss (standardized): 1.7040988278241902\n",
      "Epoch: 96, Loss (standarized): 0.6813468144818802\n",
      "          Validation Loss (standardized): 1.6975348088354476\n",
      "Final epoch: 100, Final loss (standarized): 0.6787422188768881\n",
      "Epoch: 1, Loss (standarized): 1.4355975208919705\n",
      "          Validation Loss (standardized): 1.1168956720521819\n",
      "Epoch: 6, Loss (standarized): 0.9108924921327296\n",
      "          Validation Loss (standardized): 1.2403942820976408\n",
      "Epoch: 11, Loss (standarized): 0.7940910060555499\n",
      "          Validation Loss (standardized): 1.5823182578693258\n",
      "Epoch: 16, Loss (standarized): 0.7741854478878408\n",
      "          Validation Loss (standardized): 1.8635020382142748\n",
      "Epoch: 21, Loss (standarized): 0.7669679994278595\n",
      "          Validation Loss (standardized): 2.0155547105606413\n",
      "Epoch: 26, Loss (standarized): 0.753872263180688\n",
      "          Validation Loss (standardized): 2.0503230871507196\n",
      "Epoch: 31, Loss (standarized): 0.7344076885078716\n",
      "          Validation Loss (standardized): 2.0172179266695136\n",
      "Epoch: 36, Loss (standarized): 0.7109676179321068\n",
      "          Validation Loss (standardized): 1.9439324913998999\n",
      "Epoch: 41, Loss (standarized): 0.6888929149298383\n",
      "          Validation Loss (standardized): 1.8504116660203973\n",
      "Epoch: 46, Loss (standarized): 0.6727768022382797\n",
      "          Validation Loss (standardized): 1.7694286874301057\n",
      "Epoch: 51, Loss (standarized): 0.6639069418967927\n",
      "          Validation Loss (standardized): 1.7174492033382411\n",
      "Epoch: 56, Loss (standarized): 0.6603863581445873\n",
      "          Validation Loss (standardized): 1.6875004879997828\n",
      "Epoch: 61, Loss (standarized): 0.6591698555224796\n",
      "          Validation Loss (standardized): 1.6743375580734419\n",
      "Epoch: 66, Loss (standarized): 0.6582229045057402\n",
      "          Validation Loss (standardized): 1.673748316062844\n",
      "Epoch: 71, Loss (standarized): 0.657063414246191\n",
      "          Validation Loss (standardized): 1.6776414755922853\n",
      "Epoch: 76, Loss (standarized): 0.6560208154693922\n",
      "          Validation Loss (standardized): 1.684670266239577\n",
      "Epoch: 81, Loss (standarized): 0.6553643805924534\n",
      "          Validation Loss (standardized): 1.6937500638498506\n",
      "Epoch: 86, Loss (standarized): 0.6549586681325419\n",
      "          Validation Loss (standardized): 1.7005539929167444\n",
      "Epoch: 91, Loss (standarized): 0.6545139446165588\n",
      "          Validation Loss (standardized): 1.7049606411764093\n",
      "Epoch: 96, Loss (standarized): 0.6538946875764047\n",
      "          Validation Loss (standardized): 1.706034219877552\n",
      "Final epoch: 100, Final loss (standarized): 0.653318292378724\n",
      "Epoch: 1, Loss (standarized): 1.0416558740002504\n",
      "          Validation Loss (standardized): 1.1398108282281838\n",
      "Epoch: 6, Loss (standarized): 0.8076501629236719\n",
      "          Validation Loss (standardized): 1.5801705949093565\n",
      "Epoch: 11, Loss (standarized): 0.7797854539912658\n",
      "          Validation Loss (standardized): 1.9293148059221967\n",
      "Epoch: 16, Loss (standarized): 0.7691218448032398\n",
      "          Validation Loss (standardized): 2.08672144384893\n",
      "Epoch: 21, Loss (standarized): 0.7497308561566277\n",
      "          Validation Loss (standardized): 2.0957929322017503\n",
      "Epoch: 26, Loss (standarized): 0.7219126829755681\n",
      "          Validation Loss (standardized): 2.011172667258833\n",
      "Epoch: 31, Loss (standarized): 0.6920108280382837\n",
      "          Validation Loss (standardized): 1.88860802198699\n",
      "Epoch: 36, Loss (standarized): 0.6685007186084315\n",
      "          Validation Loss (standardized): 1.7678440751536564\n",
      "Epoch: 41, Loss (standarized): 0.6570002101693633\n",
      "          Validation Loss (standardized): 1.6854655580530187\n",
      "Epoch: 46, Loss (standarized): 0.6553545904791245\n",
      "          Validation Loss (standardized): 1.6456375821480689\n",
      "Epoch: 51, Loss (standarized): 0.6561338049907177\n",
      "          Validation Loss (standardized): 1.640984842697691\n",
      "Epoch: 56, Loss (standarized): 0.6548077031645394\n",
      "          Validation Loss (standardized): 1.6528644296478974\n",
      "Epoch: 61, Loss (standarized): 0.6522060826711702\n",
      "          Validation Loss (standardized): 1.6718158439148616\n",
      "Epoch: 66, Loss (standarized): 0.650497575693779\n",
      "          Validation Loss (standardized): 1.6889571280854765\n",
      "Epoch: 71, Loss (standarized): 0.6499879528480247\n",
      "          Validation Loss (standardized): 1.7006123650934406\n",
      "Epoch: 76, Loss (standarized): 0.6495635139922518\n",
      "          Validation Loss (standardized): 1.704362475612927\n",
      "Epoch: 81, Loss (standarized): 0.6487232992631352\n",
      "          Validation Loss (standardized): 1.7010915419590535\n",
      "Epoch: 86, Loss (standarized): 0.6478463195897235\n",
      "          Validation Loss (standardized): 1.6940819669439895\n",
      "Epoch: 91, Loss (standarized): 0.6471953754168338\n",
      "          Validation Loss (standardized): 1.6860516033133894\n",
      "Epoch: 96, Loss (standarized): 0.6466522535713148\n",
      "          Validation Loss (standardized): 1.6799056743945808\n",
      "Final epoch: 100, Final loss (standarized): 0.6462287473725168\n",
      "Epoch: 1, Loss (standarized): 1.0873438906040722\n",
      "Epoch: 6, Loss (standarized): 0.7929938058697649\n",
      "Epoch: 11, Loss (standarized): 0.7105673648039191\n",
      "Epoch: 16, Loss (standarized): 0.6572520053588362\n",
      "Epoch: 21, Loss (standarized): 0.6409026184041209\n",
      "Epoch: 26, Loss (standarized): 0.6401749503956821\n",
      "Epoch: 31, Loss (standarized): 0.6218434540521509\n",
      "Epoch: 36, Loss (standarized): 0.5988978186362888\n",
      "Epoch: 41, Loss (standarized): 0.5677998651323545\n",
      "Epoch: 46, Loss (standarized): 0.5324485599608191\n",
      "Epoch: 51, Loss (standarized): 0.48976143192673627\n",
      "Epoch: 56, Loss (standarized): 0.44763726425309175\n",
      "Epoch: 61, Loss (standarized): 0.4094681488352736\n",
      "Epoch: 66, Loss (standarized): 0.37308467050098243\n",
      "Epoch: 71, Loss (standarized): 0.3354680478402675\n",
      "Epoch: 76, Loss (standarized): 0.29753950661721545\n",
      "Epoch: 81, Loss (standarized): 0.2628585883580202\n",
      "Epoch: 86, Loss (standarized): 0.2351869691593256\n",
      "Epoch: 91, Loss (standarized): 0.2154598522877065\n",
      "Epoch: 96, Loss (standarized): 0.20110398212729183\n",
      "Final epoch: 100, Final loss (standarized): 0.19152830258092074\n",
      "Epoch: 1, Loss (standarized): 1.2354048808584974\n",
      "Epoch: 6, Loss (standarized): 0.8140986567958745\n",
      "Epoch: 11, Loss (standarized): 0.7432227363968359\n",
      "Epoch: 16, Loss (standarized): 0.6797464605786249\n",
      "Epoch: 21, Loss (standarized): 0.6550885485901855\n",
      "Epoch: 26, Loss (standarized): 0.6590991415046187\n",
      "Epoch: 31, Loss (standarized): 0.6533146963677293\n",
      "Epoch: 36, Loss (standarized): 0.648111925122111\n",
      "Epoch: 41, Loss (standarized): 0.6474630585496647\n",
      "Epoch: 46, Loss (standarized): 0.6475102739510332\n",
      "Epoch: 51, Loss (standarized): 0.6480984082600927\n",
      "Epoch: 56, Loss (standarized): 0.6467793764853463\n",
      "Epoch: 61, Loss (standarized): 0.6450595055888607\n",
      "Epoch: 66, Loss (standarized): 0.6443585975143732\n",
      "Epoch: 71, Loss (standarized): 0.6442703214119979\n",
      "Epoch: 76, Loss (standarized): 0.6444482835783854\n",
      "Epoch: 81, Loss (standarized): 0.6443716108229628\n",
      "Epoch: 86, Loss (standarized): 0.6440082252578674\n",
      "Epoch: 91, Loss (standarized): 0.6436315509870557\n",
      "Epoch: 96, Loss (standarized): 0.6433875821322225\n",
      "Final epoch: 100, Final loss (standarized): 0.6432370250130098\n",
      "Epoch: 1, Loss (standarized): 1.2828633812997736\n",
      "Epoch: 6, Loss (standarized): 0.809067324635698\n",
      "Epoch: 11, Loss (standarized): 0.7518049270965511\n",
      "Epoch: 16, Loss (standarized): 0.6920536580615084\n",
      "Epoch: 21, Loss (standarized): 0.6536189861921823\n",
      "Epoch: 26, Loss (standarized): 0.6531062125497576\n",
      "Epoch: 31, Loss (standarized): 0.6501828469792126\n",
      "Epoch: 36, Loss (standarized): 0.6484855022647933\n",
      "Epoch: 41, Loss (standarized): 0.6425397411460771\n",
      "Epoch: 46, Loss (standarized): 0.6376826374204104\n",
      "Epoch: 51, Loss (standarized): 0.6333077001157886\n",
      "Epoch: 56, Loss (standarized): 0.6275126362560626\n",
      "Epoch: 61, Loss (standarized): 0.6181399737877077\n",
      "Epoch: 66, Loss (standarized): 0.6038707226343114\n",
      "Epoch: 71, Loss (standarized): 0.5825227002219243\n",
      "Epoch: 76, Loss (standarized): 0.5530515916345281\n",
      "Epoch: 81, Loss (standarized): 0.517045347023115\n",
      "Epoch: 86, Loss (standarized): 0.47925541547455797\n",
      "Epoch: 91, Loss (standarized): 0.4442393053541211\n",
      "Epoch: 96, Loss (standarized): 0.41150763971541326\n",
      "Final epoch: 100, Final loss (standarized): 0.3845545811157827\n",
      "Epoch: 1, Loss (standarized): 1.0922400676165078\n",
      "Epoch: 6, Loss (standarized): 0.7760065245257809\n",
      "Epoch: 11, Loss (standarized): 0.7082033616094494\n",
      "Epoch: 16, Loss (standarized): 0.6612146165068483\n",
      "Epoch: 21, Loss (standarized): 0.6635844895370703\n",
      "Epoch: 26, Loss (standarized): 0.6603988854652059\n",
      "Epoch: 31, Loss (standarized): 0.653219752606633\n",
      "Epoch: 36, Loss (standarized): 0.6505290342338502\n",
      "Epoch: 41, Loss (standarized): 0.6450493098166152\n",
      "Epoch: 46, Loss (standarized): 0.6437157132098668\n",
      "Epoch: 51, Loss (standarized): 0.6416266423476225\n",
      "Epoch: 56, Loss (standarized): 0.6386292546615108\n",
      "Epoch: 61, Loss (standarized): 0.6345162738823987\n",
      "Epoch: 66, Loss (standarized): 0.6287516649104081\n",
      "Epoch: 71, Loss (standarized): 0.6191929563531299\n",
      "Epoch: 76, Loss (standarized): 0.6037717912782309\n",
      "Epoch: 81, Loss (standarized): 0.5807575119826088\n",
      "Epoch: 86, Loss (standarized): 0.5502636296116581\n",
      "Epoch: 91, Loss (standarized): 0.516171330179522\n",
      "Epoch: 96, Loss (standarized): 0.48428916494687485\n",
      "Final epoch: 100, Final loss (standarized): 0.46209130512713353\n",
      "Epoch: 1, Loss (standarized): 1.3600968409997116\n",
      "Epoch: 6, Loss (standarized): 0.8209216076515441\n",
      "Epoch: 11, Loss (standarized): 0.7186861432367189\n",
      "Epoch: 16, Loss (standarized): 0.6761765702718064\n",
      "Epoch: 21, Loss (standarized): 0.661204392772698\n",
      "Epoch: 26, Loss (standarized): 0.6614511050826689\n",
      "Epoch: 31, Loss (standarized): 0.6655394508627479\n",
      "Epoch: 36, Loss (standarized): 0.6675482631736246\n",
      "Epoch: 41, Loss (standarized): 0.666786172094955\n",
      "Epoch: 46, Loss (standarized): 0.6663067271252741\n",
      "Epoch: 51, Loss (standarized): 0.6652265869454849\n",
      "Epoch: 56, Loss (standarized): 0.6642857271936423\n",
      "Epoch: 61, Loss (standarized): 0.663743811148885\n",
      "Epoch: 66, Loss (standarized): 0.6642172743275322\n",
      "Epoch: 71, Loss (standarized): 0.6649235596778639\n",
      "Epoch: 76, Loss (standarized): 0.6641293393931937\n",
      "Epoch: 81, Loss (standarized): 0.6637822515148082\n",
      "Epoch: 86, Loss (standarized): 0.6635583048063283\n",
      "Epoch: 91, Loss (standarized): 0.6630099280421005\n",
      "Epoch: 96, Loss (standarized): 0.662232432558881\n",
      "Final epoch: 100, Final loss (standarized): 0.6619467586700182\n",
      "Epoch: 1, Loss (standarized): 1.098647714753655\n",
      "Epoch: 6, Loss (standarized): 0.815426570792915\n",
      "Epoch: 11, Loss (standarized): 0.7265391320464044\n",
      "Epoch: 16, Loss (standarized): 0.6914494520603361\n",
      "Epoch: 21, Loss (standarized): 0.6820351311083138\n",
      "Epoch: 26, Loss (standarized): 0.6783305274212492\n",
      "Epoch: 31, Loss (standarized): 0.676074640353617\n",
      "Epoch: 36, Loss (standarized): 0.6754202365919124\n",
      "Epoch: 41, Loss (standarized): 0.6749415930617976\n",
      "Epoch: 46, Loss (standarized): 0.6753441585260913\n",
      "Epoch: 51, Loss (standarized): 0.6772078146701661\n",
      "Epoch: 56, Loss (standarized): 0.6774474446545719\n",
      "Epoch: 61, Loss (standarized): 0.6767868408706762\n",
      "Epoch: 66, Loss (standarized): 0.6756816046910866\n",
      "Epoch: 71, Loss (standarized): 0.6742863291227553\n",
      "Epoch: 76, Loss (standarized): 0.6736897668292657\n",
      "Epoch: 81, Loss (standarized): 0.6718285599501366\n",
      "Epoch: 86, Loss (standarized): 0.6699724781008611\n",
      "Epoch: 91, Loss (standarized): 0.6682483599607787\n",
      "Epoch: 96, Loss (standarized): 0.6670885710592898\n",
      "Final epoch: 100, Final loss (standarized): 0.6669792539064463\n",
      "Epoch: 1, Loss (standarized): 1.2300079897115144\n",
      "Epoch: 6, Loss (standarized): 0.8080234162561146\n",
      "Epoch: 11, Loss (standarized): 0.7322420707069794\n",
      "Epoch: 16, Loss (standarized): 0.6840325249428982\n",
      "Epoch: 21, Loss (standarized): 0.6710128121087557\n",
      "Epoch: 26, Loss (standarized): 0.6693226880603782\n",
      "Epoch: 31, Loss (standarized): 0.6684063291492051\n",
      "Epoch: 36, Loss (standarized): 0.6671200310331244\n",
      "Epoch: 41, Loss (standarized): 0.66708284403377\n",
      "Epoch: 46, Loss (standarized): 0.6684707224497959\n",
      "Epoch: 51, Loss (standarized): 0.669330121656477\n",
      "Epoch: 56, Loss (standarized): 0.6694159224559307\n",
      "Epoch: 61, Loss (standarized): 0.6685661432127306\n",
      "Epoch: 66, Loss (standarized): 0.6673398953365678\n",
      "Epoch: 71, Loss (standarized): 0.6659966500436415\n",
      "Epoch: 76, Loss (standarized): 0.6648318266825184\n",
      "Epoch: 81, Loss (standarized): 0.6642499059418819\n",
      "Epoch: 86, Loss (standarized): 0.6629328480576319\n",
      "Epoch: 91, Loss (standarized): 0.6619039547958369\n",
      "Epoch: 96, Loss (standarized): 0.6613772476134766\n",
      "Final epoch: 100, Final loss (standarized): 0.6609338553652601\n",
      "Epoch: 1, Loss (standarized): 1.3713626263097605\n",
      "Epoch: 6, Loss (standarized): 0.8512645043524424\n",
      "Epoch: 11, Loss (standarized): 0.7103621311238418\n",
      "Epoch: 16, Loss (standarized): 0.6726528088645917\n",
      "Epoch: 21, Loss (standarized): 0.6575834202720677\n",
      "Epoch: 26, Loss (standarized): 0.6575308759795485\n",
      "Epoch: 31, Loss (standarized): 0.6623345175052409\n",
      "Epoch: 36, Loss (standarized): 0.6654951418483434\n",
      "Epoch: 41, Loss (standarized): 0.6668164305098019\n",
      "Epoch: 46, Loss (standarized): 0.6663662839545453\n",
      "Epoch: 51, Loss (standarized): 0.6647434143296204\n",
      "Epoch: 56, Loss (standarized): 0.6628071507786222\n",
      "Epoch: 61, Loss (standarized): 0.6617332533300035\n",
      "Epoch: 66, Loss (standarized): 0.6605634694488848\n",
      "Epoch: 71, Loss (standarized): 0.6590445580857677\n",
      "Epoch: 76, Loss (standarized): 0.657595569538917\n",
      "Epoch: 81, Loss (standarized): 0.6567779962421665\n",
      "Epoch: 86, Loss (standarized): 0.6565502230069961\n",
      "Epoch: 91, Loss (standarized): 0.6563685682593171\n",
      "Epoch: 96, Loss (standarized): 0.6563620557010599\n",
      "Final epoch: 100, Final loss (standarized): 0.6562328720234536\n",
      "Epoch: 1, Loss (standarized): 1.1328547642753886\n",
      "Epoch: 6, Loss (standarized): 0.7844611098494098\n",
      "Epoch: 11, Loss (standarized): 0.7095130181183087\n",
      "Epoch: 16, Loss (standarized): 0.6517874265488953\n",
      "Epoch: 21, Loss (standarized): 0.6515640908208977\n",
      "Epoch: 26, Loss (standarized): 0.6438761111125894\n",
      "Epoch: 31, Loss (standarized): 0.6342650306631181\n",
      "Epoch: 36, Loss (standarized): 0.6244809523033926\n",
      "Epoch: 41, Loss (standarized): 0.6102958945530881\n",
      "Epoch: 46, Loss (standarized): 0.5949012168812651\n",
      "Epoch: 51, Loss (standarized): 0.5736954650676018\n",
      "Epoch: 56, Loss (standarized): 0.5482356117455734\n",
      "Epoch: 61, Loss (standarized): 0.5180873767713683\n",
      "Epoch: 66, Loss (standarized): 0.4836517703010266\n",
      "Epoch: 71, Loss (standarized): 0.4474252323915256\n",
      "Epoch: 76, Loss (standarized): 0.41126953029999685\n",
      "Epoch: 81, Loss (standarized): 0.37758483482843325\n",
      "Epoch: 86, Loss (standarized): 0.3471597789748202\n",
      "Epoch: 91, Loss (standarized): 0.319042810123023\n",
      "Epoch: 96, Loss (standarized): 0.29219289926580405\n",
      "Final epoch: 100, Final loss (standarized): 0.2721815043838177\n",
      "Epoch: 1, Loss (standarized): 1.095767187700284\n",
      "Epoch: 6, Loss (standarized): 0.8012933961906763\n",
      "Epoch: 11, Loss (standarized): 0.7295330269904879\n",
      "Epoch: 16, Loss (standarized): 0.6607987308923683\n",
      "Epoch: 21, Loss (standarized): 0.6524312588662483\n",
      "Epoch: 26, Loss (standarized): 0.652182137379452\n",
      "Epoch: 31, Loss (standarized): 0.6443797866081521\n",
      "Epoch: 36, Loss (standarized): 0.6435514641156399\n",
      "Epoch: 41, Loss (standarized): 0.644765361660761\n",
      "Epoch: 46, Loss (standarized): 0.6463771771738809\n",
      "Epoch: 51, Loss (standarized): 0.6460171901919967\n",
      "Epoch: 56, Loss (standarized): 0.644362256332019\n",
      "Epoch: 61, Loss (standarized): 0.6437525300111326\n",
      "Epoch: 66, Loss (standarized): 0.6439680268120954\n",
      "Epoch: 71, Loss (standarized): 0.6444548708496572\n",
      "Epoch: 76, Loss (standarized): 0.6442370562649866\n",
      "Epoch: 81, Loss (standarized): 0.6439769517822683\n",
      "Epoch: 86, Loss (standarized): 0.6440243515214238\n",
      "Epoch: 91, Loss (standarized): 0.6442870002270384\n",
      "Epoch: 96, Loss (standarized): 0.6444248446120129\n",
      "Final epoch: 100, Final loss (standarized): 0.6445086338402113\n",
      "Epoch: 1, Loss (standarized): 1.183781730718129\n",
      "Epoch: 6, Loss (standarized): 0.7830885973082621\n",
      "Epoch: 11, Loss (standarized): 0.7232220422072646\n",
      "Epoch: 16, Loss (standarized): 0.662039177373015\n",
      "Epoch: 21, Loss (standarized): 0.6530878763654375\n",
      "Epoch: 26, Loss (standarized): 0.6551957198780912\n",
      "Epoch: 31, Loss (standarized): 0.6431464998772329\n",
      "Epoch: 36, Loss (standarized): 0.6363660453673122\n",
      "Epoch: 41, Loss (standarized): 0.6303288609736886\n",
      "Epoch: 46, Loss (standarized): 0.6228355613835658\n",
      "Epoch: 51, Loss (standarized): 0.6153582568392161\n",
      "Epoch: 56, Loss (standarized): 0.604297822405545\n",
      "Epoch: 61, Loss (standarized): 0.5911619029786995\n",
      "Epoch: 66, Loss (standarized): 0.5762803662634772\n",
      "Epoch: 71, Loss (standarized): 0.5591774195155892\n",
      "Epoch: 76, Loss (standarized): 0.5388384572163032\n",
      "Epoch: 81, Loss (standarized): 0.5153340612000512\n",
      "Epoch: 86, Loss (standarized): 0.4892803761201393\n",
      "Epoch: 91, Loss (standarized): 0.4607845109086309\n",
      "Epoch: 96, Loss (standarized): 0.4294171538726253\n",
      "Final epoch: 100, Final loss (standarized): 0.40267043451269136\n",
      "Epoch: 1, Loss (standarized): 1.1251801978516398\n",
      "Epoch: 6, Loss (standarized): 0.7838185035675735\n",
      "Epoch: 11, Loss (standarized): 0.7125070234420481\n",
      "Epoch: 16, Loss (standarized): 0.6618046840320646\n",
      "Epoch: 21, Loss (standarized): 0.651092290193451\n",
      "Epoch: 26, Loss (standarized): 0.6544690026212571\n",
      "Epoch: 31, Loss (standarized): 0.6468223342964369\n",
      "Epoch: 36, Loss (standarized): 0.643951022459654\n",
      "Epoch: 41, Loss (standarized): 0.6418865253796336\n",
      "Epoch: 46, Loss (standarized): 0.6417992395346724\n",
      "Epoch: 51, Loss (standarized): 0.640215525473966\n",
      "Epoch: 56, Loss (standarized): 0.638407566116292\n",
      "Epoch: 61, Loss (standarized): 0.6365340429208354\n",
      "Epoch: 66, Loss (standarized): 0.6340617857929095\n",
      "Epoch: 71, Loss (standarized): 0.6302005258068328\n",
      "Epoch: 76, Loss (standarized): 0.6250133553695049\n",
      "Epoch: 81, Loss (standarized): 0.6176149118305465\n",
      "Epoch: 86, Loss (standarized): 0.6069441817852232\n",
      "Epoch: 91, Loss (standarized): 0.5921313730644056\n",
      "Epoch: 96, Loss (standarized): 0.5723881781481023\n",
      "Final epoch: 100, Final loss (standarized): 0.5528627760062846\n",
      "Epoch: 1, Loss (standarized): 0.9929550402848618\n",
      "Epoch: 6, Loss (standarized): 0.8009118602120558\n",
      "Epoch: 11, Loss (standarized): 0.7003994730576971\n",
      "Epoch: 16, Loss (standarized): 0.6514254248832877\n",
      "Epoch: 21, Loss (standarized): 0.6606793847235922\n",
      "Epoch: 26, Loss (standarized): 0.652300522713266\n",
      "Epoch: 31, Loss (standarized): 0.6420922522241198\n",
      "Epoch: 36, Loss (standarized): 0.630111317602165\n",
      "Epoch: 41, Loss (standarized): 0.61857006625355\n",
      "Epoch: 46, Loss (standarized): 0.6003797452455102\n",
      "Epoch: 51, Loss (standarized): 0.5752691609926449\n",
      "Epoch: 56, Loss (standarized): 0.5450099590042846\n",
      "Epoch: 61, Loss (standarized): 0.5126101149350761\n",
      "Epoch: 66, Loss (standarized): 0.47953208948196935\n",
      "Epoch: 71, Loss (standarized): 0.4436051388595412\n",
      "Epoch: 76, Loss (standarized): 0.4007820514619531\n",
      "Epoch: 81, Loss (standarized): 0.35216479288187624\n",
      "Epoch: 86, Loss (standarized): 0.3058957288012983\n",
      "Epoch: 91, Loss (standarized): 0.267513573272978\n",
      "Epoch: 96, Loss (standarized): 0.23767342796854332\n",
      "Final epoch: 100, Final loss (standarized): 0.21921199026826393\n",
      "Epoch: 1, Loss (standarized): 1.0274368145631836\n",
      "Epoch: 6, Loss (standarized): 0.7914139916687853\n",
      "Epoch: 11, Loss (standarized): 0.7011450145150283\n",
      "Epoch: 16, Loss (standarized): 0.654548979903373\n",
      "Epoch: 21, Loss (standarized): 0.6593455143309824\n",
      "Epoch: 26, Loss (standarized): 0.6541570616144664\n",
      "Epoch: 31, Loss (standarized): 0.6469529137421554\n",
      "Epoch: 36, Loss (standarized): 0.6481435694400289\n",
      "Epoch: 41, Loss (standarized): 0.6491334121171082\n",
      "Epoch: 46, Loss (standarized): 0.6474962069768536\n",
      "Epoch: 51, Loss (standarized): 0.6457089093436683\n",
      "Epoch: 56, Loss (standarized): 0.6444240746203761\n",
      "Epoch: 61, Loss (standarized): 0.6442033422103228\n",
      "Epoch: 66, Loss (standarized): 0.644819444783807\n",
      "Epoch: 71, Loss (standarized): 0.6450739389759387\n",
      "Epoch: 76, Loss (standarized): 0.6444766384454964\n",
      "Epoch: 81, Loss (standarized): 0.6438700804957979\n",
      "Epoch: 86, Loss (standarized): 0.6437929428758028\n",
      "Epoch: 91, Loss (standarized): 0.6438741401052633\n",
      "Epoch: 96, Loss (standarized): 0.6437748013463658\n",
      "Final epoch: 100, Final loss (standarized): 0.6435995095899684\n",
      "Epoch: 1, Loss (standarized): 1.1818447616473404\n",
      "Epoch: 6, Loss (standarized): 0.7996061390967952\n",
      "Epoch: 11, Loss (standarized): 0.7279635457969856\n",
      "Epoch: 16, Loss (standarized): 0.6659984247293994\n",
      "Epoch: 21, Loss (standarized): 0.6595830000755527\n",
      "Epoch: 26, Loss (standarized): 0.660214702134098\n",
      "Epoch: 31, Loss (standarized): 0.6489104562200688\n",
      "Epoch: 36, Loss (standarized): 0.6387925710429475\n",
      "Epoch: 41, Loss (standarized): 0.6283053906385014\n",
      "Epoch: 46, Loss (standarized): 0.6120476840175907\n",
      "Epoch: 51, Loss (standarized): 0.590483448565045\n",
      "Epoch: 56, Loss (standarized): 0.557783760188484\n",
      "Epoch: 61, Loss (standarized): 0.5173266310769303\n",
      "Epoch: 66, Loss (standarized): 0.474273595990102\n",
      "Epoch: 71, Loss (standarized): 0.4328040210668745\n",
      "Epoch: 76, Loss (standarized): 0.39436611646426584\n",
      "Epoch: 81, Loss (standarized): 0.35683723459188205\n",
      "Epoch: 86, Loss (standarized): 0.3196668657122162\n",
      "Epoch: 91, Loss (standarized): 0.2843692690822953\n",
      "Epoch: 96, Loss (standarized): 0.2553283466227095\n",
      "Final epoch: 100, Final loss (standarized): 0.23762250179743113\n",
      "Epoch: 1, Loss (standarized): 1.2183221413305334\n",
      "Epoch: 6, Loss (standarized): 0.7794132711479586\n",
      "Epoch: 11, Loss (standarized): 0.7112487909221128\n",
      "Epoch: 16, Loss (standarized): 0.6624529804897623\n",
      "Epoch: 21, Loss (standarized): 0.664162262247663\n",
      "Epoch: 26, Loss (standarized): 0.6630770050275483\n",
      "Epoch: 31, Loss (standarized): 0.6515693976919374\n",
      "Epoch: 36, Loss (standarized): 0.6453720788058216\n",
      "Epoch: 41, Loss (standarized): 0.6419164074540507\n",
      "Epoch: 46, Loss (standarized): 0.6361777944271203\n",
      "Epoch: 51, Loss (standarized): 0.6302047879784637\n",
      "Epoch: 56, Loss (standarized): 0.621029010020962\n",
      "Epoch: 61, Loss (standarized): 0.6093744250933462\n",
      "Epoch: 66, Loss (standarized): 0.593928218693886\n",
      "Epoch: 71, Loss (standarized): 0.5742127921089487\n",
      "Epoch: 76, Loss (standarized): 0.5509485985020223\n",
      "Epoch: 81, Loss (standarized): 0.5269274610071429\n",
      "Epoch: 86, Loss (standarized): 0.5057576291016669\n",
      "Epoch: 91, Loss (standarized): 0.4900843450039681\n",
      "Epoch: 96, Loss (standarized): 0.48010278673046947\n",
      "Final epoch: 100, Final loss (standarized): 0.47492083289541526\n",
      "Epoch: 1, Loss (standarized): 1.2358294759402304\n",
      "          Validation Loss (standardized): 1.148632935405175\n",
      "Epoch: 6, Loss (standarized): 0.8498928056780924\n",
      "          Validation Loss (standardized): 1.0670440283328604\n",
      "Epoch: 11, Loss (standarized): 0.7230974966795044\n",
      "          Validation Loss (standardized): 1.3032665065950269\n",
      "Epoch: 16, Loss (standarized): 0.675566263140156\n",
      "          Validation Loss (standardized): 1.6488876983783547\n",
      "Epoch: 21, Loss (standarized): 0.6616697308797296\n",
      "          Validation Loss (standardized): 1.9344037509470056\n",
      "Epoch: 26, Loss (standarized): 0.6584351651929952\n",
      "          Validation Loss (standardized): 2.009583486907083\n",
      "Epoch: 31, Loss (standarized): 0.65273335251021\n",
      "          Validation Loss (standardized): 1.9114320608659052\n",
      "Epoch: 36, Loss (standarized): 0.6378050924126557\n",
      "          Validation Loss (standardized): 1.7510961104882785\n",
      "Epoch: 41, Loss (standarized): 0.6279510943763601\n",
      "          Validation Loss (standardized): 1.6308065391223332\n",
      "Epoch: 46, Loss (standarized): 0.6129516627044147\n",
      "          Validation Loss (standardized): 1.5739479263409935\n",
      "Epoch: 51, Loss (standarized): 0.5916619942931238\n",
      "          Validation Loss (standardized): 1.5636720233346155\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5631192035937359\n",
      "          Validation Loss (standardized): 1.5624028264730379\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5294497809687905\n",
      "          Validation Loss (standardized): 1.5456873585744275\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.49136760557331044\n",
      "          Validation Loss (standardized): 1.5001914525368816\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.44902704863633597\n",
      "          Validation Loss (standardized): 1.4453043755048036\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.4031373150307221\n",
      "          Validation Loss (standardized): 1.399777642698885\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.3594267823024589\n",
      "          Validation Loss (standardized): 1.3667225379994334\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.319809701909342\n",
      "          Validation Loss (standardized): 1.3469346801388946\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.28508883309874417\n",
      "          Validation Loss (standardized): 1.3205582783013357\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.2561577231283725\n",
      "          Validation Loss (standardized): 1.282785285261322\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.23680856744437526\n",
      "Epoch: 1, Loss (standarized): 1.1548823088190474\n",
      "          Validation Loss (standardized): 1.054316445856068\n",
      "Epoch: 6, Loss (standarized): 0.7832218266743979\n",
      "          Validation Loss (standardized): 1.15104128191058\n",
      "Epoch: 11, Loss (standarized): 0.7165287974030291\n",
      "          Validation Loss (standardized): 1.3565106804270486\n",
      "Epoch: 16, Loss (standarized): 0.6587559587409534\n",
      "          Validation Loss (standardized): 1.5456679020807178\n",
      "Epoch: 21, Loss (standarized): 0.6550918515866182\n",
      "          Validation Loss (standardized): 1.7210550746947113\n",
      "Epoch: 26, Loss (standarized): 0.6547193029479947\n",
      "          Validation Loss (standardized): 1.7753977541751713\n",
      "Epoch: 31, Loss (standarized): 0.6478670666070903\n",
      "          Validation Loss (standardized): 1.739341573332533\n",
      "Epoch: 36, Loss (standarized): 0.6456231994463995\n",
      "          Validation Loss (standardized): 1.6678121715451852\n",
      "Epoch: 41, Loss (standarized): 0.6451611122150028\n",
      "          Validation Loss (standardized): 1.5882739234071166\n",
      "Epoch: 46, Loss (standarized): 0.6462041730983551\n",
      "          Validation Loss (standardized): 1.556926546960523\n",
      "Epoch: 51, Loss (standarized): 0.6455332058076654\n",
      "          Validation Loss (standardized): 1.5806753052664524\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6432019607684193\n",
      "          Validation Loss (standardized): 1.6185584553320265\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6418577770735366\n",
      "          Validation Loss (standardized): 1.6416241273156607\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6411057405057093\n",
      "          Validation Loss (standardized): 1.64063571707429\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.640368607142604\n",
      "          Validation Loss (standardized): 1.6230308718760411\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6388932775242477\n",
      "          Validation Loss (standardized): 1.6117326722404717\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6367497848421143\n",
      "          Validation Loss (standardized): 1.6079165431537434\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6334608853018665\n",
      "          Validation Loss (standardized): 1.6097039250617533\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6280145757811967\n",
      "          Validation Loss (standardized): 1.6123245765228043\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.619107511433955\n",
      "          Validation Loss (standardized): 1.607005036183678\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6084479326982416\n",
      "Epoch: 1, Loss (standarized): 1.2045713996156378\n",
      "          Validation Loss (standardized): 1.1202566776813214\n",
      "Epoch: 6, Loss (standarized): 0.8108068217231547\n",
      "          Validation Loss (standardized): 1.167335878463659\n",
      "Epoch: 11, Loss (standarized): 0.7460235509185505\n",
      "          Validation Loss (standardized): 1.3251806183410864\n",
      "Epoch: 16, Loss (standarized): 0.6724816006334586\n",
      "          Validation Loss (standardized): 1.4748959729380409\n",
      "Epoch: 21, Loss (standarized): 0.641873228729992\n",
      "          Validation Loss (standardized): 1.6507610073338939\n",
      "Epoch: 26, Loss (standarized): 0.6447295796981631\n",
      "          Validation Loss (standardized): 1.8119261126363553\n",
      "Epoch: 31, Loss (standarized): 0.6315456003254604\n",
      "          Validation Loss (standardized): 1.865104230828852\n",
      "Epoch: 36, Loss (standarized): 0.6166478828488462\n",
      "          Validation Loss (standardized): 1.7557505905916682\n",
      "Epoch: 41, Loss (standarized): 0.6003233295230446\n",
      "          Validation Loss (standardized): 1.6348793231437033\n",
      "Epoch: 46, Loss (standarized): 0.5809290594235469\n",
      "          Validation Loss (standardized): 1.5300931562991438\n",
      "Epoch: 51, Loss (standarized): 0.5608773666065596\n",
      "          Validation Loss (standardized): 1.4801044442249425\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5376431948170999\n",
      "          Validation Loss (standardized): 1.4801094868480122\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5140151504198073\n",
      "          Validation Loss (standardized): 1.4670126279789288\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.49036181547999785\n",
      "          Validation Loss (standardized): 1.4397019670143063\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.4654738720590377\n",
      "          Validation Loss (standardized): 1.429868007675948\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.43766973248397495\n",
      "          Validation Loss (standardized): 1.3976484633730775\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.40540764197590207\n",
      "          Validation Loss (standardized): 1.3727202454431526\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.3696167652129454\n",
      "          Validation Loss (standardized): 1.3353603777493763\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.33494487111192695\n",
      "          Validation Loss (standardized): 1.3001572831373578\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.30421913353093955\n",
      "          Validation Loss (standardized): 1.2592617342753452\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.2824661496613941\n",
      "Epoch: 1, Loss (standarized): 1.1270855040218117\n",
      "          Validation Loss (standardized): 1.1233745977531457\n",
      "Epoch: 6, Loss (standarized): 0.7787379108682246\n",
      "          Validation Loss (standardized): 1.190976021032797\n",
      "Epoch: 11, Loss (standarized): 0.7167398094312855\n",
      "          Validation Loss (standardized): 1.3899449521775638\n",
      "Epoch: 16, Loss (standarized): 0.6647533564672727\n",
      "          Validation Loss (standardized): 1.5799945956147394\n",
      "Epoch: 21, Loss (standarized): 0.6453203774926023\n",
      "          Validation Loss (standardized): 1.7601984157863086\n",
      "Epoch: 26, Loss (standarized): 0.6443909379728849\n",
      "          Validation Loss (standardized): 1.8938452244612793\n",
      "Epoch: 31, Loss (standarized): 0.6324263080774494\n",
      "          Validation Loss (standardized): 1.8822382425755217\n",
      "Epoch: 36, Loss (standarized): 0.6191534867018025\n",
      "          Validation Loss (standardized): 1.7340337857141945\n",
      "Epoch: 41, Loss (standarized): 0.6040726242534493\n",
      "          Validation Loss (standardized): 1.5848149313201174\n",
      "Epoch: 46, Loss (standarized): 0.5914606681211285\n",
      "          Validation Loss (standardized): 1.5001994792723672\n",
      "Epoch: 51, Loss (standarized): 0.5748791441558747\n",
      "          Validation Loss (standardized): 1.5051618284393444\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5531293567390616\n",
      "          Validation Loss (standardized): 1.4929384164505393\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.523860099754258\n",
      "          Validation Loss (standardized): 1.4782752730923998\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.4830351503336061\n",
      "          Validation Loss (standardized): 1.4573460500375095\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.42976328639164935\n",
      "          Validation Loss (standardized): 1.3731045841913345\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.3710745338899507\n",
      "          Validation Loss (standardized): 1.3033873518004626\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.32023747046356515\n",
      "          Validation Loss (standardized): 1.2477675055591426\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.2818042774673045\n",
      "          Validation Loss (standardized): 1.2409250563918295\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.25143144041180265\n",
      "          Validation Loss (standardized): 1.2325085966149445\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.22581687253990734\n",
      "          Validation Loss (standardized): 1.2016423757943988\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.20900539919651903\n",
      "Epoch: 1, Loss (standarized): 1.098917803751793\n",
      "          Validation Loss (standardized): 1.0837435018245647\n",
      "Epoch: 6, Loss (standarized): 0.8161049577983708\n",
      "          Validation Loss (standardized): 1.1385229568360702\n",
      "Epoch: 11, Loss (standarized): 0.7304214437145337\n",
      "          Validation Loss (standardized): 1.249901586999828\n",
      "Epoch: 16, Loss (standarized): 0.6882934632125032\n",
      "          Validation Loss (standardized): 1.324405938514779\n",
      "Epoch: 21, Loss (standarized): 0.675046991657227\n",
      "          Validation Loss (standardized): 1.4106490980933373\n",
      "Epoch: 26, Loss (standarized): 0.672535912339309\n",
      "          Validation Loss (standardized): 1.4908882971914181\n",
      "Epoch: 31, Loss (standarized): 0.6692989592758778\n",
      "          Validation Loss (standardized): 1.529503359629767\n",
      "Epoch: 36, Loss (standarized): 0.6666918997560757\n",
      "          Validation Loss (standardized): 1.5186967108180005\n",
      "Epoch: 41, Loss (standarized): 0.666943487919142\n",
      "          Validation Loss (standardized): 1.4980251408931695\n",
      "Epoch: 46, Loss (standarized): 0.6673135014770817\n",
      "          Validation Loss (standardized): 1.4894482320369982\n",
      "Epoch: 51, Loss (standarized): 0.6672003607496915\n",
      "          Validation Loss (standardized): 1.4842255612782134\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6660373614520452\n",
      "          Validation Loss (standardized): 1.4900425419465597\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6660925146654791\n",
      "          Validation Loss (standardized): 1.4840335325197653\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6651471377825053\n",
      "          Validation Loss (standardized): 1.4857564174219937\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6638261558568391\n",
      "          Validation Loss (standardized): 1.4850147658718849\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6622920858041436\n",
      "          Validation Loss (standardized): 1.4975498379719434\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6603063902264221\n",
      "          Validation Loss (standardized): 1.5007887273146558\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6589176659358326\n",
      "          Validation Loss (standardized): 1.5030795253267983\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6579377835903976\n",
      "          Validation Loss (standardized): 1.504967035590077\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6569585951866351\n",
      "          Validation Loss (standardized): 1.505589581702354\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.656208423277793\n",
      "Epoch: 1, Loss (standarized): 0.9765705025828194\n",
      "          Validation Loss (standardized): 1.0233699559362983\n",
      "Epoch: 6, Loss (standarized): 0.7964881206761953\n",
      "          Validation Loss (standardized): 1.0893382484622893\n",
      "Epoch: 11, Loss (standarized): 0.7304112929899345\n",
      "          Validation Loss (standardized): 1.1737933865300076\n",
      "Epoch: 16, Loss (standarized): 0.6924989776463658\n",
      "          Validation Loss (standardized): 1.2880727082139873\n",
      "Epoch: 21, Loss (standarized): 0.6755648259875274\n",
      "          Validation Loss (standardized): 1.386961990897297\n",
      "Epoch: 26, Loss (standarized): 0.6685653708202568\n",
      "          Validation Loss (standardized): 1.4412502824922317\n",
      "Epoch: 31, Loss (standarized): 0.6691822764051064\n",
      "          Validation Loss (standardized): 1.45466054267122\n",
      "Epoch: 36, Loss (standarized): 0.6718609339865661\n",
      "          Validation Loss (standardized): 1.4482711202875862\n",
      "Epoch: 41, Loss (standarized): 0.6730989439896289\n",
      "          Validation Loss (standardized): 1.4404409072328652\n",
      "Epoch: 46, Loss (standarized): 0.6705053094156792\n",
      "          Validation Loss (standardized): 1.450438578644286\n",
      "Epoch: 51, Loss (standarized): 0.6681210399508194\n",
      "          Validation Loss (standardized): 1.4576551686329997\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6679158577519375\n",
      "          Validation Loss (standardized): 1.4566758489175333\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6686617612830391\n",
      "          Validation Loss (standardized): 1.4588710788123374\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6684291292009182\n",
      "          Validation Loss (standardized): 1.469414662515624\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.667732095355848\n",
      "          Validation Loss (standardized): 1.4726532198126592\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.667168704834844\n",
      "          Validation Loss (standardized): 1.4773785157043016\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6665628288178669\n",
      "          Validation Loss (standardized): 1.4802823672349619\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6660798234773855\n",
      "          Validation Loss (standardized): 1.4834783036719459\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.665144853321362\n",
      "          Validation Loss (standardized): 1.4877348770126027\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6643992443990265\n",
      "          Validation Loss (standardized): 1.4878706522727292\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6639012808332797\n",
      "Epoch: 1, Loss (standarized): 1.129567861559482\n",
      "          Validation Loss (standardized): 1.0980761100192742\n",
      "Epoch: 6, Loss (standarized): 0.7596154098960423\n",
      "          Validation Loss (standardized): 1.1502312039372589\n",
      "Epoch: 11, Loss (standarized): 0.6925606953968808\n",
      "          Validation Loss (standardized): 1.337368407479779\n",
      "Epoch: 16, Loss (standarized): 0.6664944385116539\n",
      "          Validation Loss (standardized): 1.4314060041631205\n",
      "Epoch: 21, Loss (standarized): 0.6677750252014866\n",
      "          Validation Loss (standardized): 1.4597681393973243\n",
      "Epoch: 26, Loss (standarized): 0.6729269359505092\n",
      "          Validation Loss (standardized): 1.4707207362035652\n",
      "Epoch: 31, Loss (standarized): 0.6709993853062328\n",
      "          Validation Loss (standardized): 1.467166110997674\n",
      "Epoch: 36, Loss (standarized): 0.6674378911031211\n",
      "          Validation Loss (standardized): 1.4573523527719472\n",
      "Epoch: 41, Loss (standarized): 0.6657118690068642\n",
      "          Validation Loss (standardized): 1.447627545987136\n",
      "Epoch: 46, Loss (standarized): 0.6655857460302794\n",
      "          Validation Loss (standardized): 1.439664167575796\n",
      "Epoch: 51, Loss (standarized): 0.6668056309295606\n",
      "          Validation Loss (standardized): 1.4379991386705397\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6669392248385805\n",
      "          Validation Loss (standardized): 1.4470343757371338\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6656587145196706\n",
      "          Validation Loss (standardized): 1.4619726223126142\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6636754005098033\n",
      "          Validation Loss (standardized): 1.476648152411161\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6616606617982569\n",
      "          Validation Loss (standardized): 1.493480621652773\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6614420601057175\n",
      "          Validation Loss (standardized): 1.494022728039442\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6613137250938377\n",
      "          Validation Loss (standardized): 1.496988222746555\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6604035832631788\n",
      "          Validation Loss (standardized): 1.5034855353670682\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.659428935718362\n",
      "          Validation Loss (standardized): 1.5110917509761888\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6585723562664619\n",
      "          Validation Loss (standardized): 1.5142992068363843\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6581023334687811\n",
      "Epoch: 1, Loss (standarized): 0.9099095929302917\n",
      "          Validation Loss (standardized): 1.0404638675669997\n",
      "Epoch: 6, Loss (standarized): 0.8014537392216049\n",
      "          Validation Loss (standardized): 1.1064166386011438\n",
      "Epoch: 11, Loss (standarized): 0.7296002014951207\n",
      "          Validation Loss (standardized): 1.2134459534260496\n",
      "Epoch: 16, Loss (standarized): 0.6823266305063859\n",
      "          Validation Loss (standardized): 1.3591905341896613\n",
      "Epoch: 21, Loss (standarized): 0.6636303241729569\n",
      "          Validation Loss (standardized): 1.500285006042299\n",
      "Epoch: 26, Loss (standarized): 0.6594969302224039\n",
      "          Validation Loss (standardized): 1.5708733035344764\n",
      "Epoch: 31, Loss (standarized): 0.659014472404629\n",
      "          Validation Loss (standardized): 1.5565295010994968\n",
      "Epoch: 36, Loss (standarized): 0.6604871182985654\n",
      "          Validation Loss (standardized): 1.5195382421419972\n",
      "Epoch: 41, Loss (standarized): 0.6608042271668816\n",
      "          Validation Loss (standardized): 1.5029083618722112\n",
      "Epoch: 46, Loss (standarized): 0.6615810006222251\n",
      "          Validation Loss (standardized): 1.4925065820474406\n",
      "Epoch: 51, Loss (standarized): 0.661822269218402\n",
      "          Validation Loss (standardized): 1.4806009549043333\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6618466031302495\n",
      "          Validation Loss (standardized): 1.4781876098062052\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6619745155343603\n",
      "          Validation Loss (standardized): 1.4932788024260657\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6605047049538945\n",
      "          Validation Loss (standardized): 1.5024845224408394\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6585618934028833\n",
      "          Validation Loss (standardized): 1.5212711987108178\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6577880315199001\n",
      "          Validation Loss (standardized): 1.528390872695676\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6574171725996363\n",
      "          Validation Loss (standardized): 1.5237921298849106\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6567474924084231\n",
      "          Validation Loss (standardized): 1.5146329828242902\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.656181545577409\n",
      "          Validation Loss (standardized): 1.5027213948000426\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6556657328993476\n",
      "          Validation Loss (standardized): 1.49856128750888\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6538756269511219\n",
      "Epoch: 1, Loss (standarized): 1.194691585712888\n",
      "          Validation Loss (standardized): 1.088782191474892\n",
      "Epoch: 6, Loss (standarized): 0.8250513304832108\n",
      "          Validation Loss (standardized): 1.1274320666432605\n",
      "Epoch: 11, Loss (standarized): 0.7519197958040162\n",
      "          Validation Loss (standardized): 1.3355912135243482\n",
      "Epoch: 16, Loss (standarized): 0.6745672972681883\n",
      "          Validation Loss (standardized): 1.5257027283026567\n",
      "Epoch: 21, Loss (standarized): 0.6505635553016444\n",
      "          Validation Loss (standardized): 1.7464155797162644\n",
      "Epoch: 26, Loss (standarized): 0.6543264229142572\n",
      "          Validation Loss (standardized): 1.8730873360421734\n",
      "Epoch: 31, Loss (standarized): 0.6419196653973889\n",
      "          Validation Loss (standardized): 1.8469111484188994\n",
      "Epoch: 36, Loss (standarized): 0.631032954336013\n",
      "          Validation Loss (standardized): 1.7254233523953044\n",
      "Epoch: 41, Loss (standarized): 0.6213301733325095\n",
      "          Validation Loss (standardized): 1.6081664328511847\n",
      "Epoch: 46, Loss (standarized): 0.6074190497855605\n",
      "          Validation Loss (standardized): 1.5607021428324737\n",
      "Epoch: 51, Loss (standarized): 0.5919383461986214\n",
      "          Validation Loss (standardized): 1.562367512016996\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5727102238509263\n",
      "          Validation Loss (standardized): 1.5860891319934676\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5528155899922084\n",
      "          Validation Loss (standardized): 1.5931868003191119\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.5331499311722759\n",
      "          Validation Loss (standardized): 1.5716853800355315\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.5145360938629558\n",
      "          Validation Loss (standardized): 1.5642724872074\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.4971687104786711\n",
      "          Validation Loss (standardized): 1.5511510621968145\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.48084863976153425\n",
      "          Validation Loss (standardized): 1.5279323264765345\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.4645166341035881\n",
      "          Validation Loss (standardized): 1.5123099143968326\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.44640031903685373\n",
      "          Validation Loss (standardized): 1.4832118092976376\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.42440453160426556\n",
      "          Validation Loss (standardized): 1.444611246195312\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.4035652761762178\n",
      "Epoch: 1, Loss (standarized): 1.0803569100832655\n",
      "          Validation Loss (standardized): 1.0240097804419592\n",
      "Epoch: 6, Loss (standarized): 0.8203997821366021\n",
      "          Validation Loss (standardized): 1.1598806065867147\n",
      "Epoch: 11, Loss (standarized): 0.730584857505299\n",
      "          Validation Loss (standardized): 1.2979301400420054\n",
      "Epoch: 16, Loss (standarized): 0.6692536136787552\n",
      "          Validation Loss (standardized): 1.4956085523649052\n",
      "Epoch: 21, Loss (standarized): 0.6603908255755747\n",
      "          Validation Loss (standardized): 1.6979608914778832\n",
      "Epoch: 26, Loss (standarized): 0.6540849288892058\n",
      "          Validation Loss (standardized): 1.747880713317094\n",
      "Epoch: 31, Loss (standarized): 0.6481456140283096\n",
      "          Validation Loss (standardized): 1.68278651042148\n",
      "Epoch: 36, Loss (standarized): 0.6474299244125025\n",
      "          Validation Loss (standardized): 1.5966670364581028\n",
      "Epoch: 41, Loss (standarized): 0.6481541576241729\n",
      "          Validation Loss (standardized): 1.5516994061871001\n",
      "Epoch: 46, Loss (standarized): 0.6484500597598221\n",
      "          Validation Loss (standardized): 1.557174762374919\n",
      "Epoch: 51, Loss (standarized): 0.6472197898141802\n",
      "          Validation Loss (standardized): 1.583342905849689\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6455841586872519\n",
      "          Validation Loss (standardized): 1.6036947678966653\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6449180313796821\n",
      "          Validation Loss (standardized): 1.6054612481000254\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6447687359129225\n",
      "          Validation Loss (standardized): 1.5994854496264774\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6446560758355865\n",
      "          Validation Loss (standardized): 1.5969265079558606\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6444381680351301\n",
      "          Validation Loss (standardized): 1.6002337978510859\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.644166905360741\n",
      "          Validation Loss (standardized): 1.6055200337351876\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.644027825031755\n",
      "          Validation Loss (standardized): 1.6061152559472982\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6440278885934932\n",
      "          Validation Loss (standardized): 1.6063741784227261\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6439247581592499\n",
      "          Validation Loss (standardized): 1.6103469320557233\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6437848807337779\n",
      "Epoch: 1, Loss (standarized): 1.107699510396021\n",
      "          Validation Loss (standardized): 1.073579468513855\n",
      "Epoch: 6, Loss (standarized): 0.7852584052522787\n",
      "          Validation Loss (standardized): 1.1555113731296414\n",
      "Epoch: 11, Loss (standarized): 0.7177358463513769\n",
      "          Validation Loss (standardized): 1.4305988551723903\n",
      "Epoch: 16, Loss (standarized): 0.6636496770470757\n",
      "          Validation Loss (standardized): 1.6944260750739604\n",
      "Epoch: 21, Loss (standarized): 0.6567800513611877\n",
      "          Validation Loss (standardized): 1.852642412520367\n",
      "Epoch: 26, Loss (standarized): 0.6610673005058485\n",
      "          Validation Loss (standardized): 1.8634444905234198\n",
      "Epoch: 31, Loss (standarized): 0.6526078187884385\n",
      "          Validation Loss (standardized): 1.763871885161529\n",
      "Epoch: 36, Loss (standarized): 0.6484855931890751\n",
      "          Validation Loss (standardized): 1.650427678246745\n",
      "Epoch: 41, Loss (standarized): 0.6484376980248302\n",
      "          Validation Loss (standardized): 1.601763403827262\n",
      "Epoch: 46, Loss (standarized): 0.6470867532911871\n",
      "          Validation Loss (standardized): 1.5968751168249542\n",
      "Epoch: 51, Loss (standarized): 0.6452366779092621\n",
      "          Validation Loss (standardized): 1.613686398571735\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6426965851700791\n",
      "          Validation Loss (standardized): 1.6424761941804014\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6393664443893511\n",
      "          Validation Loss (standardized): 1.6517911095024143\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6352622684245025\n",
      "          Validation Loss (standardized): 1.6479682927596024\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6292050778393067\n",
      "          Validation Loss (standardized): 1.6372497598445321\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6199062454673001\n",
      "          Validation Loss (standardized): 1.6248761289953269\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6061623036259114\n",
      "          Validation Loss (standardized): 1.615245381768851\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.5879765697719288\n",
      "          Validation Loss (standardized): 1.5998389106522373\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.5668847985642826\n",
      "          Validation Loss (standardized): 1.588443063607649\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.5454098846044219\n",
      "          Validation Loss (standardized): 1.5747540660661425\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.5294087589833886\n",
      "Epoch: 1, Loss (standarized): 1.1345230617163438\n",
      "          Validation Loss (standardized): 1.1177838207761779\n",
      "Epoch: 6, Loss (standarized): 0.8157066946788746\n",
      "          Validation Loss (standardized): 1.1320990935426822\n",
      "Epoch: 11, Loss (standarized): 0.7288057032105941\n",
      "          Validation Loss (standardized): 1.3490815729673173\n",
      "Epoch: 16, Loss (standarized): 0.6733693984813139\n",
      "          Validation Loss (standardized): 1.5231251241596988\n",
      "Epoch: 21, Loss (standarized): 0.6438068894994539\n",
      "          Validation Loss (standardized): 1.6990828057501963\n",
      "Epoch: 26, Loss (standarized): 0.6482067502496615\n",
      "          Validation Loss (standardized): 1.8330214685266\n",
      "Epoch: 31, Loss (standarized): 0.6443954233641376\n",
      "          Validation Loss (standardized): 1.827351578845865\n",
      "Epoch: 36, Loss (standarized): 0.6338813685911235\n",
      "          Validation Loss (standardized): 1.734150084009505\n",
      "Epoch: 41, Loss (standarized): 0.6271814517417097\n",
      "          Validation Loss (standardized): 1.6477153931046464\n",
      "Epoch: 46, Loss (standarized): 0.6174725341601809\n",
      "          Validation Loss (standardized): 1.5692042060673452\n",
      "Epoch: 51, Loss (standarized): 0.6043791722177255\n",
      "          Validation Loss (standardized): 1.5291718195981556\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5849979613243365\n",
      "          Validation Loss (standardized): 1.5209784520806233\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5584306158977608\n",
      "          Validation Loss (standardized): 1.4981818862877843\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.5266870080228117\n",
      "          Validation Loss (standardized): 1.4421440050706151\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.4931444235066397\n",
      "          Validation Loss (standardized): 1.407177937429613\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.46042615836391154\n",
      "          Validation Loss (standardized): 1.397493553189393\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.4289650369209605\n",
      "          Validation Loss (standardized): 1.37975079264209\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.39683740901957965\n",
      "          Validation Loss (standardized): 1.3606092135346717\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.3636552841698773\n",
      "          Validation Loss (standardized): 1.3365771310677919\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.3292511136892004\n",
      "          Validation Loss (standardized): 1.3008301085656782\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.3026690629108692\n",
      "Epoch: 1, Loss (standarized): 1.083469214952643\n",
      "          Validation Loss (standardized): 1.014315163707158\n",
      "Epoch: 6, Loss (standarized): 0.7743051665062655\n",
      "          Validation Loss (standardized): 1.1791339767836435\n",
      "Epoch: 11, Loss (standarized): 0.6975010155160007\n",
      "          Validation Loss (standardized): 1.4960665879767316\n",
      "Epoch: 16, Loss (standarized): 0.656567669918465\n",
      "          Validation Loss (standardized): 1.8184952354220096\n",
      "Epoch: 21, Loss (standarized): 0.6597731558653905\n",
      "          Validation Loss (standardized): 1.9299962427080624\n",
      "Epoch: 26, Loss (standarized): 0.6438642548167706\n",
      "          Validation Loss (standardized): 1.8156379277515968\n",
      "Epoch: 31, Loss (standarized): 0.6273742275919668\n",
      "          Validation Loss (standardized): 1.6938580058658057\n",
      "Epoch: 36, Loss (standarized): 0.6067079946809335\n",
      "          Validation Loss (standardized): 1.6244144787040353\n",
      "Epoch: 41, Loss (standarized): 0.5856014570064411\n",
      "          Validation Loss (standardized): 1.5597260937108564\n",
      "Epoch: 46, Loss (standarized): 0.5634623135436966\n",
      "          Validation Loss (standardized): 1.5133919597776726\n",
      "Epoch: 51, Loss (standarized): 0.5384303114150211\n",
      "          Validation Loss (standardized): 1.5044281372248793\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5118806769242478\n",
      "          Validation Loss (standardized): 1.5048289921879368\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.48130202138348627\n",
      "          Validation Loss (standardized): 1.5093309797886214\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.44272166889752246\n",
      "          Validation Loss (standardized): 1.4740089784458288\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.3952407733815883\n",
      "          Validation Loss (standardized): 1.4040866591201075\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.3457904974124122\n",
      "          Validation Loss (standardized): 1.333367383253545\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.30207982670329075\n",
      "          Validation Loss (standardized): 1.2839618397039976\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.26811695465298824\n",
      "          Validation Loss (standardized): 1.2512492133364008\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.24357899385517046\n",
      "          Validation Loss (standardized): 1.2303020522609325\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.2241317307321034\n",
      "          Validation Loss (standardized): 1.2129515081470226\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.21101940566460844\n",
      "Epoch: 1, Loss (standarized): 1.2873246401248921\n",
      "          Validation Loss (standardized): 1.099078845706942\n",
      "Epoch: 6, Loss (standarized): 0.810237211680028\n",
      "          Validation Loss (standardized): 1.0946426456291127\n",
      "Epoch: 11, Loss (standarized): 0.7058750956011162\n",
      "          Validation Loss (standardized): 1.342946365994162\n",
      "Epoch: 16, Loss (standarized): 0.6651840644828405\n",
      "          Validation Loss (standardized): 1.5872520184915289\n",
      "Epoch: 21, Loss (standarized): 0.6531121688278736\n",
      "          Validation Loss (standardized): 1.7491412996401858\n",
      "Epoch: 26, Loss (standarized): 0.652548241602629\n",
      "          Validation Loss (standardized): 1.7731814899144347\n",
      "Epoch: 31, Loss (standarized): 0.6480299580671072\n",
      "          Validation Loss (standardized): 1.7084976080947072\n",
      "Epoch: 36, Loss (standarized): 0.643238752502839\n",
      "          Validation Loss (standardized): 1.631426437184776\n",
      "Epoch: 41, Loss (standarized): 0.6422973456685473\n",
      "          Validation Loss (standardized): 1.5858573735036352\n",
      "Epoch: 46, Loss (standarized): 0.6405302869353611\n",
      "          Validation Loss (standardized): 1.5647366640251217\n",
      "Epoch: 51, Loss (standarized): 0.6393632043393501\n",
      "          Validation Loss (standardized): 1.5678605221492463\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6372916585288179\n",
      "          Validation Loss (standardized): 1.5877543408966408\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6340821469673507\n",
      "          Validation Loss (standardized): 1.601441956767643\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6309554556609261\n",
      "          Validation Loss (standardized): 1.6037425986414144\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.6280344792252274\n",
      "          Validation Loss (standardized): 1.599536980733131\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.6243502440373343\n",
      "          Validation Loss (standardized): 1.5884565033847997\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.619505578888742\n",
      "          Validation Loss (standardized): 1.5813709239084068\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6133608389574766\n",
      "          Validation Loss (standardized): 1.5761453042881644\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6055570596978275\n",
      "          Validation Loss (standardized): 1.5699865733577745\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.5959276555378232\n",
      "          Validation Loss (standardized): 1.5629102211707695\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.5866585448856769\n",
      "Epoch: 1, Loss (standarized): 1.2872356376287402\n",
      "          Validation Loss (standardized): 1.11693782478923\n",
      "Epoch: 6, Loss (standarized): 0.806479261884133\n",
      "          Validation Loss (standardized): 1.1207976041666898\n",
      "Epoch: 11, Loss (standarized): 0.7420396420503486\n",
      "          Validation Loss (standardized): 1.3141758919129025\n",
      "Epoch: 16, Loss (standarized): 0.6782479930793152\n",
      "          Validation Loss (standardized): 1.4846726271329413\n",
      "Epoch: 21, Loss (standarized): 0.6518592024993886\n",
      "          Validation Loss (standardized): 1.7009926076420678\n",
      "Epoch: 26, Loss (standarized): 0.6492039946332931\n",
      "          Validation Loss (standardized): 1.8346428458347808\n",
      "Epoch: 31, Loss (standarized): 0.6438488739123238\n",
      "          Validation Loss (standardized): 1.8358085411187821\n",
      "Epoch: 36, Loss (standarized): 0.6358324858649822\n",
      "          Validation Loss (standardized): 1.7756786060562164\n",
      "Epoch: 41, Loss (standarized): 0.62924680853013\n",
      "          Validation Loss (standardized): 1.7190409221775955\n",
      "Epoch: 46, Loss (standarized): 0.6200161170145277\n",
      "          Validation Loss (standardized): 1.6774679277819917\n",
      "Epoch: 51, Loss (standarized): 0.6089222592223105\n",
      "          Validation Loss (standardized): 1.6452834583206173\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.596505096761691\n",
      "          Validation Loss (standardized): 1.6143720705124807\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5797401107509476\n",
      "          Validation Loss (standardized): 1.5814476703726974\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.5588125872376342\n",
      "          Validation Loss (standardized): 1.555188284327556\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.5338166591794454\n",
      "          Validation Loss (standardized): 1.531466041455751\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.5064915093819291\n",
      "          Validation Loss (standardized): 1.5074064711424262\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.47839925914402187\n",
      "          Validation Loss (standardized): 1.4894015446633555\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.4512138128118334\n",
      "          Validation Loss (standardized): 1.4679323390218941\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.425295488634667\n",
      "          Validation Loss (standardized): 1.442124461757156\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.4003287977181764\n",
      "          Validation Loss (standardized): 1.4162653774308105\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.3808946812756684\n",
      "Epoch: 1, Loss (standarized): 1.1325776190141938\n",
      "          Validation Loss (standardized): 1.0958372373520957\n",
      "Epoch: 6, Loss (standarized): 0.7702270559924661\n",
      "          Validation Loss (standardized): 1.1894798266488829\n",
      "Epoch: 11, Loss (standarized): 0.7025434187158391\n",
      "          Validation Loss (standardized): 1.4080539500821523\n",
      "Epoch: 16, Loss (standarized): 0.6589236619008875\n",
      "          Validation Loss (standardized): 1.660797937891758\n",
      "Epoch: 21, Loss (standarized): 0.6482009946953338\n",
      "          Validation Loss (standardized): 1.8459266642453485\n",
      "Epoch: 26, Loss (standarized): 0.6545238111238176\n",
      "          Validation Loss (standardized): 1.9248969813282466\n",
      "Epoch: 31, Loss (standarized): 0.6465183114787979\n",
      "          Validation Loss (standardized): 1.8996165651322612\n",
      "Epoch: 36, Loss (standarized): 0.6397665166634134\n",
      "          Validation Loss (standardized): 1.7387567478144288\n",
      "Epoch: 41, Loss (standarized): 0.6348374265655143\n",
      "          Validation Loss (standardized): 1.5807724250545148\n",
      "Epoch: 46, Loss (standarized): 0.629497691967205\n",
      "          Validation Loss (standardized): 1.5406363223659425\n",
      "Epoch: 51, Loss (standarized): 0.6194550116760683\n",
      "          Validation Loss (standardized): 1.5417417785659382\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6019839684738236\n",
      "          Validation Loss (standardized): 1.5155994673235507\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5744703981989481\n",
      "          Validation Loss (standardized): 1.490814611309799\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.5348852079102315\n",
      "          Validation Loss (standardized): 1.463397208708584\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.48747368409934483\n",
      "          Validation Loss (standardized): 1.4003859137736314\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.4403359586968188\n",
      "          Validation Loss (standardized): 1.3717227459239871\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.3983841429071167\n",
      "          Validation Loss (standardized): 1.3389757066722783\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.3597784631348343\n",
      "          Validation Loss (standardized): 1.3238815076350712\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.32177842005775625\n",
      "          Validation Loss (standardized): 1.2855799324471933\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.2847191356485971\n",
      "          Validation Loss (standardized): 1.2335141725111975\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.258758306566774\n",
      "Epoch: 1, Loss (standarized): 1.013818620540553\n",
      "          Validation Loss (standardized): 1.012360144406466\n",
      "Epoch: 6, Loss (standarized): 0.7995923381389783\n",
      "          Validation Loss (standardized): 1.1878630245462596\n",
      "Epoch: 11, Loss (standarized): 0.7025333795479399\n",
      "          Validation Loss (standardized): 1.3496337095359727\n",
      "Epoch: 16, Loss (standarized): 0.6450246656310242\n",
      "          Validation Loss (standardized): 1.5849957689716732\n",
      "Epoch: 21, Loss (standarized): 0.6411589830046847\n",
      "          Validation Loss (standardized): 1.8335108561318703\n",
      "Epoch: 26, Loss (standarized): 0.6262743746836424\n",
      "          Validation Loss (standardized): 1.9314846390988203\n",
      "Epoch: 31, Loss (standarized): 0.6077164290691304\n",
      "          Validation Loss (standardized): 1.8248581068758933\n",
      "Epoch: 36, Loss (standarized): 0.5767224425166452\n",
      "          Validation Loss (standardized): 1.6458658238561623\n",
      "Epoch: 41, Loss (standarized): 0.5428828564645535\n",
      "          Validation Loss (standardized): 1.5330313403991627\n",
      "Epoch: 46, Loss (standarized): 0.5037123850009345\n",
      "          Validation Loss (standardized): 1.4924657264976458\n",
      "Epoch: 51, Loss (standarized): 0.4623437579289599\n",
      "          Validation Loss (standardized): 1.4319832275538726\n",
      "Epoch: 56, Loss (standarized): 0.4186117207998143\n",
      "          Validation Loss (standardized): 1.425207106296977\n",
      "Epoch: 61, Loss (standarized): 0.3727526979560447\n",
      "          Validation Loss (standardized): 1.3734955235619855\n",
      "Epoch: 66, Loss (standarized): 0.3270462053557389\n",
      "          Validation Loss (standardized): 1.3353300895694535\n",
      "Epoch: 71, Loss (standarized): 0.28646259028539167\n",
      "          Validation Loss (standardized): 1.319415354713894\n",
      "Epoch: 76, Loss (standarized): 0.2542705875202498\n",
      "          Validation Loss (standardized): 1.2881709569433268\n",
      "Epoch: 81, Loss (standarized): 0.2287364978805519\n",
      "          Validation Loss (standardized): 1.233727339454337\n",
      "Epoch: 86, Loss (standarized): 0.20944289115441433\n",
      "          Validation Loss (standardized): 1.1758918894801793\n",
      "Epoch: 91, Loss (standarized): 0.195038493375118\n",
      "          Validation Loss (standardized): 1.1386283037622726\n",
      "Epoch: 96, Loss (standarized): 0.1840515949075027\n",
      "          Validation Loss (standardized): 1.1183712398249017\n",
      "Final epoch: 100, Final loss (standarized): 0.17661002064808282\n",
      "Epoch: 1, Loss (standarized): 1.4435411578342434\n",
      "          Validation Loss (standardized): 1.192070590833987\n",
      "Epoch: 6, Loss (standarized): 0.8241991142932289\n",
      "          Validation Loss (standardized): 1.0784653510696485\n",
      "Epoch: 11, Loss (standarized): 0.7368031231873219\n",
      "          Validation Loss (standardized): 1.330662905293453\n",
      "Epoch: 16, Loss (standarized): 0.6886865926792087\n",
      "          Validation Loss (standardized): 1.5331522761310254\n",
      "Epoch: 21, Loss (standarized): 0.6565542594907919\n",
      "          Validation Loss (standardized): 1.6891092344807375\n",
      "Epoch: 26, Loss (standarized): 0.6527678612555544\n",
      "          Validation Loss (standardized): 1.7812986887572506\n",
      "Epoch: 31, Loss (standarized): 0.6573879959411045\n",
      "          Validation Loss (standardized): 1.786725462778922\n",
      "Epoch: 36, Loss (standarized): 0.6508722096414743\n",
      "          Validation Loss (standardized): 1.7250011535194765\n",
      "Epoch: 41, Loss (standarized): 0.6459787255050484\n",
      "          Validation Loss (standardized): 1.6455383512923556\n",
      "Epoch: 46, Loss (standarized): 0.6455558666442764\n",
      "          Validation Loss (standardized): 1.5927056346155732\n",
      "Epoch: 51, Loss (standarized): 0.6451060486344345\n",
      "          Validation Loss (standardized): 1.580745842024935\n",
      "Epoch: 56, Loss (standarized): 0.6439513952722804\n",
      "          Validation Loss (standardized): 1.5949017961921874\n",
      "Epoch: 61, Loss (standarized): 0.6429017223683391\n",
      "          Validation Loss (standardized): 1.6176286847541457\n",
      "Epoch: 66, Loss (standarized): 0.6418043405173424\n",
      "          Validation Loss (standardized): 1.6403837132931485\n",
      "Epoch: 71, Loss (standarized): 0.6403924082522892\n",
      "          Validation Loss (standardized): 1.649069391991823\n",
      "Epoch: 76, Loss (standarized): 0.6391416414679493\n",
      "          Validation Loss (standardized): 1.6405405744848065\n",
      "Epoch: 81, Loss (standarized): 0.6381274005050882\n",
      "          Validation Loss (standardized): 1.6287779501197206\n",
      "Epoch: 86, Loss (standarized): 0.6370758463496367\n",
      "          Validation Loss (standardized): 1.6197605690615546\n",
      "Epoch: 91, Loss (standarized): 0.6356776984640407\n",
      "          Validation Loss (standardized): 1.616968442911073\n",
      "Epoch: 96, Loss (standarized): 0.6337371921995685\n",
      "          Validation Loss (standardized): 1.6210302908509393\n",
      "Final epoch: 100, Final loss (standarized): 0.6318041748255672\n",
      "Epoch: 1, Loss (standarized): 1.1515848668560458\n",
      "          Validation Loss (standardized): 1.1232237189539414\n",
      "Epoch: 6, Loss (standarized): 0.7977412463093035\n",
      "          Validation Loss (standardized): 1.1154885022494232\n",
      "Epoch: 11, Loss (standarized): 0.7275271222785259\n",
      "          Validation Loss (standardized): 1.3092895370135038\n",
      "Epoch: 16, Loss (standarized): 0.6699602890666769\n",
      "          Validation Loss (standardized): 1.5426338126553765\n",
      "Epoch: 21, Loss (standarized): 0.6466257232349123\n",
      "          Validation Loss (standardized): 1.7467604798426808\n",
      "Epoch: 26, Loss (standarized): 0.6511728733745231\n",
      "          Validation Loss (standardized): 1.8676036277634085\n",
      "Epoch: 31, Loss (standarized): 0.641366405334583\n",
      "          Validation Loss (standardized): 1.899343733402984\n",
      "Epoch: 36, Loss (standarized): 0.6316815780522422\n",
      "          Validation Loss (standardized): 1.7986198693429152\n",
      "Epoch: 41, Loss (standarized): 0.6206100571247622\n",
      "          Validation Loss (standardized): 1.654469521409724\n",
      "Epoch: 46, Loss (standarized): 0.6073930090886787\n",
      "          Validation Loss (standardized): 1.5617648012822756\n",
      "Epoch: 51, Loss (standarized): 0.5893120365006972\n",
      "          Validation Loss (standardized): 1.5163935657738394\n",
      "Epoch: 56, Loss (standarized): 0.5647799093925264\n",
      "          Validation Loss (standardized): 1.5117175212091998\n",
      "Epoch: 61, Loss (standarized): 0.5341004576206478\n",
      "          Validation Loss (standardized): 1.486819246055437\n",
      "Epoch: 66, Loss (standarized): 0.5013778615316616\n",
      "          Validation Loss (standardized): 1.4896102972069067\n",
      "Epoch: 71, Loss (standarized): 0.47094467371005827\n",
      "          Validation Loss (standardized): 1.4671158678160345\n",
      "Epoch: 76, Loss (standarized): 0.4423828244285747\n",
      "          Validation Loss (standardized): 1.4423254344701777\n",
      "Epoch: 81, Loss (standarized): 0.4109621475315678\n",
      "          Validation Loss (standardized): 1.4063526197615743\n",
      "Epoch: 86, Loss (standarized): 0.37268328596114886\n",
      "          Validation Loss (standardized): 1.3583513258638518\n",
      "Epoch: 91, Loss (standarized): 0.3302787625312476\n",
      "          Validation Loss (standardized): 1.305055226078246\n",
      "Epoch: 96, Loss (standarized): 0.29148940599527456\n",
      "          Validation Loss (standardized): 1.2706655948057262\n",
      "Final epoch: 100, Final loss (standarized): 0.2659191592197167\n",
      "Epoch: 1, Loss (standarized): 1.1850717780687823\n",
      "          Validation Loss (standardized): 1.0733299434828325\n",
      "Epoch: 6, Loss (standarized): 0.8012016786860462\n",
      "          Validation Loss (standardized): 1.1789854034209157\n",
      "Epoch: 11, Loss (standarized): 0.7317844974613483\n",
      "          Validation Loss (standardized): 1.4264640498639254\n",
      "Epoch: 16, Loss (standarized): 0.6669875087428379\n",
      "          Validation Loss (standardized): 1.651116235646066\n",
      "Epoch: 21, Loss (standarized): 0.6567347115210219\n",
      "          Validation Loss (standardized): 1.8429219949599844\n",
      "Epoch: 26, Loss (standarized): 0.6595100436210605\n",
      "          Validation Loss (standardized): 1.9091224399059261\n",
      "Epoch: 31, Loss (standarized): 0.6425311185573966\n",
      "          Validation Loss (standardized): 1.847264227409104\n",
      "Epoch: 36, Loss (standarized): 0.6309996830747024\n",
      "          Validation Loss (standardized): 1.7438139420436838\n",
      "Epoch: 41, Loss (standarized): 0.6183693971794371\n",
      "          Validation Loss (standardized): 1.6634152750607458\n",
      "Epoch: 46, Loss (standarized): 0.6012331952653485\n",
      "          Validation Loss (standardized): 1.6170902035128296\n",
      "Epoch: 51, Loss (standarized): 0.5860918750725066\n",
      "          Validation Loss (standardized): 1.588094967888344\n",
      "Epoch: 56, Loss (standarized): 0.5692129455066888\n",
      "          Validation Loss (standardized): 1.5711951814721905\n",
      "Epoch: 61, Loss (standarized): 0.5522567943446034\n",
      "          Validation Loss (standardized): 1.5643761760189343\n",
      "Epoch: 66, Loss (standarized): 0.5353913561926447\n",
      "          Validation Loss (standardized): 1.5526152789289753\n",
      "Epoch: 71, Loss (standarized): 0.5193206748680954\n",
      "          Validation Loss (standardized): 1.5462877284999894\n",
      "Epoch: 76, Loss (standarized): 0.5024833195655838\n",
      "          Validation Loss (standardized): 1.5470290804498743\n",
      "Epoch: 81, Loss (standarized): 0.48351422775146374\n",
      "          Validation Loss (standardized): 1.532629322005639\n",
      "Epoch: 86, Loss (standarized): 0.4597311300207432\n",
      "          Validation Loss (standardized): 1.5100961806021322\n",
      "Epoch: 91, Loss (standarized): 0.4290565452264663\n",
      "          Validation Loss (standardized): 1.4756775629333239\n",
      "Epoch: 96, Loss (standarized): 0.3919727655022503\n",
      "          Validation Loss (standardized): 1.4266424003363396\n",
      "Final epoch: 100, Final loss (standarized): 0.35964802984718813\n",
      "Epoch: 1, Loss (standarized): 1.2152400504586272\n",
      "          Validation Loss (standardized): 1.103614570543648\n",
      "Epoch: 6, Loss (standarized): 0.8182488845374598\n",
      "          Validation Loss (standardized): 1.1978702062362758\n",
      "Epoch: 11, Loss (standarized): 0.7388652694702483\n",
      "          Validation Loss (standardized): 1.2770512327997996\n",
      "Epoch: 16, Loss (standarized): 0.6900792524558739\n",
      "          Validation Loss (standardized): 1.3118898999545925\n",
      "Epoch: 21, Loss (standarized): 0.6701084368969545\n",
      "          Validation Loss (standardized): 1.387095187915284\n",
      "Epoch: 26, Loss (standarized): 0.6678049592332093\n",
      "          Validation Loss (standardized): 1.4743685569913176\n",
      "Epoch: 31, Loss (standarized): 0.6634490935932305\n",
      "          Validation Loss (standardized): 1.526767087135056\n",
      "Epoch: 36, Loss (standarized): 0.6589241014981629\n",
      "          Validation Loss (standardized): 1.5309410047022987\n",
      "Epoch: 41, Loss (standarized): 0.6572284976326174\n",
      "          Validation Loss (standardized): 1.5080820134290853\n",
      "Epoch: 46, Loss (standarized): 0.6596273133226824\n",
      "          Validation Loss (standardized): 1.4858379438811398\n",
      "Epoch: 51, Loss (standarized): 0.6624357265774202\n",
      "          Validation Loss (standardized): 1.4818451892074103\n",
      "Epoch: 56, Loss (standarized): 0.6620416205983498\n",
      "          Validation Loss (standardized): 1.4855843101657555\n",
      "Epoch: 61, Loss (standarized): 0.6605495153668438\n",
      "          Validation Loss (standardized): 1.4806726495087916\n",
      "Epoch: 66, Loss (standarized): 0.6598635068225113\n",
      "          Validation Loss (standardized): 1.4705276129094296\n",
      "Epoch: 71, Loss (standarized): 0.6601434492608232\n",
      "          Validation Loss (standardized): 1.4625531864924044\n",
      "Epoch: 76, Loss (standarized): 0.6602294902011205\n",
      "          Validation Loss (standardized): 1.4678455844952198\n",
      "Epoch: 81, Loss (standarized): 0.6592747418016799\n",
      "          Validation Loss (standardized): 1.4746573532354286\n",
      "Epoch: 86, Loss (standarized): 0.6581061274956485\n",
      "          Validation Loss (standardized): 1.4788112092796342\n",
      "Epoch: 91, Loss (standarized): 0.6572411728827807\n",
      "          Validation Loss (standardized): 1.4841418390489145\n",
      "Epoch: 96, Loss (standarized): 0.6559104931450553\n",
      "          Validation Loss (standardized): 1.4903294010630994\n",
      "Final epoch: 100, Final loss (standarized): 0.654789516299637\n",
      "Epoch: 1, Loss (standarized): 1.1793611874588432\n",
      "          Validation Loss (standardized): 1.0799793556592385\n",
      "Epoch: 6, Loss (standarized): 0.805193666078385\n",
      "          Validation Loss (standardized): 1.1651833390621114\n",
      "Epoch: 11, Loss (standarized): 0.7258230247941219\n",
      "          Validation Loss (standardized): 1.3031518757339364\n",
      "Epoch: 16, Loss (standarized): 0.6875273257125823\n",
      "          Validation Loss (standardized): 1.3633054665352453\n",
      "Epoch: 21, Loss (standarized): 0.6739808538292917\n",
      "          Validation Loss (standardized): 1.3960973659700218\n",
      "Epoch: 26, Loss (standarized): 0.6773449855854926\n",
      "          Validation Loss (standardized): 1.417329011130212\n",
      "Epoch: 31, Loss (standarized): 0.6808857672064548\n",
      "          Validation Loss (standardized): 1.4258100923202701\n",
      "Epoch: 36, Loss (standarized): 0.6825748591379323\n",
      "          Validation Loss (standardized): 1.4264101554205622\n",
      "Epoch: 41, Loss (standarized): 0.6800886555666075\n",
      "          Validation Loss (standardized): 1.4250420207428078\n",
      "Epoch: 46, Loss (standarized): 0.6777071925551597\n",
      "          Validation Loss (standardized): 1.4288238870244558\n",
      "Epoch: 51, Loss (standarized): 0.6758148241878185\n",
      "          Validation Loss (standardized): 1.4364905006466355\n",
      "Epoch: 56, Loss (standarized): 0.6746043448777865\n",
      "          Validation Loss (standardized): 1.4549480053148833\n",
      "Epoch: 61, Loss (standarized): 0.6735995512964539\n",
      "          Validation Loss (standardized): 1.4563491250665765\n",
      "Epoch: 66, Loss (standarized): 0.6721309668023463\n",
      "          Validation Loss (standardized): 1.4592879942884356\n",
      "Epoch: 71, Loss (standarized): 0.6718120984202756\n",
      "          Validation Loss (standardized): 1.4636252397403513\n",
      "Epoch: 76, Loss (standarized): 0.670575408534845\n",
      "          Validation Loss (standardized): 1.4695182728648626\n",
      "Epoch: 81, Loss (standarized): 0.6696585923392517\n",
      "          Validation Loss (standardized): 1.4655060382688545\n",
      "Epoch: 86, Loss (standarized): 0.66940285977822\n",
      "          Validation Loss (standardized): 1.4645279694980087\n",
      "Epoch: 91, Loss (standarized): 0.6682594279273167\n",
      "          Validation Loss (standardized): 1.474026074276293\n",
      "Epoch: 96, Loss (standarized): 0.6672080457107282\n",
      "          Validation Loss (standardized): 1.4733902531879266\n",
      "Final epoch: 100, Final loss (standarized): 0.666817943851229\n",
      "Epoch: 1, Loss (standarized): 1.121942776356813\n",
      "          Validation Loss (standardized): 1.074429745080392\n",
      "Epoch: 6, Loss (standarized): 0.817288616681802\n",
      "          Validation Loss (standardized): 1.0686544498849704\n",
      "Epoch: 11, Loss (standarized): 0.744347376721294\n",
      "          Validation Loss (standardized): 1.1890586765464546\n",
      "Epoch: 16, Loss (standarized): 0.693917146716197\n",
      "          Validation Loss (standardized): 1.3011038293989223\n",
      "Epoch: 21, Loss (standarized): 0.6771731991484136\n",
      "          Validation Loss (standardized): 1.410299818650047\n",
      "Epoch: 26, Loss (standarized): 0.6721234792647427\n",
      "          Validation Loss (standardized): 1.4810833496844888\n",
      "Epoch: 31, Loss (standarized): 0.6674626173133236\n",
      "          Validation Loss (standardized): 1.5036719077229759\n",
      "Epoch: 36, Loss (standarized): 0.6640070256343235\n",
      "          Validation Loss (standardized): 1.4979160717586073\n",
      "Epoch: 41, Loss (standarized): 0.6630564497898935\n",
      "          Validation Loss (standardized): 1.4836360104641244\n",
      "Epoch: 46, Loss (standarized): 0.6635063128624573\n",
      "          Validation Loss (standardized): 1.4690920776759753\n",
      "Epoch: 51, Loss (standarized): 0.6633201555251533\n",
      "          Validation Loss (standardized): 1.467555071845451\n",
      "Epoch: 56, Loss (standarized): 0.6630590517188127\n",
      "          Validation Loss (standardized): 1.468839273636932\n",
      "Epoch: 61, Loss (standarized): 0.6632325022149504\n",
      "          Validation Loss (standardized): 1.4628922416226364\n",
      "Epoch: 66, Loss (standarized): 0.6629826645981348\n",
      "          Validation Loss (standardized): 1.46566407854297\n",
      "Epoch: 71, Loss (standarized): 0.6627670356446281\n",
      "          Validation Loss (standardized): 1.4674580695326733\n",
      "Epoch: 76, Loss (standarized): 0.6619362519824445\n",
      "          Validation Loss (standardized): 1.4793050122851805\n",
      "Epoch: 81, Loss (standarized): 0.6614445269803981\n",
      "          Validation Loss (standardized): 1.4742916302831708\n",
      "Epoch: 86, Loss (standarized): 0.6609334974864479\n",
      "          Validation Loss (standardized): 1.477553853499269\n",
      "Epoch: 91, Loss (standarized): 0.6598785673991587\n",
      "          Validation Loss (standardized): 1.483505459936548\n",
      "Epoch: 96, Loss (standarized): 0.6590095239002053\n",
      "          Validation Loss (standardized): 1.4928576386914487\n",
      "Final epoch: 100, Final loss (standarized): 0.6583798504561376\n",
      "Epoch: 1, Loss (standarized): 1.089352683561628\n",
      "          Validation Loss (standardized): 1.012214253807718\n",
      "Epoch: 6, Loss (standarized): 0.8174284841225907\n",
      "          Validation Loss (standardized): 1.085076202484354\n",
      "Epoch: 11, Loss (standarized): 0.743744258006473\n",
      "          Validation Loss (standardized): 1.1989297873085187\n",
      "Epoch: 16, Loss (standarized): 0.6976745027998283\n",
      "          Validation Loss (standardized): 1.3078159494265933\n",
      "Epoch: 21, Loss (standarized): 0.6788842729275476\n",
      "          Validation Loss (standardized): 1.415308634370341\n",
      "Epoch: 26, Loss (standarized): 0.6667806597187732\n",
      "          Validation Loss (standardized): 1.4885733490123525\n",
      "Epoch: 31, Loss (standarized): 0.6606988383728942\n",
      "          Validation Loss (standardized): 1.518375804530291\n",
      "Epoch: 36, Loss (standarized): 0.6596414224283914\n",
      "          Validation Loss (standardized): 1.502502853305589\n",
      "Epoch: 41, Loss (standarized): 0.6617932175696694\n",
      "          Validation Loss (standardized): 1.471419223629958\n",
      "Epoch: 46, Loss (standarized): 0.6633965679882977\n",
      "          Validation Loss (standardized): 1.4578094240252066\n",
      "Epoch: 51, Loss (standarized): 0.6637160991488013\n",
      "          Validation Loss (standardized): 1.4495639877765214\n",
      "Epoch: 56, Loss (standarized): 0.6643350294276706\n",
      "          Validation Loss (standardized): 1.4469816266429\n",
      "Epoch: 61, Loss (standarized): 0.6647404460891349\n",
      "          Validation Loss (standardized): 1.4451882964725569\n",
      "Epoch: 66, Loss (standarized): 0.6649316543913734\n",
      "          Validation Loss (standardized): 1.45256943131658\n",
      "Epoch: 71, Loss (standarized): 0.6632396532944156\n",
      "          Validation Loss (standardized): 1.4687176238843622\n",
      "Epoch: 76, Loss (standarized): 0.6617067834140427\n",
      "          Validation Loss (standardized): 1.4854123765085283\n",
      "Epoch: 81, Loss (standarized): 0.6610357053092609\n",
      "          Validation Loss (standardized): 1.4971221016657454\n",
      "Epoch: 86, Loss (standarized): 0.6610013349329156\n",
      "          Validation Loss (standardized): 1.500297956017683\n",
      "Epoch: 91, Loss (standarized): 0.6609046818254622\n",
      "          Validation Loss (standardized): 1.4949253714264448\n",
      "Epoch: 96, Loss (standarized): 0.6612124955758009\n",
      "          Validation Loss (standardized): 1.4905414908561563\n",
      "Final epoch: 100, Final loss (standarized): 0.6608619856400963\n",
      "Epoch: 1, Loss (standarized): 1.1229739505306773\n",
      "          Validation Loss (standardized): 1.0569370737761696\n",
      "Epoch: 6, Loss (standarized): 0.7602167485843162\n",
      "          Validation Loss (standardized): 1.2259385551583784\n",
      "Epoch: 11, Loss (standarized): 0.6987680674840633\n",
      "          Validation Loss (standardized): 1.5541074382059692\n",
      "Epoch: 16, Loss (standarized): 0.6572014686847857\n",
      "          Validation Loss (standardized): 1.8211118338190238\n",
      "Epoch: 21, Loss (standarized): 0.6589850204546146\n",
      "          Validation Loss (standardized): 1.9422103590532585\n",
      "Epoch: 26, Loss (standarized): 0.6598795248095329\n",
      "          Validation Loss (standardized): 1.8812435274836556\n",
      "Epoch: 31, Loss (standarized): 0.6494565420169277\n",
      "          Validation Loss (standardized): 1.7512967750911566\n",
      "Epoch: 36, Loss (standarized): 0.6474129885196722\n",
      "          Validation Loss (standardized): 1.651734235010162\n",
      "Epoch: 41, Loss (standarized): 0.6473384866205242\n",
      "          Validation Loss (standardized): 1.6096206542238425\n",
      "Epoch: 46, Loss (standarized): 0.646294149677674\n",
      "          Validation Loss (standardized): 1.6200851905969358\n",
      "Epoch: 51, Loss (standarized): 0.6457662788202613\n",
      "          Validation Loss (standardized): 1.6526876412383962\n",
      "Epoch: 56, Loss (standarized): 0.6446370507139293\n",
      "          Validation Loss (standardized): 1.6746466282951946\n",
      "Epoch: 61, Loss (standarized): 0.6438122097416167\n",
      "          Validation Loss (standardized): 1.6712926640536296\n",
      "Epoch: 66, Loss (standarized): 0.6431201131048736\n",
      "          Validation Loss (standardized): 1.657621546288239\n",
      "Epoch: 71, Loss (standarized): 0.6422845195951475\n",
      "          Validation Loss (standardized): 1.6546410219971004\n",
      "Epoch: 76, Loss (standarized): 0.640847872542551\n",
      "          Validation Loss (standardized): 1.6574454576853381\n",
      "Epoch: 81, Loss (standarized): 0.6384435097857459\n",
      "          Validation Loss (standardized): 1.6516786620179154\n",
      "Epoch: 86, Loss (standarized): 0.6341713604705205\n",
      "          Validation Loss (standardized): 1.642446359348973\n",
      "Epoch: 91, Loss (standarized): 0.6267428441282356\n",
      "          Validation Loss (standardized): 1.6327570295775318\n",
      "Epoch: 96, Loss (standarized): 0.6144665668473346\n",
      "          Validation Loss (standardized): 1.6169366460331651\n",
      "Final epoch: 100, Final loss (standarized): 0.600377081703474\n",
      "Epoch: 1, Loss (standarized): 1.2101222223084782\n",
      "          Validation Loss (standardized): 1.100757282097151\n",
      "Epoch: 6, Loss (standarized): 0.7895790509315459\n",
      "          Validation Loss (standardized): 1.1265169578975456\n",
      "Epoch: 11, Loss (standarized): 0.7239364203716212\n",
      "          Validation Loss (standardized): 1.3438131261842268\n",
      "Epoch: 16, Loss (standarized): 0.6656272085120551\n",
      "          Validation Loss (standardized): 1.51959914314665\n",
      "Epoch: 21, Loss (standarized): 0.6548361450080171\n",
      "          Validation Loss (standardized): 1.6692263407364503\n",
      "Epoch: 26, Loss (standarized): 0.6555447946632397\n",
      "          Validation Loss (standardized): 1.7209976960088795\n",
      "Epoch: 31, Loss (standarized): 0.6522593983540806\n",
      "          Validation Loss (standardized): 1.6973349551429786\n",
      "Epoch: 36, Loss (standarized): 0.6476253518885259\n",
      "          Validation Loss (standardized): 1.642848244488167\n",
      "Epoch: 41, Loss (standarized): 0.6478288999603073\n",
      "          Validation Loss (standardized): 1.577715197594555\n",
      "Epoch: 46, Loss (standarized): 0.6487330240847481\n",
      "          Validation Loss (standardized): 1.544211161926467\n",
      "Epoch: 51, Loss (standarized): 0.649261113907733\n",
      "          Validation Loss (standardized): 1.5538017817424417\n",
      "Epoch: 56, Loss (standarized): 0.6493495906405589\n",
      "          Validation Loss (standardized): 1.5749741312500918\n",
      "Epoch: 61, Loss (standarized): 0.6482366971608775\n",
      "          Validation Loss (standardized): 1.5892164894613348\n",
      "Epoch: 66, Loss (standarized): 0.6472553724641564\n",
      "          Validation Loss (standardized): 1.5960113910299332\n",
      "Epoch: 71, Loss (standarized): 0.6469892692898478\n",
      "          Validation Loss (standardized): 1.5914400847212513\n",
      "Epoch: 76, Loss (standarized): 0.6471287795216232\n",
      "          Validation Loss (standardized): 1.589129950966243\n",
      "Epoch: 81, Loss (standarized): 0.6472405119906246\n",
      "          Validation Loss (standardized): 1.591404055910372\n",
      "Epoch: 86, Loss (standarized): 0.6469696860727069\n",
      "          Validation Loss (standardized): 1.5917556659602765\n",
      "Epoch: 91, Loss (standarized): 0.6466542734163967\n",
      "          Validation Loss (standardized): 1.5957242591885554\n",
      "Epoch: 96, Loss (standarized): 0.6463807046873161\n",
      "          Validation Loss (standardized): 1.5985205618190503\n",
      "Final epoch: 100, Final loss (standarized): 0.646238404172161\n",
      "Epoch: 1, Loss (standarized): 1.044612220039592\n",
      "          Validation Loss (standardized): 1.0464965415136585\n",
      "Epoch: 6, Loss (standarized): 0.7507408460606585\n",
      "          Validation Loss (standardized): 1.186322013543493\n",
      "Epoch: 11, Loss (standarized): 0.6813549847565503\n",
      "          Validation Loss (standardized): 1.5096055898569043\n",
      "Epoch: 16, Loss (standarized): 0.6531459656600019\n",
      "          Validation Loss (standardized): 1.7779342205995097\n",
      "Epoch: 21, Loss (standarized): 0.6537349267186177\n",
      "          Validation Loss (standardized): 1.8624986300240685\n",
      "Epoch: 26, Loss (standarized): 0.6525496102606003\n",
      "          Validation Loss (standardized): 1.7940468027207261\n",
      "Epoch: 31, Loss (standarized): 0.6422208830543075\n",
      "          Validation Loss (standardized): 1.6834592499411847\n",
      "Epoch: 36, Loss (standarized): 0.638951901981188\n",
      "          Validation Loss (standardized): 1.5792960262961546\n",
      "Epoch: 41, Loss (standarized): 0.6351158667601348\n",
      "          Validation Loss (standardized): 1.5172965566527497\n",
      "Epoch: 46, Loss (standarized): 0.628095186647033\n",
      "          Validation Loss (standardized): 1.5154048664877238\n",
      "Epoch: 51, Loss (standarized): 0.6155446737822717\n",
      "          Validation Loss (standardized): 1.5426665726829862\n",
      "Epoch: 56, Loss (standarized): 0.5976511448612467\n",
      "          Validation Loss (standardized): 1.539855852404069\n",
      "Epoch: 61, Loss (standarized): 0.5721887519375335\n",
      "          Validation Loss (standardized): 1.4766105020380227\n",
      "Epoch: 66, Loss (standarized): 0.5383744154369885\n",
      "          Validation Loss (standardized): 1.4237949664834824\n",
      "Epoch: 71, Loss (standarized): 0.5003128121202448\n",
      "          Validation Loss (standardized): 1.3804670294301646\n",
      "Epoch: 76, Loss (standarized): 0.46582323811880844\n",
      "          Validation Loss (standardized): 1.367136717290311\n",
      "Epoch: 81, Loss (standarized): 0.43610352030046234\n",
      "          Validation Loss (standardized): 1.3746280614269457\n",
      "Epoch: 86, Loss (standarized): 0.4072428222027008\n",
      "          Validation Loss (standardized): 1.3796074992473806\n",
      "Epoch: 91, Loss (standarized): 0.3774178961210623\n",
      "          Validation Loss (standardized): 1.361021164141162\n",
      "Epoch: 96, Loss (standarized): 0.346698421252511\n",
      "          Validation Loss (standardized): 1.324238303660527\n",
      "Final epoch: 100, Final loss (standarized): 0.32157937636589307\n",
      "Epoch: 1, Loss (standarized): 1.0818226441358396\n",
      "          Validation Loss (standardized): 1.0747195423066775\n",
      "Epoch: 6, Loss (standarized): 0.8088055879457182\n",
      "          Validation Loss (standardized): 1.1339700944808364\n",
      "Epoch: 11, Loss (standarized): 0.7373722574114784\n",
      "          Validation Loss (standardized): 1.2922060830318727\n",
      "Epoch: 16, Loss (standarized): 0.6650583907733939\n",
      "          Validation Loss (standardized): 1.5130450387913215\n",
      "Epoch: 21, Loss (standarized): 0.6531893651472351\n",
      "          Validation Loss (standardized): 1.7583791027346496\n",
      "Epoch: 26, Loss (standarized): 0.6575196299055532\n",
      "          Validation Loss (standardized): 1.8839640155875423\n",
      "Epoch: 31, Loss (standarized): 0.6500706950800864\n",
      "          Validation Loss (standardized): 1.8859272067100796\n",
      "Epoch: 36, Loss (standarized): 0.6463150320713555\n",
      "          Validation Loss (standardized): 1.7767943406283606\n",
      "Epoch: 41, Loss (standarized): 0.6441671959098784\n",
      "          Validation Loss (standardized): 1.6572817923619845\n",
      "Epoch: 46, Loss (standarized): 0.6438414468777052\n",
      "          Validation Loss (standardized): 1.5987607785765392\n",
      "Epoch: 51, Loss (standarized): 0.6432153812969625\n",
      "          Validation Loss (standardized): 1.5917819173176686\n",
      "Epoch: 56, Loss (standarized): 0.6410827819557378\n",
      "          Validation Loss (standardized): 1.618702076796198\n",
      "Epoch: 61, Loss (standarized): 0.6391238149111534\n",
      "          Validation Loss (standardized): 1.644203834997384\n",
      "Epoch: 66, Loss (standarized): 0.6367532078804\n",
      "          Validation Loss (standardized): 1.6435485847350477\n",
      "Epoch: 71, Loss (standarized): 0.6336072230931642\n",
      "          Validation Loss (standardized): 1.638646448768065\n",
      "Epoch: 76, Loss (standarized): 0.628370105216227\n",
      "          Validation Loss (standardized): 1.633909283289263\n",
      "Epoch: 81, Loss (standarized): 0.6201882853832015\n",
      "          Validation Loss (standardized): 1.6246772189377163\n",
      "Epoch: 86, Loss (standarized): 0.6067553319064475\n",
      "          Validation Loss (standardized): 1.5976109597011843\n",
      "Epoch: 91, Loss (standarized): 0.5850418114682434\n",
      "          Validation Loss (standardized): 1.5531955866598033\n",
      "Epoch: 96, Loss (standarized): 0.551709472402283\n",
      "          Validation Loss (standardized): 1.4913963132794887\n",
      "Final epoch: 100, Final loss (standarized): 0.5162527453881717\n",
      "Epoch: 1, Loss (standarized): 1.0490503313024868\n",
      "          Validation Loss (standardized): 1.073856254182273\n",
      "Epoch: 6, Loss (standarized): 0.798812932904393\n",
      "          Validation Loss (standardized): 1.1891887689395197\n",
      "Epoch: 11, Loss (standarized): 0.7073606808973248\n",
      "          Validation Loss (standardized): 1.4169014166030738\n",
      "Epoch: 16, Loss (standarized): 0.6548950967123643\n",
      "          Validation Loss (standardized): 1.7132509710587218\n",
      "Epoch: 21, Loss (standarized): 0.6617499710456349\n",
      "          Validation Loss (standardized): 1.9591756951074997\n",
      "Epoch: 26, Loss (standarized): 0.6556353479108429\n",
      "          Validation Loss (standardized): 1.99576817924832\n",
      "Epoch: 31, Loss (standarized): 0.6472818853018765\n",
      "          Validation Loss (standardized): 1.8627267533378056\n",
      "Epoch: 36, Loss (standarized): 0.6403268276735445\n",
      "          Validation Loss (standardized): 1.7151072489567973\n",
      "Epoch: 41, Loss (standarized): 0.633126789594384\n",
      "          Validation Loss (standardized): 1.6127296267437052\n",
      "Epoch: 46, Loss (standarized): 0.6244375965555902\n",
      "          Validation Loss (standardized): 1.58051798290182\n",
      "Epoch: 51, Loss (standarized): 0.6080292538033385\n",
      "          Validation Loss (standardized): 1.6017915372692537\n",
      "Epoch: 56, Loss (standarized): 0.5822149323707254\n",
      "          Validation Loss (standardized): 1.5939853149667287\n",
      "Epoch: 61, Loss (standarized): 0.546005075514365\n",
      "          Validation Loss (standardized): 1.5601275979434603\n",
      "Epoch: 66, Loss (standarized): 0.5004023073346184\n",
      "          Validation Loss (standardized): 1.513939120904717\n",
      "Epoch: 71, Loss (standarized): 0.45028298799327615\n",
      "          Validation Loss (standardized): 1.4396748711853038\n",
      "Epoch: 76, Loss (standarized): 0.40028507366517\n",
      "          Validation Loss (standardized): 1.386824602619905\n",
      "Epoch: 81, Loss (standarized): 0.3527826090019621\n",
      "          Validation Loss (standardized): 1.3312992287986551\n",
      "Epoch: 86, Loss (standarized): 0.3085902841262654\n",
      "          Validation Loss (standardized): 1.293994305223079\n",
      "Epoch: 91, Loss (standarized): 0.270175241435665\n",
      "          Validation Loss (standardized): 1.250739180152398\n",
      "Epoch: 96, Loss (standarized): 0.2396204065487113\n",
      "          Validation Loss (standardized): 1.2088356670200338\n",
      "Final epoch: 100, Final loss (standarized): 0.2207919812915216\n",
      "Epoch: 1, Loss (standarized): 1.2019237164815095\n",
      "          Validation Loss (standardized): 1.043750457429455\n",
      "Epoch: 6, Loss (standarized): 0.8299005441098509\n",
      "          Validation Loss (standardized): 1.1229804940590276\n",
      "Epoch: 11, Loss (standarized): 0.7677499291500229\n",
      "          Validation Loss (standardized): 1.2991653844769806\n",
      "Epoch: 16, Loss (standarized): 0.7054162044839805\n",
      "          Validation Loss (standardized): 1.4108425903628872\n",
      "Epoch: 21, Loss (standarized): 0.6643561202278833\n",
      "          Validation Loss (standardized): 1.5123675264901817\n",
      "Epoch: 26, Loss (standarized): 0.6590935977802299\n",
      "          Validation Loss (standardized): 1.6288493903924814\n",
      "Epoch: 31, Loss (standarized): 0.6539172938910482\n",
      "          Validation Loss (standardized): 1.7297199791583158\n",
      "Epoch: 36, Loss (standarized): 0.6521459094166353\n",
      "          Validation Loss (standardized): 1.7583591726995391\n",
      "Epoch: 41, Loss (standarized): 0.649166745314245\n",
      "          Validation Loss (standardized): 1.70663856152852\n",
      "Epoch: 46, Loss (standarized): 0.6485878568830924\n",
      "          Validation Loss (standardized): 1.6460326627702988\n",
      "Epoch: 51, Loss (standarized): 0.6479815848209133\n",
      "          Validation Loss (standardized): 1.6076144494051583\n",
      "Epoch: 56, Loss (standarized): 0.6480100556814404\n",
      "          Validation Loss (standardized): 1.590488501269698\n",
      "Epoch: 61, Loss (standarized): 0.6475295954251852\n",
      "          Validation Loss (standardized): 1.598950165157202\n",
      "Epoch: 66, Loss (standarized): 0.6465170231256556\n",
      "          Validation Loss (standardized): 1.6228787118092456\n",
      "Epoch: 71, Loss (standarized): 0.6458075724706727\n",
      "          Validation Loss (standardized): 1.6391031277435923\n",
      "Epoch: 76, Loss (standarized): 0.645431621903569\n",
      "          Validation Loss (standardized): 1.6411258983388484\n",
      "Epoch: 81, Loss (standarized): 0.6451988882055456\n",
      "          Validation Loss (standardized): 1.6344859975820547\n",
      "Epoch: 86, Loss (standarized): 0.6451772690272278\n",
      "          Validation Loss (standardized): 1.6264314060756724\n",
      "Epoch: 91, Loss (standarized): 0.645115846611492\n",
      "          Validation Loss (standardized): 1.623734950411227\n",
      "Epoch: 96, Loss (standarized): 0.6449103103983308\n",
      "          Validation Loss (standardized): 1.6265240451900966\n",
      "Final epoch: 100, Final loss (standarized): 0.6447636245430856\n",
      "Epoch: 1, Loss (standarized): 1.1488462689133918\n",
      "          Validation Loss (standardized): 1.079371203561316\n",
      "Epoch: 6, Loss (standarized): 0.8053393870727943\n",
      "          Validation Loss (standardized): 1.1412485851999778\n",
      "Epoch: 11, Loss (standarized): 0.7331916853954972\n",
      "          Validation Loss (standardized): 1.3270157357001002\n",
      "Epoch: 16, Loss (standarized): 0.6671970227261176\n",
      "          Validation Loss (standardized): 1.5498149382894204\n",
      "Epoch: 21, Loss (standarized): 0.6577912049334474\n",
      "          Validation Loss (standardized): 1.7840789929607976\n",
      "Epoch: 26, Loss (standarized): 0.6557985118580733\n",
      "          Validation Loss (standardized): 1.9082570094140332\n",
      "Epoch: 31, Loss (standarized): 0.6514475301765668\n",
      "          Validation Loss (standardized): 1.9148778035857226\n",
      "Epoch: 36, Loss (standarized): 0.6439650185230642\n",
      "          Validation Loss (standardized): 1.847765327913072\n",
      "Epoch: 41, Loss (standarized): 0.637120745487543\n",
      "          Validation Loss (standardized): 1.7340392471157644\n",
      "Epoch: 46, Loss (standarized): 0.6309892368164718\n",
      "          Validation Loss (standardized): 1.6412356771760228\n",
      "Epoch: 51, Loss (standarized): 0.6233721103416618\n",
      "          Validation Loss (standardized): 1.600335687727612\n",
      "Epoch: 56, Loss (standarized): 0.6126410181380201\n",
      "          Validation Loss (standardized): 1.5965790107527773\n",
      "Epoch: 61, Loss (standarized): 0.5976453248424716\n",
      "          Validation Loss (standardized): 1.6159210941384823\n",
      "Epoch: 66, Loss (standarized): 0.5788803050247077\n",
      "          Validation Loss (standardized): 1.6245383081457803\n",
      "Epoch: 71, Loss (standarized): 0.5563777849062067\n",
      "          Validation Loss (standardized): 1.596386087084572\n",
      "Epoch: 76, Loss (standarized): 0.5323291651215413\n",
      "          Validation Loss (standardized): 1.5692371673536754\n",
      "Epoch: 81, Loss (standarized): 0.5093414380435759\n",
      "          Validation Loss (standardized): 1.5397009291553825\n",
      "Epoch: 86, Loss (standarized): 0.489272634236236\n",
      "          Validation Loss (standardized): 1.502172234872271\n",
      "Epoch: 91, Loss (standarized): 0.4706487696982142\n",
      "          Validation Loss (standardized): 1.4830175834840762\n",
      "Epoch: 96, Loss (standarized): 0.45126500402492464\n",
      "          Validation Loss (standardized): 1.4513193951068992\n",
      "Final epoch: 100, Final loss (standarized): 0.4331496058962758\n",
      "Epoch: 1, Loss (standarized): 1.1307406747128923\n",
      "          Validation Loss (standardized): 1.1037650292180259\n",
      "Epoch: 6, Loss (standarized): 0.7892156428742159\n",
      "          Validation Loss (standardized): 1.1349581637634705\n",
      "Epoch: 11, Loss (standarized): 0.7101331157453157\n",
      "          Validation Loss (standardized): 1.3507129932469106\n",
      "Epoch: 16, Loss (standarized): 0.6580568500382399\n",
      "          Validation Loss (standardized): 1.6252753495617902\n",
      "Epoch: 21, Loss (standarized): 0.6446262686142225\n",
      "          Validation Loss (standardized): 1.8317457585439123\n",
      "Epoch: 26, Loss (standarized): 0.6483847323101698\n",
      "          Validation Loss (standardized): 1.8977636142390075\n",
      "Epoch: 31, Loss (standarized): 0.6328250248242151\n",
      "          Validation Loss (standardized): 1.8356685525953653\n",
      "Epoch: 36, Loss (standarized): 0.6135733117748979\n",
      "          Validation Loss (standardized): 1.6751610148191258\n",
      "Epoch: 41, Loss (standarized): 0.594087038572031\n",
      "          Validation Loss (standardized): 1.5406780621057214\n",
      "Epoch: 46, Loss (standarized): 0.5705275252160538\n",
      "          Validation Loss (standardized): 1.455132465822316\n",
      "Epoch: 51, Loss (standarized): 0.5426232545025841\n",
      "          Validation Loss (standardized): 1.4113879305807888\n",
      "Epoch: 56, Loss (standarized): 0.511033369030482\n",
      "          Validation Loss (standardized): 1.4240925400528872\n",
      "Epoch: 61, Loss (standarized): 0.4786876229562852\n",
      "          Validation Loss (standardized): 1.4187174083217\n",
      "Epoch: 66, Loss (standarized): 0.4451490463996426\n",
      "          Validation Loss (standardized): 1.4113019428151379\n",
      "Epoch: 71, Loss (standarized): 0.40729962108400697\n",
      "          Validation Loss (standardized): 1.3963584085754506\n",
      "Epoch: 76, Loss (standarized): 0.3636627712518216\n",
      "          Validation Loss (standardized): 1.3593207451125104\n",
      "Epoch: 81, Loss (standarized): 0.3197537900073074\n",
      "          Validation Loss (standardized): 1.3264134162835757\n",
      "Epoch: 86, Loss (standarized): 0.28193930995296684\n",
      "          Validation Loss (standardized): 1.2873091485844785\n",
      "Epoch: 91, Loss (standarized): 0.25158630592470704\n",
      "          Validation Loss (standardized): 1.241700075677067\n",
      "Epoch: 96, Loss (standarized): 0.2272756363673062\n",
      "          Validation Loss (standardized): 1.2004304100343453\n",
      "Final epoch: 100, Final loss (standarized): 0.21166094470005037\n",
      "Epoch: 1, Loss (standarized): 1.1100854629844816\n",
      "          Validation Loss (standardized): 1.0690174187603538\n",
      "Epoch: 6, Loss (standarized): 0.764476933621945\n",
      "          Validation Loss (standardized): 1.2066824273073244\n",
      "Epoch: 11, Loss (standarized): 0.6932424355370872\n",
      "          Validation Loss (standardized): 1.5171530473313746\n",
      "Epoch: 16, Loss (standarized): 0.6556028928826113\n",
      "          Validation Loss (standardized): 1.8295643507535961\n",
      "Epoch: 21, Loss (standarized): 0.661419485391278\n",
      "          Validation Loss (standardized): 1.989491385100216\n",
      "Epoch: 26, Loss (standarized): 0.6581428424542999\n",
      "          Validation Loss (standardized): 1.9453912207138588\n",
      "Epoch: 31, Loss (standarized): 0.6455809234497305\n",
      "          Validation Loss (standardized): 1.816679934802774\n",
      "Epoch: 36, Loss (standarized): 0.6408597402804181\n",
      "          Validation Loss (standardized): 1.675665627646543\n",
      "Epoch: 41, Loss (standarized): 0.6333681624128487\n",
      "          Validation Loss (standardized): 1.5711879248230016\n",
      "Epoch: 46, Loss (standarized): 0.6254196064013301\n",
      "          Validation Loss (standardized): 1.5434265732016157\n",
      "Epoch: 51, Loss (standarized): 0.6098060142632896\n",
      "          Validation Loss (standardized): 1.5616913639141785\n",
      "Epoch: 56, Loss (standarized): 0.5851922665897816\n",
      "          Validation Loss (standardized): 1.558810029834182\n",
      "Epoch: 61, Loss (standarized): 0.548774331425898\n",
      "          Validation Loss (standardized): 1.512484007122659\n",
      "Epoch: 66, Loss (standarized): 0.501798917976144\n",
      "          Validation Loss (standardized): 1.463373184337418\n",
      "Epoch: 71, Loss (standarized): 0.4488556340255321\n",
      "          Validation Loss (standardized): 1.4130605020043818\n",
      "Epoch: 76, Loss (standarized): 0.39495013686173486\n",
      "          Validation Loss (standardized): 1.3487636462477512\n",
      "Epoch: 81, Loss (standarized): 0.34279675516537367\n",
      "          Validation Loss (standardized): 1.3032495969878746\n",
      "Epoch: 86, Loss (standarized): 0.2965651332741955\n",
      "          Validation Loss (standardized): 1.2557312999215096\n",
      "Epoch: 91, Loss (standarized): 0.2597637054192512\n",
      "          Validation Loss (standardized): 1.2355271741881853\n",
      "Epoch: 96, Loss (standarized): 0.23219853315677735\n",
      "          Validation Loss (standardized): 1.2081642716610859\n",
      "Final epoch: 100, Final loss (standarized): 0.21525445831558768\n",
      "Epoch: 1, Loss (standarized): 1.0893528221320072\n",
      "          Validation Loss (standardized): 0.9966577853639131\n",
      "Epoch: 6, Loss (standarized): 0.8086708744049322\n",
      "          Validation Loss (standardized): 1.137535573215196\n",
      "Epoch: 11, Loss (standarized): 0.7374901243978516\n",
      "          Validation Loss (standardized): 1.2965757455500944\n",
      "Epoch: 16, Loss (standarized): 0.6687435302693722\n",
      "          Validation Loss (standardized): 1.4716165914822978\n",
      "Epoch: 21, Loss (standarized): 0.653518070448298\n",
      "          Validation Loss (standardized): 1.6817812459511414\n",
      "Epoch: 26, Loss (standarized): 0.6516066282466664\n",
      "          Validation Loss (standardized): 1.7736020271673745\n",
      "Epoch: 31, Loss (standarized): 0.6481455909788721\n",
      "          Validation Loss (standardized): 1.7436062331243003\n",
      "Epoch: 36, Loss (standarized): 0.6465672770947124\n",
      "          Validation Loss (standardized): 1.6706457030634847\n",
      "Epoch: 41, Loss (standarized): 0.6459909045368815\n",
      "          Validation Loss (standardized): 1.6056652818963868\n",
      "Epoch: 46, Loss (standarized): 0.6473102592278335\n",
      "          Validation Loss (standardized): 1.5758514761416593\n",
      "Epoch: 51, Loss (standarized): 0.6471183970730265\n",
      "          Validation Loss (standardized): 1.584954683697059\n",
      "Epoch: 56, Loss (standarized): 0.6455013773238987\n",
      "          Validation Loss (standardized): 1.6160826143055256\n",
      "Epoch: 61, Loss (standarized): 0.6442827512544754\n",
      "          Validation Loss (standardized): 1.6381877000479008\n",
      "Epoch: 66, Loss (standarized): 0.6437650590034629\n",
      "          Validation Loss (standardized): 1.6403594799123211\n",
      "Epoch: 71, Loss (standarized): 0.64357070940588\n",
      "          Validation Loss (standardized): 1.6286678294219004\n",
      "Epoch: 76, Loss (standarized): 0.6431684105887597\n",
      "          Validation Loss (standardized): 1.6189905754936027\n",
      "Epoch: 81, Loss (standarized): 0.642697423725932\n",
      "          Validation Loss (standardized): 1.618171232495933\n",
      "Epoch: 86, Loss (standarized): 0.6421907478792842\n",
      "          Validation Loss (standardized): 1.6239760739204452\n",
      "Epoch: 91, Loss (standarized): 0.6415424000155182\n",
      "          Validation Loss (standardized): 1.6293918728985481\n",
      "Epoch: 96, Loss (standarized): 0.6406094866666023\n",
      "          Validation Loss (standardized): 1.6304435798064882\n",
      "Final epoch: 100, Final loss (standarized): 0.6396702365437362\n",
      "Epoch: 1, Loss (standarized): 1.1222567841454076\n",
      "          Validation Loss (standardized): 1.0417119994145843\n",
      "Epoch: 6, Loss (standarized): 0.8015156602018227\n",
      "          Validation Loss (standardized): 1.1268268936048682\n",
      "Epoch: 11, Loss (standarized): 0.7279895591470937\n",
      "          Validation Loss (standardized): 1.299411003864787\n",
      "Epoch: 16, Loss (standarized): 0.6485723625080991\n",
      "          Validation Loss (standardized): 1.4710015880199507\n",
      "Epoch: 21, Loss (standarized): 0.6232444921538222\n",
      "          Validation Loss (standardized): 1.6782889551003526\n",
      "Epoch: 26, Loss (standarized): 0.6196982359609963\n",
      "          Validation Loss (standardized): 1.8052338790693347\n",
      "Epoch: 31, Loss (standarized): 0.5951942202875733\n",
      "          Validation Loss (standardized): 1.7960572111431292\n",
      "Epoch: 36, Loss (standarized): 0.5743634291952049\n",
      "          Validation Loss (standardized): 1.6950082325663343\n",
      "Epoch: 41, Loss (standarized): 0.5505138982361241\n",
      "          Validation Loss (standardized): 1.5728429058952629\n",
      "Epoch: 46, Loss (standarized): 0.5282175037611945\n",
      "          Validation Loss (standardized): 1.4885516036730753\n",
      "Epoch: 51, Loss (standarized): 0.5049245216336214\n",
      "          Validation Loss (standardized): 1.4531176149008402\n",
      "Epoch: 56, Loss (standarized): 0.48085104165434744\n",
      "          Validation Loss (standardized): 1.458519865158399\n",
      "Epoch: 61, Loss (standarized): 0.454407278703694\n",
      "          Validation Loss (standardized): 1.455021178295444\n",
      "Epoch: 66, Loss (standarized): 0.4242056784370471\n",
      "          Validation Loss (standardized): 1.45219724065643\n",
      "Epoch: 71, Loss (standarized): 0.3887447312388905\n",
      "          Validation Loss (standardized): 1.4381438718157769\n",
      "Epoch: 76, Loss (standarized): 0.3500046967659219\n",
      "          Validation Loss (standardized): 1.3936983926784783\n",
      "Epoch: 81, Loss (standarized): 0.3137179303273122\n",
      "          Validation Loss (standardized): 1.3468018039505674\n",
      "Epoch: 86, Loss (standarized): 0.2826436970787261\n",
      "          Validation Loss (standardized): 1.303040928529833\n",
      "Epoch: 91, Loss (standarized): 0.25671688324823877\n",
      "          Validation Loss (standardized): 1.2602538280781919\n",
      "Epoch: 96, Loss (standarized): 0.23569105377622518\n",
      "          Validation Loss (standardized): 1.2320367571246775\n",
      "Final epoch: 100, Final loss (standarized): 0.22209569787921296\n",
      "Epoch: 1, Loss (standarized): 1.1181341619818954\n",
      "          Validation Loss (standardized): 1.0468914437330972\n",
      "Epoch: 6, Loss (standarized): 0.7692885989736173\n",
      "          Validation Loss (standardized): 1.212638902980786\n",
      "Epoch: 11, Loss (standarized): 0.7072690236715944\n",
      "          Validation Loss (standardized): 1.497819827854552\n",
      "Epoch: 16, Loss (standarized): 0.6513780249484343\n",
      "          Validation Loss (standardized): 1.708401077238978\n",
      "Epoch: 21, Loss (standarized): 0.6465417093262504\n",
      "          Validation Loss (standardized): 1.8651392693329576\n",
      "Epoch: 26, Loss (standarized): 0.6464191125775031\n",
      "          Validation Loss (standardized): 1.8961747868357333\n",
      "Epoch: 31, Loss (standarized): 0.6290272696747633\n",
      "          Validation Loss (standardized): 1.8107898163094496\n",
      "Epoch: 36, Loss (standarized): 0.6163613472732422\n",
      "          Validation Loss (standardized): 1.7151577096362096\n",
      "Epoch: 41, Loss (standarized): 0.6010910598039645\n",
      "          Validation Loss (standardized): 1.6206884586177275\n",
      "Epoch: 46, Loss (standarized): 0.585128341370823\n",
      "          Validation Loss (standardized): 1.5599051619701323\n",
      "Epoch: 51, Loss (standarized): 0.5688132396059233\n",
      "          Validation Loss (standardized): 1.557029642969456\n",
      "Epoch: 56, Loss (standarized): 0.550980559451882\n",
      "          Validation Loss (standardized): 1.5813650631049812\n",
      "Epoch: 61, Loss (standarized): 0.5332461884474673\n",
      "          Validation Loss (standardized): 1.5793413840147328\n",
      "Epoch: 66, Loss (standarized): 0.5157188585542289\n",
      "          Validation Loss (standardized): 1.5680207778513309\n",
      "Epoch: 71, Loss (standarized): 0.4981594795262927\n",
      "          Validation Loss (standardized): 1.5647890023731497\n",
      "Epoch: 76, Loss (standarized): 0.48105991804343573\n",
      "          Validation Loss (standardized): 1.5258139473238819\n",
      "Epoch: 81, Loss (standarized): 0.4639817007454468\n",
      "          Validation Loss (standardized): 1.5056373801782101\n",
      "Epoch: 86, Loss (standarized): 0.44548210709628544\n",
      "          Validation Loss (standardized): 1.4774201199139472\n",
      "Epoch: 91, Loss (standarized): 0.42217009814956646\n",
      "          Validation Loss (standardized): 1.4452605496939646\n",
      "Epoch: 96, Loss (standarized): 0.3899120135303509\n",
      "          Validation Loss (standardized): 1.4065105707198882\n",
      "Final epoch: 100, Final loss (standarized): 0.3570879070201783\n",
      "Epoch: 1, Loss (standarized): 1.1216275114483696\n",
      "          Validation Loss (standardized): 1.0659722044283328\n",
      "Epoch: 6, Loss (standarized): 0.7792254921570557\n",
      "          Validation Loss (standardized): 1.1266481022936663\n",
      "Epoch: 11, Loss (standarized): 0.7029171271588209\n",
      "          Validation Loss (standardized): 1.3006339081162337\n",
      "Epoch: 16, Loss (standarized): 0.6675601211921478\n",
      "          Validation Loss (standardized): 1.4307249580124366\n",
      "Epoch: 21, Loss (standarized): 0.6654932468261281\n",
      "          Validation Loss (standardized): 1.5020017860603951\n",
      "Epoch: 26, Loss (standarized): 0.6695245552740331\n",
      "          Validation Loss (standardized): 1.4884819747556854\n",
      "Epoch: 31, Loss (standarized): 0.6717546671672974\n",
      "          Validation Loss (standardized): 1.4513163717568105\n",
      "Epoch: 36, Loss (standarized): 0.670606270197204\n",
      "          Validation Loss (standardized): 1.4241358006437852\n",
      "Epoch: 41, Loss (standarized): 0.6686511040306489\n",
      "          Validation Loss (standardized): 1.4233223604879335\n",
      "Epoch: 46, Loss (standarized): 0.6669988915840928\n",
      "          Validation Loss (standardized): 1.4320527292729608\n",
      "Epoch: 51, Loss (standarized): 0.6666648502046845\n",
      "          Validation Loss (standardized): 1.432848428731024\n",
      "Epoch: 56, Loss (standarized): 0.6660843320478823\n",
      "          Validation Loss (standardized): 1.4359781210599167\n",
      "Epoch: 61, Loss (standarized): 0.6651179570274112\n",
      "          Validation Loss (standardized): 1.4396507446507376\n",
      "Epoch: 66, Loss (standarized): 0.6625435637816101\n",
      "          Validation Loss (standardized): 1.4487379561698113\n",
      "Epoch: 71, Loss (standarized): 0.6596878377578718\n",
      "          Validation Loss (standardized): 1.4564577279196622\n",
      "Epoch: 76, Loss (standarized): 0.6570636656433503\n",
      "          Validation Loss (standardized): 1.4662269979635518\n",
      "Epoch: 81, Loss (standarized): 0.6553716939399693\n",
      "          Validation Loss (standardized): 1.4684263098689756\n",
      "Epoch: 86, Loss (standarized): 0.6538794936658566\n",
      "          Validation Loss (standardized): 1.4686080384680302\n",
      "Epoch: 91, Loss (standarized): 0.6522947285499321\n",
      "          Validation Loss (standardized): 1.4641687208512304\n",
      "Epoch: 96, Loss (standarized): 0.6500747172190275\n",
      "          Validation Loss (standardized): 1.4652163537561165\n",
      "Final epoch: 100, Final loss (standarized): 0.6474302695107242\n",
      "Epoch: 1, Loss (standarized): 0.9963925534456888\n",
      "          Validation Loss (standardized): 1.0261731216500576\n",
      "Epoch: 6, Loss (standarized): 0.7781329521585224\n",
      "          Validation Loss (standardized): 1.1547147612076543\n",
      "Epoch: 11, Loss (standarized): 0.712668473765459\n",
      "          Validation Loss (standardized): 1.242429525419635\n",
      "Epoch: 16, Loss (standarized): 0.6902373350234378\n",
      "          Validation Loss (standardized): 1.3313785515140544\n",
      "Epoch: 21, Loss (standarized): 0.676091690801897\n",
      "          Validation Loss (standardized): 1.4041393153760309\n",
      "Epoch: 26, Loss (standarized): 0.6695182369363162\n",
      "          Validation Loss (standardized): 1.4464865612624191\n",
      "Epoch: 31, Loss (standarized): 0.6714512004518114\n",
      "          Validation Loss (standardized): 1.4454174724290774\n",
      "Epoch: 36, Loss (standarized): 0.675974015729\n",
      "          Validation Loss (standardized): 1.4193980753756996\n",
      "Epoch: 41, Loss (standarized): 0.6774150659401149\n",
      "          Validation Loss (standardized): 1.4152191649661396\n",
      "Epoch: 46, Loss (standarized): 0.6750243749502356\n",
      "          Validation Loss (standardized): 1.428484546983973\n",
      "Epoch: 51, Loss (standarized): 0.6717851555995067\n",
      "          Validation Loss (standardized): 1.4442790105145027\n",
      "Epoch: 56, Loss (standarized): 0.669894551961859\n",
      "          Validation Loss (standardized): 1.451937298665447\n",
      "Epoch: 61, Loss (standarized): 0.6700515307325017\n",
      "          Validation Loss (standardized): 1.4567169617520703\n",
      "Epoch: 66, Loss (standarized): 0.6701301772092038\n",
      "          Validation Loss (standardized): 1.4627366986895958\n",
      "Epoch: 71, Loss (standarized): 0.6697698509438494\n",
      "          Validation Loss (standardized): 1.4616341800366885\n",
      "Epoch: 76, Loss (standarized): 0.6697403012488343\n",
      "          Validation Loss (standardized): 1.4578976910836858\n",
      "Epoch: 81, Loss (standarized): 0.6695703776313194\n",
      "          Validation Loss (standardized): 1.4615662370817104\n",
      "Epoch: 86, Loss (standarized): 0.669127664764944\n",
      "          Validation Loss (standardized): 1.4637481784706787\n",
      "Epoch: 91, Loss (standarized): 0.6681765549594266\n",
      "          Validation Loss (standardized): 1.4736365175948656\n",
      "Epoch: 96, Loss (standarized): 0.6674938618257373\n",
      "          Validation Loss (standardized): 1.4768225738831202\n",
      "Final epoch: 100, Final loss (standarized): 0.6666808782160774\n",
      "Epoch: 1, Loss (standarized): 1.1616769025250224\n",
      "          Validation Loss (standardized): 1.05822081242045\n",
      "Epoch: 6, Loss (standarized): 0.7911519589731734\n",
      "          Validation Loss (standardized): 1.1923328843422454\n",
      "Epoch: 11, Loss (standarized): 0.723347376773634\n",
      "          Validation Loss (standardized): 1.314723516776354\n",
      "Epoch: 16, Loss (standarized): 0.6801765354744956\n",
      "          Validation Loss (standardized): 1.3858627556159062\n",
      "Epoch: 21, Loss (standarized): 0.6678272528631637\n",
      "          Validation Loss (standardized): 1.4535219096475116\n",
      "Epoch: 26, Loss (standarized): 0.6672963998186805\n",
      "          Validation Loss (standardized): 1.5057026125115127\n",
      "Epoch: 31, Loss (standarized): 0.6651033148943241\n",
      "          Validation Loss (standardized): 1.5381204054139976\n",
      "Epoch: 36, Loss (standarized): 0.6626494826983089\n",
      "          Validation Loss (standardized): 1.5409519487641226\n",
      "Epoch: 41, Loss (standarized): 0.6604642636109613\n",
      "          Validation Loss (standardized): 1.5308571884825775\n",
      "Epoch: 46, Loss (standarized): 0.660159400256286\n",
      "          Validation Loss (standardized): 1.5220511835667563\n",
      "Epoch: 51, Loss (standarized): 0.6610672552764747\n",
      "          Validation Loss (standardized): 1.5135147825882764\n",
      "Epoch: 56, Loss (standarized): 0.6621215918826734\n",
      "          Validation Loss (standardized): 1.4997038686733941\n",
      "Epoch: 61, Loss (standarized): 0.6623383902755128\n",
      "          Validation Loss (standardized): 1.490916840490534\n",
      "Epoch: 66, Loss (standarized): 0.661864555826382\n",
      "          Validation Loss (standardized): 1.4930896607973305\n",
      "Epoch: 71, Loss (standarized): 0.6607218644708013\n",
      "          Validation Loss (standardized): 1.50147250254159\n",
      "Epoch: 76, Loss (standarized): 0.6591554502760925\n",
      "          Validation Loss (standardized): 1.4994040516761475\n",
      "Epoch: 81, Loss (standarized): 0.6587340808956756\n",
      "          Validation Loss (standardized): 1.491587424672772\n",
      "Epoch: 86, Loss (standarized): 0.6576735449946772\n",
      "          Validation Loss (standardized): 1.5001017572452695\n",
      "Epoch: 91, Loss (standarized): 0.6568555657110745\n",
      "          Validation Loss (standardized): 1.5075615681066357\n",
      "Epoch: 96, Loss (standarized): 0.6564019269794993\n",
      "          Validation Loss (standardized): 1.513484528544026\n",
      "Final epoch: 100, Final loss (standarized): 0.6556855056973712\n",
      "Epoch: 1, Loss (standarized): 1.1640089762123111\n",
      "          Validation Loss (standardized): 1.1119932309283185\n",
      "Epoch: 6, Loss (standarized): 0.8437282896036298\n",
      "          Validation Loss (standardized): 1.0625309648660335\n",
      "Epoch: 11, Loss (standarized): 0.7263926551622317\n",
      "          Validation Loss (standardized): 1.196523332874513\n",
      "Epoch: 16, Loss (standarized): 0.6770118032638418\n",
      "          Validation Loss (standardized): 1.3548619851473738\n",
      "Epoch: 21, Loss (standarized): 0.6651784731203967\n",
      "          Validation Loss (standardized): 1.47479835415032\n",
      "Epoch: 26, Loss (standarized): 0.6653311119968104\n",
      "          Validation Loss (standardized): 1.5165502058702223\n",
      "Epoch: 31, Loss (standarized): 0.6662552874077191\n",
      "          Validation Loss (standardized): 1.5108282400986508\n",
      "Epoch: 36, Loss (standarized): 0.6654860991945597\n",
      "          Validation Loss (standardized): 1.496169930418308\n",
      "Epoch: 41, Loss (standarized): 0.6643092806461989\n",
      "          Validation Loss (standardized): 1.4722866381939066\n",
      "Epoch: 46, Loss (standarized): 0.6647278646601378\n",
      "          Validation Loss (standardized): 1.4591697599321234\n",
      "Epoch: 51, Loss (standarized): 0.6644093119197679\n",
      "          Validation Loss (standardized): 1.4699252230629956\n",
      "Epoch: 56, Loss (standarized): 0.66311486126446\n",
      "          Validation Loss (standardized): 1.4721198514915559\n",
      "Epoch: 61, Loss (standarized): 0.6615597269639545\n",
      "          Validation Loss (standardized): 1.4846742447735108\n",
      "Epoch: 66, Loss (standarized): 0.6605747937222335\n",
      "          Validation Loss (standardized): 1.4944690090839508\n",
      "Epoch: 71, Loss (standarized): 0.6589995986661152\n",
      "          Validation Loss (standardized): 1.5086592928760558\n",
      "Epoch: 76, Loss (standarized): 0.6575648621038145\n",
      "          Validation Loss (standardized): 1.5153099220297568\n",
      "Epoch: 81, Loss (standarized): 0.656628975283214\n",
      "          Validation Loss (standardized): 1.5229946264786756\n",
      "Epoch: 86, Loss (standarized): 0.6562767354753424\n",
      "          Validation Loss (standardized): 1.5253067009476433\n",
      "Epoch: 91, Loss (standarized): 0.6557091790208963\n",
      "          Validation Loss (standardized): 1.5239579169513282\n",
      "Epoch: 96, Loss (standarized): 0.6543229815542984\n",
      "          Validation Loss (standardized): 1.5307468073792005\n",
      "Final epoch: 100, Final loss (standarized): 0.6534500587782919\n",
      "Epoch: 1, Loss (standarized): 1.1344686627232083\n",
      "          Validation Loss (standardized): 1.049760469918656\n",
      "Epoch: 6, Loss (standarized): 0.783995009320442\n",
      "          Validation Loss (standardized): 1.1171793463087119\n",
      "Epoch: 11, Loss (standarized): 0.7140606062629\n",
      "          Validation Loss (standardized): 1.3947181062237615\n",
      "Epoch: 16, Loss (standarized): 0.6606553839703464\n",
      "          Validation Loss (standardized): 1.6508612875030149\n",
      "Epoch: 21, Loss (standarized): 0.6519914381948594\n",
      "          Validation Loss (standardized): 1.8277419671574635\n",
      "Epoch: 26, Loss (standarized): 0.6572059280332948\n",
      "          Validation Loss (standardized): 1.8519814479215295\n",
      "Epoch: 31, Loss (standarized): 0.6484243274157921\n",
      "          Validation Loss (standardized): 1.7668704286144876\n",
      "Epoch: 36, Loss (standarized): 0.6439879405626391\n",
      "          Validation Loss (standardized): 1.6650859374479337\n",
      "Epoch: 41, Loss (standarized): 0.6420942940175808\n",
      "          Validation Loss (standardized): 1.6009416024651009\n",
      "Epoch: 46, Loss (standarized): 0.6392535607741718\n",
      "          Validation Loss (standardized): 1.581938778534104\n",
      "Epoch: 51, Loss (standarized): 0.6362829894988972\n",
      "          Validation Loss (standardized): 1.5890035730983318\n",
      "Epoch: 56, Loss (standarized): 0.6309449778912808\n",
      "          Validation Loss (standardized): 1.606484334335764\n",
      "Epoch: 61, Loss (standarized): 0.6235433888505513\n",
      "          Validation Loss (standardized): 1.6115361355871092\n",
      "Epoch: 66, Loss (standarized): 0.6135365760854768\n",
      "          Validation Loss (standardized): 1.591793928619968\n",
      "Epoch: 71, Loss (standarized): 0.5998351788882607\n",
      "          Validation Loss (standardized): 1.5717126759527396\n",
      "Epoch: 76, Loss (standarized): 0.5816338727574769\n",
      "          Validation Loss (standardized): 1.551317451541172\n",
      "Epoch: 81, Loss (standarized): 0.5596308696846042\n",
      "          Validation Loss (standardized): 1.5306047624209196\n",
      "Epoch: 86, Loss (standarized): 0.5361134257973781\n",
      "          Validation Loss (standardized): 1.509440508271552\n",
      "Epoch: 91, Loss (standarized): 0.5131275622098298\n",
      "          Validation Loss (standardized): 1.497649684685044\n",
      "Epoch: 96, Loss (standarized): 0.4905269233250488\n",
      "          Validation Loss (standardized): 1.4882373627491639\n",
      "Final epoch: 100, Final loss (standarized): 0.4699077250224585\n",
      "Epoch: 1, Loss (standarized): 1.3816684252825608\n",
      "          Validation Loss (standardized): 1.2340059332261812\n",
      "Epoch: 6, Loss (standarized): 0.8120881738538864\n",
      "          Validation Loss (standardized): 1.1647730735408404\n",
      "Epoch: 11, Loss (standarized): 0.7225644387920943\n",
      "          Validation Loss (standardized): 1.338883111144181\n",
      "Epoch: 16, Loss (standarized): 0.6721986209646102\n",
      "          Validation Loss (standardized): 1.4947923180643483\n",
      "Epoch: 21, Loss (standarized): 0.6535889629676329\n",
      "          Validation Loss (standardized): 1.6476908437403923\n",
      "Epoch: 26, Loss (standarized): 0.6530788864755731\n",
      "          Validation Loss (standardized): 1.7205137484238362\n",
      "Epoch: 31, Loss (standarized): 0.6535546899427078\n",
      "          Validation Loss (standardized): 1.706679448068558\n",
      "Epoch: 36, Loss (standarized): 0.6496444081812863\n",
      "          Validation Loss (standardized): 1.651192159240751\n",
      "Epoch: 41, Loss (standarized): 0.6477147950462537\n",
      "          Validation Loss (standardized): 1.5925415012487931\n",
      "Epoch: 46, Loss (standarized): 0.648487838851036\n",
      "          Validation Loss (standardized): 1.5661205727217316\n",
      "Epoch: 51, Loss (standarized): 0.6485392812741072\n",
      "          Validation Loss (standardized): 1.5712933631324928\n",
      "Epoch: 56, Loss (standarized): 0.6481088935924614\n",
      "          Validation Loss (standardized): 1.5886097578809417\n",
      "Epoch: 61, Loss (standarized): 0.6476181013078346\n",
      "          Validation Loss (standardized): 1.602275819530799\n",
      "Epoch: 66, Loss (standarized): 0.6469352284595555\n",
      "          Validation Loss (standardized): 1.6065262457456124\n",
      "Epoch: 71, Loss (standarized): 0.6465647443253184\n",
      "          Validation Loss (standardized): 1.6058525960565757\n",
      "Epoch: 76, Loss (standarized): 0.6465792857417545\n",
      "          Validation Loss (standardized): 1.6068812578758294\n",
      "Epoch: 81, Loss (standarized): 0.6466411128603466\n",
      "          Validation Loss (standardized): 1.6054054469768708\n",
      "Epoch: 86, Loss (standarized): 0.6466155443994716\n",
      "          Validation Loss (standardized): 1.6052654552166392\n",
      "Epoch: 91, Loss (standarized): 0.6465651151692752\n",
      "          Validation Loss (standardized): 1.6073842160109488\n",
      "Epoch: 96, Loss (standarized): 0.6465368190232789\n",
      "          Validation Loss (standardized): 1.6098821973821076\n",
      "Final epoch: 100, Final loss (standarized): 0.6464810832211895\n",
      "Epoch: 1, Loss (standarized): 1.2587503754186369\n",
      "          Validation Loss (standardized): 1.1784145987801122\n",
      "Epoch: 6, Loss (standarized): 0.8661994966819595\n",
      "          Validation Loss (standardized): 1.073183364376223\n",
      "Epoch: 11, Loss (standarized): 0.7109942698117373\n",
      "          Validation Loss (standardized): 1.2549797195007724\n",
      "Epoch: 16, Loss (standarized): 0.6697591773967616\n",
      "          Validation Loss (standardized): 1.5577731138261222\n",
      "Epoch: 21, Loss (standarized): 0.654670885590141\n",
      "          Validation Loss (standardized): 1.8189702682106976\n",
      "Epoch: 26, Loss (standarized): 0.6517374543252\n",
      "          Validation Loss (standardized): 1.9009990255122142\n",
      "Epoch: 31, Loss (standarized): 0.6513822591801236\n",
      "          Validation Loss (standardized): 1.8307373033813892\n",
      "Epoch: 36, Loss (standarized): 0.6435738866032257\n",
      "          Validation Loss (standardized): 1.705611593146045\n",
      "Epoch: 41, Loss (standarized): 0.6392342361833848\n",
      "          Validation Loss (standardized): 1.6041422179394207\n",
      "Epoch: 46, Loss (standarized): 0.6368643986596265\n",
      "          Validation Loss (standardized): 1.5657550049516822\n",
      "Epoch: 51, Loss (standarized): 0.6312212941678033\n",
      "          Validation Loss (standardized): 1.5747305171667751\n",
      "Epoch: 56, Loss (standarized): 0.6234255051884815\n",
      "          Validation Loss (standardized): 1.5875306766768378\n",
      "Epoch: 61, Loss (standarized): 0.6116348572576398\n",
      "          Validation Loss (standardized): 1.5877685318971217\n",
      "Epoch: 66, Loss (standarized): 0.5947776588812043\n",
      "          Validation Loss (standardized): 1.5637639854277143\n",
      "Epoch: 71, Loss (standarized): 0.5727603290674897\n",
      "          Validation Loss (standardized): 1.5287678363408663\n",
      "Epoch: 76, Loss (standarized): 0.5462720607830335\n",
      "          Validation Loss (standardized): 1.5011009412452032\n",
      "Epoch: 81, Loss (standarized): 0.5157775017214128\n",
      "          Validation Loss (standardized): 1.47735073566124\n",
      "Epoch: 86, Loss (standarized): 0.48304332081144613\n",
      "          Validation Loss (standardized): 1.4470214762022038\n",
      "Epoch: 91, Loss (standarized): 0.44931573533211194\n",
      "          Validation Loss (standardized): 1.4183850413917916\n",
      "Epoch: 96, Loss (standarized): 0.4140885334685993\n",
      "          Validation Loss (standardized): 1.3850175443254147\n",
      "Final epoch: 100, Final loss (standarized): 0.3844843000647665\n",
      "Epoch: 1, Loss (standarized): 1.167865619777379\n",
      "          Validation Loss (standardized): 1.1014027552967467\n",
      "Epoch: 6, Loss (standarized): 0.8100898714622807\n",
      "          Validation Loss (standardized): 1.0875226569015157\n",
      "Epoch: 11, Loss (standarized): 0.7103230852258715\n",
      "          Validation Loss (standardized): 1.3756848549971996\n",
      "Epoch: 16, Loss (standarized): 0.6670688158000553\n",
      "          Validation Loss (standardized): 1.6816656734655397\n",
      "Epoch: 21, Loss (standarized): 0.6532422350032503\n",
      "          Validation Loss (standardized): 1.837903584499149\n",
      "Epoch: 26, Loss (standarized): 0.6569763715657947\n",
      "          Validation Loss (standardized): 1.8551335713057535\n",
      "Epoch: 31, Loss (standarized): 0.6456650099727511\n",
      "          Validation Loss (standardized): 1.7964315769928678\n",
      "Epoch: 36, Loss (standarized): 0.6354100254089671\n",
      "          Validation Loss (standardized): 1.693857468845011\n",
      "Epoch: 41, Loss (standarized): 0.628574681257045\n",
      "          Validation Loss (standardized): 1.582346648234312\n",
      "Epoch: 46, Loss (standarized): 0.6187211251034518\n",
      "          Validation Loss (standardized): 1.5223537380740826\n",
      "Epoch: 51, Loss (standarized): 0.6046027269776301\n",
      "          Validation Loss (standardized): 1.5121836246914568\n",
      "Epoch: 56, Loss (standarized): 0.5839016577683576\n",
      "          Validation Loss (standardized): 1.5412594534705335\n",
      "Epoch: 61, Loss (standarized): 0.5593266756581692\n",
      "          Validation Loss (standardized): 1.5388020144627639\n",
      "Epoch: 66, Loss (standarized): 0.5337262112569086\n",
      "          Validation Loss (standardized): 1.5075150529152659\n",
      "Epoch: 71, Loss (standarized): 0.5108173206872428\n",
      "          Validation Loss (standardized): 1.4966914465965389\n",
      "Epoch: 76, Loss (standarized): 0.49441067131832106\n",
      "          Validation Loss (standardized): 1.4794726958417206\n",
      "Epoch: 81, Loss (standarized): 0.48361137640227153\n",
      "          Validation Loss (standardized): 1.480646501536489\n",
      "Epoch: 86, Loss (standarized): 0.47674098579915736\n",
      "          Validation Loss (standardized): 1.4748508209719253\n",
      "Epoch: 91, Loss (standarized): 0.47237841217323573\n",
      "          Validation Loss (standardized): 1.484879944833189\n",
      "Epoch: 96, Loss (standarized): 0.4691558327486514\n",
      "          Validation Loss (standardized): 1.4901109771828587\n",
      "Final epoch: 100, Final loss (standarized): 0.46665093341123204\n",
      "Epoch: 1, Loss (standarized): 1.230231652354862\n",
      "          Validation Loss (standardized): 1.1164019148122306\n",
      "Epoch: 6, Loss (standarized): 0.8142076229591713\n",
      "          Validation Loss (standardized): 1.1357650173510427\n",
      "Epoch: 11, Loss (standarized): 0.7025352425409436\n",
      "          Validation Loss (standardized): 1.370673372139709\n",
      "Epoch: 16, Loss (standarized): 0.6687161165788321\n",
      "          Validation Loss (standardized): 1.6489894671082053\n",
      "Epoch: 21, Loss (standarized): 0.6597505241426599\n",
      "          Validation Loss (standardized): 1.8261465159987766\n",
      "Epoch: 26, Loss (standarized): 0.6497860375162223\n",
      "          Validation Loss (standardized): 1.8728465007442192\n",
      "Epoch: 31, Loss (standarized): 0.6476025958046614\n",
      "          Validation Loss (standardized): 1.8624139314295918\n",
      "Epoch: 36, Loss (standarized): 0.6362265313719188\n",
      "          Validation Loss (standardized): 1.8052440152595095\n",
      "Epoch: 41, Loss (standarized): 0.6249584483679334\n",
      "          Validation Loss (standardized): 1.7062520638066172\n",
      "Epoch: 46, Loss (standarized): 0.6138439163785271\n",
      "          Validation Loss (standardized): 1.6218451688030888\n",
      "Epoch: 51, Loss (standarized): 0.5986819336993489\n",
      "          Validation Loss (standardized): 1.5689822032786607\n",
      "Epoch: 56, Loss (standarized): 0.5782373812266708\n",
      "          Validation Loss (standardized): 1.5363648430715886\n",
      "Epoch: 61, Loss (standarized): 0.5509401766932501\n",
      "          Validation Loss (standardized): 1.533867067584582\n",
      "Epoch: 66, Loss (standarized): 0.518101850069436\n",
      "          Validation Loss (standardized): 1.5043276119672637\n",
      "Epoch: 71, Loss (standarized): 0.4830335471227213\n",
      "          Validation Loss (standardized): 1.4774811523822173\n",
      "Epoch: 76, Loss (standarized): 0.44883216844213547\n",
      "          Validation Loss (standardized): 1.4531442659479143\n",
      "Epoch: 81, Loss (standarized): 0.41662694531997707\n",
      "          Validation Loss (standardized): 1.4133278014674515\n",
      "Epoch: 86, Loss (standarized): 0.3852714271408129\n",
      "          Validation Loss (standardized): 1.3825859146748476\n",
      "Epoch: 91, Loss (standarized): 0.352621857727246\n",
      "          Validation Loss (standardized): 1.3399572757570841\n",
      "Epoch: 96, Loss (standarized): 0.3180998769892012\n",
      "          Validation Loss (standardized): 1.3032616419759848\n",
      "Final epoch: 100, Final loss (standarized): 0.29079919860370923\n",
      "Epoch: 1, Loss (standarized): 1.0918718564642713\n",
      "          Validation Loss (standardized): 1.0166937440983375\n",
      "Epoch: 6, Loss (standarized): 0.7940868931835203\n",
      "          Validation Loss (standardized): 1.179512865451242\n",
      "Epoch: 11, Loss (standarized): 0.7236475494957358\n",
      "          Validation Loss (standardized): 1.3620104280009193\n",
      "Epoch: 16, Loss (standarized): 0.6606112294015102\n",
      "          Validation Loss (standardized): 1.5382569350561557\n",
      "Epoch: 21, Loss (standarized): 0.6559261198624501\n",
      "          Validation Loss (standardized): 1.7298901919503678\n",
      "Epoch: 26, Loss (standarized): 0.6531379015837904\n",
      "          Validation Loss (standardized): 1.7872735369968167\n",
      "Epoch: 31, Loss (standarized): 0.6480935961745486\n",
      "          Validation Loss (standardized): 1.722193242096238\n",
      "Epoch: 36, Loss (standarized): 0.6474983941029088\n",
      "          Validation Loss (standardized): 1.6364527961213682\n",
      "Epoch: 41, Loss (standarized): 0.6478125498008405\n",
      "          Validation Loss (standardized): 1.5861686467689597\n",
      "Epoch: 46, Loss (standarized): 0.6484497279922053\n",
      "          Validation Loss (standardized): 1.5831554012754319\n",
      "Epoch: 51, Loss (standarized): 0.647414821719519\n",
      "          Validation Loss (standardized): 1.6126347978910347\n",
      "Epoch: 56, Loss (standarized): 0.6458912832382792\n",
      "          Validation Loss (standardized): 1.6375730303457363\n",
      "Epoch: 61, Loss (standarized): 0.6452941835605037\n",
      "          Validation Loss (standardized): 1.6412806051733164\n",
      "Epoch: 66, Loss (standarized): 0.6453381932690953\n",
      "          Validation Loss (standardized): 1.628832670028603\n",
      "Epoch: 71, Loss (standarized): 0.6453200726922017\n",
      "          Validation Loss (standardized): 1.6195103210741066\n",
      "Epoch: 76, Loss (standarized): 0.6449179791368475\n",
      "          Validation Loss (standardized): 1.6216601424748172\n",
      "Epoch: 81, Loss (standarized): 0.6445470681991828\n",
      "          Validation Loss (standardized): 1.630245876381991\n",
      "Epoch: 86, Loss (standarized): 0.6444230025827267\n",
      "          Validation Loss (standardized): 1.6352014982170504\n",
      "Epoch: 91, Loss (standarized): 0.6443201277290259\n",
      "          Validation Loss (standardized): 1.6345867745148426\n",
      "Epoch: 96, Loss (standarized): 0.6441435074077217\n",
      "          Validation Loss (standardized): 1.6322380270883259\n",
      "Final epoch: 100, Final loss (standarized): 0.6440198177229862\n",
      "Epoch: 1, Loss (standarized): 1.168678018525507\n",
      "          Validation Loss (standardized): 1.1610065866786918\n",
      "Epoch: 6, Loss (standarized): 0.7786901012406723\n",
      "          Validation Loss (standardized): 1.1723005187479927\n",
      "Epoch: 11, Loss (standarized): 0.7099123474469803\n",
      "          Validation Loss (standardized): 1.429596640225833\n",
      "Epoch: 16, Loss (standarized): 0.66558377756311\n",
      "          Validation Loss (standardized): 1.6670835949227243\n",
      "Epoch: 21, Loss (standarized): 0.6543707338388083\n",
      "          Validation Loss (standardized): 1.8328783885982785\n",
      "Epoch: 26, Loss (standarized): 0.6599544805817983\n",
      "          Validation Loss (standardized): 1.8980410045584846\n",
      "Epoch: 31, Loss (standarized): 0.6527175567243625\n",
      "          Validation Loss (standardized): 1.8774823099025753\n",
      "Epoch: 36, Loss (standarized): 0.6478411053459993\n",
      "          Validation Loss (standardized): 1.7797750599878286\n",
      "Epoch: 41, Loss (standarized): 0.6460042520070255\n",
      "          Validation Loss (standardized): 1.6683009680361478\n",
      "Epoch: 46, Loss (standarized): 0.6446758746798368\n",
      "          Validation Loss (standardized): 1.6069300697699145\n",
      "Epoch: 51, Loss (standarized): 0.6437389963273739\n",
      "          Validation Loss (standardized): 1.608997438257806\n",
      "Epoch: 56, Loss (standarized): 0.641655684187782\n",
      "          Validation Loss (standardized): 1.660840963052762\n",
      "Epoch: 61, Loss (standarized): 0.6401458622649348\n",
      "          Validation Loss (standardized): 1.6963585075504741\n",
      "Epoch: 66, Loss (standarized): 0.6382778516044314\n",
      "          Validation Loss (standardized): 1.6898778604927056\n",
      "Epoch: 71, Loss (standarized): 0.6357717697358429\n",
      "          Validation Loss (standardized): 1.6717906106849159\n",
      "Epoch: 76, Loss (standarized): 0.6316546911243337\n",
      "          Validation Loss (standardized): 1.6479675365009057\n",
      "Epoch: 81, Loss (standarized): 0.6248957921477893\n",
      "          Validation Loss (standardized): 1.6281218567735993\n",
      "Epoch: 86, Loss (standarized): 0.6133670790644472\n",
      "          Validation Loss (standardized): 1.6012672380543969\n",
      "Epoch: 91, Loss (standarized): 0.5943269438005049\n",
      "          Validation Loss (standardized): 1.571023287108065\n",
      "Epoch: 96, Loss (standarized): 0.5650229177728099\n",
      "          Validation Loss (standardized): 1.5229746249598912\n",
      "Final epoch: 100, Final loss (standarized): 0.5341063193104556\n",
      "Epoch: 1, Loss (standarized): 1.1344046432225627\n",
      "          Validation Loss (standardized): 1.0641941710636076\n",
      "Epoch: 6, Loss (standarized): 0.8237487033781794\n",
      "          Validation Loss (standardized): 1.1362232919250965\n",
      "Epoch: 11, Loss (standarized): 0.7469222018186011\n",
      "          Validation Loss (standardized): 1.3426483661332245\n",
      "Epoch: 16, Loss (standarized): 0.666244030491234\n",
      "          Validation Loss (standardized): 1.562048942246656\n",
      "Epoch: 21, Loss (standarized): 0.6474802932495964\n",
      "          Validation Loss (standardized): 1.7914928465707607\n",
      "Epoch: 26, Loss (standarized): 0.6485437042815808\n",
      "          Validation Loss (standardized): 1.9151970505878944\n",
      "Epoch: 31, Loss (standarized): 0.6306304518156252\n",
      "          Validation Loss (standardized): 1.8937524649228847\n",
      "Epoch: 36, Loss (standarized): 0.615715974857745\n",
      "          Validation Loss (standardized): 1.7636702748386568\n",
      "Epoch: 41, Loss (standarized): 0.5944104618930324\n",
      "          Validation Loss (standardized): 1.6281230819184507\n",
      "Epoch: 46, Loss (standarized): 0.5711908967763905\n",
      "          Validation Loss (standardized): 1.5220613010867459\n",
      "Epoch: 51, Loss (standarized): 0.54199405927422\n",
      "          Validation Loss (standardized): 1.4758462079896786\n",
      "Epoch: 56, Loss (standarized): 0.5105404327762338\n",
      "          Validation Loss (standardized): 1.4562170512768853\n",
      "Epoch: 61, Loss (standarized): 0.4798844278663287\n",
      "          Validation Loss (standardized): 1.4161027680040457\n",
      "Epoch: 66, Loss (standarized): 0.4496968096918948\n",
      "          Validation Loss (standardized): 1.4097853359587644\n",
      "Epoch: 71, Loss (standarized): 0.41627783522755774\n",
      "          Validation Loss (standardized): 1.3860108421908603\n",
      "Epoch: 76, Loss (standarized): 0.37873212440261234\n",
      "          Validation Loss (standardized): 1.348816924120525\n",
      "Epoch: 81, Loss (standarized): 0.3396631944891453\n",
      "          Validation Loss (standardized): 1.3025036193982646\n",
      "Epoch: 86, Loss (standarized): 0.30160900475170344\n",
      "          Validation Loss (standardized): 1.2651156079374328\n",
      "Epoch: 91, Loss (standarized): 0.2681664484552614\n",
      "          Validation Loss (standardized): 1.234318234615328\n",
      "Epoch: 96, Loss (standarized): 0.24131654423502283\n",
      "          Validation Loss (standardized): 1.2208632853699863\n",
      "Final epoch: 100, Final loss (standarized): 0.22376940151165597\n",
      "Epoch: 1, Loss (standarized): 1.1064295530268013\n",
      "          Validation Loss (standardized): 1.1112744102761047\n",
      "Epoch: 6, Loss (standarized): 0.7739475336247744\n",
      "          Validation Loss (standardized): 1.1968385090881783\n",
      "Epoch: 11, Loss (standarized): 0.6957344658911714\n",
      "          Validation Loss (standardized): 1.3786847609269735\n",
      "Epoch: 16, Loss (standarized): 0.6546781174924451\n",
      "          Validation Loss (standardized): 1.617873265806103\n",
      "Epoch: 21, Loss (standarized): 0.645659067677513\n",
      "          Validation Loss (standardized): 1.8254999563186318\n",
      "Epoch: 26, Loss (standarized): 0.6420039756806162\n",
      "          Validation Loss (standardized): 1.9339409760763502\n",
      "Epoch: 31, Loss (standarized): 0.6325011763889427\n",
      "          Validation Loss (standardized): 1.8648335462166905\n",
      "Epoch: 36, Loss (standarized): 0.6125723987700757\n",
      "          Validation Loss (standardized): 1.6572181242405737\n",
      "Epoch: 41, Loss (standarized): 0.5912860125578626\n",
      "          Validation Loss (standardized): 1.5168506829816906\n",
      "Epoch: 46, Loss (standarized): 0.5614282329602217\n",
      "          Validation Loss (standardized): 1.455115816217252\n",
      "Epoch: 51, Loss (standarized): 0.5225033843878826\n",
      "          Validation Loss (standardized): 1.3999270611825172\n",
      "Epoch: 56, Loss (standarized): 0.4766172434348092\n",
      "          Validation Loss (standardized): 1.3829945292025054\n",
      "Epoch: 61, Loss (standarized): 0.4286189226158463\n",
      "          Validation Loss (standardized): 1.398457893245184\n",
      "Epoch: 66, Loss (standarized): 0.38325372982517736\n",
      "          Validation Loss (standardized): 1.3874786273852455\n",
      "Epoch: 71, Loss (standarized): 0.34185047272826113\n",
      "          Validation Loss (standardized): 1.3750982333218977\n",
      "Epoch: 76, Loss (standarized): 0.3044858874169559\n",
      "          Validation Loss (standardized): 1.333468056967982\n",
      "Epoch: 81, Loss (standarized): 0.27144901440214536\n",
      "          Validation Loss (standardized): 1.287027167443403\n",
      "Epoch: 86, Loss (standarized): 0.24457891781948138\n",
      "          Validation Loss (standardized): 1.2463521268155064\n",
      "Epoch: 91, Loss (standarized): 0.2251551154800908\n",
      "          Validation Loss (standardized): 1.208994612365677\n",
      "Epoch: 96, Loss (standarized): 0.21130155257106015\n",
      "          Validation Loss (standardized): 1.1856118385177001\n",
      "Final epoch: 100, Final loss (standarized): 0.20239175853064392\n",
      "Epoch: 1, Loss (standarized): 1.3134570902706615\n",
      "          Validation Loss (standardized): 1.285213711854033\n",
      "Epoch: 6, Loss (standarized): 0.8557304974675116\n",
      "          Validation Loss (standardized): 1.1728670784597734\n",
      "Epoch: 11, Loss (standarized): 0.716218810666406\n",
      "          Validation Loss (standardized): 1.3909336480406396\n",
      "Epoch: 16, Loss (standarized): 0.68044536893056\n",
      "          Validation Loss (standardized): 1.6007434734481385\n",
      "Epoch: 21, Loss (standarized): 0.6601252557774306\n",
      "          Validation Loss (standardized): 1.717581016382613\n",
      "Epoch: 26, Loss (standarized): 0.6619210987342039\n",
      "          Validation Loss (standardized): 1.7613423286036674\n",
      "Epoch: 31, Loss (standarized): 0.6584508180989285\n",
      "          Validation Loss (standardized): 1.7318117958569612\n",
      "Epoch: 36, Loss (standarized): 0.651275898951038\n",
      "          Validation Loss (standardized): 1.6626072237972194\n",
      "Epoch: 41, Loss (standarized): 0.6502978662651789\n",
      "          Validation Loss (standardized): 1.5990123770289384\n",
      "Epoch: 46, Loss (standarized): 0.6504184828017855\n",
      "          Validation Loss (standardized): 1.5704078000825314\n",
      "Epoch: 51, Loss (standarized): 0.6498813607234157\n",
      "          Validation Loss (standardized): 1.584216807468048\n",
      "Epoch: 56, Loss (standarized): 0.6485846759184769\n",
      "          Validation Loss (standardized): 1.621044100696918\n",
      "Epoch: 61, Loss (standarized): 0.6467069707174307\n",
      "          Validation Loss (standardized): 1.6467800469828437\n",
      "Epoch: 66, Loss (standarized): 0.6458299938884456\n",
      "          Validation Loss (standardized): 1.6434442809851317\n",
      "Epoch: 71, Loss (standarized): 0.6457550268188117\n",
      "          Validation Loss (standardized): 1.6259811462317397\n",
      "Epoch: 76, Loss (standarized): 0.6458745026376488\n",
      "          Validation Loss (standardized): 1.6153495066892067\n",
      "Epoch: 81, Loss (standarized): 0.6454869296025197\n",
      "          Validation Loss (standardized): 1.6200210226577592\n",
      "Epoch: 86, Loss (standarized): 0.6450026422748786\n",
      "          Validation Loss (standardized): 1.6294035880561237\n",
      "Epoch: 91, Loss (standarized): 0.6447660518289194\n",
      "          Validation Loss (standardized): 1.6335558276939628\n",
      "Epoch: 96, Loss (standarized): 0.6446343510960095\n",
      "          Validation Loss (standardized): 1.6322715986551521\n",
      "Final epoch: 100, Final loss (standarized): 0.6444529381683375\n",
      "Epoch: 1, Loss (standarized): 1.1921259570892788\n",
      "          Validation Loss (standardized): 1.1475457343743938\n",
      "Epoch: 6, Loss (standarized): 0.7781680675379178\n",
      "          Validation Loss (standardized): 1.1261772419943932\n",
      "Epoch: 11, Loss (standarized): 0.7064853220472624\n",
      "          Validation Loss (standardized): 1.3937555648949893\n",
      "Epoch: 16, Loss (standarized): 0.6616646182693939\n",
      "          Validation Loss (standardized): 1.666396106932768\n",
      "Epoch: 21, Loss (standarized): 0.6543326241696398\n",
      "          Validation Loss (standardized): 1.8596935322458308\n",
      "Epoch: 26, Loss (standarized): 0.6570385791580503\n",
      "          Validation Loss (standardized): 1.9083789549620394\n",
      "Epoch: 31, Loss (standarized): 0.6521410155042164\n",
      "          Validation Loss (standardized): 1.8677701012401235\n",
      "Epoch: 36, Loss (standarized): 0.6464474781920159\n",
      "          Validation Loss (standardized): 1.7866921538877496\n",
      "Epoch: 41, Loss (standarized): 0.6445261507501975\n",
      "          Validation Loss (standardized): 1.6867356153635547\n",
      "Epoch: 46, Loss (standarized): 0.6431574074300616\n",
      "          Validation Loss (standardized): 1.6212681064019034\n",
      "Epoch: 51, Loss (standarized): 0.6421138485303015\n",
      "          Validation Loss (standardized): 1.6097284625914239\n",
      "Epoch: 56, Loss (standarized): 0.6404639809558823\n",
      "          Validation Loss (standardized): 1.6306829438496466\n",
      "Epoch: 61, Loss (standarized): 0.6383120891815527\n",
      "          Validation Loss (standardized): 1.6657155819514824\n",
      "Epoch: 66, Loss (standarized): 0.6360887297293137\n",
      "          Validation Loss (standardized): 1.691405665405099\n",
      "Epoch: 71, Loss (standarized): 0.6328344315288909\n",
      "          Validation Loss (standardized): 1.6869194301208248\n",
      "Epoch: 76, Loss (standarized): 0.6279656204910938\n",
      "          Validation Loss (standardized): 1.6684164038875182\n",
      "Epoch: 81, Loss (standarized): 0.620095359587774\n",
      "          Validation Loss (standardized): 1.6433569294925128\n",
      "Epoch: 86, Loss (standarized): 0.6073040733418936\n",
      "          Validation Loss (standardized): 1.6109248370182991\n",
      "Epoch: 91, Loss (standarized): 0.5868124761224379\n",
      "          Validation Loss (standardized): 1.56440683355091\n",
      "Epoch: 96, Loss (standarized): 0.5560926117611422\n",
      "          Validation Loss (standardized): 1.5059260705281936\n",
      "Final epoch: 100, Final loss (standarized): 0.5245997965941276\n",
      "Epoch: 1, Loss (standarized): 1.1763764431504826\n",
      "          Validation Loss (standardized): 1.097256699272742\n",
      "Epoch: 6, Loss (standarized): 0.777351559285389\n",
      "          Validation Loss (standardized): 1.2277976343178194\n",
      "Epoch: 11, Loss (standarized): 0.7171933632166451\n",
      "          Validation Loss (standardized): 1.4593007364796813\n",
      "Epoch: 16, Loss (standarized): 0.6629651670100232\n",
      "          Validation Loss (standardized): 1.6625101811363248\n",
      "Epoch: 21, Loss (standarized): 0.6540526074162727\n",
      "          Validation Loss (standardized): 1.8444722187257006\n",
      "Epoch: 26, Loss (standarized): 0.6608425744733122\n",
      "          Validation Loss (standardized): 1.9163727726754551\n",
      "Epoch: 31, Loss (standarized): 0.6507018075390706\n",
      "          Validation Loss (standardized): 1.8683770052280049\n",
      "Epoch: 36, Loss (standarized): 0.6457794902975128\n",
      "          Validation Loss (standardized): 1.7566164374547197\n",
      "Epoch: 41, Loss (standarized): 0.6426316055356788\n",
      "          Validation Loss (standardized): 1.6650459123705037\n",
      "Epoch: 46, Loss (standarized): 0.6378662361557821\n",
      "          Validation Loss (standardized): 1.6224011102934388\n",
      "Epoch: 51, Loss (standarized): 0.6325851549503606\n",
      "          Validation Loss (standardized): 1.6141261376839688\n",
      "Epoch: 56, Loss (standarized): 0.6230972766375038\n",
      "          Validation Loss (standardized): 1.6259706603639088\n",
      "Epoch: 61, Loss (standarized): 0.6068163120449548\n",
      "          Validation Loss (standardized): 1.6268819724983004\n",
      "Epoch: 66, Loss (standarized): 0.5846355751650583\n",
      "          Validation Loss (standardized): 1.611112237001646\n",
      "Epoch: 71, Loss (standarized): 0.5607571020016032\n",
      "          Validation Loss (standardized): 1.6016366603865673\n",
      "Epoch: 76, Loss (standarized): 0.5391902540821963\n",
      "          Validation Loss (standardized): 1.5989777968835543\n",
      "Epoch: 81, Loss (standarized): 0.520680686174307\n",
      "          Validation Loss (standardized): 1.6112454253875248\n",
      "Epoch: 86, Loss (standarized): 0.5045008486113849\n",
      "          Validation Loss (standardized): 1.6205323239200298\n",
      "Epoch: 91, Loss (standarized): 0.48946695557894376\n",
      "          Validation Loss (standardized): 1.6114671012299144\n",
      "Epoch: 96, Loss (standarized): 0.4747816263891576\n",
      "          Validation Loss (standardized): 1.5838088340761074\n",
      "Final epoch: 100, Final loss (standarized): 0.46185423301601974\n",
      "Epoch: 1, Loss (standarized): 1.2314387062513619\n",
      "          Validation Loss (standardized): 1.101739909831739\n",
      "Epoch: 6, Loss (standarized): 0.8017430838168716\n",
      "          Validation Loss (standardized): 1.1142850787899157\n",
      "Epoch: 11, Loss (standarized): 0.7307665166169544\n",
      "          Validation Loss (standardized): 1.2475220414226806\n",
      "Epoch: 16, Loss (standarized): 0.6840255140113711\n",
      "          Validation Loss (standardized): 1.3164524786459098\n",
      "Epoch: 21, Loss (standarized): 0.6690586868190775\n",
      "          Validation Loss (standardized): 1.395276595310312\n",
      "Epoch: 26, Loss (standarized): 0.6687862145739547\n",
      "          Validation Loss (standardized): 1.4539735654355512\n",
      "Epoch: 31, Loss (standarized): 0.6650405785885112\n",
      "          Validation Loss (standardized): 1.4658529340102509\n",
      "Epoch: 36, Loss (standarized): 0.6622105977005686\n",
      "          Validation Loss (standardized): 1.4613039457271775\n",
      "Epoch: 41, Loss (standarized): 0.6624146457603124\n",
      "          Validation Loss (standardized): 1.4563459457796448\n",
      "Epoch: 46, Loss (standarized): 0.6629759133676504\n",
      "          Validation Loss (standardized): 1.4553892222569598\n",
      "Epoch: 51, Loss (standarized): 0.6632533886499902\n",
      "          Validation Loss (standardized): 1.4526073196153775\n",
      "Epoch: 56, Loss (standarized): 0.6643754821852649\n",
      "          Validation Loss (standardized): 1.4529552475041991\n",
      "Epoch: 61, Loss (standarized): 0.6622777519432088\n",
      "          Validation Loss (standardized): 1.472503775226136\n",
      "Epoch: 66, Loss (standarized): 0.6593132593038958\n",
      "          Validation Loss (standardized): 1.4911751189652285\n",
      "Epoch: 71, Loss (standarized): 0.6571857012077217\n",
      "          Validation Loss (standardized): 1.5038037295595417\n",
      "Epoch: 76, Loss (standarized): 0.6554569351828871\n",
      "          Validation Loss (standardized): 1.5053483880785914\n",
      "Epoch: 81, Loss (standarized): 0.6537557538848653\n",
      "          Validation Loss (standardized): 1.5112539134779333\n",
      "Epoch: 86, Loss (standarized): 0.6528884983603699\n",
      "          Validation Loss (standardized): 1.5151176868584362\n",
      "Epoch: 91, Loss (standarized): 0.6519554976442214\n",
      "          Validation Loss (standardized): 1.523744999041394\n",
      "Epoch: 96, Loss (standarized): 0.6511183026159484\n",
      "          Validation Loss (standardized): 1.5277033642326647\n",
      "Final epoch: 100, Final loss (standarized): 0.650276655674823\n",
      "Epoch: 1, Loss (standarized): 1.22034892999228\n",
      "          Validation Loss (standardized): 1.1639168197555032\n",
      "Epoch: 6, Loss (standarized): 0.8140301007368717\n",
      "          Validation Loss (standardized): 1.129596586397886\n",
      "Epoch: 11, Loss (standarized): 0.7388880428840948\n",
      "          Validation Loss (standardized): 1.232278670878822\n",
      "Epoch: 16, Loss (standarized): 0.6934951765036915\n",
      "          Validation Loss (standardized): 1.3010617255716348\n",
      "Epoch: 21, Loss (standarized): 0.6758003338919232\n",
      "          Validation Loss (standardized): 1.3750448651001466\n",
      "Epoch: 26, Loss (standarized): 0.6764817620704735\n",
      "          Validation Loss (standardized): 1.4376997518661514\n",
      "Epoch: 31, Loss (standarized): 0.6751465595701699\n",
      "          Validation Loss (standardized): 1.4714046884219856\n",
      "Epoch: 36, Loss (standarized): 0.6732224341055394\n",
      "          Validation Loss (standardized): 1.470525137192928\n",
      "Epoch: 41, Loss (standarized): 0.6725667905975494\n",
      "          Validation Loss (standardized): 1.4481407823006325\n",
      "Epoch: 46, Loss (standarized): 0.673265401512497\n",
      "          Validation Loss (standardized): 1.4298570995281812\n",
      "Epoch: 51, Loss (standarized): 0.6738053995606942\n",
      "          Validation Loss (standardized): 1.4295615900500318\n",
      "Epoch: 56, Loss (standarized): 0.6732285626167662\n",
      "          Validation Loss (standardized): 1.433568204430379\n",
      "Epoch: 61, Loss (standarized): 0.6722842926376782\n",
      "          Validation Loss (standardized): 1.4372863645447358\n",
      "Epoch: 66, Loss (standarized): 0.6710203045554007\n",
      "          Validation Loss (standardized): 1.4413311798358257\n",
      "Epoch: 71, Loss (standarized): 0.6700141707364148\n",
      "          Validation Loss (standardized): 1.4465952605527375\n",
      "Epoch: 76, Loss (standarized): 0.6684754917018494\n",
      "          Validation Loss (standardized): 1.456643407481265\n",
      "Epoch: 81, Loss (standarized): 0.6675223788214105\n",
      "          Validation Loss (standardized): 1.45679376265148\n",
      "Epoch: 86, Loss (standarized): 0.6670158010798127\n",
      "          Validation Loss (standardized): 1.4678043062773083\n",
      "Epoch: 91, Loss (standarized): 0.6665520608387356\n",
      "          Validation Loss (standardized): 1.4747068172689823\n",
      "Epoch: 96, Loss (standarized): 0.6663242357080879\n",
      "          Validation Loss (standardized): 1.4835466170094123\n",
      "Final epoch: 100, Final loss (standarized): 0.6655360950338833\n",
      "Epoch: 1, Loss (standarized): 1.2091283221582931\n",
      "          Validation Loss (standardized): 1.12681636721819\n",
      "Epoch: 6, Loss (standarized): 0.8513978746614439\n",
      "          Validation Loss (standardized): 1.0983091795503845\n",
      "Epoch: 11, Loss (standarized): 0.7204249512950286\n",
      "          Validation Loss (standardized): 1.231211741328626\n",
      "Epoch: 16, Loss (standarized): 0.675814497853882\n",
      "          Validation Loss (standardized): 1.3733168970213618\n",
      "Epoch: 21, Loss (standarized): 0.6595563079169676\n",
      "          Validation Loss (standardized): 1.4782203742557771\n",
      "Epoch: 26, Loss (standarized): 0.6607216644114876\n",
      "          Validation Loss (standardized): 1.5156865979395087\n",
      "Epoch: 31, Loss (standarized): 0.6639285257871644\n",
      "          Validation Loss (standardized): 1.5074085086739084\n",
      "Epoch: 36, Loss (standarized): 0.6647410763106931\n",
      "          Validation Loss (standardized): 1.48434603429392\n",
      "Epoch: 41, Loss (standarized): 0.6650020157263581\n",
      "          Validation Loss (standardized): 1.459521852399378\n",
      "Epoch: 46, Loss (standarized): 0.6655449298124069\n",
      "          Validation Loss (standardized): 1.433720882489902\n",
      "Epoch: 51, Loss (standarized): 0.6653814564415319\n",
      "          Validation Loss (standardized): 1.4312418190090703\n",
      "Epoch: 56, Loss (standarized): 0.6640095958825786\n",
      "          Validation Loss (standardized): 1.4502552917109595\n",
      "Epoch: 61, Loss (standarized): 0.6634109398982172\n",
      "          Validation Loss (standardized): 1.4572811741219376\n",
      "Epoch: 66, Loss (standarized): 0.6623427809655101\n",
      "          Validation Loss (standardized): 1.4650516194925718\n",
      "Epoch: 71, Loss (standarized): 0.661205766518402\n",
      "          Validation Loss (standardized): 1.4825062627810224\n",
      "Epoch: 76, Loss (standarized): 0.6604091133631104\n",
      "          Validation Loss (standardized): 1.4989069216406903\n",
      "Epoch: 81, Loss (standarized): 0.6595913352206835\n",
      "          Validation Loss (standardized): 1.5069711592859596\n",
      "Epoch: 86, Loss (standarized): 0.6589608904993428\n",
      "          Validation Loss (standardized): 1.507374453978724\n",
      "Epoch: 91, Loss (standarized): 0.6580768649701899\n",
      "          Validation Loss (standardized): 1.512415711181038\n",
      "Epoch: 96, Loss (standarized): 0.6572814551137586\n",
      "          Validation Loss (standardized): 1.5085426945183236\n",
      "Final epoch: 100, Final loss (standarized): 0.65709237991756\n",
      "Epoch: 1, Loss (standarized): 1.2153215001982272\n",
      "          Validation Loss (standardized): 1.098007818050902\n",
      "Epoch: 6, Loss (standarized): 0.7940218857843007\n",
      "          Validation Loss (standardized): 1.16167519039632\n",
      "Epoch: 11, Loss (standarized): 0.7255220594866306\n",
      "          Validation Loss (standardized): 1.3168808286945564\n",
      "Epoch: 16, Loss (standarized): 0.6763969626214668\n",
      "          Validation Loss (standardized): 1.394615701965641\n",
      "Epoch: 21, Loss (standarized): 0.6657258492801224\n",
      "          Validation Loss (standardized): 1.471533211954232\n",
      "Epoch: 26, Loss (standarized): 0.6687573612425777\n",
      "          Validation Loss (standardized): 1.5184836118770788\n",
      "Epoch: 31, Loss (standarized): 0.666425992229585\n",
      "          Validation Loss (standardized): 1.515567043895192\n",
      "Epoch: 36, Loss (standarized): 0.664388748679619\n",
      "          Validation Loss (standardized): 1.4936026489159162\n",
      "Epoch: 41, Loss (standarized): 0.6641363045340176\n",
      "          Validation Loss (standardized): 1.4705209076787622\n",
      "Epoch: 46, Loss (standarized): 0.6651789888815088\n",
      "          Validation Loss (standardized): 1.4670094703451793\n",
      "Epoch: 51, Loss (standarized): 0.6656137833728707\n",
      "          Validation Loss (standardized): 1.4584128840868666\n",
      "Epoch: 56, Loss (standarized): 0.6657968782801523\n",
      "          Validation Loss (standardized): 1.4574503158718353\n",
      "Epoch: 61, Loss (standarized): 0.6663787536843714\n",
      "          Validation Loss (standardized): 1.466393536881743\n",
      "Epoch: 66, Loss (standarized): 0.6652528746549405\n",
      "          Validation Loss (standardized): 1.4765039917974427\n",
      "Epoch: 71, Loss (standarized): 0.6645672981679905\n",
      "          Validation Loss (standardized): 1.4724215837474928\n",
      "Epoch: 76, Loss (standarized): 0.6653717015277576\n",
      "          Validation Loss (standardized): 1.4678940034053616\n",
      "Epoch: 81, Loss (standarized): 0.6647900367781094\n",
      "          Validation Loss (standardized): 1.4885516801165966\n",
      "Epoch: 86, Loss (standarized): 0.664184302566766\n",
      "          Validation Loss (standardized): 1.4954688638846434\n",
      "Epoch: 91, Loss (standarized): 0.6641213633028658\n",
      "          Validation Loss (standardized): 1.4909724045813624\n",
      "Epoch: 96, Loss (standarized): 0.6641779820859525\n",
      "          Validation Loss (standardized): 1.4938059521322673\n",
      "Final epoch: 100, Final loss (standarized): 0.6639399034733382\n",
      "Epoch: 1, Loss (standarized): 1.0643234492105302\n",
      "          Validation Loss (standardized): 1.0469441611673715\n",
      "Epoch: 6, Loss (standarized): 0.761861674788832\n",
      "          Validation Loss (standardized): 1.28995811960661\n",
      "Epoch: 11, Loss (standarized): 0.692193878749981\n",
      "          Validation Loss (standardized): 1.5458971929937289\n",
      "Epoch: 16, Loss (standarized): 0.6530704364175998\n",
      "          Validation Loss (standardized): 1.7436627138056404\n",
      "Epoch: 21, Loss (standarized): 0.6606527978105159\n",
      "          Validation Loss (standardized): 1.8808857139696746\n",
      "Epoch: 26, Loss (standarized): 0.6565587920142032\n",
      "          Validation Loss (standardized): 1.856162442639925\n",
      "Epoch: 31, Loss (standarized): 0.6470842942120041\n",
      "          Validation Loss (standardized): 1.7295750352062351\n",
      "Epoch: 36, Loss (standarized): 0.6467339140519555\n",
      "          Validation Loss (standardized): 1.6297991793398883\n",
      "Epoch: 41, Loss (standarized): 0.6461599553058307\n",
      "          Validation Loss (standardized): 1.5842715444447215\n",
      "Epoch: 46, Loss (standarized): 0.645242097007211\n",
      "          Validation Loss (standardized): 1.5949571203258652\n",
      "Epoch: 51, Loss (standarized): 0.6436745978677485\n",
      "          Validation Loss (standardized): 1.6443688319644627\n",
      "Epoch: 56, Loss (standarized): 0.6419503998955657\n",
      "          Validation Loss (standardized): 1.6595034099011257\n",
      "Epoch: 61, Loss (standarized): 0.6403386282703853\n",
      "          Validation Loss (standardized): 1.6384157595185949\n",
      "Epoch: 66, Loss (standarized): 0.6379936204119633\n",
      "          Validation Loss (standardized): 1.6211673878519257\n",
      "Epoch: 71, Loss (standarized): 0.6338166641540625\n",
      "          Validation Loss (standardized): 1.6210841553616482\n",
      "Epoch: 76, Loss (standarized): 0.6266731627897018\n",
      "          Validation Loss (standardized): 1.6109217519840473\n",
      "Epoch: 81, Loss (standarized): 0.6147316310574419\n",
      "          Validation Loss (standardized): 1.585428509583522\n",
      "Epoch: 86, Loss (standarized): 0.594813857481255\n",
      "          Validation Loss (standardized): 1.5514784519726623\n",
      "Epoch: 91, Loss (standarized): 0.5643837943537198\n",
      "          Validation Loss (standardized): 1.507277735442236\n",
      "Epoch: 96, Loss (standarized): 0.5252642604467701\n",
      "          Validation Loss (standardized): 1.460083155972843\n",
      "Final epoch: 100, Final loss (standarized): 0.4927808995797402\n",
      "Epoch: 1, Loss (standarized): 1.0602515773087176\n",
      "          Validation Loss (standardized): 1.040332665992193\n",
      "Epoch: 6, Loss (standarized): 0.7888383196129162\n",
      "          Validation Loss (standardized): 1.1964906661374695\n",
      "Epoch: 11, Loss (standarized): 0.7127253825329092\n",
      "          Validation Loss (standardized): 1.3941357512895072\n",
      "Epoch: 16, Loss (standarized): 0.663198484539839\n",
      "          Validation Loss (standardized): 1.5549434867384175\n",
      "Epoch: 21, Loss (standarized): 0.6597857391247766\n",
      "          Validation Loss (standardized): 1.675837001940247\n",
      "Epoch: 26, Loss (standarized): 0.6580374354149184\n",
      "          Validation Loss (standardized): 1.7099270791576586\n",
      "Epoch: 31, Loss (standarized): 0.6517944653472632\n",
      "          Validation Loss (standardized): 1.6483652452227135\n",
      "Epoch: 36, Loss (standarized): 0.6509036615820765\n",
      "          Validation Loss (standardized): 1.5619520107131066\n",
      "Epoch: 41, Loss (standarized): 0.6520334487148488\n",
      "          Validation Loss (standardized): 1.532391401175671\n",
      "Epoch: 46, Loss (standarized): 0.6518569098396302\n",
      "          Validation Loss (standardized): 1.5495958002781067\n",
      "Epoch: 51, Loss (standarized): 0.6503920493940403\n",
      "          Validation Loss (standardized): 1.5818983713526433\n",
      "Epoch: 56, Loss (standarized): 0.6484924107270268\n",
      "          Validation Loss (standardized): 1.6044539679178407\n",
      "Epoch: 61, Loss (standarized): 0.6475955320541207\n",
      "          Validation Loss (standardized): 1.597757010636647\n",
      "Epoch: 66, Loss (standarized): 0.6477198156784276\n",
      "          Validation Loss (standardized): 1.590730747804158\n",
      "Epoch: 71, Loss (standarized): 0.6479409760892437\n",
      "          Validation Loss (standardized): 1.5871274980662635\n",
      "Epoch: 76, Loss (standarized): 0.647545885963029\n",
      "          Validation Loss (standardized): 1.590191990969165\n",
      "Epoch: 81, Loss (standarized): 0.6469882737086006\n",
      "          Validation Loss (standardized): 1.6004188969330775\n",
      "Epoch: 86, Loss (standarized): 0.646607256524843\n",
      "          Validation Loss (standardized): 1.6044037160581897\n",
      "Epoch: 91, Loss (standarized): 0.6465080447523424\n",
      "          Validation Loss (standardized): 1.6042027102894754\n",
      "Epoch: 96, Loss (standarized): 0.6464352606725815\n",
      "          Validation Loss (standardized): 1.6046296031415959\n",
      "Final epoch: 100, Final loss (standarized): 0.6463156498034739\n",
      "Epoch: 1, Loss (standarized): 1.1031085622697814\n",
      "          Validation Loss (standardized): 1.053987998633882\n",
      "Epoch: 6, Loss (standarized): 0.8331922720235908\n",
      "          Validation Loss (standardized): 1.0778579589610635\n",
      "Epoch: 11, Loss (standarized): 0.7384626701529672\n",
      "          Validation Loss (standardized): 1.2698478281832135\n",
      "Epoch: 16, Loss (standarized): 0.6687275456404151\n",
      "          Validation Loss (standardized): 1.532445214215366\n",
      "Epoch: 21, Loss (standarized): 0.6553347345252537\n",
      "          Validation Loss (standardized): 1.7776983102785204\n",
      "Epoch: 26, Loss (standarized): 0.6520042855812574\n",
      "          Validation Loss (standardized): 1.8478527474145383\n",
      "Epoch: 31, Loss (standarized): 0.6369747888869586\n",
      "          Validation Loss (standardized): 1.7851338374851589\n",
      "Epoch: 36, Loss (standarized): 0.6238759442277753\n",
      "          Validation Loss (standardized): 1.649490881302886\n",
      "Epoch: 41, Loss (standarized): 0.6102884910469052\n",
      "          Validation Loss (standardized): 1.5353388888838049\n",
      "Epoch: 46, Loss (standarized): 0.5970194870411316\n",
      "          Validation Loss (standardized): 1.509024300522459\n",
      "Epoch: 51, Loss (standarized): 0.5799589205459373\n",
      "          Validation Loss (standardized): 1.5318947214387963\n",
      "Epoch: 56, Loss (standarized): 0.5633032956407803\n",
      "          Validation Loss (standardized): 1.5570042423000519\n",
      "Epoch: 61, Loss (standarized): 0.5465932608242006\n",
      "          Validation Loss (standardized): 1.5478737455801082\n",
      "Epoch: 66, Loss (standarized): 0.5296143727242848\n",
      "          Validation Loss (standardized): 1.533562387072864\n",
      "Epoch: 71, Loss (standarized): 0.511206202601489\n",
      "          Validation Loss (standardized): 1.5197626727899578\n",
      "Epoch: 76, Loss (standarized): 0.49090643958753455\n",
      "          Validation Loss (standardized): 1.5011366571960767\n",
      "Epoch: 81, Loss (standarized): 0.46816828497460494\n",
      "          Validation Loss (standardized): 1.4840455573337243\n",
      "Epoch: 86, Loss (standarized): 0.44355107228776774\n",
      "          Validation Loss (standardized): 1.4534657730101517\n",
      "Epoch: 91, Loss (standarized): 0.41671864195977537\n",
      "          Validation Loss (standardized): 1.4294069032286083\n",
      "Epoch: 96, Loss (standarized): 0.3852926252711862\n",
      "          Validation Loss (standardized): 1.4098007170952163\n",
      "Final epoch: 100, Final loss (standarized): 0.3566524142523536\n",
      "Epoch: 1, Loss (standarized): 1.1374908129726629\n",
      "          Validation Loss (standardized): 1.1128867881409923\n",
      "Epoch: 6, Loss (standarized): 0.7993965575552436\n",
      "          Validation Loss (standardized): 1.1699425495218743\n",
      "Epoch: 11, Loss (standarized): 0.7107768920222038\n",
      "          Validation Loss (standardized): 1.3655912573355358\n",
      "Epoch: 16, Loss (standarized): 0.6561503089242767\n",
      "          Validation Loss (standardized): 1.579316231220556\n",
      "Epoch: 21, Loss (standarized): 0.6457667885659445\n",
      "          Validation Loss (standardized): 1.776119801175229\n",
      "Epoch: 26, Loss (standarized): 0.6393298290508633\n",
      "          Validation Loss (standardized): 1.876991683703316\n",
      "Epoch: 31, Loss (standarized): 0.6242637783072974\n",
      "          Validation Loss (standardized): 1.8351351611559716\n",
      "Epoch: 36, Loss (standarized): 0.6062596521571505\n",
      "          Validation Loss (standardized): 1.6950325620615558\n",
      "Epoch: 41, Loss (standarized): 0.5858382871449062\n",
      "          Validation Loss (standardized): 1.5705351242507073\n",
      "Epoch: 46, Loss (standarized): 0.565705462938342\n",
      "          Validation Loss (standardized): 1.5070585833332393\n",
      "Epoch: 51, Loss (standarized): 0.5431022731910035\n",
      "          Validation Loss (standardized): 1.5210562766684557\n",
      "Epoch: 56, Loss (standarized): 0.5215736981019472\n",
      "          Validation Loss (standardized): 1.541128539914552\n",
      "Epoch: 61, Loss (standarized): 0.5039443280662637\n",
      "          Validation Loss (standardized): 1.5515307162164336\n",
      "Epoch: 66, Loss (standarized): 0.4898646005488676\n",
      "          Validation Loss (standardized): 1.5606353928657561\n",
      "Epoch: 71, Loss (standarized): 0.47907931041389423\n",
      "          Validation Loss (standardized): 1.5438533776908234\n",
      "Epoch: 76, Loss (standarized): 0.4696568862981488\n",
      "          Validation Loss (standardized): 1.5336550320834017\n",
      "Epoch: 81, Loss (standarized): 0.4602444151830973\n",
      "          Validation Loss (standardized): 1.519307631161245\n",
      "Epoch: 86, Loss (standarized): 0.45039921478916384\n",
      "          Validation Loss (standardized): 1.5020280931108407\n",
      "Epoch: 91, Loss (standarized): 0.44046677867834994\n",
      "          Validation Loss (standardized): 1.4825647272757339\n",
      "Epoch: 96, Loss (standarized): 0.4303924822701261\n",
      "          Validation Loss (standardized): 1.470909207979675\n",
      "Final epoch: 100, Final loss (standarized): 0.4216942328251283\n",
      "Epoch: 1, Loss (standarized): 1.097724457049648\n",
      "          Validation Loss (standardized): 1.063255194423861\n",
      "Epoch: 6, Loss (standarized): 0.7670601009034583\n",
      "          Validation Loss (standardized): 1.1510653141747798\n",
      "Epoch: 11, Loss (standarized): 0.6953164925350828\n",
      "          Validation Loss (standardized): 1.4888920143629678\n",
      "Epoch: 16, Loss (standarized): 0.6567788237322153\n",
      "          Validation Loss (standardized): 1.7659590960402207\n",
      "Epoch: 21, Loss (standarized): 0.6538103714273837\n",
      "          Validation Loss (standardized): 1.9218521179833437\n",
      "Epoch: 26, Loss (standarized): 0.6563272916418417\n",
      "          Validation Loss (standardized): 1.9296645584124998\n",
      "Epoch: 31, Loss (standarized): 0.644218834466512\n",
      "          Validation Loss (standardized): 1.8279686282602552\n",
      "Epoch: 36, Loss (standarized): 0.6371226092932973\n",
      "          Validation Loss (standardized): 1.694327127698915\n",
      "Epoch: 41, Loss (standarized): 0.6293923618071612\n",
      "          Validation Loss (standardized): 1.5881751244595672\n",
      "Epoch: 46, Loss (standarized): 0.6179066932628112\n",
      "          Validation Loss (standardized): 1.5241901454344169\n",
      "Epoch: 51, Loss (standarized): 0.5981735575916143\n",
      "          Validation Loss (standardized): 1.5176333366663903\n",
      "Epoch: 56, Loss (standarized): 0.569093324185719\n",
      "          Validation Loss (standardized): 1.5437818793714964\n",
      "Epoch: 61, Loss (standarized): 0.5366754125623192\n",
      "          Validation Loss (standardized): 1.537973602894799\n",
      "Epoch: 66, Loss (standarized): 0.5048141733385885\n",
      "          Validation Loss (standardized): 1.5223951493437826\n",
      "Epoch: 71, Loss (standarized): 0.47249765724017306\n",
      "          Validation Loss (standardized): 1.4970619157191987\n",
      "Epoch: 76, Loss (standarized): 0.4368952676510497\n",
      "          Validation Loss (standardized): 1.4346401651625629\n",
      "Epoch: 81, Loss (standarized): 0.39725542670512126\n",
      "          Validation Loss (standardized): 1.3728719037104729\n",
      "Epoch: 86, Loss (standarized): 0.353984208963621\n",
      "          Validation Loss (standardized): 1.2964552384452257\n",
      "Epoch: 91, Loss (standarized): 0.3105726062737104\n",
      "          Validation Loss (standardized): 1.2452902353563344\n",
      "Epoch: 96, Loss (standarized): 0.272895795323541\n",
      "          Validation Loss (standardized): 1.2215512964961646\n",
      "Final epoch: 100, Final loss (standarized): 0.24755265789728487\n",
      "Epoch: 1, Loss (standarized): 1.2000980230643448\n",
      "          Validation Loss (standardized): 1.1215300773518628\n",
      "Epoch: 6, Loss (standarized): 0.778527822448056\n",
      "          Validation Loss (standardized): 1.1416095357654696\n",
      "Epoch: 11, Loss (standarized): 0.7013886182603819\n",
      "          Validation Loss (standardized): 1.3976054099193989\n",
      "Epoch: 16, Loss (standarized): 0.6610542773065566\n",
      "          Validation Loss (standardized): 1.6177651660478607\n",
      "Epoch: 21, Loss (standarized): 0.6527718971631189\n",
      "          Validation Loss (standardized): 1.7429246246372827\n",
      "Epoch: 26, Loss (standarized): 0.6527537438736107\n",
      "          Validation Loss (standardized): 1.7407557243024558\n",
      "Epoch: 31, Loss (standarized): 0.6492549210935048\n",
      "          Validation Loss (standardized): 1.691319281391933\n",
      "Epoch: 36, Loss (standarized): 0.6451451704594808\n",
      "          Validation Loss (standardized): 1.635812855212711\n",
      "Epoch: 41, Loss (standarized): 0.6444596880534588\n",
      "          Validation Loss (standardized): 1.5686486169270168\n",
      "Epoch: 46, Loss (standarized): 0.6437020512855736\n",
      "          Validation Loss (standardized): 1.5411981147714808\n",
      "Epoch: 51, Loss (standarized): 0.6417054850559044\n",
      "          Validation Loss (standardized): 1.562463508430308\n",
      "Epoch: 56, Loss (standarized): 0.6384436280464696\n",
      "          Validation Loss (standardized): 1.5909271450772775\n",
      "Epoch: 61, Loss (standarized): 0.6345004968769411\n",
      "          Validation Loss (standardized): 1.615716624677661\n",
      "Epoch: 66, Loss (standarized): 0.6301354547363062\n",
      "          Validation Loss (standardized): 1.6085324974411301\n",
      "Epoch: 71, Loss (standarized): 0.6241939499754324\n",
      "          Validation Loss (standardized): 1.5744877786892773\n",
      "Epoch: 76, Loss (standarized): 0.6154854136044232\n",
      "          Validation Loss (standardized): 1.5511734596619886\n",
      "Epoch: 81, Loss (standarized): 0.6023236796608884\n",
      "          Validation Loss (standardized): 1.5328994365537363\n",
      "Epoch: 86, Loss (standarized): 0.584279152284468\n",
      "          Validation Loss (standardized): 1.516335947416142\n",
      "Epoch: 91, Loss (standarized): 0.5610261673849614\n",
      "          Validation Loss (standardized): 1.4886060654052422\n",
      "Epoch: 96, Loss (standarized): 0.5332832260595678\n",
      "          Validation Loss (standardized): 1.462051479913046\n",
      "Final epoch: 100, Final loss (standarized): 0.5097052047895769\n",
      "Epoch: 1, Loss (standarized): 1.2548555307921296\n",
      "          Validation Loss (standardized): 1.2127984380976913\n",
      "Epoch: 6, Loss (standarized): 0.8152866586593858\n",
      "          Validation Loss (standardized): 1.1129551471371273\n",
      "Epoch: 11, Loss (standarized): 0.7125858342663657\n",
      "          Validation Loss (standardized): 1.33796440447667\n",
      "Epoch: 16, Loss (standarized): 0.6730936057783875\n",
      "          Validation Loss (standardized): 1.609170607024976\n",
      "Epoch: 21, Loss (standarized): 0.6551927957377198\n",
      "          Validation Loss (standardized): 1.8065540763241692\n",
      "Epoch: 26, Loss (standarized): 0.654175962127324\n",
      "          Validation Loss (standardized): 1.8894250445860308\n",
      "Epoch: 31, Loss (standarized): 0.6510038967038043\n",
      "          Validation Loss (standardized): 1.8914346606570631\n",
      "Epoch: 36, Loss (standarized): 0.6420987211229662\n",
      "          Validation Loss (standardized): 1.8090157019338626\n",
      "Epoch: 41, Loss (standarized): 0.6364109634644306\n",
      "          Validation Loss (standardized): 1.7066654526560472\n",
      "Epoch: 46, Loss (standarized): 0.6299175208163169\n",
      "          Validation Loss (standardized): 1.6299087497719662\n",
      "Epoch: 51, Loss (standarized): 0.621776054035268\n",
      "          Validation Loss (standardized): 1.5688047478550324\n",
      "Epoch: 56, Loss (standarized): 0.6111040686219271\n",
      "          Validation Loss (standardized): 1.5521054576442874\n",
      "Epoch: 61, Loss (standarized): 0.5958696726874516\n",
      "          Validation Loss (standardized): 1.5605167692427322\n",
      "Epoch: 66, Loss (standarized): 0.5767886064435168\n",
      "          Validation Loss (standardized): 1.5624927626714262\n",
      "Epoch: 71, Loss (standarized): 0.553381424287733\n",
      "          Validation Loss (standardized): 1.5433529090579192\n",
      "Epoch: 76, Loss (standarized): 0.525723540702304\n",
      "          Validation Loss (standardized): 1.5147329007473314\n",
      "Epoch: 81, Loss (standarized): 0.4923117060639058\n",
      "          Validation Loss (standardized): 1.4841295375153218\n",
      "Epoch: 86, Loss (standarized): 0.4512035738676786\n",
      "          Validation Loss (standardized): 1.4450170256157266\n",
      "Epoch: 91, Loss (standarized): 0.403017078016928\n",
      "          Validation Loss (standardized): 1.4035346545597167\n",
      "Epoch: 96, Loss (standarized): 0.35591451220265813\n",
      "          Validation Loss (standardized): 1.363888425904342\n",
      "Final epoch: 100, Final loss (standarized): 0.3225439097846304\n",
      "Epoch: 1, Loss (standarized): 1.1538212266980659\n",
      "          Validation Loss (standardized): 1.090091476784682\n",
      "Epoch: 6, Loss (standarized): 0.8017939957850788\n",
      "          Validation Loss (standardized): 1.1902466504895972\n",
      "Epoch: 11, Loss (standarized): 0.7371681876016606\n",
      "          Validation Loss (standardized): 1.3825935163010803\n",
      "Epoch: 16, Loss (standarized): 0.6626707548786444\n",
      "          Validation Loss (standardized): 1.539988108304029\n",
      "Epoch: 21, Loss (standarized): 0.6482820875794053\n",
      "          Validation Loss (standardized): 1.7475139972647862\n",
      "Epoch: 26, Loss (standarized): 0.6517743661427187\n",
      "          Validation Loss (standardized): 1.8958130985431048\n",
      "Epoch: 31, Loss (standarized): 0.6404533898969701\n",
      "          Validation Loss (standardized): 1.8966809065582015\n",
      "Epoch: 36, Loss (standarized): 0.6326180620788143\n",
      "          Validation Loss (standardized): 1.8034005797994173\n",
      "Epoch: 41, Loss (standarized): 0.6183523788562862\n",
      "          Validation Loss (standardized): 1.6742294089229435\n",
      "Epoch: 46, Loss (standarized): 0.6009392690422538\n",
      "          Validation Loss (standardized): 1.5546860967701006\n",
      "Epoch: 51, Loss (standarized): 0.5782407387425156\n",
      "          Validation Loss (standardized): 1.5077496586747723\n",
      "Epoch: 56, Loss (standarized): 0.547034429712357\n",
      "          Validation Loss (standardized): 1.4981027730071992\n",
      "Epoch: 61, Loss (standarized): 0.5124904361790876\n",
      "          Validation Loss (standardized): 1.48711352276725\n",
      "Epoch: 66, Loss (standarized): 0.47863779453462163\n",
      "          Validation Loss (standardized): 1.4758871877387614\n",
      "Epoch: 71, Loss (standarized): 0.44501888862564487\n",
      "          Validation Loss (standardized): 1.4752926116012444\n",
      "Epoch: 76, Loss (standarized): 0.4100600858980703\n",
      "          Validation Loss (standardized): 1.4388652204946004\n",
      "Epoch: 81, Loss (standarized): 0.37148456983610606\n",
      "          Validation Loss (standardized): 1.3971480859697192\n",
      "Epoch: 86, Loss (standarized): 0.33005196161856765\n",
      "          Validation Loss (standardized): 1.336323630005449\n",
      "Epoch: 91, Loss (standarized): 0.2926312478264038\n",
      "          Validation Loss (standardized): 1.2975273520845312\n",
      "Epoch: 96, Loss (standarized): 0.262265957797005\n",
      "          Validation Loss (standardized): 1.2522282472859687\n",
      "Final epoch: 100, Final loss (standarized): 0.24243425478953531\n",
      "Epoch: 1, Loss (standarized): 1.1334478290199292\n",
      "Epoch: 6, Loss (standarized): 0.7378121505655895\n",
      "Epoch: 11, Loss (standarized): 0.6874342514048654\n",
      "Epoch: 16, Loss (standarized): 0.6459226082501786\n",
      "Epoch: 21, Loss (standarized): 0.6055765397067472\n",
      "Epoch: 26, Loss (standarized): 0.5805188870664351\n",
      "Epoch: 31, Loss (standarized): 0.5487059223866725\n",
      "Epoch: 36, Loss (standarized): 0.516057755843763\n",
      "Epoch: 41, Loss (standarized): 0.4830208405759059\n",
      "Epoch: 46, Loss (standarized): 0.4433683670300726\n",
      "Epoch: 51, Loss (standarized): 0.398241226573953\n",
      "Epoch: 56, Loss (standarized): 0.3497108432332144\n",
      "Epoch: 61, Loss (standarized): 0.30598353078651297\n",
      "Epoch: 66, Loss (standarized): 0.2658915917742715\n",
      "Epoch: 71, Loss (standarized): 0.2346627382981984\n",
      "Epoch: 76, Loss (standarized): 0.2087490996000104\n",
      "Epoch: 81, Loss (standarized): 0.18859181865894709\n",
      "Epoch: 86, Loss (standarized): 0.1723330803581562\n",
      "Epoch: 91, Loss (standarized): 0.15859754461310738\n",
      "Epoch: 96, Loss (standarized): 0.14701874891937353\n",
      "Final epoch: 100, Final loss (standarized): 0.13899128659771637\n",
      "Epoch: 1, Loss (standarized): 1.9268138489077222\n",
      "Epoch: 6, Loss (standarized): 0.911476761156434\n",
      "Epoch: 11, Loss (standarized): 0.7621871127745657\n",
      "Epoch: 16, Loss (standarized): 0.6981703821730069\n",
      "Epoch: 21, Loss (standarized): 0.6487590301039401\n",
      "Epoch: 26, Loss (standarized): 0.6282236036878266\n",
      "Epoch: 31, Loss (standarized): 0.6029982188236472\n",
      "Epoch: 36, Loss (standarized): 0.5748359107811575\n",
      "Epoch: 41, Loss (standarized): 0.5536887351586612\n",
      "Epoch: 46, Loss (standarized): 0.5331112584458707\n",
      "Epoch: 51, Loss (standarized): 0.5118805184924525\n",
      "Epoch: 56, Loss (standarized): 0.48935758406490026\n",
      "Epoch: 61, Loss (standarized): 0.4657671128543191\n",
      "Epoch: 66, Loss (standarized): 0.44047227092099356\n",
      "Epoch: 71, Loss (standarized): 0.41384924673248896\n",
      "Epoch: 76, Loss (standarized): 0.3876742663784605\n",
      "Epoch: 81, Loss (standarized): 0.3630405593605538\n",
      "Epoch: 86, Loss (standarized): 0.33970889296753887\n",
      "Epoch: 91, Loss (standarized): 0.31824691978651276\n",
      "Epoch: 96, Loss (standarized): 0.29950336877281064\n",
      "Final epoch: 100, Final loss (standarized): 0.2863989822811657\n",
      "Epoch: 1, Loss (standarized): 1.014689538914955\n",
      "Epoch: 6, Loss (standarized): 0.7183522794256878\n",
      "Epoch: 11, Loss (standarized): 0.68175320060757\n",
      "Epoch: 16, Loss (standarized): 0.6334798826256105\n",
      "Epoch: 21, Loss (standarized): 0.619497627243017\n",
      "Epoch: 26, Loss (standarized): 0.5875646621724366\n",
      "Epoch: 31, Loss (standarized): 0.562295272530121\n",
      "Epoch: 36, Loss (standarized): 0.527085377985196\n",
      "Epoch: 41, Loss (standarized): 0.48752639005966786\n",
      "Epoch: 46, Loss (standarized): 0.439327106304215\n",
      "Epoch: 51, Loss (standarized): 0.38563499847725813\n",
      "Epoch: 56, Loss (standarized): 0.3303185962317481\n",
      "Epoch: 61, Loss (standarized): 0.2774096920968744\n",
      "Epoch: 66, Loss (standarized): 0.23366220983378957\n",
      "Epoch: 71, Loss (standarized): 0.1999834794619922\n",
      "Epoch: 76, Loss (standarized): 0.17458704367980166\n",
      "Epoch: 81, Loss (standarized): 0.1551312613612882\n",
      "Epoch: 86, Loss (standarized): 0.14017257183650975\n",
      "Epoch: 91, Loss (standarized): 0.1287134305896307\n",
      "Epoch: 96, Loss (standarized): 0.11975799377718631\n",
      "Final epoch: 100, Final loss (standarized): 0.11390921272110707\n",
      "Epoch: 1, Loss (standarized): 1.1707166320441726\n",
      "Epoch: 6, Loss (standarized): 0.6742621522024798\n",
      "Epoch: 11, Loss (standarized): 0.6627087098267744\n",
      "Epoch: 16, Loss (standarized): 0.6276991993326596\n",
      "Epoch: 21, Loss (standarized): 0.59003617229556\n",
      "Epoch: 26, Loss (standarized): 0.5369105368435804\n",
      "Epoch: 31, Loss (standarized): 0.4832566519734376\n",
      "Epoch: 36, Loss (standarized): 0.4260343793579167\n",
      "Epoch: 41, Loss (standarized): 0.37107781958410885\n",
      "Epoch: 46, Loss (standarized): 0.32328382876302214\n",
      "Epoch: 51, Loss (standarized): 0.2841954077983287\n",
      "Epoch: 56, Loss (standarized): 0.25456868546577366\n",
      "Epoch: 61, Loss (standarized): 0.23131483512413611\n",
      "Epoch: 66, Loss (standarized): 0.21255968528130345\n",
      "Epoch: 71, Loss (standarized): 0.19688892042370199\n",
      "Epoch: 76, Loss (standarized): 0.183449793892631\n",
      "Epoch: 81, Loss (standarized): 0.1713204388687364\n",
      "Epoch: 86, Loss (standarized): 0.16002689082904423\n",
      "Epoch: 91, Loss (standarized): 0.14966601394732407\n",
      "Epoch: 96, Loss (standarized): 0.14033668129445642\n",
      "Final epoch: 100, Final loss (standarized): 0.13336541631047943\n",
      "Epoch: 1, Loss (standarized): 1.1399266237159784\n",
      "Epoch: 6, Loss (standarized): 0.723713032840361\n",
      "Epoch: 11, Loss (standarized): 0.6550500863025043\n",
      "Epoch: 16, Loss (standarized): 0.642322996301635\n",
      "Epoch: 21, Loss (standarized): 0.6262738005188585\n",
      "Epoch: 26, Loss (standarized): 0.6112483304116466\n",
      "Epoch: 31, Loss (standarized): 0.5997106082928247\n",
      "Epoch: 36, Loss (standarized): 0.5911388821683647\n",
      "Epoch: 41, Loss (standarized): 0.5813709659570303\n",
      "Epoch: 46, Loss (standarized): 0.5701549997819841\n",
      "Epoch: 51, Loss (standarized): 0.561386844722892\n",
      "Epoch: 56, Loss (standarized): 0.5518373773118984\n",
      "Epoch: 61, Loss (standarized): 0.5438874958704072\n",
      "Epoch: 66, Loss (standarized): 0.5378638186445044\n",
      "Epoch: 71, Loss (standarized): 0.5316764707948144\n",
      "Epoch: 76, Loss (standarized): 0.5257807307829578\n",
      "Epoch: 81, Loss (standarized): 0.5207200983330273\n",
      "Epoch: 86, Loss (standarized): 0.5152562999016331\n",
      "Epoch: 91, Loss (standarized): 0.509345289442184\n",
      "Epoch: 96, Loss (standarized): 0.5034060871221884\n",
      "Final epoch: 100, Final loss (standarized): 0.4985448015546878\n",
      "Epoch: 1, Loss (standarized): 2.6233088056340415\n",
      "Epoch: 6, Loss (standarized): 1.1226924700240088\n",
      "Epoch: 11, Loss (standarized): 0.7530735513028948\n",
      "Epoch: 16, Loss (standarized): 0.7093883513129433\n",
      "Epoch: 21, Loss (standarized): 0.6598977670834527\n",
      "Epoch: 26, Loss (standarized): 0.6406184556035536\n",
      "Epoch: 31, Loss (standarized): 0.6379597139291926\n",
      "Epoch: 36, Loss (standarized): 0.6261825230339405\n",
      "Epoch: 41, Loss (standarized): 0.6183811556637097\n",
      "Epoch: 46, Loss (standarized): 0.6125102794308662\n",
      "Epoch: 51, Loss (standarized): 0.6079860178072681\n",
      "Epoch: 56, Loss (standarized): 0.6029945684497083\n",
      "Epoch: 61, Loss (standarized): 0.5989146172236977\n",
      "Epoch: 66, Loss (standarized): 0.5937404548759937\n",
      "Epoch: 71, Loss (standarized): 0.5888935939870826\n",
      "Epoch: 76, Loss (standarized): 0.5839833646619057\n",
      "Epoch: 81, Loss (standarized): 0.578685335651107\n",
      "Epoch: 86, Loss (standarized): 0.5732731013668645\n",
      "Epoch: 91, Loss (standarized): 0.5681903154914921\n",
      "Epoch: 96, Loss (standarized): 0.5639097426048101\n",
      "Final epoch: 100, Final loss (standarized): 0.5607803050488921\n",
      "Epoch: 1, Loss (standarized): 1.571976061468655\n",
      "Epoch: 6, Loss (standarized): 0.7693048870551917\n",
      "Epoch: 11, Loss (standarized): 0.6996881287288277\n",
      "Epoch: 16, Loss (standarized): 0.6522398743347632\n",
      "Epoch: 21, Loss (standarized): 0.6364920918700154\n",
      "Epoch: 26, Loss (standarized): 0.6278033462014453\n",
      "Epoch: 31, Loss (standarized): 0.6138204694887549\n",
      "Epoch: 36, Loss (standarized): 0.6032593784153873\n",
      "Epoch: 41, Loss (standarized): 0.5881169119163016\n",
      "Epoch: 46, Loss (standarized): 0.5753815406933532\n",
      "Epoch: 51, Loss (standarized): 0.5625473639067446\n",
      "Epoch: 56, Loss (standarized): 0.5523256561709281\n",
      "Epoch: 61, Loss (standarized): 0.5434466248467277\n",
      "Epoch: 66, Loss (standarized): 0.5337583807471538\n",
      "Epoch: 71, Loss (standarized): 0.5248500229153984\n",
      "Epoch: 76, Loss (standarized): 0.5169907598691709\n",
      "Epoch: 81, Loss (standarized): 0.5095489112687377\n",
      "Epoch: 86, Loss (standarized): 0.5022881790014413\n",
      "Epoch: 91, Loss (standarized): 0.495391097216863\n",
      "Epoch: 96, Loss (standarized): 0.48975131743983896\n",
      "Final epoch: 100, Final loss (standarized): 0.4865527659917555\n",
      "Epoch: 1, Loss (standarized): 1.697396942944815\n",
      "Epoch: 6, Loss (standarized): 0.8277635308881581\n",
      "Epoch: 11, Loss (standarized): 0.7358419914061692\n",
      "Epoch: 16, Loss (standarized): 0.7040550529938971\n",
      "Epoch: 21, Loss (standarized): 0.6632015886719106\n",
      "Epoch: 26, Loss (standarized): 0.6551173145905158\n",
      "Epoch: 31, Loss (standarized): 0.6442414862173462\n",
      "Epoch: 36, Loss (standarized): 0.6282302299338812\n",
      "Epoch: 41, Loss (standarized): 0.6136924704527115\n",
      "Epoch: 46, Loss (standarized): 0.6013351046261707\n",
      "Epoch: 51, Loss (standarized): 0.5908045018965637\n",
      "Epoch: 56, Loss (standarized): 0.5814891124271082\n",
      "Epoch: 61, Loss (standarized): 0.5723428421070336\n",
      "Epoch: 66, Loss (standarized): 0.5638700056418688\n",
      "Epoch: 71, Loss (standarized): 0.5559990114258871\n",
      "Epoch: 76, Loss (standarized): 0.5486638646115791\n",
      "Epoch: 81, Loss (standarized): 0.5410390558868926\n",
      "Epoch: 86, Loss (standarized): 0.5342870082243941\n",
      "Epoch: 91, Loss (standarized): 0.5277417908301766\n",
      "Epoch: 96, Loss (standarized): 0.5215554166796316\n",
      "Final epoch: 100, Final loss (standarized): 0.5166720269297916\n",
      "Epoch: 1, Loss (standarized): 2.251743356062737\n",
      "Epoch: 6, Loss (standarized): 0.959330429911441\n",
      "Epoch: 11, Loss (standarized): 0.7396335601158459\n",
      "Epoch: 16, Loss (standarized): 0.6898847350713514\n",
      "Epoch: 21, Loss (standarized): 0.6509588056342615\n",
      "Epoch: 26, Loss (standarized): 0.6403885757063836\n",
      "Epoch: 31, Loss (standarized): 0.6240292605731116\n",
      "Epoch: 36, Loss (standarized): 0.6028832455539748\n",
      "Epoch: 41, Loss (standarized): 0.5835778620283464\n",
      "Epoch: 46, Loss (standarized): 0.5607707352781887\n",
      "Epoch: 51, Loss (standarized): 0.5373900123908002\n",
      "Epoch: 56, Loss (standarized): 0.5103837356021471\n",
      "Epoch: 61, Loss (standarized): 0.47894653208140264\n",
      "Epoch: 66, Loss (standarized): 0.44320685430448364\n",
      "Epoch: 71, Loss (standarized): 0.40322826566659825\n",
      "Epoch: 76, Loss (standarized): 0.36112037414148274\n",
      "Epoch: 81, Loss (standarized): 0.3201626746158007\n",
      "Epoch: 86, Loss (standarized): 0.2826169609933697\n",
      "Epoch: 91, Loss (standarized): 0.2511648065112917\n",
      "Epoch: 96, Loss (standarized): 0.22649633033286048\n",
      "Final epoch: 100, Final loss (standarized): 0.21076372168441446\n",
      "Epoch: 1, Loss (standarized): 1.2247844877654315\n",
      "Epoch: 6, Loss (standarized): 0.7480489611779912\n",
      "Epoch: 11, Loss (standarized): 0.7224427292390584\n",
      "Epoch: 16, Loss (standarized): 0.7031161987310528\n",
      "Epoch: 21, Loss (standarized): 0.6799543908133309\n",
      "Epoch: 26, Loss (standarized): 0.667831305726007\n",
      "Epoch: 31, Loss (standarized): 0.6527222838821473\n",
      "Epoch: 36, Loss (standarized): 0.6359987763628198\n",
      "Epoch: 41, Loss (standarized): 0.616052631741058\n",
      "Epoch: 46, Loss (standarized): 0.5928171845402473\n",
      "Epoch: 51, Loss (standarized): 0.5694840272673192\n",
      "Epoch: 56, Loss (standarized): 0.5466600000648235\n",
      "Epoch: 61, Loss (standarized): 0.5248552031241188\n",
      "Epoch: 66, Loss (standarized): 0.5050563220584608\n",
      "Epoch: 71, Loss (standarized): 0.4860184945964119\n",
      "Epoch: 76, Loss (standarized): 0.46671281637912293\n",
      "Epoch: 81, Loss (standarized): 0.4460820994123786\n",
      "Epoch: 86, Loss (standarized): 0.42349885851233243\n",
      "Epoch: 91, Loss (standarized): 0.4009996749038263\n",
      "Epoch: 96, Loss (standarized): 0.37893507213202293\n",
      "Final epoch: 100, Final loss (standarized): 0.361904146463029\n",
      "Epoch: 1, Loss (standarized): 1.4518057284458958\n",
      "Epoch: 6, Loss (standarized): 0.8476015554732983\n",
      "Epoch: 11, Loss (standarized): 0.7052914338343937\n",
      "Epoch: 16, Loss (standarized): 0.6808843972506392\n",
      "Epoch: 21, Loss (standarized): 0.665589729229654\n",
      "Epoch: 26, Loss (standarized): 0.6400538056570211\n",
      "Epoch: 31, Loss (standarized): 0.621066944975639\n",
      "Epoch: 36, Loss (standarized): 0.6053800734165757\n",
      "Epoch: 41, Loss (standarized): 0.5868742481523913\n",
      "Epoch: 46, Loss (standarized): 0.5664088369337302\n",
      "Epoch: 51, Loss (standarized): 0.5443801263805552\n",
      "Epoch: 56, Loss (standarized): 0.519829345895487\n",
      "Epoch: 61, Loss (standarized): 0.4937377668286756\n",
      "Epoch: 66, Loss (standarized): 0.4654378069730794\n",
      "Epoch: 71, Loss (standarized): 0.4346534362821835\n",
      "Epoch: 76, Loss (standarized): 0.4018059128092242\n",
      "Epoch: 81, Loss (standarized): 0.36703023708250554\n",
      "Epoch: 86, Loss (standarized): 0.3310006553522223\n",
      "Epoch: 91, Loss (standarized): 0.2971725250288415\n",
      "Epoch: 96, Loss (standarized): 0.2671276818837139\n",
      "Final epoch: 100, Final loss (standarized): 0.24621219134404995\n",
      "Epoch: 1, Loss (standarized): 1.8805472149476417\n",
      "Epoch: 6, Loss (standarized): 0.9353393419927338\n",
      "Epoch: 11, Loss (standarized): 0.6897080535025417\n",
      "Epoch: 16, Loss (standarized): 0.6428585132481556\n",
      "Epoch: 21, Loss (standarized): 0.6087898187801897\n",
      "Epoch: 26, Loss (standarized): 0.5877582930465787\n",
      "Epoch: 31, Loss (standarized): 0.5572527227853483\n",
      "Epoch: 36, Loss (standarized): 0.5319556843249069\n",
      "Epoch: 41, Loss (standarized): 0.5044265074057341\n",
      "Epoch: 46, Loss (standarized): 0.47732511741626493\n",
      "Epoch: 51, Loss (standarized): 0.44919986757241814\n",
      "Epoch: 56, Loss (standarized): 0.42135587458336693\n",
      "Epoch: 61, Loss (standarized): 0.39415452442755144\n",
      "Epoch: 66, Loss (standarized): 0.36741052348269426\n",
      "Epoch: 71, Loss (standarized): 0.34263377003402223\n",
      "Epoch: 76, Loss (standarized): 0.3195152774916476\n",
      "Epoch: 81, Loss (standarized): 0.2981220688028529\n",
      "Epoch: 86, Loss (standarized): 0.2783569932859455\n",
      "Epoch: 91, Loss (standarized): 0.2605424717646411\n",
      "Epoch: 96, Loss (standarized): 0.2447881232861906\n",
      "Final epoch: 100, Final loss (standarized): 0.23349886946499845\n",
      "Epoch: 1, Loss (standarized): 1.0717929860444713\n",
      "Epoch: 6, Loss (standarized): 0.7705019730702996\n",
      "Epoch: 11, Loss (standarized): 0.6608637513632782\n",
      "Epoch: 16, Loss (standarized): 0.6060139009591184\n",
      "Epoch: 21, Loss (standarized): 0.5567065938484824\n",
      "Epoch: 26, Loss (standarized): 0.5021820314226203\n",
      "Epoch: 31, Loss (standarized): 0.45212158342831593\n",
      "Epoch: 36, Loss (standarized): 0.3961635541013963\n",
      "Epoch: 41, Loss (standarized): 0.34232858520045634\n",
      "Epoch: 46, Loss (standarized): 0.29670349764544296\n",
      "Epoch: 51, Loss (standarized): 0.2581213686235168\n",
      "Epoch: 56, Loss (standarized): 0.2276822341990386\n",
      "Epoch: 61, Loss (standarized): 0.20377776538903242\n",
      "Epoch: 66, Loss (standarized): 0.1842229198713546\n",
      "Epoch: 71, Loss (standarized): 0.16725279884638944\n",
      "Epoch: 76, Loss (standarized): 0.1515148566641031\n",
      "Epoch: 81, Loss (standarized): 0.13680636171816812\n",
      "Epoch: 86, Loss (standarized): 0.12346175590684183\n",
      "Epoch: 91, Loss (standarized): 0.11131356117850645\n",
      "Epoch: 96, Loss (standarized): 0.10066392316102549\n",
      "Final epoch: 100, Final loss (standarized): 0.09361772496680988\n",
      "Epoch: 1, Loss (standarized): 1.5628932791794672\n",
      "Epoch: 6, Loss (standarized): 0.7650456314205158\n",
      "Epoch: 11, Loss (standarized): 0.7059587758559195\n",
      "Epoch: 16, Loss (standarized): 0.7057931202012899\n",
      "Epoch: 21, Loss (standarized): 0.6713474095874944\n",
      "Epoch: 26, Loss (standarized): 0.6458710231685479\n",
      "Epoch: 31, Loss (standarized): 0.6290227866300796\n",
      "Epoch: 36, Loss (standarized): 0.6028091484774598\n",
      "Epoch: 41, Loss (standarized): 0.5743098342120112\n",
      "Epoch: 46, Loss (standarized): 0.5380431301489913\n",
      "Epoch: 51, Loss (standarized): 0.4973442635125503\n",
      "Epoch: 56, Loss (standarized): 0.45071807053706153\n",
      "Epoch: 61, Loss (standarized): 0.4013316697286334\n",
      "Epoch: 66, Loss (standarized): 0.35322203978133027\n",
      "Epoch: 71, Loss (standarized): 0.31107076411412826\n",
      "Epoch: 76, Loss (standarized): 0.2776960770947289\n",
      "Epoch: 81, Loss (standarized): 0.2529394736606082\n",
      "Epoch: 86, Loss (standarized): 0.23612252783014318\n",
      "Epoch: 91, Loss (standarized): 0.22475011796968403\n",
      "Epoch: 96, Loss (standarized): 0.21715397030508554\n",
      "Final epoch: 100, Final loss (standarized): 0.21313371046104249\n",
      "Epoch: 1, Loss (standarized): 1.1100246590823728\n",
      "Epoch: 6, Loss (standarized): 0.7298545119179546\n",
      "Epoch: 11, Loss (standarized): 0.7030468021197672\n",
      "Epoch: 16, Loss (standarized): 0.6656787886444759\n",
      "Epoch: 21, Loss (standarized): 0.6386515306712086\n",
      "Epoch: 26, Loss (standarized): 0.6094348480209049\n",
      "Epoch: 31, Loss (standarized): 0.5770951363017955\n",
      "Epoch: 36, Loss (standarized): 0.53370901100701\n",
      "Epoch: 41, Loss (standarized): 0.4868286957431455\n",
      "Epoch: 46, Loss (standarized): 0.4324199371177477\n",
      "Epoch: 51, Loss (standarized): 0.37498377518178877\n",
      "Epoch: 56, Loss (standarized): 0.31587606452496036\n",
      "Epoch: 61, Loss (standarized): 0.26619620747465444\n",
      "Epoch: 66, Loss (standarized): 0.229321949627981\n",
      "Epoch: 71, Loss (standarized): 0.20313077305089378\n",
      "Epoch: 76, Loss (standarized): 0.18329801008704735\n",
      "Epoch: 81, Loss (standarized): 0.16662349973621288\n",
      "Epoch: 86, Loss (standarized): 0.15215962619961954\n",
      "Epoch: 91, Loss (standarized): 0.13955441559671605\n",
      "Epoch: 96, Loss (standarized): 0.1293189908815798\n",
      "Final epoch: 100, Final loss (standarized): 0.1220524943185046\n",
      "Epoch: 1, Loss (standarized): 2.7770603286171007\n",
      "Epoch: 6, Loss (standarized): 1.2790934856096017\n",
      "Epoch: 11, Loss (standarized): 0.8967016497644656\n",
      "Epoch: 16, Loss (standarized): 0.7464691238138526\n",
      "Epoch: 21, Loss (standarized): 0.7087642318978405\n",
      "Epoch: 26, Loss (standarized): 0.6917883181802217\n",
      "Epoch: 31, Loss (standarized): 0.6674990135576863\n",
      "Epoch: 36, Loss (standarized): 0.6438690952257361\n",
      "Epoch: 41, Loss (standarized): 0.6241936793859784\n",
      "Epoch: 46, Loss (standarized): 0.603668194882157\n",
      "Epoch: 51, Loss (standarized): 0.5784709340626665\n",
      "Epoch: 56, Loss (standarized): 0.5510603676127259\n",
      "Epoch: 61, Loss (standarized): 0.5193507425340349\n",
      "Epoch: 66, Loss (standarized): 0.4850350960242827\n",
      "Epoch: 71, Loss (standarized): 0.45031557316148446\n",
      "Epoch: 76, Loss (standarized): 0.4158190061947359\n",
      "Epoch: 81, Loss (standarized): 0.38285505531561737\n",
      "Epoch: 86, Loss (standarized): 0.3515864351348519\n",
      "Epoch: 91, Loss (standarized): 0.3223036208237825\n",
      "Epoch: 96, Loss (standarized): 0.2955445089443815\n",
      "Final epoch: 100, Final loss (standarized): 0.2760799632380715\n",
      "Epoch: 1, Loss (standarized): 1.0646694056669324\n",
      "          Validation Loss (standardized): 1.2343635430831776\n",
      "Epoch: 6, Loss (standarized): 0.7460377309480631\n",
      "          Validation Loss (standardized): 1.5531609499616126\n",
      "Epoch: 11, Loss (standarized): 0.6541543794230612\n",
      "          Validation Loss (standardized): 2.074198939125231\n",
      "Epoch: 16, Loss (standarized): 0.6248398842482791\n",
      "          Validation Loss (standardized): 2.1555479564412128\n",
      "Epoch: 21, Loss (standarized): 0.5897115482364605\n",
      "          Validation Loss (standardized): 2.047345226595667\n",
      "Epoch: 26, Loss (standarized): 0.5500955959578224\n",
      "          Validation Loss (standardized): 1.8885952580116105\n",
      "Epoch: 31, Loss (standarized): 0.5129005043783351\n",
      "          Validation Loss (standardized): 1.7344089109681924\n",
      "Epoch: 36, Loss (standarized): 0.4761668857400413\n",
      "          Validation Loss (standardized): 1.778728780798146\n",
      "Epoch: 41, Loss (standarized): 0.4375065509505696\n",
      "          Validation Loss (standardized): 1.7330632488218367\n",
      "Epoch: 46, Loss (standarized): 0.3954436543733295\n",
      "          Validation Loss (standardized): 1.6977537453208704\n",
      "Epoch: 51, Loss (standarized): 0.35257961031653484\n",
      "          Validation Loss (standardized): 1.6012711696170792\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.31345599564176924\n",
      "          Validation Loss (standardized): 1.539549763453314\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.27894406014874606\n",
      "          Validation Loss (standardized): 1.4629121509384408\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.24946839295917203\n",
      "          Validation Loss (standardized): 1.3483087430253577\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.22437105177643685\n",
      "          Validation Loss (standardized): 1.2505859490330595\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.20368481143541275\n",
      "          Validation Loss (standardized): 1.1664487225378102\n",
      "Epoch: 81, Loss (standarized): 0.18517017275006445\n",
      "          Validation Loss (standardized): 1.0941103359269615\n",
      "Epoch: 86, Loss (standarized): 0.16861705708450253\n",
      "          Validation Loss (standardized): 1.0388670714667974\n",
      "Epoch: 91, Loss (standarized): 0.15449661542956142\n",
      "          Validation Loss (standardized): 0.9650775022330267\n",
      "Epoch: 96, Loss (standarized): 0.1420870468513514\n",
      "          Validation Loss (standardized): 0.9036787634535717\n",
      "Final epoch: 100, Final loss (standarized): 0.1331501889800741\n",
      "Epoch: 1, Loss (standarized): 1.0924176194144883\n",
      "          Validation Loss (standardized): 1.3137694207660606\n",
      "Epoch: 6, Loss (standarized): 0.7008498994574196\n",
      "          Validation Loss (standardized): 1.6894693088151385\n",
      "Epoch: 11, Loss (standarized): 0.647737603013837\n",
      "          Validation Loss (standardized): 1.9049475881343034\n",
      "Epoch: 16, Loss (standarized): 0.6113859835812444\n",
      "          Validation Loss (standardized): 1.8401345120970298\n",
      "Epoch: 21, Loss (standarized): 0.5845818474575432\n",
      "          Validation Loss (standardized): 1.7640350904834494\n",
      "Epoch: 26, Loss (standarized): 0.5609000653542664\n",
      "          Validation Loss (standardized): 1.7198347114059012\n",
      "Epoch: 31, Loss (standarized): 0.5326471176019886\n",
      "          Validation Loss (standardized): 1.6543124314153954\n",
      "Epoch: 36, Loss (standarized): 0.5063095749864757\n",
      "          Validation Loss (standardized): 1.6128602187818273\n",
      "Epoch: 41, Loss (standarized): 0.47448243046047167\n",
      "          Validation Loss (standardized): 1.6118724693021795\n",
      "Epoch: 46, Loss (standarized): 0.44448587930902667\n",
      "          Validation Loss (standardized): 1.5843070807248067\n",
      "Epoch: 51, Loss (standarized): 0.41460374230704483\n",
      "          Validation Loss (standardized): 1.5187641005971\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.38479397994841263\n",
      "          Validation Loss (standardized): 1.4812680409097578\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.35704223161563486\n",
      "          Validation Loss (standardized): 1.4555856228993946\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.33194250670432085\n",
      "          Validation Loss (standardized): 1.4180609467661411\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.3092753931772822\n",
      "          Validation Loss (standardized): 1.3881989551179303\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.290475694550958\n",
      "          Validation Loss (standardized): 1.3474124566345584\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.27598010418834695\n",
      "          Validation Loss (standardized): 1.303176996975531\n",
      "Epoch: 86, Loss (standarized): 0.26427300954285154\n",
      "          Validation Loss (standardized): 1.2731518990675146\n",
      "Epoch: 91, Loss (standarized): 0.25497172111725364\n",
      "          Validation Loss (standardized): 1.2427401775455178\n",
      "Epoch: 96, Loss (standarized): 0.2477435395430121\n",
      "          Validation Loss (standardized): 1.219210952655354\n",
      "Final epoch: 100, Final loss (standarized): 0.2429414242547457\n",
      "Epoch: 1, Loss (standarized): 1.1756480013917676\n",
      "          Validation Loss (standardized): 1.3589573656537637\n",
      "Epoch: 6, Loss (standarized): 0.7151118544928925\n",
      "          Validation Loss (standardized): 1.8388207246298884\n",
      "Epoch: 11, Loss (standarized): 0.6656162732955436\n",
      "          Validation Loss (standardized): 2.2343074573550292\n",
      "Epoch: 16, Loss (standarized): 0.6404599721211663\n",
      "          Validation Loss (standardized): 2.2417775927692003\n",
      "Epoch: 21, Loss (standarized): 0.6068260794269238\n",
      "          Validation Loss (standardized): 2.073817458188526\n",
      "Epoch: 26, Loss (standarized): 0.5724378400771705\n",
      "          Validation Loss (standardized): 1.8862041269406784\n",
      "Epoch: 31, Loss (standarized): 0.534359210255874\n",
      "          Validation Loss (standardized): 1.7223163754525408\n",
      "Epoch: 36, Loss (standarized): 0.49408900718633625\n",
      "          Validation Loss (standardized): 1.6247880154770031\n",
      "Epoch: 41, Loss (standarized): 0.45015051875976836\n",
      "          Validation Loss (standardized): 1.579597788482361\n",
      "Epoch: 46, Loss (standarized): 0.4025210465455218\n",
      "          Validation Loss (standardized): 1.5267956031941174\n",
      "Epoch: 51, Loss (standarized): 0.3535366565641937\n",
      "          Validation Loss (standardized): 1.4415105900415341\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.3080692251035783\n",
      "          Validation Loss (standardized): 1.3571880669574534\n",
      "Epoch: 61, Loss (standarized): 0.2686085774607969\n",
      "          Validation Loss (standardized): 1.2973876285895394\n",
      "Epoch: 66, Loss (standarized): 0.23693031848466387\n",
      "          Validation Loss (standardized): 1.2274464696652387\n",
      "Epoch: 71, Loss (standarized): 0.21229958837796975\n",
      "          Validation Loss (standardized): 1.1639909838106124\n",
      "Epoch: 76, Loss (standarized): 0.19235816217123664\n",
      "          Validation Loss (standardized): 1.0672268489888987\n",
      "Epoch: 81, Loss (standarized): 0.1754710737512761\n",
      "          Validation Loss (standardized): 0.98732563343582\n",
      "Epoch: 86, Loss (standarized): 0.16194445974466443\n",
      "          Validation Loss (standardized): 0.9370548073704935\n",
      "Epoch: 91, Loss (standarized): 0.15031656819299857\n",
      "          Validation Loss (standardized): 0.8775277949070673\n",
      "Epoch: 96, Loss (standarized): 0.14009154520951664\n",
      "          Validation Loss (standardized): 0.8255205721348415\n",
      "Final epoch: 100, Final loss (standarized): 0.13252607675883743\n",
      "Epoch: 1, Loss (standarized): 1.5923108119015867\n",
      "          Validation Loss (standardized): 1.399382153295082\n",
      "Epoch: 6, Loss (standarized): 0.7768934718119107\n",
      "          Validation Loss (standardized): 1.7133385238032655\n",
      "Epoch: 11, Loss (standarized): 0.7079245003049998\n",
      "          Validation Loss (standardized): 2.252593346993171\n",
      "Epoch: 16, Loss (standarized): 0.6777151873655346\n",
      "          Validation Loss (standardized): 2.3087974753980425\n",
      "Epoch: 21, Loss (standarized): 0.6224887330515576\n",
      "          Validation Loss (standardized): 2.1295615956367953\n",
      "Epoch: 26, Loss (standarized): 0.5928033958409367\n",
      "          Validation Loss (standardized): 1.9129877080113542\n",
      "Epoch: 31, Loss (standarized): 0.5612502805015247\n",
      "          Validation Loss (standardized): 1.7773304727350956\n",
      "Epoch: 36, Loss (standarized): 0.5255873821060028\n",
      "          Validation Loss (standardized): 1.7129773861178825\n",
      "Epoch: 41, Loss (standarized): 0.4893884864840208\n",
      "          Validation Loss (standardized): 1.6591844491644379\n",
      "Epoch: 46, Loss (standarized): 0.4486139149827724\n",
      "          Validation Loss (standardized): 1.621730172377523\n",
      "Epoch: 51, Loss (standarized): 0.4059180851016975\n",
      "          Validation Loss (standardized): 1.5797054279551432\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.36429892588984836\n",
      "          Validation Loss (standardized): 1.5144596211029016\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.32757950597265445\n",
      "          Validation Loss (standardized): 1.4500175007037641\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.29536010789344835\n",
      "          Validation Loss (standardized): 1.388951137714647\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.2677647165807757\n",
      "          Validation Loss (standardized): 1.3346822579697468\n",
      "Epoch: 76, Loss (standarized): 0.24288135565269073\n",
      "          Validation Loss (standardized): 1.2715621490301177\n",
      "Epoch: 81, Loss (standarized): 0.22062238835467154\n",
      "          Validation Loss (standardized): 1.2020945674439818\n",
      "Epoch: 86, Loss (standarized): 0.20296503468012292\n",
      "          Validation Loss (standardized): 1.1248817296899485\n",
      "Epoch: 91, Loss (standarized): 0.1883591353916671\n",
      "          Validation Loss (standardized): 1.0921103041150455\n",
      "Epoch: 96, Loss (standarized): 0.17612605767960118\n",
      "          Validation Loss (standardized): 1.029067039164239\n",
      "Final epoch: 100, Final loss (standarized): 0.16743515834739556\n",
      "Epoch: 1, Loss (standarized): 1.5995403459520392\n",
      "          Validation Loss (standardized): 1.366411961211391\n",
      "Epoch: 6, Loss (standarized): 0.7805674699025585\n",
      "          Validation Loss (standardized): 1.6708122984824696\n",
      "Epoch: 11, Loss (standarized): 0.6846125387479493\n",
      "          Validation Loss (standardized): 2.024827229469977\n",
      "Epoch: 16, Loss (standarized): 0.6758235097817176\n",
      "          Validation Loss (standardized): 2.094558106646136\n",
      "Epoch: 21, Loss (standarized): 0.6505549374621163\n",
      "          Validation Loss (standardized): 1.966322812486317\n",
      "Epoch: 26, Loss (standarized): 0.6338370330342278\n",
      "          Validation Loss (standardized): 1.7783105394306211\n",
      "Epoch: 31, Loss (standarized): 0.6238825159636424\n",
      "          Validation Loss (standardized): 1.6280931235874647\n",
      "Epoch: 36, Loss (standarized): 0.6169093718114909\n",
      "          Validation Loss (standardized): 1.552142657101579\n",
      "Epoch: 41, Loss (standarized): 0.6073736144914531\n",
      "          Validation Loss (standardized): 1.5481325373276869\n",
      "Epoch: 46, Loss (standarized): 0.5978585131716962\n",
      "          Validation Loss (standardized): 1.5767537750488307\n",
      "Epoch: 51, Loss (standarized): 0.5887207249085399\n",
      "          Validation Loss (standardized): 1.5959852148819984\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5797041052084341\n",
      "          Validation Loss (standardized): 1.5977053100342538\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.568594236826207\n",
      "          Validation Loss (standardized): 1.5880780914720267\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.5588327080153187\n",
      "          Validation Loss (standardized): 1.5773064163091075\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.5475768567349083\n",
      "          Validation Loss (standardized): 1.570733544293821\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.5357575921792092\n",
      "          Validation Loss (standardized): 1.5602033580046228\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.5238440304868225\n",
      "          Validation Loss (standardized): 1.538565727261992\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.5130482384930567\n",
      "          Validation Loss (standardized): 1.5364630370045098\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.5019049742253492\n",
      "          Validation Loss (standardized): 1.537679890281449\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.48963606189204995\n",
      "          Validation Loss (standardized): 1.5534499466040286\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.4794762764070294\n",
      "Epoch: 1, Loss (standarized): 1.3155684721445824\n",
      "          Validation Loss (standardized): 1.2573175903203824\n",
      "Epoch: 6, Loss (standarized): 0.7921770098088262\n",
      "          Validation Loss (standardized): 1.9030995797539592\n",
      "Epoch: 11, Loss (standarized): 0.7158699798864018\n",
      "          Validation Loss (standardized): 2.0611418768090872\n",
      "Epoch: 16, Loss (standarized): 0.6873107752904737\n",
      "          Validation Loss (standardized): 1.9422267719369901\n",
      "Epoch: 21, Loss (standarized): 0.6568287685731965\n",
      "          Validation Loss (standardized): 1.7548363387664245\n",
      "Epoch: 26, Loss (standarized): 0.6435262563820922\n",
      "          Validation Loss (standardized): 1.6204186267537644\n",
      "Epoch: 31, Loss (standarized): 0.6316420875875165\n",
      "          Validation Loss (standardized): 1.5413014210248766\n",
      "Epoch: 36, Loss (standarized): 0.6213741542415837\n",
      "          Validation Loss (standardized): 1.5123765140394039\n",
      "Epoch: 41, Loss (standarized): 0.6105507762992796\n",
      "          Validation Loss (standardized): 1.5285689999816707\n",
      "Epoch: 46, Loss (standarized): 0.602334494261488\n",
      "          Validation Loss (standardized): 1.5513146124869133\n",
      "Epoch: 51, Loss (standarized): 0.5938711582684866\n",
      "          Validation Loss (standardized): 1.5592867774186778\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5866685137785868\n",
      "          Validation Loss (standardized): 1.5544756203813426\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5818988404818463\n",
      "          Validation Loss (standardized): 1.5449871018113408\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.5768139350046401\n",
      "          Validation Loss (standardized): 1.5438803888766266\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.571481849272153\n",
      "          Validation Loss (standardized): 1.5403222555608764\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.5675730811700312\n",
      "          Validation Loss (standardized): 1.5346538878018114\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.5641568651504059\n",
      "          Validation Loss (standardized): 1.5332124586145506\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.5611587100063898\n",
      "          Validation Loss (standardized): 1.5336238177441388\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.5577828522895939\n",
      "          Validation Loss (standardized): 1.5371357067942724\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.554281838661199\n",
      "          Validation Loss (standardized): 1.5408921949690344\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.5514916603284516\n",
      "Epoch: 1, Loss (standarized): 1.2818778951500012\n",
      "          Validation Loss (standardized): 1.3211275274423877\n",
      "Epoch: 6, Loss (standarized): 0.7442752864636327\n",
      "          Validation Loss (standardized): 1.717374925344056\n",
      "Epoch: 11, Loss (standarized): 0.7095964158053779\n",
      "          Validation Loss (standardized): 2.0913079639114276\n",
      "Epoch: 16, Loss (standarized): 0.6574002211787265\n",
      "          Validation Loss (standardized): 2.037570533744403\n",
      "Epoch: 21, Loss (standarized): 0.6430741238795643\n",
      "          Validation Loss (standardized): 1.932672975206636\n",
      "Epoch: 26, Loss (standarized): 0.6281446637065237\n",
      "          Validation Loss (standardized): 1.8292142493058017\n",
      "Epoch: 31, Loss (standarized): 0.6108538158056733\n",
      "          Validation Loss (standardized): 1.7316514280495974\n",
      "Epoch: 36, Loss (standarized): 0.6014202577911867\n",
      "          Validation Loss (standardized): 1.6760283557963533\n",
      "Epoch: 41, Loss (standarized): 0.5906528813489396\n",
      "          Validation Loss (standardized): 1.6418481191652927\n",
      "Epoch: 46, Loss (standarized): 0.5823475423434755\n",
      "          Validation Loss (standardized): 1.6201443616386104\n",
      "Epoch: 51, Loss (standarized): 0.5733477775079058\n",
      "          Validation Loss (standardized): 1.6102668671394254\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5632808289090517\n",
      "          Validation Loss (standardized): 1.617951513723208\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5546876885037014\n",
      "          Validation Loss (standardized): 1.6142458578561754\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.5474933789050839\n",
      "          Validation Loss (standardized): 1.6049672017102552\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.5391053688147457\n",
      "          Validation Loss (standardized): 1.6023514577167626\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.5297819772052161\n",
      "          Validation Loss (standardized): 1.6055411726455444\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.520825187905589\n",
      "          Validation Loss (standardized): 1.589273027306009\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.5133553250006772\n",
      "          Validation Loss (standardized): 1.582204271276119\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.5064261083058805\n",
      "          Validation Loss (standardized): 1.5724295935357344\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.49992735876823335\n",
      "          Validation Loss (standardized): 1.5651548468458252\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.4945207628225583\n",
      "Epoch: 1, Loss (standarized): 1.524912948059985\n",
      "          Validation Loss (standardized): 1.9729291139671898\n",
      "Epoch: 6, Loss (standarized): 0.9196271740314135\n",
      "          Validation Loss (standardized): 1.3816972072698759\n",
      "Epoch: 11, Loss (standarized): 0.7871756354960873\n",
      "          Validation Loss (standardized): 1.5291459044790492\n",
      "Epoch: 16, Loss (standarized): 0.7096833880082513\n",
      "          Validation Loss (standardized): 1.7619292103823496\n",
      "Epoch: 21, Loss (standarized): 0.6795250463953352\n",
      "          Validation Loss (standardized): 1.8808578286713273\n",
      "Epoch: 26, Loss (standarized): 0.6658240074846227\n",
      "          Validation Loss (standardized): 1.8089562636795882\n",
      "Epoch: 31, Loss (standarized): 0.6539245352393456\n",
      "          Validation Loss (standardized): 1.6673703713033807\n",
      "Epoch: 36, Loss (standarized): 0.6461950185476008\n",
      "          Validation Loss (standardized): 1.594269137290687\n",
      "Epoch: 41, Loss (standarized): 0.6376307508436161\n",
      "          Validation Loss (standardized): 1.608188209083263\n",
      "Epoch: 46, Loss (standarized): 0.6296716743532657\n",
      "          Validation Loss (standardized): 1.6320243654423716\n",
      "Epoch: 51, Loss (standarized): 0.6212569244374736\n",
      "          Validation Loss (standardized): 1.6289417468209773\n",
      "Epoch: 56, Loss (standarized): 0.6125760041552859\n",
      "          Validation Loss (standardized): 1.6058959614392692\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6040689073335417\n",
      "          Validation Loss (standardized): 1.5802287260200905\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.5956639202246988\n",
      "          Validation Loss (standardized): 1.5825985317735978\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.5873561515079535\n",
      "          Validation Loss (standardized): 1.5879156515911164\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.5784229554468225\n",
      "          Validation Loss (standardized): 1.607983868097698\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.5690864243908087\n",
      "          Validation Loss (standardized): 1.603264038840283\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.5601313024103132\n",
      "          Validation Loss (standardized): 1.5967210023408966\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.5515071282928525\n",
      "          Validation Loss (standardized): 1.591303574903033\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.5435519527083392\n",
      "          Validation Loss (standardized): 1.5930648603836066\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.5379218196194699\n",
      "Epoch: 1, Loss (standarized): 3.093503671481868\n",
      "          Validation Loss (standardized): 1.5436715324057766\n",
      "Epoch: 6, Loss (standarized): 0.9839355259940419\n",
      "          Validation Loss (standardized): 1.1450111450735807\n",
      "Epoch: 11, Loss (standarized): 0.6741190793323206\n",
      "          Validation Loss (standardized): 1.8134048748645706\n",
      "Epoch: 16, Loss (standarized): 0.6710944366725398\n",
      "          Validation Loss (standardized): 2.2879456104687432\n",
      "Epoch: 21, Loss (standarized): 0.6595088024968022\n",
      "          Validation Loss (standardized): 2.489219996507647\n",
      "Epoch: 26, Loss (standarized): 0.6416170151260097\n",
      "          Validation Loss (standardized): 2.4020971509049494\n",
      "Epoch: 31, Loss (standarized): 0.6218085269849243\n",
      "          Validation Loss (standardized): 2.1814178703326625\n",
      "Epoch: 36, Loss (standarized): 0.5991462113849934\n",
      "          Validation Loss (standardized): 1.9044529901583869\n",
      "Epoch: 41, Loss (standarized): 0.5826012891073936\n",
      "          Validation Loss (standardized): 1.7294983301014517\n",
      "Epoch: 46, Loss (standarized): 0.5646206191322315\n",
      "          Validation Loss (standardized): 1.715168951571684\n",
      "Epoch: 51, Loss (standarized): 0.5464178177128841\n",
      "          Validation Loss (standardized): 1.7008181064915098\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5281976580261145\n",
      "          Validation Loss (standardized): 1.6768609833495425\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5087341506822931\n",
      "          Validation Loss (standardized): 1.6835570816865215\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.486644160086409\n",
      "          Validation Loss (standardized): 1.6576187047353603\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.46337698917811476\n",
      "          Validation Loss (standardized): 1.617688047074721\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.43714819902030017\n",
      "          Validation Loss (standardized): 1.575332213904666\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.40729745234070214\n",
      "          Validation Loss (standardized): 1.5381254967087907\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.3761873478654976\n",
      "          Validation Loss (standardized): 1.5093887701727673\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.34619856640141705\n",
      "          Validation Loss (standardized): 1.494477259518534\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.31751456376172416\n",
      "          Validation Loss (standardized): 1.4566085690931445\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.2971350933671297\n",
      "Epoch: 1, Loss (standarized): 1.0855891920339382\n",
      "          Validation Loss (standardized): 1.4263450055391362\n",
      "Epoch: 6, Loss (standarized): 0.791553935273123\n",
      "          Validation Loss (standardized): 1.425229320785596\n",
      "Epoch: 11, Loss (standarized): 0.6838972333731537\n",
      "          Validation Loss (standardized): 1.7480965389061975\n",
      "Epoch: 16, Loss (standarized): 0.6597750727251046\n",
      "          Validation Loss (standardized): 1.8892391085231734\n",
      "Epoch: 21, Loss (standarized): 0.6345439035476214\n",
      "          Validation Loss (standardized): 1.8396092683106329\n",
      "Epoch: 26, Loss (standarized): 0.6139451832011598\n",
      "          Validation Loss (standardized): 1.7402159012167144\n",
      "Epoch: 31, Loss (standarized): 0.5858257262603007\n",
      "          Validation Loss (standardized): 1.6665538527997783\n",
      "Epoch: 36, Loss (standarized): 0.5555725708960577\n",
      "          Validation Loss (standardized): 1.6339035482338584\n",
      "Epoch: 41, Loss (standarized): 0.5185341019718616\n",
      "          Validation Loss (standardized): 1.596597002954457\n",
      "Epoch: 46, Loss (standarized): 0.47711026600348516\n",
      "          Validation Loss (standardized): 1.5817501079820813\n",
      "Epoch: 51, Loss (standarized): 0.4313531511799992\n",
      "          Validation Loss (standardized): 1.542555199473907\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.3878273660700661\n",
      "          Validation Loss (standardized): 1.4750499043482959\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.34815580201962243\n",
      "          Validation Loss (standardized): 1.4273429751362274\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.316173967186521\n",
      "          Validation Loss (standardized): 1.3804942139153227\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.29097935190551855\n",
      "          Validation Loss (standardized): 1.3292708272815819\n",
      "Epoch: 76, Loss (standarized): 0.27206282217078526\n",
      "          Validation Loss (standardized): 1.2561135390889486\n",
      "Epoch: 81, Loss (standarized): 0.2582272552402538\n",
      "          Validation Loss (standardized): 1.2049138024148827\n",
      "Epoch: 86, Loss (standarized): 0.24830215283901352\n",
      "          Validation Loss (standardized): 1.1763691439964228\n",
      "Epoch: 91, Loss (standarized): 0.2416885505944918\n",
      "          Validation Loss (standardized): 1.1591904028635096\n",
      "Epoch: 96, Loss (standarized): 0.23763850168724898\n",
      "          Validation Loss (standardized): 1.1532236399489875\n",
      "Final epoch: 100, Final loss (standarized): 0.2356240218134999\n",
      "Epoch: 1, Loss (standarized): 1.3944798897817565\n",
      "          Validation Loss (standardized): 1.7213654138676984\n",
      "Epoch: 6, Loss (standarized): 0.740038884733676\n",
      "          Validation Loss (standardized): 1.6936994059494759\n",
      "Epoch: 11, Loss (standarized): 0.6664267235317567\n",
      "          Validation Loss (standardized): 2.0593794457150625\n",
      "Epoch: 16, Loss (standarized): 0.6391566267660949\n",
      "          Validation Loss (standardized): 2.0650213353911204\n",
      "Epoch: 21, Loss (standarized): 0.6071436127745807\n",
      "          Validation Loss (standardized): 1.9046788593604642\n",
      "Epoch: 26, Loss (standarized): 0.578059203270516\n",
      "          Validation Loss (standardized): 1.8055406512248777\n",
      "Epoch: 31, Loss (standarized): 0.5473512321591134\n",
      "          Validation Loss (standardized): 1.7541646196870624\n",
      "Epoch: 36, Loss (standarized): 0.5156185713895387\n",
      "          Validation Loss (standardized): 1.7036190988000453\n",
      "Epoch: 41, Loss (standarized): 0.48112560915985425\n",
      "          Validation Loss (standardized): 1.6580315643681356\n",
      "Epoch: 46, Loss (standarized): 0.4421073727134111\n",
      "          Validation Loss (standardized): 1.6086274196740826\n",
      "Epoch: 51, Loss (standarized): 0.39987905090375164\n",
      "          Validation Loss (standardized): 1.558666086364849\n",
      "Epoch: 56, Loss (standarized): 0.360489574288312\n",
      "          Validation Loss (standardized): 1.5296886058534844\n",
      "Epoch: 61, Loss (standarized): 0.32603444421852673\n",
      "          Validation Loss (standardized): 1.4973176891241624\n",
      "Epoch: 66, Loss (standarized): 0.29406751428561345\n",
      "          Validation Loss (standardized): 1.4361142396971263\n",
      "Epoch: 71, Loss (standarized): 0.2664838507204951\n",
      "          Validation Loss (standardized): 1.3735702147766742\n",
      "Epoch: 76, Loss (standarized): 0.24371499860721302\n",
      "          Validation Loss (standardized): 1.3208617746504017\n",
      "Epoch: 81, Loss (standarized): 0.2248738438224328\n",
      "          Validation Loss (standardized): 1.2710698131220126\n",
      "Epoch: 86, Loss (standarized): 0.21076010649269766\n",
      "          Validation Loss (standardized): 1.21888952060689\n",
      "Epoch: 91, Loss (standarized): 0.19944081294736468\n",
      "          Validation Loss (standardized): 1.159555616675073\n",
      "Epoch: 96, Loss (standarized): 0.19015899049626667\n",
      "          Validation Loss (standardized): 1.112469908688361\n",
      "Final epoch: 100, Final loss (standarized): 0.1836913458259931\n",
      "Epoch: 1, Loss (standarized): 1.2584549219604448\n",
      "          Validation Loss (standardized): 1.3919602076526731\n",
      "Epoch: 6, Loss (standarized): 0.7073182561674576\n",
      "          Validation Loss (standardized): 1.798091401700424\n",
      "Epoch: 11, Loss (standarized): 0.6831761151735819\n",
      "          Validation Loss (standardized): 2.2450161757433555\n",
      "Epoch: 16, Loss (standarized): 0.6542938983635792\n",
      "          Validation Loss (standardized): 2.239267060090614\n",
      "Epoch: 21, Loss (standarized): 0.6203304730029342\n",
      "          Validation Loss (standardized): 2.029413552555143\n",
      "Epoch: 26, Loss (standarized): 0.58988399632256\n",
      "          Validation Loss (standardized): 1.7826287474117053\n",
      "Epoch: 31, Loss (standarized): 0.5539661272225217\n",
      "          Validation Loss (standardized): 1.6236362359754404\n",
      "Epoch: 36, Loss (standarized): 0.5169653316587873\n",
      "          Validation Loss (standardized): 1.5527171823305017\n",
      "Epoch: 41, Loss (standarized): 0.47634086484152977\n",
      "          Validation Loss (standardized): 1.5750176090159234\n",
      "Epoch: 46, Loss (standarized): 0.43564669527644423\n",
      "          Validation Loss (standardized): 1.6154367121953859\n",
      "Epoch: 51, Loss (standarized): 0.39575385420586917\n",
      "          Validation Loss (standardized): 1.6386494289764075\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.35723483160086894\n",
      "          Validation Loss (standardized): 1.6061309464564628\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.3201402632390268\n",
      "          Validation Loss (standardized): 1.5233145449328713\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.28622446111464944\n",
      "          Validation Loss (standardized): 1.421044112530902\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.256433449178427\n",
      "          Validation Loss (standardized): 1.3541675378905471\n",
      "Epoch: 76, Loss (standarized): 0.23176977355267878\n",
      "          Validation Loss (standardized): 1.310713517239506\n",
      "Epoch: 81, Loss (standarized): 0.21149334800957773\n",
      "          Validation Loss (standardized): 1.2545975853512854\n",
      "Epoch: 86, Loss (standarized): 0.19519381734274188\n",
      "          Validation Loss (standardized): 1.1794468387846127\n",
      "Epoch: 91, Loss (standarized): 0.1816721972761081\n",
      "          Validation Loss (standardized): 1.0972425548906357\n",
      "Epoch: 96, Loss (standarized): 0.16955308454638499\n",
      "          Validation Loss (standardized): 1.0422466441894123\n",
      "Final epoch: 100, Final loss (standarized): 0.16055195311441278\n",
      "Epoch: 1, Loss (standarized): 1.086005464077841\n",
      "          Validation Loss (standardized): 1.0589487391667425\n",
      "Epoch: 6, Loss (standarized): 0.6806789640357799\n",
      "          Validation Loss (standardized): 1.5942341447318418\n",
      "Epoch: 11, Loss (standarized): 0.6465409437038411\n",
      "          Validation Loss (standardized): 2.039568661383044\n",
      "Epoch: 16, Loss (standarized): 0.6214961345505946\n",
      "          Validation Loss (standardized): 2.218689454936658\n",
      "Epoch: 21, Loss (standarized): 0.5948102929434743\n",
      "          Validation Loss (standardized): 2.164958661524547\n",
      "Epoch: 26, Loss (standarized): 0.5559241780836327\n",
      "          Validation Loss (standardized): 1.9722786931033416\n",
      "Epoch: 31, Loss (standarized): 0.516285858479865\n",
      "          Validation Loss (standardized): 1.7810796318047204\n",
      "Epoch: 36, Loss (standarized): 0.47436178143004853\n",
      "          Validation Loss (standardized): 1.6303637026413782\n",
      "Epoch: 41, Loss (standarized): 0.43110396755501074\n",
      "          Validation Loss (standardized): 1.5493275248899794\n",
      "Epoch: 46, Loss (standarized): 0.3879017403588715\n",
      "          Validation Loss (standardized): 1.542599800741435\n",
      "Epoch: 51, Loss (standarized): 0.34773985016894055\n",
      "          Validation Loss (standardized): 1.5495461411202769\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.3126717129801047\n",
      "          Validation Loss (standardized): 1.541010695102555\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.282628200169811\n",
      "          Validation Loss (standardized): 1.4967076220167463\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.25801785390693804\n",
      "          Validation Loss (standardized): 1.43443391912675\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.2381859644342659\n",
      "          Validation Loss (standardized): 1.3807626471140961\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.22180592717495975\n",
      "          Validation Loss (standardized): 1.335317562399621\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.20742892203952656\n",
      "          Validation Loss (standardized): 1.2873301053610275\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.19431902727362038\n",
      "          Validation Loss (standardized): 1.2104125779937853\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.18229193600068494\n",
      "          Validation Loss (standardized): 1.1301854766566404\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.17139510551538228\n",
      "          Validation Loss (standardized): 1.0794534133963969\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.16310554537046562\n",
      "Epoch: 1, Loss (standarized): 1.0551380384942257\n",
      "          Validation Loss (standardized): 1.2942847688040724\n",
      "Epoch: 6, Loss (standarized): 0.6708246974833618\n",
      "          Validation Loss (standardized): 1.8113586551271925\n",
      "Epoch: 11, Loss (standarized): 0.6471655582302644\n",
      "          Validation Loss (standardized): 2.1745192029021645\n",
      "Epoch: 16, Loss (standarized): 0.6209190529145616\n",
      "          Validation Loss (standardized): 2.1184609137415267\n",
      "Epoch: 21, Loss (standarized): 0.5949826578100772\n",
      "          Validation Loss (standardized): 1.8872529297556389\n",
      "Epoch: 26, Loss (standarized): 0.571103240579869\n",
      "          Validation Loss (standardized): 1.6906869191779514\n",
      "Epoch: 31, Loss (standarized): 0.5486782659806531\n",
      "          Validation Loss (standardized): 1.5833890806103779\n",
      "Epoch: 36, Loss (standarized): 0.5228961202894149\n",
      "          Validation Loss (standardized): 1.5440128936460633\n",
      "Epoch: 41, Loss (standarized): 0.4975767747452168\n",
      "          Validation Loss (standardized): 1.5416696330626225\n",
      "Epoch: 46, Loss (standarized): 0.4710494888331308\n",
      "          Validation Loss (standardized): 1.5459448487419174\n",
      "Epoch: 51, Loss (standarized): 0.4429024498503259\n",
      "          Validation Loss (standardized): 1.5444353927517147\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.4135233390230119\n",
      "          Validation Loss (standardized): 1.5273191096145198\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.38158009046585023\n",
      "          Validation Loss (standardized): 1.481218133360965\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.3493692959843712\n",
      "          Validation Loss (standardized): 1.4138322192586634\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.3187951112652284\n",
      "          Validation Loss (standardized): 1.3542612710738093\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.29288983946180325\n",
      "          Validation Loss (standardized): 1.3057652996592932\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.27251671717002507\n",
      "          Validation Loss (standardized): 1.265455153185555\n",
      "Epoch: 86, Loss (standarized): 0.25731795023159304\n",
      "          Validation Loss (standardized): 1.2297749553578952\n",
      "Epoch: 91, Loss (standarized): 0.24648661649750914\n",
      "          Validation Loss (standardized): 1.1972429882467246\n",
      "Epoch: 96, Loss (standarized): 0.2389398831749111\n",
      "          Validation Loss (standardized): 1.1732654553052475\n",
      "Final epoch: 100, Final loss (standarized): 0.23470095347451375\n",
      "Epoch: 1, Loss (standarized): 1.2114030137238485\n",
      "          Validation Loss (standardized): 1.219198340310309\n",
      "Epoch: 6, Loss (standarized): 0.733830815015915\n",
      "          Validation Loss (standardized): 1.6597199355307422\n",
      "Epoch: 11, Loss (standarized): 0.6849054562629912\n",
      "          Validation Loss (standardized): 2.1784844722122374\n",
      "Epoch: 16, Loss (standarized): 0.6614149649444028\n",
      "          Validation Loss (standardized): 2.2656553869436418\n",
      "Epoch: 21, Loss (standarized): 0.622368549030403\n",
      "          Validation Loss (standardized): 2.0897098584017972\n",
      "Epoch: 26, Loss (standarized): 0.5908403414085218\n",
      "          Validation Loss (standardized): 1.824596832692861\n",
      "Epoch: 31, Loss (standarized): 0.5546454614754572\n",
      "          Validation Loss (standardized): 1.6707323226546629\n",
      "Epoch: 36, Loss (standarized): 0.5123512163977669\n",
      "          Validation Loss (standardized): 1.6509370404832557\n",
      "Epoch: 41, Loss (standarized): 0.4677614797043744\n",
      "          Validation Loss (standardized): 1.6966077614492079\n",
      "Epoch: 46, Loss (standarized): 0.42214446377048565\n",
      "          Validation Loss (standardized): 1.6905038499779292\n",
      "Epoch: 51, Loss (standarized): 0.3753517535438781\n",
      "          Validation Loss (standardized): 1.6105652091501879\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.3307163209588193\n",
      "          Validation Loss (standardized): 1.5018411171173094\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.29071229641095314\n",
      "          Validation Loss (standardized): 1.4213547603225398\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.25699884340025503\n",
      "          Validation Loss (standardized): 1.3609377996821186\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.23025455638930334\n",
      "          Validation Loss (standardized): 1.2918972638241164\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.2092484232678872\n",
      "          Validation Loss (standardized): 1.2112724485279596\n",
      "Epoch: 81, Loss (standarized): 0.1917369183361258\n",
      "          Validation Loss (standardized): 1.1353332153779934\n",
      "Epoch: 86, Loss (standarized): 0.17705941470212005\n",
      "          Validation Loss (standardized): 1.0730115412342103\n",
      "Epoch: 91, Loss (standarized): 0.16468032465002472\n",
      "          Validation Loss (standardized): 1.0077813866254068\n",
      "Epoch: 96, Loss (standarized): 0.1541466031389888\n",
      "          Validation Loss (standardized): 0.9560864904076553\n",
      "Final epoch: 100, Final loss (standarized): 0.14678047701162739\n",
      "Epoch: 1, Loss (standarized): 1.2850285612415457\n",
      "          Validation Loss (standardized): 1.3180567914377712\n",
      "Epoch: 6, Loss (standarized): 0.7052121161865265\n",
      "          Validation Loss (standardized): 1.7101319656525817\n",
      "Epoch: 11, Loss (standarized): 0.6585723524374586\n",
      "          Validation Loss (standardized): 2.0735344309997825\n",
      "Epoch: 16, Loss (standarized): 0.6255886742882966\n",
      "          Validation Loss (standardized): 2.183997757185775\n",
      "Epoch: 21, Loss (standarized): 0.5898874314600591\n",
      "          Validation Loss (standardized): 2.1213334720451136\n",
      "Epoch: 26, Loss (standarized): 0.5536853507772836\n",
      "          Validation Loss (standardized): 1.9504470940575418\n",
      "Epoch: 31, Loss (standarized): 0.5127029653479248\n",
      "          Validation Loss (standardized): 1.7501522155035123\n",
      "Epoch: 36, Loss (standarized): 0.47090724499591896\n",
      "          Validation Loss (standardized): 1.5971148253356533\n",
      "Epoch: 41, Loss (standarized): 0.4276795247161905\n",
      "          Validation Loss (standardized): 1.517556201388014\n",
      "Epoch: 46, Loss (standarized): 0.38559025176981\n",
      "          Validation Loss (standardized): 1.473025523264016\n",
      "Epoch: 51, Loss (standarized): 0.3453566680218993\n",
      "          Validation Loss (standardized): 1.4236118173831909\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.3063929337024069\n",
      "          Validation Loss (standardized): 1.361912952156139\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.27032482791734713\n",
      "          Validation Loss (standardized): 1.296164043470539\n",
      "Epoch: 66, Loss (standarized): 0.23821976481518004\n",
      "          Validation Loss (standardized): 1.2203517000985056\n",
      "Epoch: 71, Loss (standarized): 0.21243929389438965\n",
      "          Validation Loss (standardized): 1.1665711473934397\n",
      "Epoch: 76, Loss (standarized): 0.19204862251268695\n",
      "          Validation Loss (standardized): 1.0855945054046539\n",
      "Epoch: 81, Loss (standarized): 0.17536818358393366\n",
      "          Validation Loss (standardized): 1.0348256016322412\n",
      "Epoch: 86, Loss (standarized): 0.16144421132902517\n",
      "          Validation Loss (standardized): 0.9908564159835969\n",
      "Epoch: 91, Loss (standarized): 0.14994067464167019\n",
      "          Validation Loss (standardized): 0.9369817600011638\n",
      "Epoch: 96, Loss (standarized): 0.14027539768531533\n",
      "          Validation Loss (standardized): 0.8982260917591384\n",
      "Final epoch: 100, Final loss (standarized): 0.13359889783274181\n",
      "Epoch: 1, Loss (standarized): 1.6047505216461002\n",
      "          Validation Loss (standardized): 1.5238015032290517\n",
      "Epoch: 6, Loss (standarized): 0.8389857954770847\n",
      "          Validation Loss (standardized): 1.7364297161275333\n",
      "Epoch: 11, Loss (standarized): 0.689645701092253\n",
      "          Validation Loss (standardized): 2.2394446557482897\n",
      "Epoch: 16, Loss (standarized): 0.6711490702057196\n",
      "          Validation Loss (standardized): 2.4381303518173327\n",
      "Epoch: 21, Loss (standarized): 0.628953583066902\n",
      "          Validation Loss (standardized): 2.2631346880693655\n",
      "Epoch: 26, Loss (standarized): 0.6018934867928014\n",
      "          Validation Loss (standardized): 1.923212497113432\n",
      "Epoch: 31, Loss (standarized): 0.571404447917977\n",
      "          Validation Loss (standardized): 1.691664262198769\n",
      "Epoch: 36, Loss (standarized): 0.547774545973987\n",
      "          Validation Loss (standardized): 1.6043428735549878\n",
      "Epoch: 41, Loss (standarized): 0.5212838969851993\n",
      "          Validation Loss (standardized): 1.5960733206919595\n",
      "Epoch: 46, Loss (standarized): 0.49427615320461066\n",
      "          Validation Loss (standardized): 1.6217905639533174\n",
      "Epoch: 51, Loss (standarized): 0.4667416419827113\n",
      "          Validation Loss (standardized): 1.6335889905455443\n",
      "Epoch: 56, Loss (standarized): 0.4351865172569584\n",
      "          Validation Loss (standardized): 1.5615394361206776\n",
      "Epoch: 61, Loss (standarized): 0.39827883848390744\n",
      "          Validation Loss (standardized): 1.4592559420446014\n",
      "Epoch: 66, Loss (standarized): 0.3606571599108275\n",
      "          Validation Loss (standardized): 1.4185550219991758\n",
      "Epoch: 71, Loss (standarized): 0.3273136549401075\n",
      "          Validation Loss (standardized): 1.412840943717773\n",
      "Epoch: 76, Loss (standarized): 0.29746862579433864\n",
      "          Validation Loss (standardized): 1.394828236251317\n",
      "Epoch: 81, Loss (standarized): 0.2704078179416702\n",
      "          Validation Loss (standardized): 1.299545525334405\n",
      "Epoch: 86, Loss (standarized): 0.24673309340905794\n",
      "          Validation Loss (standardized): 1.2543884319524614\n",
      "Epoch: 91, Loss (standarized): 0.22636218699347815\n",
      "          Validation Loss (standardized): 1.1995711341433375\n",
      "Epoch: 96, Loss (standarized): 0.2084607226678768\n",
      "          Validation Loss (standardized): 1.1295706851609482\n",
      "Final epoch: 100, Final loss (standarized): 0.19596354312455297\n",
      "Epoch: 1, Loss (standarized): 1.8268032502259426\n",
      "          Validation Loss (standardized): 1.9294422901914614\n",
      "Epoch: 6, Loss (standarized): 0.7270477525976234\n",
      "          Validation Loss (standardized): 1.728339947908934\n",
      "Epoch: 11, Loss (standarized): 0.7777799128884186\n",
      "          Validation Loss (standardized): 2.180604661845123\n",
      "Epoch: 16, Loss (standarized): 0.6659396170617655\n",
      "          Validation Loss (standardized): 2.1074646389569565\n",
      "Epoch: 21, Loss (standarized): 0.6334982542375449\n",
      "          Validation Loss (standardized): 1.9224503804749848\n",
      "Epoch: 26, Loss (standarized): 0.6110810325928726\n",
      "          Validation Loss (standardized): 1.7473298716674248\n",
      "Epoch: 31, Loss (standarized): 0.5707773696610318\n",
      "          Validation Loss (standardized): 1.627088639239386\n",
      "Epoch: 36, Loss (standarized): 0.547248905517893\n",
      "          Validation Loss (standardized): 1.6002506284059836\n",
      "Epoch: 41, Loss (standarized): 0.521736612583503\n",
      "          Validation Loss (standardized): 1.5688553708417305\n",
      "Epoch: 46, Loss (standarized): 0.4957350975995482\n",
      "          Validation Loss (standardized): 1.5485150897303621\n",
      "Epoch: 51, Loss (standarized): 0.4731020015606902\n",
      "          Validation Loss (standardized): 1.5259769973194373\n",
      "Epoch: 56, Loss (standarized): 0.4479284408004629\n",
      "          Validation Loss (standardized): 1.4846065722334132\n",
      "Epoch: 61, Loss (standarized): 0.4211616683982343\n",
      "          Validation Loss (standardized): 1.431672499511211\n",
      "Epoch: 66, Loss (standarized): 0.39321307037079123\n",
      "          Validation Loss (standardized): 1.3970919678431424\n",
      "Epoch: 71, Loss (standarized): 0.3635382334885271\n",
      "          Validation Loss (standardized): 1.3837752465589026\n",
      "Epoch: 76, Loss (standarized): 0.3371766306064531\n",
      "          Validation Loss (standardized): 1.362319194988633\n",
      "Epoch: 81, Loss (standarized): 0.3129516165765249\n",
      "          Validation Loss (standardized): 1.3288144871752892\n",
      "Epoch: 86, Loss (standarized): 0.2918032444783813\n",
      "          Validation Loss (standardized): 1.2963128513536553\n",
      "Epoch: 91, Loss (standarized): 0.27460762084142726\n",
      "          Validation Loss (standardized): 1.2779006867136036\n",
      "Epoch: 96, Loss (standarized): 0.25977589251342126\n",
      "          Validation Loss (standardized): 1.2639627323724196\n",
      "Final epoch: 100, Final loss (standarized): 0.25122858030342027\n",
      "Epoch: 1, Loss (standarized): 1.2888730293475579\n",
      "          Validation Loss (standardized): 1.3194382513601608\n",
      "Epoch: 6, Loss (standarized): 0.8743047251267904\n",
      "          Validation Loss (standardized): 1.5189456195150783\n",
      "Epoch: 11, Loss (standarized): 0.7138119967733372\n",
      "          Validation Loss (standardized): 1.7861427495545\n",
      "Epoch: 16, Loss (standarized): 0.6747798573955851\n",
      "          Validation Loss (standardized): 2.0239723246971324\n",
      "Epoch: 21, Loss (standarized): 0.6332922214765273\n",
      "          Validation Loss (standardized): 2.080894795526807\n",
      "Epoch: 26, Loss (standarized): 0.591187747588346\n",
      "          Validation Loss (standardized): 1.9724258925574194\n",
      "Epoch: 31, Loss (standarized): 0.5558545493726422\n",
      "          Validation Loss (standardized): 1.8090402652538857\n",
      "Epoch: 36, Loss (standarized): 0.5164807035381593\n",
      "          Validation Loss (standardized): 1.6395716699045744\n",
      "Epoch: 41, Loss (standarized): 0.4769131320804495\n",
      "          Validation Loss (standardized): 1.5377952710201106\n",
      "Epoch: 46, Loss (standarized): 0.4371335154521751\n",
      "          Validation Loss (standardized): 1.5070654582319016\n",
      "Epoch: 51, Loss (standarized): 0.39592368052531435\n",
      "          Validation Loss (standardized): 1.496146832017024\n",
      "Epoch: 56, Loss (standarized): 0.3540976156841511\n",
      "          Validation Loss (standardized): 1.4566752138769459\n",
      "Epoch: 61, Loss (standarized): 0.31570876936539927\n",
      "          Validation Loss (standardized): 1.3900553223635734\n",
      "Epoch: 66, Loss (standarized): 0.2831045311597796\n",
      "          Validation Loss (standardized): 1.3292196673516132\n",
      "Epoch: 71, Loss (standarized): 0.25404094690940454\n",
      "          Validation Loss (standardized): 1.2657082592062752\n",
      "Epoch: 76, Loss (standarized): 0.22954255310305452\n",
      "          Validation Loss (standardized): 1.1823274934337338\n",
      "Epoch: 81, Loss (standarized): 0.2090756437846328\n",
      "          Validation Loss (standardized): 1.1052819168019299\n",
      "Epoch: 86, Loss (standarized): 0.19285640260916365\n",
      "          Validation Loss (standardized): 1.0219754019570648\n",
      "Epoch: 91, Loss (standarized): 0.17999931068589148\n",
      "          Validation Loss (standardized): 0.9640600685305124\n",
      "Epoch: 96, Loss (standarized): 0.16906365545265303\n",
      "          Validation Loss (standardized): 0.9175938537090235\n",
      "Final epoch: 100, Final loss (standarized): 0.16139343651205754\n",
      "Epoch: 1, Loss (standarized): 1.6126616311904436\n",
      "          Validation Loss (standardized): 1.1215851761975015\n",
      "Epoch: 6, Loss (standarized): 0.7155091687574258\n",
      "          Validation Loss (standardized): 1.9023636174494123\n",
      "Epoch: 11, Loss (standarized): 0.7149443431979\n",
      "          Validation Loss (standardized): 2.654469869757354\n",
      "Epoch: 16, Loss (standarized): 0.7038181811990478\n",
      "          Validation Loss (standardized): 2.7630467493482875\n",
      "Epoch: 21, Loss (standarized): 0.6740270256590276\n",
      "          Validation Loss (standardized): 2.5180678887330714\n",
      "Epoch: 26, Loss (standarized): 0.6365019459822387\n",
      "          Validation Loss (standardized): 2.2216117066238885\n",
      "Epoch: 31, Loss (standarized): 0.611347837458543\n",
      "          Validation Loss (standardized): 1.9132456821298374\n",
      "Epoch: 36, Loss (standarized): 0.5871066203082499\n",
      "          Validation Loss (standardized): 1.6735367350976196\n",
      "Epoch: 41, Loss (standarized): 0.5654826011882739\n",
      "          Validation Loss (standardized): 1.5850711381427913\n",
      "Epoch: 46, Loss (standarized): 0.5426448170619491\n",
      "          Validation Loss (standardized): 1.583615203519063\n",
      "Epoch: 51, Loss (standarized): 0.5184224636987418\n",
      "          Validation Loss (standardized): 1.621040668569771\n",
      "Epoch: 56, Loss (standarized): 0.49500867069959287\n",
      "          Validation Loss (standardized): 1.6822530410759968\n",
      "Epoch: 61, Loss (standarized): 0.47115909184435223\n",
      "          Validation Loss (standardized): 1.69435155028279\n",
      "Epoch: 66, Loss (standarized): 0.4452662443137535\n",
      "          Validation Loss (standardized): 1.6524242553369435\n",
      "Epoch: 71, Loss (standarized): 0.4177380028705045\n",
      "          Validation Loss (standardized): 1.5933889575609987\n",
      "Epoch: 76, Loss (standarized): 0.38984507478764413\n",
      "          Validation Loss (standardized): 1.540489089467091\n",
      "Epoch: 81, Loss (standarized): 0.3616790362988464\n",
      "          Validation Loss (standardized): 1.5291075521428639\n",
      "Epoch: 86, Loss (standarized): 0.33454472794606827\n",
      "          Validation Loss (standardized): 1.522125131543031\n",
      "Epoch: 91, Loss (standarized): 0.3096778551473633\n",
      "          Validation Loss (standardized): 1.5015496153236698\n",
      "Epoch: 96, Loss (standarized): 0.2867633153383425\n",
      "          Validation Loss (standardized): 1.4521216821340945\n",
      "Final epoch: 100, Final loss (standarized): 0.2696153961248549\n",
      "Epoch: 1, Loss (standarized): 0.9867836482985337\n",
      "          Validation Loss (standardized): 2.1498924217447675\n",
      "Epoch: 6, Loss (standarized): 0.7452444701218065\n",
      "          Validation Loss (standardized): 2.2412702140342615\n",
      "Epoch: 11, Loss (standarized): 0.6850076375937743\n",
      "          Validation Loss (standardized): 2.0921769090042552\n",
      "Epoch: 16, Loss (standarized): 0.6540260899533563\n",
      "          Validation Loss (standardized): 1.9085725410830137\n",
      "Epoch: 21, Loss (standarized): 0.6278884034678652\n",
      "          Validation Loss (standardized): 1.7122199540089413\n",
      "Epoch: 26, Loss (standarized): 0.609661679477527\n",
      "          Validation Loss (standardized): 1.603708589383241\n",
      "Epoch: 31, Loss (standarized): 0.5986600967483459\n",
      "          Validation Loss (standardized): 1.5817805662491777\n",
      "Epoch: 36, Loss (standarized): 0.5891367824021714\n",
      "          Validation Loss (standardized): 1.5907621780589898\n",
      "Epoch: 41, Loss (standarized): 0.5798143821290627\n",
      "          Validation Loss (standardized): 1.6163813495930717\n",
      "Epoch: 46, Loss (standarized): 0.5689904480021817\n",
      "          Validation Loss (standardized): 1.6034304774379533\n",
      "Epoch: 51, Loss (standarized): 0.5574088363489594\n",
      "          Validation Loss (standardized): 1.5734206300371694\n",
      "Epoch: 56, Loss (standarized): 0.5487046617175881\n",
      "          Validation Loss (standardized): 1.5638032872704897\n",
      "Epoch: 61, Loss (standarized): 0.5389666649868836\n",
      "          Validation Loss (standardized): 1.573920092152637\n",
      "Epoch: 66, Loss (standarized): 0.5279546173145594\n",
      "          Validation Loss (standardized): 1.581410956025018\n",
      "Epoch: 71, Loss (standarized): 0.5169052406873498\n",
      "          Validation Loss (standardized): 1.5843803148299735\n",
      "Epoch: 76, Loss (standarized): 0.5041181867333574\n",
      "          Validation Loss (standardized): 1.5832006418798337\n",
      "Epoch: 81, Loss (standarized): 0.4902303524177126\n",
      "          Validation Loss (standardized): 1.5968606426201786\n",
      "Epoch: 86, Loss (standarized): 0.47598386300253165\n",
      "          Validation Loss (standardized): 1.6053180901888269\n",
      "Epoch: 91, Loss (standarized): 0.4627534459128935\n",
      "          Validation Loss (standardized): 1.608060083904757\n",
      "Epoch: 96, Loss (standarized): 0.4496510419081412\n",
      "          Validation Loss (standardized): 1.611368494876398\n",
      "Final epoch: 100, Final loss (standarized): 0.4390742800870757\n",
      "Epoch: 1, Loss (standarized): 1.2819659315416034\n",
      "          Validation Loss (standardized): 1.3179837999194284\n",
      "Epoch: 6, Loss (standarized): 0.7969753103291501\n",
      "          Validation Loss (standardized): 1.4006394551771628\n",
      "Epoch: 11, Loss (standarized): 0.7208362894350853\n",
      "          Validation Loss (standardized): 1.6762139758468322\n",
      "Epoch: 16, Loss (standarized): 0.6982121636216667\n",
      "          Validation Loss (standardized): 1.7655665818999056\n",
      "Epoch: 21, Loss (standarized): 0.6770571677319944\n",
      "          Validation Loss (standardized): 1.7144505465365818\n",
      "Epoch: 26, Loss (standarized): 0.6673908632043312\n",
      "          Validation Loss (standardized): 1.6450109346119832\n",
      "Epoch: 31, Loss (standarized): 0.6557064787702461\n",
      "          Validation Loss (standardized): 1.599816746895055\n",
      "Epoch: 36, Loss (standarized): 0.641955662028478\n",
      "          Validation Loss (standardized): 1.5881130108338644\n",
      "Epoch: 41, Loss (standarized): 0.6274759291575377\n",
      "          Validation Loss (standardized): 1.574835835048387\n",
      "Epoch: 46, Loss (standarized): 0.6129793418772086\n",
      "          Validation Loss (standardized): 1.5490335174604206\n",
      "Epoch: 51, Loss (standarized): 0.5995574485118671\n",
      "          Validation Loss (standardized): 1.5310742204413967\n",
      "Epoch: 56, Loss (standarized): 0.5863478941730504\n",
      "          Validation Loss (standardized): 1.5344225960087106\n",
      "Epoch: 61, Loss (standarized): 0.5722814392611741\n",
      "          Validation Loss (standardized): 1.536910974320987\n",
      "Epoch: 66, Loss (standarized): 0.559448115068188\n",
      "          Validation Loss (standardized): 1.5309995218966195\n",
      "Epoch: 71, Loss (standarized): 0.5480898538603564\n",
      "          Validation Loss (standardized): 1.5308239156858068\n",
      "Epoch: 76, Loss (standarized): 0.5378003514403362\n",
      "          Validation Loss (standardized): 1.537338486648979\n",
      "Epoch: 81, Loss (standarized): 0.5282187035343785\n",
      "          Validation Loss (standardized): 1.555348903640037\n",
      "Epoch: 86, Loss (standarized): 0.5199747655249787\n",
      "          Validation Loss (standardized): 1.566439965989814\n",
      "Epoch: 91, Loss (standarized): 0.5135016055198316\n",
      "          Validation Loss (standardized): 1.5721170778470603\n",
      "Epoch: 96, Loss (standarized): 0.5081569424286512\n",
      "          Validation Loss (standardized): 1.577933640473582\n",
      "Final epoch: 100, Final loss (standarized): 0.5042962862634117\n",
      "Epoch: 1, Loss (standarized): 1.8432073456396236\n",
      "          Validation Loss (standardized): 1.1806279043762784\n",
      "Epoch: 6, Loss (standarized): 0.8000346608980838\n",
      "          Validation Loss (standardized): 1.595671756046364\n",
      "Epoch: 11, Loss (standarized): 0.7040282880450155\n",
      "          Validation Loss (standardized): 2.000081433702282\n",
      "Epoch: 16, Loss (standarized): 0.6698636269861483\n",
      "          Validation Loss (standardized): 2.111232090502094\n",
      "Epoch: 21, Loss (standarized): 0.6427822756452385\n",
      "          Validation Loss (standardized): 2.0880452071195714\n",
      "Epoch: 26, Loss (standarized): 0.6284117338244661\n",
      "          Validation Loss (standardized): 2.025313476722669\n",
      "Epoch: 31, Loss (standarized): 0.6167461475495235\n",
      "          Validation Loss (standardized): 1.9318839450806315\n",
      "Epoch: 36, Loss (standarized): 0.6031111809090551\n",
      "          Validation Loss (standardized): 1.831737206994486\n",
      "Epoch: 41, Loss (standarized): 0.5910431373117917\n",
      "          Validation Loss (standardized): 1.7375960433386388\n",
      "Epoch: 46, Loss (standarized): 0.5822599346657318\n",
      "          Validation Loss (standardized): 1.6668376633824626\n",
      "Epoch: 51, Loss (standarized): 0.5741935838621386\n",
      "          Validation Loss (standardized): 1.612292229474971\n",
      "Epoch: 56, Loss (standarized): 0.5659560317105626\n",
      "          Validation Loss (standardized): 1.5893651321114586\n",
      "Epoch: 61, Loss (standarized): 0.5576717107694037\n",
      "          Validation Loss (standardized): 1.594842778184029\n",
      "Epoch: 66, Loss (standarized): 0.5500243312498895\n",
      "          Validation Loss (standardized): 1.5976948499675099\n",
      "Epoch: 71, Loss (standarized): 0.5426740441348653\n",
      "          Validation Loss (standardized): 1.587053166595486\n",
      "Epoch: 76, Loss (standarized): 0.5364848683865221\n",
      "          Validation Loss (standardized): 1.590006922383454\n",
      "Epoch: 81, Loss (standarized): 0.5305906919664558\n",
      "          Validation Loss (standardized): 1.5971552850003596\n",
      "Epoch: 86, Loss (standarized): 0.5249724040684073\n",
      "          Validation Loss (standardized): 1.6089046727708036\n",
      "Epoch: 91, Loss (standarized): 0.5196637485307538\n",
      "          Validation Loss (standardized): 1.6061367511402893\n",
      "Epoch: 96, Loss (standarized): 0.5145823404962432\n",
      "          Validation Loss (standardized): 1.6032556049229374\n",
      "Final epoch: 100, Final loss (standarized): 0.5105429595008844\n",
      "Epoch: 1, Loss (standarized): 2.3125849924203616\n",
      "          Validation Loss (standardized): 1.3878457913483557\n",
      "Epoch: 6, Loss (standarized): 1.0940027114447177\n",
      "          Validation Loss (standardized): 1.3030825418802423\n",
      "Epoch: 11, Loss (standarized): 0.7477448884833771\n",
      "          Validation Loss (standardized): 1.6772082115850973\n",
      "Epoch: 16, Loss (standarized): 0.7111820812620894\n",
      "          Validation Loss (standardized): 1.9867100938660955\n",
      "Epoch: 21, Loss (standarized): 0.6793732861051005\n",
      "          Validation Loss (standardized): 2.023695777333251\n",
      "Epoch: 26, Loss (standarized): 0.6593834850881173\n",
      "          Validation Loss (standardized): 1.931962184110734\n",
      "Epoch: 31, Loss (standarized): 0.6424978815151865\n",
      "          Validation Loss (standardized): 1.814169505944388\n",
      "Epoch: 36, Loss (standarized): 0.6235974894876585\n",
      "          Validation Loss (standardized): 1.7297601862153065\n",
      "Epoch: 41, Loss (standarized): 0.6055559154842199\n",
      "          Validation Loss (standardized): 1.6650412996417985\n",
      "Epoch: 46, Loss (standarized): 0.5916321413794968\n",
      "          Validation Loss (standardized): 1.6163577760267882\n",
      "Epoch: 51, Loss (standarized): 0.5830560027177523\n",
      "          Validation Loss (standardized): 1.5935558159105772\n",
      "Epoch: 56, Loss (standarized): 0.5736504138155072\n",
      "          Validation Loss (standardized): 1.58088413611944\n",
      "Epoch: 61, Loss (standarized): 0.5626008855013577\n",
      "          Validation Loss (standardized): 1.5771144826793966\n",
      "Epoch: 66, Loss (standarized): 0.5506812599255796\n",
      "          Validation Loss (standardized): 1.5716312241696633\n",
      "Epoch: 71, Loss (standarized): 0.539900400659222\n",
      "          Validation Loss (standardized): 1.5597117291012896\n",
      "Epoch: 76, Loss (standarized): 0.5284782025257047\n",
      "          Validation Loss (standardized): 1.5560047398695906\n",
      "Epoch: 81, Loss (standarized): 0.5143274312256518\n",
      "          Validation Loss (standardized): 1.5638377098512253\n",
      "Epoch: 86, Loss (standarized): 0.5015282289239703\n",
      "          Validation Loss (standardized): 1.5692051554626851\n",
      "Epoch: 91, Loss (standarized): 0.4886712350634427\n",
      "          Validation Loss (standardized): 1.5647207358431843\n",
      "Epoch: 96, Loss (standarized): 0.4764885743235904\n",
      "          Validation Loss (standardized): 1.5714617886684488\n",
      "Final epoch: 100, Final loss (standarized): 0.4676528642972912\n",
      "Epoch: 1, Loss (standarized): 2.187699406184209\n",
      "          Validation Loss (standardized): 1.2320507249747539\n",
      "Epoch: 6, Loss (standarized): 0.9940548380140954\n",
      "          Validation Loss (standardized): 1.33707390711753\n",
      "Epoch: 11, Loss (standarized): 0.7034291056011409\n",
      "          Validation Loss (standardized): 1.782865895223722\n",
      "Epoch: 16, Loss (standarized): 0.6440121904456092\n",
      "          Validation Loss (standardized): 2.0932720398074935\n",
      "Epoch: 21, Loss (standarized): 0.6149640352189275\n",
      "          Validation Loss (standardized): 2.1943231352334633\n",
      "Epoch: 26, Loss (standarized): 0.592135168817374\n",
      "          Validation Loss (standardized): 2.1594628730485885\n",
      "Epoch: 31, Loss (standarized): 0.5671956301172019\n",
      "          Validation Loss (standardized): 2.0394524359441757\n",
      "Epoch: 36, Loss (standarized): 0.5370288150753363\n",
      "          Validation Loss (standardized): 1.8848834021976706\n",
      "Epoch: 41, Loss (standarized): 0.5083008972644434\n",
      "          Validation Loss (standardized): 1.752253702849835\n",
      "Epoch: 46, Loss (standarized): 0.4815494305631184\n",
      "          Validation Loss (standardized): 1.6643795636037688\n",
      "Epoch: 51, Loss (standarized): 0.45684463466790215\n",
      "          Validation Loss (standardized): 1.6226181511168078\n",
      "Epoch: 56, Loss (standarized): 0.43176962234767186\n",
      "          Validation Loss (standardized): 1.6051394607065195\n",
      "Epoch: 61, Loss (standarized): 0.40848570266898726\n",
      "          Validation Loss (standardized): 1.5858654620886146\n",
      "Epoch: 66, Loss (standarized): 0.383365327294485\n",
      "          Validation Loss (standardized): 1.5494036074302522\n",
      "Epoch: 71, Loss (standarized): 0.3565293927997726\n",
      "          Validation Loss (standardized): 1.5070579065773415\n",
      "Epoch: 76, Loss (standarized): 0.3286976269187028\n",
      "          Validation Loss (standardized): 1.4619152412253027\n",
      "Epoch: 81, Loss (standarized): 0.30075634463312606\n",
      "          Validation Loss (standardized): 1.4187211793526686\n",
      "Epoch: 86, Loss (standarized): 0.27485632368602053\n",
      "          Validation Loss (standardized): 1.3789625888696473\n",
      "Epoch: 91, Loss (standarized): 0.2517793957780133\n",
      "          Validation Loss (standardized): 1.3503644389573193\n",
      "Epoch: 96, Loss (standarized): 0.23250201572506773\n",
      "          Validation Loss (standardized): 1.3265888552812135\n",
      "Final epoch: 100, Final loss (standarized): 0.21972680582945636\n",
      "Epoch: 1, Loss (standarized): 1.504175139452267\n",
      "          Validation Loss (standardized): 1.4417722713586087\n",
      "Epoch: 6, Loss (standarized): 0.8669078840055372\n",
      "          Validation Loss (standardized): 1.6756206151902597\n",
      "Epoch: 11, Loss (standarized): 0.6977338833485364\n",
      "          Validation Loss (standardized): 1.914602688635222\n",
      "Epoch: 16, Loss (standarized): 0.6429442540589216\n",
      "          Validation Loss (standardized): 1.964233821895506\n",
      "Epoch: 21, Loss (standarized): 0.6039233757636968\n",
      "          Validation Loss (standardized): 1.8183157610448206\n",
      "Epoch: 26, Loss (standarized): 0.5752831373104463\n",
      "          Validation Loss (standardized): 1.643695024942996\n",
      "Epoch: 31, Loss (standarized): 0.5515996143749148\n",
      "          Validation Loss (standardized): 1.5445056385761944\n",
      "Epoch: 36, Loss (standarized): 0.5207080687072122\n",
      "          Validation Loss (standardized): 1.5381328685799063\n",
      "Epoch: 41, Loss (standarized): 0.4866866262276375\n",
      "          Validation Loss (standardized): 1.5785055229963674\n",
      "Epoch: 46, Loss (standarized): 0.4548077247555923\n",
      "          Validation Loss (standardized): 1.5959836765612605\n",
      "Epoch: 51, Loss (standarized): 0.4238246821061305\n",
      "          Validation Loss (standardized): 1.5629521632695242\n",
      "Epoch: 56, Loss (standarized): 0.3939853728740848\n",
      "          Validation Loss (standardized): 1.5064507077858786\n",
      "Epoch: 61, Loss (standarized): 0.36679418092818367\n",
      "          Validation Loss (standardized): 1.4460370913702663\n",
      "Epoch: 66, Loss (standarized): 0.34290336212625505\n",
      "          Validation Loss (standardized): 1.41036603001965\n",
      "Epoch: 71, Loss (standarized): 0.321611591486739\n",
      "          Validation Loss (standardized): 1.4036301407948695\n",
      "Epoch: 76, Loss (standarized): 0.30287571517829104\n",
      "          Validation Loss (standardized): 1.3817899117144417\n",
      "Epoch: 81, Loss (standarized): 0.28669587514312417\n",
      "          Validation Loss (standardized): 1.3477809630256994\n",
      "Epoch: 86, Loss (standarized): 0.27359278546802085\n",
      "          Validation Loss (standardized): 1.3067074423314957\n",
      "Epoch: 91, Loss (standarized): 0.2631573519148423\n",
      "          Validation Loss (standardized): 1.2816543268991494\n",
      "Epoch: 96, Loss (standarized): 0.2549166275436449\n",
      "          Validation Loss (standardized): 1.2621027545822225\n",
      "Final epoch: 100, Final loss (standarized): 0.24972694320942793\n",
      "Epoch: 1, Loss (standarized): 2.188712588880092\n",
      "          Validation Loss (standardized): 1.1407974529595017\n",
      "Epoch: 6, Loss (standarized): 0.8610183836545378\n",
      "          Validation Loss (standardized): 1.1874645401182666\n",
      "Epoch: 11, Loss (standarized): 0.6587504905122996\n",
      "          Validation Loss (standardized): 1.8080982987035654\n",
      "Epoch: 16, Loss (standarized): 0.654001589996582\n",
      "          Validation Loss (standardized): 2.235091472307859\n",
      "Epoch: 21, Loss (standarized): 0.642162740697264\n",
      "          Validation Loss (standardized): 2.364994514483154\n",
      "Epoch: 26, Loss (standarized): 0.618159209818172\n",
      "          Validation Loss (standardized): 2.3040812802913204\n",
      "Epoch: 31, Loss (standarized): 0.5900454322579349\n",
      "          Validation Loss (standardized): 2.1532769751158978\n",
      "Epoch: 36, Loss (standarized): 0.5603870418510002\n",
      "          Validation Loss (standardized): 1.9892308030627717\n",
      "Epoch: 41, Loss (standarized): 0.53082383618692\n",
      "          Validation Loss (standardized): 1.855156882569268\n",
      "Epoch: 46, Loss (standarized): 0.5007765545913663\n",
      "          Validation Loss (standardized): 1.7642847063371132\n",
      "Epoch: 51, Loss (standarized): 0.46911035270128987\n",
      "          Validation Loss (standardized): 1.713106432573072\n",
      "Epoch: 56, Loss (standarized): 0.4373108488409586\n",
      "          Validation Loss (standardized): 1.685907063520596\n",
      "Epoch: 61, Loss (standarized): 0.4069635384476817\n",
      "          Validation Loss (standardized): 1.6699454558807962\n",
      "Epoch: 66, Loss (standarized): 0.37819200466081393\n",
      "          Validation Loss (standardized): 1.664172113195435\n",
      "Epoch: 71, Loss (standarized): 0.3521133501580352\n",
      "          Validation Loss (standardized): 1.6626030967681504\n",
      "Epoch: 76, Loss (standarized): 0.3287170530545046\n",
      "          Validation Loss (standardized): 1.658148256459675\n",
      "Epoch: 81, Loss (standarized): 0.30772375656714424\n",
      "          Validation Loss (standardized): 1.6397580605099547\n",
      "Epoch: 86, Loss (standarized): 0.2886082353789501\n",
      "          Validation Loss (standardized): 1.6070202934036835\n",
      "Epoch: 91, Loss (standarized): 0.27069888303509104\n",
      "          Validation Loss (standardized): 1.5637463080896286\n",
      "Epoch: 96, Loss (standarized): 0.2548118696602999\n",
      "          Validation Loss (standardized): 1.5125924135587174\n",
      "Final epoch: 100, Final loss (standarized): 0.24450090463456126\n",
      "Epoch: 1, Loss (standarized): 1.2829296578740228\n",
      "          Validation Loss (standardized): 1.6098718088398634\n",
      "Epoch: 6, Loss (standarized): 0.745738037431389\n",
      "          Validation Loss (standardized): 1.8908056046164425\n",
      "Epoch: 11, Loss (standarized): 0.6968329760881661\n",
      "          Validation Loss (standardized): 2.107810755435722\n",
      "Epoch: 16, Loss (standarized): 0.6613416793870545\n",
      "          Validation Loss (standardized): 1.9704080558774921\n",
      "Epoch: 21, Loss (standarized): 0.6173413342741463\n",
      "          Validation Loss (standardized): 1.7321922384968094\n",
      "Epoch: 26, Loss (standarized): 0.5983709235792772\n",
      "          Validation Loss (standardized): 1.6156762574271633\n",
      "Epoch: 31, Loss (standarized): 0.5704976015762628\n",
      "          Validation Loss (standardized): 1.6208990177937652\n",
      "Epoch: 36, Loss (standarized): 0.541001469340904\n",
      "          Validation Loss (standardized): 1.658634660702382\n",
      "Epoch: 41, Loss (standarized): 0.5112946734817289\n",
      "          Validation Loss (standardized): 1.658479796081032\n",
      "Epoch: 46, Loss (standarized): 0.47651482224007397\n",
      "          Validation Loss (standardized): 1.5876092694911272\n",
      "Epoch: 51, Loss (standarized): 0.4398838976603419\n",
      "          Validation Loss (standardized): 1.4948375370697284\n",
      "Epoch: 56, Loss (standarized): 0.40114382002900517\n",
      "          Validation Loss (standardized): 1.4737406302389668\n",
      "Epoch: 61, Loss (standarized): 0.36289452664124244\n",
      "          Validation Loss (standardized): 1.4404922506803393\n",
      "Epoch: 66, Loss (standarized): 0.32557009809743614\n",
      "          Validation Loss (standardized): 1.383000431353202\n",
      "Epoch: 71, Loss (standarized): 0.2893089007292559\n",
      "          Validation Loss (standardized): 1.301531435079779\n",
      "Epoch: 76, Loss (standarized): 0.25935789429726847\n",
      "          Validation Loss (standardized): 1.2316252694582026\n",
      "Epoch: 81, Loss (standarized): 0.2342195433365942\n",
      "          Validation Loss (standardized): 1.1568066192530433\n",
      "Epoch: 86, Loss (standarized): 0.21389370651459672\n",
      "          Validation Loss (standardized): 1.1026079056631153\n",
      "Epoch: 91, Loss (standarized): 0.19744843963525074\n",
      "          Validation Loss (standardized): 1.0554022679700756\n",
      "Epoch: 96, Loss (standarized): 0.1837024254807841\n",
      "          Validation Loss (standardized): 1.0003332524739807\n",
      "Final epoch: 100, Final loss (standarized): 0.17439573557466143\n",
      "Epoch: 1, Loss (standarized): 1.0352847691754075\n",
      "          Validation Loss (standardized): 1.8002878226932337\n",
      "Epoch: 6, Loss (standarized): 0.7642794063671613\n",
      "          Validation Loss (standardized): 1.7710371309663433\n",
      "Epoch: 11, Loss (standarized): 0.675186961258652\n",
      "          Validation Loss (standardized): 1.8613369952169887\n",
      "Epoch: 16, Loss (standarized): 0.6504793217531708\n",
      "          Validation Loss (standardized): 1.7758471361169668\n",
      "Epoch: 21, Loss (standarized): 0.6349941462438067\n",
      "          Validation Loss (standardized): 1.7691765424178327\n",
      "Epoch: 26, Loss (standarized): 0.6105472024737131\n",
      "          Validation Loss (standardized): 1.8861687859840663\n",
      "Epoch: 31, Loss (standarized): 0.5847334422097756\n",
      "          Validation Loss (standardized): 1.8177042253091675\n",
      "Epoch: 36, Loss (standarized): 0.5574874678703372\n",
      "          Validation Loss (standardized): 1.6512737821945993\n",
      "Epoch: 41, Loss (standarized): 0.5229023885958167\n",
      "          Validation Loss (standardized): 1.5924741554892188\n",
      "Epoch: 46, Loss (standarized): 0.48263086420771767\n",
      "          Validation Loss (standardized): 1.561812952334431\n",
      "Epoch: 51, Loss (standarized): 0.4343743666070497\n",
      "          Validation Loss (standardized): 1.4756931161640967\n",
      "Epoch: 56, Loss (standarized): 0.38110752340067766\n",
      "          Validation Loss (standardized): 1.4457141978493409\n",
      "Epoch: 61, Loss (standarized): 0.32721318192218984\n",
      "          Validation Loss (standardized): 1.4056665835484703\n",
      "Epoch: 66, Loss (standarized): 0.2787476455836361\n",
      "          Validation Loss (standardized): 1.2796418533266232\n",
      "Epoch: 71, Loss (standarized): 0.2394960773282518\n",
      "          Validation Loss (standardized): 1.1673400785686314\n",
      "Epoch: 76, Loss (standarized): 0.2091540523448406\n",
      "          Validation Loss (standardized): 1.084650526665293\n",
      "Epoch: 81, Loss (standarized): 0.18572094951373774\n",
      "          Validation Loss (standardized): 1.0074797644573317\n",
      "Epoch: 86, Loss (standarized): 0.1664381421795479\n",
      "          Validation Loss (standardized): 0.9052370521721044\n",
      "Epoch: 91, Loss (standarized): 0.15053367358276823\n",
      "          Validation Loss (standardized): 0.8401843104721506\n",
      "Epoch: 96, Loss (standarized): 0.13699186089141213\n",
      "          Validation Loss (standardized): 0.7997793438906772\n",
      "Final epoch: 100, Final loss (standarized): 0.12763165115040442\n",
      "Epoch: 1, Loss (standarized): 1.949051996553412\n",
      "          Validation Loss (standardized): 1.5632563591811495\n",
      "Epoch: 6, Loss (standarized): 0.8800882012882575\n",
      "          Validation Loss (standardized): 1.4301225445760284\n",
      "Epoch: 11, Loss (standarized): 0.7779629837240716\n",
      "          Validation Loss (standardized): 1.746910331945966\n",
      "Epoch: 16, Loss (standarized): 0.7056980260133559\n",
      "          Validation Loss (standardized): 1.889052930930614\n",
      "Epoch: 21, Loss (standarized): 0.6671212352613572\n",
      "          Validation Loss (standardized): 1.9401755931447564\n",
      "Epoch: 26, Loss (standarized): 0.6511645823827875\n",
      "          Validation Loss (standardized): 1.8903607952292194\n",
      "Epoch: 31, Loss (standarized): 0.6338827128691239\n",
      "          Validation Loss (standardized): 1.7849453798162227\n",
      "Epoch: 36, Loss (standarized): 0.6225251719495787\n",
      "          Validation Loss (standardized): 1.709335046011964\n",
      "Epoch: 41, Loss (standarized): 0.6109130195072383\n",
      "          Validation Loss (standardized): 1.6863445463969138\n",
      "Epoch: 46, Loss (standarized): 0.5964100306854184\n",
      "          Validation Loss (standardized): 1.690325067131065\n",
      "Epoch: 51, Loss (standarized): 0.581384474792918\n",
      "          Validation Loss (standardized): 1.6991344860989583\n",
      "Epoch: 56, Loss (standarized): 0.5662884699699554\n",
      "          Validation Loss (standardized): 1.6892723068304722\n",
      "Epoch: 61, Loss (standarized): 0.5495137709920741\n",
      "          Validation Loss (standardized): 1.6658514057738172\n",
      "Epoch: 66, Loss (standarized): 0.5308480027764839\n",
      "          Validation Loss (standardized): 1.6339174514890085\n",
      "Epoch: 71, Loss (standarized): 0.5130421507013918\n",
      "          Validation Loss (standardized): 1.6158127023023314\n",
      "Epoch: 76, Loss (standarized): 0.4942124957340997\n",
      "          Validation Loss (standardized): 1.6056979420547308\n",
      "Epoch: 81, Loss (standarized): 0.4759188167229451\n",
      "          Validation Loss (standardized): 1.5834258319779302\n",
      "Epoch: 86, Loss (standarized): 0.458111862053886\n",
      "          Validation Loss (standardized): 1.5546869251030844\n",
      "Epoch: 91, Loss (standarized): 0.4406713149647029\n",
      "          Validation Loss (standardized): 1.53154066551197\n",
      "Epoch: 96, Loss (standarized): 0.4237701617715507\n",
      "          Validation Loss (standardized): 1.5123453843777992\n",
      "Final epoch: 100, Final loss (standarized): 0.41017402105413675\n",
      "Epoch: 1, Loss (standarized): 1.4707910222502258\n",
      "          Validation Loss (standardized): 1.9168534383065512\n",
      "Epoch: 6, Loss (standarized): 0.7429353917957714\n",
      "          Validation Loss (standardized): 2.0082918636549403\n",
      "Epoch: 11, Loss (standarized): 0.6938569638476318\n",
      "          Validation Loss (standardized): 2.2489819565353497\n",
      "Epoch: 16, Loss (standarized): 0.6710031887263714\n",
      "          Validation Loss (standardized): 2.1388834179489913\n",
      "Epoch: 21, Loss (standarized): 0.6296101818895792\n",
      "          Validation Loss (standardized): 1.861372869762109\n",
      "Epoch: 26, Loss (standarized): 0.6136388279596138\n",
      "          Validation Loss (standardized): 1.6627960231393135\n",
      "Epoch: 31, Loss (standarized): 0.5845747598057658\n",
      "          Validation Loss (standardized): 1.6482170884100649\n",
      "Epoch: 36, Loss (standarized): 0.5545513874025748\n",
      "          Validation Loss (standardized): 1.6697547669494524\n",
      "Epoch: 41, Loss (standarized): 0.5207156579232942\n",
      "          Validation Loss (standardized): 1.6354487318390734\n",
      "Epoch: 46, Loss (standarized): 0.48681690325967747\n",
      "          Validation Loss (standardized): 1.5492114743969987\n",
      "Epoch: 51, Loss (standarized): 0.4473586624308886\n",
      "          Validation Loss (standardized): 1.4569525131396377\n",
      "Epoch: 56, Loss (standarized): 0.40684001490486177\n",
      "          Validation Loss (standardized): 1.3722295181737683\n",
      "Epoch: 61, Loss (standarized): 0.3683320447496464\n",
      "          Validation Loss (standardized): 1.295833746375211\n",
      "Epoch: 66, Loss (standarized): 0.3290796325443094\n",
      "          Validation Loss (standardized): 1.2439409032054691\n",
      "Epoch: 71, Loss (standarized): 0.29111454573563966\n",
      "          Validation Loss (standardized): 1.1761690795425204\n",
      "Epoch: 76, Loss (standarized): 0.25556170359609137\n",
      "          Validation Loss (standardized): 1.099864312322754\n",
      "Epoch: 81, Loss (standarized): 0.22470081510467216\n",
      "          Validation Loss (standardized): 1.0500132693389863\n",
      "Epoch: 86, Loss (standarized): 0.2000355311077608\n",
      "          Validation Loss (standardized): 0.9929472959480997\n",
      "Epoch: 91, Loss (standarized): 0.1803228953929882\n",
      "          Validation Loss (standardized): 0.9372457128621199\n",
      "Epoch: 96, Loss (standarized): 0.16505813418571846\n",
      "          Validation Loss (standardized): 0.8903957683092847\n",
      "Final epoch: 100, Final loss (standarized): 0.15510677768291445\n",
      "Epoch: 1, Loss (standarized): 1.6294103349788651\n",
      "          Validation Loss (standardized): 1.985015707593014\n",
      "Epoch: 6, Loss (standarized): 0.7426306023877433\n",
      "          Validation Loss (standardized): 1.7937071042937422\n",
      "Epoch: 11, Loss (standarized): 0.7201753435930301\n",
      "          Validation Loss (standardized): 2.10391648364949\n",
      "Epoch: 16, Loss (standarized): 0.6760392030645582\n",
      "          Validation Loss (standardized): 1.8822961903344309\n",
      "Epoch: 21, Loss (standarized): 0.6300518942757671\n",
      "          Validation Loss (standardized): 1.6872245200606732\n",
      "Epoch: 26, Loss (standarized): 0.6135951313824375\n",
      "          Validation Loss (standardized): 1.8115840790028115\n",
      "Epoch: 31, Loss (standarized): 0.5890529340039943\n",
      "          Validation Loss (standardized): 1.7903033936204624\n",
      "Epoch: 36, Loss (standarized): 0.5601356422244851\n",
      "          Validation Loss (standardized): 1.6091516236882448\n",
      "Epoch: 41, Loss (standarized): 0.5362792131614692\n",
      "          Validation Loss (standardized): 1.5455921639526968\n",
      "Epoch: 46, Loss (standarized): 0.5052487698074626\n",
      "          Validation Loss (standardized): 1.5927017091451716\n",
      "Epoch: 51, Loss (standarized): 0.471213343837838\n",
      "          Validation Loss (standardized): 1.5525641087973112\n",
      "Epoch: 56, Loss (standarized): 0.43390723834156797\n",
      "          Validation Loss (standardized): 1.4632696316183544\n",
      "Epoch: 61, Loss (standarized): 0.3964651436205736\n",
      "          Validation Loss (standardized): 1.4417213114553447\n",
      "Epoch: 66, Loss (standarized): 0.35948274121244794\n",
      "          Validation Loss (standardized): 1.4033864688419218\n",
      "Epoch: 71, Loss (standarized): 0.32298840828385883\n",
      "          Validation Loss (standardized): 1.3226674354360417\n",
      "Epoch: 76, Loss (standarized): 0.28767371945287973\n",
      "          Validation Loss (standardized): 1.2910538563782439\n",
      "Epoch: 81, Loss (standarized): 0.2546696800369032\n",
      "          Validation Loss (standardized): 1.2027806097768938\n",
      "Epoch: 86, Loss (standarized): 0.227424401168212\n",
      "          Validation Loss (standardized): 1.1463636724324493\n",
      "Epoch: 91, Loss (standarized): 0.20672620333227185\n",
      "          Validation Loss (standardized): 1.082875566605349\n",
      "Epoch: 96, Loss (standarized): 0.1896819366021643\n",
      "          Validation Loss (standardized): 1.0124667454816711\n",
      "Final epoch: 100, Final loss (standarized): 0.1775917574275587\n",
      "Epoch: 1, Loss (standarized): 2.4057334740161935\n",
      "          Validation Loss (standardized): 1.2943742924284594\n",
      "Epoch: 6, Loss (standarized): 1.0166235332511349\n",
      "          Validation Loss (standardized): 1.3002749334589667\n",
      "Epoch: 11, Loss (standarized): 0.7506785006356507\n",
      "          Validation Loss (standardized): 1.7533070655836613\n",
      "Epoch: 16, Loss (standarized): 0.6935379791737576\n",
      "          Validation Loss (standardized): 2.0687886141406704\n",
      "Epoch: 21, Loss (standarized): 0.6635662300983984\n",
      "          Validation Loss (standardized): 2.225719374585555\n",
      "Epoch: 26, Loss (standarized): 0.6467685826015888\n",
      "          Validation Loss (standardized): 2.241607505268862\n",
      "Epoch: 31, Loss (standarized): 0.6194296622881922\n",
      "          Validation Loss (standardized): 2.1499453144333502\n",
      "Epoch: 36, Loss (standarized): 0.5923703064712804\n",
      "          Validation Loss (standardized): 2.0317652171864458\n",
      "Epoch: 41, Loss (standarized): 0.5716969038445369\n",
      "          Validation Loss (standardized): 1.9288392819089966\n",
      "Epoch: 46, Loss (standarized): 0.5514091650431633\n",
      "          Validation Loss (standardized): 1.8425687356798872\n",
      "Epoch: 51, Loss (standarized): 0.5282328426671744\n",
      "          Validation Loss (standardized): 1.7845235948845042\n",
      "Epoch: 56, Loss (standarized): 0.5033563195594699\n",
      "          Validation Loss (standardized): 1.7550539527160032\n",
      "Epoch: 61, Loss (standarized): 0.4765141398662541\n",
      "          Validation Loss (standardized): 1.7311159433154393\n",
      "Epoch: 66, Loss (standarized): 0.4479392887600347\n",
      "          Validation Loss (standardized): 1.70664133228489\n",
      "Epoch: 71, Loss (standarized): 0.4169279086150942\n",
      "          Validation Loss (standardized): 1.680176347759342\n",
      "Epoch: 76, Loss (standarized): 0.38407495002449765\n",
      "          Validation Loss (standardized): 1.6583707367850313\n",
      "Epoch: 81, Loss (standarized): 0.3487051640347018\n",
      "          Validation Loss (standardized): 1.6318872751963713\n",
      "Epoch: 86, Loss (standarized): 0.3104126283282006\n",
      "          Validation Loss (standardized): 1.5669339362000523\n",
      "Epoch: 91, Loss (standarized): 0.2727883583983346\n",
      "          Validation Loss (standardized): 1.446383005269281\n",
      "Epoch: 96, Loss (standarized): 0.24110545663159308\n",
      "          Validation Loss (standardized): 1.296270317257922\n",
      "Final epoch: 100, Final loss (standarized): 0.2205729351858215\n",
      "Epoch: 1, Loss (standarized): 1.4847230349031824\n",
      "          Validation Loss (standardized): 1.3985884629653598\n",
      "Epoch: 6, Loss (standarized): 0.8307994062480921\n",
      "          Validation Loss (standardized): 1.6695826546480768\n",
      "Epoch: 11, Loss (standarized): 0.6912219721596214\n",
      "          Validation Loss (standardized): 1.9429207455557607\n",
      "Epoch: 16, Loss (standarized): 0.6647462541437966\n",
      "          Validation Loss (standardized): 1.9909262340663327\n",
      "Epoch: 21, Loss (standarized): 0.6402314329179201\n",
      "          Validation Loss (standardized): 1.83555786965382\n",
      "Epoch: 26, Loss (standarized): 0.617686583508043\n",
      "          Validation Loss (standardized): 1.662305492953637\n",
      "Epoch: 31, Loss (standarized): 0.6004270233994368\n",
      "          Validation Loss (standardized): 1.5826367837134225\n",
      "Epoch: 36, Loss (standarized): 0.5743723483828352\n",
      "          Validation Loss (standardized): 1.588892889849778\n",
      "Epoch: 41, Loss (standarized): 0.5483294700417753\n",
      "          Validation Loss (standardized): 1.6075756012061713\n",
      "Epoch: 46, Loss (standarized): 0.5210356788992104\n",
      "          Validation Loss (standardized): 1.588487398447424\n",
      "Epoch: 51, Loss (standarized): 0.49021614522922125\n",
      "          Validation Loss (standardized): 1.5450998851190985\n",
      "Epoch: 56, Loss (standarized): 0.45447064908463947\n",
      "          Validation Loss (standardized): 1.4866703101357603\n",
      "Epoch: 61, Loss (standarized): 0.41733627131264356\n",
      "          Validation Loss (standardized): 1.4311660543697218\n",
      "Epoch: 66, Loss (standarized): 0.38101423316519206\n",
      "          Validation Loss (standardized): 1.3978766621305356\n",
      "Epoch: 71, Loss (standarized): 0.34620941230330066\n",
      "          Validation Loss (standardized): 1.3696261753388113\n",
      "Epoch: 76, Loss (standarized): 0.31435907742820757\n",
      "          Validation Loss (standardized): 1.3322650970823582\n",
      "Epoch: 81, Loss (standarized): 0.28654513840590956\n",
      "          Validation Loss (standardized): 1.2691620623319013\n",
      "Epoch: 86, Loss (standarized): 0.2641384959410092\n",
      "          Validation Loss (standardized): 1.2191921557706842\n",
      "Epoch: 91, Loss (standarized): 0.24715729812691836\n",
      "          Validation Loss (standardized): 1.1814594160330798\n",
      "Epoch: 96, Loss (standarized): 0.2347954497341217\n",
      "          Validation Loss (standardized): 1.145144719147249\n",
      "Final epoch: 100, Final loss (standarized): 0.22735296960782808\n",
      "Epoch: 1, Loss (standarized): 2.3328617312461746\n",
      "          Validation Loss (standardized): 1.5591159278817874\n",
      "Epoch: 6, Loss (standarized): 0.891478940213877\n",
      "          Validation Loss (standardized): 1.4353422230225354\n",
      "Epoch: 11, Loss (standarized): 0.7462764009787888\n",
      "          Validation Loss (standardized): 1.9645749755864585\n",
      "Epoch: 16, Loss (standarized): 0.716541125044741\n",
      "          Validation Loss (standardized): 2.212318448896424\n",
      "Epoch: 21, Loss (standarized): 0.6761963941107071\n",
      "          Validation Loss (standardized): 2.226457675564273\n",
      "Epoch: 26, Loss (standarized): 0.6536972901049305\n",
      "          Validation Loss (standardized): 2.1503784167495175\n",
      "Epoch: 31, Loss (standarized): 0.6209929690690262\n",
      "          Validation Loss (standardized): 2.024375470108703\n",
      "Epoch: 36, Loss (standarized): 0.5906925529807234\n",
      "          Validation Loss (standardized): 1.9052897025782864\n",
      "Epoch: 41, Loss (standarized): 0.5595407643577858\n",
      "          Validation Loss (standardized): 1.8018488366665704\n",
      "Epoch: 46, Loss (standarized): 0.5304119550755503\n",
      "          Validation Loss (standardized): 1.725527091728497\n",
      "Epoch: 51, Loss (standarized): 0.49993622769740464\n",
      "          Validation Loss (standardized): 1.6750220559230575\n",
      "Epoch: 56, Loss (standarized): 0.4680214770048277\n",
      "          Validation Loss (standardized): 1.6472988990054818\n",
      "Epoch: 61, Loss (standarized): 0.4362751260837521\n",
      "          Validation Loss (standardized): 1.6418688022665064\n",
      "Epoch: 66, Loss (standarized): 0.4039642153902145\n",
      "          Validation Loss (standardized): 1.6321520160798397\n",
      "Epoch: 71, Loss (standarized): 0.37298323756365453\n",
      "          Validation Loss (standardized): 1.6030866104253632\n",
      "Epoch: 76, Loss (standarized): 0.343726285132546\n",
      "          Validation Loss (standardized): 1.553167477277391\n",
      "Epoch: 81, Loss (standarized): 0.31693638024943993\n",
      "          Validation Loss (standardized): 1.4853487979614055\n",
      "Epoch: 86, Loss (standarized): 0.29299922400777184\n",
      "          Validation Loss (standardized): 1.4176213211654523\n",
      "Epoch: 91, Loss (standarized): 0.27223263810009435\n",
      "          Validation Loss (standardized): 1.3561588483503046\n",
      "Epoch: 96, Loss (standarized): 0.25481736500594404\n",
      "          Validation Loss (standardized): 1.3110941936228022\n",
      "Final epoch: 100, Final loss (standarized): 0.2427666420451872\n",
      "Epoch: 1, Loss (standarized): 1.4875813711218506\n",
      "          Validation Loss (standardized): 1.4185771855452094\n",
      "Epoch: 6, Loss (standarized): 0.7934547774190557\n",
      "          Validation Loss (standardized): 1.7291174386477492\n",
      "Epoch: 11, Loss (standarized): 0.673856958997835\n",
      "          Validation Loss (standardized): 2.2491004399168686\n",
      "Epoch: 16, Loss (standarized): 0.6481057705284397\n",
      "          Validation Loss (standardized): 2.3207905537293154\n",
      "Epoch: 21, Loss (standarized): 0.6205924793225245\n",
      "          Validation Loss (standardized): 2.105228049740318\n",
      "Epoch: 26, Loss (standarized): 0.5835656757277333\n",
      "          Validation Loss (standardized): 1.830896691818722\n",
      "Epoch: 31, Loss (standarized): 0.5513332474426756\n",
      "          Validation Loss (standardized): 1.6623989044416376\n",
      "Epoch: 36, Loss (standarized): 0.5188406629856608\n",
      "          Validation Loss (standardized): 1.6118723138746611\n",
      "Epoch: 41, Loss (standarized): 0.4815828884819126\n",
      "          Validation Loss (standardized): 1.6041891268025683\n",
      "Epoch: 46, Loss (standarized): 0.43914294938644927\n",
      "          Validation Loss (standardized): 1.5978333612209472\n",
      "Epoch: 51, Loss (standarized): 0.3943511294046883\n",
      "          Validation Loss (standardized): 1.5525956352044596\n",
      "Epoch: 56, Loss (standarized): 0.3486199256248051\n",
      "          Validation Loss (standardized): 1.464336274083302\n",
      "Epoch: 61, Loss (standarized): 0.3063596946334101\n",
      "          Validation Loss (standardized): 1.4406268524971828\n",
      "Epoch: 66, Loss (standarized): 0.27165690877712984\n",
      "          Validation Loss (standardized): 1.4191622165766775\n",
      "Epoch: 71, Loss (standarized): 0.24525664247043813\n",
      "          Validation Loss (standardized): 1.3507728030265167\n",
      "Epoch: 76, Loss (standarized): 0.2233500733710218\n",
      "          Validation Loss (standardized): 1.30234141465732\n",
      "Epoch: 81, Loss (standarized): 0.20396272738492743\n",
      "          Validation Loss (standardized): 1.1994591842446753\n",
      "Epoch: 86, Loss (standarized): 0.18794379620072033\n",
      "          Validation Loss (standardized): 1.1635555918025415\n",
      "Epoch: 91, Loss (standarized): 0.17440300974808717\n",
      "          Validation Loss (standardized): 1.0597419027991408\n",
      "Epoch: 96, Loss (standarized): 0.16160022921202583\n",
      "          Validation Loss (standardized): 0.9738976462231138\n",
      "Final epoch: 100, Final loss (standarized): 0.15009791607108278\n",
      "Epoch: 1, Loss (standarized): 1.2602154162889971\n",
      "          Validation Loss (standardized): 1.5343635373389666\n",
      "Epoch: 6, Loss (standarized): 0.7253646375168229\n",
      "          Validation Loss (standardized): 1.5020142396786988\n",
      "Epoch: 11, Loss (standarized): 0.6923817906359232\n",
      "          Validation Loss (standardized): 1.7785592817752254\n",
      "Epoch: 16, Loss (standarized): 0.6681518222389426\n",
      "          Validation Loss (standardized): 1.8023627933675062\n",
      "Epoch: 21, Loss (standarized): 0.6434739372859366\n",
      "          Validation Loss (standardized): 1.6712539118293113\n",
      "Epoch: 26, Loss (standarized): 0.6360233948567097\n",
      "          Validation Loss (standardized): 1.5799059351937184\n",
      "Epoch: 31, Loss (standarized): 0.6295858491859012\n",
      "          Validation Loss (standardized): 1.5780069724227188\n",
      "Epoch: 36, Loss (standarized): 0.6144628149264264\n",
      "          Validation Loss (standardized): 1.6188392079293572\n",
      "Epoch: 41, Loss (standarized): 0.6032446988695338\n",
      "          Validation Loss (standardized): 1.6445351744046537\n",
      "Epoch: 46, Loss (standarized): 0.5938206420452135\n",
      "          Validation Loss (standardized): 1.6193803342048343\n",
      "Epoch: 51, Loss (standarized): 0.5847053313576472\n",
      "          Validation Loss (standardized): 1.5919850998498069\n",
      "Epoch: 56, Loss (standarized): 0.5759075857373487\n",
      "          Validation Loss (standardized): 1.5713540446963221\n",
      "Epoch: 61, Loss (standarized): 0.568471232083749\n",
      "          Validation Loss (standardized): 1.5538490523575523\n",
      "Epoch: 66, Loss (standarized): 0.5620898209511627\n",
      "          Validation Loss (standardized): 1.5676965084350571\n",
      "Epoch: 71, Loss (standarized): 0.5551276147824026\n",
      "          Validation Loss (standardized): 1.5827048578434777\n",
      "Epoch: 76, Loss (standarized): 0.5489852736664215\n",
      "          Validation Loss (standardized): 1.585992612413947\n",
      "Epoch: 81, Loss (standarized): 0.5428305052489145\n",
      "          Validation Loss (standardized): 1.5853144411523186\n",
      "Epoch: 86, Loss (standarized): 0.5373257678551882\n",
      "          Validation Loss (standardized): 1.5785316787602297\n",
      "Epoch: 91, Loss (standarized): 0.532332122394286\n",
      "          Validation Loss (standardized): 1.579689106098226\n",
      "Epoch: 96, Loss (standarized): 0.5275186056331427\n",
      "          Validation Loss (standardized): 1.5783473151537237\n",
      "Final epoch: 100, Final loss (standarized): 0.523314837277295\n",
      "Epoch: 1, Loss (standarized): 1.5815987676568628\n",
      "          Validation Loss (standardized): 1.228785784128667\n",
      "Epoch: 6, Loss (standarized): 0.9327005983741924\n",
      "          Validation Loss (standardized): 1.2561340271845134\n",
      "Epoch: 11, Loss (standarized): 0.7697681001999229\n",
      "          Validation Loss (standardized): 1.4519077546013923\n",
      "Epoch: 16, Loss (standarized): 0.7038805878504942\n",
      "          Validation Loss (standardized): 1.6138175423755918\n",
      "Epoch: 21, Loss (standarized): 0.6798611469527304\n",
      "          Validation Loss (standardized): 1.7374806939585576\n",
      "Epoch: 26, Loss (standarized): 0.664565937296752\n",
      "          Validation Loss (standardized): 1.7767450966388552\n",
      "Epoch: 31, Loss (standarized): 0.6519090617182443\n",
      "          Validation Loss (standardized): 1.7370249043564145\n",
      "Epoch: 36, Loss (standarized): 0.6409346167646283\n",
      "          Validation Loss (standardized): 1.6704199658799175\n",
      "Epoch: 41, Loss (standarized): 0.6288778305771691\n",
      "          Validation Loss (standardized): 1.6086012686948767\n",
      "Epoch: 46, Loss (standarized): 0.6149983255246269\n",
      "          Validation Loss (standardized): 1.5650185694849852\n",
      "Epoch: 51, Loss (standarized): 0.6031331087046754\n",
      "          Validation Loss (standardized): 1.53064048526264\n",
      "Epoch: 56, Loss (standarized): 0.5921321026869243\n",
      "          Validation Loss (standardized): 1.5173809284492816\n",
      "Epoch: 61, Loss (standarized): 0.5822232704336905\n",
      "          Validation Loss (standardized): 1.5191755347835774\n",
      "Epoch: 66, Loss (standarized): 0.5727816082674357\n",
      "          Validation Loss (standardized): 1.5320072428593088\n",
      "Epoch: 71, Loss (standarized): 0.5645969384063403\n",
      "          Validation Loss (standardized): 1.5472068434296342\n",
      "Epoch: 76, Loss (standarized): 0.5574910713434382\n",
      "          Validation Loss (standardized): 1.551620996927228\n",
      "Epoch: 81, Loss (standarized): 0.5512421494137296\n",
      "          Validation Loss (standardized): 1.5439251977158215\n",
      "Epoch: 86, Loss (standarized): 0.545724705885487\n",
      "          Validation Loss (standardized): 1.537304845754953\n",
      "Epoch: 91, Loss (standarized): 0.540177006889782\n",
      "          Validation Loss (standardized): 1.535013915281901\n",
      "Epoch: 96, Loss (standarized): 0.535504458260819\n",
      "          Validation Loss (standardized): 1.529233049218389\n",
      "Final epoch: 100, Final loss (standarized): 0.5322713791763541\n",
      "Epoch: 1, Loss (standarized): 2.0826835951484575\n",
      "          Validation Loss (standardized): 1.9051239825589368\n",
      "Epoch: 6, Loss (standarized): 0.930456311208624\n",
      "          Validation Loss (standardized): 2.154978673520558\n",
      "Epoch: 11, Loss (standarized): 0.7954971512966437\n",
      "          Validation Loss (standardized): 2.4836493407646034\n",
      "Epoch: 16, Loss (standarized): 0.6903055940189784\n",
      "          Validation Loss (standardized): 2.2964221485368164\n",
      "Epoch: 21, Loss (standarized): 0.6703438511872741\n",
      "          Validation Loss (standardized): 2.093131887598909\n",
      "Epoch: 26, Loss (standarized): 0.6417304359726329\n",
      "          Validation Loss (standardized): 1.9004718034736614\n",
      "Epoch: 31, Loss (standarized): 0.6306430509934738\n",
      "          Validation Loss (standardized): 1.7551690310980672\n",
      "Epoch: 36, Loss (standarized): 0.6173339916502253\n",
      "          Validation Loss (standardized): 1.6296406175344933\n",
      "Epoch: 41, Loss (standarized): 0.6076707063372775\n",
      "          Validation Loss (standardized): 1.5687964975626782\n",
      "Epoch: 46, Loss (standarized): 0.5968370160949803\n",
      "          Validation Loss (standardized): 1.5570531700162045\n",
      "Epoch: 51, Loss (standarized): 0.5864578821710968\n",
      "          Validation Loss (standardized): 1.5558433289568216\n",
      "Epoch: 56, Loss (standarized): 0.5761785162555016\n",
      "          Validation Loss (standardized): 1.556936619559319\n",
      "Epoch: 61, Loss (standarized): 0.5658763160643535\n",
      "          Validation Loss (standardized): 1.55541293242457\n",
      "Epoch: 66, Loss (standarized): 0.5552597569532034\n",
      "          Validation Loss (standardized): 1.548074550501359\n",
      "Epoch: 71, Loss (standarized): 0.5431709501853039\n",
      "          Validation Loss (standardized): 1.535958417544421\n",
      "Epoch: 76, Loss (standarized): 0.5300093345070684\n",
      "          Validation Loss (standardized): 1.5411754508069448\n",
      "Epoch: 81, Loss (standarized): 0.5158100658550712\n",
      "          Validation Loss (standardized): 1.552872299276276\n",
      "Epoch: 86, Loss (standarized): 0.5006799749300553\n",
      "          Validation Loss (standardized): 1.5578930751798503\n",
      "Epoch: 91, Loss (standarized): 0.48571034179569467\n",
      "          Validation Loss (standardized): 1.5644013870687534\n",
      "Epoch: 96, Loss (standarized): 0.4712190103806619\n",
      "          Validation Loss (standardized): 1.5629422778649211\n",
      "Final epoch: 100, Final loss (standarized): 0.4599945313565415\n",
      "Epoch: 1, Loss (standarized): 1.6046094281127214\n",
      "          Validation Loss (standardized): 1.4373481627321896\n",
      "Epoch: 6, Loss (standarized): 0.813387277640279\n",
      "          Validation Loss (standardized): 1.952605243926108\n",
      "Epoch: 11, Loss (standarized): 0.7446884488862557\n",
      "          Validation Loss (standardized): 2.1532341987748986\n",
      "Epoch: 16, Loss (standarized): 0.685278064566685\n",
      "          Validation Loss (standardized): 1.907943553710015\n",
      "Epoch: 21, Loss (standarized): 0.6720374701490218\n",
      "          Validation Loss (standardized): 1.6504067962777536\n",
      "Epoch: 26, Loss (standarized): 0.6553807257049068\n",
      "          Validation Loss (standardized): 1.5564437291805595\n",
      "Epoch: 31, Loss (standarized): 0.6382048760171621\n",
      "          Validation Loss (standardized): 1.5917374341302999\n",
      "Epoch: 36, Loss (standarized): 0.6279240050977827\n",
      "          Validation Loss (standardized): 1.6255409119558812\n",
      "Epoch: 41, Loss (standarized): 0.6167318588838363\n",
      "          Validation Loss (standardized): 1.6045007518469592\n",
      "Epoch: 46, Loss (standarized): 0.608653378755587\n",
      "          Validation Loss (standardized): 1.5672879174469863\n",
      "Epoch: 51, Loss (standarized): 0.5988938091950152\n",
      "          Validation Loss (standardized): 1.5593594694358786\n",
      "Epoch: 56, Loss (standarized): 0.5873935016110239\n",
      "          Validation Loss (standardized): 1.5744288514391152\n",
      "Epoch: 61, Loss (standarized): 0.5769613284439753\n",
      "          Validation Loss (standardized): 1.5770403510186701\n",
      "Epoch: 66, Loss (standarized): 0.5687727016422272\n",
      "          Validation Loss (standardized): 1.5778421149153081\n",
      "Epoch: 71, Loss (standarized): 0.5607482625133267\n",
      "          Validation Loss (standardized): 1.5695656663841764\n",
      "Epoch: 76, Loss (standarized): 0.5528029264881956\n",
      "          Validation Loss (standardized): 1.5553904590872791\n",
      "Epoch: 81, Loss (standarized): 0.5452763270663489\n",
      "          Validation Loss (standardized): 1.5652225992181494\n",
      "Epoch: 86, Loss (standarized): 0.5389084616923048\n",
      "          Validation Loss (standardized): 1.574654216206245\n",
      "Epoch: 91, Loss (standarized): 0.5330917755318519\n",
      "          Validation Loss (standardized): 1.5569032295805996\n",
      "Epoch: 96, Loss (standarized): 0.5281226153862965\n",
      "          Validation Loss (standardized): 1.5358042636857472\n",
      "Final epoch: 100, Final loss (standarized): 0.5246511829604634\n",
      "Epoch: 1, Loss (standarized): 1.61821897633511\n",
      "          Validation Loss (standardized): 1.2893554702339725\n",
      "Epoch: 6, Loss (standarized): 0.7788774587536206\n",
      "          Validation Loss (standardized): 1.3703271400506842\n",
      "Epoch: 11, Loss (standarized): 0.6757691550020142\n",
      "          Validation Loss (standardized): 1.9822622250730182\n",
      "Epoch: 16, Loss (standarized): 0.6401438422848801\n",
      "          Validation Loss (standardized): 2.359878237467965\n",
      "Epoch: 21, Loss (standarized): 0.6248607723246761\n",
      "          Validation Loss (standardized): 2.3369134685329755\n",
      "Epoch: 26, Loss (standarized): 0.5998013308076034\n",
      "          Validation Loss (standardized): 2.1421961513492116\n",
      "Epoch: 31, Loss (standarized): 0.5690364213761974\n",
      "          Validation Loss (standardized): 1.9452238702287643\n",
      "Epoch: 36, Loss (standarized): 0.5431817435549416\n",
      "          Validation Loss (standardized): 1.7511329687620203\n",
      "Epoch: 41, Loss (standarized): 0.5196829263688237\n",
      "          Validation Loss (standardized): 1.5964246125943895\n",
      "Epoch: 46, Loss (standarized): 0.49489821124989347\n",
      "          Validation Loss (standardized): 1.5225804589941383\n",
      "Epoch: 51, Loss (standarized): 0.4663165841628317\n",
      "          Validation Loss (standardized): 1.5019368578517454\n",
      "Epoch: 56, Loss (standarized): 0.4337212431270154\n",
      "          Validation Loss (standardized): 1.506588916127445\n",
      "Epoch: 61, Loss (standarized): 0.3988174456784005\n",
      "          Validation Loss (standardized): 1.5060540986678435\n",
      "Epoch: 66, Loss (standarized): 0.36372376231617115\n",
      "          Validation Loss (standardized): 1.4708853878233743\n",
      "Epoch: 71, Loss (standarized): 0.32998589663258887\n",
      "          Validation Loss (standardized): 1.3760445978194984\n",
      "Epoch: 76, Loss (standarized): 0.2981745258102248\n",
      "          Validation Loss (standardized): 1.2809115594600207\n",
      "Epoch: 81, Loss (standarized): 0.26915637766815365\n",
      "          Validation Loss (standardized): 1.218101271118731\n",
      "Epoch: 86, Loss (standarized): 0.24423713193729593\n",
      "          Validation Loss (standardized): 1.1419391918981494\n",
      "Epoch: 91, Loss (standarized): 0.22334467359636093\n",
      "          Validation Loss (standardized): 1.0723169347890094\n",
      "Epoch: 96, Loss (standarized): 0.205740913012673\n",
      "          Validation Loss (standardized): 1.0090919267385368\n",
      "Final epoch: 100, Final loss (standarized): 0.19380755247151904\n",
      "Epoch: 1, Loss (standarized): 1.1700664209805678\n",
      "          Validation Loss (standardized): 1.46594824530465\n",
      "Epoch: 6, Loss (standarized): 0.7807702334190223\n",
      "          Validation Loss (standardized): 1.5037658957600601\n",
      "Epoch: 11, Loss (standarized): 0.6900379373811343\n",
      "          Validation Loss (standardized): 1.8709904804470823\n",
      "Epoch: 16, Loss (standarized): 0.6619790625982763\n",
      "          Validation Loss (standardized): 1.996145448104765\n",
      "Epoch: 21, Loss (standarized): 0.6314450073170539\n",
      "          Validation Loss (standardized): 1.9345150185830617\n",
      "Epoch: 26, Loss (standarized): 0.6072183545858596\n",
      "          Validation Loss (standardized): 1.7863704874144806\n",
      "Epoch: 31, Loss (standarized): 0.5844320307582267\n",
      "          Validation Loss (standardized): 1.6670749252399564\n",
      "Epoch: 36, Loss (standarized): 0.5638977853858583\n",
      "          Validation Loss (standardized): 1.6116766039555632\n",
      "Epoch: 41, Loss (standarized): 0.5399900494016145\n",
      "          Validation Loss (standardized): 1.58877569566722\n",
      "Epoch: 46, Loss (standarized): 0.5160319547533305\n",
      "          Validation Loss (standardized): 1.5692971827976767\n",
      "Epoch: 51, Loss (standarized): 0.49034119133770754\n",
      "          Validation Loss (standardized): 1.5519279232690395\n",
      "Epoch: 56, Loss (standarized): 0.4627522269245164\n",
      "          Validation Loss (standardized): 1.5293761200806393\n",
      "Epoch: 61, Loss (standarized): 0.4345267063064409\n",
      "          Validation Loss (standardized): 1.4925359776058944\n",
      "Epoch: 66, Loss (standarized): 0.4062248434276056\n",
      "          Validation Loss (standardized): 1.457856626094505\n",
      "Epoch: 71, Loss (standarized): 0.3783809706509676\n",
      "          Validation Loss (standardized): 1.4265227225479051\n",
      "Epoch: 76, Loss (standarized): 0.35277393927213496\n",
      "          Validation Loss (standardized): 1.3863192210592306\n",
      "Epoch: 81, Loss (standarized): 0.3295805883681929\n",
      "          Validation Loss (standardized): 1.350417717024482\n",
      "Epoch: 86, Loss (standarized): 0.3093748135923156\n",
      "          Validation Loss (standardized): 1.3130686326141623\n",
      "Epoch: 91, Loss (standarized): 0.2930908027019489\n",
      "          Validation Loss (standardized): 1.2769496586175473\n",
      "Epoch: 96, Loss (standarized): 0.28017069962273466\n",
      "          Validation Loss (standardized): 1.2503238493716307\n",
      "Final epoch: 100, Final loss (standarized): 0.27168645325174096\n",
      "Epoch: 1, Loss (standarized): 1.2257378786787303\n",
      "          Validation Loss (standardized): 1.7101076028671696\n",
      "Epoch: 6, Loss (standarized): 0.708836664128342\n",
      "          Validation Loss (standardized): 1.9991923842100656\n",
      "Epoch: 11, Loss (standarized): 0.7125092750564035\n",
      "          Validation Loss (standardized): 2.0470886939169306\n",
      "Epoch: 16, Loss (standarized): 0.658728348639079\n",
      "          Validation Loss (standardized): 1.7007512807403105\n",
      "Epoch: 21, Loss (standarized): 0.6218155815060609\n",
      "          Validation Loss (standardized): 1.7261615580676728\n",
      "Epoch: 26, Loss (standarized): 0.6066462626110933\n",
      "          Validation Loss (standardized): 1.828414904160225\n",
      "Epoch: 31, Loss (standarized): 0.5828952837589743\n",
      "          Validation Loss (standardized): 1.7192612808735184\n",
      "Epoch: 36, Loss (standarized): 0.5547258125401152\n",
      "          Validation Loss (standardized): 1.638962619558951\n",
      "Epoch: 41, Loss (standarized): 0.526586165492887\n",
      "          Validation Loss (standardized): 1.6113080871942371\n",
      "Epoch: 46, Loss (standarized): 0.49560288350275067\n",
      "          Validation Loss (standardized): 1.5819239532053857\n",
      "Epoch: 51, Loss (standarized): 0.462656861871718\n",
      "          Validation Loss (standardized): 1.537789216170523\n",
      "Epoch: 56, Loss (standarized): 0.42753758628151506\n",
      "          Validation Loss (standardized): 1.4854513321800262\n",
      "Epoch: 61, Loss (standarized): 0.3907373245389515\n",
      "          Validation Loss (standardized): 1.432349543974669\n",
      "Epoch: 66, Loss (standarized): 0.35298540999690964\n",
      "          Validation Loss (standardized): 1.3591242541854316\n",
      "Epoch: 71, Loss (standarized): 0.31535730076324303\n",
      "          Validation Loss (standardized): 1.3004219875230834\n",
      "Epoch: 76, Loss (standarized): 0.28023957591286375\n",
      "          Validation Loss (standardized): 1.2219401395571365\n",
      "Epoch: 81, Loss (standarized): 0.24974648343050704\n",
      "          Validation Loss (standardized): 1.1467391459434664\n",
      "Epoch: 86, Loss (standarized): 0.22387772738769218\n",
      "          Validation Loss (standardized): 1.0778701186895037\n",
      "Epoch: 91, Loss (standarized): 0.20282743270170323\n",
      "          Validation Loss (standardized): 1.012215521266472\n",
      "Epoch: 96, Loss (standarized): 0.1856331003431583\n",
      "          Validation Loss (standardized): 0.9476362531539018\n",
      "Final epoch: 100, Final loss (standarized): 0.17401626222989283\n",
      "Epoch: 1, Loss (standarized): 1.659276789590431\n",
      "          Validation Loss (standardized): 1.4184030882887773\n",
      "Epoch: 6, Loss (standarized): 0.8545072781727668\n",
      "          Validation Loss (standardized): 1.5417628340443603\n",
      "Epoch: 11, Loss (standarized): 0.7076718838474519\n",
      "          Validation Loss (standardized): 2.0148834748704063\n",
      "Epoch: 16, Loss (standarized): 0.6776971944571047\n",
      "          Validation Loss (standardized): 2.2202259209085695\n",
      "Epoch: 21, Loss (standarized): 0.6592370618900599\n",
      "          Validation Loss (standardized): 2.1826404842722495\n",
      "Epoch: 26, Loss (standarized): 0.6383744863803221\n",
      "          Validation Loss (standardized): 2.0195500723547815\n",
      "Epoch: 31, Loss (standarized): 0.6171314219268622\n",
      "          Validation Loss (standardized): 1.8612499842786852\n",
      "Epoch: 36, Loss (standarized): 0.598835417077282\n",
      "          Validation Loss (standardized): 1.7388789148229866\n",
      "Epoch: 41, Loss (standarized): 0.5791112144964711\n",
      "          Validation Loss (standardized): 1.6691162419845773\n",
      "Epoch: 46, Loss (standarized): 0.5565768841000429\n",
      "          Validation Loss (standardized): 1.648640609762663\n",
      "Epoch: 51, Loss (standarized): 0.5310178722594993\n",
      "          Validation Loss (standardized): 1.6580231174074842\n",
      "Epoch: 56, Loss (standarized): 0.5014230785294292\n",
      "          Validation Loss (standardized): 1.6489258133408538\n",
      "Epoch: 61, Loss (standarized): 0.46701593203856623\n",
      "          Validation Loss (standardized): 1.6054321233281565\n",
      "Epoch: 66, Loss (standarized): 0.42704390913412604\n",
      "          Validation Loss (standardized): 1.5262452425227966\n",
      "Epoch: 71, Loss (standarized): 0.3837485902857688\n",
      "          Validation Loss (standardized): 1.4407816646370053\n",
      "Epoch: 76, Loss (standarized): 0.3392640517201895\n",
      "          Validation Loss (standardized): 1.3698575176799408\n",
      "Epoch: 81, Loss (standarized): 0.2988793306651408\n",
      "          Validation Loss (standardized): 1.2944909631181445\n",
      "Epoch: 86, Loss (standarized): 0.26464249761527386\n",
      "          Validation Loss (standardized): 1.2450739051514492\n",
      "Epoch: 91, Loss (standarized): 0.23676231921195723\n",
      "          Validation Loss (standardized): 1.1883158963866431\n",
      "Epoch: 96, Loss (standarized): 0.21435446524969853\n",
      "          Validation Loss (standardized): 1.1211209654031045\n",
      "Final epoch: 100, Final loss (standarized): 0.19959016537711916\n",
      "Epoch: 1, Loss (standarized): 1.0033457130092533\n",
      "          Validation Loss (standardized): 1.3271835290113903\n",
      "Epoch: 6, Loss (standarized): 0.7007200041756237\n",
      "          Validation Loss (standardized): 1.731267277517472\n",
      "Epoch: 11, Loss (standarized): 0.6539930649455561\n",
      "          Validation Loss (standardized): 2.036775339400503\n",
      "Epoch: 16, Loss (standarized): 0.616057900110835\n",
      "          Validation Loss (standardized): 1.9749522461885554\n",
      "Epoch: 21, Loss (standarized): 0.570036531955157\n",
      "          Validation Loss (standardized): 1.7659768717656488\n",
      "Epoch: 26, Loss (standarized): 0.5347880784894045\n",
      "          Validation Loss (standardized): 1.6334500194142412\n",
      "Epoch: 31, Loss (standarized): 0.48765687521012346\n",
      "          Validation Loss (standardized): 1.6117560124455264\n",
      "Epoch: 36, Loss (standarized): 0.4375544087068247\n",
      "          Validation Loss (standardized): 1.5862459743571087\n",
      "Epoch: 41, Loss (standarized): 0.3858061224330863\n",
      "          Validation Loss (standardized): 1.4822807583639974\n",
      "Epoch: 46, Loss (standarized): 0.3343605640805538\n",
      "          Validation Loss (standardized): 1.399165316094869\n",
      "Epoch: 51, Loss (standarized): 0.2904599479501391\n",
      "          Validation Loss (standardized): 1.367065295041686\n",
      "Epoch: 56, Loss (standarized): 0.25531430099430114\n",
      "          Validation Loss (standardized): 1.3199216015064925\n",
      "Epoch: 61, Loss (standarized): 0.2270063227290603\n",
      "          Validation Loss (standardized): 1.2538351318871408\n",
      "Epoch: 66, Loss (standarized): 0.20415242952899834\n",
      "          Validation Loss (standardized): 1.1609956291447265\n",
      "Epoch: 71, Loss (standarized): 0.1857607293786028\n",
      "          Validation Loss (standardized): 1.075689940393209\n",
      "Epoch: 76, Loss (standarized): 0.17057905735727305\n",
      "          Validation Loss (standardized): 1.0187131093203203\n",
      "Epoch: 81, Loss (standarized): 0.15765965928579467\n",
      "          Validation Loss (standardized): 0.9679537511276244\n",
      "Epoch: 86, Loss (standarized): 0.14620935714821262\n",
      "          Validation Loss (standardized): 0.912616434455272\n",
      "Epoch: 91, Loss (standarized): 0.13594092129039217\n",
      "          Validation Loss (standardized): 0.8651457152466375\n",
      "Epoch: 96, Loss (standarized): 0.12685950737333548\n",
      "          Validation Loss (standardized): 0.8221451008761185\n",
      "Final epoch: 100, Final loss (standarized): 0.12036604517505245\n",
      "Epoch: 1, Loss (standarized): 3.208745403393565\n",
      "          Validation Loss (standardized): 2.028727603256486\n",
      "Epoch: 6, Loss (standarized): 1.2000979074837328\n",
      "          Validation Loss (standardized): 1.7452892703409995\n",
      "Epoch: 11, Loss (standarized): 0.7724719571604814\n",
      "          Validation Loss (standardized): 2.1634182539495397\n",
      "Epoch: 16, Loss (standarized): 0.7466510112466334\n",
      "          Validation Loss (standardized): 2.626853962312519\n",
      "Epoch: 21, Loss (standarized): 0.7223723802472098\n",
      "          Validation Loss (standardized): 2.744209280811678\n",
      "Epoch: 26, Loss (standarized): 0.686253014945227\n",
      "          Validation Loss (standardized): 2.576863046845118\n",
      "Epoch: 31, Loss (standarized): 0.6556301496066969\n",
      "          Validation Loss (standardized): 2.3116549064279606\n",
      "Epoch: 36, Loss (standarized): 0.6395192747901047\n",
      "          Validation Loss (standardized): 2.0667219334690405\n",
      "Epoch: 41, Loss (standarized): 0.6187967739197654\n",
      "          Validation Loss (standardized): 1.8663554974191334\n",
      "Epoch: 46, Loss (standarized): 0.6016311075093449\n",
      "          Validation Loss (standardized): 1.7214944903831932\n",
      "Epoch: 51, Loss (standarized): 0.5882534082716648\n",
      "          Validation Loss (standardized): 1.6332015601112764\n",
      "Epoch: 56, Loss (standarized): 0.5761900766092598\n",
      "          Validation Loss (standardized): 1.6019764548125053\n",
      "Epoch: 61, Loss (standarized): 0.5640818334863414\n",
      "          Validation Loss (standardized): 1.5939591573887986\n",
      "Epoch: 66, Loss (standarized): 0.5522488179357212\n",
      "          Validation Loss (standardized): 1.5965130851827367\n",
      "Epoch: 71, Loss (standarized): 0.5412297898542788\n",
      "          Validation Loss (standardized): 1.6061798092674724\n",
      "Epoch: 76, Loss (standarized): 0.5299723932847724\n",
      "          Validation Loss (standardized): 1.613052472788598\n",
      "Epoch: 81, Loss (standarized): 0.5177731364070189\n",
      "          Validation Loss (standardized): 1.6161676156461753\n",
      "Epoch: 86, Loss (standarized): 0.5014087049414288\n",
      "          Validation Loss (standardized): 1.6024320001868548\n",
      "Epoch: 91, Loss (standarized): 0.48731616288824675\n",
      "          Validation Loss (standardized): 1.5806594857795342\n",
      "Epoch: 96, Loss (standarized): 0.4742715180626086\n",
      "          Validation Loss (standardized): 1.5664610801332246\n",
      "Final epoch: 100, Final loss (standarized): 0.46433501175205144\n",
      "Epoch: 1, Loss (standarized): 1.9757398679817069\n",
      "          Validation Loss (standardized): 1.2390350152223555\n",
      "Epoch: 6, Loss (standarized): 0.9827991928504584\n",
      "          Validation Loss (standardized): 1.3414398987060703\n",
      "Epoch: 11, Loss (standarized): 0.7642576994981957\n",
      "          Validation Loss (standardized): 1.7138955156559432\n",
      "Epoch: 16, Loss (standarized): 0.6884587465596039\n",
      "          Validation Loss (standardized): 2.031440309731121\n",
      "Epoch: 21, Loss (standarized): 0.6654902036085725\n",
      "          Validation Loss (standardized): 2.1706810830025165\n",
      "Epoch: 26, Loss (standarized): 0.6435465312206458\n",
      "          Validation Loss (standardized): 2.137336956471801\n",
      "Epoch: 31, Loss (standarized): 0.6172812901007158\n",
      "          Validation Loss (standardized): 1.9842727859384863\n",
      "Epoch: 36, Loss (standarized): 0.5920333845958691\n",
      "          Validation Loss (standardized): 1.821006838997385\n",
      "Epoch: 41, Loss (standarized): 0.5665143306219503\n",
      "          Validation Loss (standardized): 1.7169552892297228\n",
      "Epoch: 46, Loss (standarized): 0.5405189355425272\n",
      "          Validation Loss (standardized): 1.6731173190123547\n",
      "Epoch: 51, Loss (standarized): 0.5094138653138153\n",
      "          Validation Loss (standardized): 1.6536202188835696\n",
      "Epoch: 56, Loss (standarized): 0.4730262365014565\n",
      "          Validation Loss (standardized): 1.6382425416364175\n",
      "Epoch: 61, Loss (standarized): 0.4320483617487974\n",
      "          Validation Loss (standardized): 1.6073761991725763\n",
      "Epoch: 66, Loss (standarized): 0.3890675656028143\n",
      "          Validation Loss (standardized): 1.5586427399463967\n",
      "Epoch: 71, Loss (standarized): 0.34957545745539725\n",
      "          Validation Loss (standardized): 1.4888972315519107\n",
      "Epoch: 76, Loss (standarized): 0.3150203438255215\n",
      "          Validation Loss (standardized): 1.4601317549379114\n",
      "Epoch: 81, Loss (standarized): 0.28574433798575033\n",
      "          Validation Loss (standardized): 1.4162559461834028\n",
      "Epoch: 86, Loss (standarized): 0.26190822718091017\n",
      "          Validation Loss (standardized): 1.3585815292607644\n",
      "Epoch: 91, Loss (standarized): 0.24271496718137323\n",
      "          Validation Loss (standardized): 1.3113492004339105\n",
      "Epoch: 96, Loss (standarized): 0.22691549979839895\n",
      "          Validation Loss (standardized): 1.2615115179364906\n",
      "Final epoch: 100, Final loss (standarized): 0.21627152195141383\n",
      "Epoch: 1, Loss (standarized): 1.3781136114265704\n",
      "          Validation Loss (standardized): 1.1961669772565415\n",
      "Epoch: 6, Loss (standarized): 0.7915110466194955\n",
      "          Validation Loss (standardized): 1.513076611242209\n",
      "Epoch: 11, Loss (standarized): 0.6924508656778988\n",
      "          Validation Loss (standardized): 1.735646214276022\n",
      "Epoch: 16, Loss (standarized): 0.6495313955677501\n",
      "          Validation Loss (standardized): 1.8500098070727182\n",
      "Epoch: 21, Loss (standarized): 0.6192752032994842\n",
      "          Validation Loss (standardized): 1.9023187249334788\n",
      "Epoch: 26, Loss (standarized): 0.583279779658106\n",
      "          Validation Loss (standardized): 1.8763095692126073\n",
      "Epoch: 31, Loss (standarized): 0.5464837933757486\n",
      "          Validation Loss (standardized): 1.791351549998509\n",
      "Epoch: 36, Loss (standarized): 0.5070176999609319\n",
      "          Validation Loss (standardized): 1.704829922426522\n",
      "Epoch: 41, Loss (standarized): 0.46420741050662967\n",
      "          Validation Loss (standardized): 1.6520996936239887\n",
      "Epoch: 46, Loss (standarized): 0.420615931492226\n",
      "          Validation Loss (standardized): 1.6168385040023168\n",
      "Epoch: 51, Loss (standarized): 0.37741077805024276\n",
      "          Validation Loss (standardized): 1.5887147639236214\n",
      "Epoch: 56, Loss (standarized): 0.3377392607511907\n",
      "          Validation Loss (standardized): 1.5757672237272518\n",
      "Epoch: 61, Loss (standarized): 0.30215541192294637\n",
      "          Validation Loss (standardized): 1.5547915246883126\n",
      "Epoch: 66, Loss (standarized): 0.2715259139463926\n",
      "          Validation Loss (standardized): 1.509527820683269\n",
      "Epoch: 71, Loss (standarized): 0.24601367067122273\n",
      "          Validation Loss (standardized): 1.4395871340523356\n",
      "Epoch: 76, Loss (standarized): 0.22444866752185103\n",
      "          Validation Loss (standardized): 1.3462082696060655\n",
      "Epoch: 81, Loss (standarized): 0.20671707617074994\n",
      "          Validation Loss (standardized): 1.258688644086879\n",
      "Epoch: 86, Loss (standarized): 0.19198087210681383\n",
      "          Validation Loss (standardized): 1.190251754138289\n",
      "Epoch: 91, Loss (standarized): 0.17905607706500057\n",
      "          Validation Loss (standardized): 1.1327369386074364\n",
      "Epoch: 96, Loss (standarized): 0.16778741320999957\n",
      "          Validation Loss (standardized): 1.0692130018468045\n",
      "Final epoch: 100, Final loss (standarized): 0.15953167807495935\n",
      "Epoch: 1, Loss (standarized): 1.9730107176983271\n",
      "          Validation Loss (standardized): 1.1211034725458964\n",
      "Epoch: 6, Loss (standarized): 0.876126411170182\n",
      "          Validation Loss (standardized): 1.3988569185284045\n",
      "Epoch: 11, Loss (standarized): 0.6936018885504285\n",
      "          Validation Loss (standardized): 1.8591425178540764\n",
      "Epoch: 16, Loss (standarized): 0.659557262466795\n",
      "          Validation Loss (standardized): 2.1404431081088933\n",
      "Epoch: 21, Loss (standarized): 0.6481571341811442\n",
      "          Validation Loss (standardized): 2.251122476627128\n",
      "Epoch: 26, Loss (standarized): 0.624698484603513\n",
      "          Validation Loss (standardized): 2.2092926097658436\n",
      "Epoch: 31, Loss (standarized): 0.5948295389875968\n",
      "          Validation Loss (standardized): 2.080448250830208\n",
      "Epoch: 36, Loss (standarized): 0.5620193947101467\n",
      "          Validation Loss (standardized): 1.9181834502445834\n",
      "Epoch: 41, Loss (standarized): 0.524977241589799\n",
      "          Validation Loss (standardized): 1.7820419514300998\n",
      "Epoch: 46, Loss (standarized): 0.4801885629350887\n",
      "          Validation Loss (standardized): 1.6810747798369412\n",
      "Epoch: 51, Loss (standarized): 0.4283430522673802\n",
      "          Validation Loss (standardized): 1.6411177102471344\n",
      "Epoch: 56, Loss (standarized): 0.37527601283452294\n",
      "          Validation Loss (standardized): 1.637609987633486\n",
      "Epoch: 61, Loss (standarized): 0.32948397590285894\n",
      "          Validation Loss (standardized): 1.629815190185719\n",
      "Epoch: 66, Loss (standarized): 0.2906293138262251\n",
      "          Validation Loss (standardized): 1.5798705845519836\n",
      "Epoch: 71, Loss (standarized): 0.2574605043259588\n",
      "          Validation Loss (standardized): 1.4902473823014641\n",
      "Epoch: 76, Loss (standarized): 0.2302031724450199\n",
      "          Validation Loss (standardized): 1.389421533207601\n",
      "Epoch: 81, Loss (standarized): 0.21014591015861062\n",
      "          Validation Loss (standardized): 1.2694140002430532\n",
      "Epoch: 86, Loss (standarized): 0.1943887997514772\n",
      "          Validation Loss (standardized): 1.1970524162082594\n",
      "Epoch: 91, Loss (standarized): 0.18178991727835694\n",
      "          Validation Loss (standardized): 1.1295294281757375\n",
      "Epoch: 96, Loss (standarized): 0.17037139122378642\n",
      "          Validation Loss (standardized): 1.092228359028076\n",
      "Final epoch: 100, Final loss (standarized): 0.162196432960368\n",
      "Epoch: 1, Loss (standarized): 1.590818506878187\n",
      "          Validation Loss (standardized): 1.3169142075588112\n",
      "Epoch: 6, Loss (standarized): 0.8108427678970023\n",
      "          Validation Loss (standardized): 1.3732362776029332\n",
      "Epoch: 11, Loss (standarized): 0.6875779437958075\n",
      "          Validation Loss (standardized): 1.84937462549115\n",
      "Epoch: 16, Loss (standarized): 0.6526223882936569\n",
      "          Validation Loss (standardized): 2.121818864827394\n",
      "Epoch: 21, Loss (standarized): 0.6340636854497695\n",
      "          Validation Loss (standardized): 2.1425646551012036\n",
      "Epoch: 26, Loss (standarized): 0.6036283130434454\n",
      "          Validation Loss (standardized): 2.001268562722498\n",
      "Epoch: 31, Loss (standarized): 0.5706421730163129\n",
      "          Validation Loss (standardized): 1.8527249497891485\n",
      "Epoch: 36, Loss (standarized): 0.5348412641821323\n",
      "          Validation Loss (standardized): 1.734618741004286\n",
      "Epoch: 41, Loss (standarized): 0.498358272915181\n",
      "          Validation Loss (standardized): 1.6569002755457742\n",
      "Epoch: 46, Loss (standarized): 0.4638800812550992\n",
      "          Validation Loss (standardized): 1.6192378662869564\n",
      "Epoch: 51, Loss (standarized): 0.42881306950728115\n",
      "          Validation Loss (standardized): 1.5893263965283144\n",
      "Epoch: 56, Loss (standarized): 0.39424669448837674\n",
      "          Validation Loss (standardized): 1.556691218702688\n",
      "Epoch: 61, Loss (standarized): 0.3640139117359841\n",
      "          Validation Loss (standardized): 1.519442372046265\n",
      "Epoch: 66, Loss (standarized): 0.3378883412732465\n",
      "          Validation Loss (standardized): 1.478253534834317\n",
      "Epoch: 71, Loss (standarized): 0.31529288674325034\n",
      "          Validation Loss (standardized): 1.431181379579903\n",
      "Epoch: 76, Loss (standarized): 0.29663593174601494\n",
      "          Validation Loss (standardized): 1.3847966804024792\n",
      "Epoch: 81, Loss (standarized): 0.2813720930009566\n",
      "          Validation Loss (standardized): 1.3465482995803881\n",
      "Epoch: 86, Loss (standarized): 0.2688328589582\n",
      "          Validation Loss (standardized): 1.3161993166163728\n",
      "Epoch: 91, Loss (standarized): 0.25877067383143415\n",
      "          Validation Loss (standardized): 1.291156004779486\n",
      "Epoch: 96, Loss (standarized): 0.2511482955117938\n",
      "          Validation Loss (standardized): 1.270404666253608\n",
      "Final epoch: 100, Final loss (standarized): 0.2464200086704027\n",
      "Epoch: 1, Loss (standarized): 0.9866450189045531\n",
      "          Validation Loss (standardized): 1.6396447953204416\n",
      "Epoch: 6, Loss (standarized): 0.689650028532622\n",
      "          Validation Loss (standardized): 2.351239177173683\n",
      "Epoch: 11, Loss (standarized): 0.6815454485064862\n",
      "          Validation Loss (standardized): 2.3377618655826287\n",
      "Epoch: 16, Loss (standarized): 0.6356973693849122\n",
      "          Validation Loss (standardized): 1.9649413108939051\n",
      "Epoch: 21, Loss (standarized): 0.6080649915504003\n",
      "          Validation Loss (standardized): 1.6767839366224644\n",
      "Epoch: 26, Loss (standarized): 0.5757833216157068\n",
      "          Validation Loss (standardized): 1.6164568151435446\n",
      "Epoch: 31, Loss (standarized): 0.5385621775686487\n",
      "          Validation Loss (standardized): 1.6682187886507627\n",
      "Epoch: 36, Loss (standarized): 0.4946877684730094\n",
      "          Validation Loss (standardized): 1.6656742897731738\n",
      "Epoch: 41, Loss (standarized): 0.44303531719384054\n",
      "          Validation Loss (standardized): 1.6128388777791143\n",
      "Epoch: 46, Loss (standarized): 0.3866220324539456\n",
      "          Validation Loss (standardized): 1.5383271340418532\n",
      "Epoch: 51, Loss (standarized): 0.32926069034712374\n",
      "          Validation Loss (standardized): 1.4411306198329124\n",
      "Epoch: 56, Loss (standarized): 0.2769011274391841\n",
      "          Validation Loss (standardized): 1.3680408791097307\n",
      "Epoch: 61, Loss (standarized): 0.2373008062984525\n",
      "          Validation Loss (standardized): 1.3061844603207597\n",
      "Epoch: 66, Loss (standarized): 0.2073520626000911\n",
      "          Validation Loss (standardized): 1.1377478203622302\n",
      "Epoch: 71, Loss (standarized): 0.1839929912352027\n",
      "          Validation Loss (standardized): 1.0626982305861044\n",
      "Epoch: 76, Loss (standarized): 0.16594165122321086\n",
      "          Validation Loss (standardized): 0.9942106900731703\n",
      "Epoch: 81, Loss (standarized): 0.15181741164883353\n",
      "          Validation Loss (standardized): 0.938272041796379\n",
      "Epoch: 86, Loss (standarized): 0.1395577140069052\n",
      "          Validation Loss (standardized): 0.8867566522705642\n",
      "Epoch: 91, Loss (standarized): 0.1293236070970387\n",
      "          Validation Loss (standardized): 0.8380149005242272\n",
      "Epoch: 96, Loss (standarized): 0.12069861776883135\n",
      "          Validation Loss (standardized): 0.7825731402570415\n",
      "Final epoch: 100, Final loss (standarized): 0.11478077712479927\n",
      "Epoch: 1, Loss (standarized): 1.5266702839773414\n",
      "          Validation Loss (standardized): 1.572526686429524\n",
      "Epoch: 6, Loss (standarized): 0.7348124081282894\n",
      "          Validation Loss (standardized): 1.9590127863362063\n",
      "Epoch: 11, Loss (standarized): 0.6703797824389105\n",
      "          Validation Loss (standardized): 2.418002633630695\n",
      "Epoch: 16, Loss (standarized): 0.6347633938109841\n",
      "          Validation Loss (standardized): 2.3512193631938936\n",
      "Epoch: 21, Loss (standarized): 0.5934348060839065\n",
      "          Validation Loss (standardized): 2.069167194795603\n",
      "Epoch: 26, Loss (standarized): 0.5477553246498833\n",
      "          Validation Loss (standardized): 1.893024265932564\n",
      "Epoch: 31, Loss (standarized): 0.503115204662024\n",
      "          Validation Loss (standardized): 1.849448084148149\n",
      "Epoch: 36, Loss (standarized): 0.4613816360700317\n",
      "          Validation Loss (standardized): 1.777609579270754\n",
      "Epoch: 41, Loss (standarized): 0.41775450890434424\n",
      "          Validation Loss (standardized): 1.640255803015843\n",
      "Epoch: 46, Loss (standarized): 0.37451885064438556\n",
      "          Validation Loss (standardized): 1.4974721385736351\n",
      "Epoch: 51, Loss (standarized): 0.3330561191189148\n",
      "          Validation Loss (standardized): 1.4204721777420088\n",
      "Epoch: 56, Loss (standarized): 0.2948124338906596\n",
      "          Validation Loss (standardized): 1.3594806103435444\n",
      "Epoch: 61, Loss (standarized): 0.26217315793663154\n",
      "          Validation Loss (standardized): 1.2627945391827657\n",
      "Epoch: 66, Loss (standarized): 0.2354370259737009\n",
      "          Validation Loss (standardized): 1.1981473488637258\n",
      "Epoch: 71, Loss (standarized): 0.2124956406492464\n",
      "          Validation Loss (standardized): 1.1285137725085215\n",
      "Epoch: 76, Loss (standarized): 0.1928665118068215\n",
      "          Validation Loss (standardized): 1.0669577096868956\n",
      "Epoch: 81, Loss (standarized): 0.17650665342229288\n",
      "          Validation Loss (standardized): 0.9866653464113375\n",
      "Epoch: 86, Loss (standarized): 0.16260631709329706\n",
      "          Validation Loss (standardized): 0.9351464087984164\n",
      "Epoch: 91, Loss (standarized): 0.15043386145418838\n",
      "          Validation Loss (standardized): 0.8737485762593306\n",
      "Epoch: 96, Loss (standarized): 0.13990141493282446\n",
      "          Validation Loss (standardized): 0.8386051506880579\n",
      "Final epoch: 100, Final loss (standarized): 0.1324992475327938\n",
      "Epoch: 1, Loss (standarized): 1.7334799256696323\n",
      "          Validation Loss (standardized): 1.3648005893482795\n",
      "Epoch: 6, Loss (standarized): 0.971468211950273\n",
      "          Validation Loss (standardized): 1.4134707562597357\n",
      "Epoch: 11, Loss (standarized): 0.7088490748675479\n",
      "          Validation Loss (standardized): 1.7843900732790783\n",
      "Epoch: 16, Loss (standarized): 0.679515108661901\n",
      "          Validation Loss (standardized): 1.9847797406078957\n",
      "Epoch: 21, Loss (standarized): 0.6503159712478656\n",
      "          Validation Loss (standardized): 1.939687317400754\n",
      "Epoch: 26, Loss (standarized): 0.6373942170163109\n",
      "          Validation Loss (standardized): 1.7991021806879424\n",
      "Epoch: 31, Loss (standarized): 0.6273342385239138\n",
      "          Validation Loss (standardized): 1.6545865767998897\n",
      "Epoch: 36, Loss (standarized): 0.6161450129085527\n",
      "          Validation Loss (standardized): 1.553927293766451\n",
      "Epoch: 41, Loss (standarized): 0.6071380144531915\n",
      "          Validation Loss (standardized): 1.5107912891998425\n",
      "Epoch: 46, Loss (standarized): 0.5997452437777162\n",
      "          Validation Loss (standardized): 1.5030273074641871\n",
      "Epoch: 51, Loss (standarized): 0.5940473163563487\n",
      "          Validation Loss (standardized): 1.5114140647097842\n",
      "Epoch: 56, Loss (standarized): 0.5894912781750501\n",
      "          Validation Loss (standardized): 1.5190867606863068\n",
      "Epoch: 61, Loss (standarized): 0.584239538293502\n",
      "          Validation Loss (standardized): 1.5328528478986785\n",
      "Epoch: 66, Loss (standarized): 0.5786111801666954\n",
      "          Validation Loss (standardized): 1.5519321078720494\n",
      "Epoch: 71, Loss (standarized): 0.5734660730200997\n",
      "          Validation Loss (standardized): 1.560055167770045\n",
      "Epoch: 76, Loss (standarized): 0.5684829796938576\n",
      "          Validation Loss (standardized): 1.5561327933349807\n",
      "Epoch: 81, Loss (standarized): 0.5631736287183797\n",
      "          Validation Loss (standardized): 1.5541369644468983\n",
      "Epoch: 86, Loss (standarized): 0.5566638790282745\n",
      "          Validation Loss (standardized): 1.5482904195434544\n",
      "Epoch: 91, Loss (standarized): 0.5511313846665999\n",
      "          Validation Loss (standardized): 1.5374781736121863\n",
      "Epoch: 96, Loss (standarized): 0.5454225082528319\n",
      "          Validation Loss (standardized): 1.5327788250669518\n",
      "Final epoch: 100, Final loss (standarized): 0.5405494641467348\n",
      "Epoch: 1, Loss (standarized): 2.2214932199056734\n",
      "          Validation Loss (standardized): 1.6132528337018242\n",
      "Epoch: 6, Loss (standarized): 1.023407973605919\n",
      "          Validation Loss (standardized): 1.3546100258619287\n",
      "Epoch: 11, Loss (standarized): 0.7593855677467056\n",
      "          Validation Loss (standardized): 1.6555194608722903\n",
      "Epoch: 16, Loss (standarized): 0.697307843745844\n",
      "          Validation Loss (standardized): 1.9014691453121695\n",
      "Epoch: 21, Loss (standarized): 0.6701553104987024\n",
      "          Validation Loss (standardized): 2.008796670754951\n",
      "Epoch: 26, Loss (standarized): 0.6582598199917701\n",
      "          Validation Loss (standardized): 1.948469647915797\n",
      "Epoch: 31, Loss (standarized): 0.6370603192789693\n",
      "          Validation Loss (standardized): 1.8339898724641066\n",
      "Epoch: 36, Loss (standarized): 0.6273145250565839\n",
      "          Validation Loss (standardized): 1.7344447583388227\n",
      "Epoch: 41, Loss (standarized): 0.620719464667259\n",
      "          Validation Loss (standardized): 1.6413902299572634\n",
      "Epoch: 46, Loss (standarized): 0.6169360823897392\n",
      "          Validation Loss (standardized): 1.5731157959571391\n",
      "Epoch: 51, Loss (standarized): 0.6120274981506965\n",
      "          Validation Loss (standardized): 1.5251976867250687\n",
      "Epoch: 56, Loss (standarized): 0.6080472524295014\n",
      "          Validation Loss (standardized): 1.4996883634666334\n",
      "Epoch: 61, Loss (standarized): 0.6048526181293805\n",
      "          Validation Loss (standardized): 1.4867970315169015\n",
      "Epoch: 66, Loss (standarized): 0.6013093110931079\n",
      "          Validation Loss (standardized): 1.4850067027422407\n",
      "Epoch: 71, Loss (standarized): 0.5966117273815335\n",
      "          Validation Loss (standardized): 1.4879279111536057\n",
      "Epoch: 76, Loss (standarized): 0.591694003789868\n",
      "          Validation Loss (standardized): 1.4952938883058\n",
      "Epoch: 81, Loss (standarized): 0.586784299876951\n",
      "          Validation Loss (standardized): 1.496974334148674\n",
      "Epoch: 86, Loss (standarized): 0.5816490514946245\n",
      "          Validation Loss (standardized): 1.501212300620591\n",
      "Epoch: 91, Loss (standarized): 0.5763948263806106\n",
      "          Validation Loss (standardized): 1.516674223661211\n",
      "Epoch: 96, Loss (standarized): 0.5719382166199821\n",
      "          Validation Loss (standardized): 1.5238208133199593\n",
      "Final epoch: 100, Final loss (standarized): 0.5681716142741488\n",
      "Epoch: 1, Loss (standarized): 1.6638058752753704\n",
      "          Validation Loss (standardized): 1.0733005492309307\n",
      "Epoch: 6, Loss (standarized): 0.8167169346041918\n",
      "          Validation Loss (standardized): 1.4133691837598301\n",
      "Epoch: 11, Loss (standarized): 0.7451014207939052\n",
      "          Validation Loss (standardized): 1.7976665096017268\n",
      "Epoch: 16, Loss (standarized): 0.71833520976735\n",
      "          Validation Loss (standardized): 1.9690734577243982\n",
      "Epoch: 21, Loss (standarized): 0.69379204192743\n",
      "          Validation Loss (standardized): 1.9990940039532206\n",
      "Epoch: 26, Loss (standarized): 0.6722552463793513\n",
      "          Validation Loss (standardized): 1.9502365893591556\n",
      "Epoch: 31, Loss (standarized): 0.6528418088973774\n",
      "          Validation Loss (standardized): 1.8700921939889097\n",
      "Epoch: 36, Loss (standarized): 0.6379875143456663\n",
      "          Validation Loss (standardized): 1.789178629931992\n",
      "Epoch: 41, Loss (standarized): 0.6247099705835746\n",
      "          Validation Loss (standardized): 1.7105377381888545\n",
      "Epoch: 46, Loss (standarized): 0.6104593962949529\n",
      "          Validation Loss (standardized): 1.642935069876324\n",
      "Epoch: 51, Loss (standarized): 0.5980435903891167\n",
      "          Validation Loss (standardized): 1.6133139650362196\n",
      "Epoch: 56, Loss (standarized): 0.5869172189653046\n",
      "          Validation Loss (standardized): 1.6067601370130014\n",
      "Epoch: 61, Loss (standarized): 0.5765137960229307\n",
      "          Validation Loss (standardized): 1.601251786057553\n",
      "Epoch: 66, Loss (standarized): 0.5672459119990864\n",
      "          Validation Loss (standardized): 1.5875355538714568\n",
      "Epoch: 71, Loss (standarized): 0.5590044599622864\n",
      "          Validation Loss (standardized): 1.5745200083121562\n",
      "Epoch: 76, Loss (standarized): 0.5515961694989071\n",
      "          Validation Loss (standardized): 1.5640931921054406\n",
      "Epoch: 81, Loss (standarized): 0.5444462732073483\n",
      "          Validation Loss (standardized): 1.553903704954927\n",
      "Epoch: 86, Loss (standarized): 0.5365848535516238\n",
      "          Validation Loss (standardized): 1.5529735015986312\n",
      "Epoch: 91, Loss (standarized): 0.5282817703507157\n",
      "          Validation Loss (standardized): 1.5684339958960496\n",
      "Epoch: 96, Loss (standarized): 0.5197590133780802\n",
      "          Validation Loss (standardized): 1.570195511404861\n",
      "Final epoch: 100, Final loss (standarized): 0.5131690576044395\n",
      "Epoch: 1, Loss (standarized): 1.1797626821427611\n",
      "          Validation Loss (standardized): 1.67369840835888\n",
      "Epoch: 6, Loss (standarized): 0.7071076545298421\n",
      "          Validation Loss (standardized): 2.0321332411801882\n",
      "Epoch: 11, Loss (standarized): 0.6677738024580555\n",
      "          Validation Loss (standardized): 2.048460701536034\n",
      "Epoch: 16, Loss (standarized): 0.6413183520200108\n",
      "          Validation Loss (standardized): 1.824831069747395\n",
      "Epoch: 21, Loss (standarized): 0.62906506512214\n",
      "          Validation Loss (standardized): 1.6592905217686744\n",
      "Epoch: 26, Loss (standarized): 0.6120475539357053\n",
      "          Validation Loss (standardized): 1.6226317150730767\n",
      "Epoch: 31, Loss (standarized): 0.597391353072616\n",
      "          Validation Loss (standardized): 1.6667724037510774\n",
      "Epoch: 36, Loss (standarized): 0.5839957912688449\n",
      "          Validation Loss (standardized): 1.6753530845606321\n",
      "Epoch: 41, Loss (standarized): 0.5717392439372097\n",
      "          Validation Loss (standardized): 1.6242937132640116\n",
      "Epoch: 46, Loss (standarized): 0.5580579643858852\n",
      "          Validation Loss (standardized): 1.6012308454837043\n",
      "Epoch: 51, Loss (standarized): 0.5439922735644601\n",
      "          Validation Loss (standardized): 1.6051192883147385\n",
      "Epoch: 56, Loss (standarized): 0.5310293086569211\n",
      "          Validation Loss (standardized): 1.5881084632206226\n",
      "Epoch: 61, Loss (standarized): 0.5166304482333116\n",
      "          Validation Loss (standardized): 1.571838707672052\n",
      "Epoch: 66, Loss (standarized): 0.503636146815911\n",
      "          Validation Loss (standardized): 1.554206698876747\n",
      "Epoch: 71, Loss (standarized): 0.4910469176600427\n",
      "          Validation Loss (standardized): 1.5583929558351215\n",
      "Epoch: 76, Loss (standarized): 0.47909677084883295\n",
      "          Validation Loss (standardized): 1.5732211232565956\n",
      "Epoch: 81, Loss (standarized): 0.4616539157814058\n",
      "          Validation Loss (standardized): 1.5973186066556624\n",
      "Epoch: 86, Loss (standarized): 0.44971563011550736\n",
      "          Validation Loss (standardized): 1.5850014317193681\n",
      "Epoch: 91, Loss (standarized): 0.44037144607127443\n",
      "          Validation Loss (standardized): 1.5674622726319651\n",
      "Epoch: 96, Loss (standarized): 0.429541969827167\n",
      "          Validation Loss (standardized): 1.5611153060768577\n",
      "Final epoch: 100, Final loss (standarized): 0.4209052736753259\n",
      "Epoch: 1, Loss (standarized): 0.9733692784805965\n",
      "          Validation Loss (standardized): 1.6371341805131328\n",
      "Epoch: 6, Loss (standarized): 0.714418901040081\n",
      "          Validation Loss (standardized): 2.1903699588807375\n",
      "Epoch: 11, Loss (standarized): 0.6447733732777413\n",
      "          Validation Loss (standardized): 2.0432950300214063\n",
      "Epoch: 16, Loss (standarized): 0.6182199476617167\n",
      "          Validation Loss (standardized): 1.8318234936666031\n",
      "Epoch: 21, Loss (standarized): 0.5719943649489142\n",
      "          Validation Loss (standardized): 1.7126462821486061\n",
      "Epoch: 26, Loss (standarized): 0.5373619748680293\n",
      "          Validation Loss (standardized): 1.6086463188867384\n",
      "Epoch: 31, Loss (standarized): 0.49961519669029425\n",
      "          Validation Loss (standardized): 1.505090737090088\n",
      "Epoch: 36, Loss (standarized): 0.45805516874179386\n",
      "          Validation Loss (standardized): 1.4685881618694538\n",
      "Epoch: 41, Loss (standarized): 0.41617705008525585\n",
      "          Validation Loss (standardized): 1.429236346092237\n",
      "Epoch: 46, Loss (standarized): 0.37427100221785925\n",
      "          Validation Loss (standardized): 1.354283527699772\n",
      "Epoch: 51, Loss (standarized): 0.332055193291589\n",
      "          Validation Loss (standardized): 1.3164666871053845\n",
      "Epoch: 56, Loss (standarized): 0.29412814101254947\n",
      "          Validation Loss (standardized): 1.2404426901465755\n",
      "Epoch: 61, Loss (standarized): 0.2607257980347428\n",
      "          Validation Loss (standardized): 1.1794566840480416\n",
      "Epoch: 66, Loss (standarized): 0.23201045485772978\n",
      "          Validation Loss (standardized): 1.1114173997747863\n",
      "Epoch: 71, Loss (standarized): 0.20871008110662215\n",
      "          Validation Loss (standardized): 1.0550005410034282\n",
      "Epoch: 76, Loss (standarized): 0.19044000643927744\n",
      "          Validation Loss (standardized): 1.010349209116295\n",
      "Epoch: 81, Loss (standarized): 0.1756205223374105\n",
      "          Validation Loss (standardized): 0.967324416710456\n",
      "Epoch: 86, Loss (standarized): 0.16321787187498205\n",
      "          Validation Loss (standardized): 0.9245621126531879\n",
      "Epoch: 91, Loss (standarized): 0.1528782687452643\n",
      "          Validation Loss (standardized): 0.876132004152633\n",
      "Epoch: 96, Loss (standarized): 0.14420136214417267\n",
      "          Validation Loss (standardized): 0.843287845467554\n",
      "Final epoch: 100, Final loss (standarized): 0.13809092694498948\n",
      "Epoch: 1, Loss (standarized): 0.9392204271316723\n",
      "          Validation Loss (standardized): 1.3468510038443238\n",
      "Epoch: 6, Loss (standarized): 0.6992557335366753\n",
      "          Validation Loss (standardized): 1.6865812477984945\n",
      "Epoch: 11, Loss (standarized): 0.6611520515190921\n",
      "          Validation Loss (standardized): 1.8999883837534608\n",
      "Epoch: 16, Loss (standarized): 0.6357451131255238\n",
      "          Validation Loss (standardized): 1.8845454615941493\n",
      "Epoch: 21, Loss (standarized): 0.6118809967922545\n",
      "          Validation Loss (standardized): 1.7573566546793582\n",
      "Epoch: 26, Loss (standarized): 0.5891208563035609\n",
      "          Validation Loss (standardized): 1.6349677470569797\n",
      "Epoch: 31, Loss (standarized): 0.5641740729533464\n",
      "          Validation Loss (standardized): 1.583081267524053\n",
      "Epoch: 36, Loss (standarized): 0.5356311273965931\n",
      "          Validation Loss (standardized): 1.5821226468005603\n",
      "Epoch: 41, Loss (standarized): 0.5060496008732054\n",
      "          Validation Loss (standardized): 1.5782484220197253\n",
      "Epoch: 46, Loss (standarized): 0.4746438503867074\n",
      "          Validation Loss (standardized): 1.5499375521634795\n",
      "Epoch: 51, Loss (standarized): 0.4426313324966411\n",
      "          Validation Loss (standardized): 1.5107946559470702\n",
      "Epoch: 56, Loss (standarized): 0.4105408459761113\n",
      "          Validation Loss (standardized): 1.4764896110606287\n",
      "Epoch: 61, Loss (standarized): 0.37706135507608235\n",
      "          Validation Loss (standardized): 1.4436063033769675\n",
      "Epoch: 66, Loss (standarized): 0.34551440340009076\n",
      "          Validation Loss (standardized): 1.4051643086189638\n",
      "Epoch: 71, Loss (standarized): 0.3179284765371558\n",
      "          Validation Loss (standardized): 1.3666432773691501\n",
      "Epoch: 76, Loss (standarized): 0.2949808862227041\n",
      "          Validation Loss (standardized): 1.336976358184892\n",
      "Epoch: 81, Loss (standarized): 0.2775639201150339\n",
      "          Validation Loss (standardized): 1.3067845050909725\n",
      "Epoch: 86, Loss (standarized): 0.26546158184493623\n",
      "          Validation Loss (standardized): 1.2767986916143967\n",
      "Epoch: 91, Loss (standarized): 0.25717573112563014\n",
      "          Validation Loss (standardized): 1.256082975853661\n",
      "Epoch: 96, Loss (standarized): 0.25191406923433746\n",
      "          Validation Loss (standardized): 1.240540629002803\n",
      "Final epoch: 100, Final loss (standarized): 0.24927542981551146\n",
      "Epoch: 1, Loss (standarized): 0.7844291292358186\n",
      "          Validation Loss (standardized): 1.37599662908352\n",
      "Epoch: 6, Loss (standarized): 0.6532574315445965\n",
      "          Validation Loss (standardized): 2.016572846838672\n",
      "Epoch: 11, Loss (standarized): 0.621969429560204\n",
      "          Validation Loss (standardized): 2.0184831920519706\n",
      "Epoch: 16, Loss (standarized): 0.579881137754044\n",
      "          Validation Loss (standardized): 1.7756558310410597\n",
      "Epoch: 21, Loss (standarized): 0.5365451679716755\n",
      "          Validation Loss (standardized): 1.5908631780685627\n",
      "Epoch: 26, Loss (standarized): 0.49170093913820756\n",
      "          Validation Loss (standardized): 1.5471078199177064\n",
      "Epoch: 31, Loss (standarized): 0.4420545043089898\n",
      "          Validation Loss (standardized): 1.55369204204361\n",
      "Epoch: 36, Loss (standarized): 0.3905218627977855\n",
      "          Validation Loss (standardized): 1.54270841350711\n",
      "Epoch: 41, Loss (standarized): 0.3413355784887085\n",
      "          Validation Loss (standardized): 1.4709352995879097\n",
      "Epoch: 46, Loss (standarized): 0.2976545675088083\n",
      "          Validation Loss (standardized): 1.3663661143150867\n",
      "Epoch: 51, Loss (standarized): 0.2620577819886303\n",
      "          Validation Loss (standardized): 1.2502734987668784\n",
      "Epoch: 56, Loss (standarized): 0.23534281260379208\n",
      "          Validation Loss (standardized): 1.1629924097466506\n",
      "Epoch: 61, Loss (standarized): 0.2153455067023059\n",
      "          Validation Loss (standardized): 1.1100641698520595\n",
      "Epoch: 66, Loss (standarized): 0.19924438321769855\n",
      "          Validation Loss (standardized): 1.0601500606125585\n",
      "Epoch: 71, Loss (standarized): 0.18636861908529698\n",
      "          Validation Loss (standardized): 1.0189677157745258\n",
      "Epoch: 76, Loss (standarized): 0.1758955600980976\n",
      "          Validation Loss (standardized): 0.9789023372845557\n",
      "Epoch: 81, Loss (standarized): 0.16741603335931424\n",
      "          Validation Loss (standardized): 0.9362768575940895\n",
      "Epoch: 86, Loss (standarized): 0.15992430786133485\n",
      "          Validation Loss (standardized): 0.9052893062305725\n",
      "Epoch: 91, Loss (standarized): 0.15319538557680212\n",
      "          Validation Loss (standardized): 0.8648053177554516\n",
      "Epoch: 96, Loss (standarized): 0.14720776756085016\n",
      "          Validation Loss (standardized): 0.8375219094461831\n",
      "Final epoch: 100, Final loss (standarized): 0.1429271452393103\n",
      "Epoch: 1, Loss (standarized): 1.7861011792494532\n",
      "          Validation Loss (standardized): 2.6583098775368583\n",
      "Epoch: 6, Loss (standarized): 0.8450851993337575\n",
      "          Validation Loss (standardized): 1.7429219659053596\n",
      "Epoch: 11, Loss (standarized): 0.7266790627091301\n",
      "          Validation Loss (standardized): 1.8176560698944286\n",
      "Epoch: 16, Loss (standarized): 0.696906824340917\n",
      "          Validation Loss (standardized): 1.7549325678100371\n",
      "Epoch: 21, Loss (standarized): 0.6426885299024894\n",
      "          Validation Loss (standardized): 1.610545974212569\n",
      "Epoch: 26, Loss (standarized): 0.6169849871626604\n",
      "          Validation Loss (standardized): 1.6238846633591337\n",
      "Epoch: 31, Loss (standarized): 0.598391933447078\n",
      "          Validation Loss (standardized): 1.7503366799730466\n",
      "Epoch: 36, Loss (standarized): 0.5811788092109187\n",
      "          Validation Loss (standardized): 1.7967361826899317\n",
      "Epoch: 41, Loss (standarized): 0.5627408428929472\n",
      "          Validation Loss (standardized): 1.7097341409237965\n",
      "Epoch: 46, Loss (standarized): 0.5402167398205304\n",
      "          Validation Loss (standardized): 1.5852981713751684\n",
      "Epoch: 51, Loss (standarized): 0.5175185771505636\n",
      "          Validation Loss (standardized): 1.5332436921075296\n",
      "Epoch: 56, Loss (standarized): 0.48865481044330344\n",
      "          Validation Loss (standardized): 1.5447112136785697\n",
      "Epoch: 61, Loss (standarized): 0.4545712519095511\n",
      "          Validation Loss (standardized): 1.5230642070338503\n",
      "Epoch: 66, Loss (standarized): 0.4134655314461163\n",
      "          Validation Loss (standardized): 1.4291950665041548\n",
      "Epoch: 71, Loss (standarized): 0.37053546343183374\n",
      "          Validation Loss (standardized): 1.34642581890763\n",
      "Epoch: 76, Loss (standarized): 0.32727861907507416\n",
      "          Validation Loss (standardized): 1.3020835511772983\n",
      "Epoch: 81, Loss (standarized): 0.28531299910753954\n",
      "          Validation Loss (standardized): 1.2167122047089673\n",
      "Epoch: 86, Loss (standarized): 0.24975656450529693\n",
      "          Validation Loss (standardized): 1.1262971380531868\n",
      "Epoch: 91, Loss (standarized): 0.22122244801299795\n",
      "          Validation Loss (standardized): 1.0795373779235207\n",
      "Epoch: 96, Loss (standarized): 0.1979003350308598\n",
      "          Validation Loss (standardized): 0.9797296226545109\n",
      "Final epoch: 100, Final loss (standarized): 0.1831757826494334\n",
      "Epoch: 1, Loss (standarized): 2.5567176515343495\n",
      "          Validation Loss (standardized): 1.334400031061235\n",
      "Epoch: 6, Loss (standarized): 0.8338343704919804\n",
      "          Validation Loss (standardized): 1.5135580275603888\n",
      "Epoch: 11, Loss (standarized): 0.6766869029481715\n",
      "          Validation Loss (standardized): 2.351769941010375\n",
      "Epoch: 16, Loss (standarized): 0.6855866269503079\n",
      "          Validation Loss (standardized): 2.731136192212467\n",
      "Epoch: 21, Loss (standarized): 0.6572355461731877\n",
      "          Validation Loss (standardized): 2.717022617763971\n",
      "Epoch: 26, Loss (standarized): 0.6280397197132463\n",
      "          Validation Loss (standardized): 2.5100367344424463\n",
      "Epoch: 31, Loss (standarized): 0.5937619706652046\n",
      "          Validation Loss (standardized): 2.258882638307973\n",
      "Epoch: 36, Loss (standarized): 0.5607572269885921\n",
      "          Validation Loss (standardized): 2.0412005488036074\n",
      "Epoch: 41, Loss (standarized): 0.5317071295372439\n",
      "          Validation Loss (standardized): 1.8662892768428136\n",
      "Epoch: 46, Loss (standarized): 0.5031141758974371\n",
      "          Validation Loss (standardized): 1.7482898428666611\n",
      "Epoch: 51, Loss (standarized): 0.4720162263339461\n",
      "          Validation Loss (standardized): 1.6923067749488176\n",
      "Epoch: 56, Loss (standarized): 0.4368198554623253\n",
      "          Validation Loss (standardized): 1.6814563305275596\n",
      "Epoch: 61, Loss (standarized): 0.40157937631688806\n",
      "          Validation Loss (standardized): 1.679471896772048\n",
      "Epoch: 66, Loss (standarized): 0.3682234916805764\n",
      "          Validation Loss (standardized): 1.665735811055273\n",
      "Epoch: 71, Loss (standarized): 0.33679339095056043\n",
      "          Validation Loss (standardized): 1.6282786205784903\n",
      "Epoch: 76, Loss (standarized): 0.30898692700267544\n",
      "          Validation Loss (standardized): 1.568384274214564\n",
      "Epoch: 81, Loss (standarized): 0.28451309922629725\n",
      "          Validation Loss (standardized): 1.4987134212275164\n",
      "Epoch: 86, Loss (standarized): 0.26319349348100923\n",
      "          Validation Loss (standardized): 1.4267764661608828\n",
      "Epoch: 91, Loss (standarized): 0.24477031224318188\n",
      "          Validation Loss (standardized): 1.35667660157055\n",
      "Epoch: 96, Loss (standarized): 0.2289514253648996\n",
      "          Validation Loss (standardized): 1.2978813828784412\n",
      "Final epoch: 100, Final loss (standarized): 0.21820542801682696\n",
      "Epoch: 1, Loss (standarized): 1.60528388190828\n",
      "          Validation Loss (standardized): 1.2828223338105846\n",
      "Epoch: 6, Loss (standarized): 0.7330199002134518\n",
      "          Validation Loss (standardized): 1.388955801783807\n",
      "Epoch: 11, Loss (standarized): 0.6765913656913183\n",
      "          Validation Loss (standardized): 1.9321271499965407\n",
      "Epoch: 16, Loss (standarized): 0.6401178962780625\n",
      "          Validation Loss (standardized): 2.2291109495189723\n",
      "Epoch: 21, Loss (standarized): 0.6062776929887203\n",
      "          Validation Loss (standardized): 2.2149811872476395\n",
      "Epoch: 26, Loss (standarized): 0.5756018206886857\n",
      "          Validation Loss (standardized): 2.0339369891280312\n",
      "Epoch: 31, Loss (standarized): 0.5348442534053864\n",
      "          Validation Loss (standardized): 1.8506331409422683\n",
      "Epoch: 36, Loss (standarized): 0.49918624819669366\n",
      "          Validation Loss (standardized): 1.6844524700598245\n",
      "Epoch: 41, Loss (standarized): 0.4610716631370746\n",
      "          Validation Loss (standardized): 1.6270925910599139\n",
      "Epoch: 46, Loss (standarized): 0.42193594806364165\n",
      "          Validation Loss (standardized): 1.6000182569979027\n",
      "Epoch: 51, Loss (standarized): 0.3845549667821336\n",
      "          Validation Loss (standardized): 1.6149345637149435\n",
      "Epoch: 56, Loss (standarized): 0.3502304007855134\n",
      "          Validation Loss (standardized): 1.60904471542656\n",
      "Epoch: 61, Loss (standarized): 0.3231026970036067\n",
      "          Validation Loss (standardized): 1.566507420695911\n",
      "Epoch: 66, Loss (standarized): 0.30147325041678774\n",
      "          Validation Loss (standardized): 1.4947744533699783\n",
      "Epoch: 71, Loss (standarized): 0.28451946350781193\n",
      "          Validation Loss (standardized): 1.426326946769503\n",
      "Epoch: 76, Loss (standarized): 0.2714281476651855\n",
      "          Validation Loss (standardized): 1.361301935931889\n",
      "Epoch: 81, Loss (standarized): 0.260774549015319\n",
      "          Validation Loss (standardized): 1.307175383460229\n",
      "Epoch: 86, Loss (standarized): 0.2520927664152855\n",
      "          Validation Loss (standardized): 1.265188878340231\n",
      "Epoch: 91, Loss (standarized): 0.24546391646047389\n",
      "          Validation Loss (standardized): 1.2365100270268778\n",
      "Epoch: 96, Loss (standarized): 0.24058147802388102\n",
      "          Validation Loss (standardized): 1.211755592249206\n",
      "Final epoch: 100, Final loss (standarized): 0.2374534048961456\n",
      "Epoch: 1, Loss (standarized): 2.7599883536853014\n",
      "          Validation Loss (standardized): 1.820612682635922\n",
      "Epoch: 6, Loss (standarized): 1.0748340347388876\n",
      "          Validation Loss (standardized): 1.5241471705848804\n",
      "Epoch: 11, Loss (standarized): 0.8259380300307458\n",
      "          Validation Loss (standardized): 2.1038764425941436\n",
      "Epoch: 16, Loss (standarized): 0.7190619850408447\n",
      "          Validation Loss (standardized): 2.2308240413086478\n",
      "Epoch: 21, Loss (standarized): 0.6694534057570939\n",
      "          Validation Loss (standardized): 2.2364724747088065\n",
      "Epoch: 26, Loss (standarized): 0.667759480903168\n",
      "          Validation Loss (standardized): 2.1452160503533944\n",
      "Epoch: 31, Loss (standarized): 0.6240756874222132\n",
      "          Validation Loss (standardized): 1.9586967574940053\n",
      "Epoch: 36, Loss (standarized): 0.5965948753692013\n",
      "          Validation Loss (standardized): 1.7762981761184415\n",
      "Epoch: 41, Loss (standarized): 0.5802417741125038\n",
      "          Validation Loss (standardized): 1.6435910698683334\n",
      "Epoch: 46, Loss (standarized): 0.5610767093431864\n",
      "          Validation Loss (standardized): 1.5750290322238838\n",
      "Epoch: 51, Loss (standarized): 0.5439926528176208\n",
      "          Validation Loss (standardized): 1.56225846312316\n",
      "Epoch: 56, Loss (standarized): 0.5232713076615528\n",
      "          Validation Loss (standardized): 1.5651706659957632\n",
      "Epoch: 61, Loss (standarized): 0.5030635321532899\n",
      "          Validation Loss (standardized): 1.556437794396726\n",
      "Epoch: 66, Loss (standarized): 0.4824679270999451\n",
      "          Validation Loss (standardized): 1.5369465387642987\n",
      "Epoch: 71, Loss (standarized): 0.46282326442406896\n",
      "          Validation Loss (standardized): 1.5133581152768891\n",
      "Epoch: 76, Loss (standarized): 0.4433703134773985\n",
      "          Validation Loss (standardized): 1.4983117349259023\n",
      "Epoch: 81, Loss (standarized): 0.42404281947329253\n",
      "          Validation Loss (standardized): 1.4862038058720337\n",
      "Epoch: 86, Loss (standarized): 0.40480683227737563\n",
      "          Validation Loss (standardized): 1.4554637926633207\n",
      "Epoch: 91, Loss (standarized): 0.38562379379562856\n",
      "          Validation Loss (standardized): 1.417974795062652\n",
      "Epoch: 96, Loss (standarized): 0.366393322273527\n",
      "          Validation Loss (standardized): 1.3897361253848404\n",
      "Final epoch: 100, Final loss (standarized): 0.3508558675008565\n",
      "Epoch: 1, Loss (standarized): 1.5170703536481147\n",
      "          Validation Loss (standardized): 1.2680272425852164\n",
      "Epoch: 6, Loss (standarized): 0.8281621604212651\n",
      "          Validation Loss (standardized): 1.4772062701651971\n",
      "Epoch: 11, Loss (standarized): 0.6939322473580679\n",
      "          Validation Loss (standardized): 1.9271049400809739\n",
      "Epoch: 16, Loss (standarized): 0.6662055184836414\n",
      "          Validation Loss (standardized): 2.156863322764859\n",
      "Epoch: 21, Loss (standarized): 0.6401010943326078\n",
      "          Validation Loss (standardized): 2.1132385578567674\n",
      "Epoch: 26, Loss (standarized): 0.6137692502579283\n",
      "          Validation Loss (standardized): 1.948379837026779\n",
      "Epoch: 31, Loss (standarized): 0.5892004906840728\n",
      "          Validation Loss (standardized): 1.788124836482213\n",
      "Epoch: 36, Loss (standarized): 0.5591276889549083\n",
      "          Validation Loss (standardized): 1.7117806495502967\n",
      "Epoch: 41, Loss (standarized): 0.5240081277476359\n",
      "          Validation Loss (standardized): 1.7119505726393618\n",
      "Epoch: 46, Loss (standarized): 0.48601099599180553\n",
      "          Validation Loss (standardized): 1.6782032074515845\n",
      "Epoch: 51, Loss (standarized): 0.4437803740593511\n",
      "          Validation Loss (standardized): 1.5857308993398664\n",
      "Epoch: 56, Loss (standarized): 0.39809521776816936\n",
      "          Validation Loss (standardized): 1.5101024131755494\n",
      "Epoch: 61, Loss (standarized): 0.35380789513047867\n",
      "          Validation Loss (standardized): 1.4590254529372526\n",
      "Epoch: 66, Loss (standarized): 0.31442873921776604\n",
      "          Validation Loss (standardized): 1.398026870754747\n",
      "Epoch: 71, Loss (standarized): 0.2812805391724293\n",
      "          Validation Loss (standardized): 1.338476471499715\n",
      "Epoch: 76, Loss (standarized): 0.2529497755363952\n",
      "          Validation Loss (standardized): 1.253648497478015\n",
      "Epoch: 81, Loss (standarized): 0.22786426543080654\n",
      "          Validation Loss (standardized): 1.1858307119512708\n",
      "Epoch: 86, Loss (standarized): 0.20620669365000566\n",
      "          Validation Loss (standardized): 1.0890906858238423\n",
      "Epoch: 91, Loss (standarized): 0.18625877677534877\n",
      "          Validation Loss (standardized): 1.0500615418774242\n",
      "Epoch: 96, Loss (standarized): 0.169481587268256\n",
      "          Validation Loss (standardized): 0.9765598813590086\n",
      "Final epoch: 100, Final loss (standarized): 0.1579736057217158\n",
      "Epoch: 1, Loss (standarized): 1.2135693988401814\n",
      "Epoch: 6, Loss (standarized): 0.7135542796305391\n",
      "Epoch: 11, Loss (standarized): 0.6872768081870264\n",
      "Epoch: 16, Loss (standarized): 0.6446158255955645\n",
      "Epoch: 21, Loss (standarized): 0.6110400069561083\n",
      "Epoch: 26, Loss (standarized): 0.5833081379945946\n",
      "Epoch: 31, Loss (standarized): 0.5479801113418625\n",
      "Epoch: 36, Loss (standarized): 0.5103526784875175\n",
      "Epoch: 41, Loss (standarized): 0.4656704379745841\n",
      "Epoch: 46, Loss (standarized): 0.41891796727740627\n",
      "Epoch: 51, Loss (standarized): 0.37293716391771353\n",
      "Epoch: 56, Loss (standarized): 0.3271475948342344\n",
      "Epoch: 61, Loss (standarized): 0.28109955287789207\n",
      "Epoch: 66, Loss (standarized): 0.2428454099697764\n",
      "Epoch: 71, Loss (standarized): 0.21413468640499908\n",
      "Epoch: 76, Loss (standarized): 0.19227271479686953\n",
      "Epoch: 81, Loss (standarized): 0.17521478553625552\n",
      "Epoch: 86, Loss (standarized): 0.1604620518982695\n",
      "Epoch: 91, Loss (standarized): 0.14835361899957852\n",
      "Epoch: 96, Loss (standarized): 0.1382927869265962\n",
      "Final epoch: 100, Final loss (standarized): 0.13116645359272147\n",
      "Epoch: 1, Loss (standarized): 1.7479722598865106\n",
      "Epoch: 6, Loss (standarized): 0.9218745802722716\n",
      "Epoch: 11, Loss (standarized): 0.6940095351140041\n",
      "Epoch: 16, Loss (standarized): 0.6583427040488082\n",
      "Epoch: 21, Loss (standarized): 0.6407508595439643\n",
      "Epoch: 26, Loss (standarized): 0.611192618834269\n",
      "Epoch: 31, Loss (standarized): 0.5857317051950292\n",
      "Epoch: 36, Loss (standarized): 0.5575737928598188\n",
      "Epoch: 41, Loss (standarized): 0.523092853086674\n",
      "Epoch: 46, Loss (standarized): 0.48614331228689\n",
      "Epoch: 51, Loss (standarized): 0.44977680159100336\n",
      "Epoch: 56, Loss (standarized): 0.4148770953063629\n",
      "Epoch: 61, Loss (standarized): 0.38292417453454924\n",
      "Epoch: 66, Loss (standarized): 0.3534561813582651\n",
      "Epoch: 71, Loss (standarized): 0.3270973266185746\n",
      "Epoch: 76, Loss (standarized): 0.30403544516865827\n",
      "Epoch: 81, Loss (standarized): 0.2856080351778053\n",
      "Epoch: 86, Loss (standarized): 0.270092816460938\n",
      "Epoch: 91, Loss (standarized): 0.25775602645826406\n",
      "Epoch: 96, Loss (standarized): 0.24798016194286981\n",
      "Final epoch: 100, Final loss (standarized): 0.2420362801776028\n",
      "Epoch: 1, Loss (standarized): 1.7098416298191248\n",
      "Epoch: 6, Loss (standarized): 0.8329073105626784\n",
      "Epoch: 11, Loss (standarized): 0.6971364789292039\n",
      "Epoch: 16, Loss (standarized): 0.6601266016607192\n",
      "Epoch: 21, Loss (standarized): 0.6423828898318651\n",
      "Epoch: 26, Loss (standarized): 0.6092664952524315\n",
      "Epoch: 31, Loss (standarized): 0.5753899251956524\n",
      "Epoch: 36, Loss (standarized): 0.5444264937802158\n",
      "Epoch: 41, Loss (standarized): 0.5139220225515286\n",
      "Epoch: 46, Loss (standarized): 0.47779247319986096\n",
      "Epoch: 51, Loss (standarized): 0.4392352092970385\n",
      "Epoch: 56, Loss (standarized): 0.4004734650965549\n",
      "Epoch: 61, Loss (standarized): 0.3635855303929588\n",
      "Epoch: 66, Loss (standarized): 0.32938628394905506\n",
      "Epoch: 71, Loss (standarized): 0.29725085805700663\n",
      "Epoch: 76, Loss (standarized): 0.26899591397890754\n",
      "Epoch: 81, Loss (standarized): 0.24503312237789499\n",
      "Epoch: 86, Loss (standarized): 0.22588408174360583\n",
      "Epoch: 91, Loss (standarized): 0.21048590476525622\n",
      "Epoch: 96, Loss (standarized): 0.19752545482240189\n",
      "Final epoch: 100, Final loss (standarized): 0.18841770531830018\n",
      "Epoch: 1, Loss (standarized): 1.0869927779635122\n",
      "Epoch: 6, Loss (standarized): 0.7104132023882861\n",
      "Epoch: 11, Loss (standarized): 0.6435717220505109\n",
      "Epoch: 16, Loss (standarized): 0.6140748778218253\n",
      "Epoch: 21, Loss (standarized): 0.5798063379920201\n",
      "Epoch: 26, Loss (standarized): 0.5465003113364764\n",
      "Epoch: 31, Loss (standarized): 0.5157676215802611\n",
      "Epoch: 36, Loss (standarized): 0.4811976631689164\n",
      "Epoch: 41, Loss (standarized): 0.44236703534060595\n",
      "Epoch: 46, Loss (standarized): 0.4012138888841912\n",
      "Epoch: 51, Loss (standarized): 0.3597730363927689\n",
      "Epoch: 56, Loss (standarized): 0.32004809952311497\n",
      "Epoch: 61, Loss (standarized): 0.28520578740277397\n",
      "Epoch: 66, Loss (standarized): 0.2566997850589441\n",
      "Epoch: 71, Loss (standarized): 0.2333005228913692\n",
      "Epoch: 76, Loss (standarized): 0.21434989063283943\n",
      "Epoch: 81, Loss (standarized): 0.1985668845594497\n",
      "Epoch: 86, Loss (standarized): 0.1849488407622381\n",
      "Epoch: 91, Loss (standarized): 0.17261923981188682\n",
      "Epoch: 96, Loss (standarized): 0.16190676504676582\n",
      "Final epoch: 100, Final loss (standarized): 0.15380137934393368\n",
      "Epoch: 1, Loss (standarized): 1.408343071522813\n",
      "Epoch: 6, Loss (standarized): 0.701664289782299\n",
      "Epoch: 11, Loss (standarized): 0.6891720830259769\n",
      "Epoch: 16, Loss (standarized): 0.6557964565128113\n",
      "Epoch: 21, Loss (standarized): 0.6416588348977509\n",
      "Epoch: 26, Loss (standarized): 0.6268090793666808\n",
      "Epoch: 31, Loss (standarized): 0.612954915553654\n",
      "Epoch: 36, Loss (standarized): 0.6030012045668346\n",
      "Epoch: 41, Loss (standarized): 0.5929927366993253\n",
      "Epoch: 46, Loss (standarized): 0.584547755666824\n",
      "Epoch: 51, Loss (standarized): 0.5779189823659681\n",
      "Epoch: 56, Loss (standarized): 0.5709928622703557\n",
      "Epoch: 61, Loss (standarized): 0.5642986698067141\n",
      "Epoch: 66, Loss (standarized): 0.5576190378548911\n",
      "Epoch: 71, Loss (standarized): 0.550802794174233\n",
      "Epoch: 76, Loss (standarized): 0.5436871001965317\n",
      "Epoch: 81, Loss (standarized): 0.5369307471114619\n",
      "Epoch: 86, Loss (standarized): 0.5300006890382676\n",
      "Epoch: 91, Loss (standarized): 0.5235672530835402\n",
      "Epoch: 96, Loss (standarized): 0.5176210285768458\n",
      "Final epoch: 100, Final loss (standarized): 0.5129906967005305\n",
      "Epoch: 1, Loss (standarized): 1.5523136180551629\n",
      "Epoch: 6, Loss (standarized): 0.8442034808435032\n",
      "Epoch: 11, Loss (standarized): 0.6944349019728516\n",
      "Epoch: 16, Loss (standarized): 0.6742950047214208\n",
      "Epoch: 21, Loss (standarized): 0.6484256224914997\n",
      "Epoch: 26, Loss (standarized): 0.6316246568393435\n",
      "Epoch: 31, Loss (standarized): 0.6232699441006377\n",
      "Epoch: 36, Loss (standarized): 0.6158259652990119\n",
      "Epoch: 41, Loss (standarized): 0.6062266757406373\n",
      "Epoch: 46, Loss (standarized): 0.5974496653989649\n",
      "Epoch: 51, Loss (standarized): 0.590133490754296\n",
      "Epoch: 56, Loss (standarized): 0.5833543130713679\n",
      "Epoch: 61, Loss (standarized): 0.5795752659715757\n",
      "Epoch: 66, Loss (standarized): 0.5778623270434616\n",
      "Epoch: 71, Loss (standarized): 0.575141623099358\n",
      "Epoch: 76, Loss (standarized): 0.5726476641266272\n",
      "Epoch: 81, Loss (standarized): 0.5699480316409934\n",
      "Epoch: 86, Loss (standarized): 0.5668329317270906\n",
      "Epoch: 91, Loss (standarized): 0.5631624507033745\n",
      "Epoch: 96, Loss (standarized): 0.5605351170739363\n",
      "Final epoch: 100, Final loss (standarized): 0.5587225746913043\n",
      "Epoch: 1, Loss (standarized): 1.2414255469800133\n",
      "Epoch: 6, Loss (standarized): 0.6886897402781322\n",
      "Epoch: 11, Loss (standarized): 0.6673105606989449\n",
      "Epoch: 16, Loss (standarized): 0.6438295190153153\n",
      "Epoch: 21, Loss (standarized): 0.6267141293390318\n",
      "Epoch: 26, Loss (standarized): 0.6106598630999821\n",
      "Epoch: 31, Loss (standarized): 0.5991063656349116\n",
      "Epoch: 36, Loss (standarized): 0.5921227845626721\n",
      "Epoch: 41, Loss (standarized): 0.5849042134441097\n",
      "Epoch: 46, Loss (standarized): 0.577859797637992\n",
      "Epoch: 51, Loss (standarized): 0.5708267417780457\n",
      "Epoch: 56, Loss (standarized): 0.5641380839080412\n",
      "Epoch: 61, Loss (standarized): 0.5576733920881419\n",
      "Epoch: 66, Loss (standarized): 0.5518931792859954\n",
      "Epoch: 71, Loss (standarized): 0.547596669605616\n",
      "Epoch: 76, Loss (standarized): 0.5440032310434606\n",
      "Epoch: 81, Loss (standarized): 0.5411138407218921\n",
      "Epoch: 86, Loss (standarized): 0.5390939847291306\n",
      "Epoch: 91, Loss (standarized): 0.5370050280963446\n",
      "Epoch: 96, Loss (standarized): 0.5347398581744758\n",
      "Final epoch: 100, Final loss (standarized): 0.5331177455780928\n",
      "Epoch: 1, Loss (standarized): 1.4015562948288303\n",
      "Epoch: 6, Loss (standarized): 0.8145468570927618\n",
      "Epoch: 11, Loss (standarized): 0.7105316846864667\n",
      "Epoch: 16, Loss (standarized): 0.6802062669137263\n",
      "Epoch: 21, Loss (standarized): 0.6630349537703377\n",
      "Epoch: 26, Loss (standarized): 0.6504363736097004\n",
      "Epoch: 31, Loss (standarized): 0.6342065303887882\n",
      "Epoch: 36, Loss (standarized): 0.6224639802666201\n",
      "Epoch: 41, Loss (standarized): 0.6129370418467595\n",
      "Epoch: 46, Loss (standarized): 0.6026509802476115\n",
      "Epoch: 51, Loss (standarized): 0.5926744128916069\n",
      "Epoch: 56, Loss (standarized): 0.5838330431616409\n",
      "Epoch: 61, Loss (standarized): 0.5759875613408698\n",
      "Epoch: 66, Loss (standarized): 0.568853772573254\n",
      "Epoch: 71, Loss (standarized): 0.5618394557411545\n",
      "Epoch: 76, Loss (standarized): 0.5553369033143216\n",
      "Epoch: 81, Loss (standarized): 0.548809094635755\n",
      "Epoch: 86, Loss (standarized): 0.542272457506225\n",
      "Epoch: 91, Loss (standarized): 0.5357393246281585\n",
      "Epoch: 96, Loss (standarized): 0.529848562359824\n",
      "Final epoch: 100, Final loss (standarized): 0.524723604372606\n",
      "Epoch: 1, Loss (standarized): 1.2177042265476028\n",
      "Epoch: 6, Loss (standarized): 0.720808435002138\n",
      "Epoch: 11, Loss (standarized): 0.6923820731559248\n",
      "Epoch: 16, Loss (standarized): 0.6521976953726171\n",
      "Epoch: 21, Loss (standarized): 0.626580858409334\n",
      "Epoch: 26, Loss (standarized): 0.5991153566834917\n",
      "Epoch: 31, Loss (standarized): 0.5699022110902221\n",
      "Epoch: 36, Loss (standarized): 0.5378531835341318\n",
      "Epoch: 41, Loss (standarized): 0.4985812059053427\n",
      "Epoch: 46, Loss (standarized): 0.45192345994135996\n",
      "Epoch: 51, Loss (standarized): 0.399207780959404\n",
      "Epoch: 56, Loss (standarized): 0.3461214907646684\n",
      "Epoch: 61, Loss (standarized): 0.29697739091798203\n",
      "Epoch: 66, Loss (standarized): 0.2563234889906907\n",
      "Epoch: 71, Loss (standarized): 0.2247243890134927\n",
      "Epoch: 76, Loss (standarized): 0.2006205663522498\n",
      "Epoch: 81, Loss (standarized): 0.18229698836978905\n",
      "Epoch: 86, Loss (standarized): 0.1681120112766872\n",
      "Epoch: 91, Loss (standarized): 0.15675641406778254\n",
      "Epoch: 96, Loss (standarized): 0.147586828474303\n",
      "Final epoch: 100, Final loss (standarized): 0.1414357885311133\n",
      "Epoch: 1, Loss (standarized): 1.5926033913676816\n",
      "Epoch: 6, Loss (standarized): 0.8618454338096778\n",
      "Epoch: 11, Loss (standarized): 0.691675642733298\n",
      "Epoch: 16, Loss (standarized): 0.6568391856861718\n",
      "Epoch: 21, Loss (standarized): 0.6271438900754696\n",
      "Epoch: 26, Loss (standarized): 0.6073770924686104\n",
      "Epoch: 31, Loss (standarized): 0.5853649344240193\n",
      "Epoch: 36, Loss (standarized): 0.5599016450254874\n",
      "Epoch: 41, Loss (standarized): 0.5378930361720492\n",
      "Epoch: 46, Loss (standarized): 0.5154133681406802\n",
      "Epoch: 51, Loss (standarized): 0.4896952473215011\n",
      "Epoch: 56, Loss (standarized): 0.45973676364683047\n",
      "Epoch: 61, Loss (standarized): 0.42998443409388504\n",
      "Epoch: 66, Loss (standarized): 0.4010780923724336\n",
      "Epoch: 71, Loss (standarized): 0.37589430700603543\n",
      "Epoch: 76, Loss (standarized): 0.3535586621950166\n",
      "Epoch: 81, Loss (standarized): 0.3340134826040685\n",
      "Epoch: 86, Loss (standarized): 0.3169050907905747\n",
      "Epoch: 91, Loss (standarized): 0.3027283136804169\n",
      "Epoch: 96, Loss (standarized): 0.2909765544757188\n",
      "Final epoch: 100, Final loss (standarized): 0.2830399116758912\n",
      "Epoch: 1, Loss (standarized): 2.717889842416744\n",
      "Epoch: 6, Loss (standarized): 1.1136341545962702\n",
      "Epoch: 11, Loss (standarized): 0.7692459303014237\n",
      "Epoch: 16, Loss (standarized): 0.7296001256352437\n",
      "Epoch: 21, Loss (standarized): 0.7172129150054161\n",
      "Epoch: 26, Loss (standarized): 0.6744067016090763\n",
      "Epoch: 31, Loss (standarized): 0.6468536969307864\n",
      "Epoch: 36, Loss (standarized): 0.6367890284103704\n",
      "Epoch: 41, Loss (standarized): 0.6213408366035911\n",
      "Epoch: 46, Loss (standarized): 0.6071205768178416\n",
      "Epoch: 51, Loss (standarized): 0.5932929833743381\n",
      "Epoch: 56, Loss (standarized): 0.5789206079774513\n",
      "Epoch: 61, Loss (standarized): 0.5607021367679925\n",
      "Epoch: 66, Loss (standarized): 0.5423773943011273\n",
      "Epoch: 71, Loss (standarized): 0.5242409256446352\n",
      "Epoch: 76, Loss (standarized): 0.5049009157290032\n",
      "Epoch: 81, Loss (standarized): 0.4843858349326035\n",
      "Epoch: 86, Loss (standarized): 0.4621417778442703\n",
      "Epoch: 91, Loss (standarized): 0.43818781092544185\n",
      "Epoch: 96, Loss (standarized): 0.4128494348815932\n",
      "Final epoch: 100, Final loss (standarized): 0.39242996962900584\n",
      "Epoch: 1, Loss (standarized): 1.7987992839266655\n",
      "Epoch: 6, Loss (standarized): 0.7718448469516999\n",
      "Epoch: 11, Loss (standarized): 0.674863919735445\n",
      "Epoch: 16, Loss (standarized): 0.6651032774059945\n",
      "Epoch: 21, Loss (standarized): 0.640382468792841\n",
      "Epoch: 26, Loss (standarized): 0.6201049409628616\n",
      "Epoch: 31, Loss (standarized): 0.5899518685912261\n",
      "Epoch: 36, Loss (standarized): 0.5608658386001469\n",
      "Epoch: 41, Loss (standarized): 0.531934197797538\n",
      "Epoch: 46, Loss (standarized): 0.5021521324328512\n",
      "Epoch: 51, Loss (standarized): 0.4728628264617763\n",
      "Epoch: 56, Loss (standarized): 0.4426442439944638\n",
      "Epoch: 61, Loss (standarized): 0.4116076703610211\n",
      "Epoch: 66, Loss (standarized): 0.38025362340617386\n",
      "Epoch: 71, Loss (standarized): 0.3499885982972385\n",
      "Epoch: 76, Loss (standarized): 0.3221801951359326\n",
      "Epoch: 81, Loss (standarized): 0.2975057092920448\n",
      "Epoch: 86, Loss (standarized): 0.27615120888726247\n",
      "Epoch: 91, Loss (standarized): 0.25785813667347496\n",
      "Epoch: 96, Loss (standarized): 0.2424852207196367\n",
      "Final epoch: 100, Final loss (standarized): 0.23197090588075892\n",
      "Epoch: 1, Loss (standarized): 0.9580060692716835\n",
      "Epoch: 6, Loss (standarized): 0.7244215841775408\n",
      "Epoch: 11, Loss (standarized): 0.674069873047276\n",
      "Epoch: 16, Loss (standarized): 0.6436062040188685\n",
      "Epoch: 21, Loss (standarized): 0.6133808916170622\n",
      "Epoch: 26, Loss (standarized): 0.5785379717079736\n",
      "Epoch: 31, Loss (standarized): 0.5407735558353278\n",
      "Epoch: 36, Loss (standarized): 0.49749182814421755\n",
      "Epoch: 41, Loss (standarized): 0.4443885908077223\n",
      "Epoch: 46, Loss (standarized): 0.3893075672151691\n",
      "Epoch: 51, Loss (standarized): 0.337140290151498\n",
      "Epoch: 56, Loss (standarized): 0.2912404797194742\n",
      "Epoch: 61, Loss (standarized): 0.2533836277426047\n",
      "Epoch: 66, Loss (standarized): 0.22461113542460423\n",
      "Epoch: 71, Loss (standarized): 0.2011703007248743\n",
      "Epoch: 76, Loss (standarized): 0.18236718327468918\n",
      "Epoch: 81, Loss (standarized): 0.16656400447752817\n",
      "Epoch: 86, Loss (standarized): 0.152015534244381\n",
      "Epoch: 91, Loss (standarized): 0.13932354817980888\n",
      "Epoch: 96, Loss (standarized): 0.1281226613127417\n",
      "Final epoch: 100, Final loss (standarized): 0.12000168326224031\n",
      "Epoch: 1, Loss (standarized): 1.8387406020686832\n",
      "Epoch: 6, Loss (standarized): 0.9110449551879753\n",
      "Epoch: 11, Loss (standarized): 0.7736536298552912\n",
      "Epoch: 16, Loss (standarized): 0.728200078950977\n",
      "Epoch: 21, Loss (standarized): 0.6768895679807879\n",
      "Epoch: 26, Loss (standarized): 0.6508029773136141\n",
      "Epoch: 31, Loss (standarized): 0.6249182104181812\n",
      "Epoch: 36, Loss (standarized): 0.5960319956646031\n",
      "Epoch: 41, Loss (standarized): 0.5756619930895567\n",
      "Epoch: 46, Loss (standarized): 0.55405281601005\n",
      "Epoch: 51, Loss (standarized): 0.5325829498903214\n",
      "Epoch: 56, Loss (standarized): 0.5092195615478754\n",
      "Epoch: 61, Loss (standarized): 0.48329106007825523\n",
      "Epoch: 66, Loss (standarized): 0.45565496893829616\n",
      "Epoch: 71, Loss (standarized): 0.4277444280995554\n",
      "Epoch: 76, Loss (standarized): 0.40043295895490133\n",
      "Epoch: 81, Loss (standarized): 0.3745779864464426\n",
      "Epoch: 86, Loss (standarized): 0.3509881107869598\n",
      "Epoch: 91, Loss (standarized): 0.32996595282753727\n",
      "Epoch: 96, Loss (standarized): 0.3120107677499631\n",
      "Final epoch: 100, Final loss (standarized): 0.2995051116251866\n",
      "Epoch: 1, Loss (standarized): 1.9030510509339753\n",
      "Epoch: 6, Loss (standarized): 0.8853360631279811\n",
      "Epoch: 11, Loss (standarized): 0.6746421314672618\n",
      "Epoch: 16, Loss (standarized): 0.6869356370407294\n",
      "Epoch: 21, Loss (standarized): 0.6452004529496019\n",
      "Epoch: 26, Loss (standarized): 0.6111847553169608\n",
      "Epoch: 31, Loss (standarized): 0.5856893734036239\n",
      "Epoch: 36, Loss (standarized): 0.5615317216056999\n",
      "Epoch: 41, Loss (standarized): 0.5432108130409941\n",
      "Epoch: 46, Loss (standarized): 0.5229146018539047\n",
      "Epoch: 51, Loss (standarized): 0.4983782582104294\n",
      "Epoch: 56, Loss (standarized): 0.4711163334625379\n",
      "Epoch: 61, Loss (standarized): 0.43244945239675475\n",
      "Epoch: 66, Loss (standarized): 0.3913170876327263\n",
      "Epoch: 71, Loss (standarized): 0.3546991051618984\n",
      "Epoch: 76, Loss (standarized): 0.32083854527347333\n",
      "Epoch: 81, Loss (standarized): 0.28919983588256776\n",
      "Epoch: 86, Loss (standarized): 0.26253470687578373\n",
      "Epoch: 91, Loss (standarized): 0.24027342997841802\n",
      "Epoch: 96, Loss (standarized): 0.2209028938925317\n",
      "Final epoch: 100, Final loss (standarized): 0.2073900711617462\n",
      "Epoch: 1, Loss (standarized): 1.410480519922504\n",
      "Epoch: 6, Loss (standarized): 0.7997613201458921\n",
      "Epoch: 11, Loss (standarized): 0.6954116021441525\n",
      "Epoch: 16, Loss (standarized): 0.6733667609916137\n",
      "Epoch: 21, Loss (standarized): 0.632332910480849\n",
      "Epoch: 26, Loss (standarized): 0.6088589703559749\n",
      "Epoch: 31, Loss (standarized): 0.5853206103062538\n",
      "Epoch: 36, Loss (standarized): 0.5554929872470853\n",
      "Epoch: 41, Loss (standarized): 0.5279604570484082\n",
      "Epoch: 46, Loss (standarized): 0.49485742672477845\n",
      "Epoch: 51, Loss (standarized): 0.4560436925088833\n",
      "Epoch: 56, Loss (standarized): 0.4116967027937262\n",
      "Epoch: 61, Loss (standarized): 0.365326496111665\n",
      "Epoch: 66, Loss (standarized): 0.3197481797392279\n",
      "Epoch: 71, Loss (standarized): 0.2775431137858746\n",
      "Epoch: 76, Loss (standarized): 0.24139278643735412\n",
      "Epoch: 81, Loss (standarized): 0.21256402193965968\n",
      "Epoch: 86, Loss (standarized): 0.18951164972980214\n",
      "Epoch: 91, Loss (standarized): 0.17036409615467507\n",
      "Epoch: 96, Loss (standarized): 0.1544449039475535\n",
      "Final epoch: 100, Final loss (standarized): 0.1437374121583334\n",
      "Epoch: 1, Loss (standarized): 3.0080885408779805\n",
      "          Validation Loss (standardized): 2.066563579527453\n",
      "Epoch: 6, Loss (standarized): 1.0127593239319328\n",
      "          Validation Loss (standardized): 1.6554689923229835\n",
      "Epoch: 11, Loss (standarized): 0.7271218437565496\n",
      "          Validation Loss (standardized): 2.553718334987252\n",
      "Epoch: 16, Loss (standarized): 0.7343735125776298\n",
      "          Validation Loss (standardized): 3.0361451661044794\n",
      "Epoch: 21, Loss (standarized): 0.6964210019609881\n",
      "          Validation Loss (standardized): 3.0789433218033317\n",
      "Epoch: 26, Loss (standarized): 0.6665770976715976\n",
      "          Validation Loss (standardized): 2.88458062176706\n",
      "Epoch: 31, Loss (standarized): 0.6390690023583283\n",
      "          Validation Loss (standardized): 2.6155537927348687\n",
      "Epoch: 36, Loss (standarized): 0.60178276441399\n",
      "          Validation Loss (standardized): 2.325162987286877\n",
      "Epoch: 41, Loss (standarized): 0.5748490378135994\n",
      "          Validation Loss (standardized): 2.0653457699440843\n",
      "Epoch: 46, Loss (standarized): 0.5448105151656422\n",
      "          Validation Loss (standardized): 1.8548298097881253\n",
      "Epoch: 51, Loss (standarized): 0.515560644546803\n",
      "          Validation Loss (standardized): 1.705314370845009\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.48489946333637873\n",
      "          Validation Loss (standardized): 1.6088613162649297\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.4503690506444264\n",
      "          Validation Loss (standardized): 1.5670224379769544\n",
      "Epoch: 66, Loss (standarized): 0.4154646597410767\n",
      "          Validation Loss (standardized): 1.5584268590141037\n",
      "Epoch: 71, Loss (standarized): 0.3791487094129554\n",
      "          Validation Loss (standardized): 1.5382812905826977\n",
      "Epoch: 76, Loss (standarized): 0.34378445717061556\n",
      "          Validation Loss (standardized): 1.4827326144480988\n",
      "Epoch: 81, Loss (standarized): 0.31069075788529993\n",
      "          Validation Loss (standardized): 1.4051509217268758\n",
      "Epoch: 86, Loss (standarized): 0.28183306689107684\n",
      "          Validation Loss (standardized): 1.3357732132957527\n",
      "Epoch: 91, Loss (standarized): 0.2573942613472787\n",
      "          Validation Loss (standardized): 1.29229651104172\n",
      "Epoch: 96, Loss (standarized): 0.23604466527826046\n",
      "          Validation Loss (standardized): 1.2476055954715144\n",
      "Final epoch: 100, Final loss (standarized): 0.2209616912402373\n",
      "Epoch: 1, Loss (standarized): 1.6863755958840512\n",
      "          Validation Loss (standardized): 1.128477981517916\n",
      "Epoch: 6, Loss (standarized): 0.7051735244166855\n",
      "          Validation Loss (standardized): 1.8030775293436845\n",
      "Epoch: 11, Loss (standarized): 0.7173681536258306\n",
      "          Validation Loss (standardized): 2.3892147284407903\n",
      "Epoch: 16, Loss (standarized): 0.6684075789678533\n",
      "          Validation Loss (standardized): 2.462412724430952\n",
      "Epoch: 21, Loss (standarized): 0.6613494460649372\n",
      "          Validation Loss (standardized): 2.294151300260982\n",
      "Epoch: 26, Loss (standarized): 0.6302467641604818\n",
      "          Validation Loss (standardized): 2.06515495323839\n",
      "Epoch: 31, Loss (standarized): 0.6072085271065073\n",
      "          Validation Loss (standardized): 1.8848354788849728\n",
      "Epoch: 36, Loss (standarized): 0.5902649315668117\n",
      "          Validation Loss (standardized): 1.7212016100320358\n",
      "Epoch: 41, Loss (standarized): 0.574078911105061\n",
      "          Validation Loss (standardized): 1.64308416040536\n",
      "Epoch: 46, Loss (standarized): 0.5544630122495541\n",
      "          Validation Loss (standardized): 1.6198966771993566\n",
      "Epoch: 51, Loss (standarized): 0.5348423944737535\n",
      "          Validation Loss (standardized): 1.6196821234369403\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.5152970967949598\n",
      "          Validation Loss (standardized): 1.6548672669112072\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.49537991947466886\n",
      "          Validation Loss (standardized): 1.6764627064689752\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.4780504730996162\n",
      "          Validation Loss (standardized): 1.6719254640173595\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.46067890762924785\n",
      "          Validation Loss (standardized): 1.6546502225465802\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.44440577458738767\n",
      "          Validation Loss (standardized): 1.6143156378200538\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.42898467784524497\n",
      "          Validation Loss (standardized): 1.5820625986449302\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.4144300021147646\n",
      "          Validation Loss (standardized): 1.5585266207801616\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.40025030349582585\n",
      "          Validation Loss (standardized): 1.536595637021769\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.3859650913396876\n",
      "          Validation Loss (standardized): 1.5130453716624102\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.3738860095191104\n",
      "Epoch: 1, Loss (standarized): 1.0674425930202753\n",
      "          Validation Loss (standardized): 1.7714214905153536\n",
      "Epoch: 6, Loss (standarized): 0.7034485678155725\n",
      "          Validation Loss (standardized): 2.0736840992683265\n",
      "Epoch: 11, Loss (standarized): 0.6559259325730941\n",
      "          Validation Loss (standardized): 2.2065878879573146\n",
      "Epoch: 16, Loss (standarized): 0.6263607925794448\n",
      "          Validation Loss (standardized): 2.1676203954260638\n",
      "Epoch: 21, Loss (standarized): 0.5857894228907697\n",
      "          Validation Loss (standardized): 1.971378702276327\n",
      "Epoch: 26, Loss (standarized): 0.5546566954586188\n",
      "          Validation Loss (standardized): 1.8238998900599992\n",
      "Epoch: 31, Loss (standarized): 0.5214794170060671\n",
      "          Validation Loss (standardized): 1.7260273686281866\n",
      "Epoch: 36, Loss (standarized): 0.4847711808838575\n",
      "          Validation Loss (standardized): 1.651828646663791\n",
      "Epoch: 41, Loss (standarized): 0.44623346382677065\n",
      "          Validation Loss (standardized): 1.5729029936852286\n",
      "Epoch: 46, Loss (standarized): 0.4045537063867744\n",
      "          Validation Loss (standardized): 1.4977147003622626\n",
      "Epoch: 51, Loss (standarized): 0.36198095832202204\n",
      "          Validation Loss (standardized): 1.4365657847045457\n",
      "Epoch: 56, Loss (standarized): 0.3211912837208727\n",
      "          Validation Loss (standardized): 1.3829865423751926\n",
      "Epoch: 61, Loss (standarized): 0.284009690896243\n",
      "          Validation Loss (standardized): 1.3019120611800672\n",
      "Epoch: 66, Loss (standarized): 0.2529953362084125\n",
      "          Validation Loss (standardized): 1.2342147196083362\n",
      "Epoch: 71, Loss (standarized): 0.22792631995534623\n",
      "          Validation Loss (standardized): 1.2113759891321658\n",
      "Epoch: 76, Loss (standarized): 0.20786467033348988\n",
      "          Validation Loss (standardized): 1.1698233448564674\n",
      "Epoch: 81, Loss (standarized): 0.1914012918544667\n",
      "          Validation Loss (standardized): 1.1099716096560015\n",
      "Epoch: 86, Loss (standarized): 0.17772257851714537\n",
      "          Validation Loss (standardized): 1.0492644068837802\n",
      "Epoch: 91, Loss (standarized): 0.1658008215208445\n",
      "          Validation Loss (standardized): 1.0044228211269934\n",
      "Epoch: 96, Loss (standarized): 0.1552796065695563\n",
      "          Validation Loss (standardized): 0.9570701283990657\n",
      "Final epoch: 100, Final loss (standarized): 0.14734733954240334\n",
      "Epoch: 1, Loss (standarized): 2.0956926238968046\n",
      "          Validation Loss (standardized): 1.8159155989030156\n",
      "Epoch: 6, Loss (standarized): 1.1098241755651268\n",
      "          Validation Loss (standardized): 1.2332676586709612\n",
      "Epoch: 11, Loss (standarized): 0.8167183481267157\n",
      "          Validation Loss (standardized): 1.4148081657268874\n",
      "Epoch: 16, Loss (standarized): 0.6937163853667113\n",
      "          Validation Loss (standardized): 1.8008760014253744\n",
      "Epoch: 21, Loss (standarized): 0.6674455206604155\n",
      "          Validation Loss (standardized): 2.1098009510586015\n",
      "Epoch: 26, Loss (standarized): 0.6372410390947346\n",
      "          Validation Loss (standardized): 2.1015952140428427\n",
      "Epoch: 31, Loss (standarized): 0.6100994742715273\n",
      "          Validation Loss (standardized): 1.9723225607326456\n",
      "Epoch: 36, Loss (standarized): 0.5801312178617448\n",
      "          Validation Loss (standardized): 1.8228233402185088\n",
      "Epoch: 41, Loss (standarized): 0.5520383111054198\n",
      "          Validation Loss (standardized): 1.6954174100238883\n",
      "Epoch: 46, Loss (standarized): 0.52467485997606\n",
      "          Validation Loss (standardized): 1.5678773342492363\n",
      "Epoch: 51, Loss (standarized): 0.49881530975768223\n",
      "          Validation Loss (standardized): 1.490653464607837\n",
      "Epoch: 56, Loss (standarized): 0.47221384188737553\n",
      "          Validation Loss (standardized): 1.4872128392233412\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.44796469108411163\n",
      "          Validation Loss (standardized): 1.4707515562348152\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.42575548122263746\n",
      "          Validation Loss (standardized): 1.4485250028638503\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.4043869243355294\n",
      "          Validation Loss (standardized): 1.4264867229811447\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.38224999476478955\n",
      "          Validation Loss (standardized): 1.3998053624680349\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.3599196122750173\n",
      "          Validation Loss (standardized): 1.3960361272777604\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.33965455604817\n",
      "          Validation Loss (standardized): 1.390272856346614\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.3201952040553901\n",
      "          Validation Loss (standardized): 1.3659544822684977\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.30055409432641406\n",
      "          Validation Loss (standardized): 1.3252352486356194\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.28407587689710906\n",
      "Epoch: 1, Loss (standarized): 1.4208815778880721\n",
      "          Validation Loss (standardized): 1.2227780435881523\n",
      "Epoch: 6, Loss (standarized): 0.789422538581347\n",
      "          Validation Loss (standardized): 1.6422629444634411\n",
      "Epoch: 11, Loss (standarized): 0.7129409454073763\n",
      "          Validation Loss (standardized): 2.055309670438108\n",
      "Epoch: 16, Loss (standarized): 0.7071062986982986\n",
      "          Validation Loss (standardized): 2.2015160046334294\n",
      "Epoch: 21, Loss (standarized): 0.6973877786924393\n",
      "          Validation Loss (standardized): 2.121149387965312\n",
      "Epoch: 26, Loss (standarized): 0.686119729721158\n",
      "          Validation Loss (standardized): 1.9515849224572361\n",
      "Epoch: 31, Loss (standarized): 0.6768138352457556\n",
      "          Validation Loss (standardized): 1.7963374806413634\n",
      "Epoch: 36, Loss (standarized): 0.6657821210641595\n",
      "          Validation Loss (standardized): 1.692872606460285\n",
      "Epoch: 41, Loss (standarized): 0.6530943548515653\n",
      "          Validation Loss (standardized): 1.6371192081450492\n",
      "Epoch: 46, Loss (standarized): 0.6430178275405641\n",
      "          Validation Loss (standardized): 1.5964494825532178\n",
      "Epoch: 51, Loss (standarized): 0.6318276760216627\n",
      "          Validation Loss (standardized): 1.5789069895393182\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.6206308018835219\n",
      "          Validation Loss (standardized): 1.5906449172424413\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.6105759022028573\n",
      "          Validation Loss (standardized): 1.6040763297259446\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.6022994404743389\n",
      "          Validation Loss (standardized): 1.6044284197096232\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.5949876863139941\n",
      "          Validation Loss (standardized): 1.6163520734010428\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.5872056051393447\n",
      "          Validation Loss (standardized): 1.624738776136011\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.579844425565413\n",
      "          Validation Loss (standardized): 1.626611891373936\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.572821910697724\n",
      "          Validation Loss (standardized): 1.6230990884889633\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.566309861294512\n",
      "          Validation Loss (standardized): 1.6232325095220461\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.5587167269222877\n",
      "          Validation Loss (standardized): 1.6258611124966547\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.5522504566983584\n",
      "Epoch: 1, Loss (standarized): 1.3081644503284011\n",
      "          Validation Loss (standardized): 1.5994740650636146\n",
      "Epoch: 6, Loss (standarized): 0.8178929286919524\n",
      "          Validation Loss (standardized): 1.7299406867401377\n",
      "Epoch: 11, Loss (standarized): 0.7019363478419374\n",
      "          Validation Loss (standardized): 1.6307706768505437\n",
      "Epoch: 16, Loss (standarized): 0.6758297209135002\n",
      "          Validation Loss (standardized): 1.5534526322231572\n",
      "Epoch: 21, Loss (standarized): 0.6572963266618546\n",
      "          Validation Loss (standardized): 1.5014146649592248\n",
      "Epoch: 26, Loss (standarized): 0.642490456106692\n",
      "          Validation Loss (standardized): 1.470092061245834\n",
      "Epoch: 31, Loss (standarized): 0.6318011691427671\n",
      "          Validation Loss (standardized): 1.4709393516939404\n",
      "Epoch: 36, Loss (standarized): 0.6273710233287055\n",
      "          Validation Loss (standardized): 1.4884369548954914\n",
      "Epoch: 41, Loss (standarized): 0.6231433862878409\n",
      "          Validation Loss (standardized): 1.494984530078061\n",
      "Epoch: 46, Loss (standarized): 0.6178266566662565\n",
      "          Validation Loss (standardized): 1.4811741537458325\n",
      "Epoch: 51, Loss (standarized): 0.6139002306823346\n",
      "          Validation Loss (standardized): 1.4752197321950344\n",
      "Epoch: 56, Loss (standarized): 0.6110649271489815\n",
      "          Validation Loss (standardized): 1.4780021048351413\n",
      "Epoch: 61, Loss (standarized): 0.6088690590620315\n",
      "          Validation Loss (standardized): 1.4942527243219557\n",
      "Epoch: 66, Loss (standarized): 0.6085130808924505\n",
      "          Validation Loss (standardized): 1.5068075243177441\n",
      "Epoch: 71, Loss (standarized): 0.6088944737504464\n",
      "          Validation Loss (standardized): 1.504219086756755\n",
      "Epoch: 76, Loss (standarized): 0.6093117136448037\n",
      "          Validation Loss (standardized): 1.5135454513433788\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.6103808212488999\n",
      "          Validation Loss (standardized): 1.5193788059665254\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.6116858286048324\n",
      "          Validation Loss (standardized): 1.523690307827207\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.6133012692897938\n",
      "          Validation Loss (standardized): 1.528549502181892\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.6147480048763341\n",
      "          Validation Loss (standardized): 1.5365203121590576\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.6160509033871808\n",
      "Epoch: 1, Loss (standarized): 2.4638679668937127\n",
      "          Validation Loss (standardized): 1.6378647369006667\n",
      "Epoch: 6, Loss (standarized): 1.1337141916729336\n",
      "          Validation Loss (standardized): 1.3401655710633391\n",
      "Epoch: 11, Loss (standarized): 0.7038516999646118\n",
      "          Validation Loss (standardized): 1.692019268707043\n",
      "Epoch: 16, Loss (standarized): 0.6823511186615309\n",
      "          Validation Loss (standardized): 2.061563619141074\n",
      "Epoch: 21, Loss (standarized): 0.6542400328824378\n",
      "          Validation Loss (standardized): 2.1111112293419874\n",
      "Epoch: 26, Loss (standarized): 0.6287111507938772\n",
      "          Validation Loss (standardized): 2.0018083746586486\n",
      "Epoch: 31, Loss (standarized): 0.618712130822653\n",
      "          Validation Loss (standardized): 1.8345613961464946\n",
      "Epoch: 36, Loss (standarized): 0.6083064148767017\n",
      "          Validation Loss (standardized): 1.6728754017107859\n",
      "Epoch: 41, Loss (standarized): 0.5963303957957196\n",
      "          Validation Loss (standardized): 1.5645624675539433\n",
      "Epoch: 46, Loss (standarized): 0.5872885447888577\n",
      "          Validation Loss (standardized): 1.5216140259400737\n",
      "Epoch: 51, Loss (standarized): 0.5813177193479644\n",
      "          Validation Loss (standardized): 1.5051506276866018\n",
      "Epoch: 56, Loss (standarized): 0.5757343823257393\n",
      "          Validation Loss (standardized): 1.4952436407110157\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.5695751261961322\n",
      "          Validation Loss (standardized): 1.4963470233155638\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.563779764165982\n",
      "          Validation Loss (standardized): 1.5098451991645145\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.5568829136511253\n",
      "          Validation Loss (standardized): 1.526756660051817\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.5496865919746999\n",
      "          Validation Loss (standardized): 1.538941309259187\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.5419077770245906\n",
      "          Validation Loss (standardized): 1.5522935953027612\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.5336245735965374\n",
      "          Validation Loss (standardized): 1.5567675441402302\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.5258509496624852\n",
      "          Validation Loss (standardized): 1.553618728372324\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.5192513161722105\n",
      "          Validation Loss (standardized): 1.5443738156912645\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.5143644891597494\n",
      "Epoch: 1, Loss (standarized): 1.3385212643286912\n",
      "          Validation Loss (standardized): 1.5050566043990499\n",
      "Epoch: 6, Loss (standarized): 0.7263451162930334\n",
      "          Validation Loss (standardized): 1.8205577712878345\n",
      "Epoch: 11, Loss (standarized): 0.6853118293503673\n",
      "          Validation Loss (standardized): 1.9414661257432757\n",
      "Epoch: 16, Loss (standarized): 0.6513964160270994\n",
      "          Validation Loss (standardized): 1.73777177968983\n",
      "Epoch: 21, Loss (standarized): 0.6301473857103368\n",
      "          Validation Loss (standardized): 1.560094087807339\n",
      "Epoch: 26, Loss (standarized): 0.6162472325690195\n",
      "          Validation Loss (standardized): 1.557383269386317\n",
      "Epoch: 31, Loss (standarized): 0.6066560594940763\n",
      "          Validation Loss (standardized): 1.6140446062747378\n",
      "Epoch: 36, Loss (standarized): 0.5943498973294575\n",
      "          Validation Loss (standardized): 1.6134230407511667\n",
      "Epoch: 41, Loss (standarized): 0.5829694833658015\n",
      "          Validation Loss (standardized): 1.5667817482734492\n",
      "Epoch: 46, Loss (standarized): 0.5722895250563738\n",
      "          Validation Loss (standardized): 1.514857744356163\n",
      "Epoch: 51, Loss (standarized): 0.5620821128151688\n",
      "          Validation Loss (standardized): 1.4955096558088998\n",
      "Epoch: 56, Loss (standarized): 0.5524700221386273\n",
      "          Validation Loss (standardized): 1.509710611549561\n",
      "Epoch: 61, Loss (standarized): 0.5441351454496967\n",
      "          Validation Loss (standardized): 1.5189931146925317\n",
      "Epoch: 66, Loss (standarized): 0.5348652754880955\n",
      "          Validation Loss (standardized): 1.5123378066725577\n",
      "Epoch: 71, Loss (standarized): 0.5278741910350481\n",
      "          Validation Loss (standardized): 1.5142642886468034\n",
      "Epoch: 76, Loss (standarized): 0.5228618063001425\n",
      "          Validation Loss (standardized): 1.517030759501893\n",
      "Epoch: 81, Loss (standarized): 0.5174231026075382\n",
      "          Validation Loss (standardized): 1.5203461551283721\n",
      "Epoch: 86, Loss (standarized): 0.5125796790383147\n",
      "          Validation Loss (standardized): 1.5250973617568275\n",
      "Epoch: 91, Loss (standarized): 0.5086758599605415\n",
      "          Validation Loss (standardized): 1.507519932632235\n",
      "Epoch: 96, Loss (standarized): 0.5056837181060164\n",
      "          Validation Loss (standardized): 1.5178746569250807\n",
      "Final epoch: 100, Final loss (standarized): 0.5035177467931302\n",
      "Epoch: 1, Loss (standarized): 2.1414084501678583\n",
      "          Validation Loss (standardized): 1.3881240329411813\n",
      "Epoch: 6, Loss (standarized): 0.9877328970377888\n",
      "          Validation Loss (standardized): 1.2203391907382288\n",
      "Epoch: 11, Loss (standarized): 0.6795750962037379\n",
      "          Validation Loss (standardized): 1.7368398567591863\n",
      "Epoch: 16, Loss (standarized): 0.6644311569387494\n",
      "          Validation Loss (standardized): 2.146850050162831\n",
      "Epoch: 21, Loss (standarized): 0.6232694644846447\n",
      "          Validation Loss (standardized): 2.220230793641651\n",
      "Epoch: 26, Loss (standarized): 0.5915764370418979\n",
      "          Validation Loss (standardized): 2.1203974156101117\n",
      "Epoch: 31, Loss (standarized): 0.5673234802665572\n",
      "          Validation Loss (standardized): 1.9543692232240946\n",
      "Epoch: 36, Loss (standarized): 0.5364436364857976\n",
      "          Validation Loss (standardized): 1.8151767618375647\n",
      "Epoch: 41, Loss (standarized): 0.5070549743573949\n",
      "          Validation Loss (standardized): 1.7389204807724463\n",
      "Epoch: 46, Loss (standarized): 0.48081453977557204\n",
      "          Validation Loss (standardized): 1.6825813033845363\n",
      "Epoch: 51, Loss (standarized): 0.45210227842287976\n",
      "          Validation Loss (standardized): 1.6208841560075136\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.42726888827811693\n",
      "          Validation Loss (standardized): 1.5825462795515528\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.4022898578759782\n",
      "          Validation Loss (standardized): 1.5621306915758237\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.37912204185906045\n",
      "          Validation Loss (standardized): 1.5421519348620334\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.3558333686412024\n",
      "          Validation Loss (standardized): 1.507472194281935\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.33304115291592773\n",
      "          Validation Loss (standardized): 1.4699286429068663\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.31189808534124663\n",
      "          Validation Loss (standardized): 1.4354520760123568\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.29216403908209704\n",
      "          Validation Loss (standardized): 1.3959792739788655\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.2734645676685104\n",
      "          Validation Loss (standardized): 1.3556648339037478\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.25632723005553093\n",
      "          Validation Loss (standardized): 1.3190621439873431\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.24393403873019748\n",
      "Epoch: 1, Loss (standarized): 1.8851017357292124\n",
      "          Validation Loss (standardized): 1.7537367177065575\n",
      "Epoch: 6, Loss (standarized): 0.7300604609850982\n",
      "          Validation Loss (standardized): 1.6773213199611192\n",
      "Epoch: 11, Loss (standarized): 0.7226401817880367\n",
      "          Validation Loss (standardized): 2.091979471901698\n",
      "Epoch: 16, Loss (standarized): 0.6665026447956335\n",
      "          Validation Loss (standardized): 2.1094593993758823\n",
      "Epoch: 21, Loss (standarized): 0.6180026377178751\n",
      "          Validation Loss (standardized): 1.9736967703271593\n",
      "Epoch: 26, Loss (standarized): 0.601398789528611\n",
      "          Validation Loss (standardized): 1.802405341786342\n",
      "Epoch: 31, Loss (standarized): 0.5879914146705901\n",
      "          Validation Loss (standardized): 1.6662716349872002\n",
      "Epoch: 36, Loss (standarized): 0.5695253994880853\n",
      "          Validation Loss (standardized): 1.6110371838694768\n",
      "Epoch: 41, Loss (standarized): 0.5523516266068685\n",
      "          Validation Loss (standardized): 1.6147891305554594\n",
      "Epoch: 46, Loss (standarized): 0.5350156563975549\n",
      "          Validation Loss (standardized): 1.6290153773144103\n",
      "Epoch: 51, Loss (standarized): 0.5168383062013596\n",
      "          Validation Loss (standardized): 1.6232813829093011\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.49655753403924485\n",
      "          Validation Loss (standardized): 1.5995228194653892\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.4780561308249322\n",
      "          Validation Loss (standardized): 1.570922819166312\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.4600877039376039\n",
      "          Validation Loss (standardized): 1.5430473404030214\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.4413938232611652\n",
      "          Validation Loss (standardized): 1.5225277082454527\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.4229442823521099\n",
      "          Validation Loss (standardized): 1.5061664089854963\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.40510304034005096\n",
      "          Validation Loss (standardized): 1.4872950411428643\n",
      "Epoch: 86, Loss (standarized): 0.38787294589559906\n",
      "          Validation Loss (standardized): 1.4664171957045309\n",
      "Epoch: 91, Loss (standarized): 0.37126218184656046\n",
      "          Validation Loss (standardized): 1.4469254644116643\n",
      "Epoch: 96, Loss (standarized): 0.3556255533313022\n",
      "          Validation Loss (standardized): 1.4302390303580932\n",
      "Final epoch: 100, Final loss (standarized): 0.34401879011312897\n",
      "Epoch: 1, Loss (standarized): 1.4082270907338506\n",
      "          Validation Loss (standardized): 1.2262251521715144\n",
      "Epoch: 6, Loss (standarized): 0.7636112080863416\n",
      "          Validation Loss (standardized): 1.4883334973457987\n",
      "Epoch: 11, Loss (standarized): 0.6578538812630774\n",
      "          Validation Loss (standardized): 1.960915785972878\n",
      "Epoch: 16, Loss (standarized): 0.6564693121731481\n",
      "          Validation Loss (standardized): 2.197160114500953\n",
      "Epoch: 21, Loss (standarized): 0.6207164841089475\n",
      "          Validation Loss (standardized): 2.0955126917773006\n",
      "Epoch: 26, Loss (standarized): 0.5852976943782067\n",
      "          Validation Loss (standardized): 1.8742930165493858\n",
      "Epoch: 31, Loss (standarized): 0.5578678781721402\n",
      "          Validation Loss (standardized): 1.687358131438556\n",
      "Epoch: 36, Loss (standarized): 0.531860732892331\n",
      "          Validation Loss (standardized): 1.5679609358082798\n",
      "Epoch: 41, Loss (standarized): 0.5021565135333784\n",
      "          Validation Loss (standardized): 1.5131727413959897\n",
      "Epoch: 46, Loss (standarized): 0.4683596757290163\n",
      "          Validation Loss (standardized): 1.4898563817051238\n",
      "Epoch: 51, Loss (standarized): 0.43532821598502747\n",
      "          Validation Loss (standardized): 1.4945681718469352\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.4051776923239844\n",
      "          Validation Loss (standardized): 1.4920768979132282\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.37645805432401985\n",
      "          Validation Loss (standardized): 1.4736239331740248\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.3486735328605653\n",
      "          Validation Loss (standardized): 1.4334096163162107\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.3220127882684055\n",
      "          Validation Loss (standardized): 1.3780669763323499\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.29717128982483354\n",
      "          Validation Loss (standardized): 1.3269835672280803\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.27416450491736\n",
      "          Validation Loss (standardized): 1.2889567603648215\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.25410497228923684\n",
      "          Validation Loss (standardized): 1.2572642216594276\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.23700155196870798\n",
      "          Validation Loss (standardized): 1.226802336179648\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.22262604584197548\n",
      "          Validation Loss (standardized): 1.1906691863960959\n",
      "Final epoch: 100, Final loss (standarized): 0.21292914131903135\n",
      "Epoch: 1, Loss (standarized): 1.9164550846184956\n",
      "          Validation Loss (standardized): 1.248024354288188\n",
      "Epoch: 6, Loss (standarized): 0.9297452003037825\n",
      "          Validation Loss (standardized): 1.3083499636442844\n",
      "Epoch: 11, Loss (standarized): 0.6835921737396911\n",
      "          Validation Loss (standardized): 1.7374049207069802\n",
      "Epoch: 16, Loss (standarized): 0.6455785788369484\n",
      "          Validation Loss (standardized): 2.0913295930266407\n",
      "Epoch: 21, Loss (standarized): 0.6208725400052649\n",
      "          Validation Loss (standardized): 2.2260822676099647\n",
      "Epoch: 26, Loss (standarized): 0.5940391490778052\n",
      "          Validation Loss (standardized): 2.201999568078883\n",
      "Epoch: 31, Loss (standarized): 0.5680222398578343\n",
      "          Validation Loss (standardized): 2.083496054754789\n",
      "Epoch: 36, Loss (standarized): 0.5362045600460236\n",
      "          Validation Loss (standardized): 1.928248561675131\n",
      "Epoch: 41, Loss (standarized): 0.5039087606729454\n",
      "          Validation Loss (standardized): 1.7870512928364086\n",
      "Epoch: 46, Loss (standarized): 0.4706344578016406\n",
      "          Validation Loss (standardized): 1.6841266489802542\n",
      "Epoch: 51, Loss (standarized): 0.43492577691268325\n",
      "          Validation Loss (standardized): 1.6520611998875974\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.39647713833626497\n",
      "          Validation Loss (standardized): 1.6487106612949214\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.3573969005250804\n",
      "          Validation Loss (standardized): 1.6438656250332393\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.32109238780227894\n",
      "          Validation Loss (standardized): 1.6155028111177017\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.2902628706439909\n",
      "          Validation Loss (standardized): 1.5645696795061215\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.2648747939727173\n",
      "          Validation Loss (standardized): 1.4997975959009053\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.24402138298801937\n",
      "          Validation Loss (standardized): 1.4202120743663937\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.22730115594073197\n",
      "          Validation Loss (standardized): 1.3559725659683173\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 91, Loss (standarized): 0.21351925155799104\n",
      "          Validation Loss (standardized): 1.3006470291195211\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 96, Loss (standarized): 0.20167062132999553\n",
      "          Validation Loss (standardized): 1.235663144488518\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Final epoch: 100, Final loss (standarized): 0.19339259186777916\n",
      "Epoch: 1, Loss (standarized): 1.131236166498267\n",
      "          Validation Loss (standardized): 1.8901868435835798\n",
      "Epoch: 6, Loss (standarized): 0.7300517037815533\n",
      "          Validation Loss (standardized): 1.8790967737572035\n",
      "Epoch: 11, Loss (standarized): 0.6946591384042354\n",
      "          Validation Loss (standardized): 1.9762082678009696\n",
      "Epoch: 16, Loss (standarized): 0.6463879913912495\n",
      "          Validation Loss (standardized): 1.8744710367626471\n",
      "Epoch: 21, Loss (standarized): 0.6175568128823394\n",
      "          Validation Loss (standardized): 1.733107331311009\n",
      "Epoch: 26, Loss (standarized): 0.5869742512269625\n",
      "          Validation Loss (standardized): 1.6324311894290227\n",
      "Epoch: 31, Loss (standarized): 0.5439565122236713\n",
      "          Validation Loss (standardized): 1.6758487149398895\n",
      "Epoch: 36, Loss (standarized): 0.4933234037693214\n",
      "          Validation Loss (standardized): 1.665457526324632\n",
      "Epoch: 41, Loss (standarized): 0.4369559273067745\n",
      "          Validation Loss (standardized): 1.5187603317026466\n",
      "Epoch: 46, Loss (standarized): 0.37621050298814845\n",
      "          Validation Loss (standardized): 1.4339593208658552\n",
      "Epoch: 51, Loss (standarized): 0.32058428863035804\n",
      "          Validation Loss (standardized): 1.380874657139604\n",
      "Epoch: 56, Loss (standarized): 0.27263900431986243\n",
      "          Validation Loss (standardized): 1.2562821094505225\n",
      "Epoch: 61, Loss (standarized): 0.23284018037113746\n",
      "          Validation Loss (standardized): 1.1459510623264766\n",
      "Epoch: 66, Loss (standarized): 0.1996048363334637\n",
      "          Validation Loss (standardized): 1.0943443669008024\n",
      "Epoch: 71, Loss (standarized): 0.17529093930874298\n",
      "          Validation Loss (standardized): 1.0298933571512894\n",
      "Epoch: 76, Loss (standarized): 0.1566597215784497\n",
      "          Validation Loss (standardized): 0.9492678171304382\n",
      "Epoch: 81, Loss (standarized): 0.14166239148103962\n",
      "          Validation Loss (standardized): 0.8985133469391285\n",
      "Epoch: 86, Loss (standarized): 0.12886344143509382\n",
      "          Validation Loss (standardized): 0.8430980965622312\n",
      "Epoch: 91, Loss (standarized): 0.11768744918770054\n",
      "          Validation Loss (standardized): 0.7920766162884925\n",
      "Epoch: 96, Loss (standarized): 0.10806244871139357\n",
      "          Validation Loss (standardized): 0.7406353896784248\n",
      "Final epoch: 100, Final loss (standarized): 0.10130275557772975\n",
      "Epoch: 1, Loss (standarized): 1.2793865541828577\n",
      "          Validation Loss (standardized): 1.3854473691481048\n",
      "Epoch: 6, Loss (standarized): 0.7115472826069636\n",
      "          Validation Loss (standardized): 1.7773769671697497\n",
      "Epoch: 11, Loss (standarized): 0.6758481784742942\n",
      "          Validation Loss (standardized): 2.171209396572558\n",
      "Epoch: 16, Loss (standarized): 0.6476208928048712\n",
      "          Validation Loss (standardized): 2.0935472873220515\n",
      "Epoch: 21, Loss (standarized): 0.6170175369654994\n",
      "          Validation Loss (standardized): 1.8400270564038166\n",
      "Epoch: 26, Loss (standarized): 0.6031351731110355\n",
      "          Validation Loss (standardized): 1.636544447416942\n",
      "Epoch: 31, Loss (standarized): 0.5829393520389325\n",
      "          Validation Loss (standardized): 1.589905837903785\n",
      "Epoch: 36, Loss (standarized): 0.5555376848688679\n",
      "          Validation Loss (standardized): 1.6409304204443504\n",
      "Epoch: 41, Loss (standarized): 0.5316189852899068\n",
      "          Validation Loss (standardized): 1.6758071220244837\n",
      "Epoch: 46, Loss (standarized): 0.5071062832229281\n",
      "          Validation Loss (standardized): 1.6548918074688186\n",
      "Epoch: 51, Loss (standarized): 0.48167076741274406\n",
      "          Validation Loss (standardized): 1.599475365187334\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.4547197051809794\n",
      "          Validation Loss (standardized): 1.5440996023917615\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.42726407861254406\n",
      "          Validation Loss (standardized): 1.5004825490037912\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.4000019635277374\n",
      "          Validation Loss (standardized): 1.4700799861365412\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.3742928968821087\n",
      "          Validation Loss (standardized): 1.4498542167679287\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 76, Loss (standarized): 0.34895281150585394\n",
      "          Validation Loss (standardized): 1.4285456421742753\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 81, Loss (standarized): 0.32542107075687066\n",
      "          Validation Loss (standardized): 1.3935695238740655\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 86, Loss (standarized): 0.3049366362497511\n",
      "          Validation Loss (standardized): 1.3535417116306971\n",
      "Epoch: 91, Loss (standarized): 0.2873720689404185\n",
      "          Validation Loss (standardized): 1.3235500946476617\n",
      "Epoch: 96, Loss (standarized): 0.272924055842945\n",
      "          Validation Loss (standardized): 1.297779289808485\n",
      "Final epoch: 100, Final loss (standarized): 0.2635175540909042\n",
      "Epoch: 1, Loss (standarized): 1.0644057437900867\n",
      "          Validation Loss (standardized): 1.7490479830535828\n",
      "Epoch: 6, Loss (standarized): 0.7026872345955074\n",
      "          Validation Loss (standardized): 1.9718656364388936\n",
      "Epoch: 11, Loss (standarized): 0.6665915637253182\n",
      "          Validation Loss (standardized): 2.175294378673644\n",
      "Epoch: 16, Loss (standarized): 0.6235475997559325\n",
      "          Validation Loss (standardized): 2.043054599689388\n",
      "Epoch: 21, Loss (standarized): 0.5913459295240758\n",
      "          Validation Loss (standardized): 1.7856799235114071\n",
      "Epoch: 26, Loss (standarized): 0.5510351518753476\n",
      "          Validation Loss (standardized): 1.5929811244367975\n",
      "Epoch: 31, Loss (standarized): 0.504926169365241\n",
      "          Validation Loss (standardized): 1.5554133347297219\n",
      "Epoch: 36, Loss (standarized): 0.45338492212230114\n",
      "          Validation Loss (standardized): 1.5389582805408195\n",
      "Epoch: 41, Loss (standarized): 0.3983747148886728\n",
      "          Validation Loss (standardized): 1.4408852038983404\n",
      "Epoch: 46, Loss (standarized): 0.34241474881797174\n",
      "          Validation Loss (standardized): 1.3422763184103705\n",
      "Epoch: 51, Loss (standarized): 0.2929945004298205\n",
      "          Validation Loss (standardized): 1.2517348482257267\n",
      "Epoch: 56, Loss (standarized): 0.25253861264335825\n",
      "          Validation Loss (standardized): 1.1815015583426816\n",
      "Epoch: 61, Loss (standarized): 0.22151034989185492\n",
      "          Validation Loss (standardized): 1.0910267299806256\n",
      "Epoch: 66, Loss (standarized): 0.19791800738463636\n",
      "          Validation Loss (standardized): 1.0140149639607225\n",
      "Epoch: 71, Loss (standarized): 0.17964492993961995\n",
      "          Validation Loss (standardized): 0.943171104259556\n",
      "Epoch: 76, Loss (standarized): 0.16514347244833824\n",
      "          Validation Loss (standardized): 0.8821304438840112\n",
      "Epoch: 81, Loss (standarized): 0.15302809212234525\n",
      "          Validation Loss (standardized): 0.8467765310225891\n",
      "Epoch: 86, Loss (standarized): 0.14271370660721772\n",
      "          Validation Loss (standardized): 0.8008998721721057\n",
      "Epoch: 91, Loss (standarized): 0.13408016243307852\n",
      "          Validation Loss (standardized): 0.7648342818206467\n",
      "Epoch: 96, Loss (standarized): 0.12664442363713818\n",
      "          Validation Loss (standardized): 0.7525049454459781\n",
      "Final epoch: 100, Final loss (standarized): 0.12125081714310969\n",
      "Epoch: 1, Loss (standarized): 1.6275101618144114\n",
      "          Validation Loss (standardized): 1.4526158932582147\n",
      "Epoch: 6, Loss (standarized): 0.835176699312634\n",
      "          Validation Loss (standardized): 1.6010666681196797\n",
      "Epoch: 11, Loss (standarized): 0.7172492524313306\n",
      "          Validation Loss (standardized): 2.0455852088424717\n",
      "Epoch: 16, Loss (standarized): 0.695938139407875\n",
      "          Validation Loss (standardized): 2.445355373701887\n",
      "Epoch: 21, Loss (standarized): 0.6759078533183934\n",
      "          Validation Loss (standardized): 2.4379540550589853\n",
      "Epoch: 26, Loss (standarized): 0.6458041513380037\n",
      "          Validation Loss (standardized): 2.18814966716187\n",
      "Epoch: 31, Loss (standarized): 0.6193700246404811\n",
      "          Validation Loss (standardized): 1.9359527736320952\n",
      "Epoch: 36, Loss (standarized): 0.5882190606897485\n",
      "          Validation Loss (standardized): 1.7175255724179868\n",
      "Epoch: 41, Loss (standarized): 0.5587816422056743\n",
      "          Validation Loss (standardized): 1.5644435578518174\n",
      "Epoch: 46, Loss (standarized): 0.527668527270893\n",
      "          Validation Loss (standardized): 1.5156128668538489\n",
      "Epoch: 51, Loss (standarized): 0.49082100085498387\n",
      "          Validation Loss (standardized): 1.5371787422039522\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 56, Loss (standarized): 0.4491543077554377\n",
      "          Validation Loss (standardized): 1.5575017684064796\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 61, Loss (standarized): 0.40347784376142953\n",
      "          Validation Loss (standardized): 1.534384729831435\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 66, Loss (standarized): 0.3582034372392769\n",
      "          Validation Loss (standardized): 1.4980914512517947\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Early stopping triggered. No improvement in validation loss for 50 epochs.\n",
      "Epoch: 71, Loss (standarized): 0.3156199441917601\n",
      "          Validation Loss (standardized): 1.4401831018931202\n",
      "Epoch: 76, Loss (standarized): 0.278213618541718\n",
      "          Validation Loss (standardized): 1.3707155036513172\n",
      "Epoch: 81, Loss (standarized): 0.248517746175631\n",
      "          Validation Loss (standardized): 1.302489519194723\n",
      "Epoch: 86, Loss (standarized): 0.2250453210143005\n",
      "          Validation Loss (standardized): 1.2437637620311444\n",
      "Epoch: 91, Loss (standarized): 0.20632303938434218\n",
      "          Validation Loss (standardized): 1.1769391085274867\n",
      "Epoch: 96, Loss (standarized): 0.19128738890936028\n",
      "          Validation Loss (standardized): 1.120500931565506\n",
      "Final epoch: 100, Final loss (standarized): 0.1809219506794148\n",
      "Epoch: 1, Loss (standarized): 2.221676270145258\n",
      "          Validation Loss (standardized): 1.6855352434732847\n",
      "Epoch: 6, Loss (standarized): 1.0866960730917865\n",
      "          Validation Loss (standardized): 1.4691588389445738\n",
      "Epoch: 11, Loss (standarized): 0.7651016623404113\n",
      "          Validation Loss (standardized): 1.8867308776316327\n",
      "Epoch: 16, Loss (standarized): 0.7314300033860317\n",
      "          Validation Loss (standardized): 2.3246806357418164\n",
      "Epoch: 21, Loss (standarized): 0.6854546892763135\n",
      "          Validation Loss (standardized): 2.4803657179948337\n",
      "Epoch: 26, Loss (standarized): 0.6575226252096092\n",
      "          Validation Loss (standardized): 2.4130548143834933\n",
      "Epoch: 31, Loss (standarized): 0.6257971601595165\n",
      "          Validation Loss (standardized): 2.1776035775804155\n",
      "Epoch: 36, Loss (standarized): 0.587236312058728\n",
      "          Validation Loss (standardized): 1.9151566292765687\n",
      "Epoch: 41, Loss (standarized): 0.5593044724971639\n",
      "          Validation Loss (standardized): 1.727730758791421\n",
      "Epoch: 46, Loss (standarized): 0.5292700066816829\n",
      "          Validation Loss (standardized): 1.6516054596419913\n",
      "Epoch: 51, Loss (standarized): 0.4960206658625403\n",
      "          Validation Loss (standardized): 1.662380387156491\n",
      "Epoch: 56, Loss (standarized): 0.4614606283922769\n",
      "          Validation Loss (standardized): 1.663897355371645\n",
      "Epoch: 61, Loss (standarized): 0.421653510526342\n",
      "          Validation Loss (standardized): 1.6194701046065967\n",
      "Epoch: 66, Loss (standarized): 0.3767232282091646\n",
      "          Validation Loss (standardized): 1.4830650825397402\n",
      "Epoch: 71, Loss (standarized): 0.3342048919435184\n",
      "          Validation Loss (standardized): 1.4032206246133965\n",
      "Epoch: 76, Loss (standarized): 0.2922020464918065\n",
      "          Validation Loss (standardized): 1.3993590336996535\n",
      "Epoch: 81, Loss (standarized): 0.25619942446690014\n",
      "          Validation Loss (standardized): 1.3278868783985103\n",
      "Epoch: 86, Loss (standarized): 0.22640994841443365\n",
      "          Validation Loss (standardized): 1.1937927985978667\n",
      "Epoch: 91, Loss (standarized): 0.20273598635163045\n",
      "          Validation Loss (standardized): 1.0961651550429368\n",
      "Epoch: 96, Loss (standarized): 0.18331866791991622\n",
      "          Validation Loss (standardized): 1.0135929055238344\n",
      "Final epoch: 100, Final loss (standarized): 0.16992005115485292\n",
      "Epoch: 1, Loss (standarized): 1.5946413247424303\n",
      "          Validation Loss (standardized): 1.7702293180625501\n",
      "Epoch: 6, Loss (standarized): 0.8150091021527404\n",
      "          Validation Loss (standardized): 1.5975104835934322\n",
      "Epoch: 11, Loss (standarized): 0.7625079407773383\n",
      "          Validation Loss (standardized): 1.8905946924872659\n",
      "Epoch: 16, Loss (standarized): 0.6925910167427536\n",
      "          Validation Loss (standardized): 2.0391960947863423\n",
      "Epoch: 21, Loss (standarized): 0.6856141100846368\n",
      "          Validation Loss (standardized): 2.0145744621721\n",
      "Epoch: 26, Loss (standarized): 0.6565782162922502\n",
      "          Validation Loss (standardized): 1.8841189720912634\n",
      "Epoch: 31, Loss (standarized): 0.6484377345438982\n",
      "          Validation Loss (standardized): 1.7606859466314422\n",
      "Epoch: 36, Loss (standarized): 0.6330152922791369\n",
      "          Validation Loss (standardized): 1.6848469678917213\n",
      "Epoch: 41, Loss (standarized): 0.6220579781810557\n",
      "          Validation Loss (standardized): 1.6638531802136722\n",
      "Epoch: 46, Loss (standarized): 0.6072941052787014\n",
      "          Validation Loss (standardized): 1.6691083339198944\n",
      "Epoch: 51, Loss (standarized): 0.5928770269809448\n",
      "          Validation Loss (standardized): 1.6876937648008985\n",
      "Epoch: 56, Loss (standarized): 0.5769279834421097\n",
      "          Validation Loss (standardized): 1.7025151009783621\n",
      "Epoch: 61, Loss (standarized): 0.5563443574211919\n",
      "          Validation Loss (standardized): 1.6971166511640987\n",
      "Epoch: 66, Loss (standarized): 0.5347850325674129\n",
      "          Validation Loss (standardized): 1.6721124358653843\n",
      "Epoch: 71, Loss (standarized): 0.510898703192046\n",
      "          Validation Loss (standardized): 1.6357333216544758\n",
      "Epoch: 76, Loss (standarized): 0.48489042563250034\n",
      "          Validation Loss (standardized): 1.5895148886845052\n",
      "Epoch: 81, Loss (standarized): 0.45970624063275917\n",
      "          Validation Loss (standardized): 1.5530778207663494\n",
      "Epoch: 86, Loss (standarized): 0.43642779096935874\n",
      "          Validation Loss (standardized): 1.530391546963926\n",
      "Epoch: 91, Loss (standarized): 0.41509743472925636\n",
      "          Validation Loss (standardized): 1.5095370166109794\n",
      "Epoch: 96, Loss (standarized): 0.3959631243470134\n",
      "          Validation Loss (standardized): 1.481504709595336\n",
      "Final epoch: 100, Final loss (standarized): 0.3812638854396887\n",
      "Epoch: 1, Loss (standarized): 1.5707197670929633\n",
      "          Validation Loss (standardized): 1.2434887142667725\n",
      "Epoch: 6, Loss (standarized): 0.8205429768130748\n",
      "          Validation Loss (standardized): 1.4435812660810168\n",
      "Epoch: 11, Loss (standarized): 0.703749286741967\n",
      "          Validation Loss (standardized): 2.0367246508456396\n",
      "Epoch: 16, Loss (standarized): 0.660765547979787\n",
      "          Validation Loss (standardized): 2.286284596722798\n",
      "Epoch: 21, Loss (standarized): 0.6159390546174663\n",
      "          Validation Loss (standardized): 2.2196559352485785\n",
      "Epoch: 26, Loss (standarized): 0.5759736140090085\n",
      "          Validation Loss (standardized): 2.0102879040897608\n",
      "Epoch: 31, Loss (standarized): 0.5365271409544239\n",
      "          Validation Loss (standardized): 1.807865318588353\n",
      "Epoch: 36, Loss (standarized): 0.4995762920485292\n",
      "          Validation Loss (standardized): 1.6697548869407561\n",
      "Epoch: 41, Loss (standarized): 0.4640364143024348\n",
      "          Validation Loss (standardized): 1.5954732184221858\n",
      "Epoch: 46, Loss (standarized): 0.4290826001824202\n",
      "          Validation Loss (standardized): 1.5673780930690804\n",
      "Epoch: 51, Loss (standarized): 0.39484383114910865\n",
      "          Validation Loss (standardized): 1.564648657537758\n",
      "Epoch: 56, Loss (standarized): 0.36077372255750434\n",
      "          Validation Loss (standardized): 1.556289991747788\n",
      "Epoch: 61, Loss (standarized): 0.32715229760298065\n",
      "          Validation Loss (standardized): 1.5071136683057258\n",
      "Epoch: 66, Loss (standarized): 0.2949111567109315\n",
      "          Validation Loss (standardized): 1.4197170092430373\n",
      "Epoch: 71, Loss (standarized): 0.26721487072389316\n",
      "          Validation Loss (standardized): 1.333767939083687\n",
      "Epoch: 76, Loss (standarized): 0.24380071385276864\n",
      "          Validation Loss (standardized): 1.2912767305918886\n",
      "Epoch: 81, Loss (standarized): 0.22463254846061037\n",
      "          Validation Loss (standardized): 1.2605034624386922\n",
      "Epoch: 86, Loss (standarized): 0.20880122104069854\n",
      "          Validation Loss (standardized): 1.2047448822190714\n",
      "Epoch: 91, Loss (standarized): 0.1951588046715683\n",
      "          Validation Loss (standardized): 1.147401036894944\n",
      "Epoch: 96, Loss (standarized): 0.183384450662038\n",
      "          Validation Loss (standardized): 1.1063843552567687\n",
      "Final epoch: 100, Final loss (standarized): 0.17507170661969074\n",
      "Epoch: 1, Loss (standarized): 1.7368414983484999\n",
      "          Validation Loss (standardized): 1.1760107137092826\n",
      "Epoch: 6, Loss (standarized): 0.9305973636419311\n",
      "          Validation Loss (standardized): 1.3519150482791304\n",
      "Epoch: 11, Loss (standarized): 0.7108339321044859\n",
      "          Validation Loss (standardized): 1.7738289617095808\n",
      "Epoch: 16, Loss (standarized): 0.6592750341838218\n",
      "          Validation Loss (standardized): 2.144617089079682\n",
      "Epoch: 21, Loss (standarized): 0.6502248000788766\n",
      "          Validation Loss (standardized): 2.2475780372464156\n",
      "Epoch: 26, Loss (standarized): 0.6320124209695649\n",
      "          Validation Loss (standardized): 2.1297213781130493\n",
      "Epoch: 31, Loss (standarized): 0.6147893570359961\n",
      "          Validation Loss (standardized): 1.9612121011188246\n",
      "Epoch: 36, Loss (standarized): 0.5986071569478363\n",
      "          Validation Loss (standardized): 1.8545582259717959\n",
      "Epoch: 41, Loss (standarized): 0.5798026053104687\n",
      "          Validation Loss (standardized): 1.8171978900430155\n",
      "Epoch: 46, Loss (standarized): 0.5576807058643067\n",
      "          Validation Loss (standardized): 1.799039084579068\n",
      "Epoch: 51, Loss (standarized): 0.5302608577035496\n",
      "          Validation Loss (standardized): 1.7998979908147794\n",
      "Epoch: 56, Loss (standarized): 0.4979442839213442\n",
      "          Validation Loss (standardized): 1.8172845014152745\n",
      "Epoch: 61, Loss (standarized): 0.46204177927182066\n",
      "          Validation Loss (standardized): 1.813837067468168\n",
      "Epoch: 66, Loss (standarized): 0.42224781704140224\n",
      "          Validation Loss (standardized): 1.7646227580359717\n",
      "Epoch: 71, Loss (standarized): 0.38097695872730086\n",
      "          Validation Loss (standardized): 1.7301406917209396\n",
      "Epoch: 76, Loss (standarized): 0.3410229249656764\n",
      "          Validation Loss (standardized): 1.6718599465886568\n",
      "Epoch: 81, Loss (standarized): 0.30344119600173985\n",
      "          Validation Loss (standardized): 1.5767920022467552\n",
      "Epoch: 86, Loss (standarized): 0.26979752853704636\n",
      "          Validation Loss (standardized): 1.4775677149399158\n",
      "Epoch: 91, Loss (standarized): 0.24335785947088648\n",
      "          Validation Loss (standardized): 1.366508653965683\n",
      "Epoch: 96, Loss (standarized): 0.2221497412884457\n",
      "          Validation Loss (standardized): 1.2837806655923698\n",
      "Final epoch: 100, Final loss (standarized): 0.20724457772488272\n",
      "Epoch: 1, Loss (standarized): 0.9230046985478114\n",
      "          Validation Loss (standardized): 1.595084918526517\n",
      "Epoch: 6, Loss (standarized): 0.687643837081524\n",
      "          Validation Loss (standardized): 1.6782311368849403\n",
      "Epoch: 11, Loss (standarized): 0.6494665734117192\n",
      "          Validation Loss (standardized): 1.7192935141640213\n",
      "Epoch: 16, Loss (standarized): 0.6263550605220055\n",
      "          Validation Loss (standardized): 1.643193398094358\n",
      "Epoch: 21, Loss (standarized): 0.6125755860684997\n",
      "          Validation Loss (standardized): 1.6042462581290755\n",
      "Epoch: 26, Loss (standarized): 0.5943706524821637\n",
      "          Validation Loss (standardized): 1.587200630554722\n",
      "Epoch: 31, Loss (standarized): 0.5791845223638274\n",
      "          Validation Loss (standardized): 1.5787616476662854\n",
      "Epoch: 36, Loss (standarized): 0.567309085933375\n",
      "          Validation Loss (standardized): 1.5430628370625137\n",
      "Epoch: 41, Loss (standarized): 0.5526914847628067\n",
      "          Validation Loss (standardized): 1.5061741013150622\n",
      "Epoch: 46, Loss (standarized): 0.5352870079922459\n",
      "          Validation Loss (standardized): 1.4988786263108747\n",
      "Epoch: 51, Loss (standarized): 0.5185002484511967\n",
      "          Validation Loss (standardized): 1.4938461573869477\n",
      "Epoch: 56, Loss (standarized): 0.5010864507513051\n",
      "          Validation Loss (standardized): 1.5041960040298878\n",
      "Epoch: 61, Loss (standarized): 0.4829184510998747\n",
      "          Validation Loss (standardized): 1.518159210080622\n",
      "Epoch: 66, Loss (standarized): 0.4654932505086053\n",
      "          Validation Loss (standardized): 1.501697978007106\n",
      "Epoch: 71, Loss (standarized): 0.44724505123435854\n",
      "          Validation Loss (standardized): 1.4834100983001703\n",
      "Epoch: 76, Loss (standarized): 0.4298197350844423\n",
      "          Validation Loss (standardized): 1.4536353944943448\n",
      "Epoch: 81, Loss (standarized): 0.4124263175624134\n",
      "          Validation Loss (standardized): 1.4307945152687576\n",
      "Epoch: 86, Loss (standarized): 0.39444222534660256\n",
      "          Validation Loss (standardized): 1.4213090859565245\n",
      "Epoch: 91, Loss (standarized): 0.3767611645679982\n",
      "          Validation Loss (standardized): 1.4051514130100142\n",
      "Epoch: 96, Loss (standarized): 0.35994391425753763\n",
      "          Validation Loss (standardized): 1.4000741242600134\n",
      "Final epoch: 100, Final loss (standarized): 0.34771654374372607\n",
      "Epoch: 1, Loss (standarized): 1.9536056956198882\n",
      "          Validation Loss (standardized): 1.2197681311849693\n",
      "Epoch: 6, Loss (standarized): 0.9153568495034442\n",
      "          Validation Loss (standardized): 1.388523253700132\n",
      "Epoch: 11, Loss (standarized): 0.7010417928604709\n",
      "          Validation Loss (standardized): 1.7399030660942971\n",
      "Epoch: 16, Loss (standarized): 0.6402040253094542\n",
      "          Validation Loss (standardized): 1.9357496965560912\n",
      "Epoch: 21, Loss (standarized): 0.6284873916137204\n",
      "          Validation Loss (standardized): 1.9923881773983751\n",
      "Epoch: 26, Loss (standarized): 0.6185321699819729\n",
      "          Validation Loss (standardized): 1.957230593367477\n",
      "Epoch: 31, Loss (standarized): 0.607184244494453\n",
      "          Validation Loss (standardized): 1.865563636228536\n",
      "Epoch: 36, Loss (standarized): 0.5998034483309951\n",
      "          Validation Loss (standardized): 1.7631570418904485\n",
      "Epoch: 41, Loss (standarized): 0.5943624682038017\n",
      "          Validation Loss (standardized): 1.6706728002776454\n",
      "Epoch: 46, Loss (standarized): 0.5905092510036614\n",
      "          Validation Loss (standardized): 1.599793449111482\n",
      "Epoch: 51, Loss (standarized): 0.5885826099466918\n",
      "          Validation Loss (standardized): 1.5458107446722102\n",
      "Epoch: 56, Loss (standarized): 0.5856757335394789\n",
      "          Validation Loss (standardized): 1.505441448059154\n",
      "Epoch: 61, Loss (standarized): 0.5815025538831899\n",
      "          Validation Loss (standardized): 1.4816187274411627\n",
      "Epoch: 66, Loss (standarized): 0.576834734626435\n",
      "          Validation Loss (standardized): 1.4737389626290258\n",
      "Epoch: 71, Loss (standarized): 0.5721953566808182\n",
      "          Validation Loss (standardized): 1.483783590992048\n",
      "Epoch: 76, Loss (standarized): 0.5674612030989595\n",
      "          Validation Loss (standardized): 1.4953631311693392\n",
      "Epoch: 81, Loss (standarized): 0.5633871750762574\n",
      "          Validation Loss (standardized): 1.498440547366369\n",
      "Epoch: 86, Loss (standarized): 0.5601866572885597\n",
      "          Validation Loss (standardized): 1.4957798804571034\n",
      "Epoch: 91, Loss (standarized): 0.5574859346862894\n",
      "          Validation Loss (standardized): 1.4866816506654328\n",
      "Epoch: 96, Loss (standarized): 0.554830604056607\n",
      "          Validation Loss (standardized): 1.4848981284214842\n",
      "Final epoch: 100, Final loss (standarized): 0.552749330829752\n",
      "Epoch: 1, Loss (standarized): 1.3906768390679485\n",
      "          Validation Loss (standardized): 1.418886437237061\n",
      "Epoch: 6, Loss (standarized): 0.8407378204332838\n",
      "          Validation Loss (standardized): 1.5777759293427271\n",
      "Epoch: 11, Loss (standarized): 0.7018100050722322\n",
      "          Validation Loss (standardized): 1.864937793655903\n",
      "Epoch: 16, Loss (standarized): 0.6555829444835868\n",
      "          Validation Loss (standardized): 1.9443365046232541\n",
      "Epoch: 21, Loss (standarized): 0.6277457546106225\n",
      "          Validation Loss (standardized): 1.8478340437394813\n",
      "Epoch: 26, Loss (standarized): 0.6094388332506241\n",
      "          Validation Loss (standardized): 1.7003456835909163\n",
      "Epoch: 31, Loss (standarized): 0.5921563837935082\n",
      "          Validation Loss (standardized): 1.587603304695296\n",
      "Epoch: 36, Loss (standarized): 0.5756065876391092\n",
      "          Validation Loss (standardized): 1.5356771076247242\n",
      "Epoch: 41, Loss (standarized): 0.5631991610853336\n",
      "          Validation Loss (standardized): 1.530302743646219\n",
      "Epoch: 46, Loss (standarized): 0.5509007161584901\n",
      "          Validation Loss (standardized): 1.5276250500641593\n",
      "Epoch: 51, Loss (standarized): 0.5392231425841459\n",
      "          Validation Loss (standardized): 1.5256904545300045\n",
      "Epoch: 56, Loss (standarized): 0.5280106959823203\n",
      "          Validation Loss (standardized): 1.518553445673207\n",
      "Epoch: 61, Loss (standarized): 0.5184503339806424\n",
      "          Validation Loss (standardized): 1.514658633449908\n",
      "Epoch: 66, Loss (standarized): 0.5102645630628482\n",
      "          Validation Loss (standardized): 1.5152659963115027\n",
      "Epoch: 71, Loss (standarized): 0.5037970748288131\n",
      "          Validation Loss (standardized): 1.5181868983404028\n",
      "Epoch: 76, Loss (standarized): 0.49791360979775007\n",
      "          Validation Loss (standardized): 1.5221180087832418\n",
      "Epoch: 81, Loss (standarized): 0.4920148487856536\n",
      "          Validation Loss (standardized): 1.5263197711461525\n",
      "Epoch: 86, Loss (standarized): 0.4872608713053591\n",
      "          Validation Loss (standardized): 1.5296231212927522\n",
      "Epoch: 91, Loss (standarized): 0.48285525004077884\n",
      "          Validation Loss (standardized): 1.5358352592183928\n",
      "Epoch: 96, Loss (standarized): 0.47878747305888114\n",
      "          Validation Loss (standardized): 1.534861567498646\n",
      "Final epoch: 100, Final loss (standarized): 0.47627014886777586\n",
      "Epoch: 1, Loss (standarized): 1.785971665542449\n",
      "          Validation Loss (standardized): 1.4766876433968825\n",
      "Epoch: 6, Loss (standarized): 0.8782391595339603\n",
      "          Validation Loss (standardized): 1.711341208608094\n",
      "Epoch: 11, Loss (standarized): 0.7454183969656482\n",
      "          Validation Loss (standardized): 2.018072300239407\n",
      "Epoch: 16, Loss (standarized): 0.6954215836739672\n",
      "          Validation Loss (standardized): 2.006267860279868\n",
      "Epoch: 21, Loss (standarized): 0.6679413816791051\n",
      "          Validation Loss (standardized): 1.8725797386375527\n",
      "Epoch: 26, Loss (standarized): 0.6536775131384132\n",
      "          Validation Loss (standardized): 1.7327782385636092\n",
      "Epoch: 31, Loss (standarized): 0.640406017733525\n",
      "          Validation Loss (standardized): 1.634310217850832\n",
      "Epoch: 36, Loss (standarized): 0.6299909145343305\n",
      "          Validation Loss (standardized): 1.5812590393925106\n",
      "Epoch: 41, Loss (standarized): 0.6200543703565708\n",
      "          Validation Loss (standardized): 1.55518216914036\n",
      "Epoch: 46, Loss (standarized): 0.6114070332902632\n",
      "          Validation Loss (standardized): 1.5229490856404997\n",
      "Epoch: 51, Loss (standarized): 0.6024512885881266\n",
      "          Validation Loss (standardized): 1.4968887065227432\n",
      "Epoch: 56, Loss (standarized): 0.5919175347884067\n",
      "          Validation Loss (standardized): 1.4876744016812777\n",
      "Epoch: 61, Loss (standarized): 0.5816975910209098\n",
      "          Validation Loss (standardized): 1.4944473078899394\n",
      "Epoch: 66, Loss (standarized): 0.5725347126508815\n",
      "          Validation Loss (standardized): 1.5065356578972342\n",
      "Epoch: 71, Loss (standarized): 0.5627658061933132\n",
      "          Validation Loss (standardized): 1.5161702559852852\n",
      "Epoch: 76, Loss (standarized): 0.553032797396355\n",
      "          Validation Loss (standardized): 1.514304787084021\n",
      "Epoch: 81, Loss (standarized): 0.5438196047505511\n",
      "          Validation Loss (standardized): 1.508622894625512\n",
      "Epoch: 86, Loss (standarized): 0.535773795048619\n",
      "          Validation Loss (standardized): 1.5014017502296924\n",
      "Epoch: 91, Loss (standarized): 0.5280126809731913\n",
      "          Validation Loss (standardized): 1.496269910686836\n",
      "Epoch: 96, Loss (standarized): 0.5204682897687558\n",
      "          Validation Loss (standardized): 1.503228098481781\n",
      "Final epoch: 100, Final loss (standarized): 0.5140815825698164\n",
      "Epoch: 1, Loss (standarized): 1.138405816005628\n",
      "          Validation Loss (standardized): 1.5897291093595145\n",
      "Epoch: 6, Loss (standarized): 0.7902650745429645\n",
      "          Validation Loss (standardized): 2.025849473190839\n",
      "Epoch: 11, Loss (standarized): 0.7049462857192292\n",
      "          Validation Loss (standardized): 2.198407613890265\n",
      "Epoch: 16, Loss (standarized): 0.669565223628127\n",
      "          Validation Loss (standardized): 2.0762685267048724\n",
      "Epoch: 21, Loss (standarized): 0.6390343913193399\n",
      "          Validation Loss (standardized): 1.8672756450132268\n",
      "Epoch: 26, Loss (standarized): 0.6150886392412394\n",
      "          Validation Loss (standardized): 1.7327561115644257\n",
      "Epoch: 31, Loss (standarized): 0.5908479906302222\n",
      "          Validation Loss (standardized): 1.6829263904360796\n",
      "Epoch: 36, Loss (standarized): 0.5659582178688793\n",
      "          Validation Loss (standardized): 1.6839720310173811\n",
      "Epoch: 41, Loss (standarized): 0.5366610387620668\n",
      "          Validation Loss (standardized): 1.6654740559722172\n",
      "Epoch: 46, Loss (standarized): 0.5032216072124635\n",
      "          Validation Loss (standardized): 1.5886217175645712\n",
      "Epoch: 51, Loss (standarized): 0.46635720139342896\n",
      "          Validation Loss (standardized): 1.5303752103852848\n",
      "Epoch: 56, Loss (standarized): 0.4259352257851918\n",
      "          Validation Loss (standardized): 1.4696543345567898\n",
      "Epoch: 61, Loss (standarized): 0.3829348685701317\n",
      "          Validation Loss (standardized): 1.4137975963682277\n",
      "Epoch: 66, Loss (standarized): 0.33937715750492575\n",
      "          Validation Loss (standardized): 1.3320403936515566\n",
      "Epoch: 71, Loss (standarized): 0.2979852131673276\n",
      "          Validation Loss (standardized): 1.256442860485206\n",
      "Epoch: 76, Loss (standarized): 0.2597951030569358\n",
      "          Validation Loss (standardized): 1.179248251331518\n",
      "Epoch: 81, Loss (standarized): 0.22727042241445697\n",
      "          Validation Loss (standardized): 1.1203995734907781\n",
      "Epoch: 86, Loss (standarized): 0.20320460449920574\n",
      "          Validation Loss (standardized): 1.061176779652014\n",
      "Epoch: 91, Loss (standarized): 0.18456605059209008\n",
      "          Validation Loss (standardized): 1.034575323236125\n",
      "Epoch: 96, Loss (standarized): 0.16983699882889614\n",
      "          Validation Loss (standardized): 0.9556196627552838\n",
      "Final epoch: 100, Final loss (standarized): 0.16021807045424008\n",
      "Epoch: 1, Loss (standarized): 1.387713915939969\n",
      "          Validation Loss (standardized): 1.520866411675833\n",
      "Epoch: 6, Loss (standarized): 0.7189963056160509\n",
      "          Validation Loss (standardized): 1.7122921324494065\n",
      "Epoch: 11, Loss (standarized): 0.696314428396736\n",
      "          Validation Loss (standardized): 2.1364376938755063\n",
      "Epoch: 16, Loss (standarized): 0.6562736611735913\n",
      "          Validation Loss (standardized): 2.075079611122853\n",
      "Epoch: 21, Loss (standarized): 0.6239819367180666\n",
      "          Validation Loss (standardized): 1.8757145075357888\n",
      "Epoch: 26, Loss (standarized): 0.6118559246705663\n",
      "          Validation Loss (standardized): 1.7075124867083933\n",
      "Epoch: 31, Loss (standarized): 0.5945976058528807\n",
      "          Validation Loss (standardized): 1.6602837119611222\n",
      "Epoch: 36, Loss (standarized): 0.5783455757538563\n",
      "          Validation Loss (standardized): 1.6875975444095666\n",
      "Epoch: 41, Loss (standarized): 0.560554428876028\n",
      "          Validation Loss (standardized): 1.6975229700241836\n",
      "Epoch: 46, Loss (standarized): 0.5385847972489413\n",
      "          Validation Loss (standardized): 1.668412566118361\n",
      "Epoch: 51, Loss (standarized): 0.5165985187186141\n",
      "          Validation Loss (standardized): 1.6287927692372177\n",
      "Epoch: 56, Loss (standarized): 0.49168893757756554\n",
      "          Validation Loss (standardized): 1.5953000882609412\n",
      "Epoch: 61, Loss (standarized): 0.46398477757728684\n",
      "          Validation Loss (standardized): 1.5546240809071024\n",
      "Epoch: 66, Loss (standarized): 0.4357480222375921\n",
      "          Validation Loss (standardized): 1.5115682415869405\n",
      "Epoch: 71, Loss (standarized): 0.40763714877587415\n",
      "          Validation Loss (standardized): 1.4704323467360736\n",
      "Epoch: 76, Loss (standarized): 0.38015801598513194\n",
      "          Validation Loss (standardized): 1.4400019017394408\n",
      "Epoch: 81, Loss (standarized): 0.3547745305208412\n",
      "          Validation Loss (standardized): 1.4118586082323608\n",
      "Epoch: 86, Loss (standarized): 0.33194523142293236\n",
      "          Validation Loss (standardized): 1.3751193155716324\n",
      "Epoch: 91, Loss (standarized): 0.3120090064337762\n",
      "          Validation Loss (standardized): 1.3244928112758538\n",
      "Epoch: 96, Loss (standarized): 0.29530525047489287\n",
      "          Validation Loss (standardized): 1.2796438676183266\n",
      "Final epoch: 100, Final loss (standarized): 0.2840138746043016\n",
      "Epoch: 1, Loss (standarized): 2.3114575527524415\n",
      "          Validation Loss (standardized): 1.4103042922132305\n",
      "Epoch: 6, Loss (standarized): 0.8114836305902298\n",
      "          Validation Loss (standardized): 1.6421382199002026\n",
      "Epoch: 11, Loss (standarized): 0.6998399143011563\n",
      "          Validation Loss (standardized): 2.3161362359378894\n",
      "Epoch: 16, Loss (standarized): 0.6907437008561811\n",
      "          Validation Loss (standardized): 2.6837729076696304\n",
      "Epoch: 21, Loss (standarized): 0.6703175734916482\n",
      "          Validation Loss (standardized): 2.6802666917192566\n",
      "Epoch: 26, Loss (standarized): 0.6431596657063797\n",
      "          Validation Loss (standardized): 2.483594236426618\n",
      "Epoch: 31, Loss (standarized): 0.6185834870972309\n",
      "          Validation Loss (standardized): 2.2349211947094307\n",
      "Epoch: 36, Loss (standarized): 0.5943858668450254\n",
      "          Validation Loss (standardized): 1.9961425560387114\n",
      "Epoch: 41, Loss (standarized): 0.5760523881060443\n",
      "          Validation Loss (standardized): 1.8083102151621018\n",
      "Epoch: 46, Loss (standarized): 0.5585114814498363\n",
      "          Validation Loss (standardized): 1.6914384828376972\n",
      "Epoch: 51, Loss (standarized): 0.5390156153109579\n",
      "          Validation Loss (standardized): 1.6388790025000786\n",
      "Epoch: 56, Loss (standarized): 0.5177673246628381\n",
      "          Validation Loss (standardized): 1.596401993432088\n",
      "Epoch: 61, Loss (standarized): 0.4933999700267277\n",
      "          Validation Loss (standardized): 1.5709533722669224\n",
      "Epoch: 66, Loss (standarized): 0.4660282371784408\n",
      "          Validation Loss (standardized): 1.5494070297813591\n",
      "Epoch: 71, Loss (standarized): 0.43473132658258123\n",
      "          Validation Loss (standardized): 1.5210862847367674\n",
      "Epoch: 76, Loss (standarized): 0.4010476184324032\n",
      "          Validation Loss (standardized): 1.4809762368229613\n",
      "Epoch: 81, Loss (standarized): 0.3643835502123726\n",
      "          Validation Loss (standardized): 1.4577799850192052\n",
      "Epoch: 86, Loss (standarized): 0.3315137047778188\n",
      "          Validation Loss (standardized): 1.3980347713178032\n",
      "Epoch: 91, Loss (standarized): 0.3024502272750712\n",
      "          Validation Loss (standardized): 1.3555659599616585\n",
      "Epoch: 96, Loss (standarized): 0.2780082083251888\n",
      "          Validation Loss (standardized): 1.2956263304089344\n",
      "Final epoch: 100, Final loss (standarized): 0.2615991455008019\n",
      "Epoch: 1, Loss (standarized): 2.3060321319361914\n",
      "          Validation Loss (standardized): 2.027137577483822\n",
      "Epoch: 6, Loss (standarized): 0.9465425416026751\n",
      "          Validation Loss (standardized): 1.671654991086392\n",
      "Epoch: 11, Loss (standarized): 0.6957307115879934\n",
      "          Validation Loss (standardized): 2.285515451593796\n",
      "Epoch: 16, Loss (standarized): 0.708485027158875\n",
      "          Validation Loss (standardized): 2.6344755171280996\n",
      "Epoch: 21, Loss (standarized): 0.6792007274506526\n",
      "          Validation Loss (standardized): 2.5212910310383134\n",
      "Epoch: 26, Loss (standarized): 0.6255711500585558\n",
      "          Validation Loss (standardized): 2.210582954547142\n",
      "Epoch: 31, Loss (standarized): 0.5991065816242964\n",
      "          Validation Loss (standardized): 1.8805041266737428\n",
      "Epoch: 36, Loss (standarized): 0.5811746970796949\n",
      "          Validation Loss (standardized): 1.660115156476786\n",
      "Epoch: 41, Loss (standarized): 0.5550578740652291\n",
      "          Validation Loss (standardized): 1.6233642295354906\n",
      "Epoch: 46, Loss (standarized): 0.5290444273178414\n",
      "          Validation Loss (standardized): 1.6737217532640114\n",
      "Epoch: 51, Loss (standarized): 0.5046002070167377\n",
      "          Validation Loss (standardized): 1.6862296964451684\n",
      "Epoch: 56, Loss (standarized): 0.479098870127121\n",
      "          Validation Loss (standardized): 1.6351747323471844\n",
      "Epoch: 61, Loss (standarized): 0.45403791856825026\n",
      "          Validation Loss (standardized): 1.5502957784875073\n",
      "Epoch: 66, Loss (standarized): 0.4277275739589615\n",
      "          Validation Loss (standardized): 1.4796700745858011\n",
      "Epoch: 71, Loss (standarized): 0.40006498883926583\n",
      "          Validation Loss (standardized): 1.4480767944591575\n",
      "Epoch: 76, Loss (standarized): 0.37278125667663226\n",
      "          Validation Loss (standardized): 1.4303153371072037\n",
      "Epoch: 81, Loss (standarized): 0.3448142220682818\n",
      "          Validation Loss (standardized): 1.3962945165273604\n",
      "Epoch: 86, Loss (standarized): 0.31731530631742266\n",
      "          Validation Loss (standardized): 1.343175273582173\n",
      "Epoch: 91, Loss (standarized): 0.2910358263644296\n",
      "          Validation Loss (standardized): 1.2986754001074448\n",
      "Epoch: 96, Loss (standarized): 0.26691092149617485\n",
      "          Validation Loss (standardized): 1.2709378733847403\n",
      "Final epoch: 100, Final loss (standarized): 0.24982329615381527\n",
      "Epoch: 1, Loss (standarized): 1.1186753774730038\n",
      "          Validation Loss (standardized): 1.661833717088038\n",
      "Epoch: 6, Loss (standarized): 0.7342990745998048\n",
      "          Validation Loss (standardized): 2.0578407777734578\n",
      "Epoch: 11, Loss (standarized): 0.6859845421317698\n",
      "          Validation Loss (standardized): 2.1231089078075867\n",
      "Epoch: 16, Loss (standarized): 0.6570140082481223\n",
      "          Validation Loss (standardized): 1.9007310592440358\n",
      "Epoch: 21, Loss (standarized): 0.636747046415114\n",
      "          Validation Loss (standardized): 1.7298202480171063\n",
      "Epoch: 26, Loss (standarized): 0.611243115514345\n",
      "          Validation Loss (standardized): 1.8139426131388177\n",
      "Epoch: 31, Loss (standarized): 0.5857158286563541\n",
      "          Validation Loss (standardized): 1.8448759234616696\n",
      "Epoch: 36, Loss (standarized): 0.5590103866733886\n",
      "          Validation Loss (standardized): 1.6825078023029894\n",
      "Epoch: 41, Loss (standarized): 0.5314757007629707\n",
      "          Validation Loss (standardized): 1.56938098642079\n",
      "Epoch: 46, Loss (standarized): 0.5011780835417907\n",
      "          Validation Loss (standardized): 1.60689873236123\n",
      "Epoch: 51, Loss (standarized): 0.4686634911334144\n",
      "          Validation Loss (standardized): 1.5987314074248233\n",
      "Epoch: 56, Loss (standarized): 0.43208513899522066\n",
      "          Validation Loss (standardized): 1.5183770607858014\n",
      "Epoch: 61, Loss (standarized): 0.3930293265227437\n",
      "          Validation Loss (standardized): 1.4761999703296451\n",
      "Epoch: 66, Loss (standarized): 0.3527587922028461\n",
      "          Validation Loss (standardized): 1.4417468025083986\n",
      "Epoch: 71, Loss (standarized): 0.30913205134717286\n",
      "          Validation Loss (standardized): 1.3683330604169277\n",
      "Epoch: 76, Loss (standarized): 0.2735048025206554\n",
      "          Validation Loss (standardized): 1.28975168112179\n",
      "Epoch: 81, Loss (standarized): 0.24428405998857633\n",
      "          Validation Loss (standardized): 1.268776273158878\n",
      "Epoch: 86, Loss (standarized): 0.2196938383548483\n",
      "          Validation Loss (standardized): 1.1908288202550235\n",
      "Epoch: 91, Loss (standarized): 0.19884268517036457\n",
      "          Validation Loss (standardized): 1.115240228977224\n",
      "Epoch: 96, Loss (standarized): 0.18215839140470377\n",
      "          Validation Loss (standardized): 1.045845264929327\n",
      "Final epoch: 100, Final loss (standarized): 0.1702662119169127\n",
      "Epoch: 1, Loss (standarized): 1.2381148252004228\n",
      "          Validation Loss (standardized): 1.2190730552425488\n",
      "Epoch: 6, Loss (standarized): 0.77285166594272\n",
      "          Validation Loss (standardized): 1.5377286568707094\n",
      "Epoch: 11, Loss (standarized): 0.6667499511266731\n",
      "          Validation Loss (standardized): 1.943525043185207\n",
      "Epoch: 16, Loss (standarized): 0.635159939205234\n",
      "          Validation Loss (standardized): 2.0755757927292082\n",
      "Epoch: 21, Loss (standarized): 0.5996611301515887\n",
      "          Validation Loss (standardized): 1.926258431551331\n",
      "Epoch: 26, Loss (standarized): 0.5699275920177368\n",
      "          Validation Loss (standardized): 1.7101946297874766\n",
      "Epoch: 31, Loss (standarized): 0.538486736013218\n",
      "          Validation Loss (standardized): 1.5585684559684168\n",
      "Epoch: 36, Loss (standarized): 0.5050602680559841\n",
      "          Validation Loss (standardized): 1.5081496274383617\n",
      "Epoch: 41, Loss (standarized): 0.47240036735030727\n",
      "          Validation Loss (standardized): 1.5020742165920924\n",
      "Epoch: 46, Loss (standarized): 0.4378162328520983\n",
      "          Validation Loss (standardized): 1.4891686813131313\n",
      "Epoch: 51, Loss (standarized): 0.402153275137456\n",
      "          Validation Loss (standardized): 1.4667630153188542\n",
      "Epoch: 56, Loss (standarized): 0.36852808207661614\n",
      "          Validation Loss (standardized): 1.4338975589116916\n",
      "Epoch: 61, Loss (standarized): 0.33760096894415975\n",
      "          Validation Loss (standardized): 1.4038477244599128\n",
      "Epoch: 66, Loss (standarized): 0.3111070999266482\n",
      "          Validation Loss (standardized): 1.3705601019443416\n",
      "Epoch: 71, Loss (standarized): 0.2896121371096455\n",
      "          Validation Loss (standardized): 1.335016549246379\n",
      "Epoch: 76, Loss (standarized): 0.27240587187529897\n",
      "          Validation Loss (standardized): 1.302444273567973\n",
      "Epoch: 81, Loss (standarized): 0.25897196364444347\n",
      "          Validation Loss (standardized): 1.2739771875449648\n",
      "Epoch: 86, Loss (standarized): 0.24909146119812248\n",
      "          Validation Loss (standardized): 1.2507506741382863\n",
      "Epoch: 91, Loss (standarized): 0.24208422852345876\n",
      "          Validation Loss (standardized): 1.235846568366974\n",
      "Epoch: 96, Loss (standarized): 0.237016974017305\n",
      "          Validation Loss (standardized): 1.2259995797598007\n",
      "Final epoch: 100, Final loss (standarized): 0.23408616708225907\n",
      "Epoch: 1, Loss (standarized): 2.184495781796677\n",
      "          Validation Loss (standardized): 1.1868063320651654\n",
      "Epoch: 6, Loss (standarized): 0.8910415508883297\n",
      "          Validation Loss (standardized): 1.34792001233398\n",
      "Epoch: 11, Loss (standarized): 0.6823737132430838\n",
      "          Validation Loss (standardized): 1.8931962717096198\n",
      "Epoch: 16, Loss (standarized): 0.6528853689797001\n",
      "          Validation Loss (standardized): 2.2473734796992453\n",
      "Epoch: 21, Loss (standarized): 0.6444955468447023\n",
      "          Validation Loss (standardized): 2.3753387966368726\n",
      "Epoch: 26, Loss (standarized): 0.627723848194317\n",
      "          Validation Loss (standardized): 2.3237470823117063\n",
      "Epoch: 31, Loss (standarized): 0.6039062658343871\n",
      "          Validation Loss (standardized): 2.1914352659801923\n",
      "Epoch: 36, Loss (standarized): 0.5795934679597396\n",
      "          Validation Loss (standardized): 2.056386301292053\n",
      "Epoch: 41, Loss (standarized): 0.5524061269536399\n",
      "          Validation Loss (standardized): 1.9433174502932276\n",
      "Epoch: 46, Loss (standarized): 0.5222454356702848\n",
      "          Validation Loss (standardized): 1.854477076136901\n",
      "Epoch: 51, Loss (standarized): 0.48941031056002626\n",
      "          Validation Loss (standardized): 1.7895631369177458\n",
      "Epoch: 56, Loss (standarized): 0.45570631028836023\n",
      "          Validation Loss (standardized): 1.7511097536535272\n",
      "Epoch: 61, Loss (standarized): 0.42014968977726175\n",
      "          Validation Loss (standardized): 1.7236962881467648\n",
      "Epoch: 66, Loss (standarized): 0.38522948155610015\n",
      "          Validation Loss (standardized): 1.7077747063934126\n",
      "Epoch: 71, Loss (standarized): 0.35295140147447734\n",
      "          Validation Loss (standardized): 1.6905935251163486\n",
      "Epoch: 76, Loss (standarized): 0.32433017645173273\n",
      "          Validation Loss (standardized): 1.669447366089204\n",
      "Epoch: 81, Loss (standarized): 0.29926386617411693\n",
      "          Validation Loss (standardized): 1.6285815100453869\n",
      "Epoch: 86, Loss (standarized): 0.2776727671186793\n",
      "          Validation Loss (standardized): 1.5627016839248258\n",
      "Epoch: 91, Loss (standarized): 0.2595213120052604\n",
      "          Validation Loss (standardized): 1.4894291497959167\n",
      "Epoch: 96, Loss (standarized): 0.2444090736323327\n",
      "          Validation Loss (standardized): 1.422989252201258\n",
      "Final epoch: 100, Final loss (standarized): 0.23398171042776397\n",
      "Epoch: 1, Loss (standarized): 2.04920599485431\n",
      "          Validation Loss (standardized): 2.03377453657153\n",
      "Epoch: 6, Loss (standarized): 0.9790247885396787\n",
      "          Validation Loss (standardized): 1.834307207600934\n",
      "Epoch: 11, Loss (standarized): 0.727786463236325\n",
      "          Validation Loss (standardized): 2.1151689601083388\n",
      "Epoch: 16, Loss (standarized): 0.6874274126774793\n",
      "          Validation Loss (standardized): 2.087418036202502\n",
      "Epoch: 21, Loss (standarized): 0.6298931521315565\n",
      "          Validation Loss (standardized): 1.8885013257694183\n",
      "Epoch: 26, Loss (standarized): 0.5928793454688251\n",
      "          Validation Loss (standardized): 1.7768809755847093\n",
      "Epoch: 31, Loss (standarized): 0.567399969387315\n",
      "          Validation Loss (standardized): 1.7842085943212183\n",
      "Epoch: 36, Loss (standarized): 0.5421829978628764\n",
      "          Validation Loss (standardized): 1.7673738771281107\n",
      "Epoch: 41, Loss (standarized): 0.5177164665877441\n",
      "          Validation Loss (standardized): 1.6808758560932042\n",
      "Epoch: 46, Loss (standarized): 0.49117687503757945\n",
      "          Validation Loss (standardized): 1.571395723530346\n",
      "Epoch: 51, Loss (standarized): 0.4615241987419703\n",
      "          Validation Loss (standardized): 1.5188986776189002\n",
      "Epoch: 56, Loss (standarized): 0.430456776973537\n",
      "          Validation Loss (standardized): 1.5185169011081614\n",
      "Epoch: 61, Loss (standarized): 0.396913027036515\n",
      "          Validation Loss (standardized): 1.4896730732870924\n",
      "Epoch: 66, Loss (standarized): 0.36113077588380604\n",
      "          Validation Loss (standardized): 1.399153278965874\n",
      "Epoch: 71, Loss (standarized): 0.3264686352819192\n",
      "          Validation Loss (standardized): 1.318389176450382\n",
      "Epoch: 76, Loss (standarized): 0.2924190160416815\n",
      "          Validation Loss (standardized): 1.2764668859856652\n",
      "Epoch: 81, Loss (standarized): 0.26139633392869904\n",
      "          Validation Loss (standardized): 1.2213851504666524\n",
      "Epoch: 86, Loss (standarized): 0.23380348696830947\n",
      "          Validation Loss (standardized): 1.1533077930671116\n",
      "Epoch: 91, Loss (standarized): 0.20984280025801488\n",
      "          Validation Loss (standardized): 1.0877914653549567\n",
      "Epoch: 96, Loss (standarized): 0.18998011985598676\n",
      "          Validation Loss (standardized): 1.024786940872893\n",
      "Final epoch: 100, Final loss (standarized): 0.17553248421791168\n",
      "Epoch: 1, Loss (standarized): 2.645806206187071\n",
      "          Validation Loss (standardized): 1.777315350363578\n",
      "Epoch: 6, Loss (standarized): 0.9967588795795224\n",
      "          Validation Loss (standardized): 1.6837678123147282\n",
      "Epoch: 11, Loss (standarized): 0.7307322662152907\n",
      "          Validation Loss (standardized): 2.252091819085826\n",
      "Epoch: 16, Loss (standarized): 0.7169759243894459\n",
      "          Validation Loss (standardized): 2.4457750477948554\n",
      "Epoch: 21, Loss (standarized): 0.6916799922948874\n",
      "          Validation Loss (standardized): 2.398569114770383\n",
      "Epoch: 26, Loss (standarized): 0.6517804787833483\n",
      "          Validation Loss (standardized): 2.2017501301428393\n",
      "Epoch: 31, Loss (standarized): 0.6118560700914153\n",
      "          Validation Loss (standardized): 1.9631104850012058\n",
      "Epoch: 36, Loss (standarized): 0.5956003280578922\n",
      "          Validation Loss (standardized): 1.7800982717038383\n",
      "Epoch: 41, Loss (standarized): 0.5758854861185555\n",
      "          Validation Loss (standardized): 1.6571414757232694\n",
      "Epoch: 46, Loss (standarized): 0.5521723230583653\n",
      "          Validation Loss (standardized): 1.589052633432758\n",
      "Epoch: 51, Loss (standarized): 0.5293251206793945\n",
      "          Validation Loss (standardized): 1.5592337195995092\n",
      "Epoch: 56, Loss (standarized): 0.5042032128028658\n",
      "          Validation Loss (standardized): 1.5540863023905995\n",
      "Epoch: 61, Loss (standarized): 0.4772429624140979\n",
      "          Validation Loss (standardized): 1.559322847665735\n",
      "Epoch: 66, Loss (standarized): 0.44873413126590833\n",
      "          Validation Loss (standardized): 1.5488400593980702\n",
      "Epoch: 71, Loss (standarized): 0.4187192137657067\n",
      "          Validation Loss (standardized): 1.5123671341060771\n",
      "Epoch: 76, Loss (standarized): 0.3898381499062404\n",
      "          Validation Loss (standardized): 1.461607349458524\n",
      "Epoch: 81, Loss (standarized): 0.36319759974068894\n",
      "          Validation Loss (standardized): 1.416916918689994\n",
      "Epoch: 86, Loss (standarized): 0.3385338906122127\n",
      "          Validation Loss (standardized): 1.3879740573358625\n",
      "Epoch: 91, Loss (standarized): 0.3162123113547654\n",
      "          Validation Loss (standardized): 1.367039672495434\n",
      "Epoch: 96, Loss (standarized): 0.29613314074110436\n",
      "          Validation Loss (standardized): 1.34187110020031\n",
      "Final epoch: 100, Final loss (standarized): 0.2815572449998942\n",
      "Epoch: 1, Loss (standarized): 2.136867576271984\n",
      "          Validation Loss (standardized): 1.340830302438649\n",
      "Epoch: 6, Loss (standarized): 0.8876196952570913\n",
      "          Validation Loss (standardized): 1.3304945864140336\n",
      "Epoch: 11, Loss (standarized): 0.7250643012316671\n",
      "          Validation Loss (standardized): 1.8205043095769304\n",
      "Epoch: 16, Loss (standarized): 0.6809316720408042\n",
      "          Validation Loss (standardized): 2.100273652864725\n",
      "Epoch: 21, Loss (standarized): 0.6668665984118635\n",
      "          Validation Loss (standardized): 2.1811556986433933\n",
      "Epoch: 26, Loss (standarized): 0.6406808963893454\n",
      "          Validation Loss (standardized): 2.0909789177195686\n",
      "Epoch: 31, Loss (standarized): 0.6193323021150073\n",
      "          Validation Loss (standardized): 1.9367212296163359\n",
      "Epoch: 36, Loss (standarized): 0.6036438425976491\n",
      "          Validation Loss (standardized): 1.7893482338207252\n",
      "Epoch: 41, Loss (standarized): 0.5923968581776013\n",
      "          Validation Loss (standardized): 1.6865505766177078\n",
      "Epoch: 46, Loss (standarized): 0.5789968464336204\n",
      "          Validation Loss (standardized): 1.6297703406816513\n",
      "Epoch: 51, Loss (standarized): 0.564462321787081\n",
      "          Validation Loss (standardized): 1.608154119128772\n",
      "Epoch: 56, Loss (standarized): 0.547783016414713\n",
      "          Validation Loss (standardized): 1.6035089732166683\n",
      "Epoch: 61, Loss (standarized): 0.5306250079491179\n",
      "          Validation Loss (standardized): 1.601261431056386\n",
      "Epoch: 66, Loss (standarized): 0.5130635312888051\n",
      "          Validation Loss (standardized): 1.5968798531414596\n",
      "Epoch: 71, Loss (standarized): 0.49511079650629103\n",
      "          Validation Loss (standardized): 1.582708665527154\n",
      "Epoch: 76, Loss (standarized): 0.4767102476596113\n",
      "          Validation Loss (standardized): 1.5594474922573973\n",
      "Epoch: 81, Loss (standarized): 0.4578235958496009\n",
      "          Validation Loss (standardized): 1.5351372302522555\n",
      "Epoch: 86, Loss (standarized): 0.4393279875430227\n",
      "          Validation Loss (standardized): 1.511476858554824\n",
      "Epoch: 91, Loss (standarized): 0.42121210877153914\n",
      "          Validation Loss (standardized): 1.4882802075631003\n",
      "Epoch: 96, Loss (standarized): 0.40344686906591476\n",
      "          Validation Loss (standardized): 1.466430607329436\n",
      "Final epoch: 100, Final loss (standarized): 0.38926090982077666\n",
      "Epoch: 1, Loss (standarized): 1.566327396960173\n",
      "          Validation Loss (standardized): 1.14079972585482\n",
      "Epoch: 6, Loss (standarized): 0.7324566082896605\n",
      "          Validation Loss (standardized): 2.07799018053632\n",
      "Epoch: 11, Loss (standarized): 0.6891713656619333\n",
      "          Validation Loss (standardized): 2.6561544831678074\n",
      "Epoch: 16, Loss (standarized): 0.6740151208565204\n",
      "          Validation Loss (standardized): 2.720398217745009\n",
      "Epoch: 21, Loss (standarized): 0.6310160088918768\n",
      "          Validation Loss (standardized): 2.4799766726441255\n",
      "Epoch: 26, Loss (standarized): 0.5820469105741112\n",
      "          Validation Loss (standardized): 2.1032523542660084\n",
      "Epoch: 31, Loss (standarized): 0.5341835830063271\n",
      "          Validation Loss (standardized): 1.7560060412833127\n",
      "Epoch: 36, Loss (standarized): 0.490729687675089\n",
      "          Validation Loss (standardized): 1.5424728018433895\n",
      "Epoch: 41, Loss (standarized): 0.44386803813563325\n",
      "          Validation Loss (standardized): 1.478973875769015\n",
      "Epoch: 46, Loss (standarized): 0.39693605849705393\n",
      "          Validation Loss (standardized): 1.4994014861203482\n",
      "Epoch: 51, Loss (standarized): 0.35483532469608614\n",
      "          Validation Loss (standardized): 1.512450061325239\n",
      "Epoch: 56, Loss (standarized): 0.3170611591036487\n",
      "          Validation Loss (standardized): 1.4657042290296671\n",
      "Epoch: 61, Loss (standarized): 0.28301667140286774\n",
      "          Validation Loss (standardized): 1.3649059397592729\n",
      "Epoch: 66, Loss (standarized): 0.25542383844059796\n",
      "          Validation Loss (standardized): 1.2847916427769577\n",
      "Epoch: 71, Loss (standarized): 0.2324068616407094\n",
      "          Validation Loss (standardized): 1.2496253139086093\n",
      "Epoch: 76, Loss (standarized): 0.2134785400790756\n",
      "          Validation Loss (standardized): 1.2258204045736794\n",
      "Epoch: 81, Loss (standarized): 0.19801798961473305\n",
      "          Validation Loss (standardized): 1.178601583160449\n",
      "Epoch: 86, Loss (standarized): 0.1851770688888585\n",
      "          Validation Loss (standardized): 1.117888927748004\n",
      "Epoch: 91, Loss (standarized): 0.17451649293866203\n",
      "          Validation Loss (standardized): 1.0737344823788046\n",
      "Epoch: 96, Loss (standarized): 0.1654966305036124\n",
      "          Validation Loss (standardized): 1.048920462151835\n",
      "Final epoch: 100, Final loss (standarized): 0.1591362410900653\n",
      "Epoch: 1, Loss (standarized): 1.131420351762248\n",
      "          Validation Loss (standardized): 1.2254211263121044\n",
      "Epoch: 6, Loss (standarized): 0.7479569353312989\n",
      "          Validation Loss (standardized): 1.5149971409201453\n",
      "Epoch: 11, Loss (standarized): 0.6908194348549931\n",
      "          Validation Loss (standardized): 1.9915809480962698\n",
      "Epoch: 16, Loss (standarized): 0.6695196976367929\n",
      "          Validation Loss (standardized): 2.1139068325783077\n",
      "Epoch: 21, Loss (standarized): 0.6365140389832914\n",
      "          Validation Loss (standardized): 2.000951909921888\n",
      "Epoch: 26, Loss (standarized): 0.6146783812552754\n",
      "          Validation Loss (standardized): 1.8664509484174783\n",
      "Epoch: 31, Loss (standarized): 0.5909812855839969\n",
      "          Validation Loss (standardized): 1.7808130004612612\n",
      "Epoch: 36, Loss (standarized): 0.5598906749099832\n",
      "          Validation Loss (standardized): 1.7475552412294877\n",
      "Epoch: 41, Loss (standarized): 0.5250856450641362\n",
      "          Validation Loss (standardized): 1.7415549882608181\n",
      "Epoch: 46, Loss (standarized): 0.4868895736182611\n",
      "          Validation Loss (standardized): 1.7234882037937524\n",
      "Epoch: 51, Loss (standarized): 0.44401847064486955\n",
      "          Validation Loss (standardized): 1.6890668703422238\n",
      "Epoch: 56, Loss (standarized): 0.39808294561308727\n",
      "          Validation Loss (standardized): 1.633508311169798\n",
      "Epoch: 61, Loss (standarized): 0.35357421434853864\n",
      "          Validation Loss (standardized): 1.5533192484627625\n",
      "Epoch: 66, Loss (standarized): 0.31002505082498355\n",
      "          Validation Loss (standardized): 1.4278222799638585\n",
      "Epoch: 71, Loss (standarized): 0.2707375350514444\n",
      "          Validation Loss (standardized): 1.3287230509840138\n",
      "Epoch: 76, Loss (standarized): 0.2373164049890953\n",
      "          Validation Loss (standardized): 1.35199683687559\n",
      "Epoch: 81, Loss (standarized): 0.2090297703863427\n",
      "          Validation Loss (standardized): 1.2670752105717071\n",
      "Epoch: 86, Loss (standarized): 0.18353442441289813\n",
      "          Validation Loss (standardized): 1.1412081469201427\n",
      "Epoch: 91, Loss (standarized): 0.16526502096978718\n",
      "          Validation Loss (standardized): 1.0436815259808803\n",
      "Epoch: 96, Loss (standarized): 0.15103086917016217\n",
      "          Validation Loss (standardized): 0.9579346495997814\n",
      "Final epoch: 100, Final loss (standarized): 0.1407506039623339\n",
      "Epoch: 1, Loss (standarized): 1.4481936576289411\n",
      "          Validation Loss (standardized): 1.41368684089602\n",
      "Epoch: 6, Loss (standarized): 0.7421765938637614\n",
      "          Validation Loss (standardized): 1.5388674122272585\n",
      "Epoch: 11, Loss (standarized): 0.6956448966011877\n",
      "          Validation Loss (standardized): 1.8840067885487202\n",
      "Epoch: 16, Loss (standarized): 0.6629130333496623\n",
      "          Validation Loss (standardized): 1.9780302209364118\n",
      "Epoch: 21, Loss (standarized): 0.6257401379096313\n",
      "          Validation Loss (standardized): 1.9184747828744075\n",
      "Epoch: 26, Loss (standarized): 0.6108866718176343\n",
      "          Validation Loss (standardized): 1.8155834780353004\n",
      "Epoch: 31, Loss (standarized): 0.5985006436126309\n",
      "          Validation Loss (standardized): 1.706996927853821\n",
      "Epoch: 36, Loss (standarized): 0.5834525272930693\n",
      "          Validation Loss (standardized): 1.619363068268393\n",
      "Epoch: 41, Loss (standarized): 0.5681429993290243\n",
      "          Validation Loss (standardized): 1.574242619536313\n",
      "Epoch: 46, Loss (standarized): 0.5537670847928432\n",
      "          Validation Loss (standardized): 1.5659476961664425\n",
      "Epoch: 51, Loss (standarized): 0.5381082401530835\n",
      "          Validation Loss (standardized): 1.5739452313141828\n",
      "Epoch: 56, Loss (standarized): 0.523808223914032\n",
      "          Validation Loss (standardized): 1.5859868160186334\n",
      "Epoch: 61, Loss (standarized): 0.5114431669606879\n",
      "          Validation Loss (standardized): 1.6012872289651368\n",
      "Epoch: 66, Loss (standarized): 0.4996271890282669\n",
      "          Validation Loss (standardized): 1.606796367850845\n",
      "Epoch: 71, Loss (standarized): 0.4881394791560449\n",
      "          Validation Loss (standardized): 1.598215797193746\n",
      "Epoch: 76, Loss (standarized): 0.47755580418512794\n",
      "          Validation Loss (standardized): 1.5791726886219732\n",
      "Epoch: 81, Loss (standarized): 0.4677814458316688\n",
      "          Validation Loss (standardized): 1.5509859242417878\n",
      "Epoch: 86, Loss (standarized): 0.4584243809742704\n",
      "          Validation Loss (standardized): 1.5445066947071564\n",
      "Epoch: 91, Loss (standarized): 0.4495673927198399\n",
      "          Validation Loss (standardized): 1.5472085985488129\n",
      "Epoch: 96, Loss (standarized): 0.4408036062684856\n",
      "          Validation Loss (standardized): 1.5460671435083815\n",
      "Final epoch: 100, Final loss (standarized): 0.4338134799800398\n",
      "Epoch: 1, Loss (standarized): 0.8013387261566111\n",
      "          Validation Loss (standardized): 1.6026541568726824\n",
      "Epoch: 6, Loss (standarized): 0.6899812169028454\n",
      "          Validation Loss (standardized): 1.8232661585481194\n",
      "Epoch: 11, Loss (standarized): 0.6564857204841712\n",
      "          Validation Loss (standardized): 1.7584555585630532\n",
      "Epoch: 16, Loss (standarized): 0.64325129464822\n",
      "          Validation Loss (standardized): 1.647806905528481\n",
      "Epoch: 21, Loss (standarized): 0.6310192416100473\n",
      "          Validation Loss (standardized): 1.5700561396205739\n",
      "Epoch: 26, Loss (standarized): 0.621239971216269\n",
      "          Validation Loss (standardized): 1.5399582222886998\n",
      "Epoch: 31, Loss (standarized): 0.6143830330428918\n",
      "          Validation Loss (standardized): 1.529235466581421\n",
      "Epoch: 36, Loss (standarized): 0.608520570753693\n",
      "          Validation Loss (standardized): 1.5439766923254248\n",
      "Epoch: 41, Loss (standarized): 0.6015657124653859\n",
      "          Validation Loss (standardized): 1.5646099061832561\n",
      "Epoch: 46, Loss (standarized): 0.5944989490043971\n",
      "          Validation Loss (standardized): 1.5677198918718058\n",
      "Epoch: 51, Loss (standarized): 0.5875331848680203\n",
      "          Validation Loss (standardized): 1.5533710481646268\n",
      "Epoch: 56, Loss (standarized): 0.5791685161520422\n",
      "          Validation Loss (standardized): 1.5472623827460166\n",
      "Epoch: 61, Loss (standarized): 0.5711351343333085\n",
      "          Validation Loss (standardized): 1.5413742115499027\n",
      "Epoch: 66, Loss (standarized): 0.563560743311106\n",
      "          Validation Loss (standardized): 1.5408933441942352\n",
      "Epoch: 71, Loss (standarized): 0.5562865472514278\n",
      "          Validation Loss (standardized): 1.5497834803365602\n",
      "Epoch: 76, Loss (standarized): 0.5500782290070896\n",
      "          Validation Loss (standardized): 1.5494351374615853\n",
      "Epoch: 81, Loss (standarized): 0.5448901328870784\n",
      "          Validation Loss (standardized): 1.545063766311425\n",
      "Epoch: 86, Loss (standarized): 0.5402106689170947\n",
      "          Validation Loss (standardized): 1.5459115505514747\n",
      "Epoch: 91, Loss (standarized): 0.5360985729691966\n",
      "          Validation Loss (standardized): 1.5426692780228237\n",
      "Epoch: 96, Loss (standarized): 0.53224837340586\n",
      "          Validation Loss (standardized): 1.5547377658663626\n",
      "Final epoch: 100, Final loss (standarized): 0.5296516254008744\n",
      "Epoch: 1, Loss (standarized): 2.112207564118754\n",
      "          Validation Loss (standardized): 1.1033785954963555\n",
      "Epoch: 6, Loss (standarized): 0.8789951986048015\n",
      "          Validation Loss (standardized): 1.4123103827357348\n",
      "Epoch: 11, Loss (standarized): 0.7777125912896126\n",
      "          Validation Loss (standardized): 2.0692141501085497\n",
      "Epoch: 16, Loss (standarized): 0.7325897069265461\n",
      "          Validation Loss (standardized): 2.368740746875631\n",
      "Epoch: 21, Loss (standarized): 0.7142248001064039\n",
      "          Validation Loss (standardized): 2.43217473980315\n",
      "Epoch: 26, Loss (standarized): 0.6933742507470742\n",
      "          Validation Loss (standardized): 2.333286877192434\n",
      "Epoch: 31, Loss (standarized): 0.6789843378690131\n",
      "          Validation Loss (standardized): 2.1557507113046546\n",
      "Epoch: 36, Loss (standarized): 0.6649154830105627\n",
      "          Validation Loss (standardized): 1.9699149698966634\n",
      "Epoch: 41, Loss (standarized): 0.6570423404248759\n",
      "          Validation Loss (standardized): 1.8134610609677275\n",
      "Epoch: 46, Loss (standarized): 0.6512804260892826\n",
      "          Validation Loss (standardized): 1.6944402028211776\n",
      "Epoch: 51, Loss (standarized): 0.647740771550633\n",
      "          Validation Loss (standardized): 1.613359212432886\n",
      "Epoch: 56, Loss (standarized): 0.6442648976014442\n",
      "          Validation Loss (standardized): 1.5597239167305916\n",
      "Epoch: 61, Loss (standarized): 0.6400921652921073\n",
      "          Validation Loss (standardized): 1.539081477603162\n",
      "Epoch: 66, Loss (standarized): 0.6345454971223906\n",
      "          Validation Loss (standardized): 1.5475907512320919\n",
      "Epoch: 71, Loss (standarized): 0.6279500792953034\n",
      "          Validation Loss (standardized): 1.5655619504267666\n",
      "Epoch: 76, Loss (standarized): 0.6222359762831798\n",
      "          Validation Loss (standardized): 1.5694730380135105\n",
      "Epoch: 81, Loss (standarized): 0.6167273267709363\n",
      "          Validation Loss (standardized): 1.555905707366661\n",
      "Epoch: 86, Loss (standarized): 0.6111963554405879\n",
      "          Validation Loss (standardized): 1.545479109854175\n",
      "Epoch: 91, Loss (standarized): 0.6050501148887321\n",
      "          Validation Loss (standardized): 1.547070434474252\n",
      "Epoch: 96, Loss (standarized): 0.5987879899828126\n",
      "          Validation Loss (standardized): 1.5501854484641675\n",
      "Final epoch: 100, Final loss (standarized): 0.5934650322664731\n",
      "Epoch: 1, Loss (standarized): 1.2519553159979406\n",
      "          Validation Loss (standardized): 1.8693545324661751\n",
      "Epoch: 6, Loss (standarized): 0.7631463501428133\n",
      "          Validation Loss (standardized): 1.9499761114625644\n",
      "Epoch: 11, Loss (standarized): 0.6964035218669551\n",
      "          Validation Loss (standardized): 1.8267596003547801\n",
      "Epoch: 16, Loss (standarized): 0.6664819622731464\n",
      "          Validation Loss (standardized): 1.6414487993867692\n",
      "Epoch: 21, Loss (standarized): 0.6475213077493038\n",
      "          Validation Loss (standardized): 1.553531836779897\n",
      "Epoch: 26, Loss (standarized): 0.6368195581925453\n",
      "          Validation Loss (standardized): 1.5820216596833605\n",
      "Epoch: 31, Loss (standarized): 0.6215075938653009\n",
      "          Validation Loss (standardized): 1.6052021770485334\n",
      "Epoch: 36, Loss (standarized): 0.6082288532766835\n",
      "          Validation Loss (standardized): 1.5866492882671481\n",
      "Epoch: 41, Loss (standarized): 0.5968428331593921\n",
      "          Validation Loss (standardized): 1.5397082406730627\n",
      "Epoch: 46, Loss (standarized): 0.5868073979439913\n",
      "          Validation Loss (standardized): 1.529624688259184\n",
      "Epoch: 51, Loss (standarized): 0.5761951354063276\n",
      "          Validation Loss (standardized): 1.5518196548115057\n",
      "Epoch: 56, Loss (standarized): 0.5678257634644599\n",
      "          Validation Loss (standardized): 1.5337655810907782\n",
      "Epoch: 61, Loss (standarized): 0.5599971716015103\n",
      "          Validation Loss (standardized): 1.5106468189391622\n",
      "Epoch: 66, Loss (standarized): 0.5517660013945611\n",
      "          Validation Loss (standardized): 1.523949030271064\n",
      "Epoch: 71, Loss (standarized): 0.5438346315313118\n",
      "          Validation Loss (standardized): 1.5225409780830248\n",
      "Epoch: 76, Loss (standarized): 0.5361977897228051\n",
      "          Validation Loss (standardized): 1.5133217467004527\n",
      "Epoch: 81, Loss (standarized): 0.5285286815319035\n",
      "          Validation Loss (standardized): 1.5200711251232413\n",
      "Epoch: 86, Loss (standarized): 0.5206337425331194\n",
      "          Validation Loss (standardized): 1.5343306720969587\n",
      "Epoch: 91, Loss (standarized): 0.5140745564521323\n",
      "          Validation Loss (standardized): 1.5466468001816338\n",
      "Epoch: 96, Loss (standarized): 0.5085598900964069\n",
      "          Validation Loss (standardized): 1.561003204026448\n",
      "Final epoch: 100, Final loss (standarized): 0.504492788614278\n",
      "Epoch: 1, Loss (standarized): 1.0363888256668528\n",
      "          Validation Loss (standardized): 1.2047879108827133\n",
      "Epoch: 6, Loss (standarized): 0.7143466120310895\n",
      "          Validation Loss (standardized): 1.8846613932238443\n",
      "Epoch: 11, Loss (standarized): 0.6693774126424854\n",
      "          Validation Loss (standardized): 2.20728586573274\n",
      "Epoch: 16, Loss (standarized): 0.6378009467770037\n",
      "          Validation Loss (standardized): 2.137705495109582\n",
      "Epoch: 21, Loss (standarized): 0.602399598102848\n",
      "          Validation Loss (standardized): 1.9301605862143665\n",
      "Epoch: 26, Loss (standarized): 0.567300343921386\n",
      "          Validation Loss (standardized): 1.7441159378756983\n",
      "Epoch: 31, Loss (standarized): 0.5301259590494343\n",
      "          Validation Loss (standardized): 1.6577345836625512\n",
      "Epoch: 36, Loss (standarized): 0.48930687950645124\n",
      "          Validation Loss (standardized): 1.6570084274550771\n",
      "Epoch: 41, Loss (standarized): 0.4462596667602151\n",
      "          Validation Loss (standardized): 1.6592959009541863\n",
      "Epoch: 46, Loss (standarized): 0.4012833430867593\n",
      "          Validation Loss (standardized): 1.605251776703159\n",
      "Epoch: 51, Loss (standarized): 0.35471814451012923\n",
      "          Validation Loss (standardized): 1.514084632794697\n",
      "Epoch: 56, Loss (standarized): 0.3115754649286871\n",
      "          Validation Loss (standardized): 1.4294987814889046\n",
      "Epoch: 61, Loss (standarized): 0.2744265463067979\n",
      "          Validation Loss (standardized): 1.3699181216896412\n",
      "Epoch: 66, Loss (standarized): 0.24474378042319056\n",
      "          Validation Loss (standardized): 1.3049284389746074\n",
      "Epoch: 71, Loss (standarized): 0.22166356368278695\n",
      "          Validation Loss (standardized): 1.219026965233015\n",
      "Epoch: 76, Loss (standarized): 0.20332210882422777\n",
      "          Validation Loss (standardized): 1.158178442916244\n",
      "Epoch: 81, Loss (standarized): 0.18869446340086082\n",
      "          Validation Loss (standardized): 1.1082489221825598\n",
      "Epoch: 86, Loss (standarized): 0.17662834624507537\n",
      "          Validation Loss (standardized): 1.0540306501862087\n",
      "Epoch: 91, Loss (standarized): 0.16649244827943285\n",
      "          Validation Loss (standardized): 1.0032780564862658\n",
      "Epoch: 96, Loss (standarized): 0.15761342207827284\n",
      "          Validation Loss (standardized): 0.956023177625433\n",
      "Final epoch: 100, Final loss (standarized): 0.1512519042654838\n",
      "Epoch: 1, Loss (standarized): 1.4065655152842729\n",
      "          Validation Loss (standardized): 1.5967344109549952\n",
      "Epoch: 6, Loss (standarized): 0.7360012897749136\n",
      "          Validation Loss (standardized): 1.685419299167671\n",
      "Epoch: 11, Loss (standarized): 0.733119618233623\n",
      "          Validation Loss (standardized): 2.0687949644465466\n",
      "Epoch: 16, Loss (standarized): 0.6828960158844212\n",
      "          Validation Loss (standardized): 2.071266540488792\n",
      "Epoch: 21, Loss (standarized): 0.6558886434040091\n",
      "          Validation Loss (standardized): 1.9396220615646942\n",
      "Epoch: 26, Loss (standarized): 0.6395637604466619\n",
      "          Validation Loss (standardized): 1.8120234141272678\n",
      "Epoch: 31, Loss (standarized): 0.6214166136260443\n",
      "          Validation Loss (standardized): 1.741004649465698\n",
      "Epoch: 36, Loss (standarized): 0.5973682986067386\n",
      "          Validation Loss (standardized): 1.7105745701917607\n",
      "Epoch: 41, Loss (standarized): 0.5727807141343813\n",
      "          Validation Loss (standardized): 1.6980325076531877\n",
      "Epoch: 46, Loss (standarized): 0.5491350272974896\n",
      "          Validation Loss (standardized): 1.6805390923697154\n",
      "Epoch: 51, Loss (standarized): 0.5284216366266686\n",
      "          Validation Loss (standardized): 1.6516958830027124\n",
      "Epoch: 56, Loss (standarized): 0.5108257380021436\n",
      "          Validation Loss (standardized): 1.6246634842343262\n",
      "Epoch: 61, Loss (standarized): 0.4945836704186214\n",
      "          Validation Loss (standardized): 1.6120323507310255\n",
      "Epoch: 66, Loss (standarized): 0.47978819983662974\n",
      "          Validation Loss (standardized): 1.6012278617722246\n",
      "Epoch: 71, Loss (standarized): 0.4662649362635268\n",
      "          Validation Loss (standardized): 1.5771122695555408\n",
      "Epoch: 76, Loss (standarized): 0.45311579157942294\n",
      "          Validation Loss (standardized): 1.5538024878137038\n",
      "Epoch: 81, Loss (standarized): 0.44017283715312133\n",
      "          Validation Loss (standardized): 1.5438915747879227\n",
      "Epoch: 86, Loss (standarized): 0.4266404929582436\n",
      "          Validation Loss (standardized): 1.5380477652805509\n",
      "Epoch: 91, Loss (standarized): 0.4122184080518726\n",
      "          Validation Loss (standardized): 1.5233868192727282\n",
      "Epoch: 96, Loss (standarized): 0.396830483144889\n",
      "          Validation Loss (standardized): 1.5009159872349793\n",
      "Final epoch: 100, Final loss (standarized): 0.38393966275952796\n",
      "Epoch: 1, Loss (standarized): 1.0362036538676447\n",
      "          Validation Loss (standardized): 1.2084757352452973\n",
      "Epoch: 6, Loss (standarized): 0.7093588006234937\n",
      "          Validation Loss (standardized): 1.4959900305119591\n",
      "Epoch: 11, Loss (standarized): 0.6432186489738232\n",
      "          Validation Loss (standardized): 1.965942302609462\n",
      "Epoch: 16, Loss (standarized): 0.6133372959877459\n",
      "          Validation Loss (standardized): 2.1870284534181055\n",
      "Epoch: 21, Loss (standarized): 0.5822322130669976\n",
      "          Validation Loss (standardized): 2.099504554814076\n",
      "Epoch: 26, Loss (standarized): 0.5471985440162874\n",
      "          Validation Loss (standardized): 1.9172216043228516\n",
      "Epoch: 31, Loss (standarized): 0.5099769440870724\n",
      "          Validation Loss (standardized): 1.7874850664132094\n",
      "Epoch: 36, Loss (standarized): 0.47586616993568626\n",
      "          Validation Loss (standardized): 1.7096972184942856\n",
      "Epoch: 41, Loss (standarized): 0.4397088291849509\n",
      "          Validation Loss (standardized): 1.64499468004769\n",
      "Epoch: 46, Loss (standarized): 0.3994639189201476\n",
      "          Validation Loss (standardized): 1.5773322862992034\n",
      "Epoch: 51, Loss (standarized): 0.3544950707636225\n",
      "          Validation Loss (standardized): 1.5177110627679695\n",
      "Epoch: 56, Loss (standarized): 0.3115777187793475\n",
      "          Validation Loss (standardized): 1.467736365974496\n",
      "Epoch: 61, Loss (standarized): 0.27338533986606267\n",
      "          Validation Loss (standardized): 1.3934497412731999\n",
      "Epoch: 66, Loss (standarized): 0.24229561585669712\n",
      "          Validation Loss (standardized): 1.3146110025826712\n",
      "Epoch: 71, Loss (standarized): 0.21892938295858\n",
      "          Validation Loss (standardized): 1.2623481400574628\n",
      "Epoch: 76, Loss (standarized): 0.20146805505206122\n",
      "          Validation Loss (standardized): 1.198607418126289\n",
      "Epoch: 81, Loss (standarized): 0.18810025399598276\n",
      "          Validation Loss (standardized): 1.1394980387825042\n",
      "Epoch: 86, Loss (standarized): 0.17749124500922675\n",
      "          Validation Loss (standardized): 1.0741080282233824\n",
      "Epoch: 91, Loss (standarized): 0.16858888029950508\n",
      "          Validation Loss (standardized): 1.0284796659561053\n",
      "Epoch: 96, Loss (standarized): 0.16105149939865168\n",
      "          Validation Loss (standardized): 0.9836129535158559\n",
      "Final epoch: 100, Final loss (standarized): 0.15564424475731567\n",
      "Epoch: 1, Loss (standarized): 1.7943334791782741\n",
      "          Validation Loss (standardized): 1.3238103845366331\n",
      "Epoch: 6, Loss (standarized): 0.7351629416486168\n",
      "          Validation Loss (standardized): 1.6571383284116945\n",
      "Epoch: 11, Loss (standarized): 0.6954175378524834\n",
      "          Validation Loss (standardized): 2.154129344619626\n",
      "Epoch: 16, Loss (standarized): 0.6901551980897561\n",
      "          Validation Loss (standardized): 2.294062426334783\n",
      "Epoch: 21, Loss (standarized): 0.6453789458712946\n",
      "          Validation Loss (standardized): 2.2295973510175964\n",
      "Epoch: 26, Loss (standarized): 0.6229922239813571\n",
      "          Validation Loss (standardized): 2.0671975960503413\n",
      "Epoch: 31, Loss (standarized): 0.5998970061705077\n",
      "          Validation Loss (standardized): 1.8817344027281173\n",
      "Epoch: 36, Loss (standarized): 0.5762232268065098\n",
      "          Validation Loss (standardized): 1.7477481606312293\n",
      "Epoch: 41, Loss (standarized): 0.5506525736436317\n",
      "          Validation Loss (standardized): 1.6669934066129606\n",
      "Epoch: 46, Loss (standarized): 0.5254128869731161\n",
      "          Validation Loss (standardized): 1.6153204520990236\n",
      "Epoch: 51, Loss (standarized): 0.49745279304209394\n",
      "          Validation Loss (standardized): 1.5735731614039667\n",
      "Epoch: 56, Loss (standarized): 0.4695562696489772\n",
      "          Validation Loss (standardized): 1.54326667841141\n",
      "Epoch: 61, Loss (standarized): 0.44209836842773936\n",
      "          Validation Loss (standardized): 1.5210727265146629\n",
      "Epoch: 66, Loss (standarized): 0.41523135529489524\n",
      "          Validation Loss (standardized): 1.4996229032764026\n",
      "Epoch: 71, Loss (standarized): 0.3886509129856203\n",
      "          Validation Loss (standardized): 1.4708890718143102\n",
      "Epoch: 76, Loss (standarized): 0.3615682398482471\n",
      "          Validation Loss (standardized): 1.4344349035974044\n",
      "Epoch: 81, Loss (standarized): 0.33399404243177894\n",
      "          Validation Loss (standardized): 1.3951316562636453\n",
      "Epoch: 86, Loss (standarized): 0.30655421061926863\n",
      "          Validation Loss (standardized): 1.3517011309612217\n",
      "Epoch: 91, Loss (standarized): 0.2816564982838895\n",
      "          Validation Loss (standardized): 1.3077581933184883\n",
      "Epoch: 96, Loss (standarized): 0.259536718674377\n",
      "          Validation Loss (standardized): 1.2711324886706894\n",
      "Final epoch: 100, Final loss (standarized): 0.2437455437978014\n",
      "Epoch: 1, Loss (standarized): 1.5816280438964008\n",
      "          Validation Loss (standardized): 1.7534589317458404\n",
      "Epoch: 6, Loss (standarized): 0.815950165216899\n",
      "          Validation Loss (standardized): 1.7364332746912337\n",
      "Epoch: 11, Loss (standarized): 0.6994499232596255\n",
      "          Validation Loss (standardized): 2.149280663353156\n",
      "Epoch: 16, Loss (standarized): 0.7024148497768531\n",
      "          Validation Loss (standardized): 2.229716085078557\n",
      "Epoch: 21, Loss (standarized): 0.6672810779146346\n",
      "          Validation Loss (standardized): 2.024155161630571\n",
      "Epoch: 26, Loss (standarized): 0.6326176046648045\n",
      "          Validation Loss (standardized): 1.7995487384599642\n",
      "Epoch: 31, Loss (standarized): 0.6209390278836722\n",
      "          Validation Loss (standardized): 1.6866276669552858\n",
      "Epoch: 36, Loss (standarized): 0.6015030884287585\n",
      "          Validation Loss (standardized): 1.6742314313373827\n",
      "Epoch: 41, Loss (standarized): 0.5725511491984129\n",
      "          Validation Loss (standardized): 1.7174634349308489\n",
      "Epoch: 46, Loss (standarized): 0.5415932934623514\n",
      "          Validation Loss (standardized): 1.7451130355658697\n",
      "Epoch: 51, Loss (standarized): 0.5015674974560391\n",
      "          Validation Loss (standardized): 1.705266943475319\n",
      "Epoch: 56, Loss (standarized): 0.45994524213367916\n",
      "          Validation Loss (standardized): 1.6079045217277403\n",
      "Epoch: 61, Loss (standarized): 0.4207118819283338\n",
      "          Validation Loss (standardized): 1.4985691892088429\n",
      "Epoch: 66, Loss (standarized): 0.3823769992467807\n",
      "          Validation Loss (standardized): 1.4286056496306119\n",
      "Epoch: 71, Loss (standarized): 0.3431395919449904\n",
      "          Validation Loss (standardized): 1.39166939601129\n",
      "Epoch: 76, Loss (standarized): 0.30517401338390276\n",
      "          Validation Loss (standardized): 1.348631521523978\n",
      "Epoch: 81, Loss (standarized): 0.2704288845408954\n",
      "          Validation Loss (standardized): 1.2654352303382357\n",
      "Epoch: 86, Loss (standarized): 0.23978720082966026\n",
      "          Validation Loss (standardized): 1.1771287629654617\n",
      "Epoch: 91, Loss (standarized): 0.21442637782879032\n",
      "          Validation Loss (standardized): 1.118959243376763\n",
      "Epoch: 96, Loss (standarized): 0.1931938800831748\n",
      "          Validation Loss (standardized): 1.0623848293688252\n",
      "Final epoch: 100, Final loss (standarized): 0.17886144609525462\n",
      "Epoch: 1, Loss (standarized): 2.3708592386517595\n",
      "          Validation Loss (standardized): 1.4684007685249625\n",
      "Epoch: 6, Loss (standarized): 0.9254021147951051\n",
      "          Validation Loss (standardized): 1.5488221553103734\n",
      "Epoch: 11, Loss (standarized): 0.743760067784484\n",
      "          Validation Loss (standardized): 2.086173394793063\n",
      "Epoch: 16, Loss (standarized): 0.701106064159956\n",
      "          Validation Loss (standardized): 2.302871503862126\n",
      "Epoch: 21, Loss (standarized): 0.6655922091978683\n",
      "          Validation Loss (standardized): 2.286598780283342\n",
      "Epoch: 26, Loss (standarized): 0.6364849726500806\n",
      "          Validation Loss (standardized): 2.1560227737249313\n",
      "Epoch: 31, Loss (standarized): 0.6168395753393658\n",
      "          Validation Loss (standardized): 2.010426382671516\n",
      "Epoch: 36, Loss (standarized): 0.5957652667520416\n",
      "          Validation Loss (standardized): 1.8839664994052268\n",
      "Epoch: 41, Loss (standarized): 0.573383588841957\n",
      "          Validation Loss (standardized): 1.80404081417107\n",
      "Epoch: 46, Loss (standarized): 0.5511640014057781\n",
      "          Validation Loss (standardized): 1.7456861102960652\n",
      "Epoch: 51, Loss (standarized): 0.529653319752089\n",
      "          Validation Loss (standardized): 1.685414632685738\n",
      "Epoch: 56, Loss (standarized): 0.5117644736772967\n",
      "          Validation Loss (standardized): 1.627903913973289\n",
      "Epoch: 61, Loss (standarized): 0.49269282794027724\n",
      "          Validation Loss (standardized): 1.5647423387953854\n",
      "Epoch: 66, Loss (standarized): 0.4725014417126763\n",
      "          Validation Loss (standardized): 1.5282724275729962\n",
      "Epoch: 71, Loss (standarized): 0.44905413863679183\n",
      "          Validation Loss (standardized): 1.5086510680877778\n",
      "Epoch: 76, Loss (standarized): 0.4272720222676499\n",
      "          Validation Loss (standardized): 1.471291263340668\n",
      "Epoch: 81, Loss (standarized): 0.4038992162849464\n",
      "          Validation Loss (standardized): 1.440719194073953\n",
      "Epoch: 86, Loss (standarized): 0.3810399240752202\n",
      "          Validation Loss (standardized): 1.4180942062535928\n",
      "Epoch: 91, Loss (standarized): 0.3589118193570358\n",
      "          Validation Loss (standardized): 1.3868159526096806\n",
      "Epoch: 96, Loss (standarized): 0.3379347371166089\n",
      "          Validation Loss (standardized): 1.3630111073547264\n",
      "Final epoch: 100, Final loss (standarized): 0.3221824978223195\n",
      "Epoch: 1, Loss (standarized): 1.6782840383970554\n",
      "          Validation Loss (standardized): 1.2627956863520946\n",
      "Epoch: 6, Loss (standarized): 0.8442146399405226\n",
      "          Validation Loss (standardized): 1.4482707997987092\n",
      "Epoch: 11, Loss (standarized): 0.6827533358174034\n",
      "          Validation Loss (standardized): 1.87502988578536\n",
      "Epoch: 16, Loss (standarized): 0.6402114896540045\n",
      "          Validation Loss (standardized): 2.217785777009789\n",
      "Epoch: 21, Loss (standarized): 0.6157964053838447\n",
      "          Validation Loss (standardized): 2.326329572065474\n",
      "Epoch: 26, Loss (standarized): 0.5947286784365274\n",
      "          Validation Loss (standardized): 2.234006335744989\n",
      "Epoch: 31, Loss (standarized): 0.5653506057076922\n",
      "          Validation Loss (standardized): 2.06296676286494\n",
      "Epoch: 36, Loss (standarized): 0.5393254302911858\n",
      "          Validation Loss (standardized): 1.8922365132999053\n",
      "Epoch: 41, Loss (standarized): 0.5175936898014737\n",
      "          Validation Loss (standardized): 1.76318923327954\n",
      "Epoch: 46, Loss (standarized): 0.490524175006554\n",
      "          Validation Loss (standardized): 1.7268469841024434\n",
      "Epoch: 51, Loss (standarized): 0.46115394042570756\n",
      "          Validation Loss (standardized): 1.722679498014488\n",
      "Epoch: 56, Loss (standarized): 0.428916334749663\n",
      "          Validation Loss (standardized): 1.7296344449578713\n",
      "Epoch: 61, Loss (standarized): 0.3939511820112792\n",
      "          Validation Loss (standardized): 1.694199977142242\n",
      "Epoch: 66, Loss (standarized): 0.35781387641425827\n",
      "          Validation Loss (standardized): 1.6545682234831\n",
      "Epoch: 71, Loss (standarized): 0.3213123512459608\n",
      "          Validation Loss (standardized): 1.6081968254466692\n",
      "Epoch: 76, Loss (standarized): 0.2900291771137671\n",
      "          Validation Loss (standardized): 1.5719423282131633\n",
      "Epoch: 81, Loss (standarized): 0.26718457522499706\n",
      "          Validation Loss (standardized): 1.5127925109490734\n",
      "Epoch: 86, Loss (standarized): 0.24663709766617659\n",
      "          Validation Loss (standardized): 1.457544159593779\n",
      "Epoch: 91, Loss (standarized): 0.2297446846600063\n",
      "          Validation Loss (standardized): 1.3602692366103175\n",
      "Epoch: 96, Loss (standarized): 0.21506309175315566\n",
      "          Validation Loss (standardized): 1.2690016224379783\n",
      "Final epoch: 100, Final loss (standarized): 0.20395652576826134\n",
      "Epoch: 1, Loss (standarized): 1.2564079821231326\n",
      "          Validation Loss (standardized): 1.0553554809745995\n",
      "Epoch: 6, Loss (standarized): 0.6990146605478963\n",
      "          Validation Loss (standardized): 1.616785732070283\n",
      "Epoch: 11, Loss (standarized): 0.6444226612990447\n",
      "          Validation Loss (standardized): 2.1692905716612696\n",
      "Epoch: 16, Loss (standarized): 0.6225060232881006\n",
      "          Validation Loss (standardized): 2.318432528641968\n",
      "Epoch: 21, Loss (standarized): 0.585721301285392\n",
      "          Validation Loss (standardized): 2.1844278058770406\n",
      "Epoch: 26, Loss (standarized): 0.54062338058885\n",
      "          Validation Loss (standardized): 1.9590575252629665\n",
      "Epoch: 31, Loss (standarized): 0.4914686279810496\n",
      "          Validation Loss (standardized): 1.753411276881809\n",
      "Epoch: 36, Loss (standarized): 0.4367553215775999\n",
      "          Validation Loss (standardized): 1.6187102310388004\n",
      "Epoch: 41, Loss (standarized): 0.3824114489190803\n",
      "          Validation Loss (standardized): 1.5561213448051787\n",
      "Epoch: 46, Loss (standarized): 0.3324249285097274\n",
      "          Validation Loss (standardized): 1.5222274477535374\n",
      "Epoch: 51, Loss (standarized): 0.2902236065044682\n",
      "          Validation Loss (standardized): 1.482958270773278\n",
      "Epoch: 56, Loss (standarized): 0.25557927132940633\n",
      "          Validation Loss (standardized): 1.408351398392204\n",
      "Epoch: 61, Loss (standarized): 0.22895016845018037\n",
      "          Validation Loss (standardized): 1.3138311831509124\n",
      "Epoch: 66, Loss (standarized): 0.2081874552748227\n",
      "          Validation Loss (standardized): 1.2181958243996391\n",
      "Epoch: 71, Loss (standarized): 0.19120294999471552\n",
      "          Validation Loss (standardized): 1.1328221253016462\n",
      "Epoch: 76, Loss (standarized): 0.17701424497123477\n",
      "          Validation Loss (standardized): 1.0572014443097362\n",
      "Epoch: 81, Loss (standarized): 0.164458993963314\n",
      "          Validation Loss (standardized): 0.9825566370386251\n",
      "Epoch: 86, Loss (standarized): 0.15308236351768884\n",
      "          Validation Loss (standardized): 0.9183190855542015\n",
      "Epoch: 91, Loss (standarized): 0.142357913052181\n",
      "          Validation Loss (standardized): 0.8598680162170794\n",
      "Epoch: 96, Loss (standarized): 0.13144945336429767\n",
      "          Validation Loss (standardized): 0.7874882924572598\n",
      "Final epoch: 100, Final loss (standarized): 0.12388929704282649\n",
      "Epoch: 1, Loss (standarized): 3.427616769174323\n",
      "          Validation Loss (standardized): 1.8225848647322034\n",
      "Epoch: 6, Loss (standarized): 1.220203903655848\n",
      "          Validation Loss (standardized): 1.409140894087508\n",
      "Epoch: 11, Loss (standarized): 0.7770423711652106\n",
      "          Validation Loss (standardized): 1.692711553131548\n",
      "Epoch: 16, Loss (standarized): 0.6697256307420207\n",
      "          Validation Loss (standardized): 1.9787338112415354\n",
      "Epoch: 21, Loss (standarized): 0.6963513664852364\n",
      "          Validation Loss (standardized): 2.1897040356255877\n",
      "Epoch: 26, Loss (standarized): 0.6571426753923424\n",
      "          Validation Loss (standardized): 2.2524283823771487\n",
      "Epoch: 31, Loss (standarized): 0.6428490182807357\n",
      "          Validation Loss (standardized): 2.274474521475631\n",
      "Epoch: 36, Loss (standarized): 0.6346309017639474\n",
      "          Validation Loss (standardized): 2.2173295603815664\n",
      "Epoch: 41, Loss (standarized): 0.6149940579038977\n",
      "          Validation Loss (standardized): 2.0960620453411956\n",
      "Epoch: 46, Loss (standarized): 0.6017924243983201\n",
      "          Validation Loss (standardized): 1.973632870046749\n",
      "Epoch: 51, Loss (standarized): 0.5893001819542095\n",
      "          Validation Loss (standardized): 1.8769340138851762\n",
      "Epoch: 56, Loss (standarized): 0.5745735930736462\n",
      "          Validation Loss (standardized): 1.8105750028261378\n",
      "Epoch: 61, Loss (standarized): 0.5564238379306784\n",
      "          Validation Loss (standardized): 1.7589035092148397\n",
      "Epoch: 66, Loss (standarized): 0.5368358681139788\n",
      "          Validation Loss (standardized): 1.7109729053038125\n",
      "Epoch: 71, Loss (standarized): 0.5172109693326534\n",
      "          Validation Loss (standardized): 1.6686987619806897\n",
      "Epoch: 76, Loss (standarized): 0.49467702610564956\n",
      "          Validation Loss (standardized): 1.633457632995679\n",
      "Epoch: 81, Loss (standarized): 0.4709832675786398\n",
      "          Validation Loss (standardized): 1.6005123875719882\n",
      "Epoch: 86, Loss (standarized): 0.44636617818145174\n",
      "          Validation Loss (standardized): 1.5868813889007274\n",
      "Epoch: 91, Loss (standarized): 0.423257490242376\n",
      "          Validation Loss (standardized): 1.581257524866825\n",
      "Epoch: 96, Loss (standarized): 0.4015163196528682\n",
      "          Validation Loss (standardized): 1.5509735405466187\n",
      "Final epoch: 100, Final loss (standarized): 0.3843708546393192\n",
      "Epoch: 1, Loss (standarized): 1.570242981311151\n",
      "          Validation Loss (standardized): 1.4276078666941812\n",
      "Epoch: 6, Loss (standarized): 0.8417924124601468\n",
      "          Validation Loss (standardized): 1.4189634662903967\n",
      "Epoch: 11, Loss (standarized): 0.6815584309244185\n",
      "          Validation Loss (standardized): 1.694019436054879\n",
      "Epoch: 16, Loss (standarized): 0.6546336783078709\n",
      "          Validation Loss (standardized): 1.99217599846475\n",
      "Epoch: 21, Loss (standarized): 0.6325825347691553\n",
      "          Validation Loss (standardized): 2.129047338242808\n",
      "Epoch: 26, Loss (standarized): 0.6116441585457028\n",
      "          Validation Loss (standardized): 2.045106636475366\n",
      "Epoch: 31, Loss (standarized): 0.5887865636992755\n",
      "          Validation Loss (standardized): 1.8889866300215776\n",
      "Epoch: 36, Loss (standarized): 0.5657250740538845\n",
      "          Validation Loss (standardized): 1.751982795604905\n",
      "Epoch: 41, Loss (standarized): 0.5416529351905931\n",
      "          Validation Loss (standardized): 1.639192485096973\n",
      "Epoch: 46, Loss (standarized): 0.514078533903706\n",
      "          Validation Loss (standardized): 1.5592399133694328\n",
      "Epoch: 51, Loss (standarized): 0.4814437753562915\n",
      "          Validation Loss (standardized): 1.515444978060847\n",
      "Epoch: 56, Loss (standarized): 0.44438435777609997\n",
      "          Validation Loss (standardized): 1.4915584862240419\n",
      "Epoch: 61, Loss (standarized): 0.40911652649823654\n",
      "          Validation Loss (standardized): 1.4771668096003245\n",
      "Epoch: 66, Loss (standarized): 0.3742830640422454\n",
      "          Validation Loss (standardized): 1.451543472970283\n",
      "Epoch: 71, Loss (standarized): 0.3428210934099531\n",
      "          Validation Loss (standardized): 1.4133863406752627\n",
      "Epoch: 76, Loss (standarized): 0.3151887069984877\n",
      "          Validation Loss (standardized): 1.366952547918103\n",
      "Epoch: 81, Loss (standarized): 0.2916307291694123\n",
      "          Validation Loss (standardized): 1.3090068617882324\n",
      "Epoch: 86, Loss (standarized): 0.273705151811772\n",
      "          Validation Loss (standardized): 1.256089234004588\n",
      "Epoch: 91, Loss (standarized): 0.25998627621458165\n",
      "          Validation Loss (standardized): 1.2219626962970624\n",
      "Epoch: 96, Loss (standarized): 0.2495586608778936\n",
      "          Validation Loss (standardized): 1.197903918390231\n",
      "Final epoch: 100, Final loss (standarized): 0.24310801218804984\n",
      "Epoch: 1, Loss (standarized): 1.9758628449251363\n",
      "          Validation Loss (standardized): 1.49525480932185\n",
      "Epoch: 6, Loss (standarized): 1.088596075297564\n",
      "          Validation Loss (standardized): 1.3868008616909915\n",
      "Epoch: 11, Loss (standarized): 0.8060484914743545\n",
      "          Validation Loss (standardized): 1.4915087930329392\n",
      "Epoch: 16, Loss (standarized): 0.685308697603224\n",
      "          Validation Loss (standardized): 1.620736383985325\n",
      "Epoch: 21, Loss (standarized): 0.6249946099303267\n",
      "          Validation Loss (standardized): 1.8329772316213215\n",
      "Epoch: 26, Loss (standarized): 0.5839767217458051\n",
      "          Validation Loss (standardized): 1.9834557076584902\n",
      "Epoch: 31, Loss (standarized): 0.5505009098552143\n",
      "          Validation Loss (standardized): 1.9205589205893776\n",
      "Epoch: 36, Loss (standarized): 0.5076092851963265\n",
      "          Validation Loss (standardized): 1.7777978473858467\n",
      "Epoch: 41, Loss (standarized): 0.4644303440097472\n",
      "          Validation Loss (standardized): 1.6568841135782313\n",
      "Epoch: 46, Loss (standarized): 0.4216448032356185\n",
      "          Validation Loss (standardized): 1.5370629307669237\n",
      "Epoch: 51, Loss (standarized): 0.37929223984488186\n",
      "          Validation Loss (standardized): 1.4897058954477107\n",
      "Epoch: 56, Loss (standarized): 0.340054217483955\n",
      "          Validation Loss (standardized): 1.4713760510443659\n",
      "Epoch: 61, Loss (standarized): 0.3042568063449494\n",
      "          Validation Loss (standardized): 1.387638980515499\n",
      "Epoch: 66, Loss (standarized): 0.2712655398263902\n",
      "          Validation Loss (standardized): 1.285216870384959\n",
      "Epoch: 71, Loss (standarized): 0.24339677516410654\n",
      "          Validation Loss (standardized): 1.1491158493774278\n",
      "Epoch: 76, Loss (standarized): 0.22178324700840452\n",
      "          Validation Loss (standardized): 1.076170162015391\n",
      "Epoch: 81, Loss (standarized): 0.2039860939279484\n",
      "          Validation Loss (standardized): 1.0511512900031235\n",
      "Epoch: 86, Loss (standarized): 0.1891227778423084\n",
      "          Validation Loss (standardized): 0.9905342855997749\n",
      "Epoch: 91, Loss (standarized): 0.17516596083541067\n",
      "          Validation Loss (standardized): 0.8966614206195463\n",
      "Epoch: 96, Loss (standarized): 0.1625232303144178\n",
      "          Validation Loss (standardized): 0.8400167759622313\n",
      "Final epoch: 100, Final loss (standarized): 0.15329846898674832\n",
      "Epoch: 1, Loss (standarized): 2.378188638869564\n",
      "          Validation Loss (standardized): 1.1581790694254899\n",
      "Epoch: 6, Loss (standarized): 0.8014020631773733\n",
      "          Validation Loss (standardized): 1.6743591879271758\n",
      "Epoch: 11, Loss (standarized): 0.6947147895573131\n",
      "          Validation Loss (standardized): 2.5269729957752984\n",
      "Epoch: 16, Loss (standarized): 0.6943895272080896\n",
      "          Validation Loss (standardized): 2.9155861047584732\n",
      "Epoch: 21, Loss (standarized): 0.6742642721412336\n",
      "          Validation Loss (standardized): 2.8930978733494674\n",
      "Epoch: 26, Loss (standarized): 0.6415668556428228\n",
      "          Validation Loss (standardized): 2.6480655515945752\n",
      "Epoch: 31, Loss (standarized): 0.6021786997671881\n",
      "          Validation Loss (standardized): 2.3527777569697967\n",
      "Epoch: 36, Loss (standarized): 0.5668364767605371\n",
      "          Validation Loss (standardized): 2.058233323533136\n",
      "Epoch: 41, Loss (standarized): 0.5374602368708923\n",
      "          Validation Loss (standardized): 1.8116603144960017\n",
      "Epoch: 46, Loss (standarized): 0.5103893733542672\n",
      "          Validation Loss (standardized): 1.655562140832325\n",
      "Epoch: 51, Loss (standarized): 0.48184802176476654\n",
      "          Validation Loss (standardized): 1.5708239750494606\n",
      "Epoch: 56, Loss (standarized): 0.44929664073202147\n",
      "          Validation Loss (standardized): 1.5454974278697236\n",
      "Epoch: 61, Loss (standarized): 0.41455766942606337\n",
      "          Validation Loss (standardized): 1.563164008774851\n",
      "Epoch: 66, Loss (standarized): 0.38071436940555714\n",
      "          Validation Loss (standardized): 1.5811968585878238\n",
      "Epoch: 71, Loss (standarized): 0.34918918885395694\n",
      "          Validation Loss (standardized): 1.575537487864341\n",
      "Epoch: 76, Loss (standarized): 0.3199520309723175\n",
      "          Validation Loss (standardized): 1.5289351086424652\n",
      "Epoch: 81, Loss (standarized): 0.29525826591790855\n",
      "          Validation Loss (standardized): 1.4613814505180784\n",
      "Epoch: 86, Loss (standarized): 0.2746996949199126\n",
      "          Validation Loss (standardized): 1.4073838284578724\n",
      "Epoch: 91, Loss (standarized): 0.2575600710737155\n",
      "          Validation Loss (standardized): 1.3579314982430268\n",
      "Epoch: 96, Loss (standarized): 0.243050734921642\n",
      "          Validation Loss (standardized): 1.3196315983427416\n",
      "Final epoch: 100, Final loss (standarized): 0.23317469114596318\n",
      "Epoch: 1, Loss (standarized): 1.1310976214137451\n",
      "          Validation Loss (standardized): 1.1951982114036233\n",
      "Epoch: 6, Loss (standarized): 0.7244910512254508\n",
      "          Validation Loss (standardized): 1.6257906032708043\n",
      "Epoch: 11, Loss (standarized): 0.6701278931727773\n",
      "          Validation Loss (standardized): 1.9199111152938022\n",
      "Epoch: 16, Loss (standarized): 0.6502643784321563\n",
      "          Validation Loss (standardized): 2.0100217859648684\n",
      "Epoch: 21, Loss (standarized): 0.6254342394257869\n",
      "          Validation Loss (standardized): 1.9750837254618219\n",
      "Epoch: 26, Loss (standarized): 0.6122519884594914\n",
      "          Validation Loss (standardized): 1.8525541760736652\n",
      "Epoch: 31, Loss (standarized): 0.5999542012784255\n",
      "          Validation Loss (standardized): 1.7248257095615085\n",
      "Epoch: 36, Loss (standarized): 0.5856729369473579\n",
      "          Validation Loss (standardized): 1.6497555001063027\n",
      "Epoch: 41, Loss (standarized): 0.5732311867566829\n",
      "          Validation Loss (standardized): 1.610838391200135\n",
      "Epoch: 46, Loss (standarized): 0.5632914538147922\n",
      "          Validation Loss (standardized): 1.5991710966427628\n",
      "Epoch: 51, Loss (standarized): 0.5535367278624223\n",
      "          Validation Loss (standardized): 1.5739783710040143\n",
      "Epoch: 56, Loss (standarized): 0.5429332190240892\n",
      "          Validation Loss (standardized): 1.5550108420778244\n",
      "Epoch: 61, Loss (standarized): 0.5302828282541161\n",
      "          Validation Loss (standardized): 1.5516362599345899\n",
      "Epoch: 66, Loss (standarized): 0.5163546479978081\n",
      "          Validation Loss (standardized): 1.5558580552345425\n",
      "Epoch: 71, Loss (standarized): 0.5013524332588355\n",
      "          Validation Loss (standardized): 1.5676652699456293\n",
      "Epoch: 76, Loss (standarized): 0.48601115322886795\n",
      "          Validation Loss (standardized): 1.5914890147403362\n",
      "Epoch: 81, Loss (standarized): 0.4706913034338016\n",
      "          Validation Loss (standardized): 1.5943043745041117\n",
      "Epoch: 86, Loss (standarized): 0.4561682109190753\n",
      "          Validation Loss (standardized): 1.5952532677392504\n",
      "Epoch: 91, Loss (standarized): 0.4437784747161401\n",
      "          Validation Loss (standardized): 1.595338414533377\n",
      "Epoch: 96, Loss (standarized): 0.43202230719203816\n",
      "          Validation Loss (standardized): 1.5971500994123538\n",
      "Final epoch: 100, Final loss (standarized): 0.4226413829060301\n",
      "Epoch: 1, Loss (standarized): 1.1124621254846878\n",
      "          Validation Loss (standardized): 1.8399924388169213\n",
      "Epoch: 6, Loss (standarized): 0.7875428454162251\n",
      "          Validation Loss (standardized): 1.8215528837061483\n",
      "Epoch: 11, Loss (standarized): 0.7193501693281246\n",
      "          Validation Loss (standardized): 1.693805387601625\n",
      "Epoch: 16, Loss (standarized): 0.6952082503105167\n",
      "          Validation Loss (standardized): 1.6459283527979804\n",
      "Epoch: 21, Loss (standarized): 0.676804208339023\n",
      "          Validation Loss (standardized): 1.6324859705071861\n",
      "Epoch: 26, Loss (standarized): 0.6681814349853603\n",
      "          Validation Loss (standardized): 1.6101174851465536\n",
      "Epoch: 31, Loss (standarized): 0.6638598704823303\n",
      "          Validation Loss (standardized): 1.5890448545874307\n",
      "Epoch: 36, Loss (standarized): 0.6575579545566703\n",
      "          Validation Loss (standardized): 1.5791286864591347\n",
      "Epoch: 41, Loss (standarized): 0.6517718914701962\n",
      "          Validation Loss (standardized): 1.5604450363808915\n",
      "Epoch: 46, Loss (standarized): 0.645751929219288\n",
      "          Validation Loss (standardized): 1.5511073902815316\n",
      "Epoch: 51, Loss (standarized): 0.6364874913547002\n",
      "          Validation Loss (standardized): 1.5349362307274523\n",
      "Epoch: 56, Loss (standarized): 0.6319501177027402\n",
      "          Validation Loss (standardized): 1.5424774065110622\n",
      "Epoch: 61, Loss (standarized): 0.6257918744101821\n",
      "          Validation Loss (standardized): 1.555034272037406\n",
      "Epoch: 66, Loss (standarized): 0.6187070868591696\n",
      "          Validation Loss (standardized): 1.5499674271559127\n",
      "Epoch: 71, Loss (standarized): 0.6117169318863588\n",
      "          Validation Loss (standardized): 1.5510448701216706\n",
      "Epoch: 76, Loss (standarized): 0.605960382653519\n",
      "          Validation Loss (standardized): 1.5470125537011663\n",
      "Epoch: 81, Loss (standarized): 0.6001700988951549\n",
      "          Validation Loss (standardized): 1.5397588430762286\n",
      "Epoch: 86, Loss (standarized): 0.5931871145608014\n",
      "          Validation Loss (standardized): 1.5393695562409828\n",
      "Epoch: 91, Loss (standarized): 0.5858587300870584\n",
      "          Validation Loss (standardized): 1.5416704875712344\n",
      "Epoch: 96, Loss (standarized): 0.5784444993453378\n",
      "          Validation Loss (standardized): 1.542974756105736\n",
      "Final epoch: 100, Final loss (standarized): 0.5730638634453555\n",
      "Epoch: 1, Loss (standarized): 1.2270690656600076\n",
      "          Validation Loss (standardized): 1.1448660884292288\n",
      "Epoch: 6, Loss (standarized): 0.7193157247210306\n",
      "          Validation Loss (standardized): 1.5889764176317263\n",
      "Epoch: 11, Loss (standarized): 0.669842788491529\n",
      "          Validation Loss (standardized): 1.907775903178519\n",
      "Epoch: 16, Loss (standarized): 0.6473656119807334\n",
      "          Validation Loss (standardized): 1.986075412817805\n",
      "Epoch: 21, Loss (standarized): 0.6319388430384154\n",
      "          Validation Loss (standardized): 1.9123038816457942\n",
      "Epoch: 26, Loss (standarized): 0.6202095335246407\n",
      "          Validation Loss (standardized): 1.7855157843812115\n",
      "Epoch: 31, Loss (standarized): 0.6102918655793793\n",
      "          Validation Loss (standardized): 1.6801729041199807\n",
      "Epoch: 36, Loss (standarized): 0.5966455043511819\n",
      "          Validation Loss (standardized): 1.6046422210327718\n",
      "Epoch: 41, Loss (standarized): 0.5832944920726244\n",
      "          Validation Loss (standardized): 1.5704644087202664\n",
      "Epoch: 46, Loss (standarized): 0.5723498543799496\n",
      "          Validation Loss (standardized): 1.5618862774030227\n",
      "Epoch: 51, Loss (standarized): 0.560672875252648\n",
      "          Validation Loss (standardized): 1.567192388427891\n",
      "Epoch: 56, Loss (standarized): 0.5509366780787969\n",
      "          Validation Loss (standardized): 1.568181667856418\n",
      "Epoch: 61, Loss (standarized): 0.5420855305136474\n",
      "          Validation Loss (standardized): 1.5709714921316869\n",
      "Epoch: 66, Loss (standarized): 0.5339370062572446\n",
      "          Validation Loss (standardized): 1.572728753316312\n",
      "Epoch: 71, Loss (standarized): 0.5266934201495583\n",
      "          Validation Loss (standardized): 1.5883893750073192\n",
      "Epoch: 76, Loss (standarized): 0.520820134913455\n",
      "          Validation Loss (standardized): 1.5866577422597794\n",
      "Epoch: 81, Loss (standarized): 0.5154007249136138\n",
      "          Validation Loss (standardized): 1.5722461882235563\n",
      "Epoch: 86, Loss (standarized): 0.5097722500223605\n",
      "          Validation Loss (standardized): 1.568773971133749\n",
      "Epoch: 91, Loss (standarized): 0.5027788981386955\n",
      "          Validation Loss (standardized): 1.5716478661220188\n",
      "Epoch: 96, Loss (standarized): 0.4952309148661355\n",
      "          Validation Loss (standardized): 1.5723576788437095\n",
      "Final epoch: 100, Final loss (standarized): 0.4891472720842257\n",
      "Epoch: 1, Loss (standarized): 1.3791935298703302\n",
      "          Validation Loss (standardized): 1.1288562496844425\n",
      "Epoch: 6, Loss (standarized): 0.7494764244074079\n",
      "          Validation Loss (standardized): 1.5000695021453996\n",
      "Epoch: 11, Loss (standarized): 0.6689463554412141\n",
      "          Validation Loss (standardized): 1.9100693237078297\n",
      "Epoch: 16, Loss (standarized): 0.6474936457943362\n",
      "          Validation Loss (standardized): 2.0245953935569445\n",
      "Epoch: 21, Loss (standarized): 0.6355504304970039\n",
      "          Validation Loss (standardized): 1.9378704267028883\n",
      "Epoch: 26, Loss (standarized): 0.6249316035485348\n",
      "          Validation Loss (standardized): 1.7984343620329588\n",
      "Epoch: 31, Loss (standarized): 0.6129410953756451\n",
      "          Validation Loss (standardized): 1.6868957890192402\n",
      "Epoch: 36, Loss (standarized): 0.6013879312667912\n",
      "          Validation Loss (standardized): 1.616721943030481\n",
      "Epoch: 41, Loss (standarized): 0.5900540290059813\n",
      "          Validation Loss (standardized): 1.5715780035042481\n",
      "Epoch: 46, Loss (standarized): 0.579115475571745\n",
      "          Validation Loss (standardized): 1.564795716579943\n",
      "Epoch: 51, Loss (standarized): 0.5677625443752753\n",
      "          Validation Loss (standardized): 1.565364550335914\n",
      "Epoch: 56, Loss (standarized): 0.5577056724989764\n",
      "          Validation Loss (standardized): 1.560926534917256\n",
      "Epoch: 61, Loss (standarized): 0.5491798295419636\n",
      "          Validation Loss (standardized): 1.5591309811271785\n",
      "Epoch: 66, Loss (standarized): 0.5405925365178026\n",
      "          Validation Loss (standardized): 1.5638549254010576\n",
      "Epoch: 71, Loss (standarized): 0.5315698970661561\n",
      "          Validation Loss (standardized): 1.5548444578970129\n",
      "Epoch: 76, Loss (standarized): 0.5229478456145201\n",
      "          Validation Loss (standardized): 1.5464590037606372\n",
      "Epoch: 81, Loss (standarized): 0.5150751625136241\n",
      "          Validation Loss (standardized): 1.5543345587180202\n",
      "Epoch: 86, Loss (standarized): 0.5078548803657437\n",
      "          Validation Loss (standardized): 1.556630726274272\n",
      "Epoch: 91, Loss (standarized): 0.5009473065234007\n",
      "          Validation Loss (standardized): 1.5413828589069591\n",
      "Epoch: 96, Loss (standarized): 0.49446659266769405\n",
      "          Validation Loss (standardized): 1.549716026816495\n",
      "Final epoch: 100, Final loss (standarized): 0.489630022190404\n",
      "Epoch: 1, Loss (standarized): 1.2722131087629616\n",
      "          Validation Loss (standardized): 1.3167529588266516\n",
      "Epoch: 6, Loss (standarized): 0.7164597779187112\n",
      "          Validation Loss (standardized): 1.8937309245741216\n",
      "Epoch: 11, Loss (standarized): 0.6927250637449033\n",
      "          Validation Loss (standardized): 2.3080563163097914\n",
      "Epoch: 16, Loss (standarized): 0.6740271900936263\n",
      "          Validation Loss (standardized): 2.309465316930862\n",
      "Epoch: 21, Loss (standarized): 0.6236911986408209\n",
      "          Validation Loss (standardized): 2.0940482963790292\n",
      "Epoch: 26, Loss (standarized): 0.590071688391907\n",
      "          Validation Loss (standardized): 1.811159183888668\n",
      "Epoch: 31, Loss (standarized): 0.5594954973770787\n",
      "          Validation Loss (standardized): 1.559604485981081\n",
      "Epoch: 36, Loss (standarized): 0.5199164611957393\n",
      "          Validation Loss (standardized): 1.4907991513169272\n",
      "Epoch: 41, Loss (standarized): 0.47802177206712104\n",
      "          Validation Loss (standardized): 1.5468311735118128\n",
      "Epoch: 46, Loss (standarized): 0.43593161416079346\n",
      "          Validation Loss (standardized): 1.5420586512771983\n",
      "Epoch: 51, Loss (standarized): 0.3931927741391238\n",
      "          Validation Loss (standardized): 1.444761309763138\n",
      "Epoch: 56, Loss (standarized): 0.3516985049451758\n",
      "          Validation Loss (standardized): 1.3635165427109015\n",
      "Epoch: 61, Loss (standarized): 0.3130029445229115\n",
      "          Validation Loss (standardized): 1.3271846657504922\n",
      "Epoch: 66, Loss (standarized): 0.2792726509137455\n",
      "          Validation Loss (standardized): 1.2792536429226513\n",
      "Epoch: 71, Loss (standarized): 0.2509910849585328\n",
      "          Validation Loss (standardized): 1.1906785684236638\n",
      "Epoch: 76, Loss (standarized): 0.2277434055036163\n",
      "          Validation Loss (standardized): 1.116443108471229\n",
      "Epoch: 81, Loss (standarized): 0.20826790732840803\n",
      "          Validation Loss (standardized): 1.066083473700576\n",
      "Epoch: 86, Loss (standarized): 0.19176097761518152\n",
      "          Validation Loss (standardized): 1.0170202387306921\n",
      "Epoch: 91, Loss (standarized): 0.17814874482178122\n",
      "          Validation Loss (standardized): 0.9732051381822081\n",
      "Epoch: 96, Loss (standarized): 0.16679833884936776\n",
      "          Validation Loss (standardized): 0.9327491044131688\n",
      "Final epoch: 100, Final loss (standarized): 0.1591996137000701\n",
      "Epoch: 1, Loss (standarized): 1.3148985114958043\n",
      "          Validation Loss (standardized): 1.508719326983738\n",
      "Epoch: 6, Loss (standarized): 0.7231445038866874\n",
      "          Validation Loss (standardized): 1.7920093343790913\n",
      "Epoch: 11, Loss (standarized): 0.676455161425559\n",
      "          Validation Loss (standardized): 2.138234349784356\n",
      "Epoch: 16, Loss (standarized): 0.6415729256355919\n",
      "          Validation Loss (standardized): 2.1050177395576792\n",
      "Epoch: 21, Loss (standarized): 0.6142312130387773\n",
      "          Validation Loss (standardized): 1.8997321426825124\n",
      "Epoch: 26, Loss (standarized): 0.5947417163088675\n",
      "          Validation Loss (standardized): 1.6801926377376308\n",
      "Epoch: 31, Loss (standarized): 0.5739397830017859\n",
      "          Validation Loss (standardized): 1.5676410955211977\n",
      "Epoch: 36, Loss (standarized): 0.5486371268601932\n",
      "          Validation Loss (standardized): 1.5759660458599452\n",
      "Epoch: 41, Loss (standarized): 0.522245925819888\n",
      "          Validation Loss (standardized): 1.6114205162608457\n",
      "Epoch: 46, Loss (standarized): 0.4929885670233949\n",
      "          Validation Loss (standardized): 1.601258661873782\n",
      "Epoch: 51, Loss (standarized): 0.464141113449392\n",
      "          Validation Loss (standardized): 1.5716575626997333\n",
      "Epoch: 56, Loss (standarized): 0.4353188752608779\n",
      "          Validation Loss (standardized): 1.5382281655223364\n",
      "Epoch: 61, Loss (standarized): 0.407308945056771\n",
      "          Validation Loss (standardized): 1.4990161886257118\n",
      "Epoch: 66, Loss (standarized): 0.38008053696324384\n",
      "          Validation Loss (standardized): 1.4636954144679752\n",
      "Epoch: 71, Loss (standarized): 0.35454093815030674\n",
      "          Validation Loss (standardized): 1.428051583246048\n",
      "Epoch: 76, Loss (standarized): 0.3316156326143062\n",
      "          Validation Loss (standardized): 1.3965065471360654\n",
      "Epoch: 81, Loss (standarized): 0.31133490063676394\n",
      "          Validation Loss (standardized): 1.372555273357745\n",
      "Epoch: 86, Loss (standarized): 0.2949040631821667\n",
      "          Validation Loss (standardized): 1.3474672312419307\n",
      "Epoch: 91, Loss (standarized): 0.28165624616124957\n",
      "          Validation Loss (standardized): 1.327439606876128\n",
      "Epoch: 96, Loss (standarized): 0.2711165552553582\n",
      "          Validation Loss (standardized): 1.305896712554634\n",
      "Final epoch: 100, Final loss (standarized): 0.26470029683270907\n",
      "Epoch: 1, Loss (standarized): 0.8169645712556033\n",
      "          Validation Loss (standardized): 1.58749392830846\n",
      "Epoch: 6, Loss (standarized): 0.6764048667826571\n",
      "          Validation Loss (standardized): 2.253622029302244\n",
      "Epoch: 11, Loss (standarized): 0.6423820883750416\n",
      "          Validation Loss (standardized): 1.993820463306559\n",
      "Epoch: 16, Loss (standarized): 0.6039618045776073\n",
      "          Validation Loss (standardized): 1.5675232640207486\n",
      "Epoch: 21, Loss (standarized): 0.5765712511724821\n",
      "          Validation Loss (standardized): 1.518967693864598\n",
      "Epoch: 26, Loss (standarized): 0.540578247576858\n",
      "          Validation Loss (standardized): 1.64475075015213\n",
      "Epoch: 31, Loss (standarized): 0.5031099563888154\n",
      "          Validation Loss (standardized): 1.6631158330161238\n",
      "Epoch: 36, Loss (standarized): 0.45582347522047545\n",
      "          Validation Loss (standardized): 1.560269143674872\n",
      "Epoch: 41, Loss (standarized): 0.4048346174942955\n",
      "          Validation Loss (standardized): 1.4761267752221234\n",
      "Epoch: 46, Loss (standarized): 0.3500686645845367\n",
      "          Validation Loss (standardized): 1.4596462050363375\n",
      "Epoch: 51, Loss (standarized): 0.30107667831763246\n",
      "          Validation Loss (standardized): 1.4190659894912787\n",
      "Epoch: 56, Loss (standarized): 0.2624640565262654\n",
      "          Validation Loss (standardized): 1.320968397623473\n",
      "Epoch: 61, Loss (standarized): 0.23408235791389737\n",
      "          Validation Loss (standardized): 1.1944950128433747\n",
      "Epoch: 66, Loss (standarized): 0.21251420011345276\n",
      "          Validation Loss (standardized): 1.166966457866649\n",
      "Epoch: 71, Loss (standarized): 0.195917844954277\n",
      "          Validation Loss (standardized): 1.1096838757508158\n",
      "Epoch: 76, Loss (standarized): 0.18306442913768803\n",
      "          Validation Loss (standardized): 1.0389391279673037\n",
      "Epoch: 81, Loss (standarized): 0.17264527149622333\n",
      "          Validation Loss (standardized): 0.9975778945752647\n",
      "Epoch: 86, Loss (standarized): 0.1640715855219931\n",
      "          Validation Loss (standardized): 0.9502814277223925\n",
      "Epoch: 91, Loss (standarized): 0.15686390647547033\n",
      "          Validation Loss (standardized): 0.9168846109095476\n",
      "Epoch: 96, Loss (standarized): 0.15063796554940292\n",
      "          Validation Loss (standardized): 0.8765233697627012\n",
      "Final epoch: 100, Final loss (standarized): 0.1462958427573613\n",
      "Epoch: 1, Loss (standarized): 1.890957637347862\n",
      "          Validation Loss (standardized): 2.5027531344138425\n",
      "Epoch: 6, Loss (standarized): 0.7453675993825114\n",
      "          Validation Loss (standardized): 1.7850734996381579\n",
      "Epoch: 11, Loss (standarized): 0.7950677169809539\n",
      "          Validation Loss (standardized): 2.1745545063767104\n",
      "Epoch: 16, Loss (standarized): 0.7232915200352183\n",
      "          Validation Loss (standardized): 2.0720735321184\n",
      "Epoch: 21, Loss (standarized): 0.6440328586117293\n",
      "          Validation Loss (standardized): 1.7726865292494236\n",
      "Epoch: 26, Loss (standarized): 0.6238987051520188\n",
      "          Validation Loss (standardized): 1.6291456939398807\n",
      "Epoch: 31, Loss (standarized): 0.580179187244484\n",
      "          Validation Loss (standardized): 1.6315110387196545\n",
      "Epoch: 36, Loss (standarized): 0.5563368293633513\n",
      "          Validation Loss (standardized): 1.6358446450990278\n",
      "Epoch: 41, Loss (standarized): 0.52979275116646\n",
      "          Validation Loss (standardized): 1.5798479201854694\n",
      "Epoch: 46, Loss (standarized): 0.5025424927366651\n",
      "          Validation Loss (standardized): 1.5105378087070713\n",
      "Epoch: 51, Loss (standarized): 0.4780442200132601\n",
      "          Validation Loss (standardized): 1.4455053821999835\n",
      "Epoch: 56, Loss (standarized): 0.4523432501992563\n",
      "          Validation Loss (standardized): 1.4284125927860425\n",
      "Epoch: 61, Loss (standarized): 0.4281043185305969\n",
      "          Validation Loss (standardized): 1.4338015310631862\n",
      "Epoch: 66, Loss (standarized): 0.40379740321336965\n",
      "          Validation Loss (standardized): 1.398483760046689\n",
      "Epoch: 71, Loss (standarized): 0.37944931949414085\n",
      "          Validation Loss (standardized): 1.3527813523603736\n",
      "Epoch: 76, Loss (standarized): 0.35504903129956844\n",
      "          Validation Loss (standardized): 1.3473235467628302\n",
      "Epoch: 81, Loss (standarized): 0.3303959452265791\n",
      "          Validation Loss (standardized): 1.2964805717856724\n",
      "Epoch: 86, Loss (standarized): 0.3059353827684386\n",
      "          Validation Loss (standardized): 1.2176057172777606\n",
      "Epoch: 91, Loss (standarized): 0.2828834623956127\n",
      "          Validation Loss (standardized): 1.1915201279620844\n",
      "Epoch: 96, Loss (standarized): 0.26116378730760964\n",
      "          Validation Loss (standardized): 1.1608248999781021\n",
      "Final epoch: 100, Final loss (standarized): 0.24497286126825749\n",
      "Epoch: 1, Loss (standarized): 1.439038977199924\n",
      "          Validation Loss (standardized): 1.1833668427924544\n",
      "Epoch: 6, Loss (standarized): 0.6956485386163617\n",
      "          Validation Loss (standardized): 1.7187517835476753\n",
      "Epoch: 11, Loss (standarized): 0.6781617457422813\n",
      "          Validation Loss (standardized): 2.202760038439545\n",
      "Epoch: 16, Loss (standarized): 0.6616949787934787\n",
      "          Validation Loss (standardized): 2.3681580895627277\n",
      "Epoch: 21, Loss (standarized): 0.6438536658100994\n",
      "          Validation Loss (standardized): 2.3097623070565185\n",
      "Epoch: 26, Loss (standarized): 0.6168207682468223\n",
      "          Validation Loss (standardized): 2.1867925346095975\n",
      "Epoch: 31, Loss (standarized): 0.5845921384442669\n",
      "          Validation Loss (standardized): 2.0114783247658354\n",
      "Epoch: 36, Loss (standarized): 0.5554082282198267\n",
      "          Validation Loss (standardized): 1.8461445197443\n",
      "Epoch: 41, Loss (standarized): 0.5239749780398413\n",
      "          Validation Loss (standardized): 1.7314611912355382\n",
      "Epoch: 46, Loss (standarized): 0.49175156641880785\n",
      "          Validation Loss (standardized): 1.6472115439102166\n",
      "Epoch: 51, Loss (standarized): 0.45611142006136696\n",
      "          Validation Loss (standardized): 1.5994708554472816\n",
      "Epoch: 56, Loss (standarized): 0.41696768599077016\n",
      "          Validation Loss (standardized): 1.5840933224318532\n",
      "Epoch: 61, Loss (standarized): 0.3747657943712744\n",
      "          Validation Loss (standardized): 1.551162668379353\n",
      "Epoch: 66, Loss (standarized): 0.3327730363414293\n",
      "          Validation Loss (standardized): 1.5172513589033507\n",
      "Epoch: 71, Loss (standarized): 0.2943484159034084\n",
      "          Validation Loss (standardized): 1.456369547460517\n",
      "Epoch: 76, Loss (standarized): 0.2624093962567408\n",
      "          Validation Loss (standardized): 1.3642805266560958\n",
      "Epoch: 81, Loss (standarized): 0.2365165385037122\n",
      "          Validation Loss (standardized): 1.2684411214515683\n",
      "Epoch: 86, Loss (standarized): 0.2158517658542424\n",
      "          Validation Loss (standardized): 1.197617803741692\n",
      "Epoch: 91, Loss (standarized): 0.19916262529727363\n",
      "          Validation Loss (standardized): 1.147916931320174\n",
      "Epoch: 96, Loss (standarized): 0.18550587976436056\n",
      "          Validation Loss (standardized): 1.101170685366527\n",
      "Final epoch: 100, Final loss (standarized): 0.17585225994132342\n",
      "Epoch: 1, Loss (standarized): 1.3971511813986568\n",
      "          Validation Loss (standardized): 1.2713161385350222\n",
      "Epoch: 6, Loss (standarized): 0.7690186794419543\n",
      "          Validation Loss (standardized): 1.6295348137513275\n",
      "Epoch: 11, Loss (standarized): 0.7017150280336577\n",
      "          Validation Loss (standardized): 2.011723286359938\n",
      "Epoch: 16, Loss (standarized): 0.669592780777752\n",
      "          Validation Loss (standardized): 2.1168568304421824\n",
      "Epoch: 21, Loss (standarized): 0.647415233093428\n",
      "          Validation Loss (standardized): 2.0331325704455265\n",
      "Epoch: 26, Loss (standarized): 0.6212511866641492\n",
      "          Validation Loss (standardized): 1.9061302567491685\n",
      "Epoch: 31, Loss (standarized): 0.5987209337377699\n",
      "          Validation Loss (standardized): 1.7822962460055678\n",
      "Epoch: 36, Loss (standarized): 0.583357208200348\n",
      "          Validation Loss (standardized): 1.6918455697959693\n",
      "Epoch: 41, Loss (standarized): 0.5651346344579815\n",
      "          Validation Loss (standardized): 1.6301951791789477\n",
      "Epoch: 46, Loss (standarized): 0.5414005494225089\n",
      "          Validation Loss (standardized): 1.61952066607479\n",
      "Epoch: 51, Loss (standarized): 0.51474126502219\n",
      "          Validation Loss (standardized): 1.6603103938477988\n",
      "Epoch: 56, Loss (standarized): 0.4868507148463814\n",
      "          Validation Loss (standardized): 1.631295153529616\n",
      "Epoch: 61, Loss (standarized): 0.456816092053769\n",
      "          Validation Loss (standardized): 1.5506440921505145\n",
      "Epoch: 66, Loss (standarized): 0.42693926300449536\n",
      "          Validation Loss (standardized): 1.493258166709015\n",
      "Epoch: 71, Loss (standarized): 0.39665443309659254\n",
      "          Validation Loss (standardized): 1.4796774875159935\n",
      "Epoch: 76, Loss (standarized): 0.36765309612478186\n",
      "          Validation Loss (standardized): 1.4696716167887602\n",
      "Epoch: 81, Loss (standarized): 0.34159500362862977\n",
      "          Validation Loss (standardized): 1.4255336545015702\n",
      "Epoch: 86, Loss (standarized): 0.31877740165720997\n",
      "          Validation Loss (standardized): 1.3610429711434104\n",
      "Epoch: 91, Loss (standarized): 0.29925709432126646\n",
      "          Validation Loss (standardized): 1.317037004121772\n",
      "Epoch: 96, Loss (standarized): 0.28273198009094946\n",
      "          Validation Loss (standardized): 1.2949411978689913\n",
      "Final epoch: 100, Final loss (standarized): 0.2716333364304978\n",
      "Epoch: 1, Loss (standarized): 1.878251623698924\n",
      "          Validation Loss (standardized): 1.4171749130053186\n",
      "Epoch: 6, Loss (standarized): 0.7870670324885596\n",
      "          Validation Loss (standardized): 1.4873099705537902\n",
      "Epoch: 11, Loss (standarized): 0.6929426246986702\n",
      "          Validation Loss (standardized): 2.046340963567294\n",
      "Epoch: 16, Loss (standarized): 0.6753669567704269\n",
      "          Validation Loss (standardized): 2.358884533476955\n",
      "Epoch: 21, Loss (standarized): 0.641059377569516\n",
      "          Validation Loss (standardized): 2.4048813336164385\n",
      "Epoch: 26, Loss (standarized): 0.6139605600478572\n",
      "          Validation Loss (standardized): 2.3366549585078515\n",
      "Epoch: 31, Loss (standarized): 0.5834067877530639\n",
      "          Validation Loss (standardized): 2.195819948764804\n",
      "Epoch: 36, Loss (standarized): 0.5547411070452383\n",
      "          Validation Loss (standardized): 2.0497430310118223\n",
      "Epoch: 41, Loss (standarized): 0.5281371541192849\n",
      "          Validation Loss (standardized): 1.9229017550827001\n",
      "Epoch: 46, Loss (standarized): 0.5011680360730076\n",
      "          Validation Loss (standardized): 1.8230297439372458\n",
      "Epoch: 51, Loss (standarized): 0.4757275445980383\n",
      "          Validation Loss (standardized): 1.7520327164264495\n",
      "Epoch: 56, Loss (standarized): 0.4487660342298756\n",
      "          Validation Loss (standardized): 1.694626840820742\n",
      "Epoch: 61, Loss (standarized): 0.4202755751050465\n",
      "          Validation Loss (standardized): 1.655230603173688\n",
      "Epoch: 66, Loss (standarized): 0.3900965021968724\n",
      "          Validation Loss (standardized): 1.601740356770512\n",
      "Epoch: 71, Loss (standarized): 0.357100241261199\n",
      "          Validation Loss (standardized): 1.5194204680674723\n",
      "Epoch: 76, Loss (standarized): 0.3230533495551333\n",
      "          Validation Loss (standardized): 1.4511993848639917\n",
      "Epoch: 81, Loss (standarized): 0.2908525512118663\n",
      "          Validation Loss (standardized): 1.3953454691296383\n",
      "Epoch: 86, Loss (standarized): 0.2628430501411891\n",
      "          Validation Loss (standardized): 1.3389118665214383\n",
      "Epoch: 91, Loss (standarized): 0.23956732131962372\n",
      "          Validation Loss (standardized): 1.2773701522769194\n",
      "Epoch: 96, Loss (standarized): 0.22052319996176742\n",
      "          Validation Loss (standardized): 1.2285134643495972\n",
      "Final epoch: 100, Final loss (standarized): 0.208010938097298\n",
      "Epoch: 1, Loss (standarized): 1.8558190959286183\n",
      "          Validation Loss (standardized): 1.170498944077367\n",
      "Epoch: 6, Loss (standarized): 0.76770434974739\n",
      "          Validation Loss (standardized): 1.367525348240164\n",
      "Epoch: 11, Loss (standarized): 0.6807920916890586\n",
      "          Validation Loss (standardized): 1.8824563076093441\n",
      "Epoch: 16, Loss (standarized): 0.6257718350939243\n",
      "          Validation Loss (standardized): 2.0679724901050167\n",
      "Epoch: 21, Loss (standarized): 0.6105975753057156\n",
      "          Validation Loss (standardized): 2.1323932553655793\n",
      "Epoch: 26, Loss (standarized): 0.5889614464876056\n",
      "          Validation Loss (standardized): 2.081583807145882\n",
      "Epoch: 31, Loss (standarized): 0.5609153061600582\n",
      "          Validation Loss (standardized): 2.0052677394188962\n",
      "Epoch: 36, Loss (standarized): 0.5363760274775284\n",
      "          Validation Loss (standardized): 1.9111769719904537\n",
      "Epoch: 41, Loss (standarized): 0.5110016368921133\n",
      "          Validation Loss (standardized): 1.7983691752743272\n",
      "Epoch: 46, Loss (standarized): 0.48542824465575707\n",
      "          Validation Loss (standardized): 1.7052175484476297\n",
      "Epoch: 51, Loss (standarized): 0.46148035549627464\n",
      "          Validation Loss (standardized): 1.6602086722986187\n",
      "Epoch: 56, Loss (standarized): 0.4401403417219974\n",
      "          Validation Loss (standardized): 1.6529384753613703\n",
      "Epoch: 61, Loss (standarized): 0.4200589201676737\n",
      "          Validation Loss (standardized): 1.656413576932066\n",
      "Epoch: 66, Loss (standarized): 0.39902658792462115\n",
      "          Validation Loss (standardized): 1.6483686760790877\n",
      "Epoch: 71, Loss (standarized): 0.3760520984094121\n",
      "          Validation Loss (standardized): 1.6387480366227336\n",
      "Epoch: 76, Loss (standarized): 0.35007861798898615\n",
      "          Validation Loss (standardized): 1.6456610457289338\n",
      "Epoch: 81, Loss (standarized): 0.32206629451559465\n",
      "          Validation Loss (standardized): 1.6541303527802103\n",
      "Epoch: 86, Loss (standarized): 0.2944076067441611\n",
      "          Validation Loss (standardized): 1.6388517442019284\n",
      "Epoch: 91, Loss (standarized): 0.26947548172410934\n",
      "          Validation Loss (standardized): 1.6014304994736421\n",
      "Epoch: 96, Loss (standarized): 0.24881186450251605\n",
      "          Validation Loss (standardized): 1.5460541400114398\n",
      "Final epoch: 100, Final loss (standarized): 0.2349827837181645\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "archs = [[2, 20, 20, 3]]\n",
    "funs = [sigmoid, tanh, relu, leaky_relu]\n",
    "fun_derivs = [sigmoid_deriv, tanh_deriv, relu_deriv, leaky_relu_deriv]\n",
    "dropouts = [0] # Testy dropout'u usunąłem\n",
    "early_stops = [0, 50, 100, 200, 500]  # Patience = 1 jest za mały tak samo = 5 oraz 10 i 20, więc usunąłem\n",
    "l1_vals = [0, 0.01, 0.001, 0.0001]\n",
    "l2_vals = [0, 0.01, 0.001, 0.0001]\n",
    "initialization = [\"xavier\", \"xavier\", \"he\", \"he\"]\n",
    "results = { \"Arch\": [],\n",
    "            \"Fun\": [],\n",
    "            \"Fscore\": [],\n",
    "            \"Train_results\": [], \n",
    "            \"Dropout\": [],\n",
    "            \"Patience\": [],\n",
    "            \"Net\": [],\n",
    "            \"L1\": [],\n",
    "            \"L2\": [],}\n",
    "\n",
    "for arch in archs:\n",
    "    for i in range(len(funs)):\n",
    "        for dropout in dropouts:\n",
    "            for early_stop in early_stops:\n",
    "                for l1 in l1_vals:\n",
    "                    for l2 in l2_vals:\n",
    "                        net = MLP(arch, act_fun=funs[i], act_derivative=fun_derivs[i], out_fun=softmax, out_derivative=linear_deriv, init_type=initialization[i], dropout_rate=dropout)\n",
    "                        curr_result = net.train_classify(x = x_train, y = y_train, loss_fun=cross_entropy, epochs = 2000, optimizer=Adam(), batch_size=None, early_stopping_patience=early_stop, val_x=x_test, val_y=y_test, l1_lambda=l1, l2_lambda=l2)\n",
    "                        y_pred = net.predict(x_test)\n",
    "                        y_pred = from_one_hot_to_label(one_hot_from_probabilities(y_pred))\n",
    "                        fscore = f1_score(from_one_hot_to_label(y_test), y_pred)\n",
    "                        results[\"Arch\"].append(arch)\n",
    "                        results[\"Fun\"].append(funs[i])\n",
    "                        results[\"Fscore\"].append(fscore)\n",
    "                        results[\"Train_results\"].append(curr_result)\n",
    "                        results[\"Dropout\"].append(dropout)\n",
    "                        results[\"Patience\"].append(early_stop)\n",
    "                        results[\"Net\"].append(net)\n",
    "                        results[\"L1\"].append(l1)\n",
    "                        results[\"L2\"].append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "255d5815-aee0-45e0-887d-e2ff5f674fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Fscore</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>[1.016583566600321, 0.9520466984244051, 0.9041...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE69C0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>[0.9411144394490603, 0.8862046523558236, 0.852...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05F4D070&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>[1.1128782493420428, 1.015657261536768, 0.9431...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05FF4D70&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>[1.4937864491457113, 1.343721718329529, 1.2217...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010B7DD0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>[1.0725154212058088, 0.9911896877722811, 0.929...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE4C50&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>[1.3851567661285107, 1.235790812738661, 1.1083...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04B19A30&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>[1.0707162573606717, 1.0051110422124407, 0.956...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A7B560&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[0.9655826707994906, 0.9133646557381855, 0.877...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A4B350&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[0.9293391806694632, 0.8975654437625813, 0.874...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04EDB9E0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.3295464030813786, 1.1870921242219394, 1.077...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E7E235A90&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.586399508793111, 1.429241394760413, 1.28975...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05FFD640&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.4260659311028612, 1.2672998971884437, 1.127...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE6BD0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.073455400453543, 0.9833381433596371, 0.9207...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010B7320&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.260099449756772, 1.147256027921337, 1.06236...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05FF4FE0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.2446938336290851, 1.1009422856898081, 0.998...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE5AF0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.252426265734988, 1.130617125660706, 1.03637...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04ACCCB0&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.1493315827710644, 1.0538772853359726, 0.980...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04C47980&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.9641363201226434, 1.7472106452817535, 1.561...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A4BC80&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.1475048943837576, 1.0199471097361243, 0.920...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE4F50&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>[1.8047496845383273, 1.6438606094166084, 1.494...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E79F8E990&gt;</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Arch                                       Fun    Fscore  \\\n",
       "36  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.117065   \n",
       "20  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.117065   \n",
       "39  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.117065   \n",
       "71  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.117065   \n",
       "38  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.117065   \n",
       "70  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.117065   \n",
       "37  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.117065   \n",
       "6   [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "7   [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "53  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "4   [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "69  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "68  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "52  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "54  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "22  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "21  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "55  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "23  [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "5   [2, 20, 20, 3]  <function sigmoid at 0x0000029E017B67A0>  0.190986   \n",
       "\n",
       "                                        Train_results  Dropout  Patience  \\\n",
       "36  [1.016583566600321, 0.9520466984244051, 0.9041...        0       100   \n",
       "20  [0.9411144394490603, 0.8862046523558236, 0.852...        0        50   \n",
       "39  [1.1128782493420428, 1.015657261536768, 0.9431...        0       100   \n",
       "71  [1.4937864491457113, 1.343721718329529, 1.2217...        0       500   \n",
       "38  [1.0725154212058088, 0.9911896877722811, 0.929...        0       100   \n",
       "70  [1.3851567661285107, 1.235790812738661, 1.1083...        0       500   \n",
       "37  [1.0707162573606717, 1.0051110422124407, 0.956...        0       100   \n",
       "6   [0.9655826707994906, 0.9133646557381855, 0.877...        0         0   \n",
       "7   [0.9293391806694632, 0.8975654437625813, 0.874...        0         0   \n",
       "53  [1.3295464030813786, 1.1870921242219394, 1.077...        0       200   \n",
       "4   [1.586399508793111, 1.429241394760413, 1.28975...        0         0   \n",
       "69  [1.4260659311028612, 1.2672998971884437, 1.127...        0       500   \n",
       "68  [1.073455400453543, 0.9833381433596371, 0.9207...        0       500   \n",
       "52  [1.260099449756772, 1.147256027921337, 1.06236...        0       200   \n",
       "54  [1.2446938336290851, 1.1009422856898081, 0.998...        0       200   \n",
       "22  [1.252426265734988, 1.130617125660706, 1.03637...        0        50   \n",
       "21  [1.1493315827710644, 1.0538772853359726, 0.980...        0        50   \n",
       "55  [1.9641363201226434, 1.7472106452817535, 1.561...        0       200   \n",
       "23  [1.1475048943837576, 1.0199471097361243, 0.920...        0        50   \n",
       "5   [1.8047496845383273, 1.6438606094166084, 1.494...        0         0   \n",
       "\n",
       "                                            Net    L1      L2  \n",
       "36  <__main__.MLP object at 0x0000029E04BE69C0>  0.01  0.0000  \n",
       "20  <__main__.MLP object at 0x0000029E05F4D070>  0.01  0.0000  \n",
       "39  <__main__.MLP object at 0x0000029E05FF4D70>  0.01  0.0001  \n",
       "71  <__main__.MLP object at 0x0000029E010B7DD0>  0.01  0.0001  \n",
       "38  <__main__.MLP object at 0x0000029E04BE4C50>  0.01  0.0010  \n",
       "70  <__main__.MLP object at 0x0000029E04B19A30>  0.01  0.0010  \n",
       "37  <__main__.MLP object at 0x0000029E03A7B560>  0.01  0.0100  \n",
       "6   <__main__.MLP object at 0x0000029E03A4B350>  0.01  0.0010  \n",
       "7   <__main__.MLP object at 0x0000029E04EDB9E0>  0.01  0.0001  \n",
       "53  <__main__.MLP object at 0x0000029E7E235A90>  0.01  0.0100  \n",
       "4   <__main__.MLP object at 0x0000029E05FFD640>  0.01  0.0000  \n",
       "69  <__main__.MLP object at 0x0000029E04BE6BD0>  0.01  0.0100  \n",
       "68  <__main__.MLP object at 0x0000029E010B7320>  0.01  0.0000  \n",
       "52  <__main__.MLP object at 0x0000029E05FF4FE0>  0.01  0.0000  \n",
       "54  <__main__.MLP object at 0x0000029E04BE5AF0>  0.01  0.0010  \n",
       "22  <__main__.MLP object at 0x0000029E04ACCCB0>  0.01  0.0010  \n",
       "21  <__main__.MLP object at 0x0000029E04C47980>  0.01  0.0100  \n",
       "55  <__main__.MLP object at 0x0000029E03A4BC80>  0.01  0.0001  \n",
       "23  <__main__.MLP object at 0x0000029E04BE4F50>  0.01  0.0001  \n",
       "5   <__main__.MLP object at 0x0000029E79F8E990>  0.01  0.0100  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(\"Fscore\")\n",
    "results_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "877a9f8c-7cb2-41d3-8da4-570bc320c469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Fscore</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.571264</td>\n",
       "      <td>[1.1100246590823728, 0.9592976401424522, 0.859...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010B7020&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.576032</td>\n",
       "      <td>[1.2135693988401814, 1.0078688121734374, 0.857...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01781190&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.577753</td>\n",
       "      <td>[1.0363888256668528, 0.8830860578217514, 0.795...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04BE5E50&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.588151</td>\n",
       "      <td>[0.7844291292358186, 0.7140239901901263, 0.682...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01783E60&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.594886</td>\n",
       "      <td>[1.2829296578740228, 1.0753318205793574, 0.935...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A48440&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.596207</td>\n",
       "      <td>[1.0646694056669324, 0.935867113709947, 0.8438...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010B72F0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.599817</td>\n",
       "      <td>[0.9866450189045531, 0.8175914422206566, 0.730...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E017816D0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.602747</td>\n",
       "      <td>[1.410480519922504, 1.2197260927293212, 1.0817...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010B55E0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.607308</td>\n",
       "      <td>[1.014689538914955, 0.816431938570972, 0.72620...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010B63F0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.608668</td>\n",
       "      <td>[1.1334478290199292, 0.9917464475385128, 0.888...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A48800&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.611608</td>\n",
       "      <td>[1.0352847691754075, 0.9033094577821807, 0.819...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01783950&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.611929</td>\n",
       "      <td>[1.2564079821231326, 1.042537038959964, 0.8935...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A35B50&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.612811</td>\n",
       "      <td>[1.5170703536481147, 1.3017246935298357, 1.128...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E017839B0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.619998</td>\n",
       "      <td>[1.086005464077841, 0.9137379549652894, 0.8048...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01781100&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.634311</td>\n",
       "      <td>[1.1756480013917676, 0.9934866940792986, 0.871...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010B4F50&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.647385</td>\n",
       "      <td>[0.9580060692716835, 0.878617853875417, 0.8198...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01781C10&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.651483</td>\n",
       "      <td>[1.0644057437900867, 0.9193936363185612, 0.816...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0154E930&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.656929</td>\n",
       "      <td>[1.131236166498267, 0.9925442633679371, 0.8811...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010B57C0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.683804</td>\n",
       "      <td>[1.0033457130092533, 0.8710092050702366, 0.789...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01781580&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>[2, 20, 20, 3]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.692310</td>\n",
       "      <td>[1.0717929860444713, 0.9664421056682693, 0.887...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05FF4AA0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Arch                                          Fun    Fscore  \\\n",
       "174  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.571264   \n",
       "240  [2, 20, 20, 3]  <function leaky_relu at 0x0000029E039CE980>  0.576032   \n",
       "296  [2, 20, 20, 3]  <function leaky_relu at 0x0000029E039CE980>  0.577753   \n",
       "234  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.588151   \n",
       "203  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.594886   \n",
       "176  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.596207   \n",
       "226  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.599817   \n",
       "255  [2, 20, 20, 3]  <function leaky_relu at 0x0000029E039CE980>  0.602747   \n",
       "162  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.607308   \n",
       "160  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.608668   \n",
       "204  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.611608   \n",
       "303  [2, 20, 20, 3]  <function leaky_relu at 0x0000029E039CE980>  0.611929   \n",
       "239  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.612811   \n",
       "188  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.619998   \n",
       "178  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.634311   \n",
       "252  [2, 20, 20, 3]  <function leaky_relu at 0x0000029E039CE980>  0.647385   \n",
       "270  [2, 20, 20, 3]  <function leaky_relu at 0x0000029E039CE980>  0.651483   \n",
       "268  [2, 20, 20, 3]  <function leaky_relu at 0x0000029E039CE980>  0.656929   \n",
       "220  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.683804   \n",
       "172  [2, 20, 20, 3]        <function relu at 0x0000029E039CF2E0>  0.692310   \n",
       "\n",
       "                                         Train_results  Dropout  Patience  \\\n",
       "174  [1.1100246590823728, 0.9592976401424522, 0.859...        0         0   \n",
       "240  [1.2135693988401814, 1.0078688121734374, 0.857...        0         0   \n",
       "296  [1.0363888256668528, 0.8830860578217514, 0.795...        0       200   \n",
       "234  [0.7844291292358186, 0.7140239901901263, 0.682...        0       500   \n",
       "203  [1.2829296578740228, 1.0753318205793574, 0.935...        0       100   \n",
       "176  [1.0646694056669324, 0.935867113709947, 0.8438...        0        50   \n",
       "226  [0.9866450189045531, 0.8175914422206566, 0.730...        0       500   \n",
       "255  [1.410480519922504, 1.2197260927293212, 1.0817...        0         0   \n",
       "162  [1.014689538914955, 0.816431938570972, 0.72620...        0         0   \n",
       "160  [1.1334478290199292, 0.9917464475385128, 0.888...        0         0   \n",
       "204  [1.0352847691754075, 0.9033094577821807, 0.819...        0       100   \n",
       "303  [1.2564079821231326, 1.042537038959964, 0.8935...        0       200   \n",
       "239  [1.5170703536481147, 1.3017246935298357, 1.128...        0       500   \n",
       "188  [1.086005464077841, 0.9137379549652894, 0.8048...        0        50   \n",
       "178  [1.1756480013917676, 0.9934866940792986, 0.871...        0        50   \n",
       "252  [0.9580060692716835, 0.878617853875417, 0.8198...        0         0   \n",
       "270  [1.0644057437900867, 0.9193936363185612, 0.816...        0        50   \n",
       "268  [1.131236166498267, 0.9925442633679371, 0.8811...        0        50   \n",
       "220  [1.0033457130092533, 0.8710092050702366, 0.789...        0       200   \n",
       "172  [1.0717929860444713, 0.9664421056682693, 0.887...        0         0   \n",
       "\n",
       "                                             Net      L1      L2  \n",
       "174  <__main__.MLP object at 0x0000029E010B7020>  0.0001  0.0010  \n",
       "240  <__main__.MLP object at 0x0000029E01781190>  0.0000  0.0000  \n",
       "296  <__main__.MLP object at 0x0000029E04BE5E50>  0.0010  0.0000  \n",
       "234  <__main__.MLP object at 0x0000029E01783E60>  0.0010  0.0010  \n",
       "203  <__main__.MLP object at 0x0000029E03A48440>  0.0010  0.0001  \n",
       "176  <__main__.MLP object at 0x0000029E010B72F0>  0.0000  0.0000  \n",
       "226  <__main__.MLP object at 0x0000029E017816D0>  0.0000  0.0010  \n",
       "255  <__main__.MLP object at 0x0000029E010B55E0>  0.0001  0.0001  \n",
       "162  <__main__.MLP object at 0x0000029E010B63F0>  0.0000  0.0010  \n",
       "160  <__main__.MLP object at 0x0000029E03A48800>  0.0000  0.0000  \n",
       "204  <__main__.MLP object at 0x0000029E01783950>  0.0001  0.0000  \n",
       "303  <__main__.MLP object at 0x0000029E03A35B50>  0.0001  0.0001  \n",
       "239  <__main__.MLP object at 0x0000029E017839B0>  0.0001  0.0001  \n",
       "188  <__main__.MLP object at 0x0000029E01781100>  0.0001  0.0000  \n",
       "178  <__main__.MLP object at 0x0000029E010B4F50>  0.0000  0.0010  \n",
       "252  <__main__.MLP object at 0x0000029E01781C10>  0.0001  0.0000  \n",
       "270  <__main__.MLP object at 0x0000029E0154E930>  0.0001  0.0010  \n",
       "268  <__main__.MLP object at 0x0000029E010B57C0>  0.0001  0.0000  \n",
       "220  <__main__.MLP object at 0x0000029E01781580>  0.0001  0.0000  \n",
       "172  <__main__.MLP object at 0x0000029E05FF4AA0>  0.0001  0.0000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c50737-947d-406d-8d2b-8ce2ce9e0ba2",
   "metadata": {},
   "source": [
    "## Dane xor3-balance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5d76d-ddf8-440c-8921-373fc45b5588",
   "metadata": {},
   "source": [
    "### Pobranie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "96ecf56b-c6a0-471e-af8a-b3442a659d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobieramy dane\n",
    "data_train = pd.read_csv(\"../Data/classification/xor3-balance-training.csv\").to_numpy()\n",
    "x_train = data_train[:, 0:2].reshape(-1, 2)\n",
    "y_train = one_hot(np.int64(data_train[:, 2]))\n",
    "\n",
    "data_test = pd.read_csv(\"../Data/classification/xor3-balance-test.csv\").to_numpy()\n",
    "x_test = data_test[:, 0:2].reshape(-1, 2)\n",
    "y_test = one_hot(np.int64(data_test[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "da02eaf1-0767-46cb-9586-cee2597b047b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-86.23096328, -45.01857441,   0.        ],\n",
       "       [ 60.88322946,  50.77961916,   0.        ],\n",
       "       [ -8.72861184,   5.85191385,   0.        ],\n",
       "       ...,\n",
       "       [ 17.16453284,  89.25944283,   1.        ],\n",
       "       [ 22.12683172, -51.50079206,   1.        ],\n",
       "       [-60.08537863,  -8.76080655,   1.        ]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ec5d514d-6abd-4cdc-81db-570cbf327a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 3)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4dbe4fa4-8cde-4368-a5bf-8590cde6b802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train[:, 0], x_train[:, 1], c = data_train[:, 2], s = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc4872b-6f90-4f9b-a27e-65437b202f79",
   "metadata": {},
   "source": [
    "### Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bbdaa11b-2891-4033-b506-13d370cddb78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss (standarized): 0.9990982381917314\n",
      "Epoch: 2, Loss (standarized): 0.7964175200920551\n",
      "Epoch: 3, Loss (standarized): 0.6296096656335128\n",
      "Epoch: 4, Loss (standarized): 0.4980642885028339\n",
      "Epoch: 5, Loss (standarized): 0.39863400191167564\n",
      "Epoch: 6, Loss (standarized): 0.32637154240839644\n",
      "Epoch: 7, Loss (standarized): 0.2757033791037677\n",
      "Epoch: 8, Loss (standarized): 0.24137139388248682\n",
      "Epoch: 9, Loss (standarized): 0.21894060245019112\n",
      "Epoch: 10, Loss (standarized): 0.20493543161701755\n",
      "Epoch: 11, Loss (standarized): 0.19676016316697295\n",
      "Epoch: 12, Loss (standarized): 0.19253550213400017\n",
      "Epoch: 13, Loss (standarized): 0.19092757337638933\n",
      "Epoch: 14, Loss (standarized): 0.19100167841415897\n",
      "Epoch: 15, Loss (standarized): 0.1921086236642358\n",
      "Epoch: 16, Loss (standarized): 0.19380080578188694\n",
      "Epoch: 17, Loss (standarized): 0.19577202870706178\n",
      "Epoch: 18, Loss (standarized): 0.19781502519943006\n",
      "Epoch: 19, Loss (standarized): 0.1997917198666088\n",
      "Epoch: 20, Loss (standarized): 0.20161248257809022\n",
      "Final epoch: 20, Final loss (standarized): 0.20161248257809022\n",
      "Epoch: 1, Loss (standarized): 0.9229133991340521\n",
      "Epoch: 2, Loss (standarized): 0.7016916531504088\n",
      "Epoch: 3, Loss (standarized): 0.531728368887256\n",
      "Epoch: 4, Loss (standarized): 0.4086400954008611\n",
      "Epoch: 5, Loss (standarized): 0.32414636696607113\n",
      "Epoch: 6, Loss (standarized): 0.2687660526615738\n",
      "Epoch: 7, Loss (standarized): 0.2339180718254913\n",
      "Epoch: 8, Loss (standarized): 0.21288238331264026\n",
      "Epoch: 9, Loss (standarized): 0.20084994493388394\n",
      "Epoch: 10, Loss (standarized): 0.19455675428534994\n",
      "Epoch: 11, Loss (standarized): 0.19185028338326918\n",
      "Epoch: 12, Loss (standarized): 0.19132991496345234\n",
      "Epoch: 13, Loss (standarized): 0.19208883460037246\n",
      "Epoch: 14, Loss (standarized): 0.1935408388106873\n",
      "Epoch: 15, Loss (standarized): 0.19530764264539247\n",
      "Epoch: 16, Loss (standarized): 0.19714642027433626\n",
      "Epoch: 17, Loss (standarized): 0.19890328485100778\n",
      "Epoch: 18, Loss (standarized): 0.2004832701904619\n",
      "Epoch: 19, Loss (standarized): 0.201830810019013\n",
      "Epoch: 20, Loss (standarized): 0.20291692594993108\n",
      "Final epoch: 20, Final loss (standarized): 0.20291692594993108\n",
      "Epoch: 1, Loss (standarized): 0.9364754199642469\n",
      "Epoch: 2, Loss (standarized): 0.7145080030917823\n",
      "Epoch: 3, Loss (standarized): 0.5414256265333177\n",
      "Epoch: 4, Loss (standarized): 0.41402108294914136\n",
      "Epoch: 5, Loss (standarized): 0.32547455444006484\n",
      "Epoch: 6, Loss (standarized): 0.2671824922492057\n",
      "Epoch: 7, Loss (standarized): 0.23078505935342503\n",
      "Epoch: 8, Loss (standarized): 0.20938721978504635\n",
      "Epoch: 9, Loss (standarized): 0.19786268312691435\n",
      "Epoch: 10, Loss (standarized): 0.19263388866011485\n",
      "Epoch: 11, Loss (standarized): 0.19129401008129615\n",
      "Epoch: 12, Loss (standarized): 0.19225657156158318\n",
      "Epoch: 13, Loss (standarized): 0.1944881649769267\n",
      "Epoch: 14, Loss (standarized): 0.19732167088136884\n",
      "Epoch: 15, Loss (standarized): 0.20033096991923752\n",
      "Epoch: 16, Loss (standarized): 0.20324836278629627\n",
      "Epoch: 17, Loss (standarized): 0.2059104632162346\n",
      "Epoch: 18, Loss (standarized): 0.20822276311344645\n",
      "Epoch: 19, Loss (standarized): 0.21013637723573003\n",
      "Epoch: 20, Loss (standarized): 0.21163272881149833\n",
      "Final epoch: 20, Final loss (standarized): 0.21163272881149833\n",
      "Epoch: 1, Loss (standarized): 0.5522074756855709\n",
      "Epoch: 2, Loss (standarized): 0.4275996792812096\n",
      "Epoch: 3, Loss (standarized): 0.33774653654229797\n",
      "Epoch: 4, Loss (standarized): 0.27653842317852756\n",
      "Epoch: 5, Loss (standarized): 0.23709317420975076\n",
      "Epoch: 6, Loss (standarized): 0.21318026595726508\n",
      "Epoch: 7, Loss (standarized): 0.19983599790672635\n",
      "Epoch: 8, Loss (standarized): 0.19340300471081512\n",
      "Epoch: 9, Loss (standarized): 0.1913147497524688\n",
      "Epoch: 10, Loss (standarized): 0.1918244577725764\n",
      "Epoch: 11, Loss (standarized): 0.19376707548351954\n",
      "Epoch: 12, Loss (standarized): 0.1963779318028782\n",
      "Epoch: 13, Loss (standarized): 0.19916389049527095\n",
      "Epoch: 14, Loss (standarized): 0.2018149155423046\n",
      "Epoch: 15, Loss (standarized): 0.20414429192019282\n",
      "Epoch: 16, Loss (standarized): 0.20604839801551417\n",
      "Epoch: 17, Loss (standarized): 0.20747961286120575\n",
      "Epoch: 18, Loss (standarized): 0.20842801451190351\n",
      "Epoch: 19, Loss (standarized): 0.20890896734257106\n",
      "Epoch: 20, Loss (standarized): 0.20895465909783223\n",
      "Final epoch: 20, Final loss (standarized): 0.20895465909783223\n",
      "Epoch: 1, Loss (standarized): 0.9976886446436103\n",
      "Epoch: 2, Loss (standarized): 0.8004593799603155\n",
      "Epoch: 3, Loss (standarized): 0.635183701723299\n",
      "Epoch: 4, Loss (standarized): 0.5034018581545041\n",
      "Epoch: 5, Loss (standarized): 0.40295164847528453\n",
      "Epoch: 6, Loss (standarized): 0.32994879272992905\n",
      "Epoch: 7, Loss (standarized): 0.27914901035464346\n",
      "Epoch: 8, Loss (standarized): 0.24497911186241775\n",
      "Epoch: 9, Loss (standarized): 0.2227062470128496\n",
      "Epoch: 10, Loss (standarized): 0.2085962329737917\n",
      "Epoch: 11, Loss (standarized): 0.20000984899126312\n",
      "Epoch: 12, Loss (standarized): 0.19505870978190387\n",
      "Epoch: 13, Loss (standarized): 0.1924873751639066\n",
      "Epoch: 14, Loss (standarized): 0.1914134200223355\n",
      "Epoch: 15, Loss (standarized): 0.19125310268488105\n",
      "Epoch: 16, Loss (standarized): 0.1916101668395604\n",
      "Epoch: 17, Loss (standarized): 0.19222861490939888\n",
      "Epoch: 18, Loss (standarized): 0.19293045569184594\n",
      "Epoch: 19, Loss (standarized): 0.1936004776800966\n",
      "Epoch: 20, Loss (standarized): 0.194166354698207\n",
      "Final epoch: 20, Final loss (standarized): 0.194166354698207\n",
      "Epoch: 1, Loss (standarized): 0.7158060029084902\n",
      "Epoch: 2, Loss (standarized): 0.5587248356720222\n",
      "Epoch: 3, Loss (standarized): 0.4395019576185092\n",
      "Epoch: 4, Loss (standarized): 0.3534820122545889\n",
      "Epoch: 5, Loss (standarized): 0.2937665956913522\n",
      "Epoch: 6, Loss (standarized): 0.2536916704632983\n",
      "Epoch: 7, Loss (standarized): 0.22767015733423104\n",
      "Epoch: 8, Loss (standarized): 0.21131772657880116\n",
      "Epoch: 9, Loss (standarized): 0.20141796636773907\n",
      "Epoch: 10, Loss (standarized): 0.19575211437135956\n",
      "Epoch: 11, Loss (standarized): 0.1927952782011611\n",
      "Epoch: 12, Loss (standarized): 0.19152857586536204\n",
      "Epoch: 13, Loss (standarized): 0.19127663508141485\n",
      "Epoch: 14, Loss (standarized): 0.19158555479804862\n",
      "Epoch: 15, Loss (standarized): 0.1921562544508788\n",
      "Epoch: 16, Loss (standarized): 0.19279705647987405\n",
      "Epoch: 17, Loss (standarized): 0.1933905073579911\n",
      "Epoch: 18, Loss (standarized): 0.19387287754031143\n",
      "Epoch: 19, Loss (standarized): 0.19421135095769107\n",
      "Epoch: 20, Loss (standarized): 0.19439683992333845\n",
      "Final epoch: 20, Final loss (standarized): 0.19439683992333845\n",
      "Epoch: 1, Loss (standarized): 0.5164350732303622\n",
      "Epoch: 2, Loss (standarized): 0.41417624473115666\n",
      "Epoch: 3, Loss (standarized): 0.3386378292512494\n",
      "Epoch: 4, Loss (standarized): 0.284105615289073\n",
      "Epoch: 5, Loss (standarized): 0.2465044712996744\n",
      "Epoch: 6, Loss (standarized): 0.22190091543361495\n",
      "Epoch: 7, Loss (standarized): 0.20667065564279494\n",
      "Epoch: 8, Loss (standarized): 0.19789398972986982\n",
      "Epoch: 9, Loss (standarized): 0.1933889594310669\n",
      "Epoch: 10, Loss (standarized): 0.19156733357228914\n",
      "Epoch: 11, Loss (standarized): 0.191350294819417\n",
      "Epoch: 12, Loss (standarized): 0.19201226199076601\n",
      "Epoch: 13, Loss (standarized): 0.19308526038570473\n",
      "Epoch: 14, Loss (standarized): 0.19426758634209454\n",
      "Epoch: 15, Loss (standarized): 0.19535943983555554\n",
      "Epoch: 16, Loss (standarized): 0.19623651652379082\n",
      "Epoch: 17, Loss (standarized): 0.19683288630582058\n",
      "Epoch: 18, Loss (standarized): 0.19712491122506018\n",
      "Epoch: 19, Loss (standarized): 0.19711451811358602\n",
      "Epoch: 20, Loss (standarized): 0.19683914029601932\n",
      "Final epoch: 20, Final loss (standarized): 0.19683914029601932\n",
      "Epoch: 1, Loss (standarized): 0.5779693582635261\n",
      "Epoch: 2, Loss (standarized): 0.45413967765563185\n",
      "Epoch: 3, Loss (standarized): 0.3630680360508654\n",
      "Epoch: 4, Loss (standarized): 0.2993209262105071\n",
      "Epoch: 5, Loss (standarized): 0.2566967434494759\n",
      "Epoch: 6, Loss (standarized): 0.22923341350420126\n",
      "Epoch: 7, Loss (standarized): 0.21208774810668957\n",
      "Epoch: 8, Loss (standarized): 0.20176878934142445\n",
      "Epoch: 9, Loss (standarized): 0.19587678907377595\n",
      "Epoch: 10, Loss (standarized): 0.1928040140433225\n",
      "Epoch: 11, Loss (standarized): 0.19147987771912617\n",
      "Epoch: 12, Loss (standarized): 0.19119865032970162\n",
      "Epoch: 13, Loss (standarized): 0.19148950079328833\n",
      "Epoch: 14, Loss (standarized): 0.1920499185709162\n",
      "Epoch: 15, Loss (standarized): 0.19268548206583075\n",
      "Epoch: 16, Loss (standarized): 0.19327214784805624\n",
      "Epoch: 17, Loss (standarized): 0.19373081454232144\n",
      "Epoch: 18, Loss (standarized): 0.19403213062252328\n",
      "Epoch: 19, Loss (standarized): 0.19415971251735523\n",
      "Epoch: 20, Loss (standarized): 0.1941149312167311\n",
      "Final epoch: 20, Final loss (standarized): 0.1941149312167311\n",
      "Epoch: 1, Loss (standarized): 1.6285866516660188\n",
      "Epoch: 2, Loss (standarized): 1.3280829441223263\n",
      "Epoch: 3, Loss (standarized): 1.0678099153124445\n",
      "Epoch: 4, Loss (standarized): 0.8499970194854205\n",
      "Epoch: 5, Loss (standarized): 0.6742653360391384\n",
      "Epoch: 6, Loss (standarized): 0.5374301533795355\n",
      "Epoch: 7, Loss (standarized): 0.4342150861614452\n",
      "Epoch: 8, Loss (standarized): 0.35840069351114345\n",
      "Epoch: 9, Loss (standarized): 0.303894759701694\n",
      "Epoch: 10, Loss (standarized): 0.26539597147320115\n",
      "Epoch: 11, Loss (standarized): 0.23864345613469903\n",
      "Epoch: 12, Loss (standarized): 0.22038365531350088\n",
      "Epoch: 13, Loss (standarized): 0.20820689807698245\n",
      "Epoch: 14, Loss (standarized): 0.20035254971830183\n",
      "Epoch: 15, Loss (standarized): 0.1955479076118149\n",
      "Epoch: 16, Loss (standarized): 0.1928783173167208\n",
      "Epoch: 17, Loss (standarized): 0.19168221883978032\n",
      "Epoch: 18, Loss (standarized): 0.19148330877025874\n",
      "Epoch: 19, Loss (standarized): 0.19193600300959204\n",
      "Epoch: 20, Loss (standarized): 0.19279052674381383\n",
      "Final epoch: 20, Final loss (standarized): 0.19279052674381383\n",
      "Epoch: 1, Loss (standarized): 1.198764537133127\n",
      "Epoch: 2, Loss (standarized): 0.9468751877862421\n",
      "Epoch: 3, Loss (standarized): 0.7403499264610253\n",
      "Epoch: 4, Loss (standarized): 0.5784018454959988\n",
      "Epoch: 5, Loss (standarized): 0.4567364353177001\n",
      "Epoch: 6, Loss (standarized): 0.36868057966314804\n",
      "Epoch: 7, Loss (standarized): 0.3068674677416372\n",
      "Epoch: 8, Loss (standarized): 0.2645308904030875\n",
      "Epoch: 9, Loss (standarized): 0.23614157487914952\n",
      "Epoch: 10, Loss (standarized): 0.21750738621991342\n",
      "Epoch: 11, Loss (standarized): 0.20559806949278292\n",
      "Epoch: 12, Loss (standarized): 0.19827945654827756\n",
      "Epoch: 13, Loss (standarized): 0.19406759935770515\n",
      "Epoch: 14, Loss (standarized): 0.19193372495689537\n",
      "Epoch: 15, Loss (standarized): 0.19116796163800362\n",
      "Epoch: 16, Loss (standarized): 0.19127951882933109\n",
      "Epoch: 17, Loss (standarized): 0.19192892928802116\n",
      "Epoch: 18, Loss (standarized): 0.1928802781062071\n",
      "Epoch: 19, Loss (standarized): 0.19397038813532386\n",
      "Epoch: 20, Loss (standarized): 0.19508789163750154\n",
      "Final epoch: 20, Final loss (standarized): 0.19508789163750154\n",
      "Epoch: 1, Loss (standarized): 0.8409367926438204\n",
      "Epoch: 2, Loss (standarized): 0.6605783506798099\n",
      "Epoch: 3, Loss (standarized): 0.5174107936516548\n",
      "Epoch: 4, Loss (standarized): 0.4090706744983369\n",
      "Epoch: 5, Loss (standarized): 0.33071897684351015\n",
      "Epoch: 6, Loss (standarized): 0.2764204296757373\n",
      "Epoch: 7, Loss (standarized): 0.2403045353157118\n",
      "Epoch: 8, Loss (standarized): 0.2173199228233623\n",
      "Epoch: 9, Loss (standarized): 0.20348891475305836\n",
      "Epoch: 10, Loss (standarized): 0.19586213142413342\n",
      "Epoch: 11, Loss (standarized): 0.19232750932129178\n",
      "Epoch: 12, Loss (standarized): 0.19141519627408624\n",
      "Epoch: 13, Loss (standarized): 0.1921122027484881\n",
      "Epoch: 14, Loss (standarized): 0.19373119698675942\n",
      "Epoch: 15, Loss (standarized): 0.19581122020157488\n",
      "Epoch: 16, Loss (standarized): 0.19804348837123056\n",
      "Epoch: 17, Loss (standarized): 0.20022375524395236\n",
      "Epoch: 18, Loss (standarized): 0.202222197896168\n",
      "Epoch: 19, Loss (standarized): 0.20395930012790467\n",
      "Epoch: 20, Loss (standarized): 0.2053954702938124\n",
      "Final epoch: 20, Final loss (standarized): 0.2053954702938124\n",
      "Epoch: 1, Loss (standarized): 0.34651458927050544\n",
      "Epoch: 2, Loss (standarized): 0.2771127122144763\n",
      "Epoch: 3, Loss (standarized): 0.23351761310910157\n",
      "Epoch: 4, Loss (standarized): 0.20878067625549535\n",
      "Epoch: 5, Loss (standarized): 0.19657880726574586\n",
      "Epoch: 6, Loss (standarized): 0.19205082898008308\n",
      "Epoch: 7, Loss (standarized): 0.1918439809766182\n",
      "Epoch: 8, Loss (standarized): 0.19379237985082776\n",
      "Epoch: 9, Loss (standarized): 0.1965612194706313\n",
      "Epoch: 10, Loss (standarized): 0.19936409450425144\n",
      "Epoch: 11, Loss (standarized): 0.2017699028956048\n",
      "Epoch: 12, Loss (standarized): 0.2035590706447564\n",
      "Epoch: 13, Loss (standarized): 0.20464918049365804\n",
      "Epoch: 14, Loss (standarized): 0.20504384410123075\n",
      "Epoch: 15, Loss (standarized): 0.20480225837794372\n",
      "Epoch: 16, Loss (standarized): 0.20401308135730367\n",
      "Epoch: 17, Loss (standarized): 0.20278926238024414\n",
      "Epoch: 18, Loss (standarized): 0.20124873870272092\n",
      "Epoch: 19, Loss (standarized): 0.1995170607337799\n",
      "Epoch: 20, Loss (standarized): 0.19772162885275033\n",
      "Final epoch: 20, Final loss (standarized): 0.19772162885275033\n",
      "Epoch: 1, Loss (standarized): 1.0018287179309568\n",
      "Epoch: 2, Loss (standarized): 0.8033176109083405\n",
      "Epoch: 3, Loss (standarized): 0.6411609225171749\n",
      "Epoch: 4, Loss (standarized): 0.5133315385492638\n",
      "Epoch: 5, Loss (standarized): 0.4159823434514208\n",
      "Epoch: 6, Loss (standarized): 0.3440646880327425\n",
      "Epoch: 7, Loss (standarized): 0.29231587942304904\n",
      "Epoch: 8, Loss (standarized): 0.25595716339763364\n",
      "Epoch: 9, Loss (standarized): 0.23101241919601798\n",
      "Epoch: 10, Loss (standarized): 0.21435743295300116\n",
      "Epoch: 11, Loss (standarized): 0.2036276820265816\n",
      "Epoch: 12, Loss (standarized): 0.19707566235859092\n",
      "Epoch: 13, Loss (standarized): 0.19342834320850807\n",
      "Epoch: 14, Loss (standarized): 0.1917670045195699\n",
      "Epoch: 15, Loss (standarized): 0.19143241899543806\n",
      "Epoch: 16, Loss (standarized): 0.19195355295497063\n",
      "Epoch: 17, Loss (standarized): 0.19299536663414588\n",
      "Epoch: 18, Loss (standarized): 0.19432053797801577\n",
      "Epoch: 19, Loss (standarized): 0.1957623196859828\n",
      "Epoch: 20, Loss (standarized): 0.19720508042952667\n",
      "Final epoch: 20, Final loss (standarized): 0.19720508042952667\n",
      "Epoch: 1, Loss (standarized): 0.6804517196818967\n",
      "Epoch: 2, Loss (standarized): 0.5440579857352562\n",
      "Epoch: 3, Loss (standarized): 0.4361560167985866\n",
      "Epoch: 4, Loss (standarized): 0.35428945005555934\n",
      "Epoch: 5, Loss (standarized): 0.29477776110675363\n",
      "Epoch: 6, Loss (standarized): 0.2533910902678853\n",
      "Epoch: 7, Loss (standarized): 0.225952833576133\n",
      "Epoch: 8, Loss (standarized): 0.2087618129931442\n",
      "Epoch: 9, Loss (standarized): 0.19878890622194517\n",
      "Epoch: 10, Loss (standarized): 0.19370931014465984\n",
      "Epoch: 11, Loss (standarized): 0.19182129428866942\n",
      "Epoch: 12, Loss (standarized): 0.19191762207988916\n",
      "Epoch: 13, Loss (standarized): 0.1931604470813212\n",
      "Epoch: 14, Loss (standarized): 0.1949782809774279\n",
      "Epoch: 15, Loss (standarized): 0.1969881195731163\n",
      "Epoch: 16, Loss (standarized): 0.1989387634907391\n",
      "Epoch: 17, Loss (standarized): 0.200671156853351\n",
      "Epoch: 18, Loss (standarized): 0.20209071936401884\n",
      "Epoch: 19, Loss (standarized): 0.20314898943003185\n",
      "Epoch: 20, Loss (standarized): 0.20382901946426538\n",
      "Final epoch: 20, Final loss (standarized): 0.20382901946426538\n",
      "Epoch: 1, Loss (standarized): 1.566791745960727\n",
      "Epoch: 2, Loss (standarized): 1.2764268705724637\n",
      "Epoch: 3, Loss (standarized): 1.0199053283842785\n",
      "Epoch: 4, Loss (standarized): 0.8025438244822681\n",
      "Epoch: 5, Loss (standarized): 0.6266106225697007\n",
      "Epoch: 6, Loss (standarized): 0.4906946967161827\n",
      "Epoch: 7, Loss (standarized): 0.3902186290895403\n",
      "Epoch: 8, Loss (standarized): 0.3188115747689325\n",
      "Epoch: 9, Loss (standarized): 0.2698036249440016\n",
      "Epoch: 10, Loss (standarized): 0.23725327948457656\n",
      "Epoch: 11, Loss (standarized): 0.2163843689046135\n",
      "Epoch: 12, Loss (standarized): 0.20360228451633947\n",
      "Epoch: 13, Loss (standarized): 0.1963122944579832\n",
      "Epoch: 14, Loss (standarized): 0.1926879720343783\n",
      "Epoch: 15, Loss (standarized): 0.1914629419432949\n",
      "Epoch: 16, Loss (standarized): 0.1917664070201307\n",
      "Epoch: 17, Loss (standarized): 0.19300291110771364\n",
      "Epoch: 18, Loss (standarized): 0.19476674775520125\n",
      "Epoch: 19, Loss (standarized): 0.19678295021956177\n",
      "Epoch: 20, Loss (standarized): 0.19886641483262407\n",
      "Final epoch: 20, Final loss (standarized): 0.19886641483262407\n",
      "Epoch: 1, Loss (standarized): 0.4227636877203033\n",
      "Epoch: 2, Loss (standarized): 0.3331470118748336\n",
      "Epoch: 3, Loss (standarized): 0.27121365495602373\n",
      "Epoch: 4, Loss (standarized): 0.23156550649100666\n",
      "Epoch: 5, Loss (standarized): 0.20838329804848843\n",
      "Epoch: 6, Loss (standarized): 0.19649603874623445\n",
      "Epoch: 7, Loss (standarized): 0.19185509969990006\n",
      "Epoch: 8, Loss (standarized): 0.19154684044440085\n",
      "Epoch: 9, Loss (standarized): 0.19359231676575112\n",
      "Epoch: 10, Loss (standarized): 0.19670368755168122\n",
      "Epoch: 11, Loss (standarized): 0.2000731309391285\n",
      "Epoch: 12, Loss (standarized): 0.2032148987072436\n",
      "Epoch: 13, Loss (standarized): 0.20585313418669038\n",
      "Epoch: 14, Loss (standarized): 0.2078505847750307\n",
      "Epoch: 15, Loss (standarized): 0.2091573493003633\n",
      "Epoch: 16, Loss (standarized): 0.2097801396204628\n",
      "Epoch: 17, Loss (standarized): 0.20976234393865123\n",
      "Epoch: 18, Loss (standarized): 0.20917110334665184\n",
      "Epoch: 19, Loss (standarized): 0.20808896786813197\n",
      "Epoch: 20, Loss (standarized): 0.20660844800213837\n",
      "Final epoch: 20, Final loss (standarized): 0.20660844800213837\n",
      "Epoch: 1, Loss (standarized): 1.3107300372532897\n",
      "          Validation Loss (standardized): 0.7841627343070607\n",
      "Epoch: 2, Loss (standarized): 1.0516791501552134\n",
      "          Validation Loss (standardized): 0.7185906232531994\n",
      "Epoch: 3, Loss (standarized): 0.8302523941275888\n",
      "          Validation Loss (standardized): 0.6901151756448073\n",
      "Epoch: 4, Loss (standarized): 0.6490665465310017\n",
      "          Validation Loss (standardized): 0.6969627358061488\n",
      "Epoch: 5, Loss (standarized): 0.5075386298692913\n",
      "          Validation Loss (standardized): 0.7341234462368053\n",
      "Epoch: 6, Loss (standarized): 0.4018490871854381\n",
      "          Validation Loss (standardized): 0.7946389576646914\n",
      "Epoch: 7, Loss (standarized): 0.3261203340074312\n",
      "          Validation Loss (standardized): 0.8711358259373145\n",
      "Epoch: 8, Loss (standarized): 0.27385856551654036\n",
      "          Validation Loss (standardized): 0.9569789581519313\n",
      "Epoch: 9, Loss (standarized): 0.23906027038021024\n",
      "          Validation Loss (standardized): 1.0468289613299546\n",
      "Epoch: 10, Loss (standarized): 0.21676742447553266\n",
      "          Validation Loss (standardized): 1.1367243865186154\n",
      "Epoch: 11, Loss (standarized): 0.20317649426791115\n",
      "          Validation Loss (standardized): 1.22390951435701\n",
      "Epoch: 12, Loss (standarized): 0.19550572538539193\n",
      "          Validation Loss (standardized): 1.3065786545042612\n",
      "Epoch: 13, Loss (standarized): 0.19178124650213438\n",
      "          Validation Loss (standardized): 1.3836286696902602\n",
      "Epoch: 14, Loss (standarized): 0.1906282125111743\n",
      "          Validation Loss (standardized): 1.4544549822034651\n",
      "Epoch: 15, Loss (standarized): 0.19109969438046126\n",
      "          Validation Loss (standardized): 1.5187965951998876\n",
      "Epoch: 16, Loss (standarized): 0.19254811123490012\n",
      "          Validation Loss (standardized): 1.5766236736708286\n",
      "Epoch: 17, Loss (standarized): 0.19453305511702693\n",
      "          Validation Loss (standardized): 1.6280582539152275\n",
      "Epoch: 18, Loss (standarized): 0.19675688661166066\n",
      "          Validation Loss (standardized): 1.6733193221886233\n",
      "Epoch: 19, Loss (standarized): 0.1990203283238513\n",
      "          Validation Loss (standardized): 1.712685249944545\n",
      "Epoch: 20, Loss (standarized): 0.2011920161034114\n",
      "          Validation Loss (standardized): 1.7464683536298748\n",
      "Final epoch: 20, Final loss (standarized): 0.2011920161034114\n",
      "Epoch: 1, Loss (standarized): 0.5836688510488169\n",
      "          Validation Loss (standardized): 0.7120596627952134\n",
      "Epoch: 2, Loss (standarized): 0.44818602117036355\n",
      "          Validation Loss (standardized): 0.7694373951131307\n",
      "Epoch: 3, Loss (standarized): 0.35085116534672633\n",
      "          Validation Loss (standardized): 0.8509389153525001\n",
      "Epoch: 4, Loss (standarized): 0.2848673156248181\n",
      "          Validation Loss (standardized): 0.9468648567691856\n",
      "Epoch: 5, Loss (standarized): 0.242509706873786\n",
      "          Validation Loss (standardized): 1.0488287028773207\n",
      "Epoch: 6, Loss (standarized): 0.2167926870796756\n",
      "          Validation Loss (standardized): 1.1505709735148646\n",
      "Epoch: 7, Loss (standarized): 0.20221219960090192\n",
      "          Validation Loss (standardized): 1.2478520325421572\n",
      "Epoch: 8, Loss (standarized): 0.19480548943700557\n",
      "          Validation Loss (standardized): 1.3380224595609258\n",
      "Epoch: 9, Loss (standarized): 0.19186304627601583\n",
      "          Validation Loss (standardized): 1.419575155416796\n",
      "Epoch: 10, Loss (standarized): 0.19158571341160252\n",
      "          Validation Loss (standardized): 1.491781925152476\n",
      "Epoch: 11, Loss (standarized): 0.19279929967388337\n",
      "          Validation Loss (standardized): 1.554427693965182\n",
      "Epoch: 12, Loss (standarized): 0.19474668884074908\n",
      "          Validation Loss (standardized): 1.607626280662148\n",
      "Epoch: 13, Loss (standarized): 0.1969455861469462\n",
      "          Validation Loss (standardized): 1.6516967146770807\n",
      "Epoch: 14, Loss (standarized): 0.19909417363267065\n",
      "          Validation Loss (standardized): 1.6870817765423702\n",
      "Epoch: 15, Loss (standarized): 0.20100941419529797\n",
      "          Validation Loss (standardized): 1.7142951259265493\n",
      "Epoch: 16, Loss (standarized): 0.2025868713545784\n",
      "          Validation Loss (standardized): 1.7338875686661135\n",
      "Epoch: 17, Loss (standarized): 0.20377452345372987\n",
      "          Validation Loss (standardized): 1.7464260609503623\n",
      "Epoch: 18, Loss (standarized): 0.20455563469290075\n",
      "          Validation Loss (standardized): 1.7524810952897354\n",
      "Epoch: 19, Loss (standarized): 0.20493746606382113\n",
      "          Validation Loss (standardized): 1.7526195103012185\n",
      "Epoch: 20, Loss (standarized): 0.20494375555036348\n",
      "          Validation Loss (standardized): 1.7474007508118172\n",
      "Final epoch: 20, Final loss (standarized): 0.20494375555036348\n",
      "Epoch: 1, Loss (standarized): 0.822901823523368\n",
      "          Validation Loss (standardized): 0.6890987313011665\n",
      "Epoch: 2, Loss (standarized): 0.6504562170934383\n",
      "          Validation Loss (standardized): 0.6952625520664008\n",
      "Epoch: 3, Loss (standarized): 0.5105947637224316\n",
      "          Validation Loss (standardized): 0.7325792015942882\n",
      "Epoch: 4, Loss (standarized): 0.40273011594734076\n",
      "          Validation Loss (standardized): 0.7963788107589838\n",
      "Epoch: 5, Loss (standarized): 0.32383806774072027\n",
      "          Validation Loss (standardized): 0.8801789502761301\n",
      "Epoch: 6, Loss (standarized): 0.2691260862366474\n",
      "          Validation Loss (standardized): 0.9770350671148005\n",
      "Epoch: 7, Loss (standarized): 0.23323115626251623\n",
      "          Validation Loss (standardized): 1.0805773563932373\n",
      "Epoch: 8, Loss (standarized): 0.2111618757978427\n",
      "          Validation Loss (standardized): 1.1855474664351542\n",
      "Epoch: 9, Loss (standarized): 0.1987810447898536\n",
      "          Validation Loss (standardized): 1.287929635441828\n",
      "Epoch: 10, Loss (standarized): 0.19291246374645313\n",
      "          Validation Loss (standardized): 1.384852654216503\n",
      "Epoch: 11, Loss (standarized): 0.19123991853681976\n",
      "          Validation Loss (standardized): 1.4744012012351595\n",
      "Epoch: 12, Loss (standarized): 0.19213316747849513\n",
      "          Validation Loss (standardized): 1.555412097750847\n",
      "Epoch: 13, Loss (standarized): 0.1944743041434605\n",
      "          Validation Loss (standardized): 1.6272880357054913\n",
      "Epoch: 14, Loss (standarized): 0.19751309046242688\n",
      "          Validation Loss (standardized): 1.6898406825953407\n",
      "Epoch: 15, Loss (standarized): 0.2007565440897283\n",
      "          Validation Loss (standardized): 1.7431660142007026\n",
      "Epoch: 16, Loss (standarized): 0.20388874822082606\n",
      "          Validation Loss (standardized): 1.7875499997398772\n",
      "Epoch: 17, Loss (standarized): 0.2067143889310799\n",
      "          Validation Loss (standardized): 1.823400178944783\n",
      "Epoch: 18, Loss (standarized): 0.2091198013664572\n",
      "          Validation Loss (standardized): 1.8511977741086307\n",
      "Epoch: 19, Loss (standarized): 0.21104644970019637\n",
      "          Validation Loss (standardized): 1.871465235909846\n",
      "Epoch: 20, Loss (standarized): 0.21247301619593004\n",
      "          Validation Loss (standardized): 1.8847449303861796\n",
      "Final epoch: 20, Final loss (standarized): 0.21247301619593004\n",
      "Epoch: 1, Loss (standarized): 0.1957214163091791\n",
      "          Validation Loss (standardized): 1.3714007603311726\n",
      "Epoch: 2, Loss (standarized): 0.19104620602830236\n",
      "          Validation Loss (standardized): 1.4859633226994924\n",
      "Epoch: 3, Loss (standarized): 0.19217645409667847\n",
      "          Validation Loss (standardized): 1.5273130255369614\n",
      "Epoch: 4, Loss (standarized): 0.19326503392990652\n",
      "          Validation Loss (standardized): 1.5121680863365112\n",
      "Epoch: 5, Loss (standarized): 0.19272050943949612\n",
      "          Validation Loss (standardized): 1.4664427288106237\n",
      "Epoch: 6, Loss (standarized): 0.1915300298778928\n",
      "          Validation Loss (standardized): 1.409111792365681\n",
      "Epoch: 7, Loss (standarized): 0.19074583345836388\n",
      "          Validation Loss (standardized): 1.3556781568973657\n",
      "Epoch: 8, Loss (standarized): 0.1908169925340826\n",
      "          Validation Loss (standardized): 1.3193486752533012\n",
      "Epoch: 9, Loss (standarized): 0.19136608910397462\n",
      "          Validation Loss (standardized): 1.307021531473274\n",
      "Epoch: 10, Loss (standarized): 0.19162794416995335\n",
      "          Validation Loss (standardized): 1.3171598892261938\n",
      "Epoch: 11, Loss (standarized): 0.1913213710595733\n",
      "          Validation Loss (standardized): 1.3435069707022103\n",
      "Epoch: 12, Loss (standarized): 0.19076512314533572\n",
      "          Validation Loss (standardized): 1.3782746581581575\n",
      "Epoch: 13, Loss (standarized): 0.19038831132868161\n",
      "          Validation Loss (standardized): 1.413193777087065\n",
      "Epoch: 14, Loss (standarized): 0.19036405651867203\n",
      "          Validation Loss (standardized): 1.4406191537074315\n",
      "Epoch: 15, Loss (standarized): 0.1905577566063755\n",
      "          Validation Loss (standardized): 1.4552990158968044\n",
      "Epoch: 16, Loss (standarized): 0.19071018080529564\n",
      "          Validation Loss (standardized): 1.455572638729094\n",
      "Epoch: 17, Loss (standarized): 0.19066001721731904\n",
      "          Validation Loss (standardized): 1.4431385643202201\n",
      "Epoch: 18, Loss (standarized): 0.19043134140549997\n",
      "          Validation Loss (standardized): 1.4220042106387636\n",
      "Epoch: 19, Loss (standarized): 0.19017348741756956\n",
      "          Validation Loss (standardized): 1.3974336101865037\n",
      "Epoch: 20, Loss (standarized): 0.19003718622838872\n",
      "          Validation Loss (standardized): 1.3750075232935992\n",
      "Final epoch: 20, Final loss (standarized): 0.19003718622838872\n",
      "Epoch: 1, Loss (standarized): 0.22466642274127815\n",
      "          Validation Loss (standardized): 1.1034156686441852\n",
      "Epoch: 2, Loss (standarized): 0.20814414549532537\n",
      "          Validation Loss (standardized): 1.1898994484750784\n",
      "Epoch: 3, Loss (standarized): 0.19883019365900143\n",
      "          Validation Loss (standardized): 1.2714636469858056\n",
      "Epoch: 4, Loss (standarized): 0.19397083104731525\n",
      "          Validation Loss (standardized): 1.341629038550591\n",
      "Epoch: 5, Loss (standarized): 0.19205321819346519\n",
      "          Validation Loss (standardized): 1.3962524563050183\n",
      "Epoch: 6, Loss (standarized): 0.19170261081462128\n",
      "          Validation Loss (standardized): 1.4340582589729294\n",
      "Epoch: 7, Loss (standarized): 0.19194705651043972\n",
      "          Validation Loss (standardized): 1.4562861403737808\n",
      "Epoch: 8, Loss (standarized): 0.1922501232760765\n",
      "          Validation Loss (standardized): 1.4651258046947395\n",
      "Epoch: 9, Loss (standarized): 0.19239054225591995\n",
      "          Validation Loss (standardized): 1.4623030837734334\n",
      "Epoch: 10, Loss (standarized): 0.19231821625901174\n",
      "          Validation Loss (standardized): 1.4509085842630043\n",
      "Epoch: 11, Loss (standarized): 0.19210377366310993\n",
      "          Validation Loss (standardized): 1.4333632455619412\n",
      "Epoch: 12, Loss (standarized): 0.19184499305020306\n",
      "          Validation Loss (standardized): 1.4111487982161919\n",
      "Epoch: 13, Loss (standarized): 0.1916338374815722\n",
      "          Validation Loss (standardized): 1.3856787608841228\n",
      "Epoch: 14, Loss (standarized): 0.19155945896713028\n",
      "          Validation Loss (standardized): 1.3586841343127936\n",
      "Epoch: 15, Loss (standarized): 0.19168846917185603\n",
      "          Validation Loss (standardized): 1.3316983205814805\n",
      "Epoch: 16, Loss (standarized): 0.1920485149900548\n",
      "          Validation Loss (standardized): 1.306451036064877\n",
      "Epoch: 17, Loss (standarized): 0.19261099965985842\n",
      "          Validation Loss (standardized): 1.2838648563588007\n",
      "Epoch: 18, Loss (standarized): 0.19331442188376666\n",
      "          Validation Loss (standardized): 1.2645757428285533\n",
      "Epoch: 19, Loss (standarized): 0.19407680289868517\n",
      "          Validation Loss (standardized): 1.2495779501481803\n",
      "Epoch: 20, Loss (standarized): 0.19477959456803773\n",
      "          Validation Loss (standardized): 1.2399231175495304\n",
      "Final epoch: 20, Final loss (standarized): 0.19477959456803773\n",
      "Epoch: 1, Loss (standarized): 0.5346192479978806\n",
      "          Validation Loss (standardized): 0.7346706176138963\n",
      "Epoch: 2, Loss (standarized): 0.3998888610169586\n",
      "          Validation Loss (standardized): 0.8132636584429289\n",
      "Epoch: 3, Loss (standarized): 0.3104154950077931\n",
      "          Validation Loss (standardized): 0.9117172970849322\n",
      "Epoch: 4, Loss (standarized): 0.2554724067136021\n",
      "          Validation Loss (standardized): 1.015340241052809\n",
      "Epoch: 5, Loss (standarized): 0.22381736428285726\n",
      "          Validation Loss (standardized): 1.1151935560564779\n",
      "Epoch: 6, Loss (standarized): 0.206398498210873\n",
      "          Validation Loss (standardized): 1.2064397918174563\n",
      "Epoch: 7, Loss (standarized): 0.19737317676864774\n",
      "          Validation Loss (standardized): 1.2866732176146107\n",
      "Epoch: 8, Loss (standarized): 0.19317902578975502\n",
      "          Validation Loss (standardized): 1.3552006592197727\n",
      "Epoch: 9, Loss (standarized): 0.1916673644018806\n",
      "          Validation Loss (standardized): 1.4120799926767356\n",
      "Epoch: 10, Loss (standarized): 0.19156279580074478\n",
      "          Validation Loss (standardized): 1.4575788992864938\n",
      "Epoch: 11, Loss (standarized): 0.19210642892607624\n",
      "          Validation Loss (standardized): 1.4924570237667638\n",
      "Epoch: 12, Loss (standarized): 0.19285113107180737\n",
      "          Validation Loss (standardized): 1.5182801796198686\n",
      "Epoch: 13, Loss (standarized): 0.1935680821296904\n",
      "          Validation Loss (standardized): 1.5358404649137094\n",
      "Epoch: 14, Loss (standarized): 0.19413116861957794\n",
      "          Validation Loss (standardized): 1.54615617160483\n",
      "Epoch: 15, Loss (standarized): 0.19448862588393354\n",
      "          Validation Loss (standardized): 1.5499567551297275\n",
      "Epoch: 16, Loss (standarized): 0.19462410461231439\n",
      "          Validation Loss (standardized): 1.5480348812877442\n",
      "Epoch: 17, Loss (standarized): 0.19455227676573106\n",
      "          Validation Loss (standardized): 1.5413849513746152\n",
      "Epoch: 18, Loss (standarized): 0.1943148651546585\n",
      "          Validation Loss (standardized): 1.5307754313439035\n",
      "Epoch: 19, Loss (standarized): 0.1939546951698534\n",
      "          Validation Loss (standardized): 1.5170554417947864\n",
      "Epoch: 20, Loss (standarized): 0.19352127406440073\n",
      "          Validation Loss (standardized): 1.5009653693980152\n",
      "Final epoch: 20, Final loss (standarized): 0.19352127406440073\n",
      "Epoch: 1, Loss (standarized): 1.5291801617918575\n",
      "          Validation Loss (standardized): 0.8621314199591459\n",
      "Epoch: 2, Loss (standarized): 1.2570551491881863\n",
      "          Validation Loss (standardized): 0.772538438991038\n",
      "Epoch: 3, Loss (standarized): 1.0195406983591249\n",
      "          Validation Loss (standardized): 0.7152965724541203\n",
      "Epoch: 4, Loss (standarized): 0.8190099989685091\n",
      "          Validation Loss (standardized): 0.6898288909348005\n",
      "Epoch: 5, Loss (standarized): 0.6555658360523016\n",
      "          Validation Loss (standardized): 0.6930519623582763\n",
      "Epoch: 6, Loss (standarized): 0.5272266428841689\n",
      "          Validation Loss (standardized): 0.7197914552198036\n",
      "Epoch: 7, Loss (standarized): 0.42974158029196025\n",
      "          Validation Loss (standardized): 0.7640082428075675\n",
      "Epoch: 8, Loss (standarized): 0.3576566964650389\n",
      "          Validation Loss (standardized): 0.819905867900961\n",
      "Epoch: 9, Loss (standarized): 0.30546001543723855\n",
      "          Validation Loss (standardized): 0.8825471565908223\n",
      "Epoch: 10, Loss (standarized): 0.2682881018479757\n",
      "          Validation Loss (standardized): 0.948252772297138\n",
      "Epoch: 11, Loss (standarized): 0.24212937106798824\n",
      "          Validation Loss (standardized): 1.0142290248553174\n",
      "Epoch: 12, Loss (standarized): 0.22397776274912296\n",
      "          Validation Loss (standardized): 1.0782844082370997\n",
      "Epoch: 13, Loss (standarized): 0.2116184316399239\n",
      "          Validation Loss (standardized): 1.138821378012884\n",
      "Epoch: 14, Loss (standarized): 0.203396391482262\n",
      "          Validation Loss (standardized): 1.1949596333008312\n",
      "Epoch: 15, Loss (standarized): 0.19807109648915522\n",
      "          Validation Loss (standardized): 1.2461682939449685\n",
      "Epoch: 16, Loss (standarized): 0.19475438353414828\n",
      "          Validation Loss (standardized): 1.292422863988564\n",
      "Epoch: 17, Loss (standarized): 0.19280185301857852\n",
      "          Validation Loss (standardized): 1.333884920919777\n",
      "Epoch: 18, Loss (standarized): 0.19176780144372446\n",
      "          Validation Loss (standardized): 1.370975463019721\n",
      "Epoch: 19, Loss (standarized): 0.19134159540224757\n",
      "          Validation Loss (standardized): 1.4037141048552064\n",
      "Epoch: 20, Loss (standarized): 0.19131349756608956\n",
      "          Validation Loss (standardized): 1.4322213188534725\n",
      "Final epoch: 20, Final loss (standarized): 0.19131349756608956\n",
      "Epoch: 1, Loss (standarized): 0.9265453448537556\n",
      "          Validation Loss (standardized): 0.6963955776970931\n",
      "Epoch: 2, Loss (standarized): 0.7171868700573599\n",
      "          Validation Loss (standardized): 0.689934218146978\n",
      "Epoch: 3, Loss (standarized): 0.5528605624862665\n",
      "          Validation Loss (standardized): 0.7191179506798043\n",
      "Epoch: 4, Loss (standarized): 0.4306910616878065\n",
      "          Validation Loss (standardized): 0.7756971315245713\n",
      "Epoch: 5, Loss (standarized): 0.3441542334074557\n",
      "          Validation Loss (standardized): 0.8501620114878915\n",
      "Epoch: 6, Loss (standarized): 0.28549850833411156\n",
      "          Validation Loss (standardized): 0.9339239835332213\n",
      "Epoch: 7, Loss (standarized): 0.2471389967956507\n",
      "          Validation Loss (standardized): 1.020298759506922\n",
      "Epoch: 8, Loss (standarized): 0.2228593664104401\n",
      "          Validation Loss (standardized): 1.104629205861611\n",
      "Epoch: 9, Loss (standarized): 0.20802541796023938\n",
      "          Validation Loss (standardized): 1.1840930843657085\n",
      "Epoch: 10, Loss (standarized): 0.19936488613012338\n",
      "          Validation Loss (standardized): 1.2570340496226233\n",
      "Epoch: 11, Loss (standarized): 0.1946730524777576\n",
      "          Validation Loss (standardized): 1.3226864313167774\n",
      "Epoch: 12, Loss (standarized): 0.19247932824043015\n",
      "          Validation Loss (standardized): 1.380807780310426\n",
      "Epoch: 13, Loss (standarized): 0.19181598996505897\n",
      "          Validation Loss (standardized): 1.431369872305001\n",
      "Epoch: 14, Loss (standarized): 0.1920472796407567\n",
      "          Validation Loss (standardized): 1.4745701748710973\n",
      "Epoch: 15, Loss (standarized): 0.1927532980154412\n",
      "          Validation Loss (standardized): 1.5106177936050937\n",
      "Epoch: 16, Loss (standarized): 0.19365536119524543\n",
      "          Validation Loss (standardized): 1.53982794087011\n",
      "Epoch: 17, Loss (standarized): 0.19457270291557235\n",
      "          Validation Loss (standardized): 1.5625412058597408\n",
      "Epoch: 18, Loss (standarized): 0.19538997571115835\n",
      "          Validation Loss (standardized): 1.5789922892681068\n",
      "Epoch: 19, Loss (standarized): 0.1960325677188147\n",
      "          Validation Loss (standardized): 1.5895028552939154\n",
      "Epoch: 20, Loss (standarized): 0.19646054773780097\n",
      "          Validation Loss (standardized): 1.5946932637928217\n",
      "Final epoch: 20, Final loss (standarized): 0.19646054773780097\n",
      "Epoch: 1, Loss (standarized): 0.4127792578303991\n",
      "          Validation Loss (standardized): 0.7867338566343927\n",
      "Epoch: 2, Loss (standarized): 0.3340897671723606\n",
      "          Validation Loss (standardized): 0.864227134131853\n",
      "Epoch: 3, Loss (standarized): 0.27827961858361816\n",
      "          Validation Loss (standardized): 0.9544163588923641\n",
      "Epoch: 4, Loss (standarized): 0.24075300204263755\n",
      "          Validation Loss (standardized): 1.051203845756141\n",
      "Epoch: 5, Loss (standarized): 0.21691472140698767\n",
      "          Validation Loss (standardized): 1.149354553159583\n",
      "Epoch: 6, Loss (standarized): 0.20283959242001234\n",
      "          Validation Loss (standardized): 1.2447774535388192\n",
      "Epoch: 7, Loss (standarized): 0.19542380404234386\n",
      "          Validation Loss (standardized): 1.3345067343637547\n",
      "Epoch: 8, Loss (standarized): 0.19235182899666162\n",
      "          Validation Loss (standardized): 1.4165370486078093\n",
      "Epoch: 9, Loss (standarized): 0.19197438870327355\n",
      "          Validation Loss (standardized): 1.489659524159818\n",
      "Epoch: 10, Loss (standarized): 0.19314132290966582\n",
      "          Validation Loss (standardized): 1.553238145000422\n",
      "Epoch: 11, Loss (standarized): 0.19508134524220988\n",
      "          Validation Loss (standardized): 1.6070521762702423\n",
      "Epoch: 12, Loss (standarized): 0.1972833523823426\n",
      "          Validation Loss (standardized): 1.6511359053880694\n",
      "Epoch: 13, Loss (standarized): 0.1994125663109467\n",
      "          Validation Loss (standardized): 1.6857343504832523\n",
      "Epoch: 14, Loss (standarized): 0.20126440021842387\n",
      "          Validation Loss (standardized): 1.7113549465238378\n",
      "Epoch: 15, Loss (standarized): 0.20272690782641373\n",
      "          Validation Loss (standardized): 1.7284836410296207\n",
      "Epoch: 16, Loss (standarized): 0.2037428752062059\n",
      "          Validation Loss (standardized): 1.7377619495457184\n",
      "Epoch: 17, Loss (standarized): 0.20429998079801867\n",
      "          Validation Loss (standardized): 1.7398837645315701\n",
      "Epoch: 18, Loss (standarized): 0.20441705977355387\n",
      "          Validation Loss (standardized): 1.7355438769106086\n",
      "Epoch: 19, Loss (standarized): 0.20413280680812004\n",
      "          Validation Loss (standardized): 1.7254172290568237\n",
      "Epoch: 20, Loss (standarized): 0.20349595221288863\n",
      "          Validation Loss (standardized): 1.7102078483350291\n",
      "Final epoch: 20, Final loss (standarized): 0.20349595221288863\n",
      "Epoch: 1, Loss (standarized): 0.39026106706756225\n",
      "          Validation Loss (standardized): 0.811944898275208\n",
      "Epoch: 2, Loss (standarized): 0.31085132057919096\n",
      "          Validation Loss (standardized): 0.9062134865256561\n",
      "Epoch: 3, Loss (standarized): 0.25729559604883034\n",
      "          Validation Loss (standardized): 1.0140282470779456\n",
      "Epoch: 4, Loss (standarized): 0.22381415516443615\n",
      "          Validation Loss (standardized): 1.1263416096308918\n",
      "Epoch: 5, Loss (standarized): 0.2047994669065393\n",
      "          Validation Loss (standardized): 1.2355917195571806\n",
      "Epoch: 6, Loss (standarized): 0.195381094797045\n",
      "          Validation Loss (standardized): 1.336547566363134\n",
      "Epoch: 7, Loss (standarized): 0.1918485325956193\n",
      "          Validation Loss (standardized): 1.4259539412949822\n",
      "Epoch: 8, Loss (standarized): 0.19164274997443834\n",
      "          Validation Loss (standardized): 1.502176155538176\n",
      "Epoch: 9, Loss (standarized): 0.19310036119305496\n",
      "          Validation Loss (standardized): 1.5646931053916844\n",
      "Epoch: 10, Loss (standarized): 0.19519023274360928\n",
      "          Validation Loss (standardized): 1.6135866130546064\n",
      "Epoch: 11, Loss (standarized): 0.19729414380394236\n",
      "          Validation Loss (standardized): 1.6494142827312295\n",
      "Epoch: 12, Loss (standarized): 0.1990647052512603\n",
      "          Validation Loss (standardized): 1.6731134002490102\n",
      "Epoch: 13, Loss (standarized): 0.20033334649961118\n",
      "          Validation Loss (standardized): 1.685721985229239\n",
      "Epoch: 14, Loss (standarized): 0.2010395566135795\n",
      "          Validation Loss (standardized): 1.6883877251222428\n",
      "Epoch: 15, Loss (standarized): 0.2011946128545084\n",
      "          Validation Loss (standardized): 1.6822895071494508\n",
      "Epoch: 16, Loss (standarized): 0.20085395720658658\n",
      "          Validation Loss (standardized): 1.6685265322405645\n",
      "Epoch: 17, Loss (standarized): 0.20009739206295526\n",
      "          Validation Loss (standardized): 1.6482344684833499\n",
      "Epoch: 18, Loss (standarized): 0.19902387477784964\n",
      "          Validation Loss (standardized): 1.6225628596620343\n",
      "Epoch: 19, Loss (standarized): 0.19774405774219492\n",
      "          Validation Loss (standardized): 1.592613830835509\n",
      "Epoch: 20, Loss (standarized): 0.19637148903893653\n",
      "          Validation Loss (standardized): 1.5595010367965452\n",
      "Final epoch: 20, Final loss (standarized): 0.19637148903893653\n",
      "Epoch: 1, Loss (standarized): 0.4479701725959487\n",
      "          Validation Loss (standardized): 0.7902235838859866\n",
      "Epoch: 2, Loss (standarized): 0.3337548094444075\n",
      "          Validation Loss (standardized): 0.9019873889603295\n",
      "Epoch: 3, Loss (standarized): 0.26244344473193915\n",
      "          Validation Loss (standardized): 1.0337464545617978\n",
      "Epoch: 4, Loss (standarized): 0.2223690042858518\n",
      "          Validation Loss (standardized): 1.1707471184988023\n",
      "Epoch: 5, Loss (standarized): 0.2025894010376625\n",
      "          Validation Loss (standardized): 1.3023903646987054\n",
      "Epoch: 6, Loss (standarized): 0.19485905911417675\n",
      "          Validation Loss (standardized): 1.422402617172746\n",
      "Epoch: 7, Loss (standarized): 0.19373039526381838\n",
      "          Validation Loss (standardized): 1.5277173987369452\n",
      "Epoch: 8, Loss (standarized): 0.1958870278038951\n",
      "          Validation Loss (standardized): 1.6172608152977848\n",
      "Epoch: 9, Loss (standarized): 0.1994073373124013\n",
      "          Validation Loss (standardized): 1.691112389187515\n",
      "Epoch: 10, Loss (standarized): 0.20321208280269007\n",
      "          Validation Loss (standardized): 1.7499759679706448\n",
      "Epoch: 11, Loss (standarized): 0.20671649283611848\n",
      "          Validation Loss (standardized): 1.7948739307529704\n",
      "Epoch: 12, Loss (standarized): 0.2096228347463592\n",
      "          Validation Loss (standardized): 1.8269374255799997\n",
      "Epoch: 13, Loss (standarized): 0.21180056887749735\n",
      "          Validation Loss (standardized): 1.8473167993918203\n",
      "Epoch: 14, Loss (standarized): 0.2132130927696216\n",
      "          Validation Loss (standardized): 1.8571369474262662\n",
      "Epoch: 15, Loss (standarized): 0.2138816740826509\n",
      "          Validation Loss (standardized): 1.857458847632147\n",
      "Epoch: 16, Loss (standarized): 0.2138587051770748\n",
      "          Validation Loss (standardized): 1.8492996454467345\n",
      "Epoch: 17, Loss (standarized): 0.21321784068934085\n",
      "          Validation Loss (standardized): 1.833619590523128\n",
      "Epoch: 18, Loss (standarized): 0.21204428534999384\n",
      "          Validation Loss (standardized): 1.8113096706695153\n",
      "Epoch: 19, Loss (standarized): 0.21043093621453293\n",
      "          Validation Loss (standardized): 1.783263010411832\n",
      "Epoch: 20, Loss (standarized): 0.20847837851857512\n",
      "          Validation Loss (standardized): 1.7503765895817736\n",
      "Final epoch: 20, Final loss (standarized): 0.20847837851857512\n",
      "Epoch: 1, Loss (standarized): 0.49696209599484065\n",
      "          Validation Loss (standardized): 0.7430483617757201\n",
      "Epoch: 2, Loss (standarized): 0.38627306332580985\n",
      "          Validation Loss (standardized): 0.8176528927616203\n",
      "Epoch: 3, Loss (standarized): 0.30714334016209144\n",
      "          Validation Loss (standardized): 0.9144379705425172\n",
      "Epoch: 4, Loss (standarized): 0.2543387256494729\n",
      "          Validation Loss (standardized): 1.0246436012802411\n",
      "Epoch: 5, Loss (standarized): 0.22163369427052446\n",
      "          Validation Loss (standardized): 1.1401020676547866\n",
      "Epoch: 6, Loss (standarized): 0.20320242442203035\n",
      "          Validation Loss (standardized): 1.254173120814331\n",
      "Epoch: 7, Loss (standarized): 0.1942750971993082\n",
      "          Validation Loss (standardized): 1.3620389491327165\n",
      "Epoch: 8, Loss (standarized): 0.1913027463103978\n",
      "          Validation Loss (standardized): 1.4605905256031158\n",
      "Epoch: 9, Loss (standarized): 0.19181492080502238\n",
      "          Validation Loss (standardized): 1.5480478006763685\n",
      "Epoch: 10, Loss (standarized): 0.1941718904043242\n",
      "          Validation Loss (standardized): 1.6235462600283912\n",
      "Epoch: 11, Loss (standarized): 0.19732292319877473\n",
      "          Validation Loss (standardized): 1.6868502242231915\n",
      "Epoch: 12, Loss (standarized): 0.20061264498594125\n",
      "          Validation Loss (standardized): 1.7382338495080358\n",
      "Epoch: 13, Loss (standarized): 0.20365064549584855\n",
      "          Validation Loss (standardized): 1.7781473092106785\n",
      "Epoch: 14, Loss (standarized): 0.20621051555177836\n",
      "          Validation Loss (standardized): 1.807263156483853\n",
      "Epoch: 15, Loss (standarized): 0.20818010248480695\n",
      "          Validation Loss (standardized): 1.8263775917832197\n",
      "Epoch: 16, Loss (standarized): 0.20951981712296355\n",
      "          Validation Loss (standardized): 1.8363279464891777\n",
      "Epoch: 17, Loss (standarized): 0.21023550370563043\n",
      "          Validation Loss (standardized): 1.8379815737890386\n",
      "Epoch: 18, Loss (standarized): 0.21036505014290166\n",
      "          Validation Loss (standardized): 1.8321347263031214\n",
      "Epoch: 19, Loss (standarized): 0.2099616246277958\n",
      "          Validation Loss (standardized): 1.8195855885430228\n",
      "Epoch: 20, Loss (standarized): 0.20909107301714253\n",
      "          Validation Loss (standardized): 1.8012309927496182\n",
      "Final epoch: 20, Final loss (standarized): 0.20909107301714253\n",
      "Epoch: 1, Loss (standarized): 0.5348113450730504\n",
      "          Validation Loss (standardized): 0.7341213479058541\n",
      "Epoch: 2, Loss (standarized): 0.40031671461635265\n",
      "          Validation Loss (standardized): 0.8149666843368323\n",
      "Epoch: 3, Loss (standarized): 0.3086705317100332\n",
      "          Validation Loss (standardized): 0.9219832330000088\n",
      "Epoch: 4, Loss (standarized): 0.2509927974390911\n",
      "          Validation Loss (standardized): 1.0425237810529338\n",
      "Epoch: 5, Loss (standarized): 0.21757146045337084\n",
      "          Validation Loss (standardized): 1.1662717645245024\n",
      "Epoch: 6, Loss (standarized): 0.20011675962709286\n",
      "          Validation Loss (standardized): 1.2860280598356308\n",
      "Epoch: 7, Loss (standarized): 0.19253837249613887\n",
      "          Validation Loss (standardized): 1.3973301207181672\n",
      "Epoch: 8, Loss (standarized): 0.19074690350150997\n",
      "          Validation Loss (standardized): 1.4977075259634478\n",
      "Epoch: 9, Loss (standarized): 0.19213543841858075\n",
      "          Validation Loss (standardized): 1.5860112642943027\n",
      "Epoch: 10, Loss (standarized): 0.19509109701443417\n",
      "          Validation Loss (standardized): 1.6619307396268532\n",
      "Epoch: 11, Loss (standarized): 0.19863504238770263\n",
      "          Validation Loss (standardized): 1.7256667161168622\n",
      "Epoch: 12, Loss (standarized): 0.20218503970152027\n",
      "          Validation Loss (standardized): 1.7777300076205131\n",
      "Epoch: 13, Loss (standarized): 0.20540606604829906\n",
      "          Validation Loss (standardized): 1.8188142751215128\n",
      "Epoch: 14, Loss (standarized): 0.20811610701930733\n",
      "          Validation Loss (standardized): 1.8496965934456204\n",
      "Epoch: 15, Loss (standarized): 0.21022997671545662\n",
      "          Validation Loss (standardized): 1.871195743655631\n",
      "Epoch: 16, Loss (standarized): 0.2117226371585617\n",
      "          Validation Loss (standardized): 1.8841369264033607\n",
      "Epoch: 17, Loss (standarized): 0.21260685488498798\n",
      "          Validation Loss (standardized): 1.8893320591510636\n",
      "Epoch: 18, Loss (standarized): 0.21291910813964493\n",
      "          Validation Loss (standardized): 1.8875642444011465\n",
      "Epoch: 19, Loss (standarized): 0.2127105958095307\n",
      "          Validation Loss (standardized): 1.8795858314087028\n",
      "Epoch: 20, Loss (standarized): 0.2120411653604653\n",
      "          Validation Loss (standardized): 1.8661162693013986\n",
      "Final epoch: 20, Final loss (standarized): 0.2120411653604653\n",
      "Epoch: 1, Loss (standarized): 1.7826292869680982\n",
      "          Validation Loss (standardized): 0.9427140573280091\n",
      "Epoch: 2, Loss (standarized): 1.4423028900767416\n",
      "          Validation Loss (standardized): 0.8166728174899884\n",
      "Epoch: 3, Loss (standarized): 1.1417801907346663\n",
      "          Validation Loss (standardized): 0.732667168024457\n",
      "Epoch: 4, Loss (standarized): 0.887857120004413\n",
      "          Validation Loss (standardized): 0.6925031240519494\n",
      "Epoch: 5, Loss (standarized): 0.6836044479370421\n",
      "          Validation Loss (standardized): 0.6931825319880821\n",
      "Epoch: 6, Loss (standarized): 0.527368680935165\n",
      "          Validation Loss (standardized): 0.7276346096118199\n",
      "Epoch: 7, Loss (standarized): 0.41332945055219983\n",
      "          Validation Loss (standardized): 0.7867794816375125\n",
      "Epoch: 8, Loss (standarized): 0.33337597497448107\n",
      "          Validation Loss (standardized): 0.8616767360399004\n",
      "Epoch: 9, Loss (standarized): 0.2791636749473107\n",
      "          Validation Loss (standardized): 0.9448599809427128\n",
      "Epoch: 10, Loss (standarized): 0.2434540342077871\n",
      "          Validation Loss (standardized): 1.0307622014192688\n",
      "Epoch: 11, Loss (standarized): 0.22060087806640458\n",
      "          Validation Loss (standardized): 1.1155610498511563\n",
      "Epoch: 12, Loss (standarized): 0.20648313692318027\n",
      "          Validation Loss (standardized): 1.196807904114268\n",
      "Epoch: 13, Loss (standarized): 0.19820966341293034\n",
      "          Validation Loss (standardized): 1.2730469567817368\n",
      "Epoch: 14, Loss (standarized): 0.1937961793184017\n",
      "          Validation Loss (standardized): 1.3434961117868733\n",
      "Epoch: 15, Loss (standarized): 0.191896313782111\n",
      "          Validation Loss (standardized): 1.4078186139665854\n",
      "Epoch: 16, Loss (standarized): 0.19160054003746171\n",
      "          Validation Loss (standardized): 1.4659622100969956\n",
      "Epoch: 17, Loss (standarized): 0.1922957494132866\n",
      "          Validation Loss (standardized): 1.5180511651555333\n",
      "Epoch: 18, Loss (standarized): 0.19356863314776016\n",
      "          Validation Loss (standardized): 1.5643127807160169\n",
      "Epoch: 19, Loss (standarized): 0.19514095056043396\n",
      "          Validation Loss (standardized): 1.605036541110136\n",
      "Epoch: 20, Loss (standarized): 0.19682596378283776\n",
      "          Validation Loss (standardized): 1.6405381850704708\n",
      "Final epoch: 20, Final loss (standarized): 0.19682596378283776\n",
      "Epoch: 1, Loss (standarized): 0.31069199843481143\n",
      "          Validation Loss (standardized): 0.9112994622371974\n",
      "Epoch: 2, Loss (standarized): 0.2557079317221215\n",
      "          Validation Loss (standardized): 1.0271592429584075\n",
      "Epoch: 3, Loss (standarized): 0.2211434394954797\n",
      "          Validation Loss (standardized): 1.1518690020663258\n",
      "Epoch: 4, Loss (standarized): 0.201930607589394\n",
      "          Validation Loss (standardized): 1.2765921889118568\n",
      "Epoch: 5, Loss (standarized): 0.19324581946787328\n",
      "          Validation Loss (standardized): 1.3938343928922703\n",
      "Epoch: 6, Loss (standarized): 0.19109306244653568\n",
      "          Validation Loss (standardized): 1.4981210115581203\n",
      "Epoch: 7, Loss (standarized): 0.19250696860546684\n",
      "          Validation Loss (standardized): 1.5860984949861552\n",
      "Epoch: 8, Loss (standarized): 0.19547811272229143\n",
      "          Validation Loss (standardized): 1.656250059383923\n",
      "Epoch: 9, Loss (standarized): 0.19875215360451212\n",
      "          Validation Loss (standardized): 1.7084761032897495\n",
      "Epoch: 10, Loss (standarized): 0.2016151673816553\n",
      "          Validation Loss (standardized): 1.74359703551459\n",
      "Epoch: 11, Loss (standarized): 0.20371192237868602\n",
      "          Validation Loss (standardized): 1.7629784585088775\n",
      "Epoch: 12, Loss (standarized): 0.204913433349191\n",
      "          Validation Loss (standardized): 1.768258443052199\n",
      "Epoch: 13, Loss (standarized): 0.20522794796969315\n",
      "          Validation Loss (standardized): 1.7612031912894377\n",
      "Epoch: 14, Loss (standarized): 0.20474672869866292\n",
      "          Validation Loss (standardized): 1.7436116592834128\n",
      "Epoch: 15, Loss (standarized): 0.2036091123606272\n",
      "          Validation Loss (standardized): 1.7172629372589108\n",
      "Epoch: 16, Loss (standarized): 0.20198137233381852\n",
      "          Validation Loss (standardized): 1.683893980886827\n",
      "Epoch: 17, Loss (standarized): 0.20004229336593965\n",
      "          Validation Loss (standardized): 1.6451910569860837\n",
      "Epoch: 18, Loss (standarized): 0.1979728903726573\n",
      "          Validation Loss (standardized): 1.6027826045228781\n",
      "Epoch: 19, Loss (standarized): 0.1959467525371386\n",
      "          Validation Loss (standardized): 1.5582417061413654\n",
      "Epoch: 20, Loss (standarized): 0.1941206878741773\n",
      "          Validation Loss (standardized): 1.513073546548909\n",
      "Final epoch: 20, Final loss (standarized): 0.1941206878741773\n",
      "Epoch: 1, Loss (standarized): 0.20528715547910847\n",
      "          Validation Loss (standardized): 1.3096248711145138\n",
      "Epoch: 2, Loss (standarized): 0.19251721313307774\n",
      "          Validation Loss (standardized): 1.4750911577992716\n",
      "Epoch: 3, Loss (standarized): 0.1925741020930885\n",
      "          Validation Loss (standardized): 1.5762018093090857\n",
      "Epoch: 4, Loss (standarized): 0.19574302413508624\n",
      "          Validation Loss (standardized): 1.607749810232153\n",
      "Epoch: 5, Loss (standarized): 0.19702210558992522\n",
      "          Validation Loss (standardized): 1.5875694130488858\n",
      "Epoch: 6, Loss (standarized): 0.19601413314894012\n",
      "          Validation Loss (standardized): 1.5346399195339047\n",
      "Epoch: 7, Loss (standarized): 0.19386651244804376\n",
      "          Validation Loss (standardized): 1.4646507006608551\n",
      "Epoch: 8, Loss (standarized): 0.19187992772588627\n",
      "          Validation Loss (standardized): 1.3912462570307462\n",
      "Epoch: 9, Loss (standarized): 0.1910142474884955\n",
      "          Validation Loss (standardized): 1.3273192817021486\n",
      "Epoch: 10, Loss (standarized): 0.1914985368222634\n",
      "          Validation Loss (standardized): 1.2839143632881855\n",
      "Epoch: 11, Loss (standarized): 0.19261044875430744\n",
      "          Validation Loss (standardized): 1.2668893862836987\n",
      "Epoch: 12, Loss (standarized): 0.1932192132065213\n",
      "          Validation Loss (standardized): 1.2752803477595214\n",
      "Epoch: 13, Loss (standarized): 0.19282705998147884\n",
      "          Validation Loss (standardized): 1.3035794297171015\n",
      "Epoch: 14, Loss (standarized): 0.19182990673618736\n",
      "          Validation Loss (standardized): 1.3443545081051929\n",
      "Epoch: 15, Loss (standarized): 0.19093162884748852\n",
      "          Validation Loss (standardized): 1.3894155981484408\n",
      "Epoch: 16, Loss (standarized): 0.1905720690121979\n",
      "          Validation Loss (standardized): 1.4307972528100756\n",
      "Epoch: 17, Loss (standarized): 0.1907452711985808\n",
      "          Validation Loss (standardized): 1.461937198260965\n",
      "Epoch: 18, Loss (standarized): 0.19114644358315352\n",
      "          Validation Loss (standardized): 1.4787777790440748\n",
      "Epoch: 19, Loss (standarized): 0.19143181447583926\n",
      "          Validation Loss (standardized): 1.4801600541338176\n",
      "Epoch: 20, Loss (standarized): 0.1914110361076379\n",
      "          Validation Loss (standardized): 1.467504395008846\n",
      "Final epoch: 20, Final loss (standarized): 0.1914110361076379\n",
      "Epoch: 1, Loss (standarized): 0.2975992702512402\n",
      "          Validation Loss (standardized): 0.941503271365046\n",
      "Epoch: 2, Loss (standarized): 0.2442313541296358\n",
      "          Validation Loss (standardized): 1.0696796936706254\n",
      "Epoch: 3, Loss (standarized): 0.2131031751661007\n",
      "          Validation Loss (standardized): 1.2032002345643285\n",
      "Epoch: 4, Loss (standarized): 0.1975929268242537\n",
      "          Validation Loss (standardized): 1.3320484923496718\n",
      "Epoch: 5, Loss (standarized): 0.19193300770177135\n",
      "          Validation Loss (standardized): 1.4488952817225391\n",
      "Epoch: 6, Loss (standarized): 0.19180771260180338\n",
      "          Validation Loss (standardized): 1.549216781874828\n",
      "Epoch: 7, Loss (standarized): 0.19432077461218109\n",
      "          Validation Loss (standardized): 1.630849333814765\n",
      "Epoch: 8, Loss (standarized): 0.19768529133361826\n",
      "          Validation Loss (standardized): 1.6933663838756714\n",
      "Epoch: 9, Loss (standarized): 0.2008834126728658\n",
      "          Validation Loss (standardized): 1.7374733966078921\n",
      "Epoch: 10, Loss (standarized): 0.20339258982498049\n",
      "          Validation Loss (standardized): 1.7645281993170292\n",
      "Epoch: 11, Loss (standarized): 0.20499389358551473\n",
      "          Validation Loss (standardized): 1.7762169011814581\n",
      "Epoch: 12, Loss (standarized): 0.2056487985361974\n",
      "          Validation Loss (standardized): 1.774357833964903\n",
      "Epoch: 13, Loss (standarized): 0.20542408738782303\n",
      "          Validation Loss (standardized): 1.7607941053155052\n",
      "Epoch: 14, Loss (standarized): 0.20444743887612293\n",
      "          Validation Loss (standardized): 1.7373422848189848\n",
      "Epoch: 15, Loss (standarized): 0.20288139051670515\n",
      "          Validation Loss (standardized): 1.7057742111587586\n",
      "Epoch: 16, Loss (standarized): 0.2009076087664838\n",
      "          Validation Loss (standardized): 1.6678165151361757\n",
      "Epoch: 17, Loss (standarized): 0.19871625460060846\n",
      "          Validation Loss (standardized): 1.625157568619117\n",
      "Epoch: 18, Loss (standarized): 0.19649701509274273\n",
      "          Validation Loss (standardized): 1.5794546239631915\n",
      "Epoch: 19, Loss (standarized): 0.19442952616608453\n",
      "          Validation Loss (standardized): 1.5323355810867383\n",
      "Epoch: 20, Loss (standarized): 0.1926718513479948\n",
      "          Validation Loss (standardized): 1.485390827505945\n",
      "Final epoch: 20, Final loss (standarized): 0.1926718513479948\n",
      "Epoch: 1, Loss (standarized): 0.6693350284578735\n",
      "          Validation Loss (standardized): 0.6929182028355312\n",
      "Epoch: 2, Loss (standarized): 0.522565112934067\n",
      "          Validation Loss (standardized): 0.7279274513122121\n",
      "Epoch: 3, Loss (standarized): 0.41050673144480926\n",
      "          Validation Loss (standardized): 0.7897129595612045\n",
      "Epoch: 4, Loss (standarized): 0.3293546882426934\n",
      "          Validation Loss (standardized): 0.8707601347692178\n",
      "Epoch: 5, Loss (standarized): 0.27354607684132337\n",
      "          Validation Loss (standardized): 0.9633137449229534\n",
      "Epoch: 6, Loss (standarized): 0.2370626683236913\n",
      "          Validation Loss (standardized): 1.0606129204381889\n",
      "Epoch: 7, Loss (standarized): 0.21446584980715244\n",
      "          Validation Loss (standardized): 1.1574372243710205\n",
      "Epoch: 8, Loss (standarized): 0.20139172301274008\n",
      "          Validation Loss (standardized): 1.2501194866028529\n",
      "Epoch: 9, Loss (standarized): 0.19460338540179942\n",
      "          Validation Loss (standardized): 1.3362868462206723\n",
      "Epoch: 10, Loss (standarized): 0.1918188901733208\n",
      "          Validation Loss (standardized): 1.4145345592397545\n",
      "Epoch: 11, Loss (standarized): 0.1914800265850461\n",
      "          Validation Loss (standardized): 1.4841375228224882\n",
      "Epoch: 12, Loss (standarized): 0.19254390814458866\n",
      "          Validation Loss (standardized): 1.5448319790600087\n",
      "Epoch: 13, Loss (standarized): 0.19432221276945902\n",
      "          Validation Loss (standardized): 1.5966603893796485\n",
      "Epoch: 14, Loss (standarized): 0.19636662576213662\n",
      "          Validation Loss (standardized): 1.6398639638757693\n",
      "Epoch: 15, Loss (standarized): 0.19839038036847254\n",
      "          Validation Loss (standardized): 1.674810174518347\n",
      "Epoch: 16, Loss (standarized): 0.20021541498273862\n",
      "          Validation Loss (standardized): 1.7019445143408831\n",
      "Epoch: 17, Loss (standarized): 0.20173704632633943\n",
      "          Validation Loss (standardized): 1.7217582361365702\n",
      "Epoch: 18, Loss (standarized): 0.20290043102869532\n",
      "          Validation Loss (standardized): 1.7347670666871886\n",
      "Epoch: 19, Loss (standarized): 0.20368485527669186\n",
      "          Validation Loss (standardized): 1.741497494942006\n",
      "Epoch: 20, Loss (standarized): 0.20409320953512014\n",
      "          Validation Loss (standardized): 1.742478278166464\n",
      "Final epoch: 20, Final loss (standarized): 0.20409320953512014\n",
      "Epoch: 1, Loss (standarized): 0.20356261090895192\n",
      "          Validation Loss (standardized): 1.2836258906428544\n",
      "Epoch: 2, Loss (standarized): 0.19330211486802124\n",
      "          Validation Loss (standardized): 1.4192864798459106\n",
      "Epoch: 3, Loss (standarized): 0.1916216254801574\n",
      "          Validation Loss (standardized): 1.5177836865728311\n",
      "Epoch: 4, Loss (standarized): 0.19351488112467288\n",
      "          Validation Loss (standardized): 1.5666996901087997\n",
      "Epoch: 5, Loss (standarized): 0.19515529897891504\n",
      "          Validation Loss (standardized): 1.5723978573986068\n",
      "Epoch: 6, Loss (standarized): 0.19532038217269376\n",
      "          Validation Loss (standardized): 1.547195834762587\n",
      "Epoch: 7, Loss (standarized): 0.1943099203989991\n",
      "          Validation Loss (standardized): 1.502512912966045\n",
      "Epoch: 8, Loss (standarized): 0.1928516326735272\n",
      "          Validation Loss (standardized): 1.4479989143213385\n",
      "Epoch: 9, Loss (standarized): 0.1916436467644683\n",
      "          Validation Loss (standardized): 1.3922140954008295\n",
      "Epoch: 10, Loss (standarized): 0.19114827549393393\n",
      "          Validation Loss (standardized): 1.3430612730883558\n",
      "Epoch: 11, Loss (standarized): 0.19143531514619472\n",
      "          Validation Loss (standardized): 1.3072309965520212\n",
      "Epoch: 12, Loss (standarized): 0.19213370406128524\n",
      "          Validation Loss (standardized): 1.2887601157380566\n",
      "Epoch: 13, Loss (standarized): 0.19266295187731683\n",
      "          Validation Loss (standardized): 1.2881317790104745\n",
      "Epoch: 14, Loss (standarized): 0.19265526483753762\n",
      "          Validation Loss (standardized): 1.3029208884128745\n",
      "Epoch: 15, Loss (standarized): 0.19216395595906843\n",
      "          Validation Loss (standardized): 1.329045547650316\n",
      "Epoch: 16, Loss (standarized): 0.19151576731598577\n",
      "          Validation Loss (standardized): 1.3616087003042014\n",
      "Epoch: 17, Loss (standarized): 0.1910414599988689\n",
      "          Validation Loss (standardized): 1.39539721074682\n",
      "Epoch: 18, Loss (standarized): 0.1908978036952389\n",
      "          Validation Loss (standardized): 1.4254313032922539\n",
      "Epoch: 19, Loss (standarized): 0.19103615989909997\n",
      "          Validation Loss (standardized): 1.4476569251438773\n",
      "Epoch: 20, Loss (standarized): 0.1912818018634833\n",
      "          Validation Loss (standardized): 1.459550466981982\n",
      "Final epoch: 20, Final loss (standarized): 0.1912818018634833\n",
      "Epoch: 1, Loss (standarized): 0.6347924245072043\n",
      "          Validation Loss (standardized): 0.6980370121214559\n",
      "Epoch: 2, Loss (standarized): 0.4988287127677048\n",
      "          Validation Loss (standardized): 0.7377437229030579\n",
      "Epoch: 3, Loss (standarized): 0.39439563949826045\n",
      "          Validation Loss (standardized): 0.802941604799528\n",
      "Epoch: 4, Loss (standarized): 0.3183077854173381\n",
      "          Validation Loss (standardized): 0.8870491916843344\n",
      "Epoch: 5, Loss (standarized): 0.26571359592341864\n",
      "          Validation Loss (standardized): 0.9831570203511794\n",
      "Epoch: 6, Loss (standarized): 0.23128607348957683\n",
      "          Validation Loss (standardized): 1.0850246537469457\n",
      "Epoch: 7, Loss (standarized): 0.21013024628013763\n",
      "          Validation Loss (standardized): 1.1875802492456289\n",
      "Epoch: 8, Loss (standarized): 0.1982293721689659\n",
      "          Validation Loss (standardized): 1.2870158769303504\n",
      "Epoch: 9, Loss (standarized): 0.19252422139223804\n",
      "          Validation Loss (standardized): 1.3806590922923432\n",
      "Epoch: 10, Loss (standarized): 0.19079829579666066\n",
      "          Validation Loss (standardized): 1.4667633938359506\n",
      "Epoch: 11, Loss (standarized): 0.19149954024531388\n",
      "          Validation Loss (standardized): 1.5442946405264066\n",
      "Epoch: 12, Loss (standarized): 0.19356752480525036\n",
      "          Validation Loss (standardized): 1.612745061131311\n",
      "Epoch: 13, Loss (standarized): 0.19629199699113617\n",
      "          Validation Loss (standardized): 1.6719832841573068\n",
      "Epoch: 14, Loss (standarized): 0.19920651784566515\n",
      "          Validation Loss (standardized): 1.7221390568762707\n",
      "Epoch: 15, Loss (standarized): 0.2020121686547665\n",
      "          Validation Loss (standardized): 1.7635175951451891\n",
      "Epoch: 16, Loss (standarized): 0.20452429649750645\n",
      "          Validation Loss (standardized): 1.7965376564104552\n",
      "Epoch: 17, Loss (standarized): 0.20663592124975208\n",
      "          Validation Loss (standardized): 1.8216878394912623\n",
      "Epoch: 18, Loss (standarized): 0.20829281051518966\n",
      "          Validation Loss (standardized): 1.8394964610291096\n",
      "Epoch: 19, Loss (standarized): 0.20947657481037368\n",
      "          Validation Loss (standardized): 1.8505112884209327\n",
      "Epoch: 20, Loss (standarized): 0.21019321570802504\n",
      "          Validation Loss (standardized): 1.8552862731418502\n",
      "Final epoch: 20, Final loss (standarized): 0.21019321570802504\n",
      "Epoch: 1, Loss (standarized): 0.6909454443445316\n",
      "          Validation Loss (standardized): 0.6879910692686354\n",
      "Epoch: 2, Loss (standarized): 0.5764505400629641\n",
      "          Validation Loss (standardized): 0.7014265152168768\n",
      "Epoch: 3, Loss (standarized): 0.4815128955454755\n",
      "          Validation Loss (standardized): 0.730967637058355\n",
      "Epoch: 4, Loss (standarized): 0.40525196989798046\n",
      "          Validation Loss (standardized): 0.7737831691673632\n",
      "Epoch: 5, Loss (standarized): 0.34558281684537645\n",
      "          Validation Loss (standardized): 0.8268222508142824\n",
      "Epoch: 6, Loss (standarized): 0.2999440582925999\n",
      "          Validation Loss (standardized): 0.8867788444339826\n",
      "Epoch: 7, Loss (standarized): 0.2659398363800482\n",
      "          Validation Loss (standardized): 0.9506470437149618\n",
      "Epoch: 8, Loss (standarized): 0.24118796378131255\n",
      "          Validation Loss (standardized): 1.0159668245843263\n",
      "Epoch: 9, Loss (standarized): 0.22355895043674145\n",
      "          Validation Loss (standardized): 1.0807284176744543\n",
      "Epoch: 10, Loss (standarized): 0.21130882520953898\n",
      "          Validation Loss (standardized): 1.1432782704164572\n",
      "Epoch: 11, Loss (standarized): 0.2030571547986437\n",
      "          Validation Loss (standardized): 1.2026971149886507\n",
      "Epoch: 12, Loss (standarized): 0.19769422781118043\n",
      "          Validation Loss (standardized): 1.2581266154862618\n",
      "Epoch: 13, Loss (standarized): 0.19440933257415421\n",
      "          Validation Loss (standardized): 1.3090707936095032\n",
      "Epoch: 14, Loss (standarized): 0.19258305194562608\n",
      "          Validation Loss (standardized): 1.3553975845629394\n",
      "Epoch: 15, Loss (standarized): 0.19175327761426333\n",
      "          Validation Loss (standardized): 1.3971376304581804\n",
      "Epoch: 16, Loss (standarized): 0.19158740599309718\n",
      "          Validation Loss (standardized): 1.434156072129088\n",
      "Epoch: 17, Loss (standarized): 0.19184641332529453\n",
      "          Validation Loss (standardized): 1.4663720719383833\n",
      "Epoch: 18, Loss (standarized): 0.19234947837192332\n",
      "          Validation Loss (standardized): 1.4935803813109039\n",
      "Epoch: 19, Loss (standarized): 0.19295693509561704\n",
      "          Validation Loss (standardized): 1.515714530756204\n",
      "Epoch: 20, Loss (standarized): 0.1935648560507805\n",
      "          Validation Loss (standardized): 1.5329608375394879\n",
      "Final epoch: 20, Final loss (standarized): 0.1935648560507805\n",
      "Epoch: 1, Loss (standarized): 1.3976599416138513\n",
      "          Validation Loss (standardized): 0.8205087123895635\n",
      "Epoch: 2, Loss (standarized): 1.1527903122066212\n",
      "          Validation Loss (standardized): 0.7465525280779011\n",
      "Epoch: 3, Loss (standarized): 0.9383053839835199\n",
      "          Validation Loss (standardized): 0.7022652948684558\n",
      "Epoch: 4, Loss (standarized): 0.7563787630194119\n",
      "          Validation Loss (standardized): 0.6873549824072495\n",
      "Epoch: 5, Loss (standarized): 0.6078471559130724\n",
      "          Validation Loss (standardized): 0.6990112945372629\n",
      "Epoch: 6, Loss (standarized): 0.4909700420891637\n",
      "          Validation Loss (standardized): 0.7325941023590691\n",
      "Epoch: 7, Loss (standarized): 0.40199786147543376\n",
      "          Validation Loss (standardized): 0.7825384572250761\n",
      "Epoch: 8, Loss (standarized): 0.33629386725889027\n",
      "          Validation Loss (standardized): 0.8433817213653881\n",
      "Epoch: 9, Loss (standarized): 0.28893903554407435\n",
      "          Validation Loss (standardized): 0.9103524361267862\n",
      "Epoch: 10, Loss (standarized): 0.2555226337680698\n",
      "          Validation Loss (standardized): 0.9796503156905695\n",
      "Epoch: 11, Loss (standarized): 0.23239144034435066\n",
      "          Validation Loss (standardized): 1.0482580826133125\n",
      "Epoch: 12, Loss (standarized): 0.21672719241677002\n",
      "          Validation Loss (standardized): 1.1143191784790494\n",
      "Epoch: 13, Loss (standarized): 0.206334812205135\n",
      "          Validation Loss (standardized): 1.1765684130792047\n",
      "Epoch: 14, Loss (standarized): 0.19963799511468547\n",
      "          Validation Loss (standardized): 1.2342313488475773\n",
      "Epoch: 15, Loss (standarized): 0.1955035479156601\n",
      "          Validation Loss (standardized): 1.2869833505190513\n",
      "Epoch: 16, Loss (standarized): 0.19311983295523613\n",
      "          Validation Loss (standardized): 1.3346497239102717\n",
      "Epoch: 17, Loss (standarized): 0.19192018478354012\n",
      "          Validation Loss (standardized): 1.376936383538027\n",
      "Epoch: 18, Loss (standarized): 0.1915017306210614\n",
      "          Validation Loss (standardized): 1.4139481989497031\n",
      "Epoch: 19, Loss (standarized): 0.19157041814685175\n",
      "          Validation Loss (standardized): 1.4459234651425215\n",
      "Epoch: 20, Loss (standarized): 0.19192035295880172\n",
      "          Validation Loss (standardized): 1.472993062604459\n",
      "Final epoch: 20, Final loss (standarized): 0.19192035295880172\n",
      "Epoch: 1, Loss (standarized): 0.35383693582770853\n",
      "          Validation Loss (standardized): 0.8448578124593641\n",
      "Epoch: 2, Loss (standarized): 0.29159425795423927\n",
      "          Validation Loss (standardized): 0.9317801464328579\n",
      "Epoch: 3, Loss (standarized): 0.24985749857189532\n",
      "          Validation Loss (standardized): 1.0251251756264654\n",
      "Epoch: 4, Loss (standarized): 0.22317021271610948\n",
      "          Validation Loss (standardized): 1.1186994394366983\n",
      "Epoch: 5, Loss (standarized): 0.20714248381917957\n",
      "          Validation Loss (standardized): 1.20714067034087\n",
      "Epoch: 6, Loss (standarized): 0.1983110528563738\n",
      "          Validation Loss (standardized): 1.2873224201768243\n",
      "Epoch: 7, Loss (standarized): 0.1940030571069304\n",
      "          Validation Loss (standardized): 1.3573784919993301\n",
      "Epoch: 8, Loss (standarized): 0.19238697772287353\n",
      "          Validation Loss (standardized): 1.4165999541329424\n",
      "Epoch: 9, Loss (standarized): 0.1922564680231008\n",
      "          Validation Loss (standardized): 1.4645997816288852\n",
      "Epoch: 10, Loss (standarized): 0.19283642687932812\n",
      "          Validation Loss (standardized): 1.5015364614400601\n",
      "Epoch: 11, Loss (standarized): 0.19364393233683636\n",
      "          Validation Loss (standardized): 1.5280118990556881\n",
      "Epoch: 12, Loss (standarized): 0.19439343130438042\n",
      "          Validation Loss (standardized): 1.5447413468790654\n",
      "Epoch: 13, Loss (standarized): 0.19493015030336325\n",
      "          Validation Loss (standardized): 1.5525669698596567\n",
      "Epoch: 14, Loss (standarized): 0.19518762209339074\n",
      "          Validation Loss (standardized): 1.5522380673830325\n",
      "Epoch: 15, Loss (standarized): 0.195153473425082\n",
      "          Validation Loss (standardized): 1.5448063333869737\n",
      "Epoch: 16, Loss (standarized): 0.19486501526466268\n",
      "          Validation Loss (standardized): 1.531606696968532\n",
      "Epoch: 17, Loss (standarized): 0.1943931522850767\n",
      "          Validation Loss (standardized): 1.5141837706429604\n",
      "Epoch: 18, Loss (standarized): 0.19382631681256296\n",
      "          Validation Loss (standardized): 1.4936346455355909\n",
      "Epoch: 19, Loss (standarized): 0.19323801647159272\n",
      "          Validation Loss (standardized): 1.4711398745689497\n",
      "Epoch: 20, Loss (standarized): 0.19269773110512883\n",
      "          Validation Loss (standardized): 1.4473097433446878\n",
      "Final epoch: 20, Final loss (standarized): 0.19269773110512883\n",
      "Epoch: 1, Loss (standarized): 0.976928142270628\n",
      "          Validation Loss (standardized): 0.7078508127257311\n",
      "Epoch: 2, Loss (standarized): 0.7805997158942217\n",
      "          Validation Loss (standardized): 0.688729039254379\n",
      "Epoch: 3, Loss (standarized): 0.617646413171585\n",
      "          Validation Loss (standardized): 0.7006539752357079\n",
      "Epoch: 4, Loss (standarized): 0.48987905546397725\n",
      "          Validation Loss (standardized): 0.738498393364057\n",
      "Epoch: 5, Loss (standarized): 0.394341492194583\n",
      "          Validation Loss (standardized): 0.7954159903001354\n",
      "Epoch: 6, Loss (standarized): 0.3255558772389315\n",
      "          Validation Loss (standardized): 0.8644391815200737\n",
      "Epoch: 7, Loss (standarized): 0.27759028498770305\n",
      "          Validation Loss (standardized): 0.9395007183779301\n",
      "Epoch: 8, Loss (standarized): 0.24504913541189277\n",
      "          Validation Loss (standardized): 1.0158695664893336\n",
      "Epoch: 9, Loss (standarized): 0.2235261637353772\n",
      "          Validation Loss (standardized): 1.0902099355508563\n",
      "Epoch: 10, Loss (standarized): 0.20966013075083711\n",
      "          Validation Loss (standardized): 1.1604326016008601\n",
      "Epoch: 11, Loss (standarized): 0.20100301198253195\n",
      "          Validation Loss (standardized): 1.2250565388343286\n",
      "Epoch: 12, Loss (standarized): 0.19585574749106627\n",
      "          Validation Loss (standardized): 1.2834972862542102\n",
      "Epoch: 13, Loss (standarized): 0.19301364313561564\n",
      "          Validation Loss (standardized): 1.33528882620532\n",
      "Epoch: 14, Loss (standarized): 0.19166250636637017\n",
      "          Validation Loss (standardized): 1.380295338852875\n",
      "Epoch: 15, Loss (standarized): 0.19123758955384038\n",
      "          Validation Loss (standardized): 1.4187888555952752\n",
      "Epoch: 16, Loss (standarized): 0.1913532958665694\n",
      "          Validation Loss (standardized): 1.4513148426341105\n",
      "Epoch: 17, Loss (standarized): 0.19175720414649183\n",
      "          Validation Loss (standardized): 1.4783803184477102\n",
      "Epoch: 18, Loss (standarized): 0.1922885268997944\n",
      "          Validation Loss (standardized): 1.500055915358258\n",
      "Epoch: 19, Loss (standarized): 0.19283402919670034\n",
      "          Validation Loss (standardized): 1.5168640079154119\n",
      "Epoch: 20, Loss (standarized): 0.19332758666473038\n",
      "          Validation Loss (standardized): 1.5292966692121341\n",
      "Final epoch: 20, Final loss (standarized): 0.19332758666473038\n",
      "Epoch: 1, Loss (standarized): 0.26335151062758844\n",
      "          Validation Loss (standardized): 1.0390905498589502\n",
      "Epoch: 2, Loss (standarized): 0.2188366453548951\n",
      "          Validation Loss (standardized): 1.199870913566522\n",
      "Epoch: 3, Loss (standarized): 0.1978970959097654\n",
      "          Validation Loss (standardized): 1.3566355770809038\n",
      "Epoch: 4, Loss (standarized): 0.19162300219360315\n",
      "          Validation Loss (standardized): 1.4934093655524043\n",
      "Epoch: 5, Loss (standarized): 0.19275427276726045\n",
      "          Validation Loss (standardized): 1.6012867159057067\n",
      "Epoch: 6, Loss (standarized): 0.19649742640342524\n",
      "          Validation Loss (standardized): 1.6777726300086804\n",
      "Epoch: 7, Loss (standarized): 0.20026622201054795\n",
      "          Validation Loss (standardized): 1.724318002353718\n",
      "Epoch: 8, Loss (standarized): 0.20292248869043392\n",
      "          Validation Loss (standardized): 1.744273337909531\n",
      "Epoch: 9, Loss (standarized): 0.20412811507583473\n",
      "          Validation Loss (standardized): 1.7415259192330523\n",
      "Epoch: 10, Loss (standarized): 0.20394341750787776\n",
      "          Validation Loss (standardized): 1.7200385293982132\n",
      "Epoch: 11, Loss (standarized): 0.20262489891995938\n",
      "          Validation Loss (standardized): 1.6836790157228767\n",
      "Epoch: 12, Loss (standarized): 0.20052397255080276\n",
      "          Validation Loss (standardized): 1.6361019396170264\n",
      "Epoch: 13, Loss (standarized): 0.19802895087224545\n",
      "          Validation Loss (standardized): 1.5809611165324111\n",
      "Epoch: 14, Loss (standarized): 0.19553853596100446\n",
      "          Validation Loss (standardized): 1.5218464093892294\n",
      "Epoch: 15, Loss (standarized): 0.19342195159389994\n",
      "          Validation Loss (standardized): 1.4621716498266324\n",
      "Epoch: 16, Loss (standarized): 0.1919663207384629\n",
      "          Validation Loss (standardized): 1.4051982316860658\n",
      "Epoch: 17, Loss (standarized): 0.19133388991896666\n",
      "          Validation Loss (standardized): 1.3539152037113595\n",
      "Epoch: 18, Loss (standarized): 0.19151243345646782\n",
      "          Validation Loss (standardized): 1.3110580166615449\n",
      "Epoch: 19, Loss (standarized): 0.19229865520882392\n",
      "          Validation Loss (standardized): 1.2785390546397837\n",
      "Epoch: 20, Loss (standarized): 0.19333867219921114\n",
      "          Validation Loss (standardized): 1.257579976380544\n",
      "Final epoch: 20, Final loss (standarized): 0.19333867219921114\n",
      "Epoch: 1, Loss (standarized): 0.20891923665585355\n",
      "          Validation Loss (standardized): 1.2365922493282582\n",
      "Epoch: 2, Loss (standarized): 0.19523619102556033\n",
      "          Validation Loss (standardized): 1.3558724614225537\n",
      "Epoch: 3, Loss (standarized): 0.19138739135620647\n",
      "          Validation Loss (standardized): 1.4428935006436923\n",
      "Epoch: 4, Loss (standarized): 0.19155796095465477\n",
      "          Validation Loss (standardized): 1.494327599843333\n",
      "Epoch: 5, Loss (standarized): 0.19255632311816737\n",
      "          Validation Loss (standardized): 1.5147079085961928\n",
      "Epoch: 6, Loss (standarized): 0.19310955974834346\n",
      "          Validation Loss (standardized): 1.510814381145381\n",
      "Epoch: 7, Loss (standarized): 0.19299805021233601\n",
      "          Validation Loss (standardized): 1.489203634623773\n",
      "Epoch: 8, Loss (standarized): 0.1924311424817246\n",
      "          Validation Loss (standardized): 1.4560018253500555\n",
      "Epoch: 9, Loss (standarized): 0.191754022010603\n",
      "          Validation Loss (standardized): 1.4168074586858834\n",
      "Epoch: 10, Loss (standarized): 0.19128560832190575\n",
      "          Validation Loss (standardized): 1.3767478779992874\n",
      "Epoch: 11, Loss (standarized): 0.19122296696075872\n",
      "          Validation Loss (standardized): 1.3402503726150954\n",
      "Epoch: 12, Loss (standarized): 0.19157858964678126\n",
      "          Validation Loss (standardized): 1.3115696496120257\n",
      "Epoch: 13, Loss (standarized): 0.19216852440306192\n",
      "          Validation Loss (standardized): 1.2934209415859075\n",
      "Epoch: 14, Loss (standarized): 0.1926996236233978\n",
      "          Validation Loss (standardized): 1.2866202089680236\n",
      "Epoch: 15, Loss (standarized): 0.19293890688481333\n",
      "          Validation Loss (standardized): 1.2902722130368118\n",
      "Epoch: 16, Loss (standarized): 0.19282766712119007\n",
      "          Validation Loss (standardized): 1.302385593825337\n",
      "Epoch: 17, Loss (standarized): 0.19246683548076118\n",
      "          Validation Loss (standardized): 1.3203937242962496\n",
      "Epoch: 18, Loss (standarized): 0.19202616604757916\n",
      "          Validation Loss (standardized): 1.3414496102758513\n",
      "Epoch: 19, Loss (standarized): 0.19165426311962971\n",
      "          Validation Loss (standardized): 1.362558981775302\n",
      "Epoch: 20, Loss (standarized): 0.19142820975813718\n",
      "          Validation Loss (standardized): 1.3811993007863692\n",
      "Final epoch: 20, Final loss (standarized): 0.19142820975813718\n",
      "Epoch: 1, Loss (standarized): 0.36451745438313254\n",
      "          Validation Loss (standardized): 0.8576530969505405\n",
      "Epoch: 2, Loss (standarized): 0.28071887852873945\n",
      "          Validation Loss (standardized): 0.9859664186857632\n",
      "Epoch: 3, Loss (standarized): 0.23087657202158554\n",
      "          Validation Loss (standardized): 1.1265638257419244\n",
      "Epoch: 4, Loss (standarized): 0.2050025723585872\n",
      "          Validation Loss (standardized): 1.2656399449722944\n",
      "Epoch: 5, Loss (standarized): 0.19412944492178424\n",
      "          Validation Loss (standardized): 1.3936205141525868\n",
      "Epoch: 6, Loss (standarized): 0.19166131863078328\n",
      "          Validation Loss (standardized): 1.5052233287982022\n",
      "Epoch: 7, Loss (standarized): 0.1933531904456125\n",
      "          Validation Loss (standardized): 1.5982896999937837\n",
      "Epoch: 8, Loss (standarized): 0.19671321291762514\n",
      "          Validation Loss (standardized): 1.672514947112556\n",
      "Epoch: 9, Loss (standarized): 0.20036388567346447\n",
      "          Validation Loss (standardized): 1.728653801194363\n",
      "Epoch: 10, Loss (standarized): 0.2035869059388279\n",
      "          Validation Loss (standardized): 1.7680150051573482\n",
      "Epoch: 11, Loss (standarized): 0.20604539663593882\n",
      "          Validation Loss (standardized): 1.7921216551487078\n",
      "Epoch: 12, Loss (standarized): 0.20761538789297318\n",
      "          Validation Loss (standardized): 1.8025549410322208\n",
      "Epoch: 13, Loss (standarized): 0.20829122383403037\n",
      "          Validation Loss (standardized): 1.800852321731796\n",
      "Epoch: 14, Loss (standarized): 0.20814012375119623\n",
      "          Validation Loss (standardized): 1.7885157632248785\n",
      "Epoch: 15, Loss (standarized): 0.20727026669255794\n",
      "          Validation Loss (standardized): 1.7670044457598846\n",
      "Epoch: 16, Loss (standarized): 0.20581459275189617\n",
      "          Validation Loss (standardized): 1.7377608038128796\n",
      "Epoch: 17, Loss (standarized): 0.2039235222804388\n",
      "          Validation Loss (standardized): 1.7021227838998412\n",
      "Epoch: 18, Loss (standarized): 0.20175255977771767\n",
      "          Validation Loss (standardized): 1.6614596994464101\n",
      "Epoch: 19, Loss (standarized): 0.19946477271787125\n",
      "          Validation Loss (standardized): 1.6171526442060014\n",
      "Epoch: 20, Loss (standarized): 0.19722347115348693\n",
      "          Validation Loss (standardized): 1.5705619086114024\n",
      "Final epoch: 20, Final loss (standarized): 0.19722347115348693\n",
      "Epoch: 1, Loss (standarized): 1.4061704068988714\n",
      "          Validation Loss (standardized): 0.8194531644776504\n",
      "Epoch: 2, Loss (standarized): 1.1500875138314557\n",
      "          Validation Loss (standardized): 0.7439620843381074\n",
      "Epoch: 3, Loss (standarized): 0.9296802462311615\n",
      "          Validation Loss (standardized): 0.7005457606045171\n",
      "Epoch: 4, Loss (standarized): 0.7465442378574348\n",
      "          Validation Loss (standardized): 0.6873884472472929\n",
      "Epoch: 5, Loss (standarized): 0.5995735481578558\n",
      "          Validation Loss (standardized): 0.7004836813312108\n",
      "Epoch: 6, Loss (standarized): 0.48537849783459175\n",
      "          Validation Loss (standardized): 0.7345107447837854\n",
      "Epoch: 7, Loss (standarized): 0.39912783681448977\n",
      "          Validation Loss (standardized): 0.7838285838537058\n",
      "Epoch: 8, Loss (standarized): 0.33550709669556367\n",
      "          Validation Loss (standardized): 0.8432532236409852\n",
      "Epoch: 9, Loss (standarized): 0.2894813691653313\n",
      "          Validation Loss (standardized): 0.9084473834490276\n",
      "Epoch: 10, Loss (standarized): 0.2567392935228355\n",
      "          Validation Loss (standardized): 0.9760514157736435\n",
      "Epoch: 11, Loss (standarized): 0.2338070144271824\n",
      "          Validation Loss (standardized): 1.0436023264033505\n",
      "Epoch: 12, Loss (standarized): 0.21801224776601347\n",
      "          Validation Loss (standardized): 1.1093784822219694\n",
      "Epoch: 13, Loss (standarized): 0.20735648413613628\n",
      "          Validation Loss (standardized): 1.1722183940205964\n",
      "Epoch: 14, Loss (standarized): 0.20037092553439698\n",
      "          Validation Loss (standardized): 1.2313987589597988\n",
      "Epoch: 15, Loss (standarized): 0.19598575719020458\n",
      "          Validation Loss (standardized): 1.2864954831767483\n",
      "Epoch: 16, Loss (standarized): 0.19342908228714864\n",
      "          Validation Loss (standardized): 1.3372982270655152\n",
      "Epoch: 17, Loss (standarized): 0.19213804009895324\n",
      "          Validation Loss (standardized): 1.383746048735568\n",
      "Epoch: 18, Loss (standarized): 0.1917160104762591\n",
      "          Validation Loss (standardized): 1.4258793584713234\n",
      "Epoch: 19, Loss (standarized): 0.19187294182928208\n",
      "          Validation Loss (standardized): 1.4638161383840258\n",
      "Epoch: 20, Loss (standarized): 0.1923988364416853\n",
      "          Validation Loss (standardized): 1.4977068245019338\n",
      "Final epoch: 20, Final loss (standarized): 0.1923988364416853\n",
      "Epoch: 1, Loss (standarized): 0.7951319238136473\n",
      "          Validation Loss (standardized): 0.689283747142037\n",
      "Epoch: 2, Loss (standarized): 0.621123209075846\n",
      "          Validation Loss (standardized): 0.7025763615402886\n",
      "Epoch: 3, Loss (standarized): 0.4848729351104187\n",
      "          Validation Loss (standardized): 0.746450691062046\n",
      "Epoch: 4, Loss (standarized): 0.3832209793599988\n",
      "          Validation Loss (standardized): 0.8141434054726084\n",
      "Epoch: 5, Loss (standarized): 0.31089954957612087\n",
      "          Validation Loss (standardized): 0.8981563461222573\n",
      "Epoch: 6, Loss (standarized): 0.2617025349211011\n",
      "          Validation Loss (standardized): 0.9915581094312319\n",
      "Epoch: 7, Loss (standarized): 0.22971337908889267\n",
      "          Validation Loss (standardized): 1.0886612953185903\n",
      "Epoch: 8, Loss (standarized): 0.2099738734574248\n",
      "          Validation Loss (standardized): 1.185171606083043\n",
      "Epoch: 9, Loss (standarized): 0.19865813207052202\n",
      "          Validation Loss (standardized): 1.2780470144009763\n",
      "Epoch: 10, Loss (standarized): 0.1929656031052728\n",
      "          Validation Loss (standardized): 1.365255413785074\n",
      "Epoch: 11, Loss (standarized): 0.19091421285426136\n",
      "          Validation Loss (standardized): 1.4455353613276014\n",
      "Epoch: 12, Loss (standarized): 0.19113141995587576\n",
      "          Validation Loss (standardized): 1.5181885948348783\n",
      "Epoch: 13, Loss (standarized): 0.1926813188765747\n",
      "          Validation Loss (standardized): 1.5829150048773826\n",
      "Epoch: 14, Loss (standarized): 0.194933476701963\n",
      "          Validation Loss (standardized): 1.6396942440753006\n",
      "Epoch: 15, Loss (standarized): 0.19746866262404406\n",
      "          Validation Loss (standardized): 1.6886957786945134\n",
      "Epoch: 16, Loss (standarized): 0.2000124656626456\n",
      "          Validation Loss (standardized): 1.7302098921257212\n",
      "Epoch: 17, Loss (standarized): 0.20238948324158926\n",
      "          Validation Loss (standardized): 1.7645990310666773\n",
      "Epoch: 18, Loss (standarized): 0.20449187349235412\n",
      "          Validation Loss (standardized): 1.7922720456436878\n",
      "Epoch: 19, Loss (standarized): 0.2062582684058507\n",
      "          Validation Loss (standardized): 1.8136606693696833\n",
      "Epoch: 20, Loss (standarized): 0.20765894451154948\n",
      "          Validation Loss (standardized): 1.8292031916864244\n",
      "Final epoch: 20, Final loss (standarized): 0.20765894451154948\n",
      "Epoch: 1, Loss (standarized): 0.6653457982226427\n",
      "          Validation Loss (standardized): 0.695688600661843\n",
      "Epoch: 2, Loss (standarized): 0.5124109619439052\n",
      "          Validation Loss (standardized): 0.7370187989248018\n",
      "Epoch: 3, Loss (standarized): 0.39637418860720713\n",
      "          Validation Loss (standardized): 0.8092863290733848\n",
      "Epoch: 4, Loss (standarized): 0.31370281563012514\n",
      "          Validation Loss (standardized): 0.9041891830970988\n",
      "Epoch: 5, Loss (standarized): 0.25857135661914377\n",
      "          Validation Loss (standardized): 1.0125465775750888\n",
      "Epoch: 6, Loss (standarized): 0.22433964035992615\n",
      "          Validation Loss (standardized): 1.1260536350556567\n",
      "Epoch: 7, Loss (standarized): 0.20484038948237135\n",
      "          Validation Loss (standardized): 1.2382139392320273\n",
      "Epoch: 8, Loss (standarized): 0.1951067182912407\n",
      "          Validation Loss (standardized): 1.3444666628947568\n",
      "Epoch: 9, Loss (standarized): 0.19150461192116042\n",
      "          Validation Loss (standardized): 1.4419071347100487\n",
      "Epoch: 10, Loss (standarized): 0.19153506285937996\n",
      "          Validation Loss (standardized): 1.528888278497491\n",
      "Epoch: 11, Loss (standarized): 0.19354795361103302\n",
      "          Validation Loss (standardized): 1.6046311985931216\n",
      "Epoch: 12, Loss (standarized): 0.1964828215234007\n",
      "          Validation Loss (standardized): 1.6689475073529911\n",
      "Epoch: 13, Loss (standarized): 0.19967390070762328\n",
      "          Validation Loss (standardized): 1.7220362331398889\n",
      "Epoch: 14, Loss (standarized): 0.2027147215752953\n",
      "          Validation Loss (standardized): 1.764348697714641\n",
      "Epoch: 15, Loss (standarized): 0.2053679362996818\n",
      "          Validation Loss (standardized): 1.796487294457946\n",
      "Epoch: 16, Loss (standarized): 0.20750597176927843\n",
      "          Validation Loss (standardized): 1.8191484800759485\n",
      "Epoch: 17, Loss (standarized): 0.20907335296239601\n",
      "          Validation Loss (standardized): 1.8330841640201936\n",
      "Epoch: 18, Loss (standarized): 0.21006221867933197\n",
      "          Validation Loss (standardized): 1.8390688101470334\n",
      "Epoch: 19, Loss (standarized): 0.21049529753174295\n",
      "          Validation Loss (standardized): 1.8378815972822622\n",
      "Epoch: 20, Loss (standarized): 0.21041653149362308\n",
      "          Validation Loss (standardized): 1.8302952434110193\n",
      "Final epoch: 20, Final loss (standarized): 0.21041653149362308\n",
      "Epoch: 1, Loss (standarized): 0.33198565863898577\n",
      "          Validation Loss (standardized): 0.8703383276248305\n",
      "Epoch: 2, Loss (standarized): 0.27386706563842167\n",
      "          Validation Loss (standardized): 0.9713588324009383\n",
      "Epoch: 3, Loss (standarized): 0.2348342477623546\n",
      "          Validation Loss (standardized): 1.0833019854865915\n",
      "Epoch: 4, Loss (standarized): 0.21086329966141484\n",
      "          Validation Loss (standardized): 1.1992100171198385\n",
      "Epoch: 5, Loss (standarized): 0.19792416712090136\n",
      "          Validation Loss (standardized): 1.3126527303047366\n",
      "Epoch: 6, Loss (standarized): 0.19247514994404222\n",
      "          Validation Loss (standardized): 1.4182843365572513\n",
      "Epoch: 7, Loss (standarized): 0.19168144926602412\n",
      "          Validation Loss (standardized): 1.5121493796992218\n",
      "Epoch: 8, Loss (standarized): 0.19344195818696958\n",
      "          Validation Loss (standardized): 1.5917668819671313\n",
      "Epoch: 9, Loss (standarized): 0.19630552879614727\n",
      "          Validation Loss (standardized): 1.6559468061214693\n",
      "Epoch: 10, Loss (standarized): 0.19933747129838186\n",
      "          Validation Loss (standardized): 1.704512292809956\n",
      "Epoch: 11, Loss (standarized): 0.2019826644500226\n",
      "          Validation Loss (standardized): 1.7380063015932703\n",
      "Epoch: 12, Loss (standarized): 0.2039480822697444\n",
      "          Validation Loss (standardized): 1.7574414602780013\n",
      "Epoch: 13, Loss (standarized): 0.20511806253032114\n",
      "          Validation Loss (standardized): 1.7641097727500574\n",
      "Epoch: 14, Loss (standarized): 0.20548957983625304\n",
      "          Validation Loss (standardized): 1.759463187608423\n",
      "Epoch: 15, Loss (standarized): 0.205132010834431\n",
      "          Validation Loss (standardized): 1.7450404414140746\n",
      "Epoch: 16, Loss (standarized): 0.2041592528414834\n",
      "          Validation Loss (standardized): 1.7223858817492024\n",
      "Epoch: 17, Loss (standarized): 0.20271068184780147\n",
      "          Validation Loss (standardized): 1.6930333571296332\n",
      "Epoch: 18, Loss (standarized): 0.2009390149746593\n",
      "          Validation Loss (standardized): 1.6584836562577812\n",
      "Epoch: 19, Loss (standarized): 0.1990004005945687\n",
      "          Validation Loss (standardized): 1.6201925718170047\n",
      "Epoch: 20, Loss (standarized): 0.19704638498380636\n",
      "          Validation Loss (standardized): 1.5795615277027943\n",
      "Final epoch: 20, Final loss (standarized): 0.19704638498380636\n",
      "Epoch: 1, Loss (standarized): 0.5463559339101063\n",
      "          Validation Loss (standardized): 0.7204306159546943\n",
      "Epoch: 2, Loss (standarized): 0.4275883152597608\n",
      "          Validation Loss (standardized): 0.781113142495605\n",
      "Epoch: 3, Loss (standarized): 0.3382689329215709\n",
      "          Validation Loss (standardized): 0.8674026597854624\n",
      "Epoch: 4, Loss (standarized): 0.2754825517827057\n",
      "          Validation Loss (standardized): 0.9719361682887734\n",
      "Epoch: 5, Loss (standarized): 0.23447275461967046\n",
      "          Validation Loss (standardized): 1.0868192277407989\n",
      "Epoch: 6, Loss (standarized): 0.20991552016444773\n",
      "          Validation Loss (standardized): 1.2048889739574713\n",
      "Epoch: 7, Loss (standarized): 0.1969312266433473\n",
      "          Validation Loss (standardized): 1.3203749162165728\n",
      "Epoch: 8, Loss (standarized): 0.19158335621323486\n",
      "          Validation Loss (standardized): 1.4290507877637395\n",
      "Epoch: 9, Loss (standarized): 0.19095673262827653\n",
      "          Validation Loss (standardized): 1.5280759969477944\n",
      "Epoch: 10, Loss (standarized): 0.193015782943818\n",
      "          Validation Loss (standardized): 1.6157485651964363\n",
      "Epoch: 11, Loss (standarized): 0.19639825316000023\n",
      "          Validation Loss (standardized): 1.6912327470973787\n",
      "Epoch: 12, Loss (standarized): 0.20022424344580533\n",
      "          Validation Loss (standardized): 1.7543346385115388\n",
      "Epoch: 13, Loss (standarized): 0.20394548315105862\n",
      "          Validation Loss (standardized): 1.8052811346538624\n",
      "Epoch: 14, Loss (standarized): 0.20723775935289068\n",
      "          Validation Loss (standardized): 1.8445837804815124\n",
      "Epoch: 15, Loss (standarized): 0.2099235666602395\n",
      "          Validation Loss (standardized): 1.87292602729948\n",
      "Epoch: 16, Loss (standarized): 0.21192136519125118\n",
      "          Validation Loss (standardized): 1.891087080939147\n",
      "Epoch: 17, Loss (standarized): 0.2132119510909514\n",
      "          Validation Loss (standardized): 1.8999011149188487\n",
      "Epoch: 18, Loss (standarized): 0.21381662741575666\n",
      "          Validation Loss (standardized): 1.9002276221632102\n",
      "Epoch: 19, Loss (standarized): 0.21378267933997766\n",
      "          Validation Loss (standardized): 1.8929271192961148\n",
      "Epoch: 20, Loss (standarized): 0.21317550558957907\n",
      "          Validation Loss (standardized): 1.878849399219432\n",
      "Final epoch: 20, Final loss (standarized): 0.21317550558957907\n",
      "Epoch: 1, Loss (standarized): 1.308704908667861\n",
      "          Validation Loss (standardized): 0.7909243702856315\n",
      "Epoch: 2, Loss (standarized): 1.0730737694235821\n",
      "          Validation Loss (standardized): 0.7272826175690769\n",
      "Epoch: 3, Loss (standarized): 0.8695063762306342\n",
      "          Validation Loss (standardized): 0.6935911929167529\n",
      "Epoch: 4, Loss (standarized): 0.6988120440260193\n",
      "          Validation Loss (standardized): 0.6888883102719633\n",
      "Epoch: 5, Loss (standarized): 0.5604297309427901\n",
      "          Validation Loss (standardized): 0.7102734327591389\n",
      "Epoch: 6, Loss (standarized): 0.45210660156547205\n",
      "          Validation Loss (standardized): 0.7533393917667884\n",
      "Epoch: 7, Loss (standarized): 0.3701097858253948\n",
      "          Validation Loss (standardized): 0.8129686235621821\n",
      "Epoch: 8, Loss (standarized): 0.3099494568724079\n",
      "          Validation Loss (standardized): 0.8840790592839965\n",
      "Epoch: 9, Loss (standarized): 0.2670968154217436\n",
      "          Validation Loss (standardized): 0.9621263673074817\n",
      "Epoch: 10, Loss (standarized): 0.23746933168397164\n",
      "          Validation Loss (standardized): 1.0433434252434128\n",
      "Epoch: 11, Loss (standarized): 0.2176570446362432\n",
      "          Validation Loss (standardized): 1.1247850060217321\n",
      "Epoch: 12, Loss (standarized): 0.20495860754862727\n",
      "          Validation Loss (standardized): 1.204260266496219\n",
      "Epoch: 13, Loss (standarized): 0.19731175104283347\n",
      "          Validation Loss (standardized): 1.280216451211284\n",
      "Epoch: 14, Loss (standarized): 0.19318239178138044\n",
      "          Validation Loss (standardized): 1.351612451348645\n",
      "Epoch: 15, Loss (standarized): 0.19145005118841044\n",
      "          Validation Loss (standardized): 1.417801882947867\n",
      "Epoch: 16, Loss (standarized): 0.1913070677594608\n",
      "          Validation Loss (standardized): 1.4784336589165286\n",
      "Epoch: 17, Loss (standarized): 0.19217706577269583\n",
      "          Validation Loss (standardized): 1.5333717200557504\n",
      "Epoch: 18, Loss (standarized): 0.19365218518204946\n",
      "          Validation Loss (standardized): 1.5826325472601719\n",
      "Epoch: 19, Loss (standarized): 0.1954462251866238\n",
      "          Validation Loss (standardized): 1.6263378437639142\n",
      "Epoch: 20, Loss (standarized): 0.19736034575662265\n",
      "          Validation Loss (standardized): 1.6646794963307545\n",
      "Final epoch: 20, Final loss (standarized): 0.19736034575662265\n",
      "Epoch: 1, Loss (standarized): 0.9392713438182994\n",
      "          Validation Loss (standardized): 0.7003480762561134\n",
      "Epoch: 2, Loss (standarized): 0.7419643021441743\n",
      "          Validation Loss (standardized): 0.6883379287419706\n",
      "Epoch: 3, Loss (standarized): 0.5813653897647297\n",
      "          Validation Loss (standardized): 0.7092364373064182\n",
      "Epoch: 4, Loss (standarized): 0.4567924086442122\n",
      "          Validation Loss (standardized): 0.7579775353155072\n",
      "Epoch: 5, Loss (standarized): 0.3646605241285887\n",
      "          Validation Loss (standardized): 0.8276703059835832\n",
      "Epoch: 6, Loss (standarized): 0.29951961751281647\n",
      "          Validation Loss (standardized): 0.9110476672775287\n",
      "Epoch: 7, Loss (standarized): 0.25538333251323597\n",
      "          Validation Loss (standardized): 1.0015832550060286\n",
      "Epoch: 8, Loss (standarized): 0.22673153272575913\n",
      "          Validation Loss (standardized): 1.0940610434735987\n",
      "Epoch: 9, Loss (standarized): 0.20901976842609846\n",
      "          Validation Loss (standardized): 1.1846638853889526\n",
      "Epoch: 10, Loss (standarized): 0.1987842424079724\n",
      "          Validation Loss (standardized): 1.270791778305767\n",
      "Epoch: 11, Loss (standarized): 0.19351586746360017\n",
      "          Validation Loss (standardized): 1.3507953412590863\n",
      "Epoch: 12, Loss (standarized): 0.19145496344791071\n",
      "          Validation Loss (standardized): 1.4237210309458959\n",
      "Epoch: 13, Loss (standarized): 0.19139196064403768\n",
      "          Validation Loss (standardized): 1.489103089973939\n",
      "Epoch: 14, Loss (standarized): 0.19250597263353406\n",
      "          Validation Loss (standardized): 1.5468070397757372\n",
      "Epoch: 15, Loss (standarized): 0.1942452366779327\n",
      "          Validation Loss (standardized): 1.596917519389509\n",
      "Epoch: 16, Loss (standarized): 0.1962425147669492\n",
      "          Validation Loss (standardized): 1.639660245097544\n",
      "Epoch: 17, Loss (standarized): 0.1982566185145741\n",
      "          Validation Loss (standardized): 1.6753487689552853\n",
      "Epoch: 18, Loss (standarized): 0.20013250621204248\n",
      "          Validation Loss (standardized): 1.7043487287678625\n",
      "Epoch: 19, Loss (standarized): 0.20177423139627915\n",
      "          Validation Loss (standardized): 1.727054226735221\n",
      "Epoch: 20, Loss (standarized): 0.2031266374822531\n",
      "          Validation Loss (standardized): 1.7438725499017982\n",
      "Final epoch: 20, Final loss (standarized): 0.2031266374822531\n",
      "Epoch: 1, Loss (standarized): 1.2313713624571834\n",
      "          Validation Loss (standardized): 0.7667215004986112\n",
      "Epoch: 2, Loss (standarized): 1.0013984552706907\n",
      "          Validation Loss (standardized): 0.7122617019712917\n",
      "Epoch: 3, Loss (standarized): 0.8051032686103962\n",
      "          Validation Loss (standardized): 0.688901516335346\n",
      "Epoch: 4, Loss (standarized): 0.6437651277783794\n",
      "          Validation Loss (standardized): 0.6943963954356414\n",
      "Epoch: 5, Loss (standarized): 0.5160419032568665\n",
      "          Validation Loss (standardized): 0.724407942040725\n",
      "Epoch: 6, Loss (standarized): 0.418383170217371\n",
      "          Validation Loss (standardized): 0.7734926432457014\n",
      "Epoch: 7, Loss (standarized): 0.3459739206449302\n",
      "          Validation Loss (standardized): 0.8360856061839991\n",
      "Epoch: 8, Loss (standarized): 0.2937125150570716\n",
      "          Validation Loss (standardized): 0.9071808975375695\n",
      "Epoch: 9, Loss (standarized): 0.2569046092659984\n",
      "          Validation Loss (standardized): 0.9826520207587204\n",
      "Epoch: 10, Loss (standarized): 0.23160369667772304\n",
      "          Validation Loss (standardized): 1.0593061041857412\n",
      "Epoch: 11, Loss (standarized): 0.21468394099902924\n",
      "          Validation Loss (standardized): 1.134793444038123\n",
      "Epoch: 12, Loss (standarized): 0.2037651032988486\n",
      "          Validation Loss (standardized): 1.2074618122000982\n",
      "Epoch: 13, Loss (standarized): 0.1970809225967842\n",
      "          Validation Loss (standardized): 1.2762057643293074\n",
      "Epoch: 14, Loss (standarized): 0.1933426029431071\n",
      "          Validation Loss (standardized): 1.3403332624605655\n",
      "Epoch: 15, Loss (standarized): 0.19161996936218462\n",
      "          Validation Loss (standardized): 1.3994564120757895\n",
      "Epoch: 16, Loss (standarized): 0.1912465351205888\n",
      "          Validation Loss (standardized): 1.4534059219244566\n",
      "Epoch: 17, Loss (standarized): 0.19174723879838365\n",
      "          Validation Loss (standardized): 1.5021661284992645\n",
      "Epoch: 18, Loss (standarized): 0.1927849855842967\n",
      "          Validation Loss (standardized): 1.5458267302071476\n",
      "Epoch: 19, Loss (standarized): 0.1941217713762061\n",
      "          Validation Loss (standardized): 1.5845475687500368\n",
      "Epoch: 20, Loss (standarized): 0.1955906928853438\n",
      "          Validation Loss (standardized): 1.6185333249330751\n",
      "Final epoch: 20, Final loss (standarized): 0.1955906928853438\n",
      "Epoch: 1, Loss (standarized): 0.4917361899724765\n",
      "          Validation Loss (standardized): 0.745035477042398\n",
      "Epoch: 2, Loss (standarized): 0.3856511143993956\n",
      "          Validation Loss (standardized): 0.8162950577316113\n",
      "Epoch: 3, Loss (standarized): 0.30990512845935114\n",
      "          Validation Loss (standardized): 0.9069494539399732\n",
      "Epoch: 4, Loss (standarized): 0.25883485594956784\n",
      "          Validation Loss (standardized): 1.0090758086661165\n",
      "Epoch: 5, Loss (standarized): 0.22644933134865014\n",
      "          Validation Loss (standardized): 1.115715971294965\n",
      "Epoch: 6, Loss (standarized): 0.20735826090473075\n",
      "          Validation Loss (standardized): 1.2214186586945834\n",
      "Epoch: 7, Loss (standarized): 0.19725750801784214\n",
      "          Validation Loss (standardized): 1.3222456104599087\n",
      "Epoch: 8, Loss (standarized): 0.19296802270358338\n",
      "          Validation Loss (standardized): 1.415539447405437\n",
      "Epoch: 9, Loss (standarized): 0.19225516859296468\n",
      "          Validation Loss (standardized): 1.4996425509914217\n",
      "Epoch: 10, Loss (standarized): 0.19359788407561448\n",
      "          Validation Loss (standardized): 1.5736474433755148\n",
      "Epoch: 11, Loss (standarized): 0.1959848239809018\n",
      "          Validation Loss (standardized): 1.637195886735401\n",
      "Epoch: 12, Loss (standarized): 0.19875802713936755\n",
      "          Validation Loss (standardized): 1.6903214382580432\n",
      "Epoch: 13, Loss (standarized): 0.20150061743430223\n",
      "          Validation Loss (standardized): 1.7333278826656078\n",
      "Epoch: 14, Loss (standarized): 0.20395866215044942\n",
      "          Validation Loss (standardized): 1.7666978205131343\n",
      "Epoch: 15, Loss (standarized): 0.20598772851097485\n",
      "          Validation Loss (standardized): 1.7910263496249197\n",
      "Epoch: 16, Loss (standarized): 0.2075167315787048\n",
      "          Validation Loss (standardized): 1.8069747033331844\n",
      "Epoch: 17, Loss (standarized): 0.20852365427263228\n",
      "          Validation Loss (standardized): 1.8152389280210348\n",
      "Epoch: 18, Loss (standarized): 0.20901929799458088\n",
      "          Validation Loss (standardized): 1.816529359035111\n",
      "Epoch: 19, Loss (standarized): 0.20903639822787742\n",
      "          Validation Loss (standardized): 1.811557536777059\n",
      "Epoch: 20, Loss (standarized): 0.20862228395123128\n",
      "          Validation Loss (standardized): 1.8010280565371348\n",
      "Final epoch: 20, Final loss (standarized): 0.20862228395123128\n",
      "Epoch: 1, Loss (standarized): 0.4028123324230486\n",
      "          Validation Loss (standardized): 0.8100612668031162\n",
      "Epoch: 2, Loss (standarized): 0.3120656874959454\n",
      "          Validation Loss (standardized): 0.9104682054895697\n",
      "Epoch: 3, Loss (standarized): 0.25559033336071857\n",
      "          Validation Loss (standardized): 1.0190680955646139\n",
      "Epoch: 4, Loss (standarized): 0.2228398691215593\n",
      "          Validation Loss (standardized): 1.1248490754622493\n",
      "Epoch: 5, Loss (standarized): 0.20517080642039798\n",
      "          Validation Loss (standardized): 1.2217474093321363\n",
      "Epoch: 6, Loss (standarized): 0.19639141050587602\n",
      "          Validation Loss (standardized): 1.3071999316498084\n",
      "Epoch: 7, Loss (standarized): 0.19262516364020274\n",
      "          Validation Loss (standardized): 1.3799743514349634\n",
      "Epoch: 8, Loss (standarized): 0.19158329972076238\n",
      "          Validation Loss (standardized): 1.439907710201332\n",
      "Epoch: 9, Loss (standarized): 0.19190159989319844\n",
      "          Validation Loss (standardized): 1.4876222181643357\n",
      "Epoch: 10, Loss (standarized): 0.19278277331884922\n",
      "          Validation Loss (standardized): 1.5240803249135597\n",
      "Epoch: 11, Loss (standarized): 0.19377984220470115\n",
      "          Validation Loss (standardized): 1.5500581446946236\n",
      "Epoch: 12, Loss (standarized): 0.19464111988846586\n",
      "          Validation Loss (standardized): 1.5666237812554653\n",
      "Epoch: 13, Loss (standarized): 0.19524693155203315\n",
      "          Validation Loss (standardized): 1.5745223644214186\n",
      "Epoch: 14, Loss (standarized): 0.1955415866067929\n",
      "          Validation Loss (standardized): 1.5746610002070058\n",
      "Epoch: 15, Loss (standarized): 0.19552831753251665\n",
      "          Validation Loss (standardized): 1.5678678081800286\n",
      "Epoch: 16, Loss (standarized): 0.19524066266976248\n",
      "          Validation Loss (standardized): 1.5552533615312085\n",
      "Epoch: 17, Loss (standarized): 0.19474260909880878\n",
      "          Validation Loss (standardized): 1.5380518041731848\n",
      "Epoch: 18, Loss (standarized): 0.19411335355599896\n",
      "          Validation Loss (standardized): 1.5171154192163652\n",
      "Epoch: 19, Loss (standarized): 0.19342463012632358\n",
      "          Validation Loss (standardized): 1.493118849338606\n",
      "Epoch: 20, Loss (standarized): 0.1927441565989863\n",
      "          Validation Loss (standardized): 1.4670721523256554\n",
      "Final epoch: 20, Final loss (standarized): 0.1927441565989863\n",
      "Epoch: 1, Loss (standarized): 1.7892241153057948\n",
      "          Validation Loss (standardized): 0.9807952535786228\n",
      "Epoch: 2, Loss (standarized): 1.5254670184118138\n",
      "          Validation Loss (standardized): 0.8745157939338875\n",
      "Epoch: 3, Loss (standarized): 1.2862381603580961\n",
      "          Validation Loss (standardized): 0.7917893562503121\n",
      "Epoch: 4, Loss (standarized): 1.0744545195242488\n",
      "          Validation Loss (standardized): 0.7336525214448426\n",
      "Epoch: 5, Loss (standarized): 0.8916409676188618\n",
      "          Validation Loss (standardized): 0.6996696901879815\n",
      "Epoch: 6, Loss (standarized): 0.7376976540828268\n",
      "          Validation Loss (standardized): 0.6880676589405326\n",
      "Epoch: 7, Loss (standarized): 0.6112563877778812\n",
      "          Validation Loss (standardized): 0.6959054581675886\n",
      "Epoch: 8, Loss (standarized): 0.5099461319343392\n",
      "          Validation Loss (standardized): 0.7193993760206208\n",
      "Epoch: 9, Loss (standarized): 0.43062738296139513\n",
      "          Validation Loss (standardized): 0.754526068699437\n",
      "Epoch: 10, Loss (standarized): 0.36960882513598153\n",
      "          Validation Loss (standardized): 0.7974364209147873\n",
      "Epoch: 11, Loss (standarized): 0.3233794372002616\n",
      "          Validation Loss (standardized): 0.8448264020838474\n",
      "Epoch: 12, Loss (standarized): 0.2887276962039632\n",
      "          Validation Loss (standardized): 0.8942086174521288\n",
      "Epoch: 13, Loss (standarized): 0.26288161949529426\n",
      "          Validation Loss (standardized): 0.9435654337658537\n",
      "Epoch: 14, Loss (standarized): 0.24373148154928753\n",
      "          Validation Loss (standardized): 0.9915828501176637\n",
      "Epoch: 15, Loss (standarized): 0.22957384285200322\n",
      "          Validation Loss (standardized): 1.0375177469973342\n",
      "Epoch: 16, Loss (standarized): 0.2190998889321518\n",
      "          Validation Loss (standardized): 1.0809382903567175\n",
      "Epoch: 17, Loss (standarized): 0.21135188643181604\n",
      "          Validation Loss (standardized): 1.1212999860622848\n",
      "Epoch: 18, Loss (standarized): 0.20566780589856382\n",
      "          Validation Loss (standardized): 1.158456964507704\n",
      "Epoch: 19, Loss (standarized): 0.20151392127106976\n",
      "          Validation Loss (standardized): 1.1923586489948248\n",
      "Epoch: 20, Loss (standarized): 0.19849595453671975\n",
      "          Validation Loss (standardized): 1.2226284295216914\n",
      "Final epoch: 20, Final loss (standarized): 0.19849595453671975\n",
      "Epoch: 1, Loss (standarized): 0.5585817003191869\n",
      "          Validation Loss (standardized): 0.7160117126371586\n",
      "Epoch: 2, Loss (standarized): 0.43801869782694264\n",
      "          Validation Loss (standardized): 0.7697047404901\n",
      "Epoch: 3, Loss (standarized): 0.35037573991502446\n",
      "          Validation Loss (standardized): 0.8417920207583071\n",
      "Epoch: 4, Loss (standarized): 0.29010500334894035\n",
      "          Validation Loss (standardized): 0.9239853404027246\n",
      "Epoch: 5, Loss (standarized): 0.25020331436457843\n",
      "          Validation Loss (standardized): 1.0095829249234092\n",
      "Epoch: 6, Loss (standarized): 0.22467784549290454\n",
      "          Validation Loss (standardized): 1.0939553734261636\n",
      "Epoch: 7, Loss (standarized): 0.20889717744796854\n",
      "          Validation Loss (standardized): 1.1741702275144241\n",
      "Epoch: 8, Loss (standarized): 0.19956592150155703\n",
      "          Validation Loss (standardized): 1.248105937683131\n",
      "Epoch: 9, Loss (standarized): 0.1944499356590028\n",
      "          Validation Loss (standardized): 1.3143881465602865\n",
      "Epoch: 10, Loss (standarized): 0.19201486797193631\n",
      "          Validation Loss (standardized): 1.372563540959136\n",
      "Epoch: 11, Loss (standarized): 0.19120920032262834\n",
      "          Validation Loss (standardized): 1.4223549420771422\n",
      "Epoch: 12, Loss (standarized): 0.19133829675769465\n",
      "          Validation Loss (standardized): 1.4641193142496263\n",
      "Epoch: 13, Loss (standarized): 0.19194472790374265\n",
      "          Validation Loss (standardized): 1.498070449074161\n",
      "Epoch: 14, Loss (standarized): 0.19273452121319595\n",
      "          Validation Loss (standardized): 1.5249187873174026\n",
      "Epoch: 15, Loss (standarized): 0.19353024229803512\n",
      "          Validation Loss (standardized): 1.5452084004002058\n",
      "Epoch: 16, Loss (standarized): 0.1942260577882419\n",
      "          Validation Loss (standardized): 1.5596352374020364\n",
      "Epoch: 17, Loss (standarized): 0.19476778490037933\n",
      "          Validation Loss (standardized): 1.5684763639833061\n",
      "Epoch: 18, Loss (standarized): 0.1951207903631452\n",
      "          Validation Loss (standardized): 1.572308419573084\n",
      "Epoch: 19, Loss (standarized): 0.19528347634936735\n",
      "          Validation Loss (standardized): 1.5715129563076269\n",
      "Epoch: 20, Loss (standarized): 0.19526081955548213\n",
      "          Validation Loss (standardized): 1.5663652589158181\n",
      "Final epoch: 20, Final loss (standarized): 0.19526081955548213\n",
      "Epoch: 1, Loss (standarized): 0.4338985347154128\n",
      "          Validation Loss (standardized): 0.7830630626656676\n",
      "Epoch: 2, Loss (standarized): 0.3377246884220772\n",
      "          Validation Loss (standardized): 0.8712521220537074\n",
      "Epoch: 3, Loss (standarized): 0.27445108991691247\n",
      "          Validation Loss (standardized): 0.9693151939594131\n",
      "Epoch: 4, Loss (standarized): 0.23600818693200593\n",
      "          Validation Loss (standardized): 1.0667437063820333\n",
      "Epoch: 5, Loss (standarized): 0.2138643294011998\n",
      "          Validation Loss (standardized): 1.1575998117184434\n",
      "Epoch: 6, Loss (standarized): 0.20168014080070032\n",
      "          Validation Loss (standardized): 1.2386191640815558\n",
      "Epoch: 7, Loss (standarized): 0.19541636643706095\n",
      "          Validation Loss (standardized): 1.3088879215391969\n",
      "Epoch: 8, Loss (standarized): 0.19254790032689886\n",
      "          Validation Loss (standardized): 1.368400402693676\n",
      "Epoch: 9, Loss (standarized): 0.19157158984761016\n",
      "          Validation Loss (standardized): 1.4173298009412827\n",
      "Epoch: 10, Loss (standarized): 0.19159105461151157\n",
      "          Validation Loss (standardized): 1.4560364731816247\n",
      "Epoch: 11, Loss (standarized): 0.19206087345225256\n",
      "          Validation Loss (standardized): 1.4853337931743065\n",
      "Epoch: 12, Loss (standarized): 0.19265489577449735\n",
      "          Validation Loss (standardized): 1.5059614070730418\n",
      "Epoch: 13, Loss (standarized): 0.19318548874480704\n",
      "          Validation Loss (standardized): 1.51860587830626\n",
      "Epoch: 14, Loss (standarized): 0.19355181684976006\n",
      "          Validation Loss (standardized): 1.5242904506034494\n",
      "Epoch: 15, Loss (standarized): 0.19372440166635368\n",
      "          Validation Loss (standardized): 1.5239140423175235\n",
      "Epoch: 16, Loss (standarized): 0.19370744726536965\n",
      "          Validation Loss (standardized): 1.5183500189509822\n",
      "Epoch: 17, Loss (standarized): 0.19352994096439138\n",
      "          Validation Loss (standardized): 1.508410344863658\n",
      "Epoch: 18, Loss (standarized): 0.1932313706131633\n",
      "          Validation Loss (standardized): 1.4953510459743649\n",
      "Epoch: 19, Loss (standarized): 0.19287250780105777\n",
      "          Validation Loss (standardized): 1.4798536208766142\n",
      "Epoch: 20, Loss (standarized): 0.1924945524718731\n",
      "          Validation Loss (standardized): 1.4624267040656735\n",
      "Final epoch: 20, Final loss (standarized): 0.1924945524718731\n",
      "Epoch: 1, Loss (standarized): 0.9098571086392558\n",
      "          Validation Loss (standardized): 0.6948459748506682\n",
      "Epoch: 2, Loss (standarized): 0.7096071603116828\n",
      "          Validation Loss (standardized): 0.6898115997710386\n",
      "Epoch: 3, Loss (standarized): 0.5484078094244051\n",
      "          Validation Loss (standardized): 0.7207981801741138\n",
      "Epoch: 4, Loss (standarized): 0.4256123665200932\n",
      "          Validation Loss (standardized): 0.7819118710034206\n",
      "Epoch: 5, Loss (standarized): 0.3371269075018577\n",
      "          Validation Loss (standardized): 0.8651352779055986\n",
      "Epoch: 6, Loss (standarized): 0.2766990796682578\n",
      "          Validation Loss (standardized): 0.9621607116098878\n",
      "Epoch: 7, Loss (standarized): 0.23758353528689374\n",
      "          Validation Loss (standardized): 1.0657156975842041\n",
      "Epoch: 8, Loss (standarized): 0.21372865867699573\n",
      "          Validation Loss (standardized): 1.1700910545095935\n",
      "Epoch: 9, Loss (standarized): 0.2003136906643135\n",
      "          Validation Loss (standardized): 1.2712095538731243\n",
      "Epoch: 10, Loss (standarized): 0.1937661631617464\n",
      "          Validation Loss (standardized): 1.3663535043935147\n",
      "Epoch: 11, Loss (standarized): 0.1915780207265701\n",
      "          Validation Loss (standardized): 1.453855947956081\n",
      "Epoch: 12, Loss (standarized): 0.1920375576250841\n",
      "          Validation Loss (standardized): 1.532829729444104\n",
      "Epoch: 13, Loss (standarized): 0.19400197993181567\n",
      "          Validation Loss (standardized): 1.6029166121286917\n",
      "Epoch: 14, Loss (standarized): 0.19672315093634118\n",
      "          Validation Loss (standardized): 1.6641202741592536\n",
      "Epoch: 15, Loss (standarized): 0.19971828572647163\n",
      "          Validation Loss (standardized): 1.716652579963769\n",
      "Epoch: 16, Loss (standarized): 0.20267756431895362\n",
      "          Validation Loss (standardized): 1.7608548961072308\n",
      "Epoch: 17, Loss (standarized): 0.20540945731129362\n",
      "          Validation Loss (standardized): 1.7971426003424893\n",
      "Epoch: 18, Loss (standarized): 0.20779783625538162\n",
      "          Validation Loss (standardized): 1.8260049496886563\n",
      "Epoch: 19, Loss (standarized): 0.2097822606366943\n",
      "          Validation Loss (standardized): 1.847941271815336\n",
      "Epoch: 20, Loss (standarized): 0.21133605586979018\n",
      "          Validation Loss (standardized): 1.86344805374131\n",
      "Final epoch: 20, Final loss (standarized): 0.21133605586979018\n",
      "Epoch: 1, Loss (standarized): 0.9312138770262018\n",
      "          Validation Loss (standardized): 0.7023848786972238\n",
      "Epoch: 2, Loss (standarized): 0.7570947781569687\n",
      "          Validation Loss (standardized): 0.687462671878522\n",
      "Epoch: 3, Loss (standarized): 0.6122538623889139\n",
      "          Validation Loss (standardized): 0.6981160859511454\n",
      "Epoch: 4, Loss (standarized): 0.4956412129020973\n",
      "          Validation Loss (standardized): 0.7313273341700602\n",
      "Epoch: 5, Loss (standarized): 0.40475502569616156\n",
      "          Validation Loss (standardized): 0.7830558873940447\n",
      "Epoch: 6, Loss (standarized): 0.3361419149788668\n",
      "          Validation Loss (standardized): 0.8487688131527631\n",
      "Epoch: 7, Loss (standarized): 0.28596238886708136\n",
      "          Validation Loss (standardized): 0.9239434823303272\n",
      "Epoch: 8, Loss (standarized): 0.2504451534179829\n",
      "          Validation Loss (standardized): 1.0044211847600624\n",
      "Epoch: 9, Loss (standarized): 0.22618588498876155\n",
      "          Validation Loss (standardized): 1.0866716150298645\n",
      "Epoch: 10, Loss (standarized): 0.21029490696408076\n",
      "          Validation Loss (standardized): 1.1678874956613343\n",
      "Epoch: 11, Loss (standarized): 0.2004495546501362\n",
      "          Validation Loss (standardized): 1.2459565669695436\n",
      "Epoch: 12, Loss (standarized): 0.19485665074412115\n",
      "          Validation Loss (standardized): 1.3193711425963484\n",
      "Epoch: 13, Loss (standarized): 0.19217296844527768\n",
      "          Validation Loss (standardized): 1.3871225273384664\n",
      "Epoch: 14, Loss (standarized): 0.19141507475467273\n",
      "          Validation Loss (standardized): 1.4486489973067633\n",
      "Epoch: 15, Loss (standarized): 0.19187535721851884\n",
      "          Validation Loss (standardized): 1.503648177677702\n",
      "Epoch: 16, Loss (standarized): 0.19305413667721127\n",
      "          Validation Loss (standardized): 1.5520187323317969\n",
      "Epoch: 17, Loss (standarized): 0.1946000077542394\n",
      "          Validation Loss (standardized): 1.593822276560433\n",
      "Epoch: 18, Loss (standarized): 0.19626965262936483\n",
      "          Validation Loss (standardized): 1.6291701766602298\n",
      "Epoch: 19, Loss (standarized): 0.19789645532499828\n",
      "          Validation Loss (standardized): 1.658228591232041\n",
      "Epoch: 20, Loss (standarized): 0.1993680364151049\n",
      "          Validation Loss (standardized): 1.6812929511223969\n",
      "Final epoch: 20, Final loss (standarized): 0.1993680364151049\n",
      "Epoch: 1, Loss (standarized): 0.5731594418178003\n",
      "          Validation Loss (standardized): 0.7241873244623511\n",
      "Epoch: 2, Loss (standarized): 0.4239725108106541\n",
      "          Validation Loss (standardized): 0.802479982612053\n",
      "Epoch: 3, Loss (standarized): 0.3209933930672748\n",
      "          Validation Loss (standardized): 0.912843885319466\n",
      "Epoch: 4, Loss (standarized): 0.25609771103741186\n",
      "          Validation Loss (standardized): 1.0409837174962404\n",
      "Epoch: 5, Loss (standarized): 0.21901608379464377\n",
      "          Validation Loss (standardized): 1.1741636053154685\n",
      "Epoch: 6, Loss (standarized): 0.20032077150895686\n",
      "          Validation Loss (standardized): 1.3032019093815486\n",
      "Epoch: 7, Loss (standarized): 0.19281623591655547\n",
      "          Validation Loss (standardized): 1.4224567841884543\n",
      "Epoch: 8, Loss (standarized): 0.1916557484779532\n",
      "          Validation Loss (standardized): 1.5289073991543347\n",
      "Epoch: 9, Loss (standarized): 0.1938088243390744\n",
      "          Validation Loss (standardized): 1.6213016867149244\n",
      "Epoch: 10, Loss (standarized): 0.19745682766154715\n",
      "          Validation Loss (standardized): 1.699417363531329\n",
      "Epoch: 11, Loss (standarized): 0.2015388461352541\n",
      "          Validation Loss (standardized): 1.7636058393216083\n",
      "Epoch: 12, Loss (standarized): 0.20544943884608716\n",
      "          Validation Loss (standardized): 1.8145853129829588\n",
      "Epoch: 13, Loss (standarized): 0.20885683074637704\n",
      "          Validation Loss (standardized): 1.8532331085816822\n",
      "Epoch: 14, Loss (standarized): 0.21159746501302823\n",
      "          Validation Loss (standardized): 1.8805156814752957\n",
      "Epoch: 15, Loss (standarized): 0.2136030209670242\n",
      "          Validation Loss (standardized): 1.8974332253563135\n",
      "Epoch: 16, Loss (standarized): 0.21487530554431042\n",
      "          Validation Loss (standardized): 1.9049516212397861\n",
      "Epoch: 17, Loss (standarized): 0.21544761915649963\n",
      "          Validation Loss (standardized): 1.9039675704301657\n",
      "Epoch: 18, Loss (standarized): 0.21536871410198344\n",
      "          Validation Loss (standardized): 1.8954379727898567\n",
      "Epoch: 19, Loss (standarized): 0.214717805082854\n",
      "          Validation Loss (standardized): 1.880183254793314\n",
      "Epoch: 20, Loss (standarized): 0.21356961652180312\n",
      "          Validation Loss (standardized): 1.8590402795466603\n",
      "Final epoch: 20, Final loss (standarized): 0.21356961652180312\n",
      "Epoch: 1, Loss (standarized): 1.131511159839764\n",
      "          Validation Loss (standardized): 0.7389855028329744\n",
      "Epoch: 2, Loss (standarized): 0.9111998413055707\n",
      "          Validation Loss (standardized): 0.6979419328418953\n",
      "Epoch: 3, Loss (standarized): 0.7272701931679711\n",
      "          Validation Loss (standardized): 0.6883717256531469\n",
      "Epoch: 4, Loss (standarized): 0.5796378903630703\n",
      "          Validation Loss (standardized): 0.7065282094605518\n",
      "Epoch: 5, Loss (standarized): 0.46545542639622917\n",
      "          Validation Loss (standardized): 0.7469982678404351\n",
      "Epoch: 6, Loss (standarized): 0.37998506881118255\n",
      "          Validation Loss (standardized): 0.8038770315026161\n",
      "Epoch: 7, Loss (standarized): 0.3177703727082699\n",
      "          Validation Loss (standardized): 0.8716458719131591\n",
      "Epoch: 8, Loss (standarized): 0.2735819914540117\n",
      "          Validation Loss (standardized): 0.945663223387567\n",
      "Epoch: 9, Loss (standarized): 0.24291297415045898\n",
      "          Validation Loss (standardized): 1.0222739572279498\n",
      "Epoch: 10, Loss (standarized): 0.2221476947644745\n",
      "          Validation Loss (standardized): 1.0987629685986213\n",
      "Epoch: 11, Loss (standarized): 0.20850963732625707\n",
      "          Validation Loss (standardized): 1.173170190648921\n",
      "Epoch: 12, Loss (standarized): 0.19993090307922126\n",
      "          Validation Loss (standardized): 1.2441490806459432\n",
      "Epoch: 13, Loss (standarized): 0.1948966826290774\n",
      "          Validation Loss (standardized): 1.3108109590618522\n",
      "Epoch: 14, Loss (standarized): 0.19230982084193285\n",
      "          Validation Loss (standardized): 1.3726214231779381\n",
      "Epoch: 15, Loss (standarized): 0.1913811668700336\n",
      "          Validation Loss (standardized): 1.4292927047876243\n",
      "Epoch: 16, Loss (standarized): 0.19154608921827546\n",
      "          Validation Loss (standardized): 1.4807278109692141\n",
      "Epoch: 17, Loss (standarized): 0.19240147971304272\n",
      "          Validation Loss (standardized): 1.5269293137994395\n",
      "Epoch: 18, Loss (standarized): 0.19366115774053913\n",
      "          Validation Loss (standardized): 1.5679916213536125\n",
      "Epoch: 19, Loss (standarized): 0.1951214789394218\n",
      "          Validation Loss (standardized): 1.6040647697764467\n",
      "Epoch: 20, Loss (standarized): 0.1966402598619328\n",
      "          Validation Loss (standardized): 1.6353264660930227\n",
      "Final epoch: 20, Final loss (standarized): 0.1966402598619328\n",
      "Epoch: 1, Loss (standarized): 0.8142757087868012\n",
      "          Validation Loss (standardized): 0.6887665581057625\n",
      "Epoch: 2, Loss (standarized): 0.6398565075758645\n",
      "          Validation Loss (standardized): 0.6975708919953789\n",
      "Epoch: 3, Loss (standarized): 0.5004004298620329\n",
      "          Validation Loss (standardized): 0.7379065163036677\n",
      "Epoch: 4, Loss (standarized): 0.394171999282559\n",
      "          Validation Loss (standardized): 0.8045386831050814\n",
      "Epoch: 5, Loss (standarized): 0.31725491125497585\n",
      "          Validation Loss (standardized): 0.8906850664013396\n",
      "Epoch: 6, Loss (standarized): 0.26441096761885985\n",
      "          Validation Loss (standardized): 0.9892594889557473\n",
      "Epoch: 7, Loss (standarized): 0.23009131960996423\n",
      "          Validation Loss (standardized): 1.0938839077440614\n",
      "Epoch: 8, Loss (standarized): 0.20925151680032505\n",
      "          Validation Loss (standardized): 1.1994030380920313\n",
      "Epoch: 9, Loss (standarized): 0.19777474727397806\n",
      "          Validation Loss (standardized): 1.3019619618020215\n",
      "Epoch: 10, Loss (standarized): 0.19254255459869876\n",
      "          Validation Loss (standardized): 1.3988519209699797\n",
      "Epoch: 11, Loss (standarized): 0.19130580490122123\n",
      "          Validation Loss (standardized): 1.48827152233355\n",
      "Epoch: 12, Loss (standarized): 0.1924943322560324\n",
      "          Validation Loss (standardized): 1.5691178781827646\n",
      "Epoch: 13, Loss (standarized): 0.19503571386938878\n",
      "          Validation Loss (standardized): 1.6408064243579803\n",
      "Epoch: 14, Loss (standarized): 0.1982102847028306\n",
      "          Validation Loss (standardized): 1.703130845831346\n",
      "Epoch: 15, Loss (standarized): 0.20154406126587618\n",
      "          Validation Loss (standardized): 1.7561652955723122\n",
      "Epoch: 16, Loss (standarized): 0.20473239341328142\n",
      "          Validation Loss (standardized): 1.8001778988658068\n",
      "Epoch: 17, Loss (standarized): 0.2075869615101411\n",
      "          Validation Loss (standardized): 1.8355731425523572\n",
      "Epoch: 18, Loss (standarized): 0.2099994265024431\n",
      "          Validation Loss (standardized): 1.8628393810410449\n",
      "Epoch: 19, Loss (standarized): 0.21191569292231094\n",
      "          Validation Loss (standardized): 1.8825218567836026\n",
      "Epoch: 20, Loss (standarized): 0.21331919636399937\n",
      "          Validation Loss (standardized): 1.8951927778291349\n",
      "Final epoch: 20, Final loss (standarized): 0.21331919636399937\n",
      "Epoch: 1, Loss (standarized): 0.8634535290527499\n",
      "          Validation Loss (standardized): 0.6906256411502139\n",
      "Epoch: 2, Loss (standarized): 0.655870468774991\n",
      "          Validation Loss (standardized): 0.6993260304009484\n",
      "Epoch: 3, Loss (standarized): 0.49654336057404935\n",
      "          Validation Loss (standardized): 0.7468808957105302\n",
      "Epoch: 4, Loss (standarized): 0.3815245220280252\n",
      "          Validation Loss (standardized): 0.8235908222573707\n",
      "Epoch: 5, Loss (standarized): 0.3032668389481505\n",
      "          Validation Loss (standardized): 0.9186729479849219\n",
      "Epoch: 6, Loss (standarized): 0.252895711762006\n",
      "          Validation Loss (standardized): 1.0225426050669961\n",
      "Epoch: 7, Loss (standarized): 0.2222165362933632\n",
      "          Validation Loss (standardized): 1.1278973377560966\n",
      "Epoch: 8, Loss (standarized): 0.2047166301005649\n",
      "          Validation Loss (standardized): 1.2297803211580736\n",
      "Epoch: 9, Loss (standarized): 0.19569131835430797\n",
      "          Validation Loss (standardized): 1.3251343466001901\n",
      "Epoch: 10, Loss (standarized): 0.19193735778580143\n",
      "          Validation Loss (standardized): 1.4122562847916758\n",
      "Epoch: 11, Loss (standarized): 0.1913472040763417\n",
      "          Validation Loss (standardized): 1.4903352672025016\n",
      "Epoch: 12, Loss (standarized): 0.19256039467195335\n",
      "          Validation Loss (standardized): 1.5591252236850945\n",
      "Epoch: 13, Loss (standarized): 0.1947074751668392\n",
      "          Validation Loss (standardized): 1.6187270058737093\n",
      "Epoch: 14, Loss (standarized): 0.19723728853790515\n",
      "          Validation Loss (standardized): 1.6694450243385146\n",
      "Epoch: 15, Loss (standarized): 0.19980444709975775\n",
      "          Validation Loss (standardized): 1.7117035064894435\n",
      "Epoch: 16, Loss (standarized): 0.20219660897010022\n",
      "          Validation Loss (standardized): 1.7459916063725165\n",
      "Epoch: 17, Loss (standarized): 0.20428830447616114\n",
      "          Validation Loss (standardized): 1.7728296844223073\n",
      "Epoch: 18, Loss (standarized): 0.20601117409506123\n",
      "          Validation Loss (standardized): 1.792749102451549\n",
      "Epoch: 19, Loss (standarized): 0.20733490378708744\n",
      "          Validation Loss (standardized): 1.8062842830732413\n",
      "Epoch: 20, Loss (standarized): 0.20825467203058512\n",
      "          Validation Loss (standardized): 1.813952723658914\n",
      "Final epoch: 20, Final loss (standarized): 0.20825467203058512\n",
      "Epoch: 1, Loss (standarized): 0.3650372372918437\n",
      "          Validation Loss (standardized): 0.8482107066709073\n",
      "Epoch: 2, Loss (standarized): 0.2864324955324289\n",
      "          Validation Loss (standardized): 0.9623958679286975\n",
      "Epoch: 3, Loss (standarized): 0.2376607739157605\n",
      "          Validation Loss (standardized): 1.0880363733383362\n",
      "Epoch: 4, Loss (standarized): 0.21027842408206338\n",
      "          Validation Loss (standardized): 1.214779645421582\n",
      "Epoch: 5, Loss (standarized): 0.19693478666083808\n",
      "          Validation Loss (standardized): 1.33506157495998\n",
      "Epoch: 6, Loss (standarized): 0.1921126252197447\n",
      "          Validation Loss (standardized): 1.4440368083867565\n",
      "Epoch: 7, Loss (standarized): 0.19205790168190245\n",
      "          Validation Loss (standardized): 1.5390101778688003\n",
      "Epoch: 8, Loss (standarized): 0.1943746800907413\n",
      "          Validation Loss (standardized): 1.618818183155569\n",
      "Epoch: 9, Loss (standarized): 0.19760297119081785\n",
      "          Validation Loss (standardized): 1.6833310402533954\n",
      "Epoch: 10, Loss (standarized): 0.2008888928638918\n",
      "          Validation Loss (standardized): 1.7330536553619533\n",
      "Epoch: 11, Loss (standarized): 0.20375894291411079\n",
      "          Validation Loss (standardized): 1.7688884268574967\n",
      "Epoch: 12, Loss (standarized): 0.2059757413195074\n",
      "          Validation Loss (standardized): 1.7919444850924688\n",
      "Epoch: 13, Loss (standarized): 0.20744618029877762\n",
      "          Validation Loss (standardized): 1.8034213248890836\n",
      "Epoch: 14, Loss (standarized): 0.2081648278772288\n",
      "          Validation Loss (standardized): 1.804554160402625\n",
      "Epoch: 15, Loss (standarized): 0.20818045803350427\n",
      "          Validation Loss (standardized): 1.7965736526525071\n",
      "Epoch: 16, Loss (standarized): 0.20757459317842852\n",
      "          Validation Loss (standardized): 1.7806792736365267\n",
      "Epoch: 17, Loss (standarized): 0.20644813157785413\n",
      "          Validation Loss (standardized): 1.7580365128204198\n",
      "Epoch: 18, Loss (standarized): 0.20491353639416984\n",
      "          Validation Loss (standardized): 1.7297738613286904\n",
      "Epoch: 19, Loss (standarized): 0.20308934909035334\n",
      "          Validation Loss (standardized): 1.6969845224843134\n",
      "Epoch: 20, Loss (standarized): 0.20109587300278664\n",
      "          Validation Loss (standardized): 1.6607287232582473\n",
      "Final epoch: 20, Final loss (standarized): 0.20109587300278664\n",
      "Epoch: 1, Loss (standarized): 0.9177017638822175\n",
      "          Validation Loss (standardized): 0.6957759063469104\n",
      "Epoch: 2, Loss (standarized): 0.7081034925721036\n",
      "          Validation Loss (standardized): 0.6917502071355439\n",
      "Epoch: 3, Loss (standarized): 0.542109751841516\n",
      "          Validation Loss (standardized): 0.7256669032409788\n",
      "Epoch: 4, Loss (standarized): 0.418041061267567\n",
      "          Validation Loss (standardized): 0.7900772449352799\n",
      "Epoch: 5, Loss (standarized): 0.3303842811369825\n",
      "          Validation Loss (standardized): 0.8757526342111871\n",
      "Epoch: 6, Loss (standarized): 0.2716214830845582\n",
      "          Validation Loss (standardized): 0.973812912379326\n",
      "Epoch: 7, Loss (standarized): 0.23417926194594754\n",
      "          Validation Loss (standardized): 1.076966654357976\n",
      "Epoch: 8, Loss (standarized): 0.21162907925003754\n",
      "          Validation Loss (standardized): 1.1798441390073295\n",
      "Epoch: 9, Loss (standarized): 0.19906539029260983\n",
      "          Validation Loss (standardized): 1.278805782564271\n",
      "Epoch: 10, Loss (standarized): 0.1929859139773611\n",
      "          Validation Loss (standardized): 1.3715604895237856\n",
      "Epoch: 11, Loss (standarized): 0.19098937157436896\n",
      "          Validation Loss (standardized): 1.456783742031492\n",
      "Epoch: 12, Loss (standarized): 0.19146813365205828\n",
      "          Validation Loss (standardized): 1.533814733182848\n",
      "Epoch: 13, Loss (standarized): 0.1933611608387656\n",
      "          Validation Loss (standardized): 1.602434058225117\n",
      "Epoch: 14, Loss (standarized): 0.19597503095195298\n",
      "          Validation Loss (standardized): 1.6627044811686311\n",
      "Epoch: 15, Loss (standarized): 0.1988608894249304\n",
      "          Validation Loss (standardized): 1.7148690590168052\n",
      "Epoch: 16, Loss (standarized): 0.2017317577642999\n",
      "          Validation Loss (standardized): 1.759284420037809\n",
      "Epoch: 17, Loss (standarized): 0.2044082949738453\n",
      "          Validation Loss (standardized): 1.7963689087779164\n",
      "Epoch: 18, Loss (standarized): 0.20678261552077307\n",
      "          Validation Loss (standardized): 1.8265733796948869\n",
      "Epoch: 19, Loss (standarized): 0.20879483540160512\n",
      "          Validation Loss (standardized): 1.8503617560892882\n",
      "Epoch: 20, Loss (standarized): 0.21041708382061616\n",
      "          Validation Loss (standardized): 1.8681935313477986\n",
      "Final epoch: 20, Final loss (standarized): 0.21041708382061616\n",
      "Epoch: 1, Loss (standarized): 1.3162675895859637\n",
      "          Validation Loss (standardized): 0.7871226859435494\n",
      "Epoch: 2, Loss (standarized): 1.060703407469087\n",
      "          Validation Loss (standardized): 0.7220982849651599\n",
      "Epoch: 3, Loss (standarized): 0.8455471473094098\n",
      "          Validation Loss (standardized): 0.6918190397864624\n",
      "Epoch: 4, Loss (standarized): 0.6713882185908894\n",
      "          Validation Loss (standardized): 0.6927699580631684\n",
      "Epoch: 5, Loss (standarized): 0.5355895229391431\n",
      "          Validation Loss (standardized): 0.7192690675600136\n",
      "Epoch: 6, Loss (standarized): 0.43311593338255416\n",
      "          Validation Loss (standardized): 0.764809260549427\n",
      "Epoch: 7, Loss (standarized): 0.35784907247388803\n",
      "          Validation Loss (standardized): 0.8232007254910272\n",
      "Epoch: 8, Loss (standarized): 0.30374398544753267\n",
      "          Validation Loss (standardized): 0.8892315823128777\n",
      "Epoch: 9, Loss (standarized): 0.26552529801907915\n",
      "          Validation Loss (standardized): 0.9588717067483714\n",
      "Epoch: 10, Loss (standarized): 0.23894605930691698\n",
      "          Validation Loss (standardized): 1.0291895367585215\n",
      "Epoch: 11, Loss (standarized): 0.2207606881565597\n",
      "          Validation Loss (standardized): 1.098150253702494\n",
      "Epoch: 12, Loss (standarized): 0.20856731094698658\n",
      "          Validation Loss (standardized): 1.1643994567721747\n",
      "Epoch: 13, Loss (standarized): 0.2006211005300795\n",
      "          Validation Loss (standardized): 1.2270775711929343\n",
      "Epoch: 14, Loss (standarized): 0.1956666827216409\n",
      "          Validation Loss (standardized): 1.2856759938567544\n",
      "Epoch: 15, Loss (standarized): 0.19280450188521828\n",
      "          Validation Loss (standardized): 1.3399312012716729\n",
      "Epoch: 16, Loss (standarized): 0.19139053401759012\n",
      "          Validation Loss (standardized): 1.3897487932980999\n",
      "Epoch: 17, Loss (standarized): 0.19096340465231088\n",
      "          Validation Loss (standardized): 1.4351496411992348\n",
      "Epoch: 18, Loss (standarized): 0.19119227402731526\n",
      "          Validation Loss (standardized): 1.4762318681433573\n",
      "Epoch: 19, Loss (standarized): 0.19183982457156337\n",
      "          Validation Loss (standardized): 1.5131440404947234\n",
      "Epoch: 20, Loss (standarized): 0.19273600507820837\n",
      "          Validation Loss (standardized): 1.5460662868700479\n",
      "Final epoch: 20, Final loss (standarized): 0.19273600507820837\n",
      "Epoch: 1, Loss (standarized): 0.33412536684129135\n",
      "          Validation Loss (standardized): 0.8901061600350265\n",
      "Epoch: 2, Loss (standarized): 0.26454538657866394\n",
      "          Validation Loss (standardized): 1.0171965973175927\n",
      "Epoch: 3, Loss (standarized): 0.22337621822850148\n",
      "          Validation Loss (standardized): 1.1520630427635599\n",
      "Epoch: 4, Loss (standarized): 0.20216189523063285\n",
      "          Validation Loss (standardized): 1.2828547055717192\n",
      "Epoch: 5, Loss (standarized): 0.19337794869326416\n",
      "          Validation Loss (standardized): 1.4014788927358546\n",
      "Epoch: 6, Loss (standarized): 0.1915465693706612\n",
      "          Validation Loss (standardized): 1.5033586133213561\n",
      "Epoch: 7, Loss (standarized): 0.1931262684036057\n",
      "          Validation Loss (standardized): 1.5865350259279762\n",
      "Epoch: 8, Loss (standarized): 0.1960022195741283\n",
      "          Validation Loss (standardized): 1.6507775496706132\n",
      "Epoch: 9, Loss (standarized): 0.19899037386496254\n",
      "          Validation Loss (standardized): 1.6969009151810055\n",
      "Epoch: 10, Loss (standarized): 0.2014776524779643\n",
      "          Validation Loss (standardized): 1.726288746157046\n",
      "Epoch: 11, Loss (standarized): 0.20318962221092463\n",
      "          Validation Loss (standardized): 1.7405945327981363\n",
      "Epoch: 12, Loss (standarized): 0.20404922366971187\n",
      "          Validation Loss (standardized): 1.7415720701604067\n",
      "Epoch: 13, Loss (standarized): 0.20409387866600512\n",
      "          Validation Loss (standardized): 1.7309880536441664\n",
      "Epoch: 14, Loss (standarized): 0.20342754800728158\n",
      "          Validation Loss (standardized): 1.7105823041212624\n",
      "Epoch: 15, Loss (standarized): 0.20219281963909458\n",
      "          Validation Loss (standardized): 1.6820533229347325\n",
      "Epoch: 16, Loss (standarized): 0.20055401921803367\n",
      "          Validation Loss (standardized): 1.6470554235561297\n",
      "Epoch: 17, Loss (standarized): 0.19868586776149025\n",
      "          Validation Loss (standardized): 1.6071992978435532\n",
      "Epoch: 18, Loss (standarized): 0.19676426038543485\n",
      "          Validation Loss (standardized): 1.564051898288626\n",
      "Epoch: 19, Loss (standarized): 0.1949571007732833\n",
      "          Validation Loss (standardized): 1.5191342004450876\n",
      "Epoch: 20, Loss (standarized): 0.19341410838575682\n",
      "          Validation Loss (standardized): 1.473915107721587\n",
      "Final epoch: 20, Final loss (standarized): 0.19341410838575682\n",
      "Epoch: 1, Loss (standarized): 0.9258469593565674\n",
      "          Validation Loss (standardized): 0.7000864693338679\n",
      "Epoch: 2, Loss (standarized): 0.7411600685707989\n",
      "          Validation Loss (standardized): 0.6878530444085154\n",
      "Epoch: 3, Loss (standarized): 0.5900397407496396\n",
      "          Validation Loss (standardized): 0.7045229234948606\n",
      "Epoch: 4, Loss (standarized): 0.4709127169551576\n",
      "          Validation Loss (standardized): 0.746112137144288\n",
      "Epoch: 5, Loss (standarized): 0.3804913897268872\n",
      "          Validation Loss (standardized): 0.8073869055552497\n",
      "Epoch: 6, Loss (standarized): 0.3143655440354924\n",
      "          Validation Loss (standardized): 0.8827129662100824\n",
      "Epoch: 7, Loss (standarized): 0.2677409854326199\n",
      "          Validation Loss (standardized): 0.9667850174446653\n",
      "Epoch: 8, Loss (standarized): 0.2360762199090287\n",
      "          Validation Loss (standardized): 1.0550663272460248\n",
      "Epoch: 9, Loss (standarized): 0.21546793898994732\n",
      "          Validation Loss (standardized): 1.1439445845393426\n",
      "Epoch: 10, Loss (standarized): 0.2027850107275926\n",
      "          Validation Loss (standardized): 1.2306987476436797\n",
      "Epoch: 11, Loss (standarized): 0.19563378858778074\n",
      "          Validation Loss (standardized): 1.3133756370071836\n",
      "Epoch: 12, Loss (standarized): 0.19224387554414918\n",
      "          Validation Loss (standardized): 1.3906425307864938\n",
      "Epoch: 13, Loss (standarized): 0.19133511862117691\n",
      "          Validation Loss (standardized): 1.4616490287687396\n",
      "Epoch: 14, Loss (standarized): 0.19199652078250973\n",
      "          Validation Loss (standardized): 1.5259101455859656\n",
      "Epoch: 15, Loss (standarized): 0.19358776816343734\n",
      "          Validation Loss (standardized): 1.583212203215504\n",
      "Epoch: 16, Loss (standarized): 0.195663889360429\n",
      "          Validation Loss (standardized): 1.6335392129456359\n",
      "Epoch: 17, Loss (standarized): 0.197919595968338\n",
      "          Validation Loss (standardized): 1.677016438382883\n",
      "Epoch: 18, Loss (standarized): 0.20014899696245214\n",
      "          Validation Loss (standardized): 1.7138678424210656\n",
      "Epoch: 19, Loss (standarized): 0.2022167827625629\n",
      "          Validation Loss (standardized): 1.7443844593632816\n",
      "Epoch: 20, Loss (standarized): 0.20403774237769934\n",
      "          Validation Loss (standardized): 1.7689011859103363\n",
      "Final epoch: 20, Final loss (standarized): 0.20403774237769934\n",
      "Epoch: 1, Loss (standarized): 0.8940519008127183\n",
      "          Validation Loss (standardized): 0.6920549217356253\n",
      "Epoch: 2, Loss (standarized): 0.6754163625068467\n",
      "          Validation Loss (standardized): 0.6968874222928676\n",
      "Epoch: 3, Loss (standarized): 0.5094534981501821\n",
      "          Validation Loss (standardized): 0.7415717602685823\n",
      "Epoch: 4, Loss (standarized): 0.3908743323691807\n",
      "          Validation Loss (standardized): 0.8152590956559876\n",
      "Epoch: 5, Loss (standarized): 0.3106330757774747\n",
      "          Validation Loss (standardized): 0.9067350925583111\n",
      "Epoch: 6, Loss (standarized): 0.2588823048739129\n",
      "          Validation Loss (standardized): 1.006579852289679\n",
      "Epoch: 7, Loss (standarized): 0.2269899650518954\n",
      "          Validation Loss (standardized): 1.1079303385476515\n",
      "Epoch: 8, Loss (standarized): 0.2083316008725741\n",
      "          Validation Loss (standardized): 1.206278629864425\n",
      "Epoch: 9, Loss (standarized): 0.1982245766184722\n",
      "          Validation Loss (standardized): 1.2989104833122547\n",
      "Epoch: 10, Loss (standarized): 0.1935137414904566\n",
      "          Validation Loss (standardized): 1.3843439804136974\n",
      "Epoch: 11, Loss (standarized): 0.19212725312743295\n",
      "          Validation Loss (standardized): 1.4618942831504314\n",
      "Epoch: 12, Loss (standarized): 0.19272151727067818\n",
      "          Validation Loss (standardized): 1.531372881322224\n",
      "Epoch: 13, Loss (standarized): 0.19443004695416005\n",
      "          Validation Loss (standardized): 1.5928914771819043\n",
      "Epoch: 14, Loss (standarized): 0.1966958906103218\n",
      "          Validation Loss (standardized): 1.646737564263547\n",
      "Epoch: 15, Loss (standarized): 0.19916277945986352\n",
      "          Validation Loss (standardized): 1.6932963524375118\n",
      "Epoch: 16, Loss (standarized): 0.2016050880559998\n",
      "          Validation Loss (standardized): 1.7330020124102952\n",
      "Epoch: 17, Loss (standarized): 0.2038827610228695\n",
      "          Validation Loss (standardized): 1.7663074571183066\n",
      "Epoch: 18, Loss (standarized): 0.20591215459471673\n",
      "          Validation Loss (standardized): 1.7936659445453955\n",
      "Epoch: 19, Loss (standarized): 0.20764703337576612\n",
      "          Validation Loss (standardized): 1.8155202787906548\n",
      "Epoch: 20, Loss (standarized): 0.20906608661813345\n",
      "          Validation Loss (standardized): 1.8322968953738126\n",
      "Final epoch: 20, Final loss (standarized): 0.20906608661813345\n",
      "Epoch: 1, Loss (standarized): 1.1860234694556735\n",
      "          Validation Loss (standardized): 0.7492772495949935\n",
      "Epoch: 2, Loss (standarized): 0.9465370269365273\n",
      "          Validation Loss (standardized): 0.7010295521982388\n",
      "Epoch: 3, Loss (standarized): 0.7477484616620175\n",
      "          Validation Loss (standardized): 0.6877410764055932\n",
      "Epoch: 4, Loss (standarized): 0.5900834352039515\n",
      "          Validation Loss (standardized): 0.7047037433738426\n",
      "Epoch: 5, Loss (standarized): 0.4700891360209469\n",
      "          Validation Loss (standardized): 0.7450140425097856\n",
      "Epoch: 6, Loss (standarized): 0.38209312252531874\n",
      "          Validation Loss (standardized): 0.8011391214762884\n",
      "Epoch: 7, Loss (standarized): 0.31948902908867033\n",
      "          Validation Loss (standardized): 0.8663217041177245\n",
      "Epoch: 8, Loss (standarized): 0.275940075030977\n",
      "          Validation Loss (standardized): 0.9353216380367542\n",
      "Epoch: 9, Loss (standarized): 0.2461275001520759\n",
      "          Validation Loss (standardized): 1.0044547690917582\n",
      "Epoch: 10, Loss (standarized): 0.22598327233391402\n",
      "          Validation Loss (standardized): 1.0712113058472168\n",
      "Epoch: 11, Loss (standarized): 0.21256940258900506\n",
      "          Validation Loss (standardized): 1.1340973241134436\n",
      "Epoch: 12, Loss (standarized): 0.20378688683203247\n",
      "          Validation Loss (standardized): 1.1922815124632726\n",
      "Epoch: 13, Loss (standarized): 0.19817346197312016\n",
      "          Validation Loss (standardized): 1.2452189332565857\n",
      "Epoch: 14, Loss (standarized): 0.19472470874939263\n",
      "          Validation Loss (standardized): 1.292714627624398\n",
      "Epoch: 15, Loss (standarized): 0.192733247436278\n",
      "          Validation Loss (standardized): 1.334865437546016\n",
      "Epoch: 16, Loss (standarized): 0.19170656346267212\n",
      "          Validation Loss (standardized): 1.3717920603256772\n",
      "Epoch: 17, Loss (standarized): 0.19130497411101957\n",
      "          Validation Loss (standardized): 1.4037642449207395\n",
      "Epoch: 18, Loss (standarized): 0.1912914013261096\n",
      "          Validation Loss (standardized): 1.4309332904818186\n",
      "Epoch: 19, Loss (standarized): 0.1915017342784223\n",
      "          Validation Loss (standardized): 1.4536622465376892\n",
      "Epoch: 20, Loss (standarized): 0.19182295896604512\n",
      "          Validation Loss (standardized): 1.4723263054748623\n",
      "Final epoch: 20, Final loss (standarized): 0.19182295896604512\n",
      "Epoch: 1, Loss (standarized): 0.19802195091482921\n",
      "          Validation Loss (standardized): 1.2624133865396652\n",
      "Epoch: 2, Loss (standarized): 0.19455246787495303\n",
      "          Validation Loss (standardized): 1.2849800559803597\n",
      "Epoch: 3, Loss (standarized): 0.19361987923534607\n",
      "          Validation Loss (standardized): 1.2869320679193417\n",
      "Epoch: 4, Loss (standarized): 0.19350667156138918\n",
      "          Validation Loss (standardized): 1.2778089291941108\n",
      "Epoch: 5, Loss (standarized): 0.19379360032846007\n",
      "          Validation Loss (standardized): 1.265742268607481\n",
      "Epoch: 6, Loss (standarized): 0.19424076873965337\n",
      "          Validation Loss (standardized): 1.2526322896945419\n",
      "Epoch: 7, Loss (standarized): 0.19480527345704604\n",
      "          Validation Loss (standardized): 1.2429580850202484\n",
      "Epoch: 8, Loss (standarized): 0.1952667273308068\n",
      "          Validation Loss (standardized): 1.237819177907962\n",
      "Epoch: 9, Loss (standarized): 0.19551720713869433\n",
      "          Validation Loss (standardized): 1.236990085470837\n",
      "Epoch: 10, Loss (standarized): 0.19553471907656433\n",
      "          Validation Loss (standardized): 1.2391846053845763\n",
      "Epoch: 11, Loss (standarized): 0.19538505036946607\n",
      "          Validation Loss (standardized): 1.244668474069133\n",
      "Epoch: 12, Loss (standarized): 0.1950652402630142\n",
      "          Validation Loss (standardized): 1.2509229930407681\n",
      "Epoch: 13, Loss (standarized): 0.19472497931081859\n",
      "          Validation Loss (standardized): 1.2561400313207445\n",
      "Epoch: 14, Loss (standarized): 0.19445615327330312\n",
      "          Validation Loss (standardized): 1.26097479293088\n",
      "Epoch: 15, Loss (standarized): 0.19422102747463232\n",
      "          Validation Loss (standardized): 1.2641104702699306\n",
      "Epoch: 16, Loss (standarized): 0.19407178001164843\n",
      "          Validation Loss (standardized): 1.2654339358439077\n",
      "Epoch: 17, Loss (standarized): 0.19400722201096363\n",
      "          Validation Loss (standardized): 1.2645236754128408\n",
      "Epoch: 18, Loss (standarized): 0.1940418701234954\n",
      "          Validation Loss (standardized): 1.2616589664800022\n",
      "Epoch: 19, Loss (standarized): 0.19416498062012216\n",
      "          Validation Loss (standardized): 1.2592654401140053\n",
      "Epoch: 20, Loss (standarized): 0.19426957314986856\n",
      "          Validation Loss (standardized): 1.257032787192904\n",
      "Final epoch: 20, Final loss (standarized): 0.19426957314986856\n",
      "Epoch: 1, Loss (standarized): 1.5567931334898635\n",
      "          Validation Loss (standardized): 0.8665637809941135\n",
      "Epoch: 2, Loss (standarized): 1.2680011101047421\n",
      "          Validation Loss (standardized): 0.7698167831948552\n",
      "Epoch: 3, Loss (standarized): 1.012007814200004\n",
      "          Validation Loss (standardized): 0.7097132521889516\n",
      "Epoch: 4, Loss (standarized): 0.7946977076881296\n",
      "          Validation Loss (standardized): 0.6876789611229001\n",
      "Epoch: 5, Loss (standarized): 0.6185257719916523\n",
      "          Validation Loss (standardized): 0.70129938980741\n",
      "Epoch: 6, Loss (standarized): 0.4828003592454519\n",
      "          Validation Loss (standardized): 0.7443624032865818\n",
      "Epoch: 7, Loss (standarized): 0.38339107316357396\n",
      "          Validation Loss (standardized): 0.8085820752097692\n",
      "Epoch: 8, Loss (standarized): 0.31366814661299347\n",
      "          Validation Loss (standardized): 0.8857598987068127\n",
      "Epoch: 9, Loss (standarized): 0.26646653748717425\n",
      "          Validation Loss (standardized): 0.9689614059135025\n",
      "Epoch: 10, Loss (standarized): 0.23550923204136107\n",
      "          Validation Loss (standardized): 1.0528616588974062\n",
      "Epoch: 11, Loss (standarized): 0.21586009110059223\n",
      "          Validation Loss (standardized): 1.1339597989450843\n",
      "Epoch: 12, Loss (standarized): 0.20383559309622873\n",
      "          Validation Loss (standardized): 1.2099388504069928\n",
      "Epoch: 13, Loss (standarized): 0.1968637941255846\n",
      "          Validation Loss (standardized): 1.2795340672959563\n",
      "Epoch: 14, Loss (standarized): 0.19316921149732502\n",
      "          Validation Loss (standardized): 1.3421559367081022\n",
      "Epoch: 15, Loss (standarized): 0.1915550024844584\n",
      "          Validation Loss (standardized): 1.3975311211020354\n",
      "Epoch: 16, Loss (standarized): 0.19122112423659998\n",
      "          Validation Loss (standardized): 1.4456324529044928\n",
      "Epoch: 17, Loss (standarized): 0.191631399534351\n",
      "          Validation Loss (standardized): 1.486677366995258\n",
      "Epoch: 18, Loss (standarized): 0.1924270582191908\n",
      "          Validation Loss (standardized): 1.5211592433018621\n",
      "Epoch: 19, Loss (standarized): 0.19337729233445658\n",
      "          Validation Loss (standardized): 1.5493572040788548\n",
      "Epoch: 20, Loss (standarized): 0.1943274495770366\n",
      "          Validation Loss (standardized): 1.5718103356568869\n",
      "Final epoch: 20, Final loss (standarized): 0.1943274495770366\n",
      "Epoch: 1, Loss (standarized): 1.0880809416808261\n",
      "          Validation Loss (standardized): 0.727157517753698\n",
      "Epoch: 2, Loss (standarized): 0.8693550713745489\n",
      "          Validation Loss (standardized): 0.6921307831026846\n",
      "Epoch: 3, Loss (standarized): 0.6865975247977313\n",
      "          Validation Loss (standardized): 0.6906570784031257\n",
      "Epoch: 4, Loss (standarized): 0.5412189528709322\n",
      "          Validation Loss (standardized): 0.718491716911544\n",
      "Epoch: 5, Loss (standarized): 0.43110241098430996\n",
      "          Validation Loss (standardized): 0.7690258683647673\n",
      "Epoch: 6, Loss (standarized): 0.35090209031217073\n",
      "          Validation Loss (standardized): 0.8347356668036112\n",
      "Epoch: 7, Loss (standarized): 0.29465140294406705\n",
      "          Validation Loss (standardized): 0.9087307987603214\n",
      "Epoch: 8, Loss (standarized): 0.2563541814643481\n",
      "          Validation Loss (standardized): 0.9855200966546921\n",
      "Epoch: 9, Loss (standarized): 0.2309318096470095\n",
      "          Validation Loss (standardized): 1.0612849924028007\n",
      "Epoch: 10, Loss (standarized): 0.21444181498924245\n",
      "          Validation Loss (standardized): 1.133277287791947\n",
      "Epoch: 11, Loss (standarized): 0.20406287645224955\n",
      "          Validation Loss (standardized): 1.2000291575765656\n",
      "Epoch: 12, Loss (standarized): 0.19776432983797423\n",
      "          Validation Loss (standardized): 1.260626671988412\n",
      "Epoch: 13, Loss (standarized): 0.19416411557774382\n",
      "          Validation Loss (standardized): 1.3147805691230026\n",
      "Epoch: 14, Loss (standarized): 0.19231125233685198\n",
      "          Validation Loss (standardized): 1.3626682261845025\n",
      "Epoch: 15, Loss (standarized): 0.19156328689796315\n",
      "          Validation Loss (standardized): 1.4044298128899932\n",
      "Epoch: 16, Loss (standarized): 0.1914943761543703\n",
      "          Validation Loss (standardized): 1.4401469658656076\n",
      "Epoch: 17, Loss (standarized): 0.19181304717715408\n",
      "          Validation Loss (standardized): 1.4698228081251767\n",
      "Epoch: 18, Loss (standarized): 0.19231644433433734\n",
      "          Validation Loss (standardized): 1.4936530139572333\n",
      "Epoch: 19, Loss (standarized): 0.1928654650332731\n",
      "          Validation Loss (standardized): 1.5122201796134924\n",
      "Epoch: 20, Loss (standarized): 0.1933762293580599\n",
      "          Validation Loss (standardized): 1.5260926735052545\n",
      "Final epoch: 20, Final loss (standarized): 0.1933762293580599\n",
      "Epoch: 1, Loss (standarized): 0.6565838177288799\n",
      "          Validation Loss (standardized): 0.6930079878114986\n",
      "Epoch: 2, Loss (standarized): 0.5239609475639522\n",
      "          Validation Loss (standardized): 0.7235678708199634\n",
      "Epoch: 3, Loss (standarized): 0.4200137923977202\n",
      "          Validation Loss (standardized): 0.7771742495992359\n",
      "Epoch: 4, Loss (standarized): 0.3420718749833764\n",
      "          Validation Loss (standardized): 0.8484865848661886\n",
      "Epoch: 5, Loss (standarized): 0.2860603573295146\n",
      "          Validation Loss (standardized): 0.9318259706879175\n",
      "Epoch: 6, Loss (standarized): 0.24748055249908302\n",
      "          Validation Loss (standardized): 1.0218776528149927\n",
      "Epoch: 7, Loss (standarized): 0.22210475597886115\n",
      "          Validation Loss (standardized): 1.114150917501719\n",
      "Epoch: 8, Loss (standarized): 0.20632700552268016\n",
      "          Validation Loss (standardized): 1.2050582884427021\n",
      "Epoch: 9, Loss (standarized): 0.19728989545622497\n",
      "          Validation Loss (standardized): 1.2919645214861333\n",
      "Epoch: 10, Loss (standarized): 0.19282604113513496\n",
      "          Validation Loss (standardized): 1.3730543616945894\n",
      "Epoch: 11, Loss (standarized): 0.19135457069633482\n",
      "          Validation Loss (standardized): 1.4471730186893632\n",
      "Epoch: 12, Loss (standarized): 0.19175225851774963\n",
      "          Validation Loss (standardized): 1.5136259304352149\n",
      "Epoch: 13, Loss (standarized): 0.1932325337242378\n",
      "          Validation Loss (standardized): 1.5721130602712257\n",
      "Epoch: 14, Loss (standarized): 0.1952582107432494\n",
      "          Validation Loss (standardized): 1.6226281572177543\n",
      "Epoch: 15, Loss (standarized): 0.19746880468811345\n",
      "          Validation Loss (standardized): 1.6653626772113046\n",
      "Epoch: 16, Loss (standarized): 0.19962848314175113\n",
      "          Validation Loss (standardized): 1.7006024609990065\n",
      "Epoch: 17, Loss (standarized): 0.20158877904674324\n",
      "          Validation Loss (standardized): 1.7287561547261037\n",
      "Epoch: 18, Loss (standarized): 0.20326271082277725\n",
      "          Validation Loss (standardized): 1.750243949133017\n",
      "Epoch: 19, Loss (standarized): 0.20460182105789868\n",
      "          Validation Loss (standardized): 1.7654892612563204\n",
      "Epoch: 20, Loss (standarized): 0.2055841631884929\n",
      "          Validation Loss (standardized): 1.7749630705612702\n",
      "Final epoch: 20, Final loss (standarized): 0.2055841631884929\n",
      "Epoch: 1, Loss (standarized): 0.6500323396942747\n",
      "          Validation Loss (standardized): 0.6986580716144055\n",
      "Epoch: 2, Loss (standarized): 0.4934196256561225\n",
      "          Validation Loss (standardized): 0.7480906206354202\n",
      "Epoch: 3, Loss (standarized): 0.37750733832511574\n",
      "          Validation Loss (standardized): 0.8299123901316661\n",
      "Epoch: 4, Loss (standarized): 0.29770599942317605\n",
      "          Validation Loss (standardized): 0.9335288614199598\n",
      "Epoch: 5, Loss (standarized): 0.246720521701048\n",
      "          Validation Loss (standardized): 1.0480799885537992\n",
      "Epoch: 6, Loss (standarized): 0.21661960550849516\n",
      "          Validation Loss (standardized): 1.1645627732453823\n",
      "Epoch: 7, Loss (standarized): 0.20051374655793336\n",
      "          Validation Loss (standardized): 1.276562586603606\n",
      "Epoch: 8, Loss (standarized): 0.1932196303058257\n",
      "          Validation Loss (standardized): 1.3800132692604188\n",
      "Epoch: 9, Loss (standarized): 0.19117274140448573\n",
      "          Validation Loss (standardized): 1.4726427347398718\n",
      "Epoch: 10, Loss (standarized): 0.1920506733696209\n",
      "          Validation Loss (standardized): 1.5534158330144299\n",
      "Epoch: 11, Loss (standarized): 0.19439131009142302\n",
      "          Validation Loss (standardized): 1.6220624107514559\n",
      "Epoch: 12, Loss (standarized): 0.19729512108787686\n",
      "          Validation Loss (standardized): 1.678811657561996\n",
      "Epoch: 13, Loss (standarized): 0.20022153645805998\n",
      "          Validation Loss (standardized): 1.724161582847069\n",
      "Epoch: 14, Loss (standarized): 0.20285540818433143\n",
      "          Validation Loss (standardized): 1.7587357917331883\n",
      "Epoch: 15, Loss (standarized): 0.2050218915699532\n",
      "          Validation Loss (standardized): 1.7832734283514864\n",
      "Epoch: 16, Loss (standarized): 0.20663847233760332\n",
      "          Validation Loss (standardized): 1.7985758781371397\n",
      "Epoch: 17, Loss (standarized): 0.20768197764127297\n",
      "          Validation Loss (standardized): 1.8054496660515158\n",
      "Epoch: 18, Loss (standarized): 0.2081654332840465\n",
      "          Validation Loss (standardized): 1.8047188570207\n",
      "Epoch: 19, Loss (standarized): 0.20812908780970757\n",
      "          Validation Loss (standardized): 1.7971762475151138\n",
      "Epoch: 20, Loss (standarized): 0.20762430666776274\n",
      "          Validation Loss (standardized): 1.7835823339575259\n",
      "Final epoch: 20, Final loss (standarized): 0.20762430666776274\n",
      "Epoch: 1, Loss (standarized): 0.5780563802782355\n",
      "          Validation Loss (standardized): 0.712585176175526\n",
      "Epoch: 2, Loss (standarized): 0.44565107670660026\n",
      "          Validation Loss (standardized): 0.7702424279447158\n",
      "Epoch: 3, Loss (standarized): 0.3494117895142426\n",
      "          Validation Loss (standardized): 0.852755826725724\n",
      "Epoch: 4, Loss (standarized): 0.2835167020931729\n",
      "          Validation Loss (standardized): 0.95101789550597\n",
      "Epoch: 5, Loss (standarized): 0.2409975094447921\n",
      "          Validation Loss (standardized): 1.0566526257878481\n",
      "Epoch: 6, Loss (standarized): 0.21526184556149425\n",
      "          Validation Loss (standardized): 1.1630208964817539\n",
      "Epoch: 7, Loss (standarized): 0.20091089589811803\n",
      "          Validation Loss (standardized): 1.2653859315849028\n",
      "Epoch: 8, Loss (standarized): 0.19393789699051578\n",
      "          Validation Loss (standardized): 1.3606153230693707\n",
      "Epoch: 9, Loss (standarized): 0.19154531145662795\n",
      "          Validation Loss (standardized): 1.4468718437159962\n",
      "Epoch: 10, Loss (standarized): 0.19184969214232642\n",
      "          Validation Loss (standardized): 1.5232581384075439\n",
      "Epoch: 11, Loss (standarized): 0.1936177470684622\n",
      "          Validation Loss (standardized): 1.589429570357203\n",
      "Epoch: 12, Loss (standarized): 0.1960586343289674\n",
      "          Validation Loss (standardized): 1.6454925258987643\n",
      "Epoch: 13, Loss (standarized): 0.1986742571708431\n",
      "          Validation Loss (standardized): 1.6917168963057836\n",
      "Epoch: 14, Loss (standarized): 0.20115409302153625\n",
      "          Validation Loss (standardized): 1.7286367342959397\n",
      "Epoch: 15, Loss (standarized): 0.20331982319450542\n",
      "          Validation Loss (standardized): 1.756896560708385\n",
      "Epoch: 16, Loss (standarized): 0.20507772955193834\n",
      "          Validation Loss (standardized): 1.777086856569959\n",
      "Epoch: 17, Loss (standarized): 0.20638234449054474\n",
      "          Validation Loss (standardized): 1.7898847658516004\n",
      "Epoch: 18, Loss (standarized): 0.20722643473793234\n",
      "          Validation Loss (standardized): 1.7959251774206795\n",
      "Epoch: 19, Loss (standarized): 0.2076256645517231\n",
      "          Validation Loss (standardized): 1.7958762322460322\n",
      "Epoch: 20, Loss (standarized): 0.20761368397177057\n",
      "          Validation Loss (standardized): 1.7903461287186115\n",
      "Final epoch: 20, Final loss (standarized): 0.20761368397177057\n",
      "Epoch: 1, Loss (standarized): 1.1202521339213192\n",
      "          Validation Loss (standardized): 0.7368086268764847\n",
      "Epoch: 2, Loss (standarized): 0.8997178610090749\n",
      "          Validation Loss (standardized): 0.697614058215964\n",
      "Epoch: 3, Loss (standarized): 0.7157908687664859\n",
      "          Validation Loss (standardized): 0.6905401750363828\n",
      "Epoch: 4, Loss (standarized): 0.5682620913510895\n",
      "          Validation Loss (standardized): 0.711960059960407\n",
      "Epoch: 5, Loss (standarized): 0.45430431213862016\n",
      "          Validation Loss (standardized): 0.756507722266189\n",
      "Epoch: 6, Loss (standarized): 0.3693178865170483\n",
      "          Validation Loss (standardized): 0.8181377490341291\n",
      "Epoch: 7, Loss (standarized): 0.3079253690534203\n",
      "          Validation Loss (standardized): 0.8910696855238188\n",
      "Epoch: 8, Loss (standarized): 0.26484913277975086\n",
      "          Validation Loss (standardized): 0.9703303564428262\n",
      "Epoch: 9, Loss (standarized): 0.23548071924726602\n",
      "          Validation Loss (standardized): 1.0519794818983985\n",
      "Epoch: 10, Loss (standarized): 0.2160881426302806\n",
      "          Validation Loss (standardized): 1.1330772829692835\n",
      "Epoch: 11, Loss (standarized): 0.20379916251511848\n",
      "          Validation Loss (standardized): 1.2115299512623376\n",
      "Epoch: 12, Loss (standarized): 0.19647748158712924\n",
      "          Validation Loss (standardized): 1.2859243005300578\n",
      "Epoch: 13, Loss (standarized): 0.19256936593645385\n",
      "          Validation Loss (standardized): 1.3553596894900384\n",
      "Epoch: 14, Loss (standarized): 0.19096189840207736\n",
      "          Validation Loss (standardized): 1.4193070591110881\n",
      "Epoch: 15, Loss (standarized): 0.190864219670044\n",
      "          Validation Loss (standardized): 1.4775477504062584\n",
      "Epoch: 16, Loss (standarized): 0.19171972224650619\n",
      "          Validation Loss (standardized): 1.5300215293116077\n",
      "Epoch: 17, Loss (standarized): 0.1931381596998443\n",
      "          Validation Loss (standardized): 1.5767949433415172\n",
      "Epoch: 18, Loss (standarized): 0.19484601665919557\n",
      "          Validation Loss (standardized): 1.6180098954153082\n",
      "Epoch: 19, Loss (standarized): 0.19665621804918362\n",
      "          Validation Loss (standardized): 1.6539194870873806\n",
      "Epoch: 20, Loss (standarized): 0.1984424682309018\n",
      "          Validation Loss (standardized): 1.684758166562975\n",
      "Final epoch: 20, Final loss (standarized): 0.1984424682309018\n",
      "Epoch: 1, Loss (standarized): 0.42609625836707377\n",
      "          Validation Loss (standardized): 0.785422744888781\n",
      "Epoch: 2, Loss (standarized): 0.333500310888723\n",
      "          Validation Loss (standardized): 0.8784491927990539\n",
      "Epoch: 3, Loss (standarized): 0.2696034478671799\n",
      "          Validation Loss (standardized): 0.991031115257223\n",
      "Epoch: 4, Loss (standarized): 0.22912355823080519\n",
      "          Validation Loss (standardized): 1.1138014635385214\n",
      "Epoch: 5, Loss (standarized): 0.2060142965998456\n",
      "          Validation Loss (standardized): 1.2383371579296993\n",
      "Epoch: 6, Loss (standarized): 0.19475996770364554\n",
      "          Validation Loss (standardized): 1.3580222524110195\n",
      "Epoch: 7, Loss (standarized): 0.19099982943119292\n",
      "          Validation Loss (standardized): 1.4681941347418057\n",
      "Epoch: 8, Loss (standarized): 0.19159878424442162\n",
      "          Validation Loss (standardized): 1.565904773643855\n",
      "Epoch: 9, Loss (standarized): 0.19444420456587003\n",
      "          Validation Loss (standardized): 1.6495733262853058\n",
      "Epoch: 10, Loss (standarized): 0.19817981663284426\n",
      "          Validation Loss (standardized): 1.7186323218873043\n",
      "Epoch: 11, Loss (standarized): 0.20197294296370535\n",
      "          Validation Loss (standardized): 1.7732119241328366\n",
      "Epoch: 12, Loss (standarized): 0.20533976456193606\n",
      "          Validation Loss (standardized): 1.813912448763984\n",
      "Epoch: 13, Loss (standarized): 0.20802350536323225\n",
      "          Validation Loss (standardized): 1.841612187720794\n",
      "Epoch: 14, Loss (standarized): 0.20991184174094923\n",
      "          Validation Loss (standardized): 1.8573489091248356\n",
      "Epoch: 15, Loss (standarized): 0.21098353775219889\n",
      "          Validation Loss (standardized): 1.8622425780604945\n",
      "Epoch: 16, Loss (standarized): 0.21127465763802966\n",
      "          Validation Loss (standardized): 1.857439517896426\n",
      "Epoch: 17, Loss (standarized): 0.21085789027088475\n",
      "          Validation Loss (standardized): 1.8440918108812303\n",
      "Epoch: 18, Loss (standarized): 0.20982869303139387\n",
      "          Validation Loss (standardized): 1.823337628010712\n",
      "Epoch: 19, Loss (standarized): 0.20829698176993702\n",
      "          Validation Loss (standardized): 1.7963022989528048\n",
      "Epoch: 20, Loss (standarized): 0.20638143556560737\n",
      "          Validation Loss (standardized): 1.7640894723749079\n",
      "Final epoch: 20, Final loss (standarized): 0.20638143556560737\n",
      "Epoch: 1, Loss (standarized): 1.312899895648116\n",
      "          Validation Loss (standardized): 0.7735604246934028\n",
      "Epoch: 2, Loss (standarized): 1.0228774677642913\n",
      "          Validation Loss (standardized): 0.7067503667001286\n",
      "Epoch: 3, Loss (standarized): 0.7798304352629934\n",
      "          Validation Loss (standardized): 0.6876411727313807\n",
      "Epoch: 4, Loss (standarized): 0.5877693544021352\n",
      "          Validation Loss (standardized): 0.7127926296461097\n",
      "Epoch: 5, Loss (standarized): 0.44516281227490956\n",
      "          Validation Loss (standardized): 0.773626633712262\n",
      "Epoch: 6, Loss (standarized): 0.3454755089727873\n",
      "          Validation Loss (standardized): 0.8591364987778165\n",
      "Epoch: 7, Loss (standarized): 0.2795276970875271\n",
      "          Validation Loss (standardized): 0.9587198235230556\n",
      "Epoch: 8, Loss (standarized): 0.23808227072695248\n",
      "          Validation Loss (standardized): 1.0638304359298625\n",
      "Epoch: 9, Loss (standarized): 0.21341877907441698\n",
      "          Validation Loss (standardized): 1.168371963914791\n",
      "Epoch: 10, Loss (standarized): 0.19977901496715753\n",
      "          Validation Loss (standardized): 1.2683856887198914\n",
      "Epoch: 11, Loss (standarized): 0.19315540180074978\n",
      "          Validation Loss (standardized): 1.3615184410137635\n",
      "Epoch: 12, Loss (standarized): 0.19087043132412182\n",
      "          Validation Loss (standardized): 1.446520351385949\n",
      "Epoch: 13, Loss (standarized): 0.19117595312227081\n",
      "          Validation Loss (standardized): 1.522864772114229\n",
      "Epoch: 14, Loss (standarized): 0.19294487002465063\n",
      "          Validation Loss (standardized): 1.5904781269286548\n",
      "Epoch: 15, Loss (standarized): 0.19545562318144027\n",
      "          Validation Loss (standardized): 1.6495531881010168\n",
      "Epoch: 16, Loss (standarized): 0.1982499995588551\n",
      "          Validation Loss (standardized): 1.7004443220622663\n",
      "Epoch: 17, Loss (standarized): 0.2010400572192367\n",
      "          Validation Loss (standardized): 1.7435933080667763\n",
      "Epoch: 18, Loss (standarized): 0.20364861208330257\n",
      "          Validation Loss (standardized): 1.7794801774752824\n",
      "Epoch: 19, Loss (standarized): 0.20597043170801568\n",
      "          Validation Loss (standardized): 1.8086008586051556\n",
      "Epoch: 20, Loss (standarized): 0.20794789212956954\n",
      "          Validation Loss (standardized): 1.8314492519277104\n",
      "Final epoch: 20, Final loss (standarized): 0.20794789212956954\n",
      "Epoch: 1, Loss (standarized): 0.9137710716107189\n",
      "          Validation Loss (standardized): 0.6962985973932215\n",
      "Epoch: 2, Loss (standarized): 0.7192539957182481\n",
      "          Validation Loss (standardized): 0.688789494925303\n",
      "Epoch: 3, Loss (standarized): 0.5615901127584155\n",
      "          Validation Loss (standardized): 0.7146770712951248\n",
      "Epoch: 4, Loss (standarized): 0.4401353568141095\n",
      "          Validation Loss (standardized): 0.7686177897576109\n",
      "Epoch: 5, Loss (standarized): 0.3511129011245078\n",
      "          Validation Loss (standardized): 0.8434961392325167\n",
      "Epoch: 6, Loss (standarized): 0.28884298278933873\n",
      "          Validation Loss (standardized): 0.9319748797401047\n",
      "Epoch: 7, Loss (standarized): 0.24720291715843296\n",
      "          Validation Loss (standardized): 1.0275630211030784\n",
      "Epoch: 8, Loss (standarized): 0.2206548437176907\n",
      "          Validation Loss (standardized): 1.1251000372007791\n",
      "Epoch: 9, Loss (standarized): 0.2047051843019142\n",
      "          Validation Loss (standardized): 1.2207895554256532\n",
      "Epoch: 10, Loss (standarized): 0.19595863662377386\n",
      "          Validation Loss (standardized): 1.3120153602593745\n",
      "Epoch: 11, Loss (standarized): 0.19196546798545758\n",
      "          Validation Loss (standardized): 1.3970869872128653\n",
      "Epoch: 12, Loss (standarized): 0.19101038122299938\n",
      "          Validation Loss (standardized): 1.4750020521656209\n",
      "Epoch: 13, Loss (standarized): 0.19191521156831676\n",
      "          Validation Loss (standardized): 1.545248016181916\n",
      "Epoch: 14, Loss (standarized): 0.1938814358583977\n",
      "          Validation Loss (standardized): 1.607651275079189\n",
      "Epoch: 15, Loss (standarized): 0.19637354489271605\n",
      "          Validation Loss (standardized): 1.662267840247875\n",
      "Epoch: 16, Loss (standarized): 0.19903668029534896\n",
      "          Validation Loss (standardized): 1.7093078545009421\n",
      "Epoch: 17, Loss (standarized): 0.20163916201921878\n",
      "          Validation Loss (standardized): 1.7490766751822953\n",
      "Epoch: 18, Loss (standarized): 0.2040338096516769\n",
      "          Validation Loss (standardized): 1.781940999933185\n",
      "Epoch: 19, Loss (standarized): 0.20613124548363276\n",
      "          Validation Loss (standardized): 1.8082978102229654\n",
      "Epoch: 20, Loss (standarized): 0.20788196717976823\n",
      "          Validation Loss (standardized): 1.8285658792464858\n",
      "Final epoch: 20, Final loss (standarized): 0.20788196717976823\n",
      "Epoch: 1, Loss (standarized): 0.3240654307425797\n",
      "          Validation Loss (standardized): 0.9059568394723163\n",
      "Epoch: 2, Loss (standarized): 0.2583678662814433\n",
      "          Validation Loss (standardized): 1.0355658675510773\n",
      "Epoch: 3, Loss (standarized): 0.2200806295275431\n",
      "          Validation Loss (standardized): 1.1730371388477507\n",
      "Epoch: 4, Loss (standarized): 0.20070720652634252\n",
      "          Validation Loss (standardized): 1.3073689841565426\n",
      "Epoch: 5, Loss (standarized): 0.1931658618027891\n",
      "          Validation Loss (standardized): 1.4306155703345849\n",
      "Epoch: 6, Loss (standarized): 0.19230132085630244\n",
      "          Validation Loss (standardized): 1.5378431807984114\n",
      "Epoch: 7, Loss (standarized): 0.19471531357177935\n",
      "          Validation Loss (standardized): 1.6265582728453063\n",
      "Epoch: 8, Loss (standarized): 0.19832572716211644\n",
      "          Validation Loss (standardized): 1.6961073059940093\n",
      "Epoch: 9, Loss (standarized): 0.20194149849241627\n",
      "          Validation Loss (standardized): 1.7470370420317247\n",
      "Epoch: 10, Loss (standarized): 0.20493634999637989\n",
      "          Validation Loss (standardized): 1.7806036146087636\n",
      "Epoch: 11, Loss (standarized): 0.20703030622358545\n",
      "          Validation Loss (standardized): 1.79844530411986\n",
      "Epoch: 12, Loss (standarized): 0.20814800290433327\n",
      "          Validation Loss (standardized): 1.8023505916189464\n",
      "Epoch: 13, Loss (standarized): 0.2083323451210911\n",
      "          Validation Loss (standardized): 1.794132990409729\n",
      "Epoch: 14, Loss (standarized): 0.20769242494670678\n",
      "          Validation Loss (standardized): 1.7755735861638824\n",
      "Epoch: 15, Loss (standarized): 0.20637483012063632\n",
      "          Validation Loss (standardized): 1.7483888504544551\n",
      "Epoch: 16, Loss (standarized): 0.20454596740612133\n",
      "          Validation Loss (standardized): 1.7142344899793323\n",
      "Epoch: 17, Loss (standarized): 0.20238184064185566\n",
      "          Validation Loss (standardized): 1.6746966709547753\n",
      "Epoch: 18, Loss (standarized): 0.20006036250935771\n",
      "          Validation Loss (standardized): 1.631317227086534\n",
      "Epoch: 19, Loss (standarized): 0.19775305660449394\n",
      "          Validation Loss (standardized): 1.585565909177898\n",
      "Epoch: 20, Loss (standarized): 0.19561896299903792\n",
      "          Validation Loss (standardized): 1.5388575140894039\n",
      "Final epoch: 20, Final loss (standarized): 0.19561896299903792\n",
      "Epoch: 1, Loss (standarized): 0.7551253321538772\n",
      "Epoch: 2, Loss (standarized): 0.6397721622080988\n",
      "Epoch: 3, Loss (standarized): 0.5656437783552147\n",
      "Epoch: 4, Loss (standarized): 0.5156075292633092\n",
      "Epoch: 5, Loss (standarized): 0.4685369718043632\n",
      "Epoch: 6, Loss (standarized): 0.41605627546169877\n",
      "Epoch: 7, Loss (standarized): 0.36080429083219245\n",
      "Epoch: 8, Loss (standarized): 0.30866975881601905\n",
      "Epoch: 9, Loss (standarized): 0.2647419179063146\n",
      "Epoch: 10, Loss (standarized): 0.23180510694245313\n",
      "Epoch: 11, Loss (standarized): 0.210124002652473\n",
      "Epoch: 12, Loss (standarized): 0.19812782525559933\n",
      "Epoch: 13, Loss (standarized): 0.19349177758608557\n",
      "Epoch: 14, Loss (standarized): 0.19392833162997497\n",
      "Epoch: 15, Loss (standarized): 0.19748869961155052\n",
      "Epoch: 16, Loss (standarized): 0.20260056938018958\n",
      "Epoch: 17, Loss (standarized): 0.2080530778070919\n",
      "Epoch: 18, Loss (standarized): 0.21298576854881762\n",
      "Epoch: 19, Loss (standarized): 0.21686463119811997\n",
      "Epoch: 20, Loss (standarized): 0.21943369612028538\n",
      "Final epoch: 20, Final loss (standarized): 0.21943369612028538\n",
      "Epoch: 1, Loss (standarized): 0.7244290861062048\n",
      "Epoch: 2, Loss (standarized): 0.6381342568960258\n",
      "Epoch: 3, Loss (standarized): 0.5860562469580977\n",
      "Epoch: 4, Loss (standarized): 0.5394858521921908\n",
      "Epoch: 5, Loss (standarized): 0.48806267814481447\n",
      "Epoch: 6, Loss (standarized): 0.4347487195911497\n",
      "Epoch: 7, Loss (standarized): 0.38329687418382025\n",
      "Epoch: 8, Loss (standarized): 0.3360031511006543\n",
      "Epoch: 9, Loss (standarized): 0.29447626597269\n",
      "Epoch: 10, Loss (standarized): 0.25978525815313885\n",
      "Epoch: 11, Loss (standarized): 0.23250103212091955\n",
      "Epoch: 12, Loss (standarized): 0.21275189035659578\n",
      "Epoch: 13, Loss (standarized): 0.20016205992333158\n",
      "Epoch: 14, Loss (standarized): 0.19381526844992272\n",
      "Epoch: 15, Loss (standarized): 0.1923153032281033\n",
      "Epoch: 16, Loss (standarized): 0.1940052439211277\n",
      "Epoch: 17, Loss (standarized): 0.19729378122877766\n",
      "Epoch: 18, Loss (standarized): 0.20091192051542575\n",
      "Epoch: 19, Loss (standarized): 0.20400502015976377\n",
      "Epoch: 20, Loss (standarized): 0.20609962324478498\n",
      "Final epoch: 20, Final loss (standarized): 0.20609962324478498\n",
      "Epoch: 1, Loss (standarized): 0.7033691106377484\n",
      "Epoch: 2, Loss (standarized): 0.6400406386399455\n",
      "Epoch: 3, Loss (standarized): 0.594177934896898\n",
      "Epoch: 4, Loss (standarized): 0.5421793135805203\n",
      "Epoch: 5, Loss (standarized): 0.4840719496688126\n",
      "Epoch: 6, Loss (standarized): 0.42480291002579157\n",
      "Epoch: 7, Loss (standarized): 0.3681492798090612\n",
      "Epoch: 8, Loss (standarized): 0.3165164784163766\n",
      "Epoch: 9, Loss (standarized): 0.27172433386672457\n",
      "Epoch: 10, Loss (standarized): 0.23576626107871995\n",
      "Epoch: 11, Loss (standarized): 0.2105915717184209\n",
      "Epoch: 12, Loss (standarized): 0.19685314329640594\n",
      "Epoch: 13, Loss (standarized): 0.19301461865095532\n",
      "Epoch: 14, Loss (standarized): 0.19595367341810455\n",
      "Epoch: 15, Loss (standarized): 0.2023631142026552\n",
      "Epoch: 16, Loss (standarized): 0.2096525892540882\n",
      "Epoch: 17, Loss (standarized): 0.216146629388658\n",
      "Epoch: 18, Loss (standarized): 0.22095155728057334\n",
      "Epoch: 19, Loss (standarized): 0.22374633632232946\n",
      "Epoch: 20, Loss (standarized): 0.22459605159451765\n",
      "Final epoch: 20, Final loss (standarized): 0.22459605159451765\n",
      "Epoch: 1, Loss (standarized): 0.7336461175558928\n",
      "Epoch: 2, Loss (standarized): 0.6464905700815768\n",
      "Epoch: 3, Loss (standarized): 0.589871042808675\n",
      "Epoch: 4, Loss (standarized): 0.5452726582555555\n",
      "Epoch: 5, Loss (standarized): 0.4958336515573198\n",
      "Epoch: 6, Loss (standarized): 0.43927799421338226\n",
      "Epoch: 7, Loss (standarized): 0.38118204700858405\n",
      "Epoch: 8, Loss (standarized): 0.3276940681125065\n",
      "Epoch: 9, Loss (standarized): 0.2830038955849241\n",
      "Epoch: 10, Loss (standarized): 0.24863389874652264\n",
      "Epoch: 11, Loss (standarized): 0.22405783765750445\n",
      "Epoch: 12, Loss (standarized): 0.20809382593526482\n",
      "Epoch: 13, Loss (standarized): 0.19966946059556998\n",
      "Epoch: 14, Loss (standarized): 0.1975558716476937\n",
      "Epoch: 15, Loss (standarized): 0.20004199322676153\n",
      "Epoch: 16, Loss (standarized): 0.2051242830777572\n",
      "Epoch: 17, Loss (standarized): 0.2109627428020668\n",
      "Epoch: 18, Loss (standarized): 0.21620513244950798\n",
      "Epoch: 19, Loss (standarized): 0.22006084271732854\n",
      "Epoch: 20, Loss (standarized): 0.22221616521440718\n",
      "Final epoch: 20, Final loss (standarized): 0.22221616521440718\n",
      "Epoch: 1, Loss (standarized): 0.7282208379573416\n",
      "Epoch: 2, Loss (standarized): 0.6381862801960229\n",
      "Epoch: 3, Loss (standarized): 0.5769786944484127\n",
      "Epoch: 4, Loss (standarized): 0.5285587241496558\n",
      "Epoch: 5, Loss (standarized): 0.4842878732911976\n",
      "Epoch: 6, Loss (standarized): 0.44168120420620977\n",
      "Epoch: 7, Loss (standarized): 0.40112200727319797\n",
      "Epoch: 8, Loss (standarized): 0.3634025940392074\n",
      "Epoch: 9, Loss (standarized): 0.3293088098755289\n",
      "Epoch: 10, Loss (standarized): 0.29934340709708956\n",
      "Epoch: 11, Loss (standarized): 0.27359453494803404\n",
      "Epoch: 12, Loss (standarized): 0.2521329307589426\n",
      "Epoch: 13, Loss (standarized): 0.23484968454390126\n",
      "Epoch: 14, Loss (standarized): 0.22141019842347814\n",
      "Epoch: 15, Loss (standarized): 0.21139004199562003\n",
      "Epoch: 16, Loss (standarized): 0.2042561516908514\n",
      "Epoch: 17, Loss (standarized): 0.19942705979754166\n",
      "Epoch: 18, Loss (standarized): 0.19626537744832745\n",
      "Epoch: 19, Loss (standarized): 0.19427642235987258\n",
      "Epoch: 20, Loss (standarized): 0.19306523955870755\n",
      "Final epoch: 20, Final loss (standarized): 0.19306523955870755\n",
      "Epoch: 1, Loss (standarized): 0.7200439306270984\n",
      "Epoch: 2, Loss (standarized): 0.6579674561299805\n",
      "Epoch: 3, Loss (standarized): 0.612229599468948\n",
      "Epoch: 4, Loss (standarized): 0.5735141528831916\n",
      "Epoch: 5, Loss (standarized): 0.5377648359744153\n",
      "Epoch: 6, Loss (standarized): 0.5031834674238068\n",
      "Epoch: 7, Loss (standarized): 0.4691313365932552\n",
      "Epoch: 8, Loss (standarized): 0.43556194694262224\n",
      "Epoch: 9, Loss (standarized): 0.40278054893035375\n",
      "Epoch: 10, Loss (standarized): 0.37102116211946934\n",
      "Epoch: 11, Loss (standarized): 0.3409049977820736\n",
      "Epoch: 12, Loss (standarized): 0.31294233112432396\n",
      "Epoch: 13, Loss (standarized): 0.28767164153079844\n",
      "Epoch: 14, Loss (standarized): 0.2654870894378936\n",
      "Epoch: 15, Loss (standarized): 0.24669481505959792\n",
      "Epoch: 16, Loss (standarized): 0.23142540303377843\n",
      "Epoch: 17, Loss (standarized): 0.21961917017431729\n",
      "Epoch: 18, Loss (standarized): 0.21092333517357903\n",
      "Epoch: 19, Loss (standarized): 0.20466910118142811\n",
      "Epoch: 20, Loss (standarized): 0.2004191867071988\n",
      "Final epoch: 20, Final loss (standarized): 0.2004191867071988\n",
      "Epoch: 1, Loss (standarized): 0.6973693156528706\n",
      "Epoch: 2, Loss (standarized): 0.642364319233634\n",
      "Epoch: 3, Loss (standarized): 0.5959242178493769\n",
      "Epoch: 4, Loss (standarized): 0.5540381312300648\n",
      "Epoch: 5, Loss (standarized): 0.514223360528735\n",
      "Epoch: 6, Loss (standarized): 0.475588160156151\n",
      "Epoch: 7, Loss (standarized): 0.43786188895609846\n",
      "Epoch: 8, Loss (standarized): 0.40149199507972355\n",
      "Epoch: 9, Loss (standarized): 0.36693877927881746\n",
      "Epoch: 10, Loss (standarized): 0.33463056188817975\n",
      "Epoch: 11, Loss (standarized): 0.30523722912213314\n",
      "Epoch: 12, Loss (standarized): 0.2791428950707428\n",
      "Epoch: 13, Loss (standarized): 0.2568324624060675\n",
      "Epoch: 14, Loss (standarized): 0.2383585128686071\n",
      "Epoch: 15, Loss (standarized): 0.22361885714097807\n",
      "Epoch: 16, Loss (standarized): 0.21242062032531833\n",
      "Epoch: 17, Loss (standarized): 0.2044003862549709\n",
      "Epoch: 18, Loss (standarized): 0.19895336309264594\n",
      "Epoch: 19, Loss (standarized): 0.19551503795489922\n",
      "Epoch: 20, Loss (standarized): 0.19349912167406402\n",
      "Final epoch: 20, Final loss (standarized): 0.19349912167406402\n",
      "Epoch: 1, Loss (standarized): 0.7262047423857215\n",
      "Epoch: 2, Loss (standarized): 0.6392977025614284\n",
      "Epoch: 3, Loss (standarized): 0.5791446859457878\n",
      "Epoch: 4, Loss (standarized): 0.5316973324263244\n",
      "Epoch: 5, Loss (standarized): 0.4881860460344972\n",
      "Epoch: 6, Loss (standarized): 0.4456699509286252\n",
      "Epoch: 7, Loss (standarized): 0.40414314609288526\n",
      "Epoch: 8, Loss (standarized): 0.36460610401243365\n",
      "Epoch: 9, Loss (standarized): 0.3283155336168457\n",
      "Epoch: 10, Loss (standarized): 0.2962895033458501\n",
      "Epoch: 11, Loss (standarized): 0.2691357110067851\n",
      "Epoch: 12, Loss (standarized): 0.24697860348725348\n",
      "Epoch: 13, Loss (standarized): 0.2296211244041412\n",
      "Epoch: 14, Loss (standarized): 0.2165908169983056\n",
      "Epoch: 15, Loss (standarized): 0.2071863622856777\n",
      "Epoch: 16, Loss (standarized): 0.2007745524883497\n",
      "Epoch: 17, Loss (standarized): 0.19658456547732667\n",
      "Epoch: 18, Loss (standarized): 0.19401626718629952\n",
      "Epoch: 19, Loss (standarized): 0.19255075431941393\n",
      "Epoch: 20, Loss (standarized): 0.19176106657787897\n",
      "Final epoch: 20, Final loss (standarized): 0.19176106657787897\n",
      "Epoch: 1, Loss (standarized): 0.7781348879594228\n",
      "Epoch: 2, Loss (standarized): 0.6701199619168607\n",
      "Epoch: 3, Loss (standarized): 0.5987910129941272\n",
      "Epoch: 4, Loss (standarized): 0.548661348890147\n",
      "Epoch: 5, Loss (standarized): 0.5078694721690723\n",
      "Epoch: 6, Loss (standarized): 0.4692767902339359\n",
      "Epoch: 7, Loss (standarized): 0.4288172180983715\n",
      "Epoch: 8, Loss (standarized): 0.38585101448658715\n",
      "Epoch: 9, Loss (standarized): 0.342722966994829\n",
      "Epoch: 10, Loss (standarized): 0.3026836956943421\n",
      "Epoch: 11, Loss (standarized): 0.26838334915308654\n",
      "Epoch: 12, Loss (standarized): 0.24119097699003206\n",
      "Epoch: 13, Loss (standarized): 0.22119676756303755\n",
      "Epoch: 14, Loss (standarized): 0.20764341761522748\n",
      "Epoch: 15, Loss (standarized): 0.19942176645008972\n",
      "Epoch: 16, Loss (standarized): 0.19537854376733702\n",
      "Epoch: 17, Loss (standarized): 0.19442588217125126\n",
      "Epoch: 18, Loss (standarized): 0.19557843506232023\n",
      "Epoch: 19, Loss (standarized): 0.1979741422871255\n",
      "Epoch: 20, Loss (standarized): 0.20089751987065171\n",
      "Final epoch: 20, Final loss (standarized): 0.20089751987065171\n",
      "Epoch: 1, Loss (standarized): 0.7129984070841783\n",
      "Epoch: 2, Loss (standarized): 0.6394554064936587\n",
      "Epoch: 3, Loss (standarized): 0.591410962388167\n",
      "Epoch: 4, Loss (standarized): 0.5397080976469321\n",
      "Epoch: 5, Loss (standarized): 0.4848852209160828\n",
      "Epoch: 6, Loss (standarized): 0.43217045858347525\n",
      "Epoch: 7, Loss (standarized): 0.38350121553611644\n",
      "Epoch: 8, Loss (standarized): 0.33856588077029426\n",
      "Epoch: 9, Loss (standarized): 0.2974383359501004\n",
      "Epoch: 10, Loss (standarized): 0.26153998985432825\n",
      "Epoch: 11, Loss (standarized): 0.2327721508626221\n",
      "Epoch: 12, Loss (standarized): 0.21227718984627159\n",
      "Epoch: 13, Loss (standarized): 0.19980183164792337\n",
      "Epoch: 14, Loss (standarized): 0.19389247907548773\n",
      "Epoch: 15, Loss (standarized): 0.19254904597147326\n",
      "Epoch: 16, Loss (standarized): 0.1938428518773519\n",
      "Epoch: 17, Loss (standarized): 0.19624282097199772\n",
      "Epoch: 18, Loss (standarized): 0.1986921667207842\n",
      "Epoch: 19, Loss (standarized): 0.20056377109909623\n",
      "Epoch: 20, Loss (standarized): 0.20156698568295492\n",
      "Final epoch: 20, Final loss (standarized): 0.20156698568295492\n",
      "Epoch: 1, Loss (standarized): 0.765978540904574\n",
      "Epoch: 2, Loss (standarized): 0.6330414993847087\n",
      "Epoch: 3, Loss (standarized): 0.5571456712653879\n",
      "Epoch: 4, Loss (standarized): 0.5081259278265254\n",
      "Epoch: 5, Loss (standarized): 0.4584402160812249\n",
      "Epoch: 6, Loss (standarized): 0.40303733791436774\n",
      "Epoch: 7, Loss (standarized): 0.34792610077984915\n",
      "Epoch: 8, Loss (standarized): 0.2993651359204249\n",
      "Epoch: 9, Loss (standarized): 0.2607906139670333\n",
      "Epoch: 10, Loss (standarized): 0.2328244175776274\n",
      "Epoch: 11, Loss (standarized): 0.2142628271070293\n",
      "Epoch: 12, Loss (standarized): 0.20318723712392198\n",
      "Epoch: 13, Loss (standarized): 0.197725055513186\n",
      "Epoch: 14, Loss (standarized): 0.1963024312560556\n",
      "Epoch: 15, Loss (standarized): 0.19760091639138527\n",
      "Epoch: 16, Loss (standarized): 0.20048970698648175\n",
      "Epoch: 17, Loss (standarized): 0.20402025303760576\n",
      "Epoch: 18, Loss (standarized): 0.20745527999987423\n",
      "Epoch: 19, Loss (standarized): 0.21028767013490393\n",
      "Epoch: 20, Loss (standarized): 0.21222526036385375\n",
      "Final epoch: 20, Final loss (standarized): 0.21222526036385375\n",
      "Epoch: 1, Loss (standarized): 0.7094905624333833\n",
      "Epoch: 2, Loss (standarized): 0.6457307881502906\n",
      "Epoch: 3, Loss (standarized): 0.5982823416038909\n",
      "Epoch: 4, Loss (standarized): 0.5512699250431089\n",
      "Epoch: 5, Loss (standarized): 0.5024450053025974\n",
      "Epoch: 6, Loss (standarized): 0.45177067511559166\n",
      "Epoch: 7, Loss (standarized): 0.400910205584571\n",
      "Epoch: 8, Loss (standarized): 0.3524463367187188\n",
      "Epoch: 9, Loss (standarized): 0.308892798089272\n",
      "Epoch: 10, Loss (standarized): 0.2718724131685977\n",
      "Epoch: 11, Loss (standarized): 0.24204546872515872\n",
      "Epoch: 12, Loss (standarized): 0.2197050821538521\n",
      "Epoch: 13, Loss (standarized): 0.20491778376406028\n",
      "Epoch: 14, Loss (standarized): 0.19716434892024706\n",
      "Epoch: 15, Loss (standarized): 0.19514313431033495\n",
      "Epoch: 16, Loss (standarized): 0.19702118683697678\n",
      "Epoch: 17, Loss (standarized): 0.20093370148648457\n",
      "Epoch: 18, Loss (standarized): 0.20538262071339833\n",
      "Epoch: 19, Loss (standarized): 0.2093684600132406\n",
      "Epoch: 20, Loss (standarized): 0.21234088302950693\n",
      "Final epoch: 20, Final loss (standarized): 0.21234088302950693\n",
      "Epoch: 1, Loss (standarized): 0.7263748039623645\n",
      "Epoch: 2, Loss (standarized): 0.6492508831584738\n",
      "Epoch: 3, Loss (standarized): 0.6013036971182845\n",
      "Epoch: 4, Loss (standarized): 0.5616322476394716\n",
      "Epoch: 5, Loss (standarized): 0.5166077580967424\n",
      "Epoch: 6, Loss (standarized): 0.46590356889646467\n",
      "Epoch: 7, Loss (standarized): 0.41392853306181676\n",
      "Epoch: 8, Loss (standarized): 0.36487852862253894\n",
      "Epoch: 9, Loss (standarized): 0.3212682257456179\n",
      "Epoch: 10, Loss (standarized): 0.28405471240229807\n",
      "Epoch: 11, Loss (standarized): 0.25341592380645805\n",
      "Epoch: 12, Loss (standarized): 0.22944414507277028\n",
      "Epoch: 13, Loss (standarized): 0.2122584333913795\n",
      "Epoch: 14, Loss (standarized): 0.20164237985586095\n",
      "Epoch: 15, Loss (standarized): 0.19678667048098808\n",
      "Epoch: 16, Loss (standarized): 0.19638454520877136\n",
      "Epoch: 17, Loss (standarized): 0.19891922162988984\n",
      "Epoch: 18, Loss (standarized): 0.20295557095008052\n",
      "Epoch: 19, Loss (standarized): 0.20734149605395266\n",
      "Epoch: 20, Loss (standarized): 0.21128331010227164\n",
      "Final epoch: 20, Final loss (standarized): 0.21128331010227164\n",
      "Epoch: 1, Loss (standarized): 0.7003097767836174\n",
      "Epoch: 2, Loss (standarized): 0.6531734977371718\n",
      "Epoch: 3, Loss (standarized): 0.615224366593817\n",
      "Epoch: 4, Loss (standarized): 0.5718767040226281\n",
      "Epoch: 5, Loss (standarized): 0.5256969691657399\n",
      "Epoch: 6, Loss (standarized): 0.478814332433163\n",
      "Epoch: 7, Loss (standarized): 0.4312735812252855\n",
      "Epoch: 8, Loss (standarized): 0.3833335926985657\n",
      "Epoch: 9, Loss (standarized): 0.3365715620474539\n",
      "Epoch: 10, Loss (standarized): 0.29354962168632004\n",
      "Epoch: 11, Loss (standarized): 0.2569396944169573\n",
      "Epoch: 12, Loss (standarized): 0.22862271602240075\n",
      "Epoch: 13, Loss (standarized): 0.20918329082295462\n",
      "Epoch: 14, Loss (standarized): 0.19798386682910152\n",
      "Epoch: 15, Loss (standarized): 0.19351270658037237\n",
      "Epoch: 16, Loss (standarized): 0.19376947475740872\n",
      "Epoch: 17, Loss (standarized): 0.19670413167671558\n",
      "Epoch: 18, Loss (standarized): 0.20059762742374984\n",
      "Epoch: 19, Loss (standarized): 0.20424621101371757\n",
      "Epoch: 20, Loss (standarized): 0.20695610533892655\n",
      "Final epoch: 20, Final loss (standarized): 0.20695610533892655\n",
      "Epoch: 1, Loss (standarized): 0.7969357299994644\n",
      "Epoch: 2, Loss (standarized): 0.6533833404881741\n",
      "Epoch: 3, Loss (standarized): 0.5677668471559781\n",
      "Epoch: 4, Loss (standarized): 0.5223965322090428\n",
      "Epoch: 5, Loss (standarized): 0.4825878245546408\n",
      "Epoch: 6, Loss (standarized): 0.43271025087602893\n",
      "Epoch: 7, Loss (standarized): 0.377289189015799\n",
      "Epoch: 8, Loss (standarized): 0.3244925082547004\n",
      "Epoch: 9, Loss (standarized): 0.2800571001035805\n",
      "Epoch: 10, Loss (standarized): 0.24639127886232354\n",
      "Epoch: 11, Loss (standarized): 0.22318311785355552\n",
      "Epoch: 12, Loss (standarized): 0.2086745964759386\n",
      "Epoch: 13, Loss (standarized): 0.20081302548050767\n",
      "Epoch: 14, Loss (standarized): 0.19781131509323155\n",
      "Epoch: 15, Loss (standarized): 0.1982158297913922\n",
      "Epoch: 16, Loss (standarized): 0.20080871803176878\n",
      "Epoch: 17, Loss (standarized): 0.2045425978613903\n",
      "Epoch: 18, Loss (standarized): 0.20854445366033716\n",
      "Epoch: 19, Loss (standarized): 0.2121487290188545\n",
      "Epoch: 20, Loss (standarized): 0.21491562673839965\n",
      "Final epoch: 20, Final loss (standarized): 0.21491562673839965\n",
      "Epoch: 1, Loss (standarized): 0.7121958842329787\n",
      "Epoch: 2, Loss (standarized): 0.642680090482466\n",
      "Epoch: 3, Loss (standarized): 0.5876083600116505\n",
      "Epoch: 4, Loss (standarized): 0.5403517655074986\n",
      "Epoch: 5, Loss (standarized): 0.48944287201912284\n",
      "Epoch: 6, Loss (standarized): 0.4346405467566415\n",
      "Epoch: 7, Loss (standarized): 0.3799670148298845\n",
      "Epoch: 8, Loss (standarized): 0.3288357459063178\n",
      "Epoch: 9, Loss (standarized): 0.2839655431035347\n",
      "Epoch: 10, Loss (standarized): 0.24762258282521743\n",
      "Epoch: 11, Loss (standarized): 0.2210086312502423\n",
      "Epoch: 12, Loss (standarized): 0.20397522312516178\n",
      "Epoch: 13, Loss (standarized): 0.1954566787825777\n",
      "Epoch: 14, Loss (standarized): 0.19386153392912317\n",
      "Epoch: 15, Loss (standarized): 0.19717441888153103\n",
      "Epoch: 16, Loss (standarized): 0.2031762791497258\n",
      "Epoch: 17, Loss (standarized): 0.20986686752829944\n",
      "Epoch: 18, Loss (standarized): 0.21579541179559453\n",
      "Epoch: 19, Loss (standarized): 0.22013394619732143\n",
      "Epoch: 20, Loss (standarized): 0.22257412418333833\n",
      "Final epoch: 20, Final loss (standarized): 0.22257412418333833\n",
      "Epoch: 1, Loss (standarized): 0.7740002230517952\n",
      "          Validation Loss (standardized): 0.7377751914461248\n",
      "Epoch: 2, Loss (standarized): 0.6816819132600517\n",
      "          Validation Loss (standardized): 0.7170716452491162\n",
      "Epoch: 3, Loss (standarized): 0.6183908163040013\n",
      "          Validation Loss (standardized): 0.711072799046866\n",
      "Epoch: 4, Loss (standarized): 0.5710367863758479\n",
      "          Validation Loss (standardized): 0.7112786136288015\n",
      "Epoch: 5, Loss (standarized): 0.5269607803884946\n",
      "          Validation Loss (standardized): 0.7170103955990044\n",
      "Epoch: 6, Loss (standarized): 0.4829132344188182\n",
      "          Validation Loss (standardized): 0.7307657022183821\n",
      "Epoch: 7, Loss (standarized): 0.4394118458981482\n",
      "          Validation Loss (standardized): 0.7548863557864058\n",
      "Epoch: 8, Loss (standarized): 0.3965911816447101\n",
      "          Validation Loss (standardized): 0.791355580570139\n",
      "Epoch: 9, Loss (standarized): 0.3541689038646193\n",
      "          Validation Loss (standardized): 0.8421690862073788\n",
      "Epoch: 10, Loss (standarized): 0.312733619027696\n",
      "          Validation Loss (standardized): 0.9096138064120235\n",
      "Epoch: 11, Loss (standarized): 0.2743300570972721\n",
      "          Validation Loss (standardized): 0.995631743139402\n",
      "Epoch: 12, Loss (standarized): 0.24173359422649116\n",
      "          Validation Loss (standardized): 1.100472319917379\n",
      "Epoch: 13, Loss (standarized): 0.21731479734164982\n",
      "          Validation Loss (standardized): 1.2215023505123406\n",
      "Epoch: 14, Loss (standarized): 0.20199983850094322\n",
      "          Validation Loss (standardized): 1.353088096771562\n",
      "Epoch: 15, Loss (standarized): 0.19496073520425938\n",
      "          Validation Loss (standardized): 1.487760186146552\n",
      "Epoch: 16, Loss (standarized): 0.19420047988033598\n",
      "          Validation Loss (standardized): 1.6178674296980688\n",
      "Epoch: 17, Loss (standarized): 0.1974363821283888\n",
      "          Validation Loss (standardized): 1.7368477751077125\n",
      "Epoch: 18, Loss (standarized): 0.20269004149251976\n",
      "          Validation Loss (standardized): 1.8398527467681425\n",
      "Epoch: 19, Loss (standarized): 0.20849218494339594\n",
      "          Validation Loss (standardized): 1.9238638517691475\n",
      "Epoch: 20, Loss (standarized): 0.21386748716157333\n",
      "          Validation Loss (standardized): 1.9875096565705588\n",
      "Final epoch: 20, Final loss (standarized): 0.21386748716157333\n",
      "Epoch: 1, Loss (standarized): 0.7553146417490353\n",
      "          Validation Loss (standardized): 0.7087074624188051\n",
      "Epoch: 2, Loss (standarized): 0.6494904591209366\n",
      "          Validation Loss (standardized): 0.6949575768929313\n",
      "Epoch: 3, Loss (standarized): 0.5776713419675654\n",
      "          Validation Loss (standardized): 0.7027620460122734\n",
      "Epoch: 4, Loss (standarized): 0.5277891183337687\n",
      "          Validation Loss (standardized): 0.7214781116168126\n",
      "Epoch: 5, Loss (standarized): 0.48442850813435334\n",
      "          Validation Loss (standardized): 0.7447540163688854\n",
      "Epoch: 6, Loss (standarized): 0.43819051833735123\n",
      "          Validation Loss (standardized): 0.7730548308794176\n",
      "Epoch: 7, Loss (standarized): 0.3886578635593138\n",
      "          Validation Loss (standardized): 0.8102179476232003\n",
      "Epoch: 8, Loss (standarized): 0.33982209476913144\n",
      "          Validation Loss (standardized): 0.860008409887017\n",
      "Epoch: 9, Loss (standarized): 0.2959364818171626\n",
      "          Validation Loss (standardized): 0.9245498151223717\n",
      "Epoch: 10, Loss (standarized): 0.2598168461656035\n",
      "          Validation Loss (standardized): 1.0038157866268955\n",
      "Epoch: 11, Loss (standarized): 0.23251208475971868\n",
      "          Validation Loss (standardized): 1.0956974698325967\n",
      "Epoch: 12, Loss (standarized): 0.21362009102774987\n",
      "          Validation Loss (standardized): 1.1964499072963743\n",
      "Epoch: 13, Loss (standarized): 0.2018686128411404\n",
      "          Validation Loss (standardized): 1.3013010327513934\n",
      "Epoch: 14, Loss (standarized): 0.19568244674434163\n",
      "          Validation Loss (standardized): 1.405057376299308\n",
      "Epoch: 15, Loss (standarized): 0.19353233972452133\n",
      "          Validation Loss (standardized): 1.5026755319030456\n",
      "Epoch: 16, Loss (standarized): 0.19406212077299625\n",
      "          Validation Loss (standardized): 1.589791581255684\n",
      "Epoch: 17, Loss (standarized): 0.19612009256446125\n",
      "          Validation Loss (standardized): 1.663124415749693\n",
      "Epoch: 18, Loss (standarized): 0.19878064015591926\n",
      "          Validation Loss (standardized): 1.7206511916519687\n",
      "Epoch: 19, Loss (standarized): 0.2013608543878601\n",
      "          Validation Loss (standardized): 1.7615562748762037\n",
      "Epoch: 20, Loss (standarized): 0.20341470484359286\n",
      "          Validation Loss (standardized): 1.786037966229465\n",
      "Final epoch: 20, Final loss (standarized): 0.20341470484359286\n",
      "Epoch: 1, Loss (standarized): 0.7078614842402698\n",
      "          Validation Loss (standardized): 0.6894106123739759\n",
      "Epoch: 2, Loss (standarized): 0.6417624229529767\n",
      "          Validation Loss (standardized): 0.696429892757013\n",
      "Epoch: 3, Loss (standarized): 0.5961355787781724\n",
      "          Validation Loss (standardized): 0.7042121523599643\n",
      "Epoch: 4, Loss (standarized): 0.5476210995109851\n",
      "          Validation Loss (standardized): 0.7125224397044143\n",
      "Epoch: 5, Loss (standarized): 0.49295224093266693\n",
      "          Validation Loss (standardized): 0.7273540122995388\n",
      "Epoch: 6, Loss (standarized): 0.436571644911801\n",
      "          Validation Loss (standardized): 0.7542509584510269\n",
      "Epoch: 7, Loss (standarized): 0.38227792553925927\n",
      "          Validation Loss (standardized): 0.7975070824162702\n",
      "Epoch: 8, Loss (standarized): 0.3324688513167475\n",
      "          Validation Loss (standardized): 0.8600367605459595\n",
      "Epoch: 9, Loss (standarized): 0.2885621849945728\n",
      "          Validation Loss (standardized): 0.9436273927242158\n",
      "Epoch: 10, Loss (standarized): 0.2516996819426261\n",
      "          Validation Loss (standardized): 1.0489394255047286\n",
      "Epoch: 11, Loss (standarized): 0.22321327461911994\n",
      "          Validation Loss (standardized): 1.1746027922047895\n",
      "Epoch: 12, Loss (standarized): 0.20418239453310244\n",
      "          Validation Loss (standardized): 1.3160050704917088\n",
      "Epoch: 13, Loss (standarized): 0.19454764286985876\n",
      "          Validation Loss (standardized): 1.464976704330237\n",
      "Epoch: 14, Loss (standarized): 0.19273983758399812\n",
      "          Validation Loss (standardized): 1.6111027030382954\n",
      "Epoch: 15, Loss (standarized): 0.1961616573372572\n",
      "          Validation Loss (standardized): 1.7442381453468574\n",
      "Epoch: 16, Loss (standarized): 0.20212124575492674\n",
      "          Validation Loss (standardized): 1.8567333615217052\n",
      "Epoch: 17, Loss (standarized): 0.20853747035381398\n",
      "          Validation Loss (standardized): 1.9443228491802522\n",
      "Epoch: 18, Loss (standarized): 0.21414764274442624\n",
      "          Validation Loss (standardized): 2.005869143708067\n",
      "Epoch: 19, Loss (standarized): 0.2183804432691799\n",
      "          Validation Loss (standardized): 2.042607940534931\n",
      "Epoch: 20, Loss (standarized): 0.22110678911627996\n",
      "          Validation Loss (standardized): 2.057285806137728\n",
      "Final epoch: 20, Final loss (standarized): 0.22110678911627996\n",
      "Epoch: 1, Loss (standarized): 0.6970429935077854\n",
      "          Validation Loss (standardized): 0.6897180294839231\n",
      "Epoch: 2, Loss (standarized): 0.6411370018142939\n",
      "          Validation Loss (standardized): 0.6899465928145577\n",
      "Epoch: 3, Loss (standarized): 0.5848488048734833\n",
      "          Validation Loss (standardized): 0.6961783373745004\n",
      "Epoch: 4, Loss (standarized): 0.5242349471480622\n",
      "          Validation Loss (standardized): 0.7120898755972275\n",
      "Epoch: 5, Loss (standarized): 0.46259007584657313\n",
      "          Validation Loss (standardized): 0.7413642372766793\n",
      "Epoch: 6, Loss (standarized): 0.4015196951266489\n",
      "          Validation Loss (standardized): 0.7878412939618333\n",
      "Epoch: 7, Loss (standarized): 0.3432132155263695\n",
      "          Validation Loss (standardized): 0.8557659106166463\n",
      "Epoch: 8, Loss (standarized): 0.29093858949363205\n",
      "          Validation Loss (standardized): 0.9489285545975753\n",
      "Epoch: 9, Loss (standarized): 0.2483060345159069\n",
      "          Validation Loss (standardized): 1.0687691631398795\n",
      "Epoch: 10, Loss (standarized): 0.2179121570664824\n",
      "          Validation Loss (standardized): 1.212571858542157\n",
      "Epoch: 11, Loss (standarized): 0.200300715226756\n",
      "          Validation Loss (standardized): 1.3727583591785986\n",
      "Epoch: 12, Loss (standarized): 0.1937835848668427\n",
      "          Validation Loss (standardized): 1.5380571451901335\n",
      "Epoch: 13, Loss (standarized): 0.19523650266169257\n",
      "          Validation Loss (standardized): 1.6961315803713257\n",
      "Epoch: 14, Loss (standarized): 0.2012306949041392\n",
      "          Validation Loss (standardized): 1.83624043460802\n",
      "Epoch: 15, Loss (standarized): 0.20885063853573266\n",
      "          Validation Loss (standardized): 1.9509073251495834\n",
      "Epoch: 16, Loss (standarized): 0.21606473636438073\n",
      "          Validation Loss (standardized): 2.0363407657389283\n",
      "Epoch: 17, Loss (standarized): 0.22174285892559945\n",
      "          Validation Loss (standardized): 2.0919770955073544\n",
      "Epoch: 18, Loss (standarized): 0.22548794345377998\n",
      "          Validation Loss (standardized): 2.119689196605258\n",
      "Epoch: 19, Loss (standarized): 0.22740932061356506\n",
      "          Validation Loss (standardized): 2.1229987610086694\n",
      "Epoch: 20, Loss (standarized): 0.22786786620885993\n",
      "          Validation Loss (standardized): 2.10633855715972\n",
      "Final epoch: 20, Final loss (standarized): 0.22786786620885993\n",
      "Epoch: 1, Loss (standarized): 0.7581627236798786\n",
      "          Validation Loss (standardized): 0.7081088358267594\n",
      "Epoch: 2, Loss (standarized): 0.6572151512300274\n",
      "          Validation Loss (standardized): 0.6939851188479673\n",
      "Epoch: 3, Loss (standarized): 0.5905935824312538\n",
      "          Validation Loss (standardized): 0.6946367025451744\n",
      "Epoch: 4, Loss (standarized): 0.5417421592027919\n",
      "          Validation Loss (standardized): 0.7025225536067496\n",
      "Epoch: 5, Loss (standarized): 0.5002403070340974\n",
      "          Validation Loss (standardized): 0.7145172150182278\n",
      "Epoch: 6, Loss (standarized): 0.46106132971592595\n",
      "          Validation Loss (standardized): 0.7302239786501232\n",
      "Epoch: 7, Loss (standarized): 0.42306693650115584\n",
      "          Validation Loss (standardized): 0.7503834737464748\n",
      "Epoch: 8, Loss (standarized): 0.3862774002698707\n",
      "          Validation Loss (standardized): 0.7759027298188207\n",
      "Epoch: 9, Loss (standarized): 0.35156777859720995\n",
      "          Validation Loss (standardized): 0.8075578919311274\n",
      "Epoch: 10, Loss (standarized): 0.3197407949099114\n",
      "          Validation Loss (standardized): 0.8456092358171245\n",
      "Epoch: 11, Loss (standarized): 0.29146662739358886\n",
      "          Validation Loss (standardized): 0.8899330239048677\n",
      "Epoch: 12, Loss (standarized): 0.2671825170107388\n",
      "          Validation Loss (standardized): 0.9398465279747491\n",
      "Epoch: 13, Loss (standarized): 0.24700561938579746\n",
      "          Validation Loss (standardized): 0.9942115888504679\n",
      "Epoch: 14, Loss (standarized): 0.23079661515936367\n",
      "          Validation Loss (standardized): 1.0509893223853914\n",
      "Epoch: 15, Loss (standarized): 0.21835190584564804\n",
      "          Validation Loss (standardized): 1.108452759019427\n",
      "Epoch: 16, Loss (standarized): 0.2091061430617462\n",
      "          Validation Loss (standardized): 1.1641469972023157\n",
      "Epoch: 17, Loss (standarized): 0.2025606162943249\n",
      "          Validation Loss (standardized): 1.2160391949100882\n",
      "Epoch: 18, Loss (standarized): 0.19817957782074744\n",
      "          Validation Loss (standardized): 1.2623987793444036\n",
      "Epoch: 19, Loss (standarized): 0.1954166735068745\n",
      "          Validation Loss (standardized): 1.3017483991985872\n",
      "Epoch: 20, Loss (standarized): 0.1937805944616966\n",
      "          Validation Loss (standardized): 1.3330655584643534\n",
      "Final epoch: 20, Final loss (standarized): 0.1937805944616966\n",
      "Epoch: 1, Loss (standarized): 0.6967002997538676\n",
      "          Validation Loss (standardized): 0.688671973296549\n",
      "Epoch: 2, Loss (standarized): 0.6380344932203226\n",
      "          Validation Loss (standardized): 0.6888321899230754\n",
      "Epoch: 3, Loss (standarized): 0.5876464282881229\n",
      "          Validation Loss (standardized): 0.6927259586344604\n",
      "Epoch: 4, Loss (standarized): 0.5416574987163715\n",
      "          Validation Loss (standardized): 0.7003719986481833\n",
      "Epoch: 5, Loss (standarized): 0.4983057471917467\n",
      "          Validation Loss (standardized): 0.7122646944221533\n",
      "Epoch: 6, Loss (standarized): 0.4570467553620138\n",
      "          Validation Loss (standardized): 0.7289825595945953\n",
      "Epoch: 7, Loss (standarized): 0.41779561847458135\n",
      "          Validation Loss (standardized): 0.7512425585686303\n",
      "Epoch: 8, Loss (standarized): 0.38058885546086896\n",
      "          Validation Loss (standardized): 0.779604281442502\n",
      "Epoch: 9, Loss (standarized): 0.3459376367546701\n",
      "          Validation Loss (standardized): 0.8143662970616848\n",
      "Epoch: 10, Loss (standarized): 0.314478446803336\n",
      "          Validation Loss (standardized): 0.8555727581364876\n",
      "Epoch: 11, Loss (standarized): 0.2865977028098675\n",
      "          Validation Loss (standardized): 0.9025439462955192\n",
      "Epoch: 12, Loss (standarized): 0.26278569646641514\n",
      "          Validation Loss (standardized): 0.9544258691850248\n",
      "Epoch: 13, Loss (standarized): 0.24312505164673073\n",
      "          Validation Loss (standardized): 1.0089520702848582\n",
      "Epoch: 14, Loss (standarized): 0.22766485808073286\n",
      "          Validation Loss (standardized): 1.0633396250107585\n",
      "Epoch: 15, Loss (standarized): 0.21612064670767056\n",
      "          Validation Loss (standardized): 1.1147842579080267\n",
      "Epoch: 16, Loss (standarized): 0.2079297371744863\n",
      "          Validation Loss (standardized): 1.1612608640169517\n",
      "Epoch: 17, Loss (standarized): 0.2023250342655227\n",
      "          Validation Loss (standardized): 1.2005640742465176\n",
      "Epoch: 18, Loss (standarized): 0.19866615064150844\n",
      "          Validation Loss (standardized): 1.232201143188454\n",
      "Epoch: 19, Loss (standarized): 0.19634612234687143\n",
      "          Validation Loss (standardized): 1.2551003416138786\n",
      "Epoch: 20, Loss (standarized): 0.1949729849407118\n",
      "          Validation Loss (standardized): 1.2694366254780556\n",
      "Final epoch: 20, Final loss (standarized): 0.1949729849407118\n",
      "Epoch: 1, Loss (standarized): 0.7532828897238186\n",
      "          Validation Loss (standardized): 0.7074710294532952\n",
      "Epoch: 2, Loss (standarized): 0.6475859738900196\n",
      "          Validation Loss (standardized): 0.6904296219192122\n",
      "Epoch: 3, Loss (standarized): 0.579697745022308\n",
      "          Validation Loss (standardized): 0.6941262112322312\n",
      "Epoch: 4, Loss (standarized): 0.5325163755477843\n",
      "          Validation Loss (standardized): 0.7058155595128174\n",
      "Epoch: 5, Loss (standarized): 0.49064827108087855\n",
      "          Validation Loss (standardized): 0.721373844076788\n",
      "Epoch: 6, Loss (standarized): 0.44872983915004905\n",
      "          Validation Loss (standardized): 0.7412227077017092\n",
      "Epoch: 7, Loss (standarized): 0.4070598881810441\n",
      "          Validation Loss (standardized): 0.7667453424973562\n",
      "Epoch: 8, Loss (standarized): 0.36733347608269384\n",
      "          Validation Loss (standardized): 0.799131234051398\n",
      "Epoch: 9, Loss (standarized): 0.33128160904350085\n",
      "          Validation Loss (standardized): 0.8387717285992394\n",
      "Epoch: 10, Loss (standarized): 0.2998769264137098\n",
      "          Validation Loss (standardized): 0.8851569337018845\n",
      "Epoch: 11, Loss (standarized): 0.2734380910468254\n",
      "          Validation Loss (standardized): 0.9372035202477198\n",
      "Epoch: 12, Loss (standarized): 0.25176380348495814\n",
      "          Validation Loss (standardized): 0.993408758657235\n",
      "Epoch: 13, Loss (standarized): 0.23451169917549017\n",
      "          Validation Loss (standardized): 1.051887071257182\n",
      "Epoch: 14, Loss (standarized): 0.22120561978837422\n",
      "          Validation Loss (standardized): 1.110528887514366\n",
      "Epoch: 15, Loss (standarized): 0.21132834852232538\n",
      "          Validation Loss (standardized): 1.1671992715653503\n",
      "Epoch: 16, Loss (standarized): 0.20429139134387328\n",
      "          Validation Loss (standardized): 1.2199738485201834\n",
      "Epoch: 17, Loss (standarized): 0.19948708733778248\n",
      "          Validation Loss (standardized): 1.2668549853646978\n",
      "Epoch: 18, Loss (standarized): 0.19639807287725683\n",
      "          Validation Loss (standardized): 1.3064936417532953\n",
      "Epoch: 19, Loss (standarized): 0.1945131431584898\n",
      "          Validation Loss (standardized): 1.3384917625496557\n",
      "Epoch: 20, Loss (standarized): 0.19341433531380045\n",
      "          Validation Loss (standardized): 1.362780206121589\n",
      "Final epoch: 20, Final loss (standarized): 0.19341433531380045\n",
      "Epoch: 1, Loss (standarized): 0.7785221792678743\n",
      "          Validation Loss (standardized): 0.7073568082560793\n",
      "Epoch: 2, Loss (standarized): 0.6592789482797644\n",
      "          Validation Loss (standardized): 0.6915959668737333\n",
      "Epoch: 3, Loss (standarized): 0.5780703184724333\n",
      "          Validation Loss (standardized): 0.6988557525443353\n",
      "Epoch: 4, Loss (standarized): 0.5234096594501998\n",
      "          Validation Loss (standardized): 0.7167443132013301\n",
      "Epoch: 5, Loss (standarized): 0.4808662226716081\n",
      "          Validation Loss (standardized): 0.7380095885150891\n",
      "Epoch: 6, Loss (standarized): 0.44158641382636343\n",
      "          Validation Loss (standardized): 0.7608739000229469\n",
      "Epoch: 7, Loss (standarized): 0.4030029180043488\n",
      "          Validation Loss (standardized): 0.7861485639858011\n",
      "Epoch: 8, Loss (standarized): 0.3656299607480775\n",
      "          Validation Loss (standardized): 0.8152920911737438\n",
      "Epoch: 9, Loss (standarized): 0.3309576538118135\n",
      "          Validation Loss (standardized): 0.8492080883045682\n",
      "Epoch: 10, Loss (standarized): 0.30032721867336815\n",
      "          Validation Loss (standardized): 0.8882981594197841\n",
      "Epoch: 11, Loss (standarized): 0.274380173980395\n",
      "          Validation Loss (standardized): 0.931979901032708\n",
      "Epoch: 12, Loss (standarized): 0.25322040384791716\n",
      "          Validation Loss (standardized): 0.9794174242530183\n",
      "Epoch: 13, Loss (standarized): 0.23646702618280968\n",
      "          Validation Loss (standardized): 1.0289754410102205\n",
      "Epoch: 14, Loss (standarized): 0.22361176893480705\n",
      "          Validation Loss (standardized): 1.079224135666359\n",
      "Epoch: 15, Loss (standarized): 0.21396256421017862\n",
      "          Validation Loss (standardized): 1.1284763727535057\n",
      "Epoch: 16, Loss (standarized): 0.20692690544507747\n",
      "          Validation Loss (standardized): 1.1752299016227534\n",
      "Epoch: 17, Loss (standarized): 0.20195633725887097\n",
      "          Validation Loss (standardized): 1.2184578833285844\n",
      "Epoch: 18, Loss (standarized): 0.19853003127129867\n",
      "          Validation Loss (standardized): 1.2569849666274056\n",
      "Epoch: 19, Loss (standarized): 0.19625113605004635\n",
      "          Validation Loss (standardized): 1.2897137101900933\n",
      "Epoch: 20, Loss (standarized): 0.19478975287044695\n",
      "          Validation Loss (standardized): 1.3165112085337205\n",
      "Final epoch: 20, Final loss (standarized): 0.19478975287044695\n",
      "Epoch: 1, Loss (standarized): 0.7323795256326135\n",
      "          Validation Loss (standardized): 0.700846468117631\n",
      "Epoch: 2, Loss (standarized): 0.6446638077728594\n",
      "          Validation Loss (standardized): 0.691502893617469\n",
      "Epoch: 3, Loss (standarized): 0.5892263040730251\n",
      "          Validation Loss (standardized): 0.6961568357709127\n",
      "Epoch: 4, Loss (standarized): 0.541341583167221\n",
      "          Validation Loss (standardized): 0.7070659254661836\n",
      "Epoch: 5, Loss (standarized): 0.4912817543647651\n",
      "          Validation Loss (standardized): 0.7259664497909949\n",
      "Epoch: 6, Loss (standarized): 0.4408232117647183\n",
      "          Validation Loss (standardized): 0.7548579033542617\n",
      "Epoch: 7, Loss (standarized): 0.39198729677866795\n",
      "          Validation Loss (standardized): 0.7944539252846987\n",
      "Epoch: 8, Loss (standarized): 0.34551335501062397\n",
      "          Validation Loss (standardized): 0.845709001320407\n",
      "Epoch: 9, Loss (standarized): 0.3026031627842482\n",
      "          Validation Loss (standardized): 0.9102277027098428\n",
      "Epoch: 10, Loss (standarized): 0.26549146049681627\n",
      "          Validation Loss (standardized): 0.9890041654084549\n",
      "Epoch: 11, Loss (standarized): 0.23619870105101493\n",
      "          Validation Loss (standardized): 1.0812409210131377\n",
      "Epoch: 12, Loss (standarized): 0.21539456898529805\n",
      "          Validation Loss (standardized): 1.1841378157082074\n",
      "Epoch: 13, Loss (standarized): 0.20233571248312737\n",
      "          Validation Loss (standardized): 1.2934239857204448\n",
      "Epoch: 14, Loss (standarized): 0.19552010076488266\n",
      "          Validation Loss (standardized): 1.4040992957997827\n",
      "Epoch: 15, Loss (standarized): 0.19331498761711616\n",
      "          Validation Loss (standardized): 1.5110158445078923\n",
      "Epoch: 16, Loss (standarized): 0.194230130674155\n",
      "          Validation Loss (standardized): 1.6095200499378393\n",
      "Epoch: 17, Loss (standarized): 0.19698184674182276\n",
      "          Validation Loss (standardized): 1.695777387326743\n",
      "Epoch: 18, Loss (standarized): 0.20052374361433162\n",
      "          Validation Loss (standardized): 1.767037443828314\n",
      "Epoch: 19, Loss (standarized): 0.20406035390878616\n",
      "          Validation Loss (standardized): 1.821873302635476\n",
      "Epoch: 20, Loss (standarized): 0.20706160109407765\n",
      "          Validation Loss (standardized): 1.8599887121451553\n",
      "Final epoch: 20, Final loss (standarized): 0.20706160109407765\n",
      "Epoch: 1, Loss (standarized): 0.7813703349928443\n",
      "          Validation Loss (standardized): 0.7048992940340159\n",
      "Epoch: 2, Loss (standarized): 0.6587850125515413\n",
      "          Validation Loss (standardized): 0.6889912370363487\n",
      "Epoch: 3, Loss (standarized): 0.5881919737093272\n",
      "          Validation Loss (standardized): 0.70130632736944\n",
      "Epoch: 4, Loss (standarized): 0.5457422104309091\n",
      "          Validation Loss (standardized): 0.7206682699161336\n",
      "Epoch: 5, Loss (standarized): 0.5063856481626665\n",
      "          Validation Loss (standardized): 0.7398547302090396\n",
      "Epoch: 6, Loss (standarized): 0.46123359262370656\n",
      "          Validation Loss (standardized): 0.7611306849725594\n",
      "Epoch: 7, Loss (standarized): 0.4123196746299737\n",
      "          Validation Loss (standardized): 0.7888137323692939\n",
      "Epoch: 8, Loss (standarized): 0.36417695080385903\n",
      "          Validation Loss (standardized): 0.8263960998020707\n",
      "Epoch: 9, Loss (standarized): 0.32059436409817843\n",
      "          Validation Loss (standardized): 0.8759027550927356\n",
      "Epoch: 10, Loss (standarized): 0.28384167143198447\n",
      "          Validation Loss (standardized): 0.9378209822012531\n",
      "Epoch: 11, Loss (standarized): 0.2546973219139341\n",
      "          Validation Loss (standardized): 1.011280914874465\n",
      "Epoch: 12, Loss (standarized): 0.23281606951474806\n",
      "          Validation Loss (standardized): 1.094293411026639\n",
      "Epoch: 13, Loss (standarized): 0.2172741046889658\n",
      "          Validation Loss (standardized): 1.1840369708427605\n",
      "Epoch: 14, Loss (standarized): 0.20698650324783394\n",
      "          Validation Loss (standardized): 1.276971779560007\n",
      "Epoch: 15, Loss (standarized): 0.20090828638421426\n",
      "          Validation Loss (standardized): 1.369159348505512\n",
      "Epoch: 16, Loss (standarized): 0.1980532157266128\n",
      "          Validation Loss (standardized): 1.4564849761819267\n",
      "Epoch: 17, Loss (standarized): 0.19748555208252336\n",
      "          Validation Loss (standardized): 1.5351732333749712\n",
      "Epoch: 18, Loss (standarized): 0.1983256481364455\n",
      "          Validation Loss (standardized): 1.6022321361098522\n",
      "Epoch: 19, Loss (standarized): 0.19980569470701193\n",
      "          Validation Loss (standardized): 1.6556570487094595\n",
      "Epoch: 20, Loss (standarized): 0.20132578907060286\n",
      "          Validation Loss (standardized): 1.6944061355131845\n",
      "Final epoch: 20, Final loss (standarized): 0.20132578907060286\n",
      "Epoch: 1, Loss (standarized): 0.70624698185106\n",
      "          Validation Loss (standardized): 0.6902215950838639\n",
      "Epoch: 2, Loss (standarized): 0.6365968294497404\n",
      "          Validation Loss (standardized): 0.6908997520019988\n",
      "Epoch: 3, Loss (standarized): 0.5795778989305937\n",
      "          Validation Loss (standardized): 0.6993485246293822\n",
      "Epoch: 4, Loss (standarized): 0.5211814598763366\n",
      "          Validation Loss (standardized): 0.7157357513730949\n",
      "Epoch: 5, Loss (standarized): 0.4613048272922142\n",
      "          Validation Loss (standardized): 0.7427863459833469\n",
      "Epoch: 6, Loss (standarized): 0.40216124690053157\n",
      "          Validation Loss (standardized): 0.7845016826729457\n",
      "Epoch: 7, Loss (standarized): 0.3467925659800914\n",
      "          Validation Loss (standardized): 0.8445788694503912\n",
      "Epoch: 8, Loss (standarized): 0.29796032016148155\n",
      "          Validation Loss (standardized): 0.9252912726816068\n",
      "Epoch: 9, Loss (standarized): 0.25763317697683835\n",
      "          Validation Loss (standardized): 1.0270231423763871\n",
      "Epoch: 10, Loss (standarized): 0.22696442551603646\n",
      "          Validation Loss (standardized): 1.1478863024674864\n",
      "Epoch: 11, Loss (standarized): 0.206456832836995\n",
      "          Validation Loss (standardized): 1.2830578237828467\n",
      "Epoch: 12, Loss (standarized): 0.1957401995949588\n",
      "          Validation Loss (standardized): 1.4245160370278227\n",
      "Epoch: 13, Loss (standarized): 0.19309342342290925\n",
      "          Validation Loss (standardized): 1.5625604168668599\n",
      "Epoch: 14, Loss (standarized): 0.19579713629154236\n",
      "          Validation Loss (standardized): 1.6881360839781587\n",
      "Epoch: 15, Loss (standarized): 0.20112333762276666\n",
      "          Validation Loss (standardized): 1.7945345670778579\n",
      "Epoch: 16, Loss (standarized): 0.206986862547778\n",
      "          Validation Loss (standardized): 1.8777775742620162\n",
      "Epoch: 17, Loss (standarized): 0.21206898299383184\n",
      "          Validation Loss (standardized): 1.9363781958216302\n",
      "Epoch: 18, Loss (standarized): 0.21568624667605724\n",
      "          Validation Loss (standardized): 1.9707484989353856\n",
      "Epoch: 19, Loss (standarized): 0.21761235909434212\n",
      "          Validation Loss (standardized): 1.9826479164288355\n",
      "Epoch: 20, Loss (standarized): 0.21792210122465405\n",
      "          Validation Loss (standardized): 1.9746949026893588\n",
      "Final epoch: 20, Final loss (standarized): 0.21792210122465405\n",
      "Epoch: 1, Loss (standarized): 0.7141440766640053\n",
      "          Validation Loss (standardized): 0.6908840257787995\n",
      "Epoch: 2, Loss (standarized): 0.6260182709981398\n",
      "          Validation Loss (standardized): 0.7032487269455174\n",
      "Epoch: 3, Loss (standarized): 0.5697714521269354\n",
      "          Validation Loss (standardized): 0.714986548339458\n",
      "Epoch: 4, Loss (standarized): 0.509913058374879\n",
      "          Validation Loss (standardized): 0.7305224032406663\n",
      "Epoch: 5, Loss (standarized): 0.4467824190176002\n",
      "          Validation Loss (standardized): 0.758012556569181\n",
      "Epoch: 6, Loss (standarized): 0.38668633117036627\n",
      "          Validation Loss (standardized): 0.8019812334961464\n",
      "Epoch: 7, Loss (standarized): 0.3325775108270812\n",
      "          Validation Loss (standardized): 0.8648481677296068\n",
      "Epoch: 8, Loss (standarized): 0.2860825858369358\n",
      "          Validation Loss (standardized): 0.9482097906250059\n",
      "Epoch: 9, Loss (standarized): 0.2489077419969902\n",
      "          Validation Loss (standardized): 1.0517548822571776\n",
      "Epoch: 10, Loss (standarized): 0.2219004250442375\n",
      "          Validation Loss (standardized): 1.1724482532400016\n",
      "Epoch: 11, Loss (standarized): 0.20463880943116824\n",
      "          Validation Loss (standardized): 1.3047697217043492\n",
      "Epoch: 12, Loss (standarized): 0.19577390099249697\n",
      "          Validation Loss (standardized): 1.4413444835429479\n",
      "Epoch: 13, Loss (standarized): 0.19343645876760118\n",
      "          Validation Loss (standardized): 1.5740028775697328\n",
      "Epoch: 14, Loss (standarized): 0.1955396099287095\n",
      "          Validation Loss (standardized): 1.6950457384607853\n",
      "Epoch: 15, Loss (standarized): 0.20006297954830324\n",
      "          Validation Loss (standardized): 1.7985304909777675\n",
      "Epoch: 16, Loss (standarized): 0.20533456021995816\n",
      "          Validation Loss (standardized): 1.880721817694415\n",
      "Epoch: 17, Loss (standarized): 0.210182784887387\n",
      "          Validation Loss (standardized): 1.9401166182881588\n",
      "Epoch: 18, Loss (standarized): 0.21393320910350505\n",
      "          Validation Loss (standardized): 1.9769037216328798\n",
      "Epoch: 19, Loss (standarized): 0.21630625685158308\n",
      "          Validation Loss (standardized): 1.992605059515053\n",
      "Epoch: 20, Loss (standarized): 0.21730637717852025\n",
      "          Validation Loss (standardized): 1.9895556611575234\n",
      "Final epoch: 20, Final loss (standarized): 0.21730637717852025\n",
      "Epoch: 1, Loss (standarized): 0.7352593105614135\n",
      "          Validation Loss (standardized): 0.6896073085514044\n",
      "Epoch: 2, Loss (standarized): 0.6296195619844722\n",
      "          Validation Loss (standardized): 0.7017487853986865\n",
      "Epoch: 3, Loss (standarized): 0.5720996710187862\n",
      "          Validation Loss (standardized): 0.725274294831454\n",
      "Epoch: 4, Loss (standarized): 0.5238094023426237\n",
      "          Validation Loss (standardized): 0.7442150873817066\n",
      "Epoch: 5, Loss (standarized): 0.46527859821388445\n",
      "          Validation Loss (standardized): 0.7660214654455629\n",
      "Epoch: 6, Loss (standarized): 0.4026424984423974\n",
      "          Validation Loss (standardized): 0.800668706578119\n",
      "Epoch: 7, Loss (standarized): 0.34485926176707693\n",
      "          Validation Loss (standardized): 0.8546683076540623\n",
      "Epoch: 8, Loss (standarized): 0.29729454193938354\n",
      "          Validation Loss (standardized): 0.9301966957882658\n",
      "Epoch: 9, Loss (standarized): 0.26105561484804973\n",
      "          Validation Loss (standardized): 1.026039699895561\n",
      "Epoch: 10, Loss (standarized): 0.2345922202927625\n",
      "          Validation Loss (standardized): 1.1393194522014407\n",
      "Epoch: 11, Loss (standarized): 0.2161537604127417\n",
      "          Validation Loss (standardized): 1.266147212873591\n",
      "Epoch: 12, Loss (standarized): 0.20483696041959418\n",
      "          Validation Loss (standardized): 1.4010728600749436\n",
      "Epoch: 13, Loss (standarized): 0.1999267614515574\n",
      "          Validation Loss (standardized): 1.5369245744375502\n",
      "Epoch: 14, Loss (standarized): 0.20013998254992085\n",
      "          Validation Loss (standardized): 1.6658205000951376\n",
      "Epoch: 15, Loss (standarized): 0.20367268140218373\n",
      "          Validation Loss (standardized): 1.780708460115615\n",
      "Epoch: 16, Loss (standarized): 0.20870413122794648\n",
      "          Validation Loss (standardized): 1.8764933442307739\n",
      "Epoch: 17, Loss (standarized): 0.21380463372769948\n",
      "          Validation Loss (standardized): 1.950367246934831\n",
      "Epoch: 18, Loss (standarized): 0.21806665464248323\n",
      "          Validation Loss (standardized): 2.0015801957108863\n",
      "Epoch: 19, Loss (standarized): 0.22105081925331735\n",
      "          Validation Loss (standardized): 2.030972411149493\n",
      "Epoch: 20, Loss (standarized): 0.2226687775722607\n",
      "          Validation Loss (standardized): 2.0404828751237325\n",
      "Final epoch: 20, Final loss (standarized): 0.2226687775722607\n",
      "Epoch: 1, Loss (standarized): 0.7101301942518431\n",
      "          Validation Loss (standardized): 0.6891168836127455\n",
      "Epoch: 2, Loss (standarized): 0.6420985254142356\n",
      "          Validation Loss (standardized): 0.6907211606700971\n",
      "Epoch: 3, Loss (standarized): 0.5966912329500236\n",
      "          Validation Loss (standardized): 0.6970887913857132\n",
      "Epoch: 4, Loss (standarized): 0.5492266159790439\n",
      "          Validation Loss (standardized): 0.7063845696735327\n",
      "Epoch: 5, Loss (standarized): 0.4969004527623174\n",
      "          Validation Loss (standardized): 0.7224818120257401\n",
      "Epoch: 6, Loss (standarized): 0.44317967885541165\n",
      "          Validation Loss (standardized): 0.7490850215000049\n",
      "Epoch: 7, Loss (standarized): 0.39076990078033075\n",
      "          Validation Loss (standardized): 0.789223312066037\n",
      "Epoch: 8, Loss (standarized): 0.3414656905569176\n",
      "          Validation Loss (standardized): 0.8455718467774906\n",
      "Epoch: 9, Loss (standarized): 0.2969070079738452\n",
      "          Validation Loss (standardized): 0.9203278594421517\n",
      "Epoch: 10, Loss (standarized): 0.2588850682736141\n",
      "          Validation Loss (standardized): 1.014421338504647\n",
      "Epoch: 11, Loss (standarized): 0.22909282697642755\n",
      "          Validation Loss (standardized): 1.1264326053092548\n",
      "Epoch: 12, Loss (standarized): 0.20856674279162737\n",
      "          Validation Loss (standardized): 1.2517120718425623\n",
      "Epoch: 13, Loss (standarized): 0.19707099252947355\n",
      "          Validation Loss (standardized): 1.3825309531880727\n",
      "Epoch: 14, Loss (standarized): 0.19299680339059824\n",
      "          Validation Loss (standardized): 1.509617880645106\n",
      "Epoch: 15, Loss (standarized): 0.19396016883629816\n",
      "          Validation Loss (standardized): 1.6243017871811827\n",
      "Epoch: 16, Loss (standarized): 0.19758008313652323\n",
      "          Validation Loss (standardized): 1.7200898370112818\n",
      "Epoch: 17, Loss (standarized): 0.2019706268005539\n",
      "          Validation Loss (standardized): 1.7932111222785543\n",
      "Epoch: 18, Loss (standarized): 0.20588332254682298\n",
      "          Validation Loss (standardized): 1.8423568682086822\n",
      "Epoch: 19, Loss (standarized): 0.20863680508902332\n",
      "          Validation Loss (standardized): 1.86812389285383\n",
      "Epoch: 20, Loss (standarized): 0.20997616768841892\n",
      "          Validation Loss (standardized): 1.872400036104\n",
      "Final epoch: 20, Final loss (standarized): 0.20997616768841892\n",
      "Epoch: 1, Loss (standarized): 0.7445651717548015\n",
      "          Validation Loss (standardized): 0.6944231043284367\n",
      "Epoch: 2, Loss (standarized): 0.6635680101035777\n",
      "          Validation Loss (standardized): 0.6894416095409233\n",
      "Epoch: 3, Loss (standarized): 0.6139625622913333\n",
      "          Validation Loss (standardized): 0.7011288916767308\n",
      "Epoch: 4, Loss (standarized): 0.580067619907394\n",
      "          Validation Loss (standardized): 0.7153175956304858\n",
      "Epoch: 5, Loss (standarized): 0.5443946444135473\n",
      "          Validation Loss (standardized): 0.7276631024042757\n",
      "Epoch: 6, Loss (standarized): 0.501051372782377\n",
      "          Validation Loss (standardized): 0.7412245417732771\n",
      "Epoch: 7, Loss (standarized): 0.45253382345953275\n",
      "          Validation Loss (standardized): 0.7607418056711359\n",
      "Epoch: 8, Loss (standarized): 0.40322775567103847\n",
      "          Validation Loss (standardized): 0.7904137990152897\n",
      "Epoch: 9, Loss (standarized): 0.3569956253380632\n",
      "          Validation Loss (standardized): 0.8330796145526302\n",
      "Epoch: 10, Loss (standarized): 0.31622023164229857\n",
      "          Validation Loss (standardized): 0.8899709846745963\n",
      "Epoch: 11, Loss (standarized): 0.28161514806822174\n",
      "          Validation Loss (standardized): 0.9611668762776933\n",
      "Epoch: 12, Loss (standarized): 0.25300665820511314\n",
      "          Validation Loss (standardized): 1.0462151389221297\n",
      "Epoch: 13, Loss (standarized): 0.2303196128333694\n",
      "          Validation Loss (standardized): 1.1440124920769457\n",
      "Epoch: 14, Loss (standarized): 0.21372921254635213\n",
      "          Validation Loss (standardized): 1.2521711340505088\n",
      "Epoch: 15, Loss (standarized): 0.20319303169721\n",
      "          Validation Loss (standardized): 1.3666462218623923\n",
      "Epoch: 16, Loss (standarized): 0.19810875932002514\n",
      "          Validation Loss (standardized): 1.4820011707231089\n",
      "Epoch: 17, Loss (standarized): 0.19733672922625228\n",
      "          Validation Loss (standardized): 1.5922596849335526\n",
      "Epoch: 18, Loss (standarized): 0.1994571479873031\n",
      "          Validation Loss (standardized): 1.6919608107387425\n",
      "Epoch: 19, Loss (standarized): 0.2030845751015121\n",
      "          Validation Loss (standardized): 1.7769303204471962\n",
      "Epoch: 20, Loss (standarized): 0.20709439984399675\n",
      "          Validation Loss (standardized): 1.8446035493988058\n",
      "Final epoch: 20, Final loss (standarized): 0.20709439984399675\n",
      "Epoch: 1, Loss (standarized): 0.8138378764679226\n",
      "          Validation Loss (standardized): 0.7280406298452694\n",
      "Epoch: 2, Loss (standarized): 0.6771249358865179\n",
      "          Validation Loss (standardized): 0.6946328670962751\n",
      "Epoch: 3, Loss (standarized): 0.589722410619163\n",
      "          Validation Loss (standardized): 0.6978904273166795\n",
      "Epoch: 4, Loss (standarized): 0.5414341889419698\n",
      "          Validation Loss (standardized): 0.7209324366136839\n",
      "Epoch: 5, Loss (standarized): 0.510024612768431\n",
      "          Validation Loss (standardized): 0.7466073161302978\n",
      "Epoch: 6, Loss (standarized): 0.4750133103599492\n",
      "          Validation Loss (standardized): 0.7701058523320811\n",
      "Epoch: 7, Loss (standarized): 0.43065301725057376\n",
      "          Validation Loss (standardized): 0.7953044305341868\n",
      "Epoch: 8, Loss (standarized): 0.38081457939842966\n",
      "          Validation Loss (standardized): 0.8283341934067859\n",
      "Epoch: 9, Loss (standarized): 0.33193519929965926\n",
      "          Validation Loss (standardized): 0.874194498329035\n",
      "Epoch: 10, Loss (standarized): 0.289466609734256\n",
      "          Validation Loss (standardized): 0.9352411008364566\n",
      "Epoch: 11, Loss (standarized): 0.25625604896470433\n",
      "          Validation Loss (standardized): 1.011057590144912\n",
      "Epoch: 12, Loss (standarized): 0.2324682656332257\n",
      "          Validation Loss (standardized): 1.0993277848800387\n",
      "Epoch: 13, Loss (standarized): 0.21665500276508076\n",
      "          Validation Loss (standardized): 1.1968414435543544\n",
      "Epoch: 14, Loss (standarized): 0.20696617662328973\n",
      "          Validation Loss (standardized): 1.3000474296904132\n",
      "Epoch: 15, Loss (standarized): 0.20183342395033238\n",
      "          Validation Loss (standardized): 1.405190403681661\n",
      "Epoch: 16, Loss (standarized): 0.20008668809127822\n",
      "          Validation Loss (standardized): 1.5083459135650572\n",
      "Epoch: 17, Loss (standarized): 0.20079200444414597\n",
      "          Validation Loss (standardized): 1.6056032334526942\n",
      "Epoch: 18, Loss (standarized): 0.20310137157510688\n",
      "          Validation Loss (standardized): 1.693399225602453\n",
      "Epoch: 19, Loss (standarized): 0.20622345256818347\n",
      "          Validation Loss (standardized): 1.768860485197071\n",
      "Epoch: 20, Loss (standarized): 0.20947140030272743\n",
      "          Validation Loss (standardized): 1.8300127441556362\n",
      "Final epoch: 20, Final loss (standarized): 0.20947140030272743\n",
      "Epoch: 1, Loss (standarized): 0.8120209688426318\n",
      "          Validation Loss (standardized): 0.7155372778436804\n",
      "Epoch: 2, Loss (standarized): 0.6577341871262202\n",
      "          Validation Loss (standardized): 0.6908481273300096\n",
      "Epoch: 3, Loss (standarized): 0.5629628679409706\n",
      "          Validation Loss (standardized): 0.7117957756992987\n",
      "Epoch: 4, Loss (standarized): 0.5146374770429444\n",
      "          Validation Loss (standardized): 0.7483585578750326\n",
      "Epoch: 5, Loss (standarized): 0.4773472501602466\n",
      "          Validation Loss (standardized): 0.7824043968727246\n",
      "Epoch: 6, Loss (standarized): 0.4307554547273642\n",
      "          Validation Loss (standardized): 0.8154226719436847\n",
      "Epoch: 7, Loss (standarized): 0.3768301847475876\n",
      "          Validation Loss (standardized): 0.8547641378435482\n",
      "Epoch: 8, Loss (standarized): 0.32432369699919095\n",
      "          Validation Loss (standardized): 0.9059467609527411\n",
      "Epoch: 9, Loss (standarized): 0.28019310820867616\n",
      "          Validation Loss (standardized): 0.9706419279447597\n",
      "Epoch: 10, Loss (standarized): 0.24706893567250443\n",
      "          Validation Loss (standardized): 1.047578143224236\n",
      "Epoch: 11, Loss (standarized): 0.22423522541518862\n",
      "          Validation Loss (standardized): 1.1341777291488133\n",
      "Epoch: 12, Loss (standarized): 0.20965671804333366\n",
      "          Validation Loss (standardized): 1.2275178729786433\n",
      "Epoch: 13, Loss (standarized): 0.20123896016872\n",
      "          Validation Loss (standardized): 1.3246107578631885\n",
      "Epoch: 14, Loss (standarized): 0.19726134195957604\n",
      "          Validation Loss (standardized): 1.4224203251192484\n",
      "Epoch: 15, Loss (standarized): 0.19641691229400385\n",
      "          Validation Loss (standardized): 1.517871105840114\n",
      "Epoch: 16, Loss (standarized): 0.19770863126968247\n",
      "          Validation Loss (standardized): 1.607947357274964\n",
      "Epoch: 17, Loss (standarized): 0.200334948380573\n",
      "          Validation Loss (standardized): 1.6898796249989372\n",
      "Epoch: 18, Loss (standarized): 0.20362564443878015\n",
      "          Validation Loss (standardized): 1.7613559316729714\n",
      "Epoch: 19, Loss (standarized): 0.20702743396950393\n",
      "          Validation Loss (standardized): 1.8206851091178846\n",
      "Epoch: 20, Loss (standarized): 0.21011185455249534\n",
      "          Validation Loss (standardized): 1.8668699822659005\n",
      "Final epoch: 20, Final loss (standarized): 0.21011185455249534\n",
      "Epoch: 1, Loss (standarized): 0.7701357423049778\n",
      "          Validation Loss (standardized): 0.7099693878511798\n",
      "Epoch: 2, Loss (standarized): 0.6287279560227769\n",
      "          Validation Loss (standardized): 0.6898047732531092\n",
      "Epoch: 3, Loss (standarized): 0.5490154790854209\n",
      "          Validation Loss (standardized): 0.7081936414017258\n",
      "Epoch: 4, Loss (standarized): 0.5018771090287923\n",
      "          Validation Loss (standardized): 0.7351632741167446\n",
      "Epoch: 5, Loss (standarized): 0.4521074678545069\n",
      "          Validation Loss (standardized): 0.7648632373062308\n",
      "Epoch: 6, Loss (standarized): 0.3944715998878235\n",
      "          Validation Loss (standardized): 0.8041271753592611\n",
      "Epoch: 7, Loss (standarized): 0.3373611094544792\n",
      "          Validation Loss (standardized): 0.8593515366606463\n",
      "Epoch: 8, Loss (standarized): 0.2887096017715056\n",
      "          Validation Loss (standardized): 0.9325454917566538\n",
      "Epoch: 9, Loss (standarized): 0.2521282762790287\n",
      "          Validation Loss (standardized): 1.0215462758452907\n",
      "Epoch: 10, Loss (standarized): 0.22707588865796088\n",
      "          Validation Loss (standardized): 1.122040365448211\n",
      "Epoch: 11, Loss (standarized): 0.21093978191646134\n",
      "          Validation Loss (standardized): 1.229332351147852\n",
      "Epoch: 12, Loss (standarized): 0.20111172492916862\n",
      "          Validation Loss (standardized): 1.3388575414288402\n",
      "Epoch: 13, Loss (standarized): 0.19583291370287553\n",
      "          Validation Loss (standardized): 1.4459567819142012\n",
      "Epoch: 14, Loss (standarized): 0.1939943527504996\n",
      "          Validation Loss (standardized): 1.5458687519557333\n",
      "Epoch: 15, Loss (standarized): 0.19467482400181\n",
      "          Validation Loss (standardized): 1.6342021273156735\n",
      "Epoch: 16, Loss (standarized): 0.19692660612126053\n",
      "          Validation Loss (standardized): 1.7075317467050033\n",
      "Epoch: 17, Loss (standarized): 0.19983060213393844\n",
      "          Validation Loss (standardized): 1.7637683581693404\n",
      "Epoch: 18, Loss (standarized): 0.20262968933334502\n",
      "          Validation Loss (standardized): 1.8021837525786493\n",
      "Epoch: 19, Loss (standarized): 0.20480685750862163\n",
      "          Validation Loss (standardized): 1.8231898582415915\n",
      "Epoch: 20, Loss (standarized): 0.2060867291447803\n",
      "          Validation Loss (standardized): 1.8280332889197157\n",
      "Final epoch: 20, Final loss (standarized): 0.2060867291447803\n",
      "Epoch: 1, Loss (standarized): 0.7063152486138947\n",
      "          Validation Loss (standardized): 0.6897691449514894\n",
      "Epoch: 2, Loss (standarized): 0.6445450490556737\n",
      "          Validation Loss (standardized): 0.6953929917645535\n",
      "Epoch: 3, Loss (standarized): 0.5998145759288285\n",
      "          Validation Loss (standardized): 0.7040416606397332\n",
      "Epoch: 4, Loss (standarized): 0.5518936632860334\n",
      "          Validation Loss (standardized): 0.7135586215706912\n",
      "Epoch: 5, Loss (standarized): 0.49631123286671763\n",
      "          Validation Loss (standardized): 0.7296748848975179\n",
      "Epoch: 6, Loss (standarized): 0.4372109935358987\n",
      "          Validation Loss (standardized): 0.7588593593916079\n",
      "Epoch: 7, Loss (standarized): 0.37933664554352964\n",
      "          Validation Loss (standardized): 0.8067924686356239\n",
      "Epoch: 8, Loss (standarized): 0.32660150511073927\n",
      "          Validation Loss (standardized): 0.8773114260773976\n",
      "Epoch: 9, Loss (standarized): 0.28147641995612244\n",
      "          Validation Loss (standardized): 0.9717869082352328\n",
      "Epoch: 10, Loss (standarized): 0.24519579773376812\n",
      "          Validation Loss (standardized): 1.0894064464036088\n",
      "Epoch: 11, Loss (standarized): 0.21868770079686506\n",
      "          Validation Loss (standardized): 1.2266308642786694\n",
      "Epoch: 12, Loss (standarized): 0.20242898488945707\n",
      "          Validation Loss (standardized): 1.3763435937581843\n",
      "Epoch: 13, Loss (standarized): 0.19558260205864544\n",
      "          Validation Loss (standardized): 1.528483567430864\n",
      "Epoch: 14, Loss (standarized): 0.1958880275224744\n",
      "          Validation Loss (standardized): 1.6722910001818554\n",
      "Epoch: 15, Loss (standarized): 0.2004600627874114\n",
      "          Validation Loss (standardized): 1.7986942781110855\n",
      "Epoch: 16, Loss (standarized): 0.20670648424876223\n",
      "          Validation Loss (standardized): 1.9016424743927138\n",
      "Epoch: 17, Loss (standarized): 0.2127932844689341\n",
      "          Validation Loss (standardized): 1.978253394257792\n",
      "Epoch: 18, Loss (standarized): 0.21767340834972382\n",
      "          Validation Loss (standardized): 2.0282740632650715\n",
      "Epoch: 19, Loss (standarized): 0.2209193886277299\n",
      "          Validation Loss (standardized): 2.0533493150196893\n",
      "Epoch: 20, Loss (standarized): 0.22252683479679858\n",
      "          Validation Loss (standardized): 2.0563555550823254\n",
      "Final epoch: 20, Final loss (standarized): 0.22252683479679858\n",
      "Epoch: 1, Loss (standarized): 0.7003944788133226\n",
      "          Validation Loss (standardized): 0.6904840295567053\n",
      "Epoch: 2, Loss (standarized): 0.6460274994613167\n",
      "          Validation Loss (standardized): 0.6922414146023094\n",
      "Epoch: 3, Loss (standarized): 0.6023753767251833\n",
      "          Validation Loss (standardized): 0.6942535468554485\n",
      "Epoch: 4, Loss (standarized): 0.54824134406246\n",
      "          Validation Loss (standardized): 0.704043893416544\n",
      "Epoch: 5, Loss (standarized): 0.4914671400891562\n",
      "          Validation Loss (standardized): 0.7269889300591873\n",
      "Epoch: 6, Loss (standarized): 0.4357058239041698\n",
      "          Validation Loss (standardized): 0.7646029666137624\n",
      "Epoch: 7, Loss (standarized): 0.380859487140143\n",
      "          Validation Loss (standardized): 0.8183872473241769\n",
      "Epoch: 8, Loss (standarized): 0.3277115562098797\n",
      "          Validation Loss (standardized): 0.89187932859102\n",
      "Epoch: 9, Loss (standarized): 0.27956807438431497\n",
      "          Validation Loss (standardized): 0.9890587906210464\n",
      "Epoch: 10, Loss (standarized): 0.24071117349247279\n",
      "          Validation Loss (standardized): 1.1114048399363021\n",
      "Epoch: 11, Loss (standarized): 0.21401245144869044\n",
      "          Validation Loss (standardized): 1.2558740957597363\n",
      "Epoch: 12, Loss (standarized): 0.1996340489876322\n",
      "          Validation Loss (standardized): 1.414732862307781\n",
      "Epoch: 13, Loss (standarized): 0.19541194207357238\n",
      "          Validation Loss (standardized): 1.5770693332279517\n",
      "Epoch: 14, Loss (standarized): 0.19815657717368323\n",
      "          Validation Loss (standardized): 1.7311593398161478\n",
      "Epoch: 15, Loss (standarized): 0.20467830964182646\n",
      "          Validation Loss (standardized): 1.8668537563952332\n",
      "Epoch: 16, Loss (standarized): 0.21234602948146528\n",
      "          Validation Loss (standardized): 1.9771323899880764\n",
      "Epoch: 17, Loss (standarized): 0.21933684647178456\n",
      "          Validation Loss (standardized): 2.058486974042717\n",
      "Epoch: 18, Loss (standarized): 0.22464651311869863\n",
      "          Validation Loss (standardized): 2.1104704731584287\n",
      "Epoch: 19, Loss (standarized): 0.22794942961486295\n",
      "          Validation Loss (standardized): 2.134958643378833\n",
      "Epoch: 20, Loss (standarized): 0.22941425755961117\n",
      "          Validation Loss (standardized): 2.1354692221921545\n",
      "Final epoch: 20, Final loss (standarized): 0.22941425755961117\n",
      "Epoch: 1, Loss (standarized): 0.6976249233994154\n",
      "          Validation Loss (standardized): 0.6899241865470788\n",
      "Epoch: 2, Loss (standarized): 0.641467034117524\n",
      "          Validation Loss (standardized): 0.6905191014901597\n",
      "Epoch: 3, Loss (standarized): 0.5937162526524625\n",
      "          Validation Loss (standardized): 0.694538444789367\n",
      "Epoch: 4, Loss (standarized): 0.5494428544416969\n",
      "          Validation Loss (standardized): 0.7018586123460565\n",
      "Epoch: 5, Loss (standarized): 0.5066185455305192\n",
      "          Validation Loss (standardized): 0.7129889161301923\n",
      "Epoch: 6, Loss (standarized): 0.4648612135561313\n",
      "          Validation Loss (standardized): 0.7287173675080717\n",
      "Epoch: 7, Loss (standarized): 0.42479273600037726\n",
      "          Validation Loss (standardized): 0.7497195708992223\n",
      "Epoch: 8, Loss (standarized): 0.3869768732864333\n",
      "          Validation Loss (standardized): 0.7767868720128466\n",
      "Epoch: 9, Loss (standarized): 0.3518823959508032\n",
      "          Validation Loss (standardized): 0.8103635985380968\n",
      "Epoch: 10, Loss (standarized): 0.3199020718579596\n",
      "          Validation Loss (standardized): 0.8505830307810105\n",
      "Epoch: 11, Loss (standarized): 0.29135044182707476\n",
      "          Validation Loss (standardized): 0.8969751039747527\n",
      "Epoch: 12, Loss (standarized): 0.26671774388888\n",
      "          Validation Loss (standardized): 0.948721632334794\n",
      "Epoch: 13, Loss (standarized): 0.24618397405033116\n",
      "          Validation Loss (standardized): 1.0040687438278026\n",
      "Epoch: 14, Loss (standarized): 0.22980843956526067\n",
      "          Validation Loss (standardized): 1.0606511538689143\n",
      "Epoch: 15, Loss (standarized): 0.21732774836472793\n",
      "          Validation Loss (standardized): 1.1165370584629968\n",
      "Epoch: 16, Loss (standarized): 0.2081792733326751\n",
      "          Validation Loss (standardized): 1.1688698754478617\n",
      "Epoch: 17, Loss (standarized): 0.20183548106298435\n",
      "          Validation Loss (standardized): 1.215346664566545\n",
      "Epoch: 18, Loss (standarized): 0.19766687288230683\n",
      "          Validation Loss (standardized): 1.254232269533472\n",
      "Epoch: 19, Loss (standarized): 0.19504441841784767\n",
      "          Validation Loss (standardized): 1.2841587496117775\n",
      "Epoch: 20, Loss (standarized): 0.19347484705081813\n",
      "          Validation Loss (standardized): 1.305082106916926\n",
      "Final epoch: 20, Final loss (standarized): 0.19347484705081813\n",
      "Epoch: 1, Loss (standarized): 0.7197509524665786\n",
      "          Validation Loss (standardized): 0.6960911576032751\n",
      "Epoch: 2, Loss (standarized): 0.6450618419278153\n",
      "          Validation Loss (standardized): 0.6900288332971666\n",
      "Epoch: 3, Loss (standarized): 0.5907302175662755\n",
      "          Validation Loss (standardized): 0.6925707017746534\n",
      "Epoch: 4, Loss (standarized): 0.545871888095747\n",
      "          Validation Loss (standardized): 0.6999288473643026\n",
      "Epoch: 5, Loss (standarized): 0.5044482556293147\n",
      "          Validation Loss (standardized): 0.7112708332844607\n",
      "Epoch: 6, Loss (standarized): 0.464672735397787\n",
      "          Validation Loss (standardized): 0.7269050223219671\n",
      "Epoch: 7, Loss (standarized): 0.4263809485696471\n",
      "          Validation Loss (standardized): 0.7473857629874096\n",
      "Epoch: 8, Loss (standarized): 0.39006695828105825\n",
      "          Validation Loss (standardized): 0.7732040674338045\n",
      "Epoch: 9, Loss (standarized): 0.356270729336254\n",
      "          Validation Loss (standardized): 0.804675612745418\n",
      "Epoch: 10, Loss (standarized): 0.32541090548512147\n",
      "          Validation Loss (standardized): 0.8419387431799871\n",
      "Epoch: 11, Loss (standarized): 0.2977212302411874\n",
      "          Validation Loss (standardized): 0.8847611353897006\n",
      "Epoch: 12, Loss (standarized): 0.2735024447832711\n",
      "          Validation Loss (standardized): 0.932355580553193\n",
      "Epoch: 13, Loss (standarized): 0.2529770202725558\n",
      "          Validation Loss (standardized): 0.9834811677524314\n",
      "Epoch: 14, Loss (standarized): 0.23620956160863757\n",
      "          Validation Loss (standardized): 1.0361039292354843\n",
      "Epoch: 15, Loss (standarized): 0.22309331536260388\n",
      "          Validation Loss (standardized): 1.087699719079821\n",
      "Epoch: 16, Loss (standarized): 0.213313122124078\n",
      "          Validation Loss (standardized): 1.1366497354087068\n",
      "Epoch: 17, Loss (standarized): 0.2062637395810665\n",
      "          Validation Loss (standardized): 1.18092019663167\n",
      "Epoch: 18, Loss (standarized): 0.20141095129476236\n",
      "          Validation Loss (standardized): 1.2189997585999763\n",
      "Epoch: 19, Loss (standarized): 0.19820610095409025\n",
      "          Validation Loss (standardized): 1.2499421592147744\n",
      "Epoch: 20, Loss (standarized): 0.19615899339926907\n",
      "          Validation Loss (standardized): 1.272676342440457\n",
      "Final epoch: 20, Final loss (standarized): 0.19615899339926907\n",
      "Epoch: 1, Loss (standarized): 0.6956377115227472\n",
      "          Validation Loss (standardized): 0.6889254598698612\n",
      "Epoch: 2, Loss (standarized): 0.6384598376683577\n",
      "          Validation Loss (standardized): 0.6887392982527001\n",
      "Epoch: 3, Loss (standarized): 0.58800891312141\n",
      "          Validation Loss (standardized): 0.6926925288633535\n",
      "Epoch: 4, Loss (standarized): 0.5412763720289343\n",
      "          Validation Loss (standardized): 0.700649498924262\n",
      "Epoch: 5, Loss (standarized): 0.4968121845527057\n",
      "          Validation Loss (standardized): 0.7130174616504417\n",
      "Epoch: 6, Loss (standarized): 0.454346056714444\n",
      "          Validation Loss (standardized): 0.7306413893970669\n",
      "Epoch: 7, Loss (standarized): 0.41374187751714797\n",
      "          Validation Loss (standardized): 0.754339290604427\n",
      "Epoch: 8, Loss (standarized): 0.375437745756647\n",
      "          Validation Loss (standardized): 0.7848065100673716\n",
      "Epoch: 9, Loss (standarized): 0.340008220248093\n",
      "          Validation Loss (standardized): 0.822447630857276\n",
      "Epoch: 10, Loss (standarized): 0.3080327541927817\n",
      "          Validation Loss (standardized): 0.8670566421835965\n",
      "Epoch: 11, Loss (standarized): 0.28011759375302314\n",
      "          Validation Loss (standardized): 0.9179000545254482\n",
      "Epoch: 12, Loss (standarized): 0.2566078157664745\n",
      "          Validation Loss (standardized): 0.9732188510942127\n",
      "Epoch: 13, Loss (standarized): 0.23769959084148534\n",
      "          Validation Loss (standardized): 1.0310290880555086\n",
      "Epoch: 14, Loss (standarized): 0.22309531933844348\n",
      "          Validation Loss (standardized): 1.08861021457617\n",
      "Epoch: 15, Loss (standarized): 0.21235765387550498\n",
      "          Validation Loss (standardized): 1.1431317331699642\n",
      "Epoch: 16, Loss (standarized): 0.2048446594899942\n",
      "          Validation Loss (standardized): 1.1921634390542062\n",
      "Epoch: 17, Loss (standarized): 0.19982686349119502\n",
      "          Validation Loss (standardized): 1.2339775607931185\n",
      "Epoch: 18, Loss (standarized): 0.19662084099394617\n",
      "          Validation Loss (standardized): 1.2682619170263973\n",
      "Epoch: 19, Loss (standarized): 0.1946070789905445\n",
      "          Validation Loss (standardized): 1.2947490671879915\n",
      "Epoch: 20, Loss (standarized): 0.19337027991234165\n",
      "          Validation Loss (standardized): 1.313860134414162\n",
      "Final epoch: 20, Final loss (standarized): 0.19337027991234165\n",
      "Epoch: 1, Loss (standarized): 0.7337731678764131\n",
      "          Validation Loss (standardized): 0.6917222129666165\n",
      "Epoch: 2, Loss (standarized): 0.6545515401120531\n",
      "          Validation Loss (standardized): 0.6915207806952371\n",
      "Epoch: 3, Loss (standarized): 0.6090329856023395\n",
      "          Validation Loss (standardized): 0.7002406590932779\n",
      "Epoch: 4, Loss (standarized): 0.5743262361800151\n",
      "          Validation Loss (standardized): 0.7085051764233206\n",
      "Epoch: 5, Loss (standarized): 0.5383851430377946\n",
      "          Validation Loss (standardized): 0.7158554387486589\n",
      "Epoch: 6, Loss (standarized): 0.49948547456636355\n",
      "          Validation Loss (standardized): 0.7248257206185076\n",
      "Epoch: 7, Loss (standarized): 0.4594968455921634\n",
      "          Validation Loss (standardized): 0.737981482726605\n",
      "Epoch: 8, Loss (standarized): 0.4205655445982863\n",
      "          Validation Loss (standardized): 0.7569716358795014\n",
      "Epoch: 9, Loss (standarized): 0.3841996965856687\n",
      "          Validation Loss (standardized): 0.7826477706482713\n",
      "Epoch: 10, Loss (standarized): 0.3508932930689298\n",
      "          Validation Loss (standardized): 0.8152597904549217\n",
      "Epoch: 11, Loss (standarized): 0.32063678861665135\n",
      "          Validation Loss (standardized): 0.8548950383396696\n",
      "Epoch: 12, Loss (standarized): 0.2932232922828274\n",
      "          Validation Loss (standardized): 0.9012866438379745\n",
      "Epoch: 13, Loss (standarized): 0.2688672606248788\n",
      "          Validation Loss (standardized): 0.953881891703242\n",
      "Epoch: 14, Loss (standarized): 0.2479403008171618\n",
      "          Validation Loss (standardized): 1.011558979860534\n",
      "Epoch: 15, Loss (standarized): 0.23078642442753633\n",
      "          Validation Loss (standardized): 1.072565620314454\n",
      "Epoch: 16, Loss (standarized): 0.21745839671258652\n",
      "          Validation Loss (standardized): 1.1348260597597404\n",
      "Epoch: 17, Loss (standarized): 0.2076811170131628\n",
      "          Validation Loss (standardized): 1.195865141086034\n",
      "Epoch: 18, Loss (standarized): 0.20095465893881626\n",
      "          Validation Loss (standardized): 1.2530512045919437\n",
      "Epoch: 19, Loss (standarized): 0.1966682333891344\n",
      "          Validation Loss (standardized): 1.3044457948268233\n",
      "Epoch: 20, Loss (standarized): 0.19416550640440142\n",
      "          Validation Loss (standardized): 1.3484313984115022\n",
      "Final epoch: 20, Final loss (standarized): 0.19416550640440142\n",
      "Epoch: 1, Loss (standarized): 0.7125255779402819\n",
      "          Validation Loss (standardized): 0.6933504214961963\n",
      "Epoch: 2, Loss (standarized): 0.6315443018834246\n",
      "          Validation Loss (standardized): 0.7133226937736135\n",
      "Epoch: 3, Loss (standarized): 0.5827168843154972\n",
      "          Validation Loss (standardized): 0.722049353537193\n",
      "Epoch: 4, Loss (standarized): 0.5230626719327457\n",
      "          Validation Loss (standardized): 0.7303501731197224\n",
      "Epoch: 5, Loss (standarized): 0.4594278339657783\n",
      "          Validation Loss (standardized): 0.7510899492962618\n",
      "Epoch: 6, Loss (standarized): 0.4008803801975468\n",
      "          Validation Loss (standardized): 0.7898164740915334\n",
      "Epoch: 7, Loss (standarized): 0.3495388021893454\n",
      "          Validation Loss (standardized): 0.847644892490503\n",
      "Epoch: 8, Loss (standarized): 0.30416132589596895\n",
      "          Validation Loss (standardized): 0.9252905434953348\n",
      "Epoch: 9, Loss (standarized): 0.26474186060812976\n",
      "          Validation Loss (standardized): 1.023601400758493\n",
      "Epoch: 10, Loss (standarized): 0.233157042410714\n",
      "          Validation Loss (standardized): 1.1415266458750624\n",
      "Epoch: 11, Loss (standarized): 0.2112112576882148\n",
      "          Validation Loss (standardized): 1.2744365433070317\n",
      "Epoch: 12, Loss (standarized): 0.19900545301617484\n",
      "          Validation Loss (standardized): 1.414429059353185\n",
      "Epoch: 13, Loss (standarized): 0.19480868086030942\n",
      "          Validation Loss (standardized): 1.5523129643456048\n",
      "Epoch: 14, Loss (standarized): 0.19604191817157635\n",
      "          Validation Loss (standardized): 1.6797232606752894\n",
      "Epoch: 15, Loss (standarized): 0.20026304534918724\n",
      "          Validation Loss (standardized): 1.7904035182202847\n",
      "Epoch: 16, Loss (standarized): 0.20560692740421332\n",
      "          Validation Loss (standardized): 1.8804337962607698\n",
      "Epoch: 17, Loss (standarized): 0.2108132009469713\n",
      "          Validation Loss (standardized): 1.9479504264849252\n",
      "Epoch: 18, Loss (standarized): 0.215110993735349\n",
      "          Validation Loss (standardized): 1.9927098113165453\n",
      "Epoch: 19, Loss (standarized): 0.21809431893409342\n",
      "          Validation Loss (standardized): 2.0156977875490365\n",
      "Epoch: 20, Loss (standarized): 0.2196241033123173\n",
      "          Validation Loss (standardized): 2.0187802298936828\n",
      "Final epoch: 20, Final loss (standarized): 0.2196241033123173\n",
      "Epoch: 1, Loss (standarized): 0.7198381637327297\n",
      "          Validation Loss (standardized): 0.6922747839128847\n",
      "Epoch: 2, Loss (standarized): 0.6469334453855821\n",
      "          Validation Loss (standardized): 0.6892022953434638\n",
      "Epoch: 3, Loss (standarized): 0.593395218705544\n",
      "          Validation Loss (standardized): 0.6972282663572128\n",
      "Epoch: 4, Loss (standarized): 0.5477971472457216\n",
      "          Validation Loss (standardized): 0.7103850627112567\n",
      "Epoch: 5, Loss (standarized): 0.5013130617417166\n",
      "          Validation Loss (standardized): 0.7279320510302347\n",
      "Epoch: 6, Loss (standarized): 0.4516150768337515\n",
      "          Validation Loss (standardized): 0.7525575061366014\n",
      "Epoch: 7, Loss (standarized): 0.4002490442266989\n",
      "          Validation Loss (standardized): 0.7880696090013082\n",
      "Epoch: 8, Loss (standarized): 0.3500501846616702\n",
      "          Validation Loss (standardized): 0.8382118737841114\n",
      "Epoch: 9, Loss (standarized): 0.3040272916557079\n",
      "          Validation Loss (standardized): 0.9057963138225114\n",
      "Epoch: 10, Loss (standarized): 0.26479521695140584\n",
      "          Validation Loss (standardized): 0.9918631225093723\n",
      "Epoch: 11, Loss (standarized): 0.23413603283043674\n",
      "          Validation Loss (standardized): 1.0948375537532693\n",
      "Epoch: 12, Loss (standarized): 0.21268960613894772\n",
      "          Validation Loss (standardized): 1.2101086368962912\n",
      "Epoch: 13, Loss (standarized): 0.1998723488789956\n",
      "          Validation Loss (standardized): 1.3302148548408013\n",
      "Epoch: 14, Loss (standarized): 0.1941270810866508\n",
      "          Validation Loss (standardized): 1.4462715898271816\n",
      "Epoch: 15, Loss (standarized): 0.19333708824679424\n",
      "          Validation Loss (standardized): 1.5502694727976851\n",
      "Epoch: 16, Loss (standarized): 0.1953408950311731\n",
      "          Validation Loss (standardized): 1.6363755188768294\n",
      "Epoch: 17, Loss (standarized): 0.1983676541514077\n",
      "          Validation Loss (standardized): 1.701245542747107\n",
      "Epoch: 18, Loss (standarized): 0.20121031154852934\n",
      "          Validation Loss (standardized): 1.743727064592928\n",
      "Epoch: 19, Loss (standarized): 0.2031856618650137\n",
      "          Validation Loss (standardized): 1.764404665649672\n",
      "Epoch: 20, Loss (standarized): 0.2040209959660861\n",
      "          Validation Loss (standardized): 1.7651261078435423\n",
      "Final epoch: 20, Final loss (standarized): 0.2040209959660861\n",
      "Epoch: 1, Loss (standarized): 0.8236243566452845\n",
      "          Validation Loss (standardized): 0.7307925684004657\n",
      "Epoch: 2, Loss (standarized): 0.6917375892736097\n",
      "          Validation Loss (standardized): 0.6973262789547321\n",
      "Epoch: 3, Loss (standarized): 0.601306076619206\n",
      "          Validation Loss (standardized): 0.6939913964184027\n",
      "Epoch: 4, Loss (standarized): 0.5419393865216315\n",
      "          Validation Loss (standardized): 0.7122001535922301\n",
      "Epoch: 5, Loss (standarized): 0.500359584295007\n",
      "          Validation Loss (standardized): 0.7419327674825295\n",
      "Epoch: 6, Loss (standarized): 0.46473190033450984\n",
      "          Validation Loss (standardized): 0.7752236327997928\n",
      "Epoch: 7, Loss (standarized): 0.42728353038146855\n",
      "          Validation Loss (standardized): 0.8096853754666953\n",
      "Epoch: 8, Loss (standarized): 0.38602450355715695\n",
      "          Validation Loss (standardized): 0.8475250102275004\n",
      "Epoch: 9, Loss (standarized): 0.3432044613999502\n",
      "          Validation Loss (standardized): 0.8924704275153569\n",
      "Epoch: 10, Loss (standarized): 0.30249650683252793\n",
      "          Validation Loss (standardized): 0.9476353541169441\n",
      "Epoch: 11, Loss (standarized): 0.2671057382491307\n",
      "          Validation Loss (standardized): 1.0145434441399583\n",
      "Epoch: 12, Loss (standarized): 0.2389395612285148\n",
      "          Validation Loss (standardized): 1.0927556252584212\n",
      "Epoch: 13, Loss (standarized): 0.2185110899007539\n",
      "          Validation Loss (standardized): 1.1801618856467113\n",
      "Epoch: 14, Loss (standarized): 0.20523814319886488\n",
      "          Validation Loss (standardized): 1.273494920078065\n",
      "Epoch: 15, Loss (standarized): 0.197892512955393\n",
      "          Validation Loss (standardized): 1.368878328280531\n",
      "Epoch: 16, Loss (standarized): 0.1950205686246947\n",
      "          Validation Loss (standardized): 1.462260453309298\n",
      "Epoch: 17, Loss (standarized): 0.19522578182029135\n",
      "          Validation Loss (standardized): 1.5498521649996377\n",
      "Epoch: 18, Loss (standarized): 0.1973046255940134\n",
      "          Validation Loss (standardized): 1.6285124563073714\n",
      "Epoch: 19, Loss (standarized): 0.20029971417407133\n",
      "          Validation Loss (standardized): 1.6958311188540494\n",
      "Epoch: 20, Loss (standarized): 0.2034961975065901\n",
      "          Validation Loss (standardized): 1.7503329907194385\n",
      "Final epoch: 20, Final loss (standarized): 0.2034961975065901\n",
      "Epoch: 1, Loss (standarized): 0.7244586327231094\n",
      "          Validation Loss (standardized): 0.6915308004006653\n",
      "Epoch: 2, Loss (standarized): 0.6203067754036329\n",
      "          Validation Loss (standardized): 0.6956220233723113\n",
      "Epoch: 3, Loss (standarized): 0.5538581203667368\n",
      "          Validation Loss (standardized): 0.7160466961412386\n",
      "Epoch: 4, Loss (standarized): 0.49365439855723525\n",
      "          Validation Loss (standardized): 0.741984725804871\n",
      "Epoch: 5, Loss (standarized): 0.4272304270257821\n",
      "          Validation Loss (standardized): 0.7797177958835507\n",
      "Epoch: 6, Loss (standarized): 0.36186398517247015\n",
      "          Validation Loss (standardized): 0.8366260091158039\n",
      "Epoch: 7, Loss (standarized): 0.3052630727826298\n",
      "          Validation Loss (standardized): 0.9165758945209826\n",
      "Epoch: 8, Loss (standarized): 0.26108437346479973\n",
      "          Validation Loss (standardized): 1.0193994288113826\n",
      "Epoch: 9, Loss (standarized): 0.2295200449309499\n",
      "          Validation Loss (standardized): 1.1417452771114416\n",
      "Epoch: 10, Loss (standarized): 0.2090574724723537\n",
      "          Validation Loss (standardized): 1.2780322099538477\n",
      "Epoch: 11, Loss (standarized): 0.19786367200984392\n",
      "          Validation Loss (standardized): 1.4206690301988323\n",
      "Epoch: 12, Loss (standarized): 0.19410300907535663\n",
      "          Validation Loss (standardized): 1.5607054970103258\n",
      "Epoch: 13, Loss (standarized): 0.19570928422871453\n",
      "          Validation Loss (standardized): 1.6892622925090057\n",
      "Epoch: 14, Loss (standarized): 0.20044265748661322\n",
      "          Validation Loss (standardized): 1.7989971096091408\n",
      "Epoch: 15, Loss (standarized): 0.2062680099421806\n",
      "          Validation Loss (standardized): 1.8853139809073785\n",
      "Epoch: 16, Loss (standarized): 0.2116855143001059\n",
      "          Validation Loss (standardized): 1.9462693854778035\n",
      "Epoch: 17, Loss (standarized): 0.2157954918294764\n",
      "          Validation Loss (standardized): 1.9821040728745225\n",
      "Epoch: 18, Loss (standarized): 0.2182063668836606\n",
      "          Validation Loss (standardized): 1.9945752035075204\n",
      "Epoch: 19, Loss (standarized): 0.21888813199557483\n",
      "          Validation Loss (standardized): 1.9863410597289641\n",
      "Epoch: 20, Loss (standarized): 0.21803823594698624\n",
      "          Validation Loss (standardized): 1.9604806363449852\n",
      "Final epoch: 20, Final loss (standarized): 0.21803823594698624\n",
      "Epoch: 1, Loss (standarized): 0.7582177528434682\n",
      "          Validation Loss (standardized): 0.7064052900612015\n",
      "Epoch: 2, Loss (standarized): 0.6492946814641727\n",
      "          Validation Loss (standardized): 0.6893037080453026\n",
      "Epoch: 3, Loss (standarized): 0.5808824537374873\n",
      "          Validation Loss (standardized): 0.7001854522762949\n",
      "Epoch: 4, Loss (standarized): 0.5363385575116127\n",
      "          Validation Loss (standardized): 0.7204353463583\n",
      "Epoch: 5, Loss (standarized): 0.4917967223333024\n",
      "          Validation Loss (standardized): 0.7432580413121225\n",
      "Epoch: 6, Loss (standarized): 0.43942932243602084\n",
      "          Validation Loss (standardized): 0.7724179205499676\n",
      "Epoch: 7, Loss (standarized): 0.3837612634652826\n",
      "          Validation Loss (standardized): 0.8136939470897976\n",
      "Epoch: 8, Loss (standarized): 0.33117716858240165\n",
      "          Validation Loss (standardized): 0.8713424091790811\n",
      "Epoch: 9, Loss (standarized): 0.2862077107948146\n",
      "          Validation Loss (standardized): 0.9471431229646836\n",
      "Epoch: 10, Loss (standarized): 0.2509363626182228\n",
      "          Validation Loss (standardized): 1.0404819881522522\n",
      "Epoch: 11, Loss (standarized): 0.2254197495557006\n",
      "          Validation Loss (standardized): 1.1488681722727538\n",
      "Epoch: 12, Loss (standarized): 0.20854367413494396\n",
      "          Validation Loss (standardized): 1.268485276790429\n",
      "Epoch: 13, Loss (standarized): 0.19883871696813754\n",
      "          Validation Loss (standardized): 1.3944901736181043\n",
      "Epoch: 14, Loss (standarized): 0.19487320923734713\n",
      "          Validation Loss (standardized): 1.521185671381284\n",
      "Epoch: 15, Loss (standarized): 0.19525931934856328\n",
      "          Validation Loss (standardized): 1.6424123915852908\n",
      "Epoch: 16, Loss (standarized): 0.19858562926738504\n",
      "          Validation Loss (standardized): 1.7522562001465025\n",
      "Epoch: 17, Loss (standarized): 0.20346944135906078\n",
      "          Validation Loss (standardized): 1.845877098418753\n",
      "Epoch: 18, Loss (standarized): 0.2087026874722689\n",
      "          Validation Loss (standardized): 1.9200537616851217\n",
      "Epoch: 19, Loss (standarized): 0.21337652562183335\n",
      "          Validation Loss (standardized): 1.973294756953726\n",
      "Epoch: 20, Loss (standarized): 0.21692115404652193\n",
      "          Validation Loss (standardized): 2.005611647948716\n",
      "Final epoch: 20, Final loss (standarized): 0.21692115404652193\n",
      "Epoch: 1, Loss (standarized): 0.6997587432428336\n",
      "          Validation Loss (standardized): 0.7028281713669238\n",
      "Epoch: 2, Loss (standarized): 0.6379930687296673\n",
      "          Validation Loss (standardized): 0.6966507346961646\n",
      "Epoch: 3, Loss (standarized): 0.5744162958134318\n",
      "          Validation Loss (standardized): 0.7022636862002731\n",
      "Epoch: 4, Loss (standarized): 0.5176357395666408\n",
      "          Validation Loss (standardized): 0.7170973859266618\n",
      "Epoch: 5, Loss (standarized): 0.45920201005217953\n",
      "          Validation Loss (standardized): 0.7438312923872812\n",
      "Epoch: 6, Loss (standarized): 0.40052786103272225\n",
      "          Validation Loss (standardized): 0.7874831689857829\n",
      "Epoch: 7, Loss (standarized): 0.34624895939042233\n",
      "          Validation Loss (standardized): 0.8502888205179022\n",
      "Epoch: 8, Loss (standarized): 0.2985211338067538\n",
      "          Validation Loss (standardized): 0.9325470460362861\n",
      "Epoch: 9, Loss (standarized): 0.2584505582728388\n",
      "          Validation Loss (standardized): 1.0340759664808603\n",
      "Epoch: 10, Loss (standarized): 0.22769673577033703\n",
      "          Validation Loss (standardized): 1.152990818604547\n",
      "Epoch: 11, Loss (standarized): 0.20756792456653983\n",
      "          Validation Loss (standardized): 1.2838104534643575\n",
      "Epoch: 12, Loss (standarized): 0.19748840674417925\n",
      "          Validation Loss (standardized): 1.4176841969481742\n",
      "Epoch: 13, Loss (standarized): 0.19500168855852926\n",
      "          Validation Loss (standardized): 1.5447499842960366\n",
      "Epoch: 14, Loss (standarized): 0.19706987177376592\n",
      "          Validation Loss (standardized): 1.6565673735492978\n",
      "Epoch: 15, Loss (standarized): 0.20112340063343917\n",
      "          Validation Loss (standardized): 1.7473620911555077\n",
      "Epoch: 16, Loss (standarized): 0.20537531604231163\n",
      "          Validation Loss (standardized): 1.8141945385999128\n",
      "Epoch: 17, Loss (standarized): 0.2087679144798192\n",
      "          Validation Loss (standardized): 1.856518728829755\n",
      "Epoch: 18, Loss (standarized): 0.21081639269714558\n",
      "          Validation Loss (standardized): 1.8755682004386336\n",
      "Epoch: 19, Loss (standarized): 0.21144352720028983\n",
      "          Validation Loss (standardized): 1.8737753949008167\n",
      "Epoch: 20, Loss (standarized): 0.21083423303302873\n",
      "          Validation Loss (standardized): 1.8542782470643884\n",
      "Final epoch: 20, Final loss (standarized): 0.21083423303302873\n",
      "Epoch: 1, Loss (standarized): 0.6964020631565823\n",
      "          Validation Loss (standardized): 0.6884624008362924\n",
      "Epoch: 2, Loss (standarized): 0.642468996190755\n",
      "          Validation Loss (standardized): 0.6896644340394311\n",
      "Epoch: 3, Loss (standarized): 0.5907905487982887\n",
      "          Validation Loss (standardized): 0.6941968813836777\n",
      "Epoch: 4, Loss (standarized): 0.5331956545274225\n",
      "          Validation Loss (standardized): 0.7075815848933383\n",
      "Epoch: 5, Loss (standarized): 0.47385760461720405\n",
      "          Validation Loss (standardized): 0.7339018504472758\n",
      "Epoch: 6, Loss (standarized): 0.4148702851918028\n",
      "          Validation Loss (standardized): 0.7760225019686586\n",
      "Epoch: 7, Loss (standarized): 0.35738775851900584\n",
      "          Validation Loss (standardized): 0.8375827941322115\n",
      "Epoch: 8, Loss (standarized): 0.30377556485521773\n",
      "          Validation Loss (standardized): 0.923265739709054\n",
      "Epoch: 9, Loss (standarized): 0.25796050593803244\n",
      "          Validation Loss (standardized): 1.0365037582332577\n",
      "Epoch: 10, Loss (standarized): 0.2237789858926798\n",
      "          Validation Loss (standardized): 1.1764119261894785\n",
      "Epoch: 11, Loss (standarized): 0.20290355566426277\n",
      "          Validation Loss (standardized): 1.3361980183541384\n",
      "Epoch: 12, Loss (standarized): 0.1940533503732991\n",
      "          Validation Loss (standardized): 1.5043820940000288\n",
      "Epoch: 13, Loss (standarized): 0.19409924351462088\n",
      "          Validation Loss (standardized): 1.6675825190830762\n",
      "Epoch: 14, Loss (standarized): 0.19948561377811194\n",
      "          Validation Loss (standardized): 1.8134834214152038\n",
      "Epoch: 15, Loss (standarized): 0.20702928907435011\n",
      "          Validation Loss (standardized): 1.933199610794515\n",
      "Epoch: 16, Loss (standarized): 0.2143697688479649\n",
      "          Validation Loss (standardized): 2.0220852239578178\n",
      "Epoch: 17, Loss (standarized): 0.2201067430974587\n",
      "          Validation Loss (standardized): 2.0792203211179596\n",
      "Epoch: 18, Loss (standarized): 0.22366679051228275\n",
      "          Validation Loss (standardized): 2.1063876510149067\n",
      "Epoch: 19, Loss (standarized): 0.22506886947958615\n",
      "          Validation Loss (standardized): 2.1071030434627205\n",
      "Epoch: 20, Loss (standarized): 0.22469563518027882\n",
      "          Validation Loss (standardized): 2.085872348669558\n",
      "Final epoch: 20, Final loss (standarized): 0.22469563518027882\n",
      "Epoch: 1, Loss (standarized): 0.8046293963255873\n",
      "          Validation Loss (standardized): 0.7188422789277571\n",
      "Epoch: 2, Loss (standarized): 0.6691793223688401\n",
      "          Validation Loss (standardized): 0.6941284033167598\n",
      "Epoch: 3, Loss (standarized): 0.5803509463633054\n",
      "          Validation Loss (standardized): 0.7052496908545788\n",
      "Epoch: 4, Loss (standarized): 0.5306825215673769\n",
      "          Validation Loss (standardized): 0.7339032352400148\n",
      "Epoch: 5, Loss (standarized): 0.49679468155427564\n",
      "          Validation Loss (standardized): 0.7630536231413041\n",
      "Epoch: 6, Loss (standarized): 0.4575348333719917\n",
      "          Validation Loss (standardized): 0.7901295213782069\n",
      "Epoch: 7, Loss (standarized): 0.408965754661019\n",
      "          Validation Loss (standardized): 0.8210966182829803\n",
      "Epoch: 8, Loss (standarized): 0.35681267965950336\n",
      "          Validation Loss (standardized): 0.8630276703482656\n",
      "Epoch: 9, Loss (standarized): 0.30801782060670574\n",
      "          Validation Loss (standardized): 0.9208329961838292\n",
      "Epoch: 10, Loss (standarized): 0.2674950745391492\n",
      "          Validation Loss (standardized): 0.9960905819170296\n",
      "Epoch: 11, Loss (standarized): 0.23735412202989295\n",
      "          Validation Loss (standardized): 1.0872649459087371\n",
      "Epoch: 12, Loss (standarized): 0.21728617352324045\n",
      "          Validation Loss (standardized): 1.1907827621700786\n",
      "Epoch: 13, Loss (standarized): 0.20559968013440624\n",
      "          Validation Loss (standardized): 1.3020694978805016\n",
      "Epoch: 14, Loss (standarized): 0.20023072573741804\n",
      "          Validation Loss (standardized): 1.4161882285386531\n",
      "Epoch: 15, Loss (standarized): 0.19931445971489026\n",
      "          Validation Loss (standardized): 1.52816211380179\n",
      "Epoch: 16, Loss (standarized): 0.2013271561840604\n",
      "          Validation Loss (standardized): 1.6332292820620182\n",
      "Epoch: 17, Loss (standarized): 0.2050275427446835\n",
      "          Validation Loss (standardized): 1.727174346273526\n",
      "Epoch: 18, Loss (standarized): 0.20939538701039556\n",
      "          Validation Loss (standardized): 1.8066742252918615\n",
      "Epoch: 19, Loss (standarized): 0.213622590417405\n",
      "          Validation Loss (standardized): 1.8695413248551127\n",
      "Epoch: 20, Loss (standarized): 0.217125547121174\n",
      "          Validation Loss (standardized): 1.9147647741572404\n",
      "Final epoch: 20, Final loss (standarized): 0.217125547121174\n",
      "Epoch: 1, Loss (standarized): 0.7932384821621277\n",
      "          Validation Loss (standardized): 0.737692384351185\n",
      "Epoch: 2, Loss (standarized): 0.687625434987461\n",
      "          Validation Loss (standardized): 0.701462133726107\n",
      "Epoch: 3, Loss (standarized): 0.6137540105300764\n",
      "          Validation Loss (standardized): 0.6945847670276312\n",
      "Epoch: 4, Loss (standarized): 0.5701832026667619\n",
      "          Validation Loss (standardized): 0.7076000156566232\n",
      "Epoch: 5, Loss (standarized): 0.5429120851362405\n",
      "          Validation Loss (standardized): 0.725148428303132\n",
      "Epoch: 6, Loss (standarized): 0.512656022671957\n",
      "          Validation Loss (standardized): 0.7409862111740376\n",
      "Epoch: 7, Loss (standarized): 0.4724091182494173\n",
      "          Validation Loss (standardized): 0.7578826654735243\n",
      "Epoch: 8, Loss (standarized): 0.42523857395834824\n",
      "          Validation Loss (standardized): 0.7813100726592094\n",
      "Epoch: 9, Loss (standarized): 0.37670663454674064\n",
      "          Validation Loss (standardized): 0.816222180810247\n",
      "Epoch: 10, Loss (standarized): 0.3316430021316712\n",
      "          Validation Loss (standardized): 0.8658253712336752\n",
      "Epoch: 11, Loss (standarized): 0.2931666914756524\n",
      "          Validation Loss (standardized): 0.9311264570226627\n",
      "Epoch: 12, Loss (standarized): 0.2624844763563542\n",
      "          Validation Loss (standardized): 1.011106451710198\n",
      "Epoch: 13, Loss (standarized): 0.23921142649855154\n",
      "          Validation Loss (standardized): 1.1034421286574883\n",
      "Epoch: 14, Loss (standarized): 0.2221465971248726\n",
      "          Validation Loss (standardized): 1.20531245687614\n",
      "Epoch: 15, Loss (standarized): 0.2101223103417043\n",
      "          Validation Loss (standardized): 1.3137391066335653\n",
      "Epoch: 16, Loss (standarized): 0.2024164445816342\n",
      "          Validation Loss (standardized): 1.425396416302259\n",
      "Epoch: 17, Loss (standarized): 0.1986154350003988\n",
      "          Validation Loss (standardized): 1.5363387517782257\n",
      "Epoch: 18, Loss (standarized): 0.19823994859432648\n",
      "          Validation Loss (standardized): 1.6420999905838385\n",
      "Epoch: 19, Loss (standarized): 0.2005161071000696\n",
      "          Validation Loss (standardized): 1.7382365549473169\n",
      "Epoch: 20, Loss (standarized): 0.2044311588125268\n",
      "          Validation Loss (standardized): 1.8210081526507595\n",
      "Final epoch: 20, Final loss (standarized): 0.2044311588125268\n",
      "Epoch: 1, Loss (standarized): 0.7054927200855571\n",
      "          Validation Loss (standardized): 0.6886947906162504\n",
      "Epoch: 2, Loss (standarized): 0.651175557282635\n",
      "          Validation Loss (standardized): 0.6912890731212493\n",
      "Epoch: 3, Loss (standarized): 0.609001410196509\n",
      "          Validation Loss (standardized): 0.6968825824202999\n",
      "Epoch: 4, Loss (standarized): 0.5666100651524114\n",
      "          Validation Loss (standardized): 0.7038964009290848\n",
      "Epoch: 5, Loss (standarized): 0.520186739549805\n",
      "          Validation Loss (standardized): 0.714834626959269\n",
      "Epoch: 6, Loss (standarized): 0.4706104252062853\n",
      "          Validation Loss (standardized): 0.733134278624977\n",
      "Epoch: 7, Loss (standarized): 0.41976902468757965\n",
      "          Validation Loss (standardized): 0.762530817091648\n",
      "Epoch: 8, Loss (standarized): 0.3696772298538433\n",
      "          Validation Loss (standardized): 0.8068470118829778\n",
      "Epoch: 9, Loss (standarized): 0.32242655105982226\n",
      "          Validation Loss (standardized): 0.8696090928572526\n",
      "Epoch: 10, Loss (standarized): 0.28020251656734163\n",
      "          Validation Loss (standardized): 0.9533372601266996\n",
      "Epoch: 11, Loss (standarized): 0.2451224755353343\n",
      "          Validation Loss (standardized): 1.0584889938578397\n",
      "Epoch: 12, Loss (standarized): 0.21885556493684633\n",
      "          Validation Loss (standardized): 1.1822787302016282\n",
      "Epoch: 13, Loss (standarized): 0.2020752352462379\n",
      "          Validation Loss (standardized): 1.3180500331785816\n",
      "Epoch: 14, Loss (standarized): 0.19404807992579376\n",
      "          Validation Loss (standardized): 1.4560549039952522\n",
      "Epoch: 15, Loss (standarized): 0.19276771846159604\n",
      "          Validation Loss (standardized): 1.5856921071774857\n",
      "Epoch: 16, Loss (standarized): 0.1956417434306847\n",
      "          Validation Loss (standardized): 1.6979817227446687\n",
      "Epoch: 17, Loss (standarized): 0.20027429098846738\n",
      "          Validation Loss (standardized): 1.7869873699639618\n",
      "Epoch: 18, Loss (standarized): 0.20491539011705218\n",
      "          Validation Loss (standardized): 1.8499725095833788\n",
      "Epoch: 19, Loss (standarized): 0.20853053575850286\n",
      "          Validation Loss (standardized): 1.8868266144088137\n",
      "Epoch: 20, Loss (standarized): 0.21066828088351566\n",
      "          Validation Loss (standardized): 1.899298625943316\n",
      "Final epoch: 20, Final loss (standarized): 0.21066828088351566\n",
      "Epoch: 1, Loss (standarized): 0.8519416113995293\n",
      "          Validation Loss (standardized): 0.7547434781785057\n",
      "Epoch: 2, Loss (standarized): 0.675736902362679\n",
      "          Validation Loss (standardized): 0.7014314398265469\n",
      "Epoch: 3, Loss (standarized): 0.5638531496765895\n",
      "          Validation Loss (standardized): 0.7011328058699803\n",
      "Epoch: 4, Loss (standarized): 0.5055067250242307\n",
      "          Validation Loss (standardized): 0.7315271334559745\n",
      "Epoch: 5, Loss (standarized): 0.47175898755764845\n",
      "          Validation Loss (standardized): 0.7679442275314509\n",
      "Epoch: 6, Loss (standarized): 0.43398753079184954\n",
      "          Validation Loss (standardized): 0.8039029549504998\n",
      "Epoch: 7, Loss (standarized): 0.38545979466330793\n",
      "          Validation Loss (standardized): 0.8450121196630114\n",
      "Epoch: 8, Loss (standarized): 0.3327730780726165\n",
      "          Validation Loss (standardized): 0.8987157468353252\n",
      "Epoch: 9, Loss (standarized): 0.28458017091309123\n",
      "          Validation Loss (standardized): 0.969431868332575\n",
      "Epoch: 10, Loss (standarized): 0.2467205654039105\n",
      "          Validation Loss (standardized): 1.0571561865911565\n",
      "Epoch: 11, Loss (standarized): 0.22090754361284953\n",
      "          Validation Loss (standardized): 1.1583697106156108\n",
      "Epoch: 12, Loss (standarized): 0.20568399225423192\n",
      "          Validation Loss (standardized): 1.2679106168820022\n",
      "Epoch: 13, Loss (standarized): 0.19832384156522398\n",
      "          Validation Loss (standardized): 1.3803960330885312\n",
      "Epoch: 14, Loss (standarized): 0.19621868638272555\n",
      "          Validation Loss (standardized): 1.4908331791280798\n",
      "Epoch: 15, Loss (standarized): 0.19736244400020408\n",
      "          Validation Loss (standardized): 1.59480599001466\n",
      "Epoch: 16, Loss (standarized): 0.20032279806320735\n",
      "          Validation Loss (standardized): 1.6885957200256683\n",
      "Epoch: 17, Loss (standarized): 0.2040845048857224\n",
      "          Validation Loss (standardized): 1.7693316254856282\n",
      "Epoch: 18, Loss (standarized): 0.20792622956667578\n",
      "          Validation Loss (standardized): 1.8351091599073606\n",
      "Epoch: 19, Loss (standarized): 0.21135164426356962\n",
      "          Validation Loss (standardized): 1.8850035393731617\n",
      "Epoch: 20, Loss (standarized): 0.2140497056602857\n",
      "          Validation Loss (standardized): 1.9189722236094382\n",
      "Final epoch: 20, Final loss (standarized): 0.2140497056602857\n",
      "Epoch: 1, Loss (standarized): 0.7676041610985574\n",
      "          Validation Loss (standardized): 0.7036909311980437\n",
      "Epoch: 2, Loss (standarized): 0.6616973198480626\n",
      "          Validation Loss (standardized): 0.6902793410617395\n",
      "Epoch: 3, Loss (standarized): 0.5908682104049467\n",
      "          Validation Loss (standardized): 0.6999934706941647\n",
      "Epoch: 4, Loss (standarized): 0.5431945281755849\n",
      "          Validation Loss (standardized): 0.7212436884529099\n",
      "Epoch: 5, Loss (standarized): 0.5027917350119201\n",
      "          Validation Loss (standardized): 0.7460424020881384\n",
      "Epoch: 6, Loss (standarized): 0.4590329706467784\n",
      "          Validation Loss (standardized): 0.7737143495260347\n",
      "Epoch: 7, Loss (standarized): 0.4102895555529129\n",
      "          Validation Loss (standardized): 0.8079762417801527\n",
      "Epoch: 8, Loss (standarized): 0.35991711749257316\n",
      "          Validation Loss (standardized): 0.8534223095787697\n",
      "Epoch: 9, Loss (standarized): 0.31240491128279285\n",
      "          Validation Loss (standardized): 0.9137227411170161\n",
      "Epoch: 10, Loss (standarized): 0.2715232997943858\n",
      "          Validation Loss (standardized): 0.990745673389644\n",
      "Epoch: 11, Loss (standarized): 0.2395406851029311\n",
      "          Validation Loss (standardized): 1.084160389968664\n",
      "Epoch: 12, Loss (standarized): 0.2170777628344241\n",
      "          Validation Loss (standardized): 1.191464796114373\n",
      "Epoch: 13, Loss (standarized): 0.20340246893632466\n",
      "          Validation Loss (standardized): 1.3083702135819755\n",
      "Epoch: 14, Loss (standarized): 0.19695945634163434\n",
      "          Validation Loss (standardized): 1.4293995547811726\n",
      "Epoch: 15, Loss (standarized): 0.19589141772256474\n",
      "          Validation Loss (standardized): 1.5485644692919127\n",
      "Epoch: 16, Loss (standarized): 0.19838874071831367\n",
      "          Validation Loss (standardized): 1.6600527260486797\n",
      "Epoch: 17, Loss (standarized): 0.20286357783822234\n",
      "          Validation Loss (standardized): 1.758862994472706\n",
      "Epoch: 18, Loss (standarized): 0.20802627965451326\n",
      "          Validation Loss (standardized): 1.8412735133130662\n",
      "Epoch: 19, Loss (standarized): 0.2129165096068745\n",
      "          Validation Loss (standardized): 1.9050433219798573\n",
      "Epoch: 20, Loss (standarized): 0.21689964690876654\n",
      "          Validation Loss (standardized): 1.9493478998206288\n",
      "Final epoch: 20, Final loss (standarized): 0.21689964690876654\n",
      "Epoch: 1, Loss (standarized): 0.7164756771218589\n",
      "          Validation Loss (standardized): 0.7073808903402758\n",
      "Epoch: 2, Loss (standarized): 0.6573664434061561\n",
      "          Validation Loss (standardized): 0.6991520110792103\n",
      "Epoch: 3, Loss (standarized): 0.6083061224275389\n",
      "          Validation Loss (standardized): 0.6965391291027538\n",
      "Epoch: 4, Loss (standarized): 0.5652963324302492\n",
      "          Validation Loss (standardized): 0.6984969369291762\n",
      "Epoch: 5, Loss (standarized): 0.5255212989342908\n",
      "          Validation Loss (standardized): 0.7047346164443195\n",
      "Epoch: 6, Loss (standarized): 0.4873177057036063\n",
      "          Validation Loss (standardized): 0.715315255227097\n",
      "Epoch: 7, Loss (standarized): 0.4501631643362298\n",
      "          Validation Loss (standardized): 0.7305522701440451\n",
      "Epoch: 8, Loss (standarized): 0.4143290308804687\n",
      "          Validation Loss (standardized): 0.7510184475532731\n",
      "Epoch: 9, Loss (standarized): 0.3798797329200537\n",
      "          Validation Loss (standardized): 0.7772636767888015\n",
      "Epoch: 10, Loss (standarized): 0.34728149458500834\n",
      "          Validation Loss (standardized): 0.809684625535328\n",
      "Epoch: 11, Loss (standarized): 0.31709546929445576\n",
      "          Validation Loss (standardized): 0.8484055287149462\n",
      "Epoch: 12, Loss (standarized): 0.28986701652614605\n",
      "          Validation Loss (standardized): 0.893053596678823\n",
      "Epoch: 13, Loss (standarized): 0.2661468735438764\n",
      "          Validation Loss (standardized): 0.9428638616163575\n",
      "Epoch: 14, Loss (standarized): 0.24620797016428167\n",
      "          Validation Loss (standardized): 0.9964783099072092\n",
      "Epoch: 15, Loss (standarized): 0.23010722994931154\n",
      "          Validation Loss (standardized): 1.0518287164806548\n",
      "Epoch: 16, Loss (standarized): 0.2177098498414449\n",
      "          Validation Loss (standardized): 1.1067650903730684\n",
      "Epoch: 17, Loss (standarized): 0.20859387796325726\n",
      "          Validation Loss (standardized): 1.1587402161265261\n",
      "Epoch: 18, Loss (standarized): 0.20222473793815146\n",
      "          Validation Loss (standardized): 1.2060093647394234\n",
      "Epoch: 19, Loss (standarized): 0.1979621294384177\n",
      "          Validation Loss (standardized): 1.2467235798306253\n",
      "Epoch: 20, Loss (standarized): 0.19526983249979685\n",
      "          Validation Loss (standardized): 1.2803078941271084\n",
      "Final epoch: 20, Final loss (standarized): 0.19526983249979685\n",
      "Epoch: 1, Loss (standarized): 0.6976055309098738\n",
      "          Validation Loss (standardized): 0.6894274293390701\n",
      "Epoch: 2, Loss (standarized): 0.6302363592169531\n",
      "          Validation Loss (standardized): 0.6910634170562733\n",
      "Epoch: 3, Loss (standarized): 0.5741993800841878\n",
      "          Validation Loss (standardized): 0.6980122584886042\n",
      "Epoch: 4, Loss (standarized): 0.5241275196219752\n",
      "          Validation Loss (standardized): 0.7090521851068686\n",
      "Epoch: 5, Loss (standarized): 0.4774856355178915\n",
      "          Validation Loss (standardized): 0.7247093365689434\n",
      "Epoch: 6, Loss (standarized): 0.4337113051679652\n",
      "          Validation Loss (standardized): 0.7457404195471881\n",
      "Epoch: 7, Loss (standarized): 0.39302270468061384\n",
      "          Validation Loss (standardized): 0.7727501622279411\n",
      "Epoch: 8, Loss (standarized): 0.3557964589093635\n",
      "          Validation Loss (standardized): 0.8060929538161331\n",
      "Epoch: 9, Loss (standarized): 0.3224362471568063\n",
      "          Validation Loss (standardized): 0.8459518448388491\n",
      "Epoch: 10, Loss (standarized): 0.2931016956469508\n",
      "          Validation Loss (standardized): 0.8917907666185382\n",
      "Epoch: 11, Loss (standarized): 0.26804833311718596\n",
      "          Validation Loss (standardized): 0.9424701777079464\n",
      "Epoch: 12, Loss (standarized): 0.24739474111025628\n",
      "          Validation Loss (standardized): 0.996079783905254\n",
      "Epoch: 13, Loss (standarized): 0.23106223104384366\n",
      "          Validation Loss (standardized): 1.050394346298691\n",
      "Epoch: 14, Loss (standarized): 0.21865576540434112\n",
      "          Validation Loss (standardized): 1.1029743645064163\n",
      "Epoch: 15, Loss (standarized): 0.20962366037017796\n",
      "          Validation Loss (standardized): 1.151133681323653\n",
      "Epoch: 16, Loss (standarized): 0.20336126893512518\n",
      "          Validation Loss (standardized): 1.1923499209618782\n",
      "Epoch: 17, Loss (standarized): 0.19922872923920296\n",
      "          Validation Loss (standardized): 1.2253729824794468\n",
      "Epoch: 18, Loss (standarized): 0.19659552211638087\n",
      "          Validation Loss (standardized): 1.2491038161998662\n",
      "Epoch: 19, Loss (standarized): 0.1950136074852941\n",
      "          Validation Loss (standardized): 1.2630899884459361\n",
      "Epoch: 20, Loss (standarized): 0.1941579953276699\n",
      "          Validation Loss (standardized): 1.2686634234003187\n",
      "Final epoch: 20, Final loss (standarized): 0.1941579953276699\n",
      "Epoch: 1, Loss (standarized): 0.7356402695849851\n",
      "          Validation Loss (standardized): 0.7068534186317499\n",
      "Epoch: 2, Loss (standarized): 0.6453124896653173\n",
      "          Validation Loss (standardized): 0.6932248678137856\n",
      "Epoch: 3, Loss (standarized): 0.5820204901990618\n",
      "          Validation Loss (standardized): 0.6940279684656017\n",
      "Epoch: 4, Loss (standarized): 0.5327622708556966\n",
      "          Validation Loss (standardized): 0.7027466874747086\n",
      "Epoch: 5, Loss (standarized): 0.48912067655693353\n",
      "          Validation Loss (standardized): 0.7168749753460335\n",
      "Epoch: 6, Loss (standarized): 0.4475669437319638\n",
      "          Validation Loss (standardized): 0.7361889922401547\n",
      "Epoch: 7, Loss (standarized): 0.40754922002624855\n",
      "          Validation Loss (standardized): 0.761289407850527\n",
      "Epoch: 8, Loss (standarized): 0.36971016909612126\n",
      "          Validation Loss (standardized): 0.7929208161682181\n",
      "Epoch: 9, Loss (standarized): 0.3348548707096787\n",
      "          Validation Loss (standardized): 0.8313953402155835\n",
      "Epoch: 10, Loss (standarized): 0.30382360335417624\n",
      "          Validation Loss (standardized): 0.8763529885259635\n",
      "Epoch: 11, Loss (standarized): 0.2771977706362747\n",
      "          Validation Loss (standardized): 0.9270704138873529\n",
      "Epoch: 12, Loss (standarized): 0.2550201465017378\n",
      "          Validation Loss (standardized): 0.9822631099656146\n",
      "Epoch: 13, Loss (standarized): 0.23713819982941042\n",
      "          Validation Loss (standardized): 1.0396577687905642\n",
      "Epoch: 14, Loss (standarized): 0.22330766582925074\n",
      "          Validation Loss (standardized): 1.09740423623761\n",
      "Epoch: 15, Loss (standarized): 0.21294203114608998\n",
      "          Validation Loss (standardized): 1.1531303120093517\n",
      "Epoch: 16, Loss (standarized): 0.20549291603759173\n",
      "          Validation Loss (standardized): 1.205003925570049\n",
      "Epoch: 17, Loss (standarized): 0.20034822545561487\n",
      "          Validation Loss (standardized): 1.2508866471008198\n",
      "Epoch: 18, Loss (standarized): 0.19697033182834656\n",
      "          Validation Loss (standardized): 1.2896236961281011\n",
      "Epoch: 19, Loss (standarized): 0.1948356055818512\n",
      "          Validation Loss (standardized): 1.320453093213966\n",
      "Epoch: 20, Loss (standarized): 0.19352317854117443\n",
      "          Validation Loss (standardized): 1.343183260393006\n",
      "Final epoch: 20, Final loss (standarized): 0.19352317854117443\n",
      "Epoch: 1, Loss (standarized): 0.7424491293665125\n",
      "          Validation Loss (standardized): 0.6917154113888102\n",
      "Epoch: 2, Loss (standarized): 0.6299755313189483\n",
      "          Validation Loss (standardized): 0.6923817071172559\n",
      "Epoch: 3, Loss (standarized): 0.5654128847455842\n",
      "          Validation Loss (standardized): 0.7055846286427845\n",
      "Epoch: 4, Loss (standarized): 0.5155958720442162\n",
      "          Validation Loss (standardized): 0.7207917325521995\n",
      "Epoch: 5, Loss (standarized): 0.46805841623085026\n",
      "          Validation Loss (standardized): 0.7381211880562705\n",
      "Epoch: 6, Loss (standarized): 0.4217950428755334\n",
      "          Validation Loss (standardized): 0.7604061073427786\n",
      "Epoch: 7, Loss (standarized): 0.37849767378783206\n",
      "          Validation Loss (standardized): 0.7899086311284901\n",
      "Epoch: 8, Loss (standarized): 0.33970464098824843\n",
      "          Validation Loss (standardized): 0.8275965995706173\n",
      "Epoch: 9, Loss (standarized): 0.3061580033434076\n",
      "          Validation Loss (standardized): 0.8734504956435464\n",
      "Epoch: 10, Loss (standarized): 0.2778350305239209\n",
      "          Validation Loss (standardized): 0.9266158480493505\n",
      "Epoch: 11, Loss (standarized): 0.2544881439069131\n",
      "          Validation Loss (standardized): 0.98567286758944\n",
      "Epoch: 12, Loss (standarized): 0.23574628611707865\n",
      "          Validation Loss (standardized): 1.0489981048448567\n",
      "Epoch: 13, Loss (standarized): 0.22115148854657513\n",
      "          Validation Loss (standardized): 1.11395106405636\n",
      "Epoch: 14, Loss (standarized): 0.21037328140347225\n",
      "          Validation Loss (standardized): 1.1777156796910853\n",
      "Epoch: 15, Loss (standarized): 0.2028564809357401\n",
      "          Validation Loss (standardized): 1.2375275363197349\n",
      "Epoch: 16, Loss (standarized): 0.1979669457717007\n",
      "          Validation Loss (standardized): 1.2909915283603504\n",
      "Epoch: 17, Loss (standarized): 0.19502166629833845\n",
      "          Validation Loss (standardized): 1.3365596396279409\n",
      "Epoch: 18, Loss (standarized): 0.1933969564493398\n",
      "          Validation Loss (standardized): 1.3726983280100695\n",
      "Epoch: 19, Loss (standarized): 0.1925980302089572\n",
      "          Validation Loss (standardized): 1.3990813220895957\n",
      "Epoch: 20, Loss (standarized): 0.19224189096195904\n",
      "          Validation Loss (standardized): 1.4161227150685172\n",
      "Final epoch: 20, Final loss (standarized): 0.19224189096195904\n",
      "Epoch: 1, Loss (standarized): 0.7210199846067429\n",
      "          Validation Loss (standardized): 0.6953713925873524\n",
      "Epoch: 2, Loss (standarized): 0.6397803759933918\n",
      "          Validation Loss (standardized): 0.6902126615916293\n",
      "Epoch: 3, Loss (standarized): 0.5877305765719556\n",
      "          Validation Loss (standardized): 0.699059674850379\n",
      "Epoch: 4, Loss (standarized): 0.5434521376138611\n",
      "          Validation Loss (standardized): 0.7113906786532169\n",
      "Epoch: 5, Loss (standarized): 0.49279419961540194\n",
      "          Validation Loss (standardized): 0.7288916112637611\n",
      "Epoch: 6, Loss (standarized): 0.43715881911086496\n",
      "          Validation Loss (standardized): 0.7570527683519707\n",
      "Epoch: 7, Loss (standarized): 0.3820941266761672\n",
      "          Validation Loss (standardized): 0.8006217213754308\n",
      "Epoch: 8, Loss (standarized): 0.33221962774959574\n",
      "          Validation Loss (standardized): 0.8621329435902458\n",
      "Epoch: 9, Loss (standarized): 0.29001461479813423\n",
      "          Validation Loss (standardized): 0.9416828896730991\n",
      "Epoch: 10, Loss (standarized): 0.2560336192598342\n",
      "          Validation Loss (standardized): 1.0376069522238014\n",
      "Epoch: 11, Loss (standarized): 0.22993014884862825\n",
      "          Validation Loss (standardized): 1.1471367572957696\n",
      "Epoch: 12, Loss (standarized): 0.2113516166499789\n",
      "          Validation Loss (standardized): 1.2664180922543435\n",
      "Epoch: 13, Loss (standarized): 0.19994270941647327\n",
      "          Validation Loss (standardized): 1.389948691777219\n",
      "Epoch: 14, Loss (standarized): 0.19488091559298606\n",
      "          Validation Loss (standardized): 1.5109923829821468\n",
      "Epoch: 15, Loss (standarized): 0.19467503924238008\n",
      "          Validation Loss (standardized): 1.6228730542489456\n",
      "Epoch: 16, Loss (standarized): 0.19749960178579126\n",
      "          Validation Loss (standardized): 1.7199773554584399\n",
      "Epoch: 17, Loss (standarized): 0.20165785406469336\n",
      "          Validation Loss (standardized): 1.798555361159048\n",
      "Epoch: 18, Loss (standarized): 0.20587787552995168\n",
      "          Validation Loss (standardized): 1.8569837456755744\n",
      "Epoch: 19, Loss (standarized): 0.20938848012069494\n",
      "          Validation Loss (standardized): 1.8951589764707446\n",
      "Epoch: 20, Loss (standarized): 0.21182048585345464\n",
      "          Validation Loss (standardized): 1.914297940904411\n",
      "Final epoch: 20, Final loss (standarized): 0.21182048585345464\n",
      "Epoch: 1, Loss (standarized): 0.8024701822089799\n",
      "          Validation Loss (standardized): 0.722470048481627\n",
      "Epoch: 2, Loss (standarized): 0.668370586512489\n",
      "          Validation Loss (standardized): 0.6930161795757761\n",
      "Epoch: 3, Loss (standarized): 0.5797511411439137\n",
      "          Validation Loss (standardized): 0.6994067800119146\n",
      "Epoch: 4, Loss (standarized): 0.526997812155875\n",
      "          Validation Loss (standardized): 0.7240587644471009\n",
      "Epoch: 5, Loss (standarized): 0.48973892220070736\n",
      "          Validation Loss (standardized): 0.7521869703649878\n",
      "Epoch: 6, Loss (standarized): 0.4517787043458677\n",
      "          Validation Loss (standardized): 0.7795797747592985\n",
      "Epoch: 7, Loss (standarized): 0.4085809013883899\n",
      "          Validation Loss (standardized): 0.8090460113365578\n",
      "Epoch: 8, Loss (standarized): 0.3629911943574782\n",
      "          Validation Loss (standardized): 0.8451317095666405\n",
      "Epoch: 9, Loss (standarized): 0.31976807178082495\n",
      "          Validation Loss (standardized): 0.8912814702138894\n",
      "Epoch: 10, Loss (standarized): 0.2827263705813625\n",
      "          Validation Loss (standardized): 0.9487915212190626\n",
      "Epoch: 11, Loss (standarized): 0.2536585957210093\n",
      "          Validation Loss (standardized): 1.0168306735346182\n",
      "Epoch: 12, Loss (standarized): 0.2324725153017079\n",
      "          Validation Loss (standardized): 1.0931423890843406\n",
      "Epoch: 13, Loss (standarized): 0.21794486540772612\n",
      "          Validation Loss (standardized): 1.1747340748149866\n",
      "Epoch: 14, Loss (standarized): 0.20853938888332535\n",
      "          Validation Loss (standardized): 1.2583927143355695\n",
      "Epoch: 15, Loss (standarized): 0.2028891928707487\n",
      "          Validation Loss (standardized): 1.3409521424518973\n",
      "Epoch: 16, Loss (standarized): 0.1999289407979947\n",
      "          Validation Loss (standardized): 1.4193942289424732\n",
      "Epoch: 17, Loss (standarized): 0.1988418150615573\n",
      "          Validation Loss (standardized): 1.4911124176246346\n",
      "Epoch: 18, Loss (standarized): 0.1989714336791835\n",
      "          Validation Loss (standardized): 1.5538754691731043\n",
      "Epoch: 19, Loss (standarized): 0.1997779494640004\n",
      "          Validation Loss (standardized): 1.6060078897047438\n",
      "Epoch: 20, Loss (standarized): 0.20081983464604836\n",
      "          Validation Loss (standardized): 1.646509197805625\n",
      "Final epoch: 20, Final loss (standarized): 0.20081983464604836\n",
      "Epoch: 1, Loss (standarized): 0.6979473096621797\n",
      "          Validation Loss (standardized): 0.6949791266857994\n",
      "Epoch: 2, Loss (standarized): 0.6424864559119197\n",
      "          Validation Loss (standardized): 0.6962571259829153\n",
      "Epoch: 3, Loss (standarized): 0.5908155389962639\n",
      "          Validation Loss (standardized): 0.697223173239087\n",
      "Epoch: 4, Loss (standarized): 0.534318645267397\n",
      "          Validation Loss (standardized): 0.7060625151497448\n",
      "Epoch: 5, Loss (standarized): 0.47741947865667034\n",
      "          Validation Loss (standardized): 0.7272099532158388\n",
      "Epoch: 6, Loss (standarized): 0.421074545861179\n",
      "          Validation Loss (standardized): 0.7634045812921174\n",
      "Epoch: 7, Loss (standarized): 0.36584456387560454\n",
      "          Validation Loss (standardized): 0.8177630632341304\n",
      "Epoch: 8, Loss (standarized): 0.3139120983828851\n",
      "          Validation Loss (standardized): 0.8937725639304991\n",
      "Epoch: 9, Loss (standarized): 0.2687365693160906\n",
      "          Validation Loss (standardized): 0.993545687902237\n",
      "Epoch: 10, Loss (standarized): 0.23355724715751122\n",
      "          Validation Loss (standardized): 1.1156654789054874\n",
      "Epoch: 11, Loss (standarized): 0.20985431305033808\n",
      "          Validation Loss (standardized): 1.2544439110604453\n",
      "Epoch: 12, Loss (standarized): 0.19695613162179526\n",
      "          Validation Loss (standardized): 1.4008861583950727\n",
      "Epoch: 13, Loss (standarized): 0.19272074792678018\n",
      "          Validation Loss (standardized): 1.5444430430527678\n",
      "Epoch: 14, Loss (standarized): 0.19438587022463588\n",
      "          Validation Loss (standardized): 1.6751202577803026\n",
      "Epoch: 15, Loss (standarized): 0.19921711549304452\n",
      "          Validation Loss (standardized): 1.7852822773737242\n",
      "Epoch: 16, Loss (standarized): 0.2049812202035555\n",
      "          Validation Loss (standardized): 1.8703166838091716\n",
      "Epoch: 17, Loss (standarized): 0.21015558543028637\n",
      "          Validation Loss (standardized): 1.9283878223858764\n",
      "Epoch: 18, Loss (standarized): 0.21389590511986487\n",
      "          Validation Loss (standardized): 1.9601809208508651\n",
      "Epoch: 19, Loss (standarized): 0.21591335627191555\n",
      "          Validation Loss (standardized): 1.9679176859624894\n",
      "Epoch: 20, Loss (standarized): 0.21628267879482155\n",
      "          Validation Loss (standardized): 1.9547999856060512\n",
      "Final epoch: 20, Final loss (standarized): 0.21628267879482155\n",
      "Epoch: 1, Loss (standarized): 0.7214298789269575\n",
      "          Validation Loss (standardized): 0.6941505117073197\n",
      "Epoch: 2, Loss (standarized): 0.6350596454718286\n",
      "          Validation Loss (standardized): 0.6917974715050795\n",
      "Epoch: 3, Loss (standarized): 0.5828781747713795\n",
      "          Validation Loss (standardized): 0.6986977949235533\n",
      "Epoch: 4, Loss (standarized): 0.5330233117261267\n",
      "          Validation Loss (standardized): 0.7104018654502886\n",
      "Epoch: 5, Loss (standarized): 0.47657863429297964\n",
      "          Validation Loss (standardized): 0.7314551255124851\n",
      "Epoch: 6, Loss (standarized): 0.4179317160224377\n",
      "          Validation Loss (standardized): 0.7671477247739489\n",
      "Epoch: 7, Loss (standarized): 0.36227369667806175\n",
      "          Validation Loss (standardized): 0.8210775714095198\n",
      "Epoch: 8, Loss (standarized): 0.3130534104766964\n",
      "          Validation Loss (standardized): 0.8947282805751491\n",
      "Epoch: 9, Loss (standarized): 0.27204651633632804\n",
      "          Validation Loss (standardized): 0.9874539900678492\n",
      "Epoch: 10, Loss (standarized): 0.23982239302773334\n",
      "          Validation Loss (standardized): 1.0969786857634296\n",
      "Epoch: 11, Loss (standarized): 0.21638464009112557\n",
      "          Validation Loss (standardized): 1.2195575161430698\n",
      "Epoch: 12, Loss (standarized): 0.20145444008073896\n",
      "          Validation Loss (standardized): 1.349771397573689\n",
      "Epoch: 13, Loss (standarized): 0.19421861298151644\n",
      "          Validation Loss (standardized): 1.480760577259409\n",
      "Epoch: 14, Loss (standarized): 0.19312696119276357\n",
      "          Validation Loss (standardized): 1.6050823559555014\n",
      "Epoch: 15, Loss (standarized): 0.19612079263242688\n",
      "          Validation Loss (standardized): 1.7159357217754183\n",
      "Epoch: 16, Loss (standarized): 0.20112932997183922\n",
      "          Validation Loss (standardized): 1.8084087370991313\n",
      "Epoch: 17, Loss (standarized): 0.2064995831533288\n",
      "          Validation Loss (standardized): 1.8796360935213305\n",
      "Epoch: 18, Loss (standarized): 0.21114306353899234\n",
      "          Validation Loss (standardized): 1.9287716504187526\n",
      "Epoch: 19, Loss (standarized): 0.21448622054129723\n",
      "          Validation Loss (standardized): 1.956506787255843\n",
      "Epoch: 20, Loss (standarized): 0.21634133084588975\n",
      "          Validation Loss (standardized): 1.9645508785069887\n",
      "Final epoch: 20, Final loss (standarized): 0.21634133084588975\n",
      "Epoch: 1, Loss (standarized): 0.8460181353575997\n",
      "          Validation Loss (standardized): 0.7603579185895936\n",
      "Epoch: 2, Loss (standarized): 0.6977772901421357\n",
      "          Validation Loss (standardized): 0.7090849992725069\n",
      "Epoch: 3, Loss (standarized): 0.5877303894185455\n",
      "          Validation Loss (standardized): 0.6979389227290156\n",
      "Epoch: 4, Loss (standarized): 0.5181581511337505\n",
      "          Validation Loss (standardized): 0.7203519764662005\n",
      "Epoch: 5, Loss (standarized): 0.47726079244072506\n",
      "          Validation Loss (standardized): 0.757390603116595\n",
      "Epoch: 6, Loss (standarized): 0.44131256870453495\n",
      "          Validation Loss (standardized): 0.7973052363504922\n",
      "Epoch: 7, Loss (standarized): 0.3983039702429122\n",
      "          Validation Loss (standardized): 0.8404427653428421\n",
      "Epoch: 8, Loss (standarized): 0.3501821845060249\n",
      "          Validation Loss (standardized): 0.8914028443954795\n",
      "Epoch: 9, Loss (standarized): 0.3031794026182046\n",
      "          Validation Loss (standardized): 0.9543431459068205\n",
      "Epoch: 10, Loss (standarized): 0.2628959754333996\n",
      "          Validation Loss (standardized): 1.0310573527685176\n",
      "Epoch: 11, Loss (standarized): 0.2324484831287499\n",
      "          Validation Loss (standardized): 1.1205919745321347\n",
      "Epoch: 12, Loss (standarized): 0.21224630550202106\n",
      "          Validation Loss (standardized): 1.2199149000110732\n",
      "Epoch: 13, Loss (standarized): 0.20086676213616605\n",
      "          Validation Loss (standardized): 1.3248842807526733\n",
      "Epoch: 14, Loss (standarized): 0.19617731026287374\n",
      "          Validation Loss (standardized): 1.4309635102472982\n",
      "Epoch: 15, Loss (standarized): 0.1960702707700412\n",
      "          Validation Loss (standardized): 1.533647879581317\n",
      "Epoch: 16, Loss (standarized): 0.19876547035989478\n",
      "          Validation Loss (standardized): 1.6288036306649267\n",
      "Epoch: 17, Loss (standarized): 0.2028737212734871\n",
      "          Validation Loss (standardized): 1.7129772430196186\n",
      "Epoch: 18, Loss (standarized): 0.20736870350199807\n",
      "          Validation Loss (standardized): 1.783623318385782\n",
      "Epoch: 19, Loss (standarized): 0.21153502187875295\n",
      "          Validation Loss (standardized): 1.8391849395495092\n",
      "Epoch: 20, Loss (standarized): 0.2149128366302319\n",
      "          Validation Loss (standardized): 1.8790545307066078\n",
      "Final epoch: 20, Final loss (standarized): 0.2149128366302319\n",
      "Epoch: 1, Loss (standarized): 0.7341496837084908\n",
      "          Validation Loss (standardized): 0.6901110103146836\n",
      "Epoch: 2, Loss (standarized): 0.629409134817727\n",
      "          Validation Loss (standardized): 0.6991025727125151\n",
      "Epoch: 3, Loss (standarized): 0.5732931133355113\n",
      "          Validation Loss (standardized): 0.7182170284111788\n",
      "Epoch: 4, Loss (standarized): 0.5266276713783912\n",
      "          Validation Loss (standardized): 0.7326082057759896\n",
      "Epoch: 5, Loss (standarized): 0.4712023476863689\n",
      "          Validation Loss (standardized): 0.7493700223555719\n",
      "Epoch: 6, Loss (standarized): 0.41287298661849914\n",
      "          Validation Loss (standardized): 0.7771245528030424\n",
      "Epoch: 7, Loss (standarized): 0.35954292522488696\n",
      "          Validation Loss (standardized): 0.8205603269181709\n",
      "Epoch: 8, Loss (standarized): 0.31512886089909137\n",
      "          Validation Loss (standardized): 0.8802849691243587\n",
      "Epoch: 9, Loss (standarized): 0.27957023236712336\n",
      "          Validation Loss (standardized): 0.9545379983657029\n",
      "Epoch: 10, Loss (standarized): 0.2511361975850101\n",
      "          Validation Loss (standardized): 1.0410337193104235\n",
      "Epoch: 11, Loss (standarized): 0.22860464848294657\n",
      "          Validation Loss (standardized): 1.1374377305509855\n",
      "Epoch: 12, Loss (standarized): 0.21178819353159345\n",
      "          Validation Loss (standardized): 1.2407092595341567\n",
      "Epoch: 13, Loss (standarized): 0.20079690143739065\n",
      "          Validation Loss (standardized): 1.3465259045146758\n",
      "Epoch: 14, Loss (standarized): 0.19521609881831523\n",
      "          Validation Loss (standardized): 1.449608175288327\n",
      "Epoch: 15, Loss (standarized): 0.19390800861545343\n",
      "          Validation Loss (standardized): 1.5447295817353108\n",
      "Epoch: 16, Loss (standarized): 0.19536834292955718\n",
      "          Validation Loss (standardized): 1.6276550372985015\n",
      "Epoch: 17, Loss (standarized): 0.19818080598086335\n",
      "          Validation Loss (standardized): 1.695587634200185\n",
      "Epoch: 18, Loss (standarized): 0.20126959510555756\n",
      "          Validation Loss (standardized): 1.7471448311434912\n",
      "Epoch: 19, Loss (standarized): 0.20394128957481716\n",
      "          Validation Loss (standardized): 1.7821090331742497\n",
      "Epoch: 20, Loss (standarized): 0.20582201840618042\n",
      "          Validation Loss (standardized): 1.8011437089686029\n",
      "Final epoch: 20, Final loss (standarized): 0.20582201840618042\n",
      "Epoch: 1, Loss (standarized): 0.7842970359353943\n",
      "          Validation Loss (standardized): 0.7201921220656148\n",
      "Epoch: 2, Loss (standarized): 0.6681356329903836\n",
      "          Validation Loss (standardized): 0.6951005568741607\n",
      "Epoch: 3, Loss (standarized): 0.5915218014926943\n",
      "          Validation Loss (standardized): 0.6977827534258578\n",
      "Epoch: 4, Loss (standarized): 0.5445382047989922\n",
      "          Validation Loss (standardized): 0.7153979356043954\n",
      "Epoch: 5, Loss (standarized): 0.5095329376716309\n",
      "          Validation Loss (standardized): 0.7367884537037007\n",
      "Epoch: 6, Loss (standarized): 0.4717762463831806\n",
      "          Validation Loss (standardized): 0.7592641764985154\n",
      "Epoch: 7, Loss (standarized): 0.4272886689656493\n",
      "          Validation Loss (standardized): 0.7859666313130735\n",
      "Epoch: 8, Loss (standarized): 0.37884090926796427\n",
      "          Validation Loss (standardized): 0.8218365749763419\n",
      "Epoch: 9, Loss (standarized): 0.3312122573356017\n",
      "          Validation Loss (standardized): 0.8712997231327704\n",
      "Epoch: 10, Loss (standarized): 0.28887475141200847\n",
      "          Validation Loss (standardized): 0.9369557519782632\n",
      "Epoch: 11, Loss (standarized): 0.25482974077732795\n",
      "          Validation Loss (standardized): 1.0188991296636973\n",
      "Epoch: 12, Loss (standarized): 0.23007029966207737\n",
      "          Validation Loss (standardized): 1.11483785163459\n",
      "Epoch: 13, Loss (standarized): 0.21384408094564644\n",
      "          Validation Loss (standardized): 1.2208947481949135\n",
      "Epoch: 14, Loss (standarized): 0.20450161181690685\n",
      "          Validation Loss (standardized): 1.3324537427616823\n",
      "Epoch: 15, Loss (standarized): 0.20029167643087303\n",
      "          Validation Loss (standardized): 1.444678474262575\n",
      "Epoch: 16, Loss (standarized): 0.19971935360202536\n",
      "          Validation Loss (standardized): 1.5527816241241248\n",
      "Epoch: 17, Loss (standarized): 0.2015575801514659\n",
      "          Validation Loss (standardized): 1.6522895589818996\n",
      "Epoch: 18, Loss (standarized): 0.20476399057551292\n",
      "          Validation Loss (standardized): 1.7393866813657228\n",
      "Epoch: 19, Loss (standarized): 0.20845018228626888\n",
      "          Validation Loss (standardized): 1.8112339589620745\n",
      "Epoch: 20, Loss (standarized): 0.21190558744375554\n",
      "          Validation Loss (standardized): 1.86613074317165\n",
      "Final epoch: 20, Final loss (standarized): 0.21190558744375554\n",
      "Epoch: 1, Loss (standarized): 0.7035508212286554\n",
      "          Validation Loss (standardized): 0.6916067173416942\n",
      "Epoch: 2, Loss (standarized): 0.6281624263002704\n",
      "          Validation Loss (standardized): 0.6939683430420609\n",
      "Epoch: 3, Loss (standarized): 0.5715152406065337\n",
      "          Validation Loss (standardized): 0.7018024596737281\n",
      "Epoch: 4, Loss (standarized): 0.5074451012342951\n",
      "          Validation Loss (standardized): 0.7211135086242422\n",
      "Epoch: 5, Loss (standarized): 0.44349875242894227\n",
      "          Validation Loss (standardized): 0.7571032777252484\n",
      "Epoch: 6, Loss (standarized): 0.38551246005975887\n",
      "          Validation Loss (standardized): 0.8105804641961625\n",
      "Epoch: 7, Loss (standarized): 0.3345836048471036\n",
      "          Validation Loss (standardized): 0.8803400822354038\n",
      "Epoch: 8, Loss (standarized): 0.29012476513861496\n",
      "          Validation Loss (standardized): 0.9659585620496557\n",
      "Epoch: 9, Loss (standarized): 0.25269791214597037\n",
      "          Validation Loss (standardized): 1.067734914163524\n",
      "Epoch: 10, Loss (standarized): 0.22411603122648965\n",
      "          Validation Loss (standardized): 1.184547879643732\n",
      "Epoch: 11, Loss (standarized): 0.20562836784816285\n",
      "          Validation Loss (standardized): 1.3123796575670743\n",
      "Epoch: 12, Loss (standarized): 0.1966153576163832\n",
      "          Validation Loss (standardized): 1.444738059323421\n",
      "Epoch: 13, Loss (standarized): 0.19486403367301494\n",
      "          Validation Loss (standardized): 1.5742084231736828\n",
      "Epoch: 14, Loss (standarized): 0.1976991516352928\n",
      "          Validation Loss (standardized): 1.6939001922367578\n",
      "Epoch: 15, Loss (standarized): 0.20281389386268525\n",
      "          Validation Loss (standardized): 1.79831922908649\n",
      "Epoch: 16, Loss (standarized): 0.20852217367731535\n",
      "          Validation Loss (standardized): 1.8837524705927846\n",
      "Epoch: 17, Loss (standarized): 0.21372088704303577\n",
      "          Validation Loss (standardized): 1.948306153931921\n",
      "Epoch: 18, Loss (standarized): 0.21778386963002233\n",
      "          Validation Loss (standardized): 1.991701489221049\n",
      "Epoch: 19, Loss (standarized): 0.22045207744343343\n",
      "          Validation Loss (standardized): 2.0149692429371613\n",
      "Epoch: 20, Loss (standarized): 0.2217318952094525\n",
      "          Validation Loss (standardized): 2.020098631594112\n",
      "Final epoch: 20, Final loss (standarized): 0.2217318952094525\n",
      "Epoch: 1, Loss (standarized): 0.7109772621304938\n",
      "          Validation Loss (standardized): 0.6921528757040128\n",
      "Epoch: 2, Loss (standarized): 0.6415278397386172\n",
      "          Validation Loss (standardized): 0.6944950227301072\n",
      "Epoch: 3, Loss (standarized): 0.598029134445337\n",
      "          Validation Loss (standardized): 0.7010941129986534\n",
      "Epoch: 4, Loss (standarized): 0.5525162710136118\n",
      "          Validation Loss (standardized): 0.708329856389216\n",
      "Epoch: 5, Loss (standarized): 0.49932193551797494\n",
      "          Validation Loss (standardized): 0.7219476969732106\n",
      "Epoch: 6, Loss (standarized): 0.44401265153558306\n",
      "          Validation Loss (standardized): 0.7476020805753006\n",
      "Epoch: 7, Loss (standarized): 0.39158960577685464\n",
      "          Validation Loss (standardized): 0.7885627883674455\n",
      "Epoch: 8, Loss (standarized): 0.3442174588971893\n",
      "          Validation Loss (standardized): 0.8458181647889086\n",
      "Epoch: 9, Loss (standarized): 0.30200016069559177\n",
      "          Validation Loss (standardized): 0.919684324231229\n",
      "Epoch: 10, Loss (standarized): 0.26509895529820304\n",
      "          Validation Loss (standardized): 1.0107032965976677\n",
      "Epoch: 11, Loss (standarized): 0.23478732523198895\n",
      "          Validation Loss (standardized): 1.1187152810662717\n",
      "Epoch: 12, Loss (standarized): 0.2126390142522389\n",
      "          Validation Loss (standardized): 1.2414581175213466\n",
      "Epoch: 13, Loss (standarized): 0.1992962453537134\n",
      "          Validation Loss (standardized): 1.3739879915459254\n",
      "Epoch: 14, Loss (standarized): 0.19395805758884746\n",
      "          Validation Loss (standardized): 1.5092276076586615\n",
      "Epoch: 15, Loss (standarized): 0.19470533548824753\n",
      "          Validation Loss (standardized): 1.6392415638755733\n",
      "Epoch: 16, Loss (standarized): 0.1992058653054694\n",
      "          Validation Loss (standardized): 1.7566767250593631\n",
      "Epoch: 17, Loss (standarized): 0.20532870375229326\n",
      "          Validation Loss (standardized): 1.8558938827449756\n",
      "Epoch: 18, Loss (standarized): 0.2114619017453297\n",
      "          Validation Loss (standardized): 1.9334726630701773\n",
      "Epoch: 19, Loss (standarized): 0.21657040714691095\n",
      "          Validation Loss (standardized): 1.9881128358618378\n",
      "Epoch: 20, Loss (standarized): 0.22011560549623368\n",
      "          Validation Loss (standardized): 2.020219355542993\n",
      "Final epoch: 20, Final loss (standarized): 0.22011560549623368\n",
      "Epoch: 1, Loss (standarized): 0.7258919679221728\n",
      "          Validation Loss (standardized): 0.6944981717933242\n",
      "Epoch: 2, Loss (standarized): 0.6650084511496477\n",
      "          Validation Loss (standardized): 0.6881554847895677\n",
      "Epoch: 3, Loss (standarized): 0.6207280054207026\n",
      "          Validation Loss (standardized): 0.691298311470415\n",
      "Epoch: 4, Loss (standarized): 0.5841708140175915\n",
      "          Validation Loss (standardized): 0.6992943813470301\n",
      "Epoch: 5, Loss (standarized): 0.5481129216630117\n",
      "          Validation Loss (standardized): 0.7098987620271572\n",
      "Epoch: 6, Loss (standarized): 0.5087766334961301\n",
      "          Validation Loss (standardized): 0.7234866268832731\n",
      "Epoch: 7, Loss (standarized): 0.4655969946881119\n",
      "          Validation Loss (standardized): 0.7421330072040433\n",
      "Epoch: 8, Loss (standarized): 0.419824466516573\n",
      "          Validation Loss (standardized): 0.7688203286318547\n",
      "Epoch: 9, Loss (standarized): 0.37353772732842605\n",
      "          Validation Loss (standardized): 0.8068611653459655\n",
      "Epoch: 10, Loss (standarized): 0.3291841241528995\n",
      "          Validation Loss (standardized): 0.85933960819023\n",
      "Epoch: 11, Loss (standarized): 0.28922957637680136\n",
      "          Validation Loss (standardized): 0.9284502984516191\n",
      "Epoch: 12, Loss (standarized): 0.2556783969687725\n",
      "          Validation Loss (standardized): 1.0147757161570745\n",
      "Epoch: 13, Loss (standarized): 0.22968288062091408\n",
      "          Validation Loss (standardized): 1.1167425644713262\n",
      "Epoch: 14, Loss (standarized): 0.21148046971761936\n",
      "          Validation Loss (standardized): 1.2303656149827895\n",
      "Epoch: 15, Loss (standarized): 0.200552528921617\n",
      "          Validation Loss (standardized): 1.349418347731658\n",
      "Epoch: 16, Loss (standarized): 0.19574396348358108\n",
      "          Validation Loss (standardized): 1.4663403735341427\n",
      "Epoch: 17, Loss (standarized): 0.19541685303642037\n",
      "          Validation Loss (standardized): 1.5737409181654527\n",
      "Epoch: 18, Loss (standarized): 0.19777428392152713\n",
      "          Validation Loss (standardized): 1.6657280875945246\n",
      "Epoch: 19, Loss (standarized): 0.20122493049929496\n",
      "          Validation Loss (standardized): 1.7385139756107597\n",
      "Epoch: 20, Loss (standarized): 0.20459517942015557\n",
      "          Validation Loss (standardized): 1.7903653196749374\n",
      "Final epoch: 20, Final loss (standarized): 0.20459517942015557\n",
      "Epoch: 1, Loss (standarized): 0.7421916047979935\n",
      "          Validation Loss (standardized): 0.7001477324079763\n",
      "Epoch: 2, Loss (standarized): 0.6508807224906414\n",
      "          Validation Loss (standardized): 0.6890567460114148\n",
      "Epoch: 3, Loss (standarized): 0.5963932841999248\n",
      "          Validation Loss (standardized): 0.6992174408489602\n",
      "Epoch: 4, Loss (standarized): 0.5586908183926494\n",
      "          Validation Loss (standardized): 0.7128288814603045\n",
      "Epoch: 5, Loss (standarized): 0.516081685516111\n",
      "          Validation Loss (standardized): 0.7266844044953022\n",
      "Epoch: 6, Loss (standarized): 0.46513917714909764\n",
      "          Validation Loss (standardized): 0.7458546950442307\n",
      "Epoch: 7, Loss (standarized): 0.4111463963280281\n",
      "          Validation Loss (standardized): 0.7761102595221164\n",
      "Epoch: 8, Loss (standarized): 0.35989691283830594\n",
      "          Validation Loss (standardized): 0.8214604445870095\n",
      "Epoch: 9, Loss (standarized): 0.315152389913693\n",
      "          Validation Loss (standardized): 0.8835715641750452\n",
      "Epoch: 10, Loss (standarized): 0.2782742983298578\n",
      "          Validation Loss (standardized): 0.9621583039382287\n",
      "Epoch: 11, Loss (standarized): 0.2490119284606239\n",
      "          Validation Loss (standardized): 1.055780435574536\n",
      "Epoch: 12, Loss (standarized): 0.22662858356731236\n",
      "          Validation Loss (standardized): 1.1623314319605307\n",
      "Epoch: 13, Loss (standarized): 0.21065944828861288\n",
      "          Validation Loss (standardized): 1.2788009219613776\n",
      "Epoch: 14, Loss (standarized): 0.20088807959825983\n",
      "          Validation Loss (standardized): 1.4007411653804802\n",
      "Epoch: 15, Loss (standarized): 0.19678735349641463\n",
      "          Validation Loss (standardized): 1.5223211789674485\n",
      "Epoch: 16, Loss (standarized): 0.19719195167872916\n",
      "          Validation Loss (standardized): 1.6372060595162672\n",
      "Epoch: 17, Loss (standarized): 0.20050920237025419\n",
      "          Validation Loss (standardized): 1.7397203824125729\n",
      "Epoch: 18, Loss (standarized): 0.20516009157836076\n",
      "          Validation Loss (standardized): 1.8256711549136044\n",
      "Epoch: 19, Loss (standarized): 0.20989424434502038\n",
      "          Validation Loss (standardized): 1.89261688402051\n",
      "Epoch: 20, Loss (standarized): 0.2138868034374771\n",
      "          Validation Loss (standardized): 1.9397258835959474\n",
      "Final epoch: 20, Final loss (standarized): 0.2138868034374771\n",
      "Epoch: 1, Loss (standarized): 0.7203498497421581\n",
      "          Validation Loss (standardized): 0.6888353460809351\n",
      "Epoch: 2, Loss (standarized): 0.6292983318952654\n",
      "          Validation Loss (standardized): 0.7007571667955113\n",
      "Epoch: 3, Loss (standarized): 0.570490614644887\n",
      "          Validation Loss (standardized): 0.7196088281960672\n",
      "Epoch: 4, Loss (standarized): 0.5123247351414953\n",
      "          Validation Loss (standardized): 0.7392573285497335\n",
      "Epoch: 5, Loss (standarized): 0.4469131060303316\n",
      "          Validation Loss (standardized): 0.7682971760927672\n",
      "Epoch: 6, Loss (standarized): 0.38145655262865963\n",
      "          Validation Loss (standardized): 0.8151340487761841\n",
      "Epoch: 7, Loss (standarized): 0.32330942155982095\n",
      "          Validation Loss (standardized): 0.8848004629137901\n",
      "Epoch: 8, Loss (standarized): 0.2764612965318467\n",
      "          Validation Loss (standardized): 0.9783897790663074\n",
      "Epoch: 9, Loss (standarized): 0.24145078871794728\n",
      "          Validation Loss (standardized): 1.094004571324305\n",
      "Epoch: 10, Loss (standarized): 0.2171906382370925\n",
      "          Validation Loss (standardized): 1.2276958851394186\n",
      "Epoch: 11, Loss (standarized): 0.2025415113655078\n",
      "          Validation Loss (standardized): 1.3732754628862203\n",
      "Epoch: 12, Loss (standarized): 0.196288652490996\n",
      "          Validation Loss (standardized): 1.5222197249580802\n",
      "Epoch: 13, Loss (standarized): 0.19657554373266195\n",
      "          Validation Loss (standardized): 1.664885173460403\n",
      "Epoch: 14, Loss (standarized): 0.2010027030527506\n",
      "          Validation Loss (standardized): 1.7925453998934102\n",
      "Epoch: 15, Loss (standarized): 0.2072410843341031\n",
      "          Validation Loss (standardized): 1.8989541662634055\n",
      "Epoch: 16, Loss (standarized): 0.21353129936078735\n",
      "          Validation Loss (standardized): 1.9808055777156262\n",
      "Epoch: 17, Loss (standarized): 0.21881842307482557\n",
      "          Validation Loss (standardized): 2.0373754653352227\n",
      "Epoch: 18, Loss (standarized): 0.22264208599941218\n",
      "          Validation Loss (standardized): 2.069869851373437\n",
      "Epoch: 19, Loss (standarized): 0.22494585703069944\n",
      "          Validation Loss (standardized): 2.08078931046833\n",
      "Epoch: 20, Loss (standarized): 0.2258755070402653\n",
      "          Validation Loss (standardized): 2.0733409547422044\n",
      "Final epoch: 20, Final loss (standarized): 0.2258755070402653\n",
      "Epoch: 1, Loss (standarized): 0.7018794927237922\n",
      "          Validation Loss (standardized): 0.6928352420749684\n",
      "Epoch: 2, Loss (standarized): 0.6475118630081139\n",
      "          Validation Loss (standardized): 0.6895707770263083\n",
      "Epoch: 3, Loss (standarized): 0.6028198265210751\n",
      "          Validation Loss (standardized): 0.6903623569813174\n",
      "Epoch: 4, Loss (standarized): 0.5626356232452249\n",
      "          Validation Loss (standardized): 0.6944635882586541\n",
      "Epoch: 5, Loss (standarized): 0.524386223721485\n",
      "          Validation Loss (standardized): 0.7019108069401913\n",
      "Epoch: 6, Loss (standarized): 0.4870463721805748\n",
      "          Validation Loss (standardized): 0.7131458944684013\n",
      "Epoch: 7, Loss (standarized): 0.4503963098934943\n",
      "          Validation Loss (standardized): 0.7286780387066701\n",
      "Epoch: 8, Loss (standarized): 0.4148330812393715\n",
      "          Validation Loss (standardized): 0.7492629646910183\n",
      "Epoch: 9, Loss (standarized): 0.38049123079782543\n",
      "          Validation Loss (standardized): 0.775648770738586\n",
      "Epoch: 10, Loss (standarized): 0.3478096609753128\n",
      "          Validation Loss (standardized): 0.808600588094677\n",
      "Epoch: 11, Loss (standarized): 0.31724373029342695\n",
      "          Validation Loss (standardized): 0.8488993730964606\n",
      "Epoch: 12, Loss (standarized): 0.2892080816535791\n",
      "          Validation Loss (standardized): 0.8959620865999596\n",
      "Epoch: 13, Loss (standarized): 0.2646844026376887\n",
      "          Validation Loss (standardized): 0.9485875380825329\n",
      "Epoch: 14, Loss (standarized): 0.2442253304508798\n",
      "          Validation Loss (standardized): 1.00474711644581\n",
      "Epoch: 15, Loss (standarized): 0.22798918210706387\n",
      "          Validation Loss (standardized): 1.0622995529401014\n",
      "Epoch: 16, Loss (standarized): 0.21569203972223652\n",
      "          Validation Loss (standardized): 1.1193145462907288\n",
      "Epoch: 17, Loss (standarized): 0.20675955848013625\n",
      "          Validation Loss (standardized): 1.1729563880520408\n",
      "Epoch: 18, Loss (standarized): 0.2006775477589335\n",
      "          Validation Loss (standardized): 1.2209566549803434\n",
      "Epoch: 19, Loss (standarized): 0.19677356184563058\n",
      "          Validation Loss (standardized): 1.2613607259458264\n",
      "Epoch: 20, Loss (standarized): 0.19442737944598076\n",
      "          Validation Loss (standardized): 1.2930176538576479\n",
      "Final epoch: 20, Final loss (standarized): 0.19442737944598076\n",
      "Epoch: 1, Loss (standarized): 0.8664318361715959\n",
      "          Validation Loss (standardized): 0.7533415765441438\n",
      "Epoch: 2, Loss (standarized): 0.7088237173038071\n",
      "          Validation Loss (standardized): 0.7046793354412483\n",
      "Epoch: 3, Loss (standarized): 0.5966356463396825\n",
      "          Validation Loss (standardized): 0.6959286851860486\n",
      "Epoch: 4, Loss (standarized): 0.5271211645374885\n",
      "          Validation Loss (standardized): 0.7123990021107117\n",
      "Epoch: 5, Loss (standarized): 0.48409181067823054\n",
      "          Validation Loss (standardized): 0.7380892121811692\n",
      "Epoch: 6, Loss (standarized): 0.45047418256439087\n",
      "          Validation Loss (standardized): 0.7645928560591148\n",
      "Epoch: 7, Loss (standarized): 0.4173506321147953\n",
      "          Validation Loss (standardized): 0.790392783397538\n",
      "Epoch: 8, Loss (standarized): 0.38307040280503024\n",
      "          Validation Loss (standardized): 0.8168609379076054\n",
      "Epoch: 9, Loss (standarized): 0.34917351364266397\n",
      "          Validation Loss (standardized): 0.8457962924591257\n",
      "Epoch: 10, Loss (standarized): 0.3177505178883128\n",
      "          Validation Loss (standardized): 0.8782896739026191\n",
      "Epoch: 11, Loss (standarized): 0.29028190343698695\n",
      "          Validation Loss (standardized): 0.9147347078109169\n",
      "Epoch: 12, Loss (standarized): 0.26731904006238544\n",
      "          Validation Loss (standardized): 0.9546703475082774\n",
      "Epoch: 13, Loss (standarized): 0.24879516193872098\n",
      "          Validation Loss (standardized): 0.9972722477358414\n",
      "Epoch: 14, Loss (standarized): 0.23422231557860299\n",
      "          Validation Loss (standardized): 1.0413201198163593\n",
      "Epoch: 15, Loss (standarized): 0.22300620863284107\n",
      "          Validation Loss (standardized): 1.0855626311539626\n",
      "Epoch: 16, Loss (standarized): 0.21452630667140557\n",
      "          Validation Loss (standardized): 1.128506105067982\n",
      "Epoch: 17, Loss (standarized): 0.208250129035155\n",
      "          Validation Loss (standardized): 1.1693993152800026\n",
      "Epoch: 18, Loss (standarized): 0.2036405832300846\n",
      "          Validation Loss (standardized): 1.2070982210926358\n",
      "Epoch: 19, Loss (standarized): 0.2003102247067339\n",
      "          Validation Loss (standardized): 1.240630091142932\n",
      "Epoch: 20, Loss (standarized): 0.1979346081887383\n",
      "          Validation Loss (standardized): 1.2695299622393212\n",
      "Final epoch: 20, Final loss (standarized): 0.1979346081887383\n",
      "Epoch: 1, Loss (standarized): 0.7425386351805536\n",
      "          Validation Loss (standardized): 0.7035223568233627\n",
      "Epoch: 2, Loss (standarized): 0.6427213896022783\n",
      "          Validation Loss (standardized): 0.6935479906777396\n",
      "Epoch: 3, Loss (standarized): 0.5711442114328882\n",
      "          Validation Loss (standardized): 0.6990632315612128\n",
      "Epoch: 4, Loss (standarized): 0.5169249488702702\n",
      "          Validation Loss (standardized): 0.7133504453892815\n",
      "Epoch: 5, Loss (standarized): 0.47088720750536683\n",
      "          Validation Loss (standardized): 0.7328966235542798\n",
      "Epoch: 6, Loss (standarized): 0.42812908779847153\n",
      "          Validation Loss (standardized): 0.7571638135246065\n",
      "Epoch: 7, Loss (standarized): 0.3872271550594784\n",
      "          Validation Loss (standardized): 0.7870968537030347\n",
      "Epoch: 8, Loss (standarized): 0.3486244616358618\n",
      "          Validation Loss (standardized): 0.8235142339681433\n",
      "Epoch: 9, Loss (standarized): 0.31363102078729266\n",
      "          Validation Loss (standardized): 0.8668065206493261\n",
      "Epoch: 10, Loss (standarized): 0.2833313029500224\n",
      "          Validation Loss (standardized): 0.9167183749865316\n",
      "Epoch: 11, Loss (standarized): 0.25822382806208094\n",
      "          Validation Loss (standardized): 0.9717018924115369\n",
      "Epoch: 12, Loss (standarized): 0.238441177652721\n",
      "          Validation Loss (standardized): 1.029735947036892\n",
      "Epoch: 13, Loss (standarized): 0.2235023259599972\n",
      "          Validation Loss (standardized): 1.088400173492495\n",
      "Epoch: 14, Loss (standarized): 0.2126781722983007\n",
      "          Validation Loss (standardized): 1.1455286876002067\n",
      "Epoch: 15, Loss (standarized): 0.20512506775390155\n",
      "          Validation Loss (standardized): 1.1983378558750797\n",
      "Epoch: 16, Loss (standarized): 0.2001162630501367\n",
      "          Validation Loss (standardized): 1.2450836844833537\n",
      "Epoch: 17, Loss (standarized): 0.1969076456636029\n",
      "          Validation Loss (standardized): 1.2840840275942458\n",
      "Epoch: 18, Loss (standarized): 0.1949420623582102\n",
      "          Validation Loss (standardized): 1.3147694019669762\n",
      "Epoch: 19, Loss (standarized): 0.19376078638784308\n",
      "          Validation Loss (standardized): 1.3367521084944616\n",
      "Epoch: 20, Loss (standarized): 0.19305563447724536\n",
      "          Validation Loss (standardized): 1.3505130480328749\n",
      "Final epoch: 20, Final loss (standarized): 0.19305563447724536\n",
      "Epoch: 1, Loss (standarized): 0.7318118222341796\n",
      "          Validation Loss (standardized): 0.70007620949737\n",
      "Epoch: 2, Loss (standarized): 0.6446905391492848\n",
      "          Validation Loss (standardized): 0.6896388397641957\n",
      "Epoch: 3, Loss (standarized): 0.5887125481093243\n",
      "          Validation Loss (standardized): 0.6924840290129254\n",
      "Epoch: 4, Loss (standarized): 0.5466858271952885\n",
      "          Validation Loss (standardized): 0.7002649701982671\n",
      "Epoch: 5, Loss (standarized): 0.5076380302865514\n",
      "          Validation Loss (standardized): 0.7109403404221587\n",
      "Epoch: 6, Loss (standarized): 0.4684638700126497\n",
      "          Validation Loss (standardized): 0.7251892396215485\n",
      "Epoch: 7, Loss (standarized): 0.4295588953046638\n",
      "          Validation Loss (standardized): 0.7444406570702804\n",
      "Epoch: 8, Loss (standarized): 0.39187336664949923\n",
      "          Validation Loss (standardized): 0.7698060508250777\n",
      "Epoch: 9, Loss (standarized): 0.356449489772352\n",
      "          Validation Loss (standardized): 0.801936127589648\n",
      "Epoch: 10, Loss (standarized): 0.32408154130225675\n",
      "          Validation Loss (standardized): 0.8408764876869934\n",
      "Epoch: 11, Loss (standarized): 0.29530597885379634\n",
      "          Validation Loss (standardized): 0.8863697916371581\n",
      "Epoch: 12, Loss (standarized): 0.2703222796374987\n",
      "          Validation Loss (standardized): 0.9374911744632095\n",
      "Epoch: 13, Loss (standarized): 0.24925430520442726\n",
      "          Validation Loss (standardized): 0.992760089268448\n",
      "Epoch: 14, Loss (standarized): 0.2321273534147579\n",
      "          Validation Loss (standardized): 1.0503054687798727\n",
      "Epoch: 15, Loss (standarized): 0.21877135634599015\n",
      "          Validation Loss (standardized): 1.1078808063714354\n",
      "Epoch: 16, Loss (standarized): 0.2088703607889719\n",
      "          Validation Loss (standardized): 1.163178643414209\n",
      "Epoch: 17, Loss (standarized): 0.2019116278185102\n",
      "          Validation Loss (standardized): 1.2135359696407273\n",
      "Epoch: 18, Loss (standarized): 0.19733521696818598\n",
      "          Validation Loss (standardized): 1.2578400275726949\n",
      "Epoch: 19, Loss (standarized): 0.19448133576029572\n",
      "          Validation Loss (standardized): 1.294909568067016\n",
      "Epoch: 20, Loss (standarized): 0.1928457210284714\n",
      "          Validation Loss (standardized): 1.3237406296524035\n",
      "Final epoch: 20, Final loss (standarized): 0.1928457210284714\n",
      "Epoch: 1, Loss (standarized): 0.816426527886083\n",
      "          Validation Loss (standardized): 0.7471437247278792\n",
      "Epoch: 2, Loss (standarized): 0.6934740064121616\n",
      "          Validation Loss (standardized): 0.7087091448731343\n",
      "Epoch: 3, Loss (standarized): 0.6081743881304906\n",
      "          Validation Loss (standardized): 0.6983945384726903\n",
      "Epoch: 4, Loss (standarized): 0.5533289601486395\n",
      "          Validation Loss (standardized): 0.7069981236267014\n",
      "Epoch: 5, Loss (standarized): 0.5160822060944749\n",
      "          Validation Loss (standardized): 0.7251006924336071\n",
      "Epoch: 6, Loss (standarized): 0.4833778886060929\n",
      "          Validation Loss (standardized): 0.7473419343819466\n",
      "Epoch: 7, Loss (standarized): 0.4473201265911978\n",
      "          Validation Loss (standardized): 0.7731890122398093\n",
      "Epoch: 8, Loss (standarized): 0.40639042444049034\n",
      "          Validation Loss (standardized): 0.8049172081926852\n",
      "Epoch: 9, Loss (standarized): 0.3628597527049902\n",
      "          Validation Loss (standardized): 0.8455583934917621\n",
      "Epoch: 10, Loss (standarized): 0.3202653113983916\n",
      "          Validation Loss (standardized): 0.89771290456974\n",
      "Epoch: 11, Loss (standarized): 0.2819818205958588\n",
      "          Validation Loss (standardized): 0.9627204427199411\n",
      "Epoch: 12, Loss (standarized): 0.250385616698326\n",
      "          Validation Loss (standardized): 1.0401774227808447\n",
      "Epoch: 13, Loss (standarized): 0.2265402831952988\n",
      "          Validation Loss (standardized): 1.1279218743264539\n",
      "Epoch: 14, Loss (standarized): 0.21021334165737823\n",
      "          Validation Loss (standardized): 1.2224861416359838\n",
      "Epoch: 15, Loss (standarized): 0.20027790073031296\n",
      "          Validation Loss (standardized): 1.319882330816949\n",
      "Epoch: 16, Loss (standarized): 0.1952414308201995\n",
      "          Validation Loss (standardized): 1.4160911610277767\n",
      "Epoch: 17, Loss (standarized): 0.1936698391286747\n",
      "          Validation Loss (standardized): 1.5074987867723064\n",
      "Epoch: 18, Loss (standarized): 0.1943637808678962\n",
      "          Validation Loss (standardized): 1.5910271538537535\n",
      "Epoch: 19, Loss (standarized): 0.1963846667518727\n",
      "          Validation Loss (standardized): 1.6642672289066294\n",
      "Epoch: 20, Loss (standarized): 0.19901701388334797\n",
      "          Validation Loss (standardized): 1.725550519220373\n",
      "Final epoch: 20, Final loss (standarized): 0.19901701388334797\n",
      "Epoch: 1, Loss (standarized): 0.7620263497395177\n",
      "          Validation Loss (standardized): 0.7064688620964918\n",
      "Epoch: 2, Loss (standarized): 0.648404102795391\n",
      "          Validation Loss (standardized): 0.6919833336008817\n",
      "Epoch: 3, Loss (standarized): 0.5774229858381461\n",
      "          Validation Loss (standardized): 0.7010966650641\n",
      "Epoch: 4, Loss (standarized): 0.5310395681457556\n",
      "          Validation Loss (standardized): 0.7196136296847064\n",
      "Epoch: 5, Loss (standarized): 0.4895060490320468\n",
      "          Validation Loss (standardized): 0.7407883573583652\n",
      "Epoch: 6, Loss (standarized): 0.44347122118115695\n",
      "          Validation Loss (standardized): 0.7658763060341762\n",
      "Epoch: 7, Loss (standarized): 0.3934956393188506\n",
      "          Validation Loss (standardized): 0.7991945472729853\n",
      "Epoch: 8, Loss (standarized): 0.3439350751782297\n",
      "          Validation Loss (standardized): 0.8449493157047812\n",
      "Epoch: 9, Loss (standarized): 0.2993623387640778\n",
      "          Validation Loss (standardized): 0.9056350567727667\n",
      "Epoch: 10, Loss (standarized): 0.26291779656026404\n",
      "          Validation Loss (standardized): 0.9812632512342045\n",
      "Epoch: 11, Loss (standarized): 0.23570930699224657\n",
      "          Validation Loss (standardized): 1.069468444750339\n",
      "Epoch: 12, Loss (standarized): 0.21706893858105997\n",
      "          Validation Loss (standardized): 1.166177167190184\n",
      "Epoch: 13, Loss (standarized): 0.20540940028879137\n",
      "          Validation Loss (standardized): 1.266358009513383\n",
      "Epoch: 14, Loss (standarized): 0.19901287238644633\n",
      "          Validation Loss (standardized): 1.3647298119429818\n",
      "Epoch: 15, Loss (standarized): 0.1963545581375442\n",
      "          Validation Loss (standardized): 1.4563538721723848\n",
      "Epoch: 16, Loss (standarized): 0.19614480939898452\n",
      "          Validation Loss (standardized): 1.5371241130407953\n",
      "Epoch: 17, Loss (standarized): 0.19730958957752265\n",
      "          Validation Loss (standardized): 1.6040147412607209\n",
      "Epoch: 18, Loss (standarized): 0.19899072906375426\n",
      "          Validation Loss (standardized): 1.6552292660109535\n",
      "Epoch: 19, Loss (standarized): 0.20056106601306012\n",
      "          Validation Loss (standardized): 1.6902282149151562\n",
      "Epoch: 20, Loss (standarized): 0.2016259319319449\n",
      "          Validation Loss (standardized): 1.7093928215385064\n",
      "Final epoch: 20, Final loss (standarized): 0.2016259319319449\n",
      "Epoch: 1, Loss (standarized): 0.6934670940643959\n",
      "          Validation Loss (standardized): 0.6987144902724185\n",
      "Epoch: 2, Loss (standarized): 0.6254859580092093\n",
      "          Validation Loss (standardized): 0.6918869093282466\n",
      "Epoch: 3, Loss (standarized): 0.5512540920692726\n",
      "          Validation Loss (standardized): 0.7040635260635358\n",
      "Epoch: 4, Loss (standarized): 0.48544645556521293\n",
      "          Validation Loss (standardized): 0.7304991433791918\n",
      "Epoch: 5, Loss (standarized): 0.4192692608889348\n",
      "          Validation Loss (standardized): 0.7737496425958823\n",
      "Epoch: 6, Loss (standarized): 0.3554829591046352\n",
      "          Validation Loss (standardized): 0.8386987593592667\n",
      "Epoch: 7, Loss (standarized): 0.2999250859862461\n",
      "          Validation Loss (standardized): 0.927268601728118\n",
      "Epoch: 8, Loss (standarized): 0.2559956323546683\n",
      "          Validation Loss (standardized): 1.03775377076959\n",
      "Epoch: 9, Loss (standarized): 0.2241996103890429\n",
      "          Validation Loss (standardized): 1.166208653826708\n",
      "Epoch: 10, Loss (standarized): 0.20387104668157013\n",
      "          Validation Loss (standardized): 1.3066125302029956\n",
      "Epoch: 11, Loss (standarized): 0.19382292833708314\n",
      "          Validation Loss (standardized): 1.450327667290856\n",
      "Epoch: 12, Loss (standarized): 0.19187597306244789\n",
      "          Validation Loss (standardized): 1.5871725086808723\n",
      "Epoch: 13, Loss (standarized): 0.1950840809291225\n",
      "          Validation Loss (standardized): 1.70821859399503\n",
      "Epoch: 14, Loss (standarized): 0.20060891243249981\n",
      "          Validation Loss (standardized): 1.807364161672374\n",
      "Epoch: 15, Loss (standarized): 0.20635600809198038\n",
      "          Validation Loss (standardized): 1.8817527285490265\n",
      "Epoch: 16, Loss (standarized): 0.21108633464917134\n",
      "          Validation Loss (standardized): 1.9309091074387945\n",
      "Epoch: 17, Loss (standarized): 0.2142228376599772\n",
      "          Validation Loss (standardized): 1.9562211191929628\n",
      "Epoch: 18, Loss (standarized): 0.21564608356623785\n",
      "          Validation Loss (standardized): 1.9601190065197012\n",
      "Epoch: 19, Loss (standarized): 0.21551011227350933\n",
      "          Validation Loss (standardized): 1.9455987325961022\n",
      "Epoch: 20, Loss (standarized): 0.21412379705458484\n",
      "          Validation Loss (standardized): 1.9158603229459692\n",
      "Final epoch: 20, Final loss (standarized): 0.21412379705458484\n",
      "Epoch: 1, Loss (standarized): 0.7516233499332594\n",
      "          Validation Loss (standardized): 0.7044413586707543\n",
      "Epoch: 2, Loss (standarized): 0.6510392131697935\n",
      "          Validation Loss (standardized): 0.6919006564389723\n",
      "Epoch: 3, Loss (standarized): 0.5904864757523146\n",
      "          Validation Loss (standardized): 0.7019644390968963\n",
      "Epoch: 4, Loss (standarized): 0.5509379154132603\n",
      "          Validation Loss (standardized): 0.7182325147214751\n",
      "Epoch: 5, Loss (standarized): 0.510221795790375\n",
      "          Validation Loss (standardized): 0.7348670136674991\n",
      "Epoch: 6, Loss (standarized): 0.4605861160141783\n",
      "          Validation Loss (standardized): 0.7558441879636965\n",
      "Epoch: 7, Loss (standarized): 0.40606365152878515\n",
      "          Validation Loss (standardized): 0.7874806115998483\n",
      "Epoch: 8, Loss (standarized): 0.353104856052762\n",
      "          Validation Loss (standardized): 0.8348692752155117\n",
      "Epoch: 9, Loss (standarized): 0.30661739314348196\n",
      "          Validation Loss (standardized): 0.9006070679169548\n",
      "Epoch: 10, Loss (standarized): 0.26889339940834917\n",
      "          Validation Loss (standardized): 0.9846350583982464\n",
      "Epoch: 11, Loss (standarized): 0.24005004242286967\n",
      "          Validation Loss (standardized): 1.0848926784791286\n",
      "Epoch: 12, Loss (standarized): 0.21914862737234037\n",
      "          Validation Loss (standardized): 1.1980928225892802\n",
      "Epoch: 13, Loss (standarized): 0.20519539852815522\n",
      "          Validation Loss (standardized): 1.3198964062933316\n",
      "Epoch: 14, Loss (standarized): 0.19741227598134772\n",
      "          Validation Loss (standardized): 1.4447391281599047\n",
      "Epoch: 15, Loss (standarized): 0.19490254563027817\n",
      "          Validation Loss (standardized): 1.5660302557314398\n",
      "Epoch: 16, Loss (standarized): 0.19637967892717798\n",
      "          Validation Loss (standardized): 1.6771095621432404\n",
      "Epoch: 17, Loss (standarized): 0.2002803076863707\n",
      "          Validation Loss (standardized): 1.7724326517324036\n",
      "Epoch: 18, Loss (standarized): 0.20510039075519035\n",
      "          Validation Loss (standardized): 1.8482946775948392\n",
      "Epoch: 19, Loss (standarized): 0.20966865960624134\n",
      "          Validation Loss (standardized): 1.903014616495403\n",
      "Epoch: 20, Loss (standarized): 0.21323915435206306\n",
      "          Validation Loss (standardized): 1.9364996990572991\n",
      "Final epoch: 20, Final loss (standarized): 0.21323915435206306\n",
      "Epoch: 1, Loss (standarized): 0.7225234872781544\n",
      "          Validation Loss (standardized): 0.692791896176726\n",
      "Epoch: 2, Loss (standarized): 0.6412522765209235\n",
      "          Validation Loss (standardized): 0.696038444403591\n",
      "Epoch: 3, Loss (standarized): 0.5820998812933257\n",
      "          Validation Loss (standardized): 0.7149219394337689\n",
      "Epoch: 4, Loss (standarized): 0.5336230194285679\n",
      "          Validation Loss (standardized): 0.7383477562866456\n",
      "Epoch: 5, Loss (standarized): 0.48276474950620946\n",
      "          Validation Loss (standardized): 0.7643703008627672\n",
      "Epoch: 6, Loss (standarized): 0.4267583249752122\n",
      "          Validation Loss (standardized): 0.7981674217406436\n",
      "Epoch: 7, Loss (standarized): 0.36990153675100357\n",
      "          Validation Loss (standardized): 0.8459059254081831\n",
      "Epoch: 8, Loss (standarized): 0.31746362093170544\n",
      "          Validation Loss (standardized): 0.9123337583317541\n",
      "Epoch: 9, Loss (standarized): 0.27346199080310013\n",
      "          Validation Loss (standardized): 0.9997908657547216\n",
      "Epoch: 10, Loss (standarized): 0.23992414409072824\n",
      "          Validation Loss (standardized): 1.1077934388090243\n",
      "Epoch: 11, Loss (standarized): 0.21699225623451013\n",
      "          Validation Loss (standardized): 1.2331165217744435\n",
      "Epoch: 12, Loss (standarized): 0.20356581751581007\n",
      "          Validation Loss (standardized): 1.3700615383177268\n",
      "Epoch: 13, Loss (standarized): 0.19796655556279213\n",
      "          Validation Loss (standardized): 1.5108646857193841\n",
      "Epoch: 14, Loss (standarized): 0.1982253711826151\n",
      "          Validation Loss (standardized): 1.6466469964603323\n",
      "Epoch: 15, Loss (standarized): 0.20221266934217264\n",
      "          Validation Loss (standardized): 1.7689868208827817\n",
      "Epoch: 16, Loss (standarized): 0.20790144904946528\n",
      "          Validation Loss (standardized): 1.8714235755379116\n",
      "Epoch: 17, Loss (standarized): 0.21367040798736844\n",
      "          Validation Loss (standardized): 1.9501917905039172\n",
      "Epoch: 18, Loss (standarized): 0.2184559617560369\n",
      "          Validation Loss (standardized): 2.004106585733828\n",
      "Epoch: 19, Loss (standarized): 0.2217278528639476\n",
      "          Validation Loss (standardized): 2.0340010284118955\n",
      "Epoch: 20, Loss (standarized): 0.2233695732947785\n",
      "          Validation Loss (standardized): 2.042097839427036\n",
      "Final epoch: 20, Final loss (standarized): 0.2233695732947785\n",
      "Epoch: 1, Loss (standarized): 0.8681419393618847\n",
      "          Validation Loss (standardized): 0.7900472552348319\n",
      "Epoch: 2, Loss (standarized): 0.7135848599256865\n",
      "          Validation Loss (standardized): 0.7252623185480701\n",
      "Epoch: 3, Loss (standarized): 0.600470416850697\n",
      "          Validation Loss (standardized): 0.7007026058352175\n",
      "Epoch: 4, Loss (standarized): 0.5296513293766965\n",
      "          Validation Loss (standardized): 0.7084841384663128\n",
      "Epoch: 5, Loss (standarized): 0.48969167833726085\n",
      "          Validation Loss (standardized): 0.7323144800713629\n",
      "Epoch: 6, Loss (standarized): 0.4605435635063453\n",
      "          Validation Loss (standardized): 0.7607383134991026\n",
      "Epoch: 7, Loss (standarized): 0.4294286292749194\n",
      "          Validation Loss (standardized): 0.7906257175881735\n",
      "Epoch: 8, Loss (standarized): 0.3932993931944308\n",
      "          Validation Loss (standardized): 0.8235348862072445\n",
      "Epoch: 9, Loss (standarized): 0.3541435546849113\n",
      "          Validation Loss (standardized): 0.8624444908210185\n",
      "Epoch: 10, Loss (standarized): 0.31553000953801985\n",
      "          Validation Loss (standardized): 0.9099040922372734\n",
      "Epoch: 11, Loss (standarized): 0.2807569737765904\n",
      "          Validation Loss (standardized): 0.9671413855834706\n",
      "Epoch: 12, Loss (standarized): 0.2519572653225334\n",
      "          Validation Loss (standardized): 1.0338265917217335\n",
      "Epoch: 13, Loss (standarized): 0.22990267717924337\n",
      "          Validation Loss (standardized): 1.108298540690201\n",
      "Epoch: 14, Loss (standarized): 0.21426358923431293\n",
      "          Validation Loss (standardized): 1.188016344541268\n",
      "Epoch: 15, Loss (standarized): 0.20406365990746808\n",
      "          Validation Loss (standardized): 1.2700263580040763\n",
      "Epoch: 16, Loss (standarized): 0.19810139138271401\n",
      "          Validation Loss (standardized): 1.3513228469214278\n",
      "Epoch: 17, Loss (standarized): 0.19522584248613287\n",
      "          Validation Loss (standardized): 1.4291066284010991\n",
      "Epoch: 18, Loss (standarized): 0.19446082970898315\n",
      "          Validation Loss (standardized): 1.5009503701657974\n",
      "Epoch: 19, Loss (standarized): 0.19503075877112985\n",
      "          Validation Loss (standardized): 1.5648908669674306\n",
      "Epoch: 20, Loss (standarized): 0.19634114737073094\n",
      "          Validation Loss (standardized): 1.6194964640293619\n",
      "Final epoch: 20, Final loss (standarized): 0.19634114737073094\n",
      "Epoch: 1, Loss (standarized): 0.7238020826835097\n",
      "          Validation Loss (standardized): 0.6911290177381738\n",
      "Epoch: 2, Loss (standarized): 0.6459391989416363\n",
      "          Validation Loss (standardized): 0.6944386580566336\n",
      "Epoch: 3, Loss (standarized): 0.5957414688184757\n",
      "          Validation Loss (standardized): 0.7092264321937989\n",
      "Epoch: 4, Loss (standarized): 0.5548366607636223\n",
      "          Validation Loss (standardized): 0.72336789404451\n",
      "Epoch: 5, Loss (standarized): 0.5073171246272425\n",
      "          Validation Loss (standardized): 0.7378865074897735\n",
      "Epoch: 6, Loss (standarized): 0.45260411618864943\n",
      "          Validation Loss (standardized): 0.7593326672369735\n",
      "Epoch: 7, Loss (standarized): 0.3963673436399944\n",
      "          Validation Loss (standardized): 0.7942157847831333\n",
      "Epoch: 8, Loss (standarized): 0.3440844950736442\n",
      "          Validation Loss (standardized): 0.8472768150413674\n",
      "Epoch: 9, Loss (standarized): 0.29904789785726293\n",
      "          Validation Loss (standardized): 0.9209280642353772\n",
      "Epoch: 10, Loss (standarized): 0.26235509717301975\n",
      "          Validation Loss (standardized): 1.0154409622501372\n",
      "Epoch: 11, Loss (standarized): 0.2339903566343859\n",
      "          Validation Loss (standardized): 1.1292579736157664\n",
      "Epoch: 12, Loss (standarized): 0.2138147834534493\n",
      "          Validation Loss (standardized): 1.2588231588515448\n",
      "Epoch: 13, Loss (standarized): 0.20161962857648907\n",
      "          Validation Loss (standardized): 1.3982085962114001\n",
      "Epoch: 14, Loss (standarized): 0.1966245395419988\n",
      "          Validation Loss (standardized): 1.5394167182146594\n",
      "Epoch: 15, Loss (standarized): 0.19725457712736325\n",
      "          Validation Loss (standardized): 1.6736287611824354\n",
      "Epoch: 16, Loss (standarized): 0.2014381777730573\n",
      "          Validation Loss (standardized): 1.7929480078473825\n",
      "Epoch: 17, Loss (standarized): 0.20714696411388667\n",
      "          Validation Loss (standardized): 1.891713840383781\n",
      "Epoch: 18, Loss (standarized): 0.2128155206939868\n",
      "          Validation Loss (standardized): 1.9668889099837787\n",
      "Epoch: 19, Loss (standarized): 0.21747639166927504\n",
      "          Validation Loss (standardized): 2.017763785307398\n",
      "Epoch: 20, Loss (standarized): 0.2206905592065903\n",
      "          Validation Loss (standardized): 2.0453976796143305\n",
      "Final epoch: 20, Final loss (standarized): 0.2206905592065903\n",
      "Epoch: 1, Loss (standarized): 0.7632610387205686\n",
      "          Validation Loss (standardized): 0.6944819450015853\n",
      "Epoch: 2, Loss (standarized): 0.6388676541778362\n",
      "          Validation Loss (standardized): 0.6967132135311951\n",
      "Epoch: 3, Loss (standarized): 0.5705256242885882\n",
      "          Validation Loss (standardized): 0.7257592975500665\n",
      "Epoch: 4, Loss (standarized): 0.5304173352316852\n",
      "          Validation Loss (standardized): 0.7519946075690285\n",
      "Epoch: 5, Loss (standarized): 0.4840774675467559\n",
      "          Validation Loss (standardized): 0.7728782053079601\n",
      "Epoch: 6, Loss (standarized): 0.426667555439475\n",
      "          Validation Loss (standardized): 0.7982572809431829\n",
      "Epoch: 7, Loss (standarized): 0.36745911580827734\n",
      "          Validation Loss (standardized): 0.837412825361984\n",
      "Epoch: 8, Loss (standarized): 0.315720182026215\n",
      "          Validation Loss (standardized): 0.8952038560200245\n",
      "Epoch: 9, Loss (standarized): 0.2759236076943721\n",
      "          Validation Loss (standardized): 0.971752578566255\n",
      "Epoch: 10, Loss (standarized): 0.24753162498930253\n",
      "          Validation Loss (standardized): 1.064399068472244\n",
      "Epoch: 11, Loss (standarized): 0.22774016742391973\n",
      "          Validation Loss (standardized): 1.1697481505632346\n",
      "Epoch: 12, Loss (standarized): 0.21416145600512274\n",
      "          Validation Loss (standardized): 1.2842548787142147\n",
      "Epoch: 13, Loss (standarized): 0.20560809553571002\n",
      "          Validation Loss (standardized): 1.4037657548549816\n",
      "Epoch: 14, Loss (standarized): 0.20150149922893362\n",
      "          Validation Loss (standardized): 1.5231807649312343\n",
      "Epoch: 15, Loss (standarized): 0.2011275179634456\n",
      "          Validation Loss (standardized): 1.6368366817019244\n",
      "Epoch: 16, Loss (standarized): 0.2034111606770491\n",
      "          Validation Loss (standardized): 1.7394047703595448\n",
      "Epoch: 17, Loss (standarized): 0.20712554055631927\n",
      "          Validation Loss (standardized): 1.8267196104041867\n",
      "Epoch: 18, Loss (standarized): 0.21118268112361674\n",
      "          Validation Loss (standardized): 1.8961862488858705\n",
      "Epoch: 19, Loss (standarized): 0.21479831494538687\n",
      "          Validation Loss (standardized): 1.9467688010286985\n",
      "Epoch: 20, Loss (standarized): 0.21751640461789118\n",
      "          Validation Loss (standardized): 1.9787227347306902\n",
      "Final epoch: 20, Final loss (standarized): 0.21751640461789118\n",
      "Epoch: 1, Loss (standarized): 1.0696691772979405\n",
      "Epoch: 2, Loss (standarized): 0.7976918189785616\n",
      "Epoch: 3, Loss (standarized): 0.6062743005232358\n",
      "Epoch: 4, Loss (standarized): 0.4791888053778663\n",
      "Epoch: 5, Loss (standarized): 0.3955816817221501\n",
      "Epoch: 6, Loss (standarized): 0.33907663941558236\n",
      "Epoch: 7, Loss (standarized): 0.2998056290799968\n",
      "Epoch: 8, Loss (standarized): 0.271531194156553\n",
      "Epoch: 9, Loss (standarized): 0.2502945827346837\n",
      "Epoch: 10, Loss (standarized): 0.2356271360029455\n",
      "Epoch: 11, Loss (standarized): 0.22677800898510353\n",
      "Epoch: 12, Loss (standarized): 0.2220228035810184\n",
      "Epoch: 13, Loss (standarized): 0.21993500118990808\n",
      "Epoch: 14, Loss (standarized): 0.21947447175718204\n",
      "Epoch: 15, Loss (standarized): 0.21979470455257819\n",
      "Epoch: 16, Loss (standarized): 0.22029816519717443\n",
      "Epoch: 17, Loss (standarized): 0.2205976010379662\n",
      "Epoch: 18, Loss (standarized): 0.22042614468590163\n",
      "Epoch: 19, Loss (standarized): 0.21964959351702742\n",
      "Epoch: 20, Loss (standarized): 0.2182083194422421\n",
      "Final epoch: 20, Final loss (standarized): 0.2182083194422421\n",
      "Epoch: 1, Loss (standarized): 1.867818706117783\n",
      "Epoch: 2, Loss (standarized): 1.3430290894872277\n",
      "Epoch: 3, Loss (standarized): 0.9781863061900922\n",
      "Epoch: 4, Loss (standarized): 0.712093892018813\n",
      "Epoch: 5, Loss (standarized): 0.5009349026259624\n",
      "Epoch: 6, Loss (standarized): 0.34878610600974036\n",
      "Epoch: 7, Loss (standarized): 0.27244997900130796\n",
      "Epoch: 8, Loss (standarized): 0.255178926980565\n",
      "Epoch: 9, Loss (standarized): 0.2618079420095474\n",
      "Epoch: 10, Loss (standarized): 0.27343115242622423\n",
      "Epoch: 11, Loss (standarized): 0.28431666524089344\n",
      "Epoch: 12, Loss (standarized): 0.29283681278784546\n",
      "Epoch: 13, Loss (standarized): 0.2987007689200157\n",
      "Epoch: 14, Loss (standarized): 0.3021125348137282\n",
      "Epoch: 15, Loss (standarized): 0.3033381106965634\n",
      "Epoch: 16, Loss (standarized): 0.30262957660118756\n",
      "Epoch: 17, Loss (standarized): 0.30038199392816795\n",
      "Epoch: 18, Loss (standarized): 0.29686555883090715\n",
      "Epoch: 19, Loss (standarized): 0.29235335568000825\n",
      "Epoch: 20, Loss (standarized): 0.28702903728385154\n",
      "Final epoch: 20, Final loss (standarized): 0.28702903728385154\n",
      "Epoch: 1, Loss (standarized): 1.1577122505957362\n",
      "Epoch: 2, Loss (standarized): 0.7663276275162463\n",
      "Epoch: 3, Loss (standarized): 0.4875675496571403\n",
      "Epoch: 4, Loss (standarized): 0.3188178363691294\n",
      "Epoch: 5, Loss (standarized): 0.2392767479791005\n",
      "Epoch: 6, Loss (standarized): 0.21033899372615994\n",
      "Epoch: 7, Loss (standarized): 0.2036701732967634\n",
      "Epoch: 8, Loss (standarized): 0.2057502274367244\n",
      "Epoch: 9, Loss (standarized): 0.210717398260612\n",
      "Epoch: 10, Loss (standarized): 0.21624619467604486\n",
      "Epoch: 11, Loss (standarized): 0.22146440568435033\n",
      "Epoch: 12, Loss (standarized): 0.22585821044291934\n",
      "Epoch: 13, Loss (standarized): 0.229254346411106\n",
      "Epoch: 14, Loss (standarized): 0.23154739666901128\n",
      "Epoch: 15, Loss (standarized): 0.23275844027224005\n",
      "Epoch: 16, Loss (standarized): 0.232926102560264\n",
      "Epoch: 17, Loss (standarized): 0.232138127388114\n",
      "Epoch: 18, Loss (standarized): 0.2305359784710022\n",
      "Epoch: 19, Loss (standarized): 0.2282562041225681\n",
      "Epoch: 20, Loss (standarized): 0.22536040776937738\n",
      "Final epoch: 20, Final loss (standarized): 0.22536040776937738\n",
      "Epoch: 1, Loss (standarized): 1.2166226413005825\n",
      "Epoch: 2, Loss (standarized): 0.8807487495648701\n",
      "Epoch: 3, Loss (standarized): 0.6238779935668838\n",
      "Epoch: 4, Loss (standarized): 0.4461499612754561\n",
      "Epoch: 5, Loss (standarized): 0.34208418345465114\n",
      "Epoch: 6, Loss (standarized): 0.2841858947398845\n",
      "Epoch: 7, Loss (standarized): 0.2534123103130187\n",
      "Epoch: 8, Loss (standarized): 0.23767733467782884\n",
      "Epoch: 9, Loss (standarized): 0.23025066397082522\n",
      "Epoch: 10, Loss (standarized): 0.22701808260313588\n",
      "Epoch: 11, Loss (standarized): 0.22528916600797144\n",
      "Epoch: 12, Loss (standarized): 0.22378249757179522\n",
      "Epoch: 13, Loss (standarized): 0.22186510364429046\n",
      "Epoch: 14, Loss (standarized): 0.21932606236234575\n",
      "Epoch: 15, Loss (standarized): 0.2162343847562195\n",
      "Epoch: 16, Loss (standarized): 0.21283035898900401\n",
      "Epoch: 17, Loss (standarized): 0.20913417666612066\n",
      "Epoch: 18, Loss (standarized): 0.2055657647346104\n",
      "Epoch: 19, Loss (standarized): 0.2021669250249644\n",
      "Epoch: 20, Loss (standarized): 0.1990651644690566\n",
      "Final epoch: 20, Final loss (standarized): 0.1990651644690566\n",
      "Epoch: 1, Loss (standarized): 0.32274627377459153\n",
      "Epoch: 2, Loss (standarized): 0.28668204765432925\n",
      "Epoch: 3, Loss (standarized): 0.2584891052864739\n",
      "Epoch: 4, Loss (standarized): 0.23714521717250017\n",
      "Epoch: 5, Loss (standarized): 0.22161415505912915\n",
      "Epoch: 6, Loss (standarized): 0.21074531910767907\n",
      "Epoch: 7, Loss (standarized): 0.20296412392185115\n",
      "Epoch: 8, Loss (standarized): 0.1975699169452369\n",
      "Epoch: 9, Loss (standarized): 0.19382800867224287\n",
      "Epoch: 10, Loss (standarized): 0.19088394854280935\n",
      "Epoch: 11, Loss (standarized): 0.1884695352084567\n",
      "Epoch: 12, Loss (standarized): 0.18643340801174865\n",
      "Epoch: 13, Loss (standarized): 0.18466548678235717\n",
      "Epoch: 14, Loss (standarized): 0.18317196047178516\n",
      "Epoch: 15, Loss (standarized): 0.18190885944165205\n",
      "Epoch: 16, Loss (standarized): 0.1808051379634104\n",
      "Epoch: 17, Loss (standarized): 0.1798816198168088\n",
      "Epoch: 18, Loss (standarized): 0.17906616737487369\n",
      "Epoch: 19, Loss (standarized): 0.1783536978727362\n",
      "Epoch: 20, Loss (standarized): 0.17774957358497345\n",
      "Final epoch: 20, Final loss (standarized): 0.17774957358497345\n",
      "Epoch: 1, Loss (standarized): 0.7518207050028051\n",
      "Epoch: 2, Loss (standarized): 0.49950381143423284\n",
      "Epoch: 3, Loss (standarized): 0.3525152485745183\n",
      "Epoch: 4, Loss (standarized): 0.2753768243586151\n",
      "Epoch: 5, Loss (standarized): 0.23777662408497255\n",
      "Epoch: 6, Loss (standarized): 0.22029114870157396\n",
      "Epoch: 7, Loss (standarized): 0.21283103173215598\n",
      "Epoch: 8, Loss (standarized): 0.21033543071853827\n",
      "Epoch: 9, Loss (standarized): 0.21022863804531186\n",
      "Epoch: 10, Loss (standarized): 0.2109236717498271\n",
      "Epoch: 11, Loss (standarized): 0.21163541797627078\n",
      "Epoch: 12, Loss (standarized): 0.21209359616397555\n",
      "Epoch: 13, Loss (standarized): 0.21208512199446064\n",
      "Epoch: 14, Loss (standarized): 0.21156174996036553\n",
      "Epoch: 15, Loss (standarized): 0.21053128317620348\n",
      "Epoch: 16, Loss (standarized): 0.2090383830670046\n",
      "Epoch: 17, Loss (standarized): 0.20716836246307824\n",
      "Epoch: 18, Loss (standarized): 0.20502426954744085\n",
      "Epoch: 19, Loss (standarized): 0.2027201586345577\n",
      "Epoch: 20, Loss (standarized): 0.2003686468212692\n",
      "Final epoch: 20, Final loss (standarized): 0.2003686468212692\n",
      "Epoch: 1, Loss (standarized): 1.156133716402426\n",
      "Epoch: 2, Loss (standarized): 0.7679101300853715\n",
      "Epoch: 3, Loss (standarized): 0.5021942445359321\n",
      "Epoch: 4, Loss (standarized): 0.34365372490518437\n",
      "Epoch: 5, Loss (standarized): 0.2616099263386926\n",
      "Epoch: 6, Loss (standarized): 0.22594655939824257\n",
      "Epoch: 7, Loss (standarized): 0.21309913788102536\n",
      "Epoch: 8, Loss (standarized): 0.210724179471244\n",
      "Epoch: 9, Loss (standarized): 0.2128268896971865\n",
      "Epoch: 10, Loss (standarized): 0.21667128899637414\n",
      "Epoch: 11, Loss (standarized): 0.22077889171563644\n",
      "Epoch: 12, Loss (standarized): 0.22444073377391913\n",
      "Epoch: 13, Loss (standarized): 0.2273113993392109\n",
      "Epoch: 14, Loss (standarized): 0.22925363109170901\n",
      "Epoch: 15, Loss (standarized): 0.23025954582680241\n",
      "Epoch: 16, Loss (standarized): 0.23037145972117548\n",
      "Epoch: 17, Loss (standarized): 0.2296513626259811\n",
      "Epoch: 18, Loss (standarized): 0.22822283065952526\n",
      "Epoch: 19, Loss (standarized): 0.22620271560367716\n",
      "Epoch: 20, Loss (standarized): 0.22371899270063267\n",
      "Final epoch: 20, Final loss (standarized): 0.22371899270063267\n",
      "Epoch: 1, Loss (standarized): 1.2484718744160221\n",
      "Epoch: 2, Loss (standarized): 0.814395226575261\n",
      "Epoch: 3, Loss (standarized): 0.5141778783985538\n",
      "Epoch: 4, Loss (standarized): 0.3451445802829729\n",
      "Epoch: 5, Loss (standarized): 0.2627933838938033\n",
      "Epoch: 6, Loss (standarized): 0.22596401859887\n",
      "Epoch: 7, Loss (standarized): 0.2107501101628895\n",
      "Epoch: 8, Loss (standarized): 0.20612777905639984\n",
      "Epoch: 9, Loss (standarized): 0.20635374444187488\n",
      "Epoch: 10, Loss (standarized): 0.20848693718982472\n",
      "Epoch: 11, Loss (standarized): 0.21126212137838327\n",
      "Epoch: 12, Loss (standarized): 0.21395066676026103\n",
      "Epoch: 13, Loss (standarized): 0.21610594878178763\n",
      "Epoch: 14, Loss (standarized): 0.21776181839670777\n",
      "Epoch: 15, Loss (standarized): 0.2188427452195093\n",
      "Epoch: 16, Loss (standarized): 0.2193656993053169\n",
      "Epoch: 17, Loss (standarized): 0.21930590995563387\n",
      "Epoch: 18, Loss (standarized): 0.21872660987704834\n",
      "Epoch: 19, Loss (standarized): 0.2176310283482918\n",
      "Epoch: 20, Loss (standarized): 0.2161252814927748\n",
      "Final epoch: 20, Final loss (standarized): 0.2161252814927748\n",
      "Epoch: 1, Loss (standarized): 2.436623389144024\n",
      "Epoch: 2, Loss (standarized): 1.7449539248540937\n",
      "Epoch: 3, Loss (standarized): 1.1726769396297037\n",
      "Epoch: 4, Loss (standarized): 0.7536274379039358\n",
      "Epoch: 5, Loss (standarized): 0.492796884236168\n",
      "Epoch: 6, Loss (standarized): 0.35064186329754643\n",
      "Epoch: 7, Loss (standarized): 0.2777963589941755\n",
      "Epoch: 8, Loss (standarized): 0.24216543704898225\n",
      "Epoch: 9, Loss (standarized): 0.22634153259043432\n",
      "Epoch: 10, Loss (standarized): 0.22083580465991276\n",
      "Epoch: 11, Loss (standarized): 0.22068166626248625\n",
      "Epoch: 12, Loss (standarized): 0.22330491606830388\n",
      "Epoch: 13, Loss (standarized): 0.22716152429456202\n",
      "Epoch: 14, Loss (standarized): 0.23135005885193463\n",
      "Epoch: 15, Loss (standarized): 0.23527608766248245\n",
      "Epoch: 16, Loss (standarized): 0.23857482694265433\n",
      "Epoch: 17, Loss (standarized): 0.24104538432222541\n",
      "Epoch: 18, Loss (standarized): 0.24250563680735318\n",
      "Epoch: 19, Loss (standarized): 0.24287581897145974\n",
      "Epoch: 20, Loss (standarized): 0.2422494641482199\n",
      "Final epoch: 20, Final loss (standarized): 0.2422494641482199\n",
      "Epoch: 1, Loss (standarized): 1.2645097704322825\n",
      "Epoch: 2, Loss (standarized): 0.8064141126207494\n",
      "Epoch: 3, Loss (standarized): 0.5051137029824289\n",
      "Epoch: 4, Loss (standarized): 0.3383055539467093\n",
      "Epoch: 5, Loss (standarized): 0.2647045901885427\n",
      "Epoch: 6, Loss (standarized): 0.23724768831917972\n",
      "Epoch: 7, Loss (standarized): 0.22913728263138627\n",
      "Epoch: 8, Loss (standarized): 0.2286002889579581\n",
      "Epoch: 9, Loss (standarized): 0.2307885076667116\n",
      "Epoch: 10, Loss (standarized): 0.23367346767181874\n",
      "Epoch: 11, Loss (standarized): 0.23636761445609197\n",
      "Epoch: 12, Loss (standarized): 0.23840320654350575\n",
      "Epoch: 13, Loss (standarized): 0.23966279109865762\n",
      "Epoch: 14, Loss (standarized): 0.2400996846472344\n",
      "Epoch: 15, Loss (standarized): 0.23975791535600735\n",
      "Epoch: 16, Loss (standarized): 0.2386654212766782\n",
      "Epoch: 17, Loss (standarized): 0.236951900904295\n",
      "Epoch: 18, Loss (standarized): 0.23474366419018727\n",
      "Epoch: 19, Loss (standarized): 0.2321931149606607\n",
      "Epoch: 20, Loss (standarized): 0.2294079957667702\n",
      "Final epoch: 20, Final loss (standarized): 0.2294079957667702\n",
      "Epoch: 1, Loss (standarized): 2.239500278708053\n",
      "Epoch: 2, Loss (standarized): 1.7051058863251671\n",
      "Epoch: 3, Loss (standarized): 1.245882776762493\n",
      "Epoch: 4, Loss (standarized): 0.8596220959934363\n",
      "Epoch: 5, Loss (standarized): 0.544747044409843\n",
      "Epoch: 6, Loss (standarized): 0.3320359559819861\n",
      "Epoch: 7, Loss (standarized): 0.24136350841672144\n",
      "Epoch: 8, Loss (standarized): 0.2207037772062384\n",
      "Epoch: 9, Loss (standarized): 0.22336370524186122\n",
      "Epoch: 10, Loss (standarized): 0.23280509509586061\n",
      "Epoch: 11, Loss (standarized): 0.2438327488229469\n",
      "Epoch: 12, Loss (standarized): 0.25444667466157894\n",
      "Epoch: 13, Loss (standarized): 0.26376789704205783\n",
      "Epoch: 14, Loss (standarized): 0.27154239836945077\n",
      "Epoch: 15, Loss (standarized): 0.2777608816601964\n",
      "Epoch: 16, Loss (standarized): 0.28235118530201947\n",
      "Epoch: 17, Loss (standarized): 0.2854358444624989\n",
      "Epoch: 18, Loss (standarized): 0.2871832434266522\n",
      "Epoch: 19, Loss (standarized): 0.2876533396234306\n",
      "Epoch: 20, Loss (standarized): 0.2869978883887119\n",
      "Final epoch: 20, Final loss (standarized): 0.2869978883887119\n",
      "Epoch: 1, Loss (standarized): 0.26615346495363273\n",
      "Epoch: 2, Loss (standarized): 0.2330194491558489\n",
      "Epoch: 3, Loss (standarized): 0.21811601280293033\n",
      "Epoch: 4, Loss (standarized): 0.20908211839373236\n",
      "Epoch: 5, Loss (standarized): 0.20196957957343362\n",
      "Epoch: 6, Loss (standarized): 0.19629287600453207\n",
      "Epoch: 7, Loss (standarized): 0.1921112454209727\n",
      "Epoch: 8, Loss (standarized): 0.18920189790993866\n",
      "Epoch: 9, Loss (standarized): 0.18662675866460604\n",
      "Epoch: 10, Loss (standarized): 0.18396437019292833\n",
      "Epoch: 11, Loss (standarized): 0.1813534853478238\n",
      "Epoch: 12, Loss (standarized): 0.17911402588416178\n",
      "Epoch: 13, Loss (standarized): 0.17723941958522968\n",
      "Epoch: 14, Loss (standarized): 0.1755351265946177\n",
      "Epoch: 15, Loss (standarized): 0.17369001566807138\n",
      "Epoch: 16, Loss (standarized): 0.1716555208882922\n",
      "Epoch: 17, Loss (standarized): 0.1695447399231248\n",
      "Epoch: 18, Loss (standarized): 0.1674547946630251\n",
      "Epoch: 19, Loss (standarized): 0.16563262953682525\n",
      "Epoch: 20, Loss (standarized): 0.1641892842200538\n",
      "Final epoch: 20, Final loss (standarized): 0.1641892842200538\n",
      "Epoch: 1, Loss (standarized): 0.840864798782081\n",
      "Epoch: 2, Loss (standarized): 0.5993133265846474\n",
      "Epoch: 3, Loss (standarized): 0.45767194927300103\n",
      "Epoch: 4, Loss (standarized): 0.37284789173564215\n",
      "Epoch: 5, Loss (standarized): 0.3174232859716415\n",
      "Epoch: 6, Loss (standarized): 0.2795259875320741\n",
      "Epoch: 7, Loss (standarized): 0.25255218600521895\n",
      "Epoch: 8, Loss (standarized): 0.2331989060869995\n",
      "Epoch: 9, Loss (standarized): 0.21984914168585148\n",
      "Epoch: 10, Loss (standarized): 0.2114040232532432\n",
      "Epoch: 11, Loss (standarized): 0.20733587944285622\n",
      "Epoch: 12, Loss (standarized): 0.20632936189141723\n",
      "Epoch: 13, Loss (standarized): 0.20715642407884532\n",
      "Epoch: 14, Loss (standarized): 0.20890328191665392\n",
      "Epoch: 15, Loss (standarized): 0.21099417778445728\n",
      "Epoch: 16, Loss (standarized): 0.21296737056099627\n",
      "Epoch: 17, Loss (standarized): 0.21453954198307834\n",
      "Epoch: 18, Loss (standarized): 0.2155465910364164\n",
      "Epoch: 19, Loss (standarized): 0.21592638641240114\n",
      "Epoch: 20, Loss (standarized): 0.2156771138127488\n",
      "Final epoch: 20, Final loss (standarized): 0.2156771138127488\n",
      "Epoch: 1, Loss (standarized): 0.7504325612146989\n",
      "Epoch: 2, Loss (standarized): 0.5450087175252568\n",
      "Epoch: 3, Loss (standarized): 0.40052818014079106\n",
      "Epoch: 4, Loss (standarized): 0.31038907050932507\n",
      "Epoch: 5, Loss (standarized): 0.25670427730736317\n",
      "Epoch: 6, Loss (standarized): 0.2268441867376113\n",
      "Epoch: 7, Loss (standarized): 0.21177544871142823\n",
      "Epoch: 8, Loss (standarized): 0.2054012129365799\n",
      "Epoch: 9, Loss (standarized): 0.20381438963335435\n",
      "Epoch: 10, Loss (standarized): 0.20485768056371295\n",
      "Epoch: 11, Loss (standarized): 0.20691876009492446\n",
      "Epoch: 12, Loss (standarized): 0.20910502760450408\n",
      "Epoch: 13, Loss (standarized): 0.21083106621816353\n",
      "Epoch: 14, Loss (standarized): 0.21188098946899425\n",
      "Epoch: 15, Loss (standarized): 0.2121331528922961\n",
      "Epoch: 16, Loss (standarized): 0.21159353822857155\n",
      "Epoch: 17, Loss (standarized): 0.21031741092992376\n",
      "Epoch: 18, Loss (standarized): 0.20849889715938788\n",
      "Epoch: 19, Loss (standarized): 0.20629339239292796\n",
      "Epoch: 20, Loss (standarized): 0.20386368513224087\n",
      "Final epoch: 20, Final loss (standarized): 0.20386368513224087\n",
      "Epoch: 1, Loss (standarized): 1.5705577378839068\n",
      "Epoch: 2, Loss (standarized): 1.0945262155242765\n",
      "Epoch: 3, Loss (standarized): 0.7478297442827159\n",
      "Epoch: 4, Loss (standarized): 0.5030839969236202\n",
      "Epoch: 5, Loss (standarized): 0.3457270017095175\n",
      "Epoch: 6, Loss (standarized): 0.2563833776370838\n",
      "Epoch: 7, Loss (standarized): 0.21445855583489898\n",
      "Epoch: 8, Loss (standarized): 0.1998549941773465\n",
      "Epoch: 9, Loss (standarized): 0.1987597907193951\n",
      "Epoch: 10, Loss (standarized): 0.2037636660009605\n",
      "Epoch: 11, Loss (standarized): 0.21100931474297202\n",
      "Epoch: 12, Loss (standarized): 0.21863772245401444\n",
      "Epoch: 13, Loss (standarized): 0.22566340140916372\n",
      "Epoch: 14, Loss (standarized): 0.23143365287491183\n",
      "Epoch: 15, Loss (standarized): 0.23580904456386254\n",
      "Epoch: 16, Loss (standarized): 0.23876913898538873\n",
      "Epoch: 17, Loss (standarized): 0.24034019428376127\n",
      "Epoch: 18, Loss (standarized): 0.24061373732153138\n",
      "Epoch: 19, Loss (standarized): 0.23978554956190107\n",
      "Epoch: 20, Loss (standarized): 0.23809054898456666\n",
      "Final epoch: 20, Final loss (standarized): 0.23809054898456666\n",
      "Epoch: 1, Loss (standarized): 0.2971735157627223\n",
      "Epoch: 2, Loss (standarized): 0.23603285787236697\n",
      "Epoch: 3, Loss (standarized): 0.2114447314492148\n",
      "Epoch: 4, Loss (standarized): 0.2031928790865207\n",
      "Epoch: 5, Loss (standarized): 0.20174083004473345\n",
      "Epoch: 6, Loss (standarized): 0.20237483007515975\n",
      "Epoch: 7, Loss (standarized): 0.20282973718903313\n",
      "Epoch: 8, Loss (standarized): 0.20212644294120874\n",
      "Epoch: 9, Loss (standarized): 0.2002374680553375\n",
      "Epoch: 10, Loss (standarized): 0.19765444921081898\n",
      "Epoch: 11, Loss (standarized): 0.19467545514227963\n",
      "Epoch: 12, Loss (standarized): 0.19140928775561233\n",
      "Epoch: 13, Loss (standarized): 0.1879296167791436\n",
      "Epoch: 14, Loss (standarized): 0.18420367043643354\n",
      "Epoch: 15, Loss (standarized): 0.18034736347638955\n",
      "Epoch: 16, Loss (standarized): 0.17656426873657202\n",
      "Epoch: 17, Loss (standarized): 0.17301651246040523\n",
      "Epoch: 18, Loss (standarized): 0.16988419728701531\n",
      "Epoch: 19, Loss (standarized): 0.1670830419518601\n",
      "Epoch: 20, Loss (standarized): 0.16468037316809986\n",
      "Final epoch: 20, Final loss (standarized): 0.16468037316809986\n",
      "Epoch: 1, Loss (standarized): 1.4244848582879739\n",
      "          Validation Loss (standardized): 0.9541406567496886\n",
      "Epoch: 2, Loss (standarized): 0.9800716018050337\n",
      "          Validation Loss (standardized): 0.9428883445399358\n",
      "Epoch: 3, Loss (standarized): 0.6619032401115011\n",
      "          Validation Loss (standardized): 1.025218951755604\n",
      "Epoch: 4, Loss (standarized): 0.4415720619729069\n",
      "          Validation Loss (standardized): 1.1820276783047372\n",
      "Epoch: 5, Loss (standarized): 0.3064408329999779\n",
      "          Validation Loss (standardized): 1.3867289523626654\n",
      "Epoch: 6, Loss (standarized): 0.24598051946204247\n",
      "          Validation Loss (standardized): 1.6003855245448984\n",
      "Epoch: 7, Loss (standarized): 0.22915504858379585\n",
      "          Validation Loss (standardized): 1.7957158850243606\n",
      "Epoch: 8, Loss (standarized): 0.2294635233162028\n",
      "          Validation Loss (standardized): 1.9609616579730866\n",
      "Epoch: 9, Loss (standarized): 0.23467295182949705\n",
      "          Validation Loss (standardized): 2.092806341139581\n",
      "Epoch: 10, Loss (standarized): 0.24018866008233067\n",
      "          Validation Loss (standardized): 2.1922489943638572\n",
      "Epoch: 11, Loss (standarized): 0.24435744882489158\n",
      "          Validation Loss (standardized): 2.2616386692490624\n",
      "Epoch: 12, Loss (standarized): 0.24665817041091886\n",
      "          Validation Loss (standardized): 2.3036978718313583\n",
      "Epoch: 13, Loss (standarized): 0.24702240283080565\n",
      "          Validation Loss (standardized): 2.3214098575249618\n",
      "Epoch: 14, Loss (standarized): 0.24561984349142546\n",
      "          Validation Loss (standardized): 2.317932790991975\n",
      "Epoch: 15, Loss (standarized): 0.24262748800715647\n",
      "          Validation Loss (standardized): 2.296329797470399\n",
      "Epoch: 16, Loss (standarized): 0.23844039326637448\n",
      "          Validation Loss (standardized): 2.259609428677516\n",
      "Epoch: 17, Loss (standarized): 0.23355213407166256\n",
      "          Validation Loss (standardized): 2.2104056562446193\n",
      "Epoch: 18, Loss (standarized): 0.2286815031105444\n",
      "          Validation Loss (standardized): 2.1522455147749793\n",
      "Epoch: 19, Loss (standarized): 0.22443816340142278\n",
      "          Validation Loss (standardized): 2.0899576881027837\n",
      "Epoch: 20, Loss (standarized): 0.22147500893193162\n",
      "          Validation Loss (standardized): 2.028118701707374\n",
      "Final epoch: 20, Final loss (standarized): 0.22147500893193162\n",
      "Epoch: 1, Loss (standarized): 0.6712702951618418\n",
      "          Validation Loss (standardized): 0.7244084651636631\n",
      "Epoch: 2, Loss (standarized): 0.48078164623117203\n",
      "          Validation Loss (standardized): 0.8057284842668163\n",
      "Epoch: 3, Loss (standarized): 0.3787186242615713\n",
      "          Validation Loss (standardized): 0.9120956199927006\n",
      "Epoch: 4, Loss (standarized): 0.32387337443495573\n",
      "          Validation Loss (standardized): 1.0220928356918741\n",
      "Epoch: 5, Loss (standarized): 0.29219849547318494\n",
      "          Validation Loss (standardized): 1.1289998967374872\n",
      "Epoch: 6, Loss (standarized): 0.272521118425179\n",
      "          Validation Loss (standardized): 1.2288949927148596\n",
      "Epoch: 7, Loss (standarized): 0.25931028580491383\n",
      "          Validation Loss (standardized): 1.3213428938165506\n",
      "Epoch: 8, Loss (standarized): 0.25023586180364027\n",
      "          Validation Loss (standardized): 1.4054790640093489\n",
      "Epoch: 9, Loss (standarized): 0.24390481803779093\n",
      "          Validation Loss (standardized): 1.4802392988728925\n",
      "Epoch: 10, Loss (standarized): 0.23943574287375105\n",
      "          Validation Loss (standardized): 1.5442496393430398\n",
      "Epoch: 11, Loss (standarized): 0.23596131695330905\n",
      "          Validation Loss (standardized): 1.5969188766279385\n",
      "Epoch: 12, Loss (standarized): 0.23312193871572898\n",
      "          Validation Loss (standardized): 1.6379311043728721\n",
      "Epoch: 13, Loss (standarized): 0.230598195159812\n",
      "          Validation Loss (standardized): 1.6676060829478292\n",
      "Epoch: 14, Loss (standarized): 0.228059641148318\n",
      "          Validation Loss (standardized): 1.6859799773971065\n",
      "Epoch: 15, Loss (standarized): 0.2253167657358262\n",
      "          Validation Loss (standardized): 1.6935259907389713\n",
      "Epoch: 16, Loss (standarized): 0.22235917480775888\n",
      "          Validation Loss (standardized): 1.6904269978112303\n",
      "Epoch: 17, Loss (standarized): 0.21900506070472395\n",
      "          Validation Loss (standardized): 1.6775951466425179\n",
      "Epoch: 18, Loss (standarized): 0.21536095644370357\n",
      "          Validation Loss (standardized): 1.6567947175803486\n",
      "Epoch: 19, Loss (standarized): 0.21158761147865687\n",
      "          Validation Loss (standardized): 1.6293124618667734\n",
      "Epoch: 20, Loss (standarized): 0.20776898677952604\n",
      "          Validation Loss (standardized): 1.5966629885068044\n",
      "Final epoch: 20, Final loss (standarized): 0.20776898677952604\n",
      "Epoch: 1, Loss (standarized): 0.7499625324445549\n",
      "          Validation Loss (standardized): 0.9167003483374612\n",
      "Epoch: 2, Loss (standarized): 0.5093162650634501\n",
      "          Validation Loss (standardized): 0.9976144853442807\n",
      "Epoch: 3, Loss (standarized): 0.35156159545909915\n",
      "          Validation Loss (standardized): 1.1437892636849003\n",
      "Epoch: 4, Loss (standarized): 0.26345648902211644\n",
      "          Validation Loss (standardized): 1.3368725616722605\n",
      "Epoch: 5, Loss (standarized): 0.22461580175433848\n",
      "          Validation Loss (standardized): 1.5361597661846316\n",
      "Epoch: 6, Loss (standarized): 0.21264092357755918\n",
      "          Validation Loss (standardized): 1.7148358120013458\n",
      "Epoch: 7, Loss (standarized): 0.21269109613971415\n",
      "          Validation Loss (standardized): 1.8631807048457227\n",
      "Epoch: 8, Loss (standarized): 0.21718449131811146\n",
      "          Validation Loss (standardized): 1.977840359438191\n",
      "Epoch: 9, Loss (standarized): 0.22267250612016531\n",
      "          Validation Loss (standardized): 2.0589303109140364\n",
      "Epoch: 10, Loss (standarized): 0.2273596313875788\n",
      "          Validation Loss (standardized): 2.108874973754082\n",
      "Epoch: 11, Loss (standarized): 0.23058507086127328\n",
      "          Validation Loss (standardized): 2.1307158630967122\n",
      "Epoch: 12, Loss (standarized): 0.23211922185745482\n",
      "          Validation Loss (standardized): 2.1278688960374437\n",
      "Epoch: 13, Loss (standarized): 0.23198275514250435\n",
      "          Validation Loss (standardized): 2.103478323480268\n",
      "Epoch: 14, Loss (standarized): 0.2303699844309223\n",
      "          Validation Loss (standardized): 2.0613037381504227\n",
      "Epoch: 15, Loss (standarized): 0.22753526269025698\n",
      "          Validation Loss (standardized): 2.0057000509385103\n",
      "Epoch: 16, Loss (standarized): 0.22382608111121668\n",
      "          Validation Loss (standardized): 1.9427930920683598\n",
      "Epoch: 17, Loss (standarized): 0.21979140164244\n",
      "          Validation Loss (standardized): 1.8739298958607697\n",
      "Epoch: 18, Loss (standarized): 0.21551213415998438\n",
      "          Validation Loss (standardized): 1.8001660404314022\n",
      "Epoch: 19, Loss (standarized): 0.21111151976914974\n",
      "          Validation Loss (standardized): 1.7233190906273597\n",
      "Epoch: 20, Loss (standarized): 0.20685331944204693\n",
      "          Validation Loss (standardized): 1.6455256382438685\n",
      "Final epoch: 20, Final loss (standarized): 0.20685331944204693\n",
      "Epoch: 1, Loss (standarized): 1.7416926402250907\n",
      "          Validation Loss (standardized): 0.9401124798351275\n",
      "Epoch: 2, Loss (standarized): 1.1904617185113173\n",
      "          Validation Loss (standardized): 0.8625665104349898\n",
      "Epoch: 3, Loss (standarized): 0.8035996980536534\n",
      "          Validation Loss (standardized): 0.8981936310687054\n",
      "Epoch: 4, Loss (standarized): 0.5484958398877509\n",
      "          Validation Loss (standardized): 1.011139036795186\n",
      "Epoch: 5, Loss (standarized): 0.39755404554568174\n",
      "          Validation Loss (standardized): 1.166838242088173\n",
      "Epoch: 6, Loss (standarized): 0.3169586738887085\n",
      "          Validation Loss (standardized): 1.3392369000886992\n",
      "Epoch: 7, Loss (standarized): 0.2763570463614858\n",
      "          Validation Loss (standardized): 1.5130445488882556\n",
      "Epoch: 8, Loss (standarized): 0.25805437509747337\n",
      "          Validation Loss (standardized): 1.680368813954793\n",
      "Epoch: 9, Loss (standarized): 0.2518037337287584\n",
      "          Validation Loss (standardized): 1.8360835298248097\n",
      "Epoch: 10, Loss (standarized): 0.25170849615990504\n",
      "          Validation Loss (standardized): 1.9760012890586498\n",
      "Epoch: 11, Loss (standarized): 0.2545836867786831\n",
      "          Validation Loss (standardized): 2.098457152879573\n",
      "Epoch: 12, Loss (standarized): 0.2588662493626103\n",
      "          Validation Loss (standardized): 2.2020589223618203\n",
      "Epoch: 13, Loss (standarized): 0.2633340847053107\n",
      "          Validation Loss (standardized): 2.285682065956875\n",
      "Epoch: 14, Loss (standarized): 0.26714837616465026\n",
      "          Validation Loss (standardized): 2.3493834486462366\n",
      "Epoch: 15, Loss (standarized): 0.26986608863751693\n",
      "          Validation Loss (standardized): 2.3940653681125936\n",
      "Epoch: 16, Loss (standarized): 0.27140908713408446\n",
      "          Validation Loss (standardized): 2.4215582504183404\n",
      "Epoch: 17, Loss (standarized): 0.27180693486565916\n",
      "          Validation Loss (standardized): 2.433168529345485\n",
      "Epoch: 18, Loss (standarized): 0.27102618426717767\n",
      "          Validation Loss (standardized): 2.4320328906713304\n",
      "Epoch: 19, Loss (standarized): 0.2693401547774129\n",
      "          Validation Loss (standardized): 2.415264307738405\n",
      "Epoch: 20, Loss (standarized): 0.266407213590048\n",
      "          Validation Loss (standardized): 2.3892654317240227\n",
      "Final epoch: 20, Final loss (standarized): 0.266407213590048\n",
      "Epoch: 1, Loss (standarized): 1.6572849433299022\n",
      "          Validation Loss (standardized): 1.0116877160278666\n",
      "Epoch: 2, Loss (standarized): 1.318987189911024\n",
      "          Validation Loss (standardized): 0.9342031235466404\n",
      "Epoch: 3, Loss (standarized): 1.031138864767651\n",
      "          Validation Loss (standardized): 0.9001286023482958\n",
      "Epoch: 4, Loss (standarized): 0.7911596760381783\n",
      "          Validation Loss (standardized): 0.9099350949470256\n",
      "Epoch: 5, Loss (standarized): 0.6023642513912372\n",
      "          Validation Loss (standardized): 0.9591251252960251\n",
      "Epoch: 6, Loss (standarized): 0.4626613098079445\n",
      "          Validation Loss (standardized): 1.0378043838483348\n",
      "Epoch: 7, Loss (standarized): 0.36351944064944586\n",
      "          Validation Loss (standardized): 1.137318328478843\n",
      "Epoch: 8, Loss (standarized): 0.295536590778301\n",
      "          Validation Loss (standardized): 1.2488671768277289\n",
      "Epoch: 9, Loss (standarized): 0.25246588490261135\n",
      "          Validation Loss (standardized): 1.3628397970547024\n",
      "Epoch: 10, Loss (standarized): 0.22786460657349283\n",
      "          Validation Loss (standardized): 1.4740553501153317\n",
      "Epoch: 11, Loss (standarized): 0.21520819712830275\n",
      "          Validation Loss (standardized): 1.5779760351339691\n",
      "Epoch: 12, Loss (standarized): 0.20980798455221203\n",
      "          Validation Loss (standardized): 1.6727328534038433\n",
      "Epoch: 13, Loss (standarized): 0.20873632338659837\n",
      "          Validation Loss (standardized): 1.7532715221830324\n",
      "Epoch: 14, Loss (standarized): 0.20982327884523336\n",
      "          Validation Loss (standardized): 1.8154976442955015\n",
      "Epoch: 15, Loss (standarized): 0.2116158408869416\n",
      "          Validation Loss (standardized): 1.85813916865173\n",
      "Epoch: 16, Loss (standarized): 0.21315038257459545\n",
      "          Validation Loss (standardized): 1.8832964037367441\n",
      "Epoch: 17, Loss (standarized): 0.21412884180318417\n",
      "          Validation Loss (standardized): 1.8935723387307923\n",
      "Epoch: 18, Loss (standarized): 0.21440569241757002\n",
      "          Validation Loss (standardized): 1.8915804367171518\n",
      "Epoch: 19, Loss (standarized): 0.21411565788593495\n",
      "          Validation Loss (standardized): 1.8797304957823315\n",
      "Epoch: 20, Loss (standarized): 0.21330255248963007\n",
      "          Validation Loss (standardized): 1.86001029023672\n",
      "Final epoch: 20, Final loss (standarized): 0.21330255248963007\n",
      "Epoch: 1, Loss (standarized): 0.5495531262442407\n",
      "          Validation Loss (standardized): 0.7469643614306363\n",
      "Epoch: 2, Loss (standarized): 0.3876943941152436\n",
      "          Validation Loss (standardized): 0.8333150481772098\n",
      "Epoch: 3, Loss (standarized): 0.2940577638499807\n",
      "          Validation Loss (standardized): 0.9448570390672865\n",
      "Epoch: 4, Loss (standarized): 0.24643313074156756\n",
      "          Validation Loss (standardized): 1.0603385239755339\n",
      "Epoch: 5, Loss (standarized): 0.22385585943326244\n",
      "          Validation Loss (standardized): 1.1661483205532357\n",
      "Epoch: 6, Loss (standarized): 0.21360892095720882\n",
      "          Validation Loss (standardized): 1.2572560705588638\n",
      "Epoch: 7, Loss (standarized): 0.20903965189539944\n",
      "          Validation Loss (standardized): 1.3329319202378\n",
      "Epoch: 8, Loss (standarized): 0.20716878347537598\n",
      "          Validation Loss (standardized): 1.3937623990660724\n",
      "Epoch: 9, Loss (standarized): 0.20634035882232415\n",
      "          Validation Loss (standardized): 1.4400593930435464\n",
      "Epoch: 10, Loss (standarized): 0.20586157169409855\n",
      "          Validation Loss (standardized): 1.4731283620021545\n",
      "Epoch: 11, Loss (standarized): 0.2053911638923278\n",
      "          Validation Loss (standardized): 1.49423118124491\n",
      "Epoch: 12, Loss (standarized): 0.20475879711594563\n",
      "          Validation Loss (standardized): 1.5049223263790912\n",
      "Epoch: 13, Loss (standarized): 0.2038684568386163\n",
      "          Validation Loss (standardized): 1.506134684793887\n",
      "Epoch: 14, Loss (standarized): 0.202694869674507\n",
      "          Validation Loss (standardized): 1.4990961525436672\n",
      "Epoch: 15, Loss (standarized): 0.20128913969235782\n",
      "          Validation Loss (standardized): 1.484886322536067\n",
      "Epoch: 16, Loss (standarized): 0.19967580030927526\n",
      "          Validation Loss (standardized): 1.464285197875316\n",
      "Epoch: 17, Loss (standarized): 0.1979172596087169\n",
      "          Validation Loss (standardized): 1.4390979975989535\n",
      "Epoch: 18, Loss (standarized): 0.19608312214779597\n",
      "          Validation Loss (standardized): 1.4110559074763396\n",
      "Epoch: 19, Loss (standarized): 0.1942759347627221\n",
      "          Validation Loss (standardized): 1.3817940414289733\n",
      "Epoch: 20, Loss (standarized): 0.19259890151092915\n",
      "          Validation Loss (standardized): 1.352301149504568\n",
      "Final epoch: 20, Final loss (standarized): 0.19259890151092915\n",
      "Epoch: 1, Loss (standarized): 2.1737674483752754\n",
      "          Validation Loss (standardized): 1.0514830076087949\n",
      "Epoch: 2, Loss (standarized): 1.4591219664898438\n",
      "          Validation Loss (standardized): 0.8506056430259105\n",
      "Epoch: 3, Loss (standarized): 0.8958805446115329\n",
      "          Validation Loss (standardized): 0.79557676873044\n",
      "Epoch: 4, Loss (standarized): 0.51257458400789\n",
      "          Validation Loss (standardized): 0.8721988264744301\n",
      "Epoch: 5, Loss (standarized): 0.31855399354447267\n",
      "          Validation Loss (standardized): 1.0200377802369267\n",
      "Epoch: 6, Loss (standarized): 0.244756956285299\n",
      "          Validation Loss (standardized): 1.1863428513524128\n",
      "Epoch: 7, Loss (standarized): 0.22038615095990036\n",
      "          Validation Loss (standardized): 1.3459226007709366\n",
      "Epoch: 8, Loss (standarized): 0.214084421766581\n",
      "          Validation Loss (standardized): 1.4912368538017216\n",
      "Epoch: 9, Loss (standarized): 0.21468993669629166\n",
      "          Validation Loss (standardized): 1.620162497326216\n",
      "Epoch: 10, Loss (standarized): 0.21811569634412434\n",
      "          Validation Loss (standardized): 1.732243607226377\n",
      "Epoch: 11, Loss (standarized): 0.22257263737353156\n",
      "          Validation Loss (standardized): 1.8274512023411296\n",
      "Epoch: 12, Loss (standarized): 0.22717040039044367\n",
      "          Validation Loss (standardized): 1.9064407271989874\n",
      "Epoch: 13, Loss (standarized): 0.231360412729562\n",
      "          Validation Loss (standardized): 1.970642146237904\n",
      "Epoch: 14, Loss (standarized): 0.2348561844876501\n",
      "          Validation Loss (standardized): 2.021038644026263\n",
      "Epoch: 15, Loss (standarized): 0.2375822820032787\n",
      "          Validation Loss (standardized): 2.0587454460921033\n",
      "Epoch: 16, Loss (standarized): 0.23949579444777241\n",
      "          Validation Loss (standardized): 2.084945958542279\n",
      "Epoch: 17, Loss (standarized): 0.240601759273823\n",
      "          Validation Loss (standardized): 2.100775381450928\n",
      "Epoch: 18, Loss (standarized): 0.2410032021318632\n",
      "          Validation Loss (standardized): 2.1055050275757092\n",
      "Epoch: 19, Loss (standarized): 0.24048754809950706\n",
      "          Validation Loss (standardized): 2.1013939734486655\n",
      "Epoch: 20, Loss (standarized): 0.23942520009245916\n",
      "          Validation Loss (standardized): 2.090202597115223\n",
      "Final epoch: 20, Final loss (standarized): 0.23942520009245916\n",
      "Epoch: 1, Loss (standarized): 0.6561579600897078\n",
      "          Validation Loss (standardized): 0.8147897781680803\n",
      "Epoch: 2, Loss (standarized): 0.4859874965756447\n",
      "          Validation Loss (standardized): 0.9198834108397755\n",
      "Epoch: 3, Loss (standarized): 0.38415096801606835\n",
      "          Validation Loss (standardized): 1.043845873365754\n",
      "Epoch: 4, Loss (standarized): 0.3212565091196637\n",
      "          Validation Loss (standardized): 1.1701559217845068\n",
      "Epoch: 5, Loss (standarized): 0.28290482564077757\n",
      "          Validation Loss (standardized): 1.2902985615355549\n",
      "Epoch: 6, Loss (standarized): 0.2594335542311257\n",
      "          Validation Loss (standardized): 1.3997543868038247\n",
      "Epoch: 7, Loss (standarized): 0.24516757160348837\n",
      "          Validation Loss (standardized): 1.494836974823876\n",
      "Epoch: 8, Loss (standarized): 0.2365403957462682\n",
      "          Validation Loss (standardized): 1.5725605371348002\n",
      "Epoch: 9, Loss (standarized): 0.23101874335585101\n",
      "          Validation Loss (standardized): 1.632666204634525\n",
      "Epoch: 10, Loss (standarized): 0.22697710263343684\n",
      "          Validation Loss (standardized): 1.6753074179862266\n",
      "Epoch: 11, Loss (standarized): 0.2235081833590078\n",
      "          Validation Loss (standardized): 1.7016507648241657\n",
      "Epoch: 12, Loss (standarized): 0.2201502786351178\n",
      "          Validation Loss (standardized): 1.7134815722574879\n",
      "Epoch: 13, Loss (standarized): 0.21666720117421814\n",
      "          Validation Loss (standardized): 1.7124989461307003\n",
      "Epoch: 14, Loss (standarized): 0.21298517703622483\n",
      "          Validation Loss (standardized): 1.7002653983878273\n",
      "Epoch: 15, Loss (standarized): 0.20918428329135097\n",
      "          Validation Loss (standardized): 1.678429827274166\n",
      "Epoch: 16, Loss (standarized): 0.20527729850307197\n",
      "          Validation Loss (standardized): 1.6488875003346453\n",
      "Epoch: 17, Loss (standarized): 0.20144722996102526\n",
      "          Validation Loss (standardized): 1.6137239425967462\n",
      "Epoch: 18, Loss (standarized): 0.19787534376499957\n",
      "          Validation Loss (standardized): 1.5748651210807727\n",
      "Epoch: 19, Loss (standarized): 0.1947810390795291\n",
      "          Validation Loss (standardized): 1.5342368635888153\n",
      "Epoch: 20, Loss (standarized): 0.19226477503011008\n",
      "          Validation Loss (standardized): 1.493777588644832\n",
      "Final epoch: 20, Final loss (standarized): 0.19226477503011008\n",
      "Epoch: 1, Loss (standarized): 1.9471298347506676\n",
      "          Validation Loss (standardized): 1.0882050276163375\n",
      "Epoch: 2, Loss (standarized): 1.4441992733085565\n",
      "          Validation Loss (standardized): 0.972846655645727\n",
      "Epoch: 3, Loss (standarized): 1.0334297817695075\n",
      "          Validation Loss (standardized): 0.9253693321973568\n",
      "Epoch: 4, Loss (standarized): 0.7116729574013042\n",
      "          Validation Loss (standardized): 0.939964143606108\n",
      "Epoch: 5, Loss (standarized): 0.47128263418050675\n",
      "          Validation Loss (standardized): 1.0175741578008357\n",
      "Epoch: 6, Loss (standarized): 0.3152921221826528\n",
      "          Validation Loss (standardized): 1.1493279818218414\n",
      "Epoch: 7, Loss (standarized): 0.23873541169272758\n",
      "          Validation Loss (standardized): 1.3104330659205772\n",
      "Epoch: 8, Loss (standarized): 0.21180321128089355\n",
      "          Validation Loss (standardized): 1.477761297575798\n",
      "Epoch: 9, Loss (standarized): 0.20738478570412094\n",
      "          Validation Loss (standardized): 1.6373548435918648\n",
      "Epoch: 10, Loss (standarized): 0.21191259236608043\n",
      "          Validation Loss (standardized): 1.7836374074624368\n",
      "Epoch: 11, Loss (standarized): 0.21995572865192575\n",
      "          Validation Loss (standardized): 1.9139441512289963\n",
      "Epoch: 12, Loss (standarized): 0.2288259406170722\n",
      "          Validation Loss (standardized): 2.026895537457802\n",
      "Epoch: 13, Loss (standarized): 0.2373397734437629\n",
      "          Validation Loss (standardized): 2.122101435273227\n",
      "Epoch: 14, Loss (standarized): 0.2448969530978489\n",
      "          Validation Loss (standardized): 2.200030565683711\n",
      "Epoch: 15, Loss (standarized): 0.2513701966415138\n",
      "          Validation Loss (standardized): 2.261210562096707\n",
      "Epoch: 16, Loss (standarized): 0.25653613272551945\n",
      "          Validation Loss (standardized): 2.306350300973042\n",
      "Epoch: 17, Loss (standarized): 0.26036404406492547\n",
      "          Validation Loss (standardized): 2.3362635106982275\n",
      "Epoch: 18, Loss (standarized): 0.26288620842277116\n",
      "          Validation Loss (standardized): 2.3521648954054455\n",
      "Epoch: 19, Loss (standarized): 0.26417609780912105\n",
      "          Validation Loss (standardized): 2.355457736911817\n",
      "Epoch: 20, Loss (standarized): 0.2643236842976012\n",
      "          Validation Loss (standardized): 2.347369712651737\n",
      "Final epoch: 20, Final loss (standarized): 0.2643236842976012\n",
      "Epoch: 1, Loss (standarized): 0.5131807104352961\n",
      "          Validation Loss (standardized): 0.7931161330398317\n",
      "Epoch: 2, Loss (standarized): 0.3997419585288217\n",
      "          Validation Loss (standardized): 0.891861764034881\n",
      "Epoch: 3, Loss (standarized): 0.33422752230809466\n",
      "          Validation Loss (standardized): 0.997886087533157\n",
      "Epoch: 4, Loss (standarized): 0.2941966990844622\n",
      "          Validation Loss (standardized): 1.0988579843368207\n",
      "Epoch: 5, Loss (standarized): 0.26952921225224075\n",
      "          Validation Loss (standardized): 1.1891778784609295\n",
      "Epoch: 6, Loss (standarized): 0.25158450673320465\n",
      "          Validation Loss (standardized): 1.26638028073629\n",
      "Epoch: 7, Loss (standarized): 0.23797566879010262\n",
      "          Validation Loss (standardized): 1.3294711439863756\n",
      "Epoch: 8, Loss (standarized): 0.22755130739142548\n",
      "          Validation Loss (standardized): 1.3787147170809613\n",
      "Epoch: 9, Loss (standarized): 0.21915891682569683\n",
      "          Validation Loss (standardized): 1.4146796310293672\n",
      "Epoch: 10, Loss (standarized): 0.21212386820483192\n",
      "          Validation Loss (standardized): 1.4380206854001654\n",
      "Epoch: 11, Loss (standarized): 0.20595713148931283\n",
      "          Validation Loss (standardized): 1.4500294996955574\n",
      "Epoch: 12, Loss (standarized): 0.20048680869243066\n",
      "          Validation Loss (standardized): 1.4518740638893632\n",
      "Epoch: 13, Loss (standarized): 0.19570312672216617\n",
      "          Validation Loss (standardized): 1.444943759152426\n",
      "Epoch: 14, Loss (standarized): 0.19155834259425594\n",
      "          Validation Loss (standardized): 1.4315222207575664\n",
      "Epoch: 15, Loss (standarized): 0.18811692102849964\n",
      "          Validation Loss (standardized): 1.4144367341283486\n",
      "Epoch: 16, Loss (standarized): 0.1855047960222147\n",
      "          Validation Loss (standardized): 1.3965995498710173\n",
      "Epoch: 17, Loss (standarized): 0.18365185563177844\n",
      "          Validation Loss (standardized): 1.3798381265312014\n",
      "Epoch: 18, Loss (standarized): 0.1825434510808095\n",
      "          Validation Loss (standardized): 1.3647698220259799\n",
      "Epoch: 19, Loss (standarized): 0.18208509762095434\n",
      "          Validation Loss (standardized): 1.3518558856845164\n",
      "Epoch: 20, Loss (standarized): 0.18198028865228846\n",
      "          Validation Loss (standardized): 1.3423284252354029\n",
      "Final epoch: 20, Final loss (standarized): 0.18198028865228846\n",
      "Epoch: 1, Loss (standarized): 1.7525033199571025\n",
      "          Validation Loss (standardized): 1.0221803763036963\n",
      "Epoch: 2, Loss (standarized): 1.2246861029098082\n",
      "          Validation Loss (standardized): 0.935405536652369\n",
      "Epoch: 3, Loss (standarized): 0.82642315101651\n",
      "          Validation Loss (standardized): 0.9451777784150233\n",
      "Epoch: 4, Loss (standarized): 0.5490264138805359\n",
      "          Validation Loss (standardized): 1.0337946729343253\n",
      "Epoch: 5, Loss (standarized): 0.37687562688546755\n",
      "          Validation Loss (standardized): 1.1766164871919371\n",
      "Epoch: 6, Loss (standarized): 0.28170118934219257\n",
      "          Validation Loss (standardized): 1.349391031716253\n",
      "Epoch: 7, Loss (standarized): 0.2358577962152798\n",
      "          Validation Loss (standardized): 1.5287165612220373\n",
      "Epoch: 8, Loss (standarized): 0.21827032816042657\n",
      "          Validation Loss (standardized): 1.7033404967999906\n",
      "Epoch: 9, Loss (standarized): 0.2156875210855432\n",
      "          Validation Loss (standardized): 1.8660293576202793\n",
      "Epoch: 10, Loss (standarized): 0.22042601689243974\n",
      "          Validation Loss (standardized): 2.009861716064511\n",
      "Epoch: 11, Loss (standarized): 0.22788673537865023\n",
      "          Validation Loss (standardized): 2.1319053793524727\n",
      "Epoch: 12, Loss (standarized): 0.2358542093929886\n",
      "          Validation Loss (standardized): 2.2306943036935842\n",
      "Epoch: 13, Loss (standarized): 0.24305390982644928\n",
      "          Validation Loss (standardized): 2.306573012622841\n",
      "Epoch: 14, Loss (standarized): 0.24896294879119138\n",
      "          Validation Loss (standardized): 2.360061866839552\n",
      "Epoch: 15, Loss (standarized): 0.2532393650565412\n",
      "          Validation Loss (standardized): 2.393615271143903\n",
      "Epoch: 16, Loss (standarized): 0.2559389524607613\n",
      "          Validation Loss (standardized): 2.4092368686270125\n",
      "Epoch: 17, Loss (standarized): 0.2571749489763185\n",
      "          Validation Loss (standardized): 2.4088791490160526\n",
      "Epoch: 18, Loss (standarized): 0.25709528570400764\n",
      "          Validation Loss (standardized): 2.3948142715501985\n",
      "Epoch: 19, Loss (standarized): 0.2558386437941257\n",
      "          Validation Loss (standardized): 2.3691325513842707\n",
      "Epoch: 20, Loss (standarized): 0.2536159794733406\n",
      "          Validation Loss (standardized): 2.3337375644618334\n",
      "Final epoch: 20, Final loss (standarized): 0.2536159794733406\n",
      "Epoch: 1, Loss (standarized): 1.5126606195422128\n",
      "          Validation Loss (standardized): 0.8096677072870997\n",
      "Epoch: 2, Loss (standarized): 0.9894042426599065\n",
      "          Validation Loss (standardized): 0.7477025932001237\n",
      "Epoch: 3, Loss (standarized): 0.6383973184537431\n",
      "          Validation Loss (standardized): 0.807405976219058\n",
      "Epoch: 4, Loss (standarized): 0.4463783954387259\n",
      "          Validation Loss (standardized): 0.9283103242817135\n",
      "Epoch: 5, Loss (standarized): 0.3473790353840173\n",
      "          Validation Loss (standardized): 1.0725868241226617\n",
      "Epoch: 6, Loss (standarized): 0.2981763933565872\n",
      "          Validation Loss (standardized): 1.2211065482682242\n",
      "Epoch: 7, Loss (standarized): 0.2751235717489331\n",
      "          Validation Loss (standardized): 1.3634896225418975\n",
      "Epoch: 8, Loss (standarized): 0.26550629523703545\n",
      "          Validation Loss (standardized): 1.4938207239633663\n",
      "Epoch: 9, Loss (standarized): 0.26197261467471616\n",
      "          Validation Loss (standardized): 1.60955448767301\n",
      "Epoch: 10, Loss (standarized): 0.2612908250864083\n",
      "          Validation Loss (standardized): 1.709990422828565\n",
      "Epoch: 11, Loss (standarized): 0.26176417717544614\n",
      "          Validation Loss (standardized): 1.7948630952840008\n",
      "Epoch: 12, Loss (standarized): 0.2623918609482503\n",
      "          Validation Loss (standardized): 1.8642539637748856\n",
      "Epoch: 13, Loss (standarized): 0.26267162252271886\n",
      "          Validation Loss (standardized): 1.919205646376507\n",
      "Epoch: 14, Loss (standarized): 0.2624221122277876\n",
      "          Validation Loss (standardized): 1.9624554084749224\n",
      "Epoch: 15, Loss (standarized): 0.26141992588197577\n",
      "          Validation Loss (standardized): 1.9940518778202811\n",
      "Epoch: 16, Loss (standarized): 0.2594685174735977\n",
      "          Validation Loss (standardized): 2.0132518265645354\n",
      "Epoch: 17, Loss (standarized): 0.256812480128637\n",
      "          Validation Loss (standardized): 2.0187977696838773\n",
      "Epoch: 18, Loss (standarized): 0.253452286693361\n",
      "          Validation Loss (standardized): 2.009248215712249\n",
      "Epoch: 19, Loss (standarized): 0.249302623922085\n",
      "          Validation Loss (standardized): 1.9857881284047785\n",
      "Epoch: 20, Loss (standarized): 0.24411994659681427\n",
      "          Validation Loss (standardized): 1.9492981261301896\n",
      "Final epoch: 20, Final loss (standarized): 0.24411994659681427\n",
      "Epoch: 1, Loss (standarized): 1.2617054914843477\n",
      "          Validation Loss (standardized): 0.7925642073596606\n",
      "Epoch: 2, Loss (standarized): 0.9982227289029769\n",
      "          Validation Loss (standardized): 0.7244109337475416\n",
      "Epoch: 3, Loss (standarized): 0.7754542501930852\n",
      "          Validation Loss (standardized): 0.7031021987844659\n",
      "Epoch: 4, Loss (standarized): 0.6108616738447092\n",
      "          Validation Loss (standardized): 0.7236040766321142\n",
      "Epoch: 5, Loss (standarized): 0.49615810161701834\n",
      "          Validation Loss (standardized): 0.7746244135116492\n",
      "Epoch: 6, Loss (standarized): 0.4160634157600252\n",
      "          Validation Loss (standardized): 0.8450829199929896\n",
      "Epoch: 7, Loss (standarized): 0.35439097683353876\n",
      "          Validation Loss (standardized): 0.9346158326035211\n",
      "Epoch: 8, Loss (standarized): 0.30519776621649913\n",
      "          Validation Loss (standardized): 1.0428938880743694\n",
      "Epoch: 9, Loss (standarized): 0.2653540489495131\n",
      "          Validation Loss (standardized): 1.169830135701711\n",
      "Epoch: 10, Loss (standarized): 0.2375973743363351\n",
      "          Validation Loss (standardized): 1.3101398133486066\n",
      "Epoch: 11, Loss (standarized): 0.2203964668753809\n",
      "          Validation Loss (standardized): 1.4569091014555255\n",
      "Epoch: 12, Loss (standarized): 0.2126773400277184\n",
      "          Validation Loss (standardized): 1.6022763022128657\n",
      "Epoch: 13, Loss (standarized): 0.21203242903163538\n",
      "          Validation Loss (standardized): 1.738151983043449\n",
      "Epoch: 14, Loss (standarized): 0.21533019131374923\n",
      "          Validation Loss (standardized): 1.8576785402193956\n",
      "Epoch: 15, Loss (standarized): 0.22029648531290677\n",
      "          Validation Loss (standardized): 1.9563152250494027\n",
      "Epoch: 16, Loss (standarized): 0.22530147457133867\n",
      "          Validation Loss (standardized): 2.0319452583096553\n",
      "Epoch: 17, Loss (standarized): 0.2294794095958344\n",
      "          Validation Loss (standardized): 2.084305867031733\n",
      "Epoch: 18, Loss (standarized): 0.23235504640456753\n",
      "          Validation Loss (standardized): 2.114500061470058\n",
      "Epoch: 19, Loss (standarized): 0.2337467518985989\n",
      "          Validation Loss (standardized): 2.1240908235138303\n",
      "Epoch: 20, Loss (standarized): 0.23363682489326337\n",
      "          Validation Loss (standardized): 2.115462551890875\n",
      "Final epoch: 20, Final loss (standarized): 0.23363682489326337\n",
      "Epoch: 1, Loss (standarized): 1.6295878505008343\n",
      "          Validation Loss (standardized): 0.8781172314995218\n",
      "Epoch: 2, Loss (standarized): 1.1270005184655962\n",
      "          Validation Loss (standardized): 0.7925520362455383\n",
      "Epoch: 3, Loss (standarized): 0.7596611667917903\n",
      "          Validation Loss (standardized): 0.8002977330488171\n",
      "Epoch: 4, Loss (standarized): 0.5065050185221417\n",
      "          Validation Loss (standardized): 0.8816571780352135\n",
      "Epoch: 5, Loss (standarized): 0.3456242838114796\n",
      "          Validation Loss (standardized): 1.0179329712209924\n",
      "Epoch: 6, Loss (standarized): 0.26095944611563154\n",
      "          Validation Loss (standardized): 1.1818295135132244\n",
      "Epoch: 7, Loss (standarized): 0.22631338944531693\n",
      "          Validation Loss (standardized): 1.3498833465304563\n",
      "Epoch: 8, Loss (standarized): 0.2155934718396238\n",
      "          Validation Loss (standardized): 1.5082435532229568\n",
      "Epoch: 9, Loss (standarized): 0.21528225901259057\n",
      "          Validation Loss (standardized): 1.6517810036420593\n",
      "Epoch: 10, Loss (standarized): 0.21912521250553085\n",
      "          Validation Loss (standardized): 1.77716831377939\n",
      "Epoch: 11, Loss (standarized): 0.22441382557143907\n",
      "          Validation Loss (standardized): 1.8829995373216548\n",
      "Epoch: 12, Loss (standarized): 0.22963892493685373\n",
      "          Validation Loss (standardized): 1.968046066310602\n",
      "Epoch: 13, Loss (standarized): 0.23403240624195762\n",
      "          Validation Loss (standardized): 2.033195788265141\n",
      "Epoch: 14, Loss (standarized): 0.23734439102712676\n",
      "          Validation Loss (standardized): 2.0801994150866396\n",
      "Epoch: 15, Loss (standarized): 0.2395177081853883\n",
      "          Validation Loss (standardized): 2.1108604178662147\n",
      "Epoch: 16, Loss (standarized): 0.2405835860489328\n",
      "          Validation Loss (standardized): 2.127420597334034\n",
      "Epoch: 17, Loss (standarized): 0.2406493421524147\n",
      "          Validation Loss (standardized): 2.1313091159507196\n",
      "Epoch: 18, Loss (standarized): 0.2398160091734254\n",
      "          Validation Loss (standardized): 2.1240817589544325\n",
      "Epoch: 19, Loss (standarized): 0.2382736982991984\n",
      "          Validation Loss (standardized): 2.107412387428028\n",
      "Epoch: 20, Loss (standarized): 0.23612751748279798\n",
      "          Validation Loss (standardized): 2.0827781430646355\n",
      "Final epoch: 20, Final loss (standarized): 0.23612751748279798\n",
      "Epoch: 1, Loss (standarized): 1.5368039857370595\n",
      "          Validation Loss (standardized): 0.9327046899587227\n",
      "Epoch: 2, Loss (standarized): 1.214180917398957\n",
      "          Validation Loss (standardized): 0.8607075029095478\n",
      "Epoch: 3, Loss (standarized): 0.9505242305043239\n",
      "          Validation Loss (standardized): 0.8301156605365708\n",
      "Epoch: 4, Loss (standarized): 0.7316594435448717\n",
      "          Validation Loss (standardized): 0.8436421492819594\n",
      "Epoch: 5, Loss (standarized): 0.5581536111165137\n",
      "          Validation Loss (standardized): 0.9027893871184942\n",
      "Epoch: 6, Loss (standarized): 0.4260677234733361\n",
      "          Validation Loss (standardized): 1.0029254883135392\n",
      "Epoch: 7, Loss (standarized): 0.33175727574302466\n",
      "          Validation Loss (standardized): 1.1354590059550154\n",
      "Epoch: 8, Loss (standarized): 0.2707408105889311\n",
      "          Validation Loss (standardized): 1.2893165504618382\n",
      "Epoch: 9, Loss (standarized): 0.2366591853818164\n",
      "          Validation Loss (standardized): 1.4503805410675625\n",
      "Epoch: 10, Loss (standarized): 0.22230698579284308\n",
      "          Validation Loss (standardized): 1.6053179757771234\n",
      "Epoch: 11, Loss (standarized): 0.21931155228161267\n",
      "          Validation Loss (standardized): 1.7460732953870044\n",
      "Epoch: 12, Loss (standarized): 0.22176349718810462\n",
      "          Validation Loss (standardized): 1.8674586711204118\n",
      "Epoch: 13, Loss (standarized): 0.226237067040586\n",
      "          Validation Loss (standardized): 1.9669452154921014\n",
      "Epoch: 14, Loss (standarized): 0.23078391413547159\n",
      "          Validation Loss (standardized): 2.0431284342927323\n",
      "Epoch: 15, Loss (standarized): 0.23442980504959093\n",
      "          Validation Loss (standardized): 2.0962051052416584\n",
      "Epoch: 16, Loss (standarized): 0.23667476164538925\n",
      "          Validation Loss (standardized): 2.127214891456324\n",
      "Epoch: 17, Loss (standarized): 0.23740359723121104\n",
      "          Validation Loss (standardized): 2.138310567916108\n",
      "Epoch: 18, Loss (standarized): 0.23662532862003968\n",
      "          Validation Loss (standardized): 2.1323052983895368\n",
      "Epoch: 19, Loss (standarized): 0.23456214961733654\n",
      "          Validation Loss (standardized): 2.1117631472869784\n",
      "Epoch: 20, Loss (standarized): 0.23150320569742747\n",
      "          Validation Loss (standardized): 2.0799358948606774\n",
      "Final epoch: 20, Final loss (standarized): 0.23150320569742747\n",
      "Epoch: 1, Loss (standarized): 0.8777579899112199\n",
      "          Validation Loss (standardized): 0.6934607796458352\n",
      "Epoch: 2, Loss (standarized): 0.6085975745209786\n",
      "          Validation Loss (standardized): 0.7114016364319877\n",
      "Epoch: 3, Loss (standarized): 0.4332861921293614\n",
      "          Validation Loss (standardized): 0.7853050794115675\n",
      "Epoch: 4, Loss (standarized): 0.3276060050035149\n",
      "          Validation Loss (standardized): 0.8925383978189825\n",
      "Epoch: 5, Loss (standarized): 0.2664788142964021\n",
      "          Validation Loss (standardized): 1.0167796397503064\n",
      "Epoch: 6, Loss (standarized): 0.2316373910599425\n",
      "          Validation Loss (standardized): 1.147043923246019\n",
      "Epoch: 7, Loss (standarized): 0.2121613444191446\n",
      "          Validation Loss (standardized): 1.2774385970503779\n",
      "Epoch: 8, Loss (standarized): 0.2017966929565372\n",
      "          Validation Loss (standardized): 1.4052849136701122\n",
      "Epoch: 9, Loss (standarized): 0.1969942528057981\n",
      "          Validation Loss (standardized): 1.5283119066651085\n",
      "Epoch: 10, Loss (standarized): 0.1961067423937337\n",
      "          Validation Loss (standardized): 1.641683760220351\n",
      "Epoch: 11, Loss (standarized): 0.1974884242233659\n",
      "          Validation Loss (standardized): 1.741818418287946\n",
      "Epoch: 12, Loss (standarized): 0.2000000445568143\n",
      "          Validation Loss (standardized): 1.826470476558907\n",
      "Epoch: 13, Loss (standarized): 0.20280369900901854\n",
      "          Validation Loss (standardized): 1.8946925220494089\n",
      "Epoch: 14, Loss (standarized): 0.20537079210480993\n",
      "          Validation Loss (standardized): 1.9461691043694367\n",
      "Epoch: 15, Loss (standarized): 0.20740681335239386\n",
      "          Validation Loss (standardized): 1.9813034403382561\n",
      "Epoch: 16, Loss (standarized): 0.20868901857150782\n",
      "          Validation Loss (standardized): 2.001013481558617\n",
      "Epoch: 17, Loss (standarized): 0.20915240243922045\n",
      "          Validation Loss (standardized): 2.0067964449221987\n",
      "Epoch: 18, Loss (standarized): 0.20886889130585895\n",
      "          Validation Loss (standardized): 2.000181896727405\n",
      "Epoch: 19, Loss (standarized): 0.20795803703782195\n",
      "          Validation Loss (standardized): 1.9828251488415858\n",
      "Epoch: 20, Loss (standarized): 0.20652145342288733\n",
      "          Validation Loss (standardized): 1.9565366264173947\n",
      "Final epoch: 20, Final loss (standarized): 0.20652145342288733\n",
      "Epoch: 1, Loss (standarized): 1.0839777388526108\n",
      "          Validation Loss (standardized): 0.8265290989149292\n",
      "Epoch: 2, Loss (standarized): 0.6464148690049535\n",
      "          Validation Loss (standardized): 0.8825805272390985\n",
      "Epoch: 3, Loss (standarized): 0.3813483261877259\n",
      "          Validation Loss (standardized): 1.0473225087626423\n",
      "Epoch: 4, Loss (standarized): 0.262341007295618\n",
      "          Validation Loss (standardized): 1.254151130808683\n",
      "Epoch: 5, Loss (standarized): 0.22257131461894905\n",
      "          Validation Loss (standardized): 1.4562569220959438\n",
      "Epoch: 6, Loss (standarized): 0.21299003788228937\n",
      "          Validation Loss (standardized): 1.6361183804094872\n",
      "Epoch: 7, Loss (standarized): 0.2139794949655868\n",
      "          Validation Loss (standardized): 1.7881185655194438\n",
      "Epoch: 8, Loss (standarized): 0.21834531824084139\n",
      "          Validation Loss (standardized): 1.9106865209038222\n",
      "Epoch: 9, Loss (standarized): 0.2230319278419155\n",
      "          Validation Loss (standardized): 2.0053172805576467\n",
      "Epoch: 10, Loss (standarized): 0.22681693783519136\n",
      "          Validation Loss (standardized): 2.0737660751748677\n",
      "Epoch: 11, Loss (standarized): 0.22921398109411106\n",
      "          Validation Loss (standardized): 2.118503240661714\n",
      "Epoch: 12, Loss (standarized): 0.2300987206251808\n",
      "          Validation Loss (standardized): 2.1419217622060573\n",
      "Epoch: 13, Loss (standarized): 0.22956107513131954\n",
      "          Validation Loss (standardized): 2.1463157933792814\n",
      "Epoch: 14, Loss (standarized): 0.22773609368864603\n",
      "          Validation Loss (standardized): 2.1351011212946065\n",
      "Epoch: 15, Loss (standarized): 0.22490275639906182\n",
      "          Validation Loss (standardized): 2.1107223567794495\n",
      "Epoch: 16, Loss (standarized): 0.22136350407336988\n",
      "          Validation Loss (standardized): 2.075813504901127\n",
      "Epoch: 17, Loss (standarized): 0.21735667287717808\n",
      "          Validation Loss (standardized): 2.0328075295265386\n",
      "Epoch: 18, Loss (standarized): 0.21322490555299486\n",
      "          Validation Loss (standardized): 1.9843070946370835\n",
      "Epoch: 19, Loss (standarized): 0.20931255559444892\n",
      "          Validation Loss (standardized): 1.9324758151150825\n",
      "Epoch: 20, Loss (standarized): 0.20582262162631654\n",
      "          Validation Loss (standardized): 1.8793720282343571\n",
      "Final epoch: 20, Final loss (standarized): 0.20582262162631654\n",
      "Epoch: 1, Loss (standarized): 1.1548195937862917\n",
      "          Validation Loss (standardized): 0.7380665185192248\n",
      "Epoch: 2, Loss (standarized): 0.7874758655119112\n",
      "          Validation Loss (standardized): 0.7163162556078646\n",
      "Epoch: 3, Loss (standarized): 0.5403031670787833\n",
      "          Validation Loss (standardized): 0.7612831267083352\n",
      "Epoch: 4, Loss (standarized): 0.38933836264402727\n",
      "          Validation Loss (standardized): 0.8508022579036262\n",
      "Epoch: 5, Loss (standarized): 0.3033806814929823\n",
      "          Validation Loss (standardized): 0.9655511017399363\n",
      "Epoch: 6, Loss (standarized): 0.2582921698715511\n",
      "          Validation Loss (standardized): 1.0896079472225364\n",
      "Epoch: 7, Loss (standarized): 0.23565983106029922\n",
      "          Validation Loss (standardized): 1.2125549396786839\n",
      "Epoch: 8, Loss (standarized): 0.22518545189651235\n",
      "          Validation Loss (standardized): 1.328161342528436\n",
      "Epoch: 9, Loss (standarized): 0.22113144926932737\n",
      "          Validation Loss (standardized): 1.4334971525459566\n",
      "Epoch: 10, Loss (standarized): 0.22047792452655682\n",
      "          Validation Loss (standardized): 1.5270162969111616\n",
      "Epoch: 11, Loss (standarized): 0.221454431981785\n",
      "          Validation Loss (standardized): 1.6078935710046047\n",
      "Epoch: 12, Loss (standarized): 0.22307428508342772\n",
      "          Validation Loss (standardized): 1.6756659091040174\n",
      "Epoch: 13, Loss (standarized): 0.22472017413280376\n",
      "          Validation Loss (standardized): 1.730257727513391\n",
      "Epoch: 14, Loss (standarized): 0.22605178104016876\n",
      "          Validation Loss (standardized): 1.7720959915919963\n",
      "Epoch: 15, Loss (standarized): 0.22689354706727327\n",
      "          Validation Loss (standardized): 1.8018076551060762\n",
      "Epoch: 16, Loss (standarized): 0.22714535623756293\n",
      "          Validation Loss (standardized): 1.8201506340107756\n",
      "Epoch: 17, Loss (standarized): 0.2267767331173998\n",
      "          Validation Loss (standardized): 1.8281008894541124\n",
      "Epoch: 18, Loss (standarized): 0.2257941899343795\n",
      "          Validation Loss (standardized): 1.8266310699802102\n",
      "Epoch: 19, Loss (standarized): 0.22424908863521198\n",
      "          Validation Loss (standardized): 1.8167042897296535\n",
      "Epoch: 20, Loss (standarized): 0.2221788341063951\n",
      "          Validation Loss (standardized): 1.7994168303649778\n",
      "Final epoch: 20, Final loss (standarized): 0.2221788341063951\n",
      "Epoch: 1, Loss (standarized): 0.8905421140106411\n",
      "          Validation Loss (standardized): 0.702715494970347\n",
      "Epoch: 2, Loss (standarized): 0.6375263628206659\n",
      "          Validation Loss (standardized): 0.7307357457232928\n",
      "Epoch: 3, Loss (standarized): 0.48342561018866426\n",
      "          Validation Loss (standardized): 0.8045687316478621\n",
      "Epoch: 4, Loss (standarized): 0.3918387846563805\n",
      "          Validation Loss (standardized): 0.8991015985304487\n",
      "Epoch: 5, Loss (standarized): 0.33427567131165276\n",
      "          Validation Loss (standardized): 0.9989517002520714\n",
      "Epoch: 6, Loss (standarized): 0.29612050641360427\n",
      "          Validation Loss (standardized): 1.1026461491547868\n",
      "Epoch: 7, Loss (standarized): 0.2701547275722744\n",
      "          Validation Loss (standardized): 1.206862620100262\n",
      "Epoch: 8, Loss (standarized): 0.252957535660304\n",
      "          Validation Loss (standardized): 1.3076999086929209\n",
      "Epoch: 9, Loss (standarized): 0.24190190456633082\n",
      "          Validation Loss (standardized): 1.4019399678805342\n",
      "Epoch: 10, Loss (standarized): 0.23510824815873727\n",
      "          Validation Loss (standardized): 1.4884830775492817\n",
      "Epoch: 11, Loss (standarized): 0.23107888755949163\n",
      "          Validation Loss (standardized): 1.5671709553736395\n",
      "Epoch: 12, Loss (standarized): 0.2287968230540756\n",
      "          Validation Loss (standardized): 1.6361903070856465\n",
      "Epoch: 13, Loss (standarized): 0.22744623728530558\n",
      "          Validation Loss (standardized): 1.6928064647024967\n",
      "Epoch: 14, Loss (standarized): 0.22644715424153547\n",
      "          Validation Loss (standardized): 1.7364411504816335\n",
      "Epoch: 15, Loss (standarized): 0.22536478205162747\n",
      "          Validation Loss (standardized): 1.766153818535044\n",
      "Epoch: 16, Loss (standarized): 0.22389139948344758\n",
      "          Validation Loss (standardized): 1.782828576247489\n",
      "Epoch: 17, Loss (standarized): 0.22185272775595433\n",
      "          Validation Loss (standardized): 1.7879765763510724\n",
      "Epoch: 18, Loss (standarized): 0.21932865930374326\n",
      "          Validation Loss (standardized): 1.7830796396805806\n",
      "Epoch: 19, Loss (standarized): 0.21623148431170575\n",
      "          Validation Loss (standardized): 1.769204766218263\n",
      "Epoch: 20, Loss (standarized): 0.21275736597203376\n",
      "          Validation Loss (standardized): 1.746535321406796\n",
      "Final epoch: 20, Final loss (standarized): 0.21275736597203376\n",
      "Epoch: 1, Loss (standarized): 0.8701630693045141\n",
      "          Validation Loss (standardized): 0.717313741012723\n",
      "Epoch: 2, Loss (standarized): 0.5965446110933322\n",
      "          Validation Loss (standardized): 0.7415008790730971\n",
      "Epoch: 3, Loss (standarized): 0.41959633770493154\n",
      "          Validation Loss (standardized): 0.8246887631731588\n",
      "Epoch: 4, Loss (standarized): 0.3135966355327235\n",
      "          Validation Loss (standardized): 0.9424492532232293\n",
      "Epoch: 5, Loss (standarized): 0.2542244936482646\n",
      "          Validation Loss (standardized): 1.0770654392339225\n",
      "Epoch: 6, Loss (standarized): 0.22239270665257213\n",
      "          Validation Loss (standardized): 1.2166994292548885\n",
      "Epoch: 7, Loss (standarized): 0.20628807692299617\n",
      "          Validation Loss (standardized): 1.3547257415508418\n",
      "Epoch: 8, Loss (standarized): 0.19931855876584187\n",
      "          Validation Loss (standardized): 1.4865083509865302\n",
      "Epoch: 9, Loss (standarized): 0.19769455659463428\n",
      "          Validation Loss (standardized): 1.608698279095712\n",
      "Epoch: 10, Loss (standarized): 0.1992335559808018\n",
      "          Validation Loss (standardized): 1.717115606720728\n",
      "Epoch: 11, Loss (standarized): 0.2023829699008124\n",
      "          Validation Loss (standardized): 1.8090963011398586\n",
      "Epoch: 12, Loss (standarized): 0.20598154016663794\n",
      "          Validation Loss (standardized): 1.8837452686963916\n",
      "Epoch: 13, Loss (standarized): 0.2094175627179552\n",
      "          Validation Loss (standardized): 1.9411786415761199\n",
      "Epoch: 14, Loss (standarized): 0.2123013397266683\n",
      "          Validation Loss (standardized): 1.981716822188078\n",
      "Epoch: 15, Loss (standarized): 0.21442915653472489\n",
      "          Validation Loss (standardized): 2.00699297267546\n",
      "Epoch: 16, Loss (standarized): 0.21573364213135238\n",
      "          Validation Loss (standardized): 2.0187077110632377\n",
      "Epoch: 17, Loss (standarized): 0.21627349744189245\n",
      "          Validation Loss (standardized): 2.0187458695000497\n",
      "Epoch: 18, Loss (standarized): 0.21612480262557424\n",
      "          Validation Loss (standardized): 2.0086881332314475\n",
      "Epoch: 19, Loss (standarized): 0.21543584651118566\n",
      "          Validation Loss (standardized): 1.9903795273677805\n",
      "Epoch: 20, Loss (standarized): 0.21427232997113357\n",
      "          Validation Loss (standardized): 1.9652160715674947\n",
      "Final epoch: 20, Final loss (standarized): 0.21427232997113357\n",
      "Epoch: 1, Loss (standarized): 1.2830795747860846\n",
      "          Validation Loss (standardized): 0.834056236345302\n",
      "Epoch: 2, Loss (standarized): 0.9298804898008841\n",
      "          Validation Loss (standardized): 0.783943204167424\n",
      "Epoch: 3, Loss (standarized): 0.6712476203998617\n",
      "          Validation Loss (standardized): 0.7936452030335954\n",
      "Epoch: 4, Loss (standarized): 0.4846121700785117\n",
      "          Validation Loss (standardized): 0.8538084325241626\n",
      "Epoch: 5, Loss (standarized): 0.357628354417807\n",
      "          Validation Loss (standardized): 0.9503273326268927\n",
      "Epoch: 6, Loss (standarized): 0.2772380959562704\n",
      "          Validation Loss (standardized): 1.0731990489530852\n",
      "Epoch: 7, Loss (standarized): 0.23163420445407404\n",
      "          Validation Loss (standardized): 1.2074689345850858\n",
      "Epoch: 8, Loss (standarized): 0.2091379033997813\n",
      "          Validation Loss (standardized): 1.3402826321556995\n",
      "Epoch: 9, Loss (standarized): 0.2000423048479868\n",
      "          Validation Loss (standardized): 1.4633059697204556\n",
      "Epoch: 10, Loss (standarized): 0.1984670439662841\n",
      "          Validation Loss (standardized): 1.570930584860066\n",
      "Epoch: 11, Loss (standarized): 0.20044758056647521\n",
      "          Validation Loss (standardized): 1.660474355525841\n",
      "Epoch: 12, Loss (standarized): 0.20377441719889783\n",
      "          Validation Loss (standardized): 1.7311084562302437\n",
      "Epoch: 13, Loss (standarized): 0.20728680627266366\n",
      "          Validation Loss (standardized): 1.7828107811404685\n",
      "Epoch: 14, Loss (standarized): 0.21027952594796118\n",
      "          Validation Loss (standardized): 1.8159255137527333\n",
      "Epoch: 15, Loss (standarized): 0.21237165673610886\n",
      "          Validation Loss (standardized): 1.8323844361822685\n",
      "Epoch: 16, Loss (standarized): 0.21350605184756624\n",
      "          Validation Loss (standardized): 1.834471314464406\n",
      "Epoch: 17, Loss (standarized): 0.2137395298640837\n",
      "          Validation Loss (standardized): 1.8242795909682326\n",
      "Epoch: 18, Loss (standarized): 0.21317836955963593\n",
      "          Validation Loss (standardized): 1.8040530701625124\n",
      "Epoch: 19, Loss (standarized): 0.21195310725528832\n",
      "          Validation Loss (standardized): 1.775794692634346\n",
      "Epoch: 20, Loss (standarized): 0.21021758961353607\n",
      "          Validation Loss (standardized): 1.7409362472860541\n",
      "Final epoch: 20, Final loss (standarized): 0.21021758961353607\n",
      "Epoch: 1, Loss (standarized): 1.393894879732931\n",
      "          Validation Loss (standardized): 1.0457448161762364\n",
      "Epoch: 2, Loss (standarized): 1.088629229397985\n",
      "          Validation Loss (standardized): 1.0478534805751036\n",
      "Epoch: 3, Loss (standarized): 0.8724907121715214\n",
      "          Validation Loss (standardized): 1.0838657799679625\n",
      "Epoch: 4, Loss (standarized): 0.7084215855592926\n",
      "          Validation Loss (standardized): 1.1408890947579282\n",
      "Epoch: 5, Loss (standarized): 0.5773659140044809\n",
      "          Validation Loss (standardized): 1.208946361913791\n",
      "Epoch: 6, Loss (standarized): 0.47082990514818746\n",
      "          Validation Loss (standardized): 1.2814649902105975\n",
      "Epoch: 7, Loss (standarized): 0.38513372933416523\n",
      "          Validation Loss (standardized): 1.3550184078499297\n",
      "Epoch: 8, Loss (standarized): 0.3181393622391987\n",
      "          Validation Loss (standardized): 1.430044391604057\n",
      "Epoch: 9, Loss (standarized): 0.2692343751338665\n",
      "          Validation Loss (standardized): 1.5074603221707696\n",
      "Epoch: 10, Loss (standarized): 0.23783422028105525\n",
      "          Validation Loss (standardized): 1.5782217999757437\n",
      "Epoch: 11, Loss (standarized): 0.22052333212632144\n",
      "          Validation Loss (standardized): 1.6362679967078184\n",
      "Epoch: 12, Loss (standarized): 0.2122342657304307\n",
      "          Validation Loss (standardized): 1.6802626880158034\n",
      "Epoch: 13, Loss (standarized): 0.208782685063807\n",
      "          Validation Loss (standardized): 1.7113457044256632\n",
      "Epoch: 14, Loss (standarized): 0.20776709252117467\n",
      "          Validation Loss (standardized): 1.7295536744033795\n",
      "Epoch: 15, Loss (standarized): 0.20764585094752144\n",
      "          Validation Loss (standardized): 1.7350601843414393\n",
      "Epoch: 16, Loss (standarized): 0.20747557753559753\n",
      "          Validation Loss (standardized): 1.7285349494722417\n",
      "Epoch: 17, Loss (standarized): 0.20680829252290414\n",
      "          Validation Loss (standardized): 1.711401570734555\n",
      "Epoch: 18, Loss (standarized): 0.20556738922302661\n",
      "          Validation Loss (standardized): 1.6852247453690534\n",
      "Epoch: 19, Loss (standarized): 0.2037595648577914\n",
      "          Validation Loss (standardized): 1.6522251313260543\n",
      "Epoch: 20, Loss (standarized): 0.2015068706452826\n",
      "          Validation Loss (standardized): 1.6138483451239591\n",
      "Final epoch: 20, Final loss (standarized): 0.2015068706452826\n",
      "Epoch: 1, Loss (standarized): 0.3470122490614994\n",
      "          Validation Loss (standardized): 0.9045251225852248\n",
      "Epoch: 2, Loss (standarized): 0.27292169832223495\n",
      "          Validation Loss (standardized): 1.0224275695773661\n",
      "Epoch: 3, Loss (standarized): 0.23251046643734932\n",
      "          Validation Loss (standardized): 1.1427798954255024\n",
      "Epoch: 4, Loss (standarized): 0.21165495294524578\n",
      "          Validation Loss (standardized): 1.2535808406980053\n",
      "Epoch: 5, Loss (standarized): 0.20139025687028045\n",
      "          Validation Loss (standardized): 1.3497443158860272\n",
      "Epoch: 6, Loss (standarized): 0.19668534363015372\n",
      "          Validation Loss (standardized): 1.4289674029602253\n",
      "Epoch: 7, Loss (standarized): 0.19468207136077825\n",
      "          Validation Loss (standardized): 1.49086414763261\n",
      "Epoch: 8, Loss (standarized): 0.1939548441092242\n",
      "          Validation Loss (standardized): 1.5357637040570142\n",
      "Epoch: 9, Loss (standarized): 0.19368712537866298\n",
      "          Validation Loss (standardized): 1.5654216092503526\n",
      "Epoch: 10, Loss (standarized): 0.1933673807377177\n",
      "          Validation Loss (standardized): 1.581222443225624\n",
      "Epoch: 11, Loss (standarized): 0.19279949953448855\n",
      "          Validation Loss (standardized): 1.584694681783085\n",
      "Epoch: 12, Loss (standarized): 0.19197117386336834\n",
      "          Validation Loss (standardized): 1.577734782329029\n",
      "Epoch: 13, Loss (standarized): 0.19093902441823166\n",
      "          Validation Loss (standardized): 1.5627282320605422\n",
      "Epoch: 14, Loss (standarized): 0.18974862425547176\n",
      "          Validation Loss (standardized): 1.5407107621443732\n",
      "Epoch: 15, Loss (standarized): 0.18837997398888434\n",
      "          Validation Loss (standardized): 1.5120800406898962\n",
      "Epoch: 16, Loss (standarized): 0.1868351379500289\n",
      "          Validation Loss (standardized): 1.4785883394345152\n",
      "Epoch: 17, Loss (standarized): 0.18520524310834469\n",
      "          Validation Loss (standardized): 1.441596724915865\n",
      "Epoch: 18, Loss (standarized): 0.18364438755983972\n",
      "          Validation Loss (standardized): 1.4026396562133692\n",
      "Epoch: 19, Loss (standarized): 0.1822877334088392\n",
      "          Validation Loss (standardized): 1.3634423449218036\n",
      "Epoch: 20, Loss (standarized): 0.18122332425189164\n",
      "          Validation Loss (standardized): 1.3252313086451624\n",
      "Final epoch: 20, Final loss (standarized): 0.18122332425189164\n",
      "Epoch: 1, Loss (standarized): 1.363805792684469\n",
      "          Validation Loss (standardized): 0.8480862577177487\n",
      "Epoch: 2, Loss (standarized): 0.9902771820246086\n",
      "          Validation Loss (standardized): 0.7900191891349997\n",
      "Epoch: 3, Loss (standarized): 0.7275639332127595\n",
      "          Validation Loss (standardized): 0.7883395400677593\n",
      "Epoch: 4, Loss (standarized): 0.5443335726241353\n",
      "          Validation Loss (standardized): 0.8267927245315165\n",
      "Epoch: 5, Loss (standarized): 0.42224136629990494\n",
      "          Validation Loss (standardized): 0.8897137533958098\n",
      "Epoch: 6, Loss (standarized): 0.34284741370044464\n",
      "          Validation Loss (standardized): 0.9666707551723812\n",
      "Epoch: 7, Loss (standarized): 0.2921365193821685\n",
      "          Validation Loss (standardized): 1.0529077352701082\n",
      "Epoch: 8, Loss (standarized): 0.26083436772804536\n",
      "          Validation Loss (standardized): 1.1436572651009942\n",
      "Epoch: 9, Loss (standarized): 0.24190991398851308\n",
      "          Validation Loss (standardized): 1.2346062219113114\n",
      "Epoch: 10, Loss (standarized): 0.2305083719515678\n",
      "          Validation Loss (standardized): 1.3227446350095247\n",
      "Epoch: 11, Loss (standarized): 0.22348080604727225\n",
      "          Validation Loss (standardized): 1.4062806725674877\n",
      "Epoch: 12, Loss (standarized): 0.21939620050180425\n",
      "          Validation Loss (standardized): 1.4845051712620647\n",
      "Epoch: 13, Loss (standarized): 0.2171479993700833\n",
      "          Validation Loss (standardized): 1.556350550794085\n",
      "Epoch: 14, Loss (standarized): 0.2165041896440398\n",
      "          Validation Loss (standardized): 1.6203940514853725\n",
      "Epoch: 15, Loss (standarized): 0.21648484313849645\n",
      "          Validation Loss (standardized): 1.6745740314251436\n",
      "Epoch: 16, Loss (standarized): 0.21660015791658743\n",
      "          Validation Loss (standardized): 1.7183132244329513\n",
      "Epoch: 17, Loss (standarized): 0.21660372739774836\n",
      "          Validation Loss (standardized): 1.750652682182614\n",
      "Epoch: 18, Loss (standarized): 0.21624206792393671\n",
      "          Validation Loss (standardized): 1.7719126765399453\n",
      "Epoch: 19, Loss (standarized): 0.21544445405128687\n",
      "          Validation Loss (standardized): 1.7830472269693332\n",
      "Epoch: 20, Loss (standarized): 0.21422125448969614\n",
      "          Validation Loss (standardized): 1.7858172676439046\n",
      "Final epoch: 20, Final loss (standarized): 0.21422125448969614\n",
      "Epoch: 1, Loss (standarized): 0.443911666032313\n",
      "          Validation Loss (standardized): 0.9889889644409843\n",
      "Epoch: 2, Loss (standarized): 0.33483490596093685\n",
      "          Validation Loss (standardized): 1.1634551732857092\n",
      "Epoch: 3, Loss (standarized): 0.2720232291297567\n",
      "          Validation Loss (standardized): 1.343948311828776\n",
      "Epoch: 4, Loss (standarized): 0.24014365251560552\n",
      "          Validation Loss (standardized): 1.5081546820733587\n",
      "Epoch: 5, Loss (standarized): 0.22597002333136632\n",
      "          Validation Loss (standardized): 1.6450970880276592\n",
      "Epoch: 6, Loss (standarized): 0.2206512236485227\n",
      "          Validation Loss (standardized): 1.7476051504157142\n",
      "Epoch: 7, Loss (standarized): 0.21869975411977657\n",
      "          Validation Loss (standardized): 1.8147110529575565\n",
      "Epoch: 8, Loss (standarized): 0.21747989959857283\n",
      "          Validation Loss (standardized): 1.8489781735107789\n",
      "Epoch: 9, Loss (standarized): 0.21577744625374942\n",
      "          Validation Loss (standardized): 1.8546624436057604\n",
      "Epoch: 10, Loss (standarized): 0.21336377316922955\n",
      "          Validation Loss (standardized): 1.8373683885216372\n",
      "Epoch: 11, Loss (standarized): 0.2101169084514079\n",
      "          Validation Loss (standardized): 1.803195681929184\n",
      "Epoch: 12, Loss (standarized): 0.2064691805187326\n",
      "          Validation Loss (standardized): 1.7574937350932927\n",
      "Epoch: 13, Loss (standarized): 0.20268103058751774\n",
      "          Validation Loss (standardized): 1.7038600129151036\n",
      "Epoch: 14, Loss (standarized): 0.19889346688859\n",
      "          Validation Loss (standardized): 1.6461378143460121\n",
      "Epoch: 15, Loss (standarized): 0.19554146172566178\n",
      "          Validation Loss (standardized): 1.5873804236879332\n",
      "Epoch: 16, Loss (standarized): 0.1926728204501166\n",
      "          Validation Loss (standardized): 1.531102744279428\n",
      "Epoch: 17, Loss (standarized): 0.19036941505180976\n",
      "          Validation Loss (standardized): 1.479088567780165\n",
      "Epoch: 18, Loss (standarized): 0.1886290605494933\n",
      "          Validation Loss (standardized): 1.4314189854578272\n",
      "Epoch: 19, Loss (standarized): 0.1871304373624471\n",
      "          Validation Loss (standardized): 1.3899183774707302\n",
      "Epoch: 20, Loss (standarized): 0.18575567974558604\n",
      "          Validation Loss (standardized): 1.3564831960483854\n",
      "Final epoch: 20, Final loss (standarized): 0.18575567974558604\n",
      "Epoch: 1, Loss (standarized): 1.783034336065763\n",
      "          Validation Loss (standardized): 0.9484581758514756\n",
      "Epoch: 2, Loss (standarized): 1.3562848352984513\n",
      "          Validation Loss (standardized): 0.8097974425347436\n",
      "Epoch: 3, Loss (standarized): 1.0098739264604901\n",
      "          Validation Loss (standardized): 0.7286311363114737\n",
      "Epoch: 4, Loss (standarized): 0.7425402922724637\n",
      "          Validation Loss (standardized): 0.702602026414727\n",
      "Epoch: 5, Loss (standarized): 0.5509342555429239\n",
      "          Validation Loss (standardized): 0.7243891798360478\n",
      "Epoch: 6, Loss (standarized): 0.4265420754257139\n",
      "          Validation Loss (standardized): 0.7800783131609945\n",
      "Epoch: 7, Loss (standarized): 0.34871368230160443\n",
      "          Validation Loss (standardized): 0.8559986528205218\n",
      "Epoch: 8, Loss (standarized): 0.2994171458116727\n",
      "          Validation Loss (standardized): 0.9423518054362288\n",
      "Epoch: 9, Loss (standarized): 0.26783361879124284\n",
      "          Validation Loss (standardized): 1.0327388631186807\n",
      "Epoch: 10, Loss (standarized): 0.24751991138741936\n",
      "          Validation Loss (standardized): 1.1228760094090142\n",
      "Epoch: 11, Loss (standarized): 0.23453105617920728\n",
      "          Validation Loss (standardized): 1.210788568540794\n",
      "Epoch: 12, Loss (standarized): 0.2265070963143591\n",
      "          Validation Loss (standardized): 1.2946366046725215\n",
      "Epoch: 13, Loss (standarized): 0.2218588155554288\n",
      "          Validation Loss (standardized): 1.3729934863265363\n",
      "Epoch: 14, Loss (standarized): 0.21945759397832082\n",
      "          Validation Loss (standardized): 1.4448202368380334\n",
      "Epoch: 15, Loss (standarized): 0.21844267224561406\n",
      "          Validation Loss (standardized): 1.5091970654428264\n",
      "Epoch: 16, Loss (standarized): 0.21825048968587302\n",
      "          Validation Loss (standardized): 1.565585072357983\n",
      "Epoch: 17, Loss (standarized): 0.21851689818976006\n",
      "          Validation Loss (standardized): 1.6134365276248053\n",
      "Epoch: 18, Loss (standarized): 0.21890855367860418\n",
      "          Validation Loss (standardized): 1.6524339248355435\n",
      "Epoch: 19, Loss (standarized): 0.21915603819821994\n",
      "          Validation Loss (standardized): 1.682566554295879\n",
      "Epoch: 20, Loss (standarized): 0.219128985496733\n",
      "          Validation Loss (standardized): 1.7041759457231467\n",
      "Final epoch: 20, Final loss (standarized): 0.219128985496733\n",
      "Epoch: 1, Loss (standarized): 0.8276150330784804\n",
      "          Validation Loss (standardized): 0.686711762917225\n",
      "Epoch: 2, Loss (standarized): 0.4790277666894583\n",
      "          Validation Loss (standardized): 0.7655526095938101\n",
      "Epoch: 3, Loss (standarized): 0.312348484930571\n",
      "          Validation Loss (standardized): 0.9117179713544331\n",
      "Epoch: 4, Loss (standarized): 0.2455855531154436\n",
      "          Validation Loss (standardized): 1.076990643400424\n",
      "Epoch: 5, Loss (standarized): 0.21949017744417995\n",
      "          Validation Loss (standardized): 1.2398269231765133\n",
      "Epoch: 6, Loss (standarized): 0.21116322844908356\n",
      "          Validation Loss (standardized): 1.3912369230321866\n",
      "Epoch: 7, Loss (standarized): 0.21095119006696517\n",
      "          Validation Loss (standardized): 1.526998847025651\n",
      "Epoch: 8, Loss (standarized): 0.21434592391494098\n",
      "          Validation Loss (standardized): 1.6450488680511404\n",
      "Epoch: 9, Loss (standarized): 0.21913671233889484\n",
      "          Validation Loss (standardized): 1.7451234511382694\n",
      "Epoch: 10, Loss (standarized): 0.22404196269328558\n",
      "          Validation Loss (standardized): 1.827354302710944\n",
      "Epoch: 11, Loss (standarized): 0.2284673055193595\n",
      "          Validation Loss (standardized): 1.8923180733137783\n",
      "Epoch: 12, Loss (standarized): 0.23209669159624244\n",
      "          Validation Loss (standardized): 1.9407923587161815\n",
      "Epoch: 13, Loss (standarized): 0.2347160999881892\n",
      "          Validation Loss (standardized): 1.973787148650206\n",
      "Epoch: 14, Loss (standarized): 0.23626413423120257\n",
      "          Validation Loss (standardized): 1.9925629399136744\n",
      "Epoch: 15, Loss (standarized): 0.2367673937389571\n",
      "          Validation Loss (standardized): 1.9983891762147636\n",
      "Epoch: 16, Loss (standarized): 0.23630078569769153\n",
      "          Validation Loss (standardized): 1.992600082617512\n",
      "Epoch: 17, Loss (standarized): 0.23494109887219028\n",
      "          Validation Loss (standardized): 1.9765501664999152\n",
      "Epoch: 18, Loss (standarized): 0.23279297430623486\n",
      "          Validation Loss (standardized): 1.95156629574397\n",
      "Epoch: 19, Loss (standarized): 0.22998612313393987\n",
      "          Validation Loss (standardized): 1.919012075592767\n",
      "Epoch: 20, Loss (standarized): 0.2266412486926425\n",
      "          Validation Loss (standardized): 1.8803328770747327\n",
      "Final epoch: 20, Final loss (standarized): 0.2266412486926425\n",
      "Epoch: 1, Loss (standarized): 2.1493735472723277\n",
      "          Validation Loss (standardized): 1.0655322010405537\n",
      "Epoch: 2, Loss (standarized): 1.6187049307415964\n",
      "          Validation Loss (standardized): 0.8624799033729011\n",
      "Epoch: 3, Loss (standarized): 1.1692777474869775\n",
      "          Validation Loss (standardized): 0.7451746544642913\n",
      "Epoch: 4, Loss (standarized): 0.8431693886898999\n",
      "          Validation Loss (standardized): 0.7013437731745035\n",
      "Epoch: 5, Loss (standarized): 0.6240159953782115\n",
      "          Validation Loss (standardized): 0.7067300296079722\n",
      "Epoch: 6, Loss (standarized): 0.46810622331861146\n",
      "          Validation Loss (standardized): 0.7510274011421079\n",
      "Epoch: 7, Loss (standarized): 0.35808263195770534\n",
      "          Validation Loss (standardized): 0.8271033557363126\n",
      "Epoch: 8, Loss (standarized): 0.2859293643261802\n",
      "          Validation Loss (standardized): 0.9262121910068555\n",
      "Epoch: 9, Loss (standarized): 0.240804873115435\n",
      "          Validation Loss (standardized): 1.0409429563684807\n",
      "Epoch: 10, Loss (standarized): 0.214559116424173\n",
      "          Validation Loss (standardized): 1.1650215742911976\n",
      "Epoch: 11, Loss (standarized): 0.20116604856518425\n",
      "          Validation Loss (standardized): 1.2947100233728424\n",
      "Epoch: 12, Loss (standarized): 0.19607508397295223\n",
      "          Validation Loss (standardized): 1.427839335686012\n",
      "Epoch: 13, Loss (standarized): 0.1970855411395931\n",
      "          Validation Loss (standardized): 1.555222121366159\n",
      "Epoch: 14, Loss (standarized): 0.2013241814969979\n",
      "          Validation Loss (standardized): 1.6670344105199546\n",
      "Epoch: 15, Loss (standarized): 0.20658827849028075\n",
      "          Validation Loss (standardized): 1.7603491863865777\n",
      "Epoch: 16, Loss (standarized): 0.21148852669773596\n",
      "          Validation Loss (standardized): 1.8362111520583009\n",
      "Epoch: 17, Loss (standarized): 0.21572636720740612\n",
      "          Validation Loss (standardized): 1.8957157344867528\n",
      "Epoch: 18, Loss (standarized): 0.21906387463817373\n",
      "          Validation Loss (standardized): 1.9403436125878313\n",
      "Epoch: 19, Loss (standarized): 0.2215123815261342\n",
      "          Validation Loss (standardized): 1.971504710938562\n",
      "Epoch: 20, Loss (standarized): 0.22316146503393341\n",
      "          Validation Loss (standardized): 1.9905888339739153\n",
      "Final epoch: 20, Final loss (standarized): 0.22316146503393341\n",
      "Epoch: 1, Loss (standarized): 2.3926323872281023\n",
      "          Validation Loss (standardized): 1.1809892605603216\n",
      "Epoch: 2, Loss (standarized): 1.8295787338337461\n",
      "          Validation Loss (standardized): 0.9628303955301312\n",
      "Epoch: 3, Loss (standarized): 1.3508397043799911\n",
      "          Validation Loss (standardized): 0.8176925452735424\n",
      "Epoch: 4, Loss (standarized): 0.962853013989367\n",
      "          Validation Loss (standardized): 0.7482582981617825\n",
      "Epoch: 5, Loss (standarized): 0.6694012003985104\n",
      "          Validation Loss (standardized): 0.750900257564765\n",
      "Epoch: 6, Loss (standarized): 0.4717719157835717\n",
      "          Validation Loss (standardized): 0.8117723141511876\n",
      "Epoch: 7, Loss (standarized): 0.35173780306697044\n",
      "          Validation Loss (standardized): 0.9100444773893573\n",
      "Epoch: 8, Loss (standarized): 0.2839384753570636\n",
      "          Validation Loss (standardized): 1.027799606244708\n",
      "Epoch: 9, Loss (standarized): 0.24759530521829956\n",
      "          Validation Loss (standardized): 1.1532487059508287\n",
      "Epoch: 10, Loss (standarized): 0.22880216674223627\n",
      "          Validation Loss (standardized): 1.2791906505054962\n",
      "Epoch: 11, Loss (standarized): 0.2201931060939978\n",
      "          Validation Loss (standardized): 1.4021643077554793\n",
      "Epoch: 12, Loss (standarized): 0.21739564117805354\n",
      "          Validation Loss (standardized): 1.519934892367795\n",
      "Epoch: 13, Loss (standarized): 0.2178140233501219\n",
      "          Validation Loss (standardized): 1.6302213875354676\n",
      "Epoch: 14, Loss (standarized): 0.2200415855310872\n",
      "          Validation Loss (standardized): 1.7283152843175116\n",
      "Epoch: 15, Loss (standarized): 0.22311720820399722\n",
      "          Validation Loss (standardized): 1.813389577786747\n",
      "Epoch: 16, Loss (standarized): 0.226425322463018\n",
      "          Validation Loss (standardized): 1.8855067098231024\n",
      "Epoch: 17, Loss (standarized): 0.22959543499192447\n",
      "          Validation Loss (standardized): 1.9447444997449008\n",
      "Epoch: 18, Loss (standarized): 0.23233304325075912\n",
      "          Validation Loss (standardized): 1.9912808492593126\n",
      "Epoch: 19, Loss (standarized): 0.2344297229402797\n",
      "          Validation Loss (standardized): 2.0254019214246153\n",
      "Epoch: 20, Loss (standarized): 0.23586141475778286\n",
      "          Validation Loss (standardized): 2.0473308607868304\n",
      "Final epoch: 20, Final loss (standarized): 0.23586141475778286\n",
      "Epoch: 1, Loss (standarized): 2.103717775683884\n",
      "          Validation Loss (standardized): 1.0398482612403246\n",
      "Epoch: 2, Loss (standarized): 1.5892659567076504\n",
      "          Validation Loss (standardized): 0.8421058490754042\n",
      "Epoch: 3, Loss (standarized): 1.1549397736172506\n",
      "          Validation Loss (standardized): 0.7179575189381583\n",
      "Epoch: 4, Loss (standarized): 0.816367631868152\n",
      "          Validation Loss (standardized): 0.6670535506742405\n",
      "Epoch: 5, Loss (standarized): 0.5725144824544394\n",
      "          Validation Loss (standardized): 0.6783447112394692\n",
      "Epoch: 6, Loss (standarized): 0.4124034907761974\n",
      "          Validation Loss (standardized): 0.7352036861542516\n",
      "Epoch: 7, Loss (standarized): 0.31097012214482694\n",
      "          Validation Loss (standardized): 0.8238184204796809\n",
      "Epoch: 8, Loss (standarized): 0.2489229120858536\n",
      "          Validation Loss (standardized): 0.9325130569470887\n",
      "Epoch: 9, Loss (standarized): 0.214366042203664\n",
      "          Validation Loss (standardized): 1.0517582316926084\n",
      "Epoch: 10, Loss (standarized): 0.19731312587067573\n",
      "          Validation Loss (standardized): 1.1728179802178156\n",
      "Epoch: 11, Loss (standarized): 0.1904144410017655\n",
      "          Validation Loss (standardized): 1.289335145836274\n",
      "Epoch: 12, Loss (standarized): 0.18925646751839062\n",
      "          Validation Loss (standardized): 1.396779863124251\n",
      "Epoch: 13, Loss (standarized): 0.1910928875281299\n",
      "          Validation Loss (standardized): 1.4925804344477274\n",
      "Epoch: 14, Loss (standarized): 0.19427367444072316\n",
      "          Validation Loss (standardized): 1.5756147200580355\n",
      "Epoch: 15, Loss (standarized): 0.19784543603086027\n",
      "          Validation Loss (standardized): 1.6460712872442251\n",
      "Epoch: 16, Loss (standarized): 0.20131746820056218\n",
      "          Validation Loss (standardized): 1.7039357543420923\n",
      "Epoch: 17, Loss (standarized): 0.20432754166893416\n",
      "          Validation Loss (standardized): 1.7496201981469222\n",
      "Epoch: 18, Loss (standarized): 0.20667720036367687\n",
      "          Validation Loss (standardized): 1.7837485451584343\n",
      "Epoch: 19, Loss (standarized): 0.20829523875491351\n",
      "          Validation Loss (standardized): 1.8072025304962958\n",
      "Epoch: 20, Loss (standarized): 0.2091946272763216\n",
      "          Validation Loss (standardized): 1.82103262172481\n",
      "Final epoch: 20, Final loss (standarized): 0.2091946272763216\n",
      "Epoch: 1, Loss (standarized): 0.5207957329373953\n",
      "          Validation Loss (standardized): 0.987733524749714\n",
      "Epoch: 2, Loss (standarized): 0.35960733106839954\n",
      "          Validation Loss (standardized): 1.1123458369645511\n",
      "Epoch: 3, Loss (standarized): 0.2719768085582107\n",
      "          Validation Loss (standardized): 1.251050486909665\n",
      "Epoch: 4, Loss (standarized): 0.23098375110677025\n",
      "          Validation Loss (standardized): 1.386552783862058\n",
      "Epoch: 5, Loss (standarized): 0.21402762466317682\n",
      "          Validation Loss (standardized): 1.5067158526158244\n",
      "Epoch: 6, Loss (standarized): 0.2080755610990754\n",
      "          Validation Loss (standardized): 1.6051173454591494\n",
      "Epoch: 7, Loss (standarized): 0.20658142389880838\n",
      "          Validation Loss (standardized): 1.6799731333425683\n",
      "Epoch: 8, Loss (standarized): 0.20654113989377954\n",
      "          Validation Loss (standardized): 1.7319134987646703\n",
      "Epoch: 9, Loss (standarized): 0.20655025402100777\n",
      "          Validation Loss (standardized): 1.7625828864859914\n",
      "Epoch: 10, Loss (standarized): 0.2060430168516096\n",
      "          Validation Loss (standardized): 1.7736179917465724\n",
      "Epoch: 11, Loss (standarized): 0.2047566717363105\n",
      "          Validation Loss (standardized): 1.7676636841897146\n",
      "Epoch: 12, Loss (standarized): 0.20271394605195187\n",
      "          Validation Loss (standardized): 1.747832675928508\n",
      "Epoch: 13, Loss (standarized): 0.200170514359872\n",
      "          Validation Loss (standardized): 1.7182080647476465\n",
      "Epoch: 14, Loss (standarized): 0.19754053358694365\n",
      "          Validation Loss (standardized): 1.6819214576413613\n",
      "Epoch: 15, Loss (standarized): 0.19517429165764005\n",
      "          Validation Loss (standardized): 1.6412954105829174\n",
      "Epoch: 16, Loss (standarized): 0.1933005403802067\n",
      "          Validation Loss (standardized): 1.5978325495352532\n",
      "Epoch: 17, Loss (standarized): 0.19201266654253535\n",
      "          Validation Loss (standardized): 1.5563695432654725\n",
      "Epoch: 18, Loss (standarized): 0.19125735648880948\n",
      "          Validation Loss (standardized): 1.5216021083985305\n",
      "Epoch: 19, Loss (standarized): 0.19062943317641856\n",
      "          Validation Loss (standardized): 1.4950398889051195\n",
      "Epoch: 20, Loss (standarized): 0.18951813885286659\n",
      "          Validation Loss (standardized): 1.4758066159063952\n",
      "Final epoch: 20, Final loss (standarized): 0.18951813885286659\n",
      "Epoch: 1, Loss (standarized): 0.5712795341104541\n",
      "          Validation Loss (standardized): 0.7414286389949263\n",
      "Epoch: 2, Loss (standarized): 0.4092758036124388\n",
      "          Validation Loss (standardized): 0.8237204425086466\n",
      "Epoch: 3, Loss (standarized): 0.3095601129441012\n",
      "          Validation Loss (standardized): 0.9413539349358857\n",
      "Epoch: 4, Loss (standarized): 0.25267367450934414\n",
      "          Validation Loss (standardized): 1.0799932029464867\n",
      "Epoch: 5, Loss (standarized): 0.2218818867665395\n",
      "          Validation Loss (standardized): 1.2268997708344846\n",
      "Epoch: 6, Loss (standarized): 0.2060386219796432\n",
      "          Validation Loss (standardized): 1.3739637139271164\n",
      "Epoch: 7, Loss (standarized): 0.20004687584868855\n",
      "          Validation Loss (standardized): 1.5143315444736067\n",
      "Epoch: 8, Loss (standarized): 0.19984142927874407\n",
      "          Validation Loss (standardized): 1.643143184470169\n",
      "Epoch: 9, Loss (standarized): 0.20279068509044512\n",
      "          Validation Loss (standardized): 1.7526892451074696\n",
      "Epoch: 10, Loss (standarized): 0.20688690891824218\n",
      "          Validation Loss (standardized): 1.839599726298323\n",
      "Epoch: 11, Loss (standarized): 0.21085311923262876\n",
      "          Validation Loss (standardized): 1.9026313072031882\n",
      "Epoch: 12, Loss (standarized): 0.2139616531868481\n",
      "          Validation Loss (standardized): 1.9423118359823421\n",
      "Epoch: 13, Loss (standarized): 0.2158787157334859\n",
      "          Validation Loss (standardized): 1.9599134997440648\n",
      "Epoch: 14, Loss (standarized): 0.21650202420913048\n",
      "          Validation Loss (standardized): 1.9574161994936434\n",
      "Epoch: 15, Loss (standarized): 0.21584298576396643\n",
      "          Validation Loss (standardized): 1.9379943849876033\n",
      "Epoch: 16, Loss (standarized): 0.2140762257638433\n",
      "          Validation Loss (standardized): 1.904549649067968\n",
      "Epoch: 17, Loss (standarized): 0.21138470993626088\n",
      "          Validation Loss (standardized): 1.8595632387982848\n",
      "Epoch: 18, Loss (standarized): 0.20798122603287242\n",
      "          Validation Loss (standardized): 1.805707337283107\n",
      "Epoch: 19, Loss (standarized): 0.20413308695319293\n",
      "          Validation Loss (standardized): 1.7453653216690808\n",
      "Epoch: 20, Loss (standarized): 0.20003573169664893\n",
      "          Validation Loss (standardized): 1.6804865941938223\n",
      "Final epoch: 20, Final loss (standarized): 0.20003573169664893\n",
      "Epoch: 1, Loss (standarized): 0.7522850978434035\n",
      "          Validation Loss (standardized): 0.865253007701813\n",
      "Epoch: 2, Loss (standarized): 0.5108971160245153\n",
      "          Validation Loss (standardized): 0.9678411333494513\n",
      "Epoch: 3, Loss (standarized): 0.36507605461758647\n",
      "          Validation Loss (standardized): 1.1109037453646542\n",
      "Epoch: 4, Loss (standarized): 0.2843202057026242\n",
      "          Validation Loss (standardized): 1.272007876035499\n",
      "Epoch: 5, Loss (standarized): 0.24423319936969548\n",
      "          Validation Loss (standardized): 1.4345713040722887\n",
      "Epoch: 6, Loss (standarized): 0.22672937235241014\n",
      "          Validation Loss (standardized): 1.5855272175395465\n",
      "Epoch: 7, Loss (standarized): 0.22098867655777407\n",
      "          Validation Loss (standardized): 1.7184729819792535\n",
      "Epoch: 8, Loss (standarized): 0.22103739666024\n",
      "          Validation Loss (standardized): 1.8300836962793252\n",
      "Epoch: 9, Loss (standarized): 0.22339540652460196\n",
      "          Validation Loss (standardized): 1.9192184975898416\n",
      "Epoch: 10, Loss (standarized): 0.22626738054228715\n",
      "          Validation Loss (standardized): 1.9859605957240545\n",
      "Epoch: 11, Loss (standarized): 0.22863243603789563\n",
      "          Validation Loss (standardized): 2.031492607690294\n",
      "Epoch: 12, Loss (standarized): 0.23003319932619612\n",
      "          Validation Loss (standardized): 2.057580063598656\n",
      "Epoch: 13, Loss (standarized): 0.23031617651577513\n",
      "          Validation Loss (standardized): 2.066336413960667\n",
      "Epoch: 14, Loss (standarized): 0.2295719987218717\n",
      "          Validation Loss (standardized): 2.0599587771416346\n",
      "Epoch: 15, Loss (standarized): 0.22782979156694577\n",
      "          Validation Loss (standardized): 2.040508316895118\n",
      "Epoch: 16, Loss (standarized): 0.22526825323387853\n",
      "          Validation Loss (standardized): 2.0104271927325086\n",
      "Epoch: 17, Loss (standarized): 0.22210167792764507\n",
      "          Validation Loss (standardized): 1.9715575427500074\n",
      "Epoch: 18, Loss (standarized): 0.21855875066191488\n",
      "          Validation Loss (standardized): 1.9250362875603424\n",
      "Epoch: 19, Loss (standarized): 0.21465598191787594\n",
      "          Validation Loss (standardized): 1.871724376375421\n",
      "Epoch: 20, Loss (standarized): 0.21060443863064263\n",
      "          Validation Loss (standardized): 1.813299409852716\n",
      "Final epoch: 20, Final loss (standarized): 0.21060443863064263\n",
      "Epoch: 1, Loss (standarized): 0.45456247033672503\n",
      "          Validation Loss (standardized): 0.8937077783318793\n",
      "Epoch: 2, Loss (standarized): 0.29823786266051877\n",
      "          Validation Loss (standardized): 1.1018298209355673\n",
      "Epoch: 3, Loss (standarized): 0.2396214797369823\n",
      "          Validation Loss (standardized): 1.2867994138810055\n",
      "Epoch: 4, Loss (standarized): 0.22020500216091415\n",
      "          Validation Loss (standardized): 1.4320262004459772\n",
      "Epoch: 5, Loss (standarized): 0.21508211390190513\n",
      "          Validation Loss (standardized): 1.5363388178885538\n",
      "Epoch: 6, Loss (standarized): 0.2141347377860985\n",
      "          Validation Loss (standardized): 1.6059054120553486\n",
      "Epoch: 7, Loss (standarized): 0.21371363067932947\n",
      "          Validation Loss (standardized): 1.6476651632668708\n",
      "Epoch: 8, Loss (standarized): 0.212549042905569\n",
      "          Validation Loss (standardized): 1.6629054810881683\n",
      "Epoch: 9, Loss (standarized): 0.2103520497124156\n",
      "          Validation Loss (standardized): 1.655935908329283\n",
      "Epoch: 10, Loss (standarized): 0.20702828128748435\n",
      "          Validation Loss (standardized): 1.631518521177728\n",
      "Epoch: 11, Loss (standarized): 0.2030474077900595\n",
      "          Validation Loss (standardized): 1.594185107114238\n",
      "Epoch: 12, Loss (standarized): 0.19884273081529466\n",
      "          Validation Loss (standardized): 1.549072168656786\n",
      "Epoch: 13, Loss (standarized): 0.1948363109908945\n",
      "          Validation Loss (standardized): 1.5003587170099544\n",
      "Epoch: 14, Loss (standarized): 0.1912867776208138\n",
      "          Validation Loss (standardized): 1.4507504723032605\n",
      "Epoch: 15, Loss (standarized): 0.18883178615137558\n",
      "          Validation Loss (standardized): 1.4034538003530528\n",
      "Epoch: 16, Loss (standarized): 0.1876047374576907\n",
      "          Validation Loss (standardized): 1.3610284504457149\n",
      "Epoch: 17, Loss (standarized): 0.18745563224108164\n",
      "          Validation Loss (standardized): 1.3266113515613198\n",
      "Epoch: 18, Loss (standarized): 0.1878959422429578\n",
      "          Validation Loss (standardized): 1.3027551046463186\n",
      "Epoch: 19, Loss (standarized): 0.18798735370218655\n",
      "          Validation Loss (standardized): 1.2908895533421214\n",
      "Epoch: 20, Loss (standarized): 0.186997554094493\n",
      "          Validation Loss (standardized): 1.2863609039743977\n",
      "Final epoch: 20, Final loss (standarized): 0.186997554094493\n",
      "Epoch: 1, Loss (standarized): 0.7462582799316065\n",
      "          Validation Loss (standardized): 0.9570352504811911\n",
      "Epoch: 2, Loss (standarized): 0.5526188638301006\n",
      "          Validation Loss (standardized): 0.9772212000533591\n",
      "Epoch: 3, Loss (standarized): 0.4167110760422106\n",
      "          Validation Loss (standardized): 1.02503998903715\n",
      "Epoch: 4, Loss (standarized): 0.32857788650671693\n",
      "          Validation Loss (standardized): 1.0915997517977276\n",
      "Epoch: 5, Loss (standarized): 0.2725081610857341\n",
      "          Validation Loss (standardized): 1.16757326881642\n",
      "Epoch: 6, Loss (standarized): 0.2381369188781303\n",
      "          Validation Loss (standardized): 1.2418909351515692\n",
      "Epoch: 7, Loss (standarized): 0.2174362205766618\n",
      "          Validation Loss (standardized): 1.312734025417363\n",
      "Epoch: 8, Loss (standarized): 0.20558218920729657\n",
      "          Validation Loss (standardized): 1.3793962926780063\n",
      "Epoch: 9, Loss (standarized): 0.19954209822216762\n",
      "          Validation Loss (standardized): 1.4424825022996668\n",
      "Epoch: 10, Loss (standarized): 0.19724708985752065\n",
      "          Validation Loss (standardized): 1.5035106916550376\n",
      "Epoch: 11, Loss (standarized): 0.19689306756468283\n",
      "          Validation Loss (standardized): 1.5637415437308453\n",
      "Epoch: 12, Loss (standarized): 0.19707479939241612\n",
      "          Validation Loss (standardized): 1.6220675220739957\n",
      "Epoch: 13, Loss (standarized): 0.1970094654676655\n",
      "          Validation Loss (standardized): 1.6758378087392993\n",
      "Epoch: 14, Loss (standarized): 0.19653326091642767\n",
      "          Validation Loss (standardized): 1.721338351284139\n",
      "Epoch: 15, Loss (standarized): 0.19610832945758055\n",
      "          Validation Loss (standardized): 1.7554819700961752\n",
      "Epoch: 16, Loss (standarized): 0.19581456012167445\n",
      "          Validation Loss (standardized): 1.774906606607968\n",
      "Epoch: 17, Loss (standarized): 0.19539136197248297\n",
      "          Validation Loss (standardized): 1.7786521760144485\n",
      "Epoch: 18, Loss (standarized): 0.19466117074413355\n",
      "          Validation Loss (standardized): 1.7672778778934919\n",
      "Epoch: 19, Loss (standarized): 0.19339671833116506\n",
      "          Validation Loss (standardized): 1.7436986443173863\n",
      "Epoch: 20, Loss (standarized): 0.19180041261266145\n",
      "          Validation Loss (standardized): 1.7112632020360414\n",
      "Final epoch: 20, Final loss (standarized): 0.19180041261266145\n",
      "Epoch: 1, Loss (standarized): 1.3461390802655486\n",
      "          Validation Loss (standardized): 0.868957581660068\n",
      "Epoch: 2, Loss (standarized): 0.9196603399735378\n",
      "          Validation Loss (standardized): 0.8159461093827877\n",
      "Epoch: 3, Loss (standarized): 0.5963199932213235\n",
      "          Validation Loss (standardized): 0.8611382471987826\n",
      "Epoch: 4, Loss (standarized): 0.3929515838630033\n",
      "          Validation Loss (standardized): 0.9785979985455657\n",
      "Epoch: 5, Loss (standarized): 0.28598345052441076\n",
      "          Validation Loss (standardized): 1.1315269970573913\n",
      "Epoch: 6, Loss (standarized): 0.23691932643652233\n",
      "          Validation Loss (standardized): 1.2938418054830458\n",
      "Epoch: 7, Loss (standarized): 0.21784184402280754\n",
      "          Validation Loss (standardized): 1.4510000569647254\n",
      "Epoch: 8, Loss (standarized): 0.21310840717972832\n",
      "          Validation Loss (standardized): 1.5955080363480567\n",
      "Epoch: 9, Loss (standarized): 0.2147459864799565\n",
      "          Validation Loss (standardized): 1.7236764445486177\n",
      "Epoch: 10, Loss (standarized): 0.2189646371175071\n",
      "          Validation Loss (standardized): 1.833630992246246\n",
      "Epoch: 11, Loss (standarized): 0.22378591607768195\n",
      "          Validation Loss (standardized): 1.925192259871863\n",
      "Epoch: 12, Loss (standarized): 0.22822744584640872\n",
      "          Validation Loss (standardized): 1.999669022446553\n",
      "Epoch: 13, Loss (standarized): 0.23194045461334295\n",
      "          Validation Loss (standardized): 2.057265662954761\n",
      "Epoch: 14, Loss (standarized): 0.23477183401443866\n",
      "          Validation Loss (standardized): 2.096619749142354\n",
      "Epoch: 15, Loss (standarized): 0.23634953062567718\n",
      "          Validation Loss (standardized): 2.119413718159628\n",
      "Epoch: 16, Loss (standarized): 0.23674148287179594\n",
      "          Validation Loss (standardized): 2.127659057621561\n",
      "Epoch: 17, Loss (standarized): 0.23605065591050742\n",
      "          Validation Loss (standardized): 2.123939341482904\n",
      "Epoch: 18, Loss (standarized): 0.23453844073778515\n",
      "          Validation Loss (standardized): 2.110876495385268\n",
      "Epoch: 19, Loss (standarized): 0.23247788757536958\n",
      "          Validation Loss (standardized): 2.0902652814597316\n",
      "Epoch: 20, Loss (standarized): 0.22997105200074444\n",
      "          Validation Loss (standardized): 2.063759968574561\n",
      "Final epoch: 20, Final loss (standarized): 0.22997105200074444\n",
      "Epoch: 1, Loss (standarized): 0.9205653748657537\n",
      "          Validation Loss (standardized): 0.7318034638572039\n",
      "Epoch: 2, Loss (standarized): 0.6148184504559785\n",
      "          Validation Loss (standardized): 0.7733159252718558\n",
      "Epoch: 3, Loss (standarized): 0.42366133350087704\n",
      "          Validation Loss (standardized): 0.8745330061830423\n",
      "Epoch: 4, Loss (standarized): 0.3155966678573917\n",
      "          Validation Loss (standardized): 1.0050328517250813\n",
      "Epoch: 5, Loss (standarized): 0.258505861247889\n",
      "          Validation Loss (standardized): 1.1450232839386396\n",
      "Epoch: 6, Loss (standarized): 0.230405834101408\n",
      "          Validation Loss (standardized): 1.2817062083825908\n",
      "Epoch: 7, Loss (standarized): 0.21835175324312694\n",
      "          Validation Loss (standardized): 1.406727764111644\n",
      "Epoch: 8, Loss (standarized): 0.2144847898777766\n",
      "          Validation Loss (standardized): 1.5155975738980616\n",
      "Epoch: 9, Loss (standarized): 0.21450693397206838\n",
      "          Validation Loss (standardized): 1.6061884860033537\n",
      "Epoch: 10, Loss (standarized): 0.21605587980270793\n",
      "          Validation Loss (standardized): 1.6786199660597458\n",
      "Epoch: 11, Loss (standarized): 0.21788985430480476\n",
      "          Validation Loss (standardized): 1.7337072781274918\n",
      "Epoch: 12, Loss (standarized): 0.21940583242979267\n",
      "          Validation Loss (standardized): 1.7725937785399224\n",
      "Epoch: 13, Loss (standarized): 0.22035317134207982\n",
      "          Validation Loss (standardized): 1.7965141482981957\n",
      "Epoch: 14, Loss (standarized): 0.22054538294427234\n",
      "          Validation Loss (standardized): 1.806861063032859\n",
      "Epoch: 15, Loss (standarized): 0.21994833367684638\n",
      "          Validation Loss (standardized): 1.8052148138484674\n",
      "Epoch: 16, Loss (standarized): 0.2186092920237674\n",
      "          Validation Loss (standardized): 1.7932319273753308\n",
      "Epoch: 17, Loss (standarized): 0.21662872339884567\n",
      "          Validation Loss (standardized): 1.7725441517610898\n",
      "Epoch: 18, Loss (standarized): 0.21414025385686325\n",
      "          Validation Loss (standardized): 1.7447095389451488\n",
      "Epoch: 19, Loss (standarized): 0.21129140677424524\n",
      "          Validation Loss (standardized): 1.7110188885673652\n",
      "Epoch: 20, Loss (standarized): 0.2082300945228896\n",
      "          Validation Loss (standardized): 1.672684740079507\n",
      "Final epoch: 20, Final loss (standarized): 0.2082300945228896\n",
      "Epoch: 1, Loss (standarized): 0.42026775157087926\n",
      "          Validation Loss (standardized): 0.8101052213348495\n",
      "Epoch: 2, Loss (standarized): 0.3000891597284046\n",
      "          Validation Loss (standardized): 0.9448374898706261\n",
      "Epoch: 3, Loss (standarized): 0.24469283102923242\n",
      "          Validation Loss (standardized): 1.0888363615814216\n",
      "Epoch: 4, Loss (standarized): 0.2185323100499388\n",
      "          Validation Loss (standardized): 1.2222895111809828\n",
      "Epoch: 5, Loss (standarized): 0.20778732760336024\n",
      "          Validation Loss (standardized): 1.334634220334625\n",
      "Epoch: 6, Loss (standarized): 0.20392760363190227\n",
      "          Validation Loss (standardized): 1.4232088689913542\n",
      "Epoch: 7, Loss (standarized): 0.20284400669020605\n",
      "          Validation Loss (standardized): 1.486768307299084\n",
      "Epoch: 8, Loss (standarized): 0.20247566701930786\n",
      "          Validation Loss (standardized): 1.5281143702623519\n",
      "Epoch: 9, Loss (standarized): 0.2020065088875535\n",
      "          Validation Loss (standardized): 1.5502651202747189\n",
      "Epoch: 10, Loss (standarized): 0.2010993562147174\n",
      "          Validation Loss (standardized): 1.556232849598657\n",
      "Epoch: 11, Loss (standarized): 0.1996819186772763\n",
      "          Validation Loss (standardized): 1.548929909008628\n",
      "Epoch: 12, Loss (standarized): 0.19785284929157995\n",
      "          Validation Loss (standardized): 1.5305979269883812\n",
      "Epoch: 13, Loss (standarized): 0.19575516948702998\n",
      "          Validation Loss (standardized): 1.5040320657688242\n",
      "Epoch: 14, Loss (standarized): 0.1936036419829048\n",
      "          Validation Loss (standardized): 1.4714277500824666\n",
      "Epoch: 15, Loss (standarized): 0.1915491992911488\n",
      "          Validation Loss (standardized): 1.4351314419883818\n",
      "Epoch: 16, Loss (standarized): 0.1897461933048972\n",
      "          Validation Loss (standardized): 1.3970842193748205\n",
      "Epoch: 17, Loss (standarized): 0.18834964894820483\n",
      "          Validation Loss (standardized): 1.3587067657910081\n",
      "Epoch: 18, Loss (standarized): 0.18740393508556175\n",
      "          Validation Loss (standardized): 1.3213786911982992\n",
      "Epoch: 19, Loss (standarized): 0.18694769065123285\n",
      "          Validation Loss (standardized): 1.286851572704412\n",
      "Epoch: 20, Loss (standarized): 0.18697035370830273\n",
      "          Validation Loss (standardized): 1.2564984945718933\n",
      "Final epoch: 20, Final loss (standarized): 0.18697035370830273\n",
      "Epoch: 1, Loss (standarized): 0.8179433095803389\n",
      "          Validation Loss (standardized): 0.7426366666596542\n",
      "Epoch: 2, Loss (standarized): 0.4547866995877197\n",
      "          Validation Loss (standardized): 0.8417167863734376\n",
      "Epoch: 3, Loss (standarized): 0.27124695053219483\n",
      "          Validation Loss (standardized): 1.0238224610704314\n",
      "Epoch: 4, Loss (standarized): 0.21063312227125933\n",
      "          Validation Loss (standardized): 1.214873585690916\n",
      "Epoch: 5, Loss (standarized): 0.19710226109274973\n",
      "          Validation Loss (standardized): 1.385342132523688\n",
      "Epoch: 6, Loss (standarized): 0.19820975231130572\n",
      "          Validation Loss (standardized): 1.5301865035254363\n",
      "Epoch: 7, Loss (standarized): 0.20361694431172997\n",
      "          Validation Loss (standardized): 1.647995382871627\n",
      "Epoch: 8, Loss (standarized): 0.20956655534961058\n",
      "          Validation Loss (standardized): 1.740150533355301\n",
      "Epoch: 9, Loss (standarized): 0.21471295673780771\n",
      "          Validation Loss (standardized): 1.808714773372866\n",
      "Epoch: 10, Loss (standarized): 0.2186335137217932\n",
      "          Validation Loss (standardized): 1.855729851623896\n",
      "Epoch: 11, Loss (standarized): 0.22112539605233697\n",
      "          Validation Loss (standardized): 1.8842788259820293\n",
      "Epoch: 12, Loss (standarized): 0.22228743024028497\n",
      "          Validation Loss (standardized): 1.8967682160379338\n",
      "Epoch: 13, Loss (standarized): 0.22235828059660634\n",
      "          Validation Loss (standardized): 1.8957233316446207\n",
      "Epoch: 14, Loss (standarized): 0.22157006084164574\n",
      "          Validation Loss (standardized): 1.8829371612218588\n",
      "Epoch: 15, Loss (standarized): 0.2199506254949274\n",
      "          Validation Loss (standardized): 1.86017863327869\n",
      "Epoch: 16, Loss (standarized): 0.21768875513677718\n",
      "          Validation Loss (standardized): 1.828666467311558\n",
      "Epoch: 17, Loss (standarized): 0.21487089049831368\n",
      "          Validation Loss (standardized): 1.7901982037554294\n",
      "Epoch: 18, Loss (standarized): 0.21169368834717242\n",
      "          Validation Loss (standardized): 1.7464992544286144\n",
      "Epoch: 19, Loss (standarized): 0.20834305742561518\n",
      "          Validation Loss (standardized): 1.6990384170837962\n",
      "Epoch: 20, Loss (standarized): 0.20491165185028515\n",
      "          Validation Loss (standardized): 1.649064131527362\n",
      "Final epoch: 20, Final loss (standarized): 0.20491165185028515\n",
      "Epoch: 1, Loss (standarized): 1.1377418463229305\n",
      "          Validation Loss (standardized): 0.7592699105646671\n",
      "Epoch: 2, Loss (standarized): 0.9144219468716726\n",
      "          Validation Loss (standardized): 0.7094897310788576\n",
      "Epoch: 3, Loss (standarized): 0.7464556237102997\n",
      "          Validation Loss (standardized): 0.6899223168204643\n",
      "Epoch: 4, Loss (standarized): 0.6230820560456478\n",
      "          Validation Loss (standardized): 0.6925347623675928\n",
      "Epoch: 5, Loss (standarized): 0.5285780471860857\n",
      "          Validation Loss (standardized): 0.7125723728140104\n",
      "Epoch: 6, Loss (standarized): 0.4568707755112574\n",
      "          Validation Loss (standardized): 0.7444065517564323\n",
      "Epoch: 7, Loss (standarized): 0.4015158705755198\n",
      "          Validation Loss (standardized): 0.785097907393407\n",
      "Epoch: 8, Loss (standarized): 0.3571532136614542\n",
      "          Validation Loss (standardized): 0.8359910231654996\n",
      "Epoch: 9, Loss (standarized): 0.32078401355523894\n",
      "          Validation Loss (standardized): 0.8958790649005843\n",
      "Epoch: 10, Loss (standarized): 0.29053092066345393\n",
      "          Validation Loss (standardized): 0.9632099908230056\n",
      "Epoch: 11, Loss (standarized): 0.26573133630343365\n",
      "          Validation Loss (standardized): 1.035831721458927\n",
      "Epoch: 12, Loss (standarized): 0.2459211495136072\n",
      "          Validation Loss (standardized): 1.1115415957694836\n",
      "Epoch: 13, Loss (standarized): 0.23080405555383107\n",
      "          Validation Loss (standardized): 1.1883460884769002\n",
      "Epoch: 14, Loss (standarized): 0.21968409372323494\n",
      "          Validation Loss (standardized): 1.2635327759462935\n",
      "Epoch: 15, Loss (standarized): 0.21196644266034453\n",
      "          Validation Loss (standardized): 1.334693221134648\n",
      "Epoch: 16, Loss (standarized): 0.20681537135055822\n",
      "          Validation Loss (standardized): 1.4000948443452443\n",
      "Epoch: 17, Loss (standarized): 0.20355622500415668\n",
      "          Validation Loss (standardized): 1.4581203025337408\n",
      "Epoch: 18, Loss (standarized): 0.20172122393208025\n",
      "          Validation Loss (standardized): 1.5075409501676609\n",
      "Epoch: 19, Loss (standarized): 0.20077711998935374\n",
      "          Validation Loss (standardized): 1.547452313025036\n",
      "Epoch: 20, Loss (standarized): 0.2003104738225843\n",
      "          Validation Loss (standardized): 1.5775052816563244\n",
      "Final epoch: 20, Final loss (standarized): 0.2003104738225843\n",
      "Epoch: 1, Loss (standarized): 0.5454827750633963\n",
      "          Validation Loss (standardized): 0.8136650965813618\n",
      "Epoch: 2, Loss (standarized): 0.39242598156201347\n",
      "          Validation Loss (standardized): 0.9286252158211836\n",
      "Epoch: 3, Loss (standarized): 0.3001295977531221\n",
      "          Validation Loss (standardized): 1.0729164098536943\n",
      "Epoch: 4, Loss (standarized): 0.24963704385061902\n",
      "          Validation Loss (standardized): 1.2288026218359784\n",
      "Epoch: 5, Loss (standarized): 0.22513962591424258\n",
      "          Validation Loss (standardized): 1.3809066971122852\n",
      "Epoch: 6, Loss (standarized): 0.2153062187014842\n",
      "          Validation Loss (standardized): 1.5190020771168713\n",
      "Epoch: 7, Loss (standarized): 0.21286927014795354\n",
      "          Validation Loss (standardized): 1.6371278482236267\n",
      "Epoch: 8, Loss (standarized): 0.21360929159774245\n",
      "          Validation Loss (standardized): 1.7333232279784048\n",
      "Epoch: 9, Loss (standarized): 0.21523150825587237\n",
      "          Validation Loss (standardized): 1.8064980194903881\n",
      "Epoch: 10, Loss (standarized): 0.2165219757230953\n",
      "          Validation Loss (standardized): 1.8573352267055692\n",
      "Epoch: 11, Loss (standarized): 0.217014516415722\n",
      "          Validation Loss (standardized): 1.8880305457662303\n",
      "Epoch: 12, Loss (standarized): 0.2166076009633066\n",
      "          Validation Loss (standardized): 1.9009890701682315\n",
      "Epoch: 13, Loss (standarized): 0.21545965389427854\n",
      "          Validation Loss (standardized): 1.8990507592249737\n",
      "Epoch: 14, Loss (standarized): 0.21383458406873312\n",
      "          Validation Loss (standardized): 1.8846149100263114\n",
      "Epoch: 15, Loss (standarized): 0.2117466221935948\n",
      "          Validation Loss (standardized): 1.8597542938624736\n",
      "Epoch: 16, Loss (standarized): 0.20933245732717687\n",
      "          Validation Loss (standardized): 1.8264022317490256\n",
      "Epoch: 17, Loss (standarized): 0.2068711140205551\n",
      "          Validation Loss (standardized): 1.7861731790643496\n",
      "Epoch: 18, Loss (standarized): 0.2043768677899315\n",
      "          Validation Loss (standardized): 1.7409071759035677\n",
      "Epoch: 19, Loss (standarized): 0.20189105458228135\n",
      "          Validation Loss (standardized): 1.6928486084470855\n",
      "Epoch: 20, Loss (standarized): 0.19955558330118547\n",
      "          Validation Loss (standardized): 1.6436939473992564\n",
      "Final epoch: 20, Final loss (standarized): 0.19955558330118547\n",
      "Epoch: 1, Loss (standarized): 1.8129334075970067\n",
      "          Validation Loss (standardized): 0.8876452729931935\n",
      "Epoch: 2, Loss (standarized): 1.2401851294230544\n",
      "          Validation Loss (standardized): 0.7227616162914501\n",
      "Epoch: 3, Loss (standarized): 0.7991389543193886\n",
      "          Validation Loss (standardized): 0.6746178384001723\n",
      "Epoch: 4, Loss (standarized): 0.517967470907215\n",
      "          Validation Loss (standardized): 0.7146746940410285\n",
      "Epoch: 5, Loss (standarized): 0.3629195963792184\n",
      "          Validation Loss (standardized): 0.802352268775613\n",
      "Epoch: 6, Loss (standarized): 0.2801150117976867\n",
      "          Validation Loss (standardized): 0.912278862021369\n",
      "Epoch: 7, Loss (standarized): 0.2376224195006275\n",
      "          Validation Loss (standardized): 1.0295237403319362\n",
      "Epoch: 8, Loss (standarized): 0.21702210480432382\n",
      "          Validation Loss (standardized): 1.1445427912367525\n",
      "Epoch: 9, Loss (standarized): 0.2065737173240366\n",
      "          Validation Loss (standardized): 1.2518560486842267\n",
      "Epoch: 10, Loss (standarized): 0.20164725989704912\n",
      "          Validation Loss (standardized): 1.3498816616783922\n",
      "Epoch: 11, Loss (standarized): 0.19975495046783912\n",
      "          Validation Loss (standardized): 1.4376558034186826\n",
      "Epoch: 12, Loss (standarized): 0.1996467873471625\n",
      "          Validation Loss (standardized): 1.515079084141592\n",
      "Epoch: 13, Loss (standarized): 0.20046499446695817\n",
      "          Validation Loss (standardized): 1.5830044693840941\n",
      "Epoch: 14, Loss (standarized): 0.2019005780911064\n",
      "          Validation Loss (standardized): 1.6415386042247406\n",
      "Epoch: 15, Loss (standarized): 0.20362015623002636\n",
      "          Validation Loss (standardized): 1.6905205754973032\n",
      "Epoch: 16, Loss (standarized): 0.20530178301891613\n",
      "          Validation Loss (standardized): 1.7302253400433756\n",
      "Epoch: 17, Loss (standarized): 0.20680223138453763\n",
      "          Validation Loss (standardized): 1.7611463993615775\n",
      "Epoch: 18, Loss (standarized): 0.2080117762599005\n",
      "          Validation Loss (standardized): 1.7833318591582026\n",
      "Epoch: 19, Loss (standarized): 0.20884780882230627\n",
      "          Validation Loss (standardized): 1.7969476841186642\n",
      "Epoch: 20, Loss (standarized): 0.20923810405253881\n",
      "          Validation Loss (standardized): 1.8019565903419277\n",
      "Final epoch: 20, Final loss (standarized): 0.20923810405253881\n",
      "Epoch: 1, Loss (standarized): 0.4496733514275121\n",
      "          Validation Loss (standardized): 0.9851747908083265\n",
      "Epoch: 2, Loss (standarized): 0.2998960793678898\n",
      "          Validation Loss (standardized): 1.2060120784510258\n",
      "Epoch: 3, Loss (standarized): 0.23526428309723454\n",
      "          Validation Loss (standardized): 1.4290542925083256\n",
      "Epoch: 4, Loss (standarized): 0.2139306838046922\n",
      "          Validation Loss (standardized): 1.6226636541210047\n",
      "Epoch: 5, Loss (standarized): 0.21071466150529558\n",
      "          Validation Loss (standardized): 1.7740288262732848\n",
      "Epoch: 6, Loss (standarized): 0.21364491542084924\n",
      "          Validation Loss (standardized): 1.8811129649090352\n",
      "Epoch: 7, Loss (standarized): 0.21773766573805703\n",
      "          Validation Loss (standardized): 1.944328158902336\n",
      "Epoch: 8, Loss (standarized): 0.2209370408103986\n",
      "          Validation Loss (standardized): 1.966386547133213\n",
      "Epoch: 9, Loss (standarized): 0.22221573643838893\n",
      "          Validation Loss (standardized): 1.9557913579258206\n",
      "Epoch: 10, Loss (standarized): 0.22163398820285682\n",
      "          Validation Loss (standardized): 1.9203098924340736\n",
      "Epoch: 11, Loss (standarized): 0.21959225113901204\n",
      "          Validation Loss (standardized): 1.8667490438039958\n",
      "Epoch: 12, Loss (standarized): 0.21649000535398186\n",
      "          Validation Loss (standardized): 1.8027616895535328\n",
      "Epoch: 13, Loss (standarized): 0.21282885550666705\n",
      "          Validation Loss (standardized): 1.7307484530205146\n",
      "Epoch: 14, Loss (standarized): 0.20883657471940537\n",
      "          Validation Loss (standardized): 1.653363049581065\n",
      "Epoch: 15, Loss (standarized): 0.20476884520553973\n",
      "          Validation Loss (standardized): 1.5740075755449505\n",
      "Epoch: 16, Loss (standarized): 0.20105670604968487\n",
      "          Validation Loss (standardized): 1.4958632552049789\n",
      "Epoch: 17, Loss (standarized): 0.19788889823010494\n",
      "          Validation Loss (standardized): 1.4218956275757515\n",
      "Epoch: 18, Loss (standarized): 0.1954343012534616\n",
      "          Validation Loss (standardized): 1.355571020854208\n",
      "Epoch: 19, Loss (standarized): 0.19355086506737415\n",
      "          Validation Loss (standardized): 1.299349875356729\n",
      "Epoch: 20, Loss (standarized): 0.19192781573716766\n",
      "          Validation Loss (standardized): 1.254830973967749\n",
      "Final epoch: 20, Final loss (standarized): 0.19192781573716766\n",
      "Epoch: 1, Loss (standarized): 0.7846367981912522\n",
      "          Validation Loss (standardized): 0.6947806179546189\n",
      "Epoch: 2, Loss (standarized): 0.5248029020260114\n",
      "          Validation Loss (standardized): 0.7688770770952479\n",
      "Epoch: 3, Loss (standarized): 0.36789469169599404\n",
      "          Validation Loss (standardized): 0.9012383392087906\n",
      "Epoch: 4, Loss (standarized): 0.2804565705181114\n",
      "          Validation Loss (standardized): 1.062543844000031\n",
      "Epoch: 5, Loss (standarized): 0.23547958556171655\n",
      "          Validation Loss (standardized): 1.2328715747549408\n",
      "Epoch: 6, Loss (standarized): 0.21477735221472466\n",
      "          Validation Loss (standardized): 1.400213837292074\n",
      "Epoch: 7, Loss (standarized): 0.2074163256887488\n",
      "          Validation Loss (standardized): 1.5566626968948811\n",
      "Epoch: 8, Loss (standarized): 0.20759940167292867\n",
      "          Validation Loss (standardized): 1.69564827174791\n",
      "Epoch: 9, Loss (standarized): 0.2113938986605873\n",
      "          Validation Loss (standardized): 1.8142580737629077\n",
      "Epoch: 10, Loss (standarized): 0.21649827567340746\n",
      "          Validation Loss (standardized): 1.910881520060998\n",
      "Epoch: 11, Loss (standarized): 0.22148410533886606\n",
      "          Validation Loss (standardized): 1.9838359944437771\n",
      "Epoch: 12, Loss (standarized): 0.225436764069523\n",
      "          Validation Loss (standardized): 2.0355188355097504\n",
      "Epoch: 13, Loss (standarized): 0.22817678038351707\n",
      "          Validation Loss (standardized): 2.067283294494256\n",
      "Epoch: 14, Loss (standarized): 0.22962146934971114\n",
      "          Validation Loss (standardized): 2.080584949420926\n",
      "Epoch: 15, Loss (standarized): 0.22973443999651907\n",
      "          Validation Loss (standardized): 2.0777624248542943\n",
      "Epoch: 16, Loss (standarized): 0.22863897737398822\n",
      "          Validation Loss (standardized): 2.061109167542732\n",
      "Epoch: 17, Loss (standarized): 0.226535315042352\n",
      "          Validation Loss (standardized): 2.0324232047062756\n",
      "Epoch: 18, Loss (standarized): 0.22368101359701414\n",
      "          Validation Loss (standardized): 1.9935972784137583\n",
      "Epoch: 19, Loss (standarized): 0.22022573996854844\n",
      "          Validation Loss (standardized): 1.9468386605840513\n",
      "Epoch: 20, Loss (standarized): 0.21625205569295214\n",
      "          Validation Loss (standardized): 1.8941588382307015\n",
      "Final epoch: 20, Final loss (standarized): 0.21625205569295214\n",
      "Epoch: 1, Loss (standarized): 1.0029501149289088\n",
      "          Validation Loss (standardized): 0.7873865537455416\n",
      "Epoch: 2, Loss (standarized): 0.7439705208410868\n",
      "          Validation Loss (standardized): 0.7959845781560944\n",
      "Epoch: 3, Loss (standarized): 0.5631465525830152\n",
      "          Validation Loss (standardized): 0.8456300098846069\n",
      "Epoch: 4, Loss (standarized): 0.44197186320106097\n",
      "          Validation Loss (standardized): 0.9226064162694478\n",
      "Epoch: 5, Loss (standarized): 0.3604716130154341\n",
      "          Validation Loss (standardized): 1.0154202708099525\n",
      "Epoch: 6, Loss (standarized): 0.3057448232266393\n",
      "          Validation Loss (standardized): 1.1182478522344603\n",
      "Epoch: 7, Loss (standarized): 0.270811709254439\n",
      "          Validation Loss (standardized): 1.2251580235908568\n",
      "Epoch: 8, Loss (standarized): 0.24899554483239258\n",
      "          Validation Loss (standardized): 1.3298441079929262\n",
      "Epoch: 9, Loss (standarized): 0.23510710407717814\n",
      "          Validation Loss (standardized): 1.429688171078221\n",
      "Epoch: 10, Loss (standarized): 0.22600453264617013\n",
      "          Validation Loss (standardized): 1.5236445849360638\n",
      "Epoch: 11, Loss (standarized): 0.22028670090611494\n",
      "          Validation Loss (standardized): 1.6095635331444818\n",
      "Epoch: 12, Loss (standarized): 0.2170650793386506\n",
      "          Validation Loss (standardized): 1.6871647869505475\n",
      "Epoch: 13, Loss (standarized): 0.21577286426052925\n",
      "          Validation Loss (standardized): 1.7567851113141961\n",
      "Epoch: 14, Loss (standarized): 0.21565404254689619\n",
      "          Validation Loss (standardized): 1.8174929603960401\n",
      "Epoch: 15, Loss (standarized): 0.21621127068556137\n",
      "          Validation Loss (standardized): 1.8662738082997594\n",
      "Epoch: 16, Loss (standarized): 0.21685034405871084\n",
      "          Validation Loss (standardized): 1.9021170947860009\n",
      "Epoch: 17, Loss (standarized): 0.21725780671340003\n",
      "          Validation Loss (standardized): 1.9242442125149548\n",
      "Epoch: 18, Loss (standarized): 0.21717066237866864\n",
      "          Validation Loss (standardized): 1.9334289578545625\n",
      "Epoch: 19, Loss (standarized): 0.21648844318207786\n",
      "          Validation Loss (standardized): 1.9310086458080855\n",
      "Epoch: 20, Loss (standarized): 0.21525790021646757\n",
      "          Validation Loss (standardized): 1.9182489590204497\n",
      "Final epoch: 20, Final loss (standarized): 0.21525790021646757\n",
      "Epoch: 1, Loss (standarized): 0.3262070515406193\n",
      "          Validation Loss (standardized): 0.981878173951275\n",
      "Epoch: 2, Loss (standarized): 0.25372879501459844\n",
      "          Validation Loss (standardized): 1.1498914779536855\n",
      "Epoch: 3, Loss (standarized): 0.22115404756798746\n",
      "          Validation Loss (standardized): 1.3122503371057173\n",
      "Epoch: 4, Loss (standarized): 0.2087169210284067\n",
      "          Validation Loss (standardized): 1.449090314853815\n",
      "Epoch: 5, Loss (standarized): 0.20516901375688215\n",
      "          Validation Loss (standardized): 1.5553909061359656\n",
      "Epoch: 6, Loss (standarized): 0.20508077477259673\n",
      "          Validation Loss (standardized): 1.6306469650395568\n",
      "Epoch: 7, Loss (standarized): 0.20583862379632262\n",
      "          Validation Loss (standardized): 1.6766752491932244\n",
      "Epoch: 8, Loss (standarized): 0.20621884891385417\n",
      "          Validation Loss (standardized): 1.6970413335662469\n",
      "Epoch: 9, Loss (standarized): 0.20573695448375606\n",
      "          Validation Loss (standardized): 1.695858172026695\n",
      "Epoch: 10, Loss (standarized): 0.2043099367300763\n",
      "          Validation Loss (standardized): 1.6770772237493856\n",
      "Epoch: 11, Loss (standarized): 0.20209221136554864\n",
      "          Validation Loss (standardized): 1.6445579559412788\n",
      "Epoch: 12, Loss (standarized): 0.1993185114589055\n",
      "          Validation Loss (standardized): 1.6018045735954523\n",
      "Epoch: 13, Loss (standarized): 0.1962527576900929\n",
      "          Validation Loss (standardized): 1.5522683737400274\n",
      "Epoch: 14, Loss (standarized): 0.19318121853867073\n",
      "          Validation Loss (standardized): 1.498975803955031\n",
      "Epoch: 15, Loss (standarized): 0.19031864992876968\n",
      "          Validation Loss (standardized): 1.4445468927506468\n",
      "Epoch: 16, Loss (standarized): 0.18785643824879567\n",
      "          Validation Loss (standardized): 1.3916652860554586\n",
      "Epoch: 17, Loss (standarized): 0.18596366435067216\n",
      "          Validation Loss (standardized): 1.3424047917966766\n",
      "Epoch: 18, Loss (standarized): 0.18466183863414834\n",
      "          Validation Loss (standardized): 1.298582618247187\n",
      "Epoch: 19, Loss (standarized): 0.18385336058736032\n",
      "          Validation Loss (standardized): 1.2617436940290156\n",
      "Epoch: 20, Loss (standarized): 0.18337268923061076\n",
      "          Validation Loss (standardized): 1.2329874832162935\n",
      "Final epoch: 20, Final loss (standarized): 0.18337268923061076\n",
      "Epoch: 1, Loss (standarized): 0.496976708617761\n",
      "          Validation Loss (standardized): 0.8477765761371541\n",
      "Epoch: 2, Loss (standarized): 0.35366600926901837\n",
      "          Validation Loss (standardized): 0.9690776734605098\n",
      "Epoch: 3, Loss (standarized): 0.27173788330395326\n",
      "          Validation Loss (standardized): 1.1140961660949913\n",
      "Epoch: 4, Loss (standarized): 0.22938544531485844\n",
      "          Validation Loss (standardized): 1.2700168844562214\n",
      "Epoch: 5, Loss (standarized): 0.20992279080799675\n",
      "          Validation Loss (standardized): 1.4261802418218428\n",
      "Epoch: 6, Loss (standarized): 0.20328818130747928\n",
      "          Validation Loss (standardized): 1.5630802811839164\n",
      "Epoch: 7, Loss (standarized): 0.20267248211425654\n",
      "          Validation Loss (standardized): 1.6750340461644897\n",
      "Epoch: 8, Loss (standarized): 0.20417781031120424\n",
      "          Validation Loss (standardized): 1.7593756552099722\n",
      "Epoch: 9, Loss (standarized): 0.20594763665607327\n",
      "          Validation Loss (standardized): 1.816020539476936\n",
      "Epoch: 10, Loss (standarized): 0.20703059842848945\n",
      "          Validation Loss (standardized): 1.8471182007409237\n",
      "Epoch: 11, Loss (standarized): 0.20699759349623276\n",
      "          Validation Loss (standardized): 1.8565658084953531\n",
      "Epoch: 12, Loss (standarized): 0.20596397404897604\n",
      "          Validation Loss (standardized): 1.8482577277678116\n",
      "Epoch: 13, Loss (standarized): 0.20409743579579542\n",
      "          Validation Loss (standardized): 1.8242473479362973\n",
      "Epoch: 14, Loss (standarized): 0.20158126021472128\n",
      "          Validation Loss (standardized): 1.787990104015426\n",
      "Epoch: 15, Loss (standarized): 0.199056969655311\n",
      "          Validation Loss (standardized): 1.744612754672363\n",
      "Epoch: 16, Loss (standarized): 0.1964571315435386\n",
      "          Validation Loss (standardized): 1.6958304011341563\n",
      "Epoch: 17, Loss (standarized): 0.19390358229750657\n",
      "          Validation Loss (standardized): 1.6434257563231371\n",
      "Epoch: 18, Loss (standarized): 0.19160166907702234\n",
      "          Validation Loss (standardized): 1.5889003000751187\n",
      "Epoch: 19, Loss (standarized): 0.18959671896670952\n",
      "          Validation Loss (standardized): 1.5337999896838677\n",
      "Epoch: 20, Loss (standarized): 0.18799853467575348\n",
      "          Validation Loss (standardized): 1.4804202627719991\n",
      "Final epoch: 20, Final loss (standarized): 0.18799853467575348\n",
      "Epoch: 1, Loss (standarized): 0.9634864476706249\n",
      "          Validation Loss (standardized): 0.9182410404583295\n",
      "Epoch: 2, Loss (standarized): 0.67746509745015\n",
      "          Validation Loss (standardized): 0.9323393363904464\n",
      "Epoch: 3, Loss (standarized): 0.4736612943240982\n",
      "          Validation Loss (standardized): 1.0044256684926338\n",
      "Epoch: 4, Loss (standarized): 0.34316834611112584\n",
      "          Validation Loss (standardized): 1.12038263451168\n",
      "Epoch: 5, Loss (standarized): 0.2732362167562139\n",
      "          Validation Loss (standardized): 1.2535151445062434\n",
      "Epoch: 6, Loss (standarized): 0.24247119434102546\n",
      "          Validation Loss (standardized): 1.3831400551124486\n",
      "Epoch: 7, Loss (standarized): 0.22991136808667817\n",
      "          Validation Loss (standardized): 1.4989637017951583\n",
      "Epoch: 8, Loss (standarized): 0.22466282978194746\n",
      "          Validation Loss (standardized): 1.596299754049781\n",
      "Epoch: 9, Loss (standarized): 0.22246538532538618\n",
      "          Validation Loss (standardized): 1.674052287969982\n",
      "Epoch: 10, Loss (standarized): 0.22132650874854612\n",
      "          Validation Loss (standardized): 1.7325281679906601\n",
      "Epoch: 11, Loss (standarized): 0.22025143212368362\n",
      "          Validation Loss (standardized): 1.7724567511360625\n",
      "Epoch: 12, Loss (standarized): 0.21890029191331586\n",
      "          Validation Loss (standardized): 1.795408777040988\n",
      "Epoch: 13, Loss (standarized): 0.21713170862248635\n",
      "          Validation Loss (standardized): 1.8032668914081063\n",
      "Epoch: 14, Loss (standarized): 0.21491585056501125\n",
      "          Validation Loss (standardized): 1.798085427975708\n",
      "Epoch: 15, Loss (standarized): 0.21234100888287913\n",
      "          Validation Loss (standardized): 1.7822125273465343\n",
      "Epoch: 16, Loss (standarized): 0.20951933438044076\n",
      "          Validation Loss (standardized): 1.7575794562716596\n",
      "Epoch: 17, Loss (standarized): 0.20654077575333613\n",
      "          Validation Loss (standardized): 1.7267392113186508\n",
      "Epoch: 18, Loss (standarized): 0.2036709372870016\n",
      "          Validation Loss (standardized): 1.6921392826406798\n",
      "Epoch: 19, Loss (standarized): 0.20089074653433467\n",
      "          Validation Loss (standardized): 1.6544345689400728\n",
      "Epoch: 20, Loss (standarized): 0.19818042428823668\n",
      "          Validation Loss (standardized): 1.6155132089819921\n",
      "Final epoch: 20, Final loss (standarized): 0.19818042428823668\n",
      "Epoch: 1, Loss (standarized): 0.5779006219795649\n",
      "          Validation Loss (standardized): 0.7804247556304099\n",
      "Epoch: 2, Loss (standarized): 0.3717950514456773\n",
      "          Validation Loss (standardized): 0.9108292812493552\n",
      "Epoch: 3, Loss (standarized): 0.28107009321327736\n",
      "          Validation Loss (standardized): 1.0750404163070777\n",
      "Epoch: 4, Loss (standarized): 0.2431155719192296\n",
      "          Validation Loss (standardized): 1.2454129787701074\n",
      "Epoch: 5, Loss (standarized): 0.22819178747071323\n",
      "          Validation Loss (standardized): 1.4099702735963904\n",
      "Epoch: 6, Loss (standarized): 0.22413052387787857\n",
      "          Validation Loss (standardized): 1.5627985901780608\n",
      "Epoch: 7, Loss (standarized): 0.22550018079630277\n",
      "          Validation Loss (standardized): 1.6976524013286678\n",
      "Epoch: 8, Loss (standarized): 0.22912862668164882\n",
      "          Validation Loss (standardized): 1.8107104895251205\n",
      "Epoch: 9, Loss (standarized): 0.23317351593212032\n",
      "          Validation Loss (standardized): 1.9005667549739933\n",
      "Epoch: 10, Loss (standarized): 0.23664883374108583\n",
      "          Validation Loss (standardized): 1.9669153114823348\n",
      "Epoch: 11, Loss (standarized): 0.23902447125207735\n",
      "          Validation Loss (standardized): 2.010408139081336\n",
      "Epoch: 12, Loss (standarized): 0.2400085167175035\n",
      "          Validation Loss (standardized): 2.0324606799242946\n",
      "Epoch: 13, Loss (standarized): 0.23954918082666835\n",
      "          Validation Loss (standardized): 2.0350222484258236\n",
      "Epoch: 14, Loss (standarized): 0.23769927475479688\n",
      "          Validation Loss (standardized): 2.020293778078087\n",
      "Epoch: 15, Loss (standarized): 0.2346296612713843\n",
      "          Validation Loss (standardized): 1.99070185848219\n",
      "Epoch: 16, Loss (standarized): 0.23053076599526137\n",
      "          Validation Loss (standardized): 1.9487570501767093\n",
      "Epoch: 17, Loss (standarized): 0.2256571911435565\n",
      "          Validation Loss (standardized): 1.8969822163720942\n",
      "Epoch: 18, Loss (standarized): 0.22026766786266497\n",
      "          Validation Loss (standardized): 1.8379559554578622\n",
      "Epoch: 19, Loss (standarized): 0.2146498692290071\n",
      "          Validation Loss (standardized): 1.7740608348048812\n",
      "Epoch: 20, Loss (standarized): 0.20907140132169963\n",
      "          Validation Loss (standardized): 1.7075159552115966\n",
      "Final epoch: 20, Final loss (standarized): 0.20907140132169963\n",
      "Epoch: 1, Loss (standarized): 0.3700469820612656\n",
      "          Validation Loss (standardized): 1.1035645330807067\n",
      "Epoch: 2, Loss (standarized): 0.28302639887498215\n",
      "          Validation Loss (standardized): 1.266281409332992\n",
      "Epoch: 3, Loss (standarized): 0.2398874901271343\n",
      "          Validation Loss (standardized): 1.4020616331332747\n",
      "Epoch: 4, Loss (standarized): 0.21969473613929663\n",
      "          Validation Loss (standardized): 1.50503388537161\n",
      "Epoch: 5, Loss (standarized): 0.21080935557727284\n",
      "          Validation Loss (standardized): 1.5771219868713078\n",
      "Epoch: 6, Loss (standarized): 0.20700690929216914\n",
      "          Validation Loss (standardized): 1.622091033211521\n",
      "Epoch: 7, Loss (standarized): 0.20515948462430955\n",
      "          Validation Loss (standardized): 1.6438233311761865\n",
      "Epoch: 8, Loss (standarized): 0.20374899208842237\n",
      "          Validation Loss (standardized): 1.6456599486451284\n",
      "Epoch: 9, Loss (standarized): 0.20232692114632728\n",
      "          Validation Loss (standardized): 1.632501594694121\n",
      "Epoch: 10, Loss (standarized): 0.20092163801445542\n",
      "          Validation Loss (standardized): 1.6063395349404113\n",
      "Epoch: 11, Loss (standarized): 0.19930026897448777\n",
      "          Validation Loss (standardized): 1.570087324737703\n",
      "Epoch: 12, Loss (standarized): 0.1976977431045079\n",
      "          Validation Loss (standardized): 1.5290084776263826\n",
      "Epoch: 13, Loss (standarized): 0.19633909330551108\n",
      "          Validation Loss (standardized): 1.4876865376160244\n",
      "Epoch: 14, Loss (standarized): 0.19513018952663033\n",
      "          Validation Loss (standardized): 1.449028594285699\n",
      "Epoch: 15, Loss (standarized): 0.19392608075716103\n",
      "          Validation Loss (standardized): 1.41500167889807\n",
      "Epoch: 16, Loss (standarized): 0.1925148460884608\n",
      "          Validation Loss (standardized): 1.386564698015164\n",
      "Epoch: 17, Loss (standarized): 0.19079203348334828\n",
      "          Validation Loss (standardized): 1.363820079276281\n",
      "Epoch: 18, Loss (standarized): 0.1888328757811115\n",
      "          Validation Loss (standardized): 1.3461112974692098\n",
      "Epoch: 19, Loss (standarized): 0.18680089711324296\n",
      "          Validation Loss (standardized): 1.3327931979402\n",
      "Epoch: 20, Loss (standarized): 0.18478628602494127\n",
      "          Validation Loss (standardized): 1.32280903162183\n",
      "Final epoch: 20, Final loss (standarized): 0.18478628602494127\n",
      "Epoch: 1, Loss (standarized): 3.1942110304337463\n",
      "          Validation Loss (standardized): 1.5609630478217342\n",
      "Epoch: 2, Loss (standarized): 2.5980964405504277\n",
      "          Validation Loss (standardized): 1.3113849489785536\n",
      "Epoch: 3, Loss (standarized): 2.120470505459384\n",
      "          Validation Loss (standardized): 1.1286701441907765\n",
      "Epoch: 4, Loss (standarized): 1.7544702299561465\n",
      "          Validation Loss (standardized): 0.9936999057507776\n",
      "Epoch: 5, Loss (standarized): 1.468387403622761\n",
      "          Validation Loss (standardized): 0.890908471796461\n",
      "Epoch: 6, Loss (standarized): 1.236299595923459\n",
      "          Validation Loss (standardized): 0.8134254862197824\n",
      "Epoch: 7, Loss (standarized): 1.0484313832207603\n",
      "          Validation Loss (standardized): 0.757773606236413\n",
      "Epoch: 8, Loss (standarized): 0.8997286896514879\n",
      "          Validation Loss (standardized): 0.721775953273855\n",
      "Epoch: 9, Loss (standarized): 0.78648473583346\n",
      "          Validation Loss (standardized): 0.7005990726025836\n",
      "Epoch: 10, Loss (standarized): 0.7037072127376428\n",
      "          Validation Loss (standardized): 0.6892372308316972\n",
      "Epoch: 11, Loss (standarized): 0.6462937984733546\n",
      "          Validation Loss (standardized): 0.6847629260937572\n",
      "Epoch: 12, Loss (standarized): 0.6087094520287285\n",
      "          Validation Loss (standardized): 0.6833375939505407\n",
      "Epoch: 13, Loss (standarized): 0.5793169524274926\n",
      "          Validation Loss (standardized): 0.6834809893811475\n",
      "Epoch: 14, Loss (standarized): 0.5535200964835217\n",
      "          Validation Loss (standardized): 0.6851560235236975\n",
      "Epoch: 15, Loss (standarized): 0.5298778736080465\n",
      "          Validation Loss (standardized): 0.6880971226631245\n",
      "Epoch: 16, Loss (standarized): 0.5075990570555186\n",
      "          Validation Loss (standardized): 0.6924811041577584\n",
      "Epoch: 17, Loss (standarized): 0.4855966633344335\n",
      "          Validation Loss (standardized): 0.6987517175844726\n",
      "Epoch: 18, Loss (standarized): 0.46314579383465926\n",
      "          Validation Loss (standardized): 0.7063286978577992\n",
      "Epoch: 19, Loss (standarized): 0.4394455587917286\n",
      "          Validation Loss (standardized): 0.7159108222840687\n",
      "Epoch: 20, Loss (standarized): 0.4148135448994032\n",
      "          Validation Loss (standardized): 0.7284017736254101\n",
      "Final epoch: 20, Final loss (standarized): 0.4148135448994032\n",
      "Epoch: 1, Loss (standarized): 0.9916629721908425\n",
      "          Validation Loss (standardized): 0.8162711248555398\n",
      "Epoch: 2, Loss (standarized): 0.7221589485124085\n",
      "          Validation Loss (standardized): 0.8203120333778589\n",
      "Epoch: 3, Loss (standarized): 0.5199541803944484\n",
      "          Validation Loss (standardized): 0.8751625550513162\n",
      "Epoch: 4, Loss (standarized): 0.3807114108259083\n",
      "          Validation Loss (standardized): 0.9677311127645798\n",
      "Epoch: 5, Loss (standarized): 0.292316580429572\n",
      "          Validation Loss (standardized): 1.0936650373724115\n",
      "Epoch: 6, Loss (standarized): 0.2407980112889395\n",
      "          Validation Loss (standardized): 1.2429727170925082\n",
      "Epoch: 7, Loss (standarized): 0.21676827808579585\n",
      "          Validation Loss (standardized): 1.403116569189802\n",
      "Epoch: 8, Loss (standarized): 0.20897081889837701\n",
      "          Validation Loss (standardized): 1.5602812907291255\n",
      "Epoch: 9, Loss (standarized): 0.20970748148423002\n",
      "          Validation Loss (standardized): 1.7054694607526277\n",
      "Epoch: 10, Loss (standarized): 0.2143188005485016\n",
      "          Validation Loss (standardized): 1.8332853839205354\n",
      "Epoch: 11, Loss (standarized): 0.2203282748922206\n",
      "          Validation Loss (standardized): 1.9400197248078592\n",
      "Epoch: 12, Loss (standarized): 0.2261569587520764\n",
      "          Validation Loss (standardized): 2.022928723306775\n",
      "Epoch: 13, Loss (standarized): 0.2309356076033752\n",
      "          Validation Loss (standardized): 2.0806901736859165\n",
      "Epoch: 14, Loss (standarized): 0.23415753764617073\n",
      "          Validation Loss (standardized): 2.114577847817676\n",
      "Epoch: 15, Loss (standarized): 0.23576978714179558\n",
      "          Validation Loss (standardized): 2.1270314224042584\n",
      "Epoch: 16, Loss (standarized): 0.23585707847540582\n",
      "          Validation Loss (standardized): 2.1210724586320446\n",
      "Epoch: 17, Loss (standarized): 0.23455024936116534\n",
      "          Validation Loss (standardized): 2.099949778690769\n",
      "Epoch: 18, Loss (standarized): 0.23211688390393884\n",
      "          Validation Loss (standardized): 2.066476181323219\n",
      "Epoch: 19, Loss (standarized): 0.22877532363971606\n",
      "          Validation Loss (standardized): 2.0229840992402606\n",
      "Epoch: 20, Loss (standarized): 0.2247284124124399\n",
      "          Validation Loss (standardized): 1.9713228809240075\n",
      "Final epoch: 20, Final loss (standarized): 0.2247284124124399\n",
      "Epoch: 1, Loss (standarized): 0.41887390207801845\n",
      "          Validation Loss (standardized): 0.8194121863376523\n",
      "Epoch: 2, Loss (standarized): 0.3488339989415935\n",
      "          Validation Loss (standardized): 0.8881408042236154\n",
      "Epoch: 3, Loss (standarized): 0.29529675140255807\n",
      "          Validation Loss (standardized): 0.9692114543450048\n",
      "Epoch: 4, Loss (standarized): 0.25640512417211614\n",
      "          Validation Loss (standardized): 1.0572820149042947\n",
      "Epoch: 5, Loss (standarized): 0.22929465958380033\n",
      "          Validation Loss (standardized): 1.1479824914813543\n",
      "Epoch: 6, Loss (standarized): 0.2113378209834555\n",
      "          Validation Loss (standardized): 1.2375987418360697\n",
      "Epoch: 7, Loss (standarized): 0.20039080478181664\n",
      "          Validation Loss (standardized): 1.3220349354569214\n",
      "Epoch: 8, Loss (standarized): 0.19487068178156192\n",
      "          Validation Loss (standardized): 1.398632391186353\n",
      "Epoch: 9, Loss (standarized): 0.19285868126863562\n",
      "          Validation Loss (standardized): 1.4635571072421294\n",
      "Epoch: 10, Loss (standarized): 0.19276405447461434\n",
      "          Validation Loss (standardized): 1.512773442986299\n",
      "Epoch: 11, Loss (standarized): 0.1932942573681218\n",
      "          Validation Loss (standardized): 1.5449135898104458\n",
      "Epoch: 12, Loss (standarized): 0.1937364590106571\n",
      "          Validation Loss (standardized): 1.5612847767023887\n",
      "Epoch: 13, Loss (standarized): 0.19378135844967184\n",
      "          Validation Loss (standardized): 1.5640586874442548\n",
      "Epoch: 14, Loss (standarized): 0.19335011114396583\n",
      "          Validation Loss (standardized): 1.5552071225061317\n",
      "Epoch: 15, Loss (standarized): 0.19246390479747952\n",
      "          Validation Loss (standardized): 1.536793515771469\n",
      "Epoch: 16, Loss (standarized): 0.1912329586978907\n",
      "          Validation Loss (standardized): 1.5108445009771734\n",
      "Epoch: 17, Loss (standarized): 0.18982435203794729\n",
      "          Validation Loss (standardized): 1.4795189622008746\n",
      "Epoch: 18, Loss (standarized): 0.1883758615528839\n",
      "          Validation Loss (standardized): 1.4449488975715457\n",
      "Epoch: 19, Loss (standarized): 0.1869956260757939\n",
      "          Validation Loss (standardized): 1.408427745548762\n",
      "Epoch: 20, Loss (standarized): 0.1857936794001481\n",
      "          Validation Loss (standardized): 1.3711856063384409\n",
      "Final epoch: 20, Final loss (standarized): 0.1857936794001481\n",
      "Epoch: 1, Loss (standarized): 1.0534128945862327\n",
      "          Validation Loss (standardized): 1.0911538106306307\n",
      "Epoch: 2, Loss (standarized): 0.7927348578756622\n",
      "          Validation Loss (standardized): 1.1157053170176825\n",
      "Epoch: 3, Loss (standarized): 0.5873163015714505\n",
      "          Validation Loss (standardized): 1.160487654603527\n",
      "Epoch: 4, Loss (standarized): 0.4327980743781128\n",
      "          Validation Loss (standardized): 1.2259148098167554\n",
      "Epoch: 5, Loss (standarized): 0.3286051710747814\n",
      "          Validation Loss (standardized): 1.3061076919709746\n",
      "Epoch: 6, Loss (standarized): 0.2654544819747255\n",
      "          Validation Loss (standardized): 1.3913099715533825\n",
      "Epoch: 7, Loss (standarized): 0.23081896411435796\n",
      "          Validation Loss (standardized): 1.471990166998887\n",
      "Epoch: 8, Loss (standarized): 0.21330513722999406\n",
      "          Validation Loss (standardized): 1.540353168774048\n",
      "Epoch: 9, Loss (standarized): 0.20510615905048182\n",
      "          Validation Loss (standardized): 1.593500906529235\n",
      "Epoch: 10, Loss (standarized): 0.2016428384116092\n",
      "          Validation Loss (standardized): 1.6309395280787964\n",
      "Epoch: 11, Loss (standarized): 0.20039779433018437\n",
      "          Validation Loss (standardized): 1.6533518398074216\n",
      "Epoch: 12, Loss (standarized): 0.20009416341468983\n",
      "          Validation Loss (standardized): 1.6628089343639687\n",
      "Epoch: 13, Loss (standarized): 0.20010182977473964\n",
      "          Validation Loss (standardized): 1.661913658341217\n",
      "Epoch: 14, Loss (standarized): 0.20015938420107363\n",
      "          Validation Loss (standardized): 1.6533147637959829\n",
      "Epoch: 15, Loss (standarized): 0.20012255089241204\n",
      "          Validation Loss (standardized): 1.6389088795344207\n",
      "Epoch: 16, Loss (standarized): 0.20009824822951297\n",
      "          Validation Loss (standardized): 1.6208387160480482\n",
      "Epoch: 17, Loss (standarized): 0.20013556576811112\n",
      "          Validation Loss (standardized): 1.599705853928834\n",
      "Epoch: 18, Loss (standarized): 0.20008261738440872\n",
      "          Validation Loss (standardized): 1.5768708914677148\n",
      "Epoch: 19, Loss (standarized): 0.19991749841336431\n",
      "          Validation Loss (standardized): 1.553440183608273\n",
      "Epoch: 20, Loss (standarized): 0.1996182362341457\n",
      "          Validation Loss (standardized): 1.5307795962212458\n",
      "Final epoch: 20, Final loss (standarized): 0.1996182362341457\n",
      "Epoch: 1, Loss (standarized): 0.3450732268553926\n",
      "          Validation Loss (standardized): 1.084809538417843\n",
      "Epoch: 2, Loss (standarized): 0.2597836237193736\n",
      "          Validation Loss (standardized): 1.2299068893051457\n",
      "Epoch: 3, Loss (standarized): 0.21995132376438195\n",
      "          Validation Loss (standardized): 1.3555021014157758\n",
      "Epoch: 4, Loss (standarized): 0.20425273795289822\n",
      "          Validation Loss (standardized): 1.4519784787759458\n",
      "Epoch: 5, Loss (standarized): 0.1993273436736283\n",
      "          Validation Loss (standardized): 1.5187922195108865\n",
      "Epoch: 6, Loss (standarized): 0.19832811124787225\n",
      "          Validation Loss (standardized): 1.5578820801024398\n",
      "Epoch: 7, Loss (standarized): 0.1982299441911031\n",
      "          Validation Loss (standardized): 1.5735191673148576\n",
      "Epoch: 8, Loss (standarized): 0.19794993155929086\n",
      "          Validation Loss (standardized): 1.5703222114193875\n",
      "Epoch: 9, Loss (standarized): 0.19723073049044718\n",
      "          Validation Loss (standardized): 1.552168980482228\n",
      "Epoch: 10, Loss (standarized): 0.19595013084896618\n",
      "          Validation Loss (standardized): 1.5226676377259667\n",
      "Epoch: 11, Loss (standarized): 0.19424301047270348\n",
      "          Validation Loss (standardized): 1.48454844664203\n",
      "Epoch: 12, Loss (standarized): 0.19229450803974824\n",
      "          Validation Loss (standardized): 1.4405850256531432\n",
      "Epoch: 13, Loss (standarized): 0.19033378480222057\n",
      "          Validation Loss (standardized): 1.394335761100062\n",
      "Epoch: 14, Loss (standarized): 0.18858782176088545\n",
      "          Validation Loss (standardized): 1.3483255969846821\n",
      "Epoch: 15, Loss (standarized): 0.18722606960519725\n",
      "          Validation Loss (standardized): 1.3050402125504958\n",
      "Epoch: 16, Loss (standarized): 0.18629158365363238\n",
      "          Validation Loss (standardized): 1.26588208586063\n",
      "Epoch: 17, Loss (standarized): 0.1857382423011416\n",
      "          Validation Loss (standardized): 1.2318528506830801\n",
      "Epoch: 18, Loss (standarized): 0.18549597105290452\n",
      "          Validation Loss (standardized): 1.2032646625747838\n",
      "Epoch: 19, Loss (standarized): 0.18549367805942757\n",
      "          Validation Loss (standardized): 1.1816269910320347\n",
      "Epoch: 20, Loss (standarized): 0.18562822757661301\n",
      "          Validation Loss (standardized): 1.166558993527983\n",
      "Final epoch: 20, Final loss (standarized): 0.18562822757661301\n",
      "Epoch: 1, Loss (standarized): 1.8940890600326727\n",
      "          Validation Loss (standardized): 1.1077420658263457\n",
      "Epoch: 2, Loss (standarized): 1.3599423079169688\n",
      "          Validation Loss (standardized): 0.9738563573293944\n",
      "Epoch: 3, Loss (standarized): 0.935038626240413\n",
      "          Validation Loss (standardized): 0.9265904255764963\n",
      "Epoch: 4, Loss (standarized): 0.6265082015990016\n",
      "          Validation Loss (standardized): 0.9621801373598443\n",
      "Epoch: 5, Loss (standarized): 0.42824261019173165\n",
      "          Validation Loss (standardized): 1.059175562786922\n",
      "Epoch: 6, Loss (standarized): 0.3159838008668771\n",
      "          Validation Loss (standardized): 1.1913119039627404\n",
      "Epoch: 7, Loss (standarized): 0.2551524291953322\n",
      "          Validation Loss (standardized): 1.3364491188626575\n",
      "Epoch: 8, Loss (standarized): 0.2243825381206356\n",
      "          Validation Loss (standardized): 1.4818023432271168\n",
      "Epoch: 9, Loss (standarized): 0.21124140658464127\n",
      "          Validation Loss (standardized): 1.6201414851742952\n",
      "Epoch: 10, Loss (standarized): 0.20774931477988032\n",
      "          Validation Loss (standardized): 1.7461095596526133\n",
      "Epoch: 11, Loss (standarized): 0.20904463040520566\n",
      "          Validation Loss (standardized): 1.8571219687098346\n",
      "Epoch: 12, Loss (standarized): 0.2125169846112123\n",
      "          Validation Loss (standardized): 1.9516733752574316\n",
      "Epoch: 13, Loss (standarized): 0.2166856955246042\n",
      "          Validation Loss (standardized): 2.0294362915588353\n",
      "Epoch: 14, Loss (standarized): 0.22073609047270895\n",
      "          Validation Loss (standardized): 2.0907394112541997\n",
      "Epoch: 15, Loss (standarized): 0.22427150806998816\n",
      "          Validation Loss (standardized): 2.1361644546022736\n",
      "Epoch: 16, Loss (standarized): 0.2270610993975168\n",
      "          Validation Loss (standardized): 2.166787752776143\n",
      "Epoch: 17, Loss (standarized): 0.22900273752124223\n",
      "          Validation Loss (standardized): 2.184046040613477\n",
      "Epoch: 18, Loss (standarized): 0.23007655431355542\n",
      "          Validation Loss (standardized): 2.1893346486661924\n",
      "Epoch: 19, Loss (standarized): 0.23032522171479133\n",
      "          Validation Loss (standardized): 2.1830392855540834\n",
      "Epoch: 20, Loss (standarized): 0.2297643184475106\n",
      "          Validation Loss (standardized): 2.16651877866125\n",
      "Final epoch: 20, Final loss (standarized): 0.2297643184475106\n",
      "Epoch: 1, Loss (standarized): 0.865981534521248\n",
      "          Validation Loss (standardized): 0.7457765495074176\n",
      "Epoch: 2, Loss (standarized): 0.5890995007678481\n",
      "          Validation Loss (standardized): 0.8353201589121084\n",
      "Epoch: 3, Loss (standarized): 0.43577813696792406\n",
      "          Validation Loss (standardized): 0.9784538286638949\n",
      "Epoch: 4, Loss (standarized): 0.3529848272933479\n",
      "          Validation Loss (standardized): 1.1442158308289634\n",
      "Epoch: 5, Loss (standarized): 0.30518593713143544\n",
      "          Validation Loss (standardized): 1.3122970698084095\n",
      "Epoch: 6, Loss (standarized): 0.2762844247058925\n",
      "          Validation Loss (standardized): 1.471559448181502\n",
      "Epoch: 7, Loss (standarized): 0.25847566524118043\n",
      "          Validation Loss (standardized): 1.6158737130098797\n",
      "Epoch: 8, Loss (standarized): 0.24810821395117327\n",
      "          Validation Loss (standardized): 1.7421217124360664\n",
      "Epoch: 9, Loss (standarized): 0.24252781697478049\n",
      "          Validation Loss (standardized): 1.8479635104217014\n",
      "Epoch: 10, Loss (standarized): 0.2396066162850555\n",
      "          Validation Loss (standardized): 1.9324963374547668\n",
      "Epoch: 11, Loss (standarized): 0.2381548181046089\n",
      "          Validation Loss (standardized): 1.9963192584860427\n",
      "Epoch: 12, Loss (standarized): 0.23724783168138247\n",
      "          Validation Loss (standardized): 2.04006121214009\n",
      "Epoch: 13, Loss (standarized): 0.2362380232899581\n",
      "          Validation Loss (standardized): 2.0646815693815355\n",
      "Epoch: 14, Loss (standarized): 0.23471473143789842\n",
      "          Validation Loss (standardized): 2.072407080459732\n",
      "Epoch: 15, Loss (standarized): 0.23258412782188684\n",
      "          Validation Loss (standardized): 2.066110672512809\n",
      "Epoch: 16, Loss (standarized): 0.229899725505732\n",
      "          Validation Loss (standardized): 2.0472467223467925\n",
      "Epoch: 17, Loss (standarized): 0.22664389194111842\n",
      "          Validation Loss (standardized): 2.0179111978763498\n",
      "Epoch: 18, Loss (standarized): 0.22291603663956489\n",
      "          Validation Loss (standardized): 1.979193628353058\n",
      "Epoch: 19, Loss (standarized): 0.21869201736336558\n",
      "          Validation Loss (standardized): 1.9320365278112999\n",
      "Epoch: 20, Loss (standarized): 0.21399131830418888\n",
      "          Validation Loss (standardized): 1.8769425732031346\n",
      "Final epoch: 20, Final loss (standarized): 0.21399131830418888\n",
      "Epoch: 1, Loss (standarized): 0.34696060542852813\n",
      "          Validation Loss (standardized): 0.8987246875873504\n",
      "Epoch: 2, Loss (standarized): 0.2816090897574536\n",
      "          Validation Loss (standardized): 1.0305745722704744\n",
      "Epoch: 3, Loss (standarized): 0.24610416852352748\n",
      "          Validation Loss (standardized): 1.160334661050994\n",
      "Epoch: 4, Loss (standarized): 0.2266054027151406\n",
      "          Validation Loss (standardized): 1.2774274473708047\n",
      "Epoch: 5, Loss (standarized): 0.2152531641839687\n",
      "          Validation Loss (standardized): 1.3771005885354801\n",
      "Epoch: 6, Loss (standarized): 0.2084797831471606\n",
      "          Validation Loss (standardized): 1.456069655064403\n",
      "Epoch: 7, Loss (standarized): 0.20423500098605885\n",
      "          Validation Loss (standardized): 1.5122257134998767\n",
      "Epoch: 8, Loss (standarized): 0.20106475887286532\n",
      "          Validation Loss (standardized): 1.5456156919739499\n",
      "Epoch: 9, Loss (standarized): 0.19826884623312252\n",
      "          Validation Loss (standardized): 1.5576997811813045\n",
      "Epoch: 10, Loss (standarized): 0.19540343960032625\n",
      "          Validation Loss (standardized): 1.551334388144719\n",
      "Epoch: 11, Loss (standarized): 0.1925261628610572\n",
      "          Validation Loss (standardized): 1.5300375087169757\n",
      "Epoch: 12, Loss (standarized): 0.18991305137520817\n",
      "          Validation Loss (standardized): 1.4981603657541853\n",
      "Epoch: 13, Loss (standarized): 0.18780394784218674\n",
      "          Validation Loss (standardized): 1.4601022274614446\n",
      "Epoch: 14, Loss (standarized): 0.18618495962147097\n",
      "          Validation Loss (standardized): 1.4206026631675912\n",
      "Epoch: 15, Loss (standarized): 0.18503412589245039\n",
      "          Validation Loss (standardized): 1.383130032389697\n",
      "Epoch: 16, Loss (standarized): 0.18419274272496422\n",
      "          Validation Loss (standardized): 1.3499416844029322\n",
      "Epoch: 17, Loss (standarized): 0.18333678070351278\n",
      "          Validation Loss (standardized): 1.3218275809477895\n",
      "Epoch: 18, Loss (standarized): 0.18220275929674412\n",
      "          Validation Loss (standardized): 1.2989338632955219\n",
      "Epoch: 19, Loss (standarized): 0.1809120840951514\n",
      "          Validation Loss (standardized): 1.2811416886189158\n",
      "Epoch: 20, Loss (standarized): 0.17960124704764688\n",
      "          Validation Loss (standardized): 1.267877189819119\n",
      "Final epoch: 20, Final loss (standarized): 0.17960124704764688\n",
      "Epoch: 1, Loss (standarized): 3.2357631044650383\n",
      "          Validation Loss (standardized): 1.5260538256764289\n",
      "Epoch: 2, Loss (standarized): 2.5405793838195208\n",
      "          Validation Loss (standardized): 1.2152507561469326\n",
      "Epoch: 3, Loss (standarized): 1.9329289456208905\n",
      "          Validation Loss (standardized): 0.9686555416455661\n",
      "Epoch: 4, Loss (standarized): 1.4144973928927524\n",
      "          Validation Loss (standardized): 0.8014020667370646\n",
      "Epoch: 5, Loss (standarized): 1.0113367940098894\n",
      "          Validation Loss (standardized): 0.7209672236063515\n",
      "Epoch: 6, Loss (standarized): 0.7403576689962371\n",
      "          Validation Loss (standardized): 0.6981041255105399\n",
      "Epoch: 7, Loss (standarized): 0.5609942352993871\n",
      "          Validation Loss (standardized): 0.7147581444192642\n",
      "Epoch: 8, Loss (standarized): 0.44454669852648443\n",
      "          Validation Loss (standardized): 0.7561458098970774\n",
      "Epoch: 9, Loss (standarized): 0.3693720092919559\n",
      "          Validation Loss (standardized): 0.8123701798204626\n",
      "Epoch: 10, Loss (standarized): 0.3194749264365068\n",
      "          Validation Loss (standardized): 0.8767997207534486\n",
      "Epoch: 11, Loss (standarized): 0.2855402785225794\n",
      "          Validation Loss (standardized): 0.9438955132835973\n",
      "Epoch: 12, Loss (standarized): 0.26228396317630054\n",
      "          Validation Loss (standardized): 1.0114959668618966\n",
      "Epoch: 13, Loss (standarized): 0.24636683093770423\n",
      "          Validation Loss (standardized): 1.0776934704172911\n",
      "Epoch: 14, Loss (standarized): 0.2354415727227914\n",
      "          Validation Loss (standardized): 1.1418554070696703\n",
      "Epoch: 15, Loss (standarized): 0.22777137852204365\n",
      "          Validation Loss (standardized): 1.2030160041208637\n",
      "Epoch: 16, Loss (standarized): 0.2223762147295465\n",
      "          Validation Loss (standardized): 1.2608130616536672\n",
      "Epoch: 17, Loss (standarized): 0.21856145148555048\n",
      "          Validation Loss (standardized): 1.3145190278492596\n",
      "Epoch: 18, Loss (standarized): 0.21565928101362555\n",
      "          Validation Loss (standardized): 1.3640225083819564\n",
      "Epoch: 19, Loss (standarized): 0.21332285326602551\n",
      "          Validation Loss (standardized): 1.4111018922592873\n",
      "Epoch: 20, Loss (standarized): 0.21166948070517308\n",
      "          Validation Loss (standardized): 1.453174311877687\n",
      "Final epoch: 20, Final loss (standarized): 0.21166948070517308\n",
      "Epoch: 1, Loss (standarized): 0.3536399521078992\n",
      "          Validation Loss (standardized): 0.9340672127238142\n",
      "Epoch: 2, Loss (standarized): 0.28534454525976255\n",
      "          Validation Loss (standardized): 1.0812619180697316\n",
      "Epoch: 3, Loss (standarized): 0.25151893055505636\n",
      "          Validation Loss (standardized): 1.2279778098448793\n",
      "Epoch: 4, Loss (standarized): 0.23437521890514554\n",
      "          Validation Loss (standardized): 1.3596897389693852\n",
      "Epoch: 5, Loss (standarized): 0.22559871955591637\n",
      "          Validation Loss (standardized): 1.4671805606960704\n",
      "Epoch: 6, Loss (standarized): 0.22034811459740158\n",
      "          Validation Loss (standardized): 1.5482593334760697\n",
      "Epoch: 7, Loss (standarized): 0.21642023694096332\n",
      "          Validation Loss (standardized): 1.6045249789112137\n",
      "Epoch: 8, Loss (standarized): 0.21280578292710403\n",
      "          Validation Loss (standardized): 1.638098924479844\n",
      "Epoch: 9, Loss (standarized): 0.20911890110583842\n",
      "          Validation Loss (standardized): 1.651536900057608\n",
      "Epoch: 10, Loss (standarized): 0.20501252808544357\n",
      "          Validation Loss (standardized): 1.646391319246087\n",
      "Epoch: 11, Loss (standarized): 0.20070352447911252\n",
      "          Validation Loss (standardized): 1.6255893914612989\n",
      "Epoch: 12, Loss (standarized): 0.19636673524003018\n",
      "          Validation Loss (standardized): 1.5938696599764535\n",
      "Epoch: 13, Loss (standarized): 0.192529373432366\n",
      "          Validation Loss (standardized): 1.5557409883591016\n",
      "Epoch: 14, Loss (standarized): 0.18945573268623186\n",
      "          Validation Loss (standardized): 1.5153905409775479\n",
      "Epoch: 15, Loss (standarized): 0.1874096141710543\n",
      "          Validation Loss (standardized): 1.4759970190018612\n",
      "Epoch: 16, Loss (standarized): 0.1865447156562599\n",
      "          Validation Loss (standardized): 1.4394986251823485\n",
      "Epoch: 17, Loss (standarized): 0.18660040910241157\n",
      "          Validation Loss (standardized): 1.4100161595441434\n",
      "Epoch: 18, Loss (standarized): 0.18729394170515332\n",
      "          Validation Loss (standardized): 1.390150171715667\n",
      "Epoch: 19, Loss (standarized): 0.18765879069104865\n",
      "          Validation Loss (standardized): 1.3806057401086569\n",
      "Epoch: 20, Loss (standarized): 0.1869365943075434\n",
      "          Validation Loss (standardized): 1.3798755878323399\n",
      "Final epoch: 20, Final loss (standarized): 0.1869365943075434\n",
      "Epoch: 1, Loss (standarized): 0.38368734049198977\n",
      "          Validation Loss (standardized): 1.0045238170386392\n",
      "Epoch: 2, Loss (standarized): 0.3151021908635744\n",
      "          Validation Loss (standardized): 1.1534066914247318\n",
      "Epoch: 3, Loss (standarized): 0.27022683661593405\n",
      "          Validation Loss (standardized): 1.296999561169052\n",
      "Epoch: 4, Loss (standarized): 0.24136785170899766\n",
      "          Validation Loss (standardized): 1.4252266427006937\n",
      "Epoch: 5, Loss (standarized): 0.22302297982136074\n",
      "          Validation Loss (standardized): 1.5354942765098805\n",
      "Epoch: 6, Loss (standarized): 0.21219262660743182\n",
      "          Validation Loss (standardized): 1.6254650412558243\n",
      "Epoch: 7, Loss (standarized): 0.2065145302037892\n",
      "          Validation Loss (standardized): 1.6936633342562708\n",
      "Epoch: 8, Loss (standarized): 0.20401600472792536\n",
      "          Validation Loss (standardized): 1.7382306976718291\n",
      "Epoch: 9, Loss (standarized): 0.2027352584467324\n",
      "          Validation Loss (standardized): 1.7592495896171885\n",
      "Epoch: 10, Loss (standarized): 0.201573878830699\n",
      "          Validation Loss (standardized): 1.760136864817318\n",
      "Epoch: 11, Loss (standarized): 0.20014807071459878\n",
      "          Validation Loss (standardized): 1.74346262284518\n",
      "Epoch: 12, Loss (standarized): 0.19835078051701244\n",
      "          Validation Loss (standardized): 1.7118547215894424\n",
      "Epoch: 13, Loss (standarized): 0.19614165294945146\n",
      "          Validation Loss (standardized): 1.6695413061371034\n",
      "Epoch: 14, Loss (standarized): 0.1938084920741409\n",
      "          Validation Loss (standardized): 1.620366252971565\n",
      "Epoch: 15, Loss (standarized): 0.19169798334523588\n",
      "          Validation Loss (standardized): 1.5684390268833845\n",
      "Epoch: 16, Loss (standarized): 0.19003069905399295\n",
      "          Validation Loss (standardized): 1.5187953361503548\n",
      "Epoch: 17, Loss (standarized): 0.18886162454439462\n",
      "          Validation Loss (standardized): 1.4730254105264737\n",
      "Epoch: 18, Loss (standarized): 0.18791445573708465\n",
      "          Validation Loss (standardized): 1.433041034704333\n",
      "Epoch: 19, Loss (standarized): 0.18688041782474643\n",
      "          Validation Loss (standardized): 1.399942492054308\n",
      "Epoch: 20, Loss (standarized): 0.18561590272524012\n",
      "          Validation Loss (standardized): 1.3742463628370785\n",
      "Final epoch: 20, Final loss (standarized): 0.18561590272524012\n",
      "Epoch: 1, Loss (standarized): 0.3097612895519148\n",
      "          Validation Loss (standardized): 1.0969112834098818\n",
      "Epoch: 2, Loss (standarized): 0.2623216692159106\n",
      "          Validation Loss (standardized): 1.2303390714789773\n",
      "Epoch: 3, Loss (standarized): 0.2350215979944376\n",
      "          Validation Loss (standardized): 1.3624922277791647\n",
      "Epoch: 4, Loss (standarized): 0.221223201442485\n",
      "          Validation Loss (standardized): 1.4806633834603056\n",
      "Epoch: 5, Loss (standarized): 0.2150760325459518\n",
      "          Validation Loss (standardized): 1.5695322763310537\n",
      "Epoch: 6, Loss (standarized): 0.21215644842903592\n",
      "          Validation Loss (standardized): 1.6246517313892321\n",
      "Epoch: 7, Loss (standarized): 0.2099090603615553\n",
      "          Validation Loss (standardized): 1.6476918385617336\n",
      "Epoch: 8, Loss (standarized): 0.20734820112238378\n",
      "          Validation Loss (standardized): 1.6428987347830866\n",
      "Epoch: 9, Loss (standarized): 0.20417709175221319\n",
      "          Validation Loss (standardized): 1.6156361237407275\n",
      "Epoch: 10, Loss (standarized): 0.2004250097146286\n",
      "          Validation Loss (standardized): 1.5714554024135392\n",
      "Epoch: 11, Loss (standarized): 0.1964214286784939\n",
      "          Validation Loss (standardized): 1.5164265815865436\n",
      "Epoch: 12, Loss (standarized): 0.19253383534192114\n",
      "          Validation Loss (standardized): 1.456450333401639\n",
      "Epoch: 13, Loss (standarized): 0.1891818077602549\n",
      "          Validation Loss (standardized): 1.3971744666826746\n",
      "Epoch: 14, Loss (standarized): 0.18680501923851858\n",
      "          Validation Loss (standardized): 1.3425679989989048\n",
      "Epoch: 15, Loss (standarized): 0.18553333191210006\n",
      "          Validation Loss (standardized): 1.295516315707751\n",
      "Epoch: 16, Loss (standarized): 0.18486740066229926\n",
      "          Validation Loss (standardized): 1.2603989618418634\n",
      "Epoch: 17, Loss (standarized): 0.18425232208451647\n",
      "          Validation Loss (standardized): 1.2393037503251845\n",
      "Epoch: 18, Loss (standarized): 0.18321159626455563\n",
      "          Validation Loss (standardized): 1.2318212483509536\n",
      "Epoch: 19, Loss (standarized): 0.1816097797562812\n",
      "          Validation Loss (standardized): 1.235836252695025\n",
      "Epoch: 20, Loss (standarized): 0.1797526056328949\n",
      "          Validation Loss (standardized): 1.2481130387110155\n",
      "Final epoch: 20, Final loss (standarized): 0.1797526056328949\n",
      "Epoch: 1, Loss (standarized): 0.2417968675684589\n",
      "          Validation Loss (standardized): 1.6520962647877004\n",
      "Epoch: 2, Loss (standarized): 0.22434337987559644\n",
      "          Validation Loss (standardized): 1.7088500877871795\n",
      "Epoch: 3, Loss (standarized): 0.21750238942530295\n",
      "          Validation Loss (standardized): 1.7072169100687113\n",
      "Epoch: 4, Loss (standarized): 0.21248546833927845\n",
      "          Validation Loss (standardized): 1.6602637317725089\n",
      "Epoch: 5, Loss (standarized): 0.20675244569697915\n",
      "          Validation Loss (standardized): 1.582195836243737\n",
      "Epoch: 6, Loss (standarized): 0.20031922848861838\n",
      "          Validation Loss (standardized): 1.4841481094212323\n",
      "Epoch: 7, Loss (standarized): 0.19378546435699198\n",
      "          Validation Loss (standardized): 1.3771124219299162\n",
      "Epoch: 8, Loss (standarized): 0.18784224883262474\n",
      "          Validation Loss (standardized): 1.2726903080874266\n",
      "Epoch: 9, Loss (standarized): 0.18317940971062074\n",
      "          Validation Loss (standardized): 1.1839379739195295\n",
      "Epoch: 10, Loss (standarized): 0.17997151758771315\n",
      "          Validation Loss (standardized): 1.1218983704193572\n",
      "Epoch: 11, Loss (standarized): 0.17706016715719156\n",
      "          Validation Loss (standardized): 1.0905314652228448\n",
      "Epoch: 12, Loss (standarized): 0.1735152473181347\n",
      "          Validation Loss (standardized): 1.0870577733884546\n",
      "Epoch: 13, Loss (standarized): 0.16951859861837726\n",
      "          Validation Loss (standardized): 1.103956746390238\n",
      "Epoch: 14, Loss (standarized): 0.16589497354290156\n",
      "          Validation Loss (standardized): 1.1304523553878465\n",
      "Epoch: 15, Loss (standarized): 0.16283511127699712\n",
      "          Validation Loss (standardized): 1.1557941715578273\n",
      "Epoch: 16, Loss (standarized): 0.16024190767816857\n",
      "          Validation Loss (standardized): 1.1715137256261114\n",
      "Epoch: 17, Loss (standarized): 0.1578779446275968\n",
      "          Validation Loss (standardized): 1.1716428273929316\n",
      "Epoch: 18, Loss (standarized): 0.15532981454393832\n",
      "          Validation Loss (standardized): 1.1542617229335823\n",
      "Epoch: 19, Loss (standarized): 0.15246332848482308\n",
      "          Validation Loss (standardized): 1.122129827944107\n",
      "Epoch: 20, Loss (standarized): 0.1494344710839944\n",
      "          Validation Loss (standardized): 1.0814586428900534\n",
      "Final epoch: 20, Final loss (standarized): 0.1494344710839944\n",
      "Epoch: 1, Loss (standarized): 0.2582103042813574\n",
      "          Validation Loss (standardized): 1.089000351071993\n",
      "Epoch: 2, Loss (standarized): 0.22932876831889967\n",
      "          Validation Loss (standardized): 1.2474611871311145\n",
      "Epoch: 3, Loss (standarized): 0.2166952077525965\n",
      "          Validation Loss (standardized): 1.3713820983865361\n",
      "Epoch: 4, Loss (standarized): 0.21034415051751817\n",
      "          Validation Loss (standardized): 1.455967576051077\n",
      "Epoch: 5, Loss (standarized): 0.20593339913550587\n",
      "          Validation Loss (standardized): 1.5002294280796673\n",
      "Epoch: 6, Loss (standarized): 0.2014915134651206\n",
      "          Validation Loss (standardized): 1.5097300960476934\n",
      "Epoch: 7, Loss (standarized): 0.19657833260627458\n",
      "          Validation Loss (standardized): 1.4921225040117312\n",
      "Epoch: 8, Loss (standarized): 0.19149536560650576\n",
      "          Validation Loss (standardized): 1.4567664277442194\n",
      "Epoch: 9, Loss (standarized): 0.18691067534417033\n",
      "          Validation Loss (standardized): 1.4144438824412218\n",
      "Epoch: 10, Loss (standarized): 0.18374620907877406\n",
      "          Validation Loss (standardized): 1.3771345904486805\n",
      "Epoch: 11, Loss (standarized): 0.18230477216236096\n",
      "          Validation Loss (standardized): 1.3560373911796397\n",
      "Epoch: 12, Loss (standarized): 0.18176187689104698\n",
      "          Validation Loss (standardized): 1.355061098221655\n",
      "Epoch: 13, Loss (standarized): 0.18034279941466383\n",
      "          Validation Loss (standardized): 1.3705544943418346\n",
      "Epoch: 14, Loss (standarized): 0.17796115378631364\n",
      "          Validation Loss (standardized): 1.3959719920408735\n",
      "Epoch: 15, Loss (standarized): 0.17569609638807068\n",
      "          Validation Loss (standardized): 1.4217374126004385\n",
      "Epoch: 16, Loss (standarized): 0.17386494654836135\n",
      "          Validation Loss (standardized): 1.4398854009816273\n",
      "Epoch: 17, Loss (standarized): 0.17239928416787836\n",
      "          Validation Loss (standardized): 1.4447959384292235\n",
      "Epoch: 18, Loss (standarized): 0.17094905461085302\n",
      "          Validation Loss (standardized): 1.4337752585099919\n",
      "Epoch: 19, Loss (standarized): 0.1692203428588572\n",
      "          Validation Loss (standardized): 1.4068090303904441\n",
      "Epoch: 20, Loss (standarized): 0.1671471655766988\n",
      "          Validation Loss (standardized): 1.3669039816585105\n",
      "Final epoch: 20, Final loss (standarized): 0.1671471655766988\n",
      "Epoch: 1, Loss (standarized): 0.5964353022773637\n",
      "Epoch: 2, Loss (standarized): 0.4449466708189708\n",
      "Epoch: 3, Loss (standarized): 0.35996891155310323\n",
      "Epoch: 4, Loss (standarized): 0.3077828658451246\n",
      "Epoch: 5, Loss (standarized): 0.27473066910588584\n",
      "Epoch: 6, Loss (standarized): 0.252767276609277\n",
      "Epoch: 7, Loss (standarized): 0.23851176637642899\n",
      "Epoch: 8, Loss (standarized): 0.230198590777759\n",
      "Epoch: 9, Loss (standarized): 0.22572815906415733\n",
      "Epoch: 10, Loss (standarized): 0.22335874949024676\n",
      "Epoch: 11, Loss (standarized): 0.22196830309510895\n",
      "Epoch: 12, Loss (standarized): 0.2206782101624216\n",
      "Epoch: 13, Loss (standarized): 0.2189594028449256\n",
      "Epoch: 14, Loss (standarized): 0.21649860422793765\n",
      "Epoch: 15, Loss (standarized): 0.21340662555948411\n",
      "Epoch: 16, Loss (standarized): 0.20980138063195722\n",
      "Epoch: 17, Loss (standarized): 0.205776588979459\n",
      "Epoch: 18, Loss (standarized): 0.2014463119605639\n",
      "Epoch: 19, Loss (standarized): 0.19705650729866334\n",
      "Epoch: 20, Loss (standarized): 0.19295181493409666\n",
      "Final epoch: 20, Final loss (standarized): 0.19295181493409666\n",
      "Epoch: 1, Loss (standarized): 0.2836013111310818\n",
      "Epoch: 2, Loss (standarized): 0.25509242471893295\n",
      "Epoch: 3, Loss (standarized): 0.2334778230505194\n",
      "Epoch: 4, Loss (standarized): 0.21816075135961713\n",
      "Epoch: 5, Loss (standarized): 0.20973431915220378\n",
      "Epoch: 6, Loss (standarized): 0.2071397411112171\n",
      "Epoch: 7, Loss (standarized): 0.20451105887872503\n",
      "Epoch: 8, Loss (standarized): 0.1991276399058773\n",
      "Epoch: 9, Loss (standarized): 0.19403389302097068\n",
      "Epoch: 10, Loss (standarized): 0.19120739269175185\n",
      "Epoch: 11, Loss (standarized): 0.18986889367910734\n",
      "Epoch: 12, Loss (standarized): 0.18866883453813063\n",
      "Epoch: 13, Loss (standarized): 0.18680483219754745\n",
      "Epoch: 14, Loss (standarized): 0.18436462058392397\n",
      "Epoch: 15, Loss (standarized): 0.18168003273093503\n",
      "Epoch: 16, Loss (standarized): 0.17931276197826806\n",
      "Epoch: 17, Loss (standarized): 0.17770580105572734\n",
      "Epoch: 18, Loss (standarized): 0.17687384099269285\n",
      "Epoch: 19, Loss (standarized): 0.17639413249254568\n",
      "Epoch: 20, Loss (standarized): 0.17572601171966165\n",
      "Final epoch: 20, Final loss (standarized): 0.17572601171966165\n",
      "Epoch: 1, Loss (standarized): 0.33227644406354956\n",
      "Epoch: 2, Loss (standarized): 0.2712807172052028\n",
      "Epoch: 3, Loss (standarized): 0.2354467066694623\n",
      "Epoch: 4, Loss (standarized): 0.2153692007557048\n",
      "Epoch: 5, Loss (standarized): 0.20377586541572584\n",
      "Epoch: 6, Loss (standarized): 0.19689457305655997\n",
      "Epoch: 7, Loss (standarized): 0.1925487657795434\n",
      "Epoch: 8, Loss (standarized): 0.18915120750679562\n",
      "Epoch: 9, Loss (standarized): 0.1860703574123868\n",
      "Epoch: 10, Loss (standarized): 0.1831901806289156\n",
      "Epoch: 11, Loss (standarized): 0.1805723029482859\n",
      "Epoch: 12, Loss (standarized): 0.17826310578975615\n",
      "Epoch: 13, Loss (standarized): 0.1760909191941316\n",
      "Epoch: 14, Loss (standarized): 0.17403887358333703\n",
      "Epoch: 15, Loss (standarized): 0.17204261457844572\n",
      "Epoch: 16, Loss (standarized): 0.16991402975688158\n",
      "Epoch: 17, Loss (standarized): 0.1677692762748827\n",
      "Epoch: 18, Loss (standarized): 0.16548464213526767\n",
      "Epoch: 19, Loss (standarized): 0.16320425865277213\n",
      "Epoch: 20, Loss (standarized): 0.16090320165608762\n",
      "Final epoch: 20, Final loss (standarized): 0.16090320165608762\n",
      "Epoch: 1, Loss (standarized): 0.21935208013207078\n",
      "Epoch: 2, Loss (standarized): 0.20009655077707336\n",
      "Epoch: 3, Loss (standarized): 0.1985266472226551\n",
      "Epoch: 4, Loss (standarized): 0.19940011860840381\n",
      "Epoch: 5, Loss (standarized): 0.1977617944075047\n",
      "Epoch: 6, Loss (standarized): 0.1935971264767304\n",
      "Epoch: 7, Loss (standarized): 0.18827090577950803\n",
      "Epoch: 8, Loss (standarized): 0.18326118561293145\n",
      "Epoch: 9, Loss (standarized): 0.17964875691106996\n",
      "Epoch: 10, Loss (standarized): 0.17751922281599658\n",
      "Epoch: 11, Loss (standarized): 0.17569960236361062\n",
      "Epoch: 12, Loss (standarized): 0.17301637924550473\n",
      "Epoch: 13, Loss (standarized): 0.16966782428398725\n",
      "Epoch: 14, Loss (standarized): 0.16630761878722777\n",
      "Epoch: 15, Loss (standarized): 0.16357155734148401\n",
      "Epoch: 16, Loss (standarized): 0.16136475386120483\n",
      "Epoch: 17, Loss (standarized): 0.15917623327870598\n",
      "Epoch: 18, Loss (standarized): 0.1567148690616827\n",
      "Epoch: 19, Loss (standarized): 0.1540580280455164\n",
      "Epoch: 20, Loss (standarized): 0.15169394437199082\n",
      "Final epoch: 20, Final loss (standarized): 0.15169394437199082\n",
      "Epoch: 1, Loss (standarized): 0.8010469769366787\n",
      "Epoch: 2, Loss (standarized): 0.5759174177828755\n",
      "Epoch: 3, Loss (standarized): 0.4290385485829983\n",
      "Epoch: 4, Loss (standarized): 0.33785477585682466\n",
      "Epoch: 5, Loss (standarized): 0.28232962107077175\n",
      "Epoch: 6, Loss (standarized): 0.24813088583954948\n",
      "Epoch: 7, Loss (standarized): 0.2262827495889423\n",
      "Epoch: 8, Loss (standarized): 0.2123822218670335\n",
      "Epoch: 9, Loss (standarized): 0.20369992002121956\n",
      "Epoch: 10, Loss (standarized): 0.19844013837711433\n",
      "Epoch: 11, Loss (standarized): 0.1955526605023799\n",
      "Epoch: 12, Loss (standarized): 0.1942339513021878\n",
      "Epoch: 13, Loss (standarized): 0.19387719052981325\n",
      "Epoch: 14, Loss (standarized): 0.19404993146860225\n",
      "Epoch: 15, Loss (standarized): 0.19440686374560404\n",
      "Epoch: 16, Loss (standarized): 0.19477375539002142\n",
      "Epoch: 17, Loss (standarized): 0.194992995616713\n",
      "Epoch: 18, Loss (standarized): 0.1950209856433494\n",
      "Epoch: 19, Loss (standarized): 0.19484800870002086\n",
      "Epoch: 20, Loss (standarized): 0.1944671403641888\n",
      "Final epoch: 20, Final loss (standarized): 0.1944671403641888\n",
      "Epoch: 1, Loss (standarized): 0.3102493904883328\n",
      "Epoch: 2, Loss (standarized): 0.25706641524919416\n",
      "Epoch: 3, Loss (standarized): 0.23356639626257572\n",
      "Epoch: 4, Loss (standarized): 0.22313342121305396\n",
      "Epoch: 5, Loss (standarized): 0.2180528889243938\n",
      "Epoch: 6, Loss (standarized): 0.21465183572037663\n",
      "Epoch: 7, Loss (standarized): 0.21149393039016612\n",
      "Epoch: 8, Loss (standarized): 0.20816025542953207\n",
      "Epoch: 9, Loss (standarized): 0.204627596227192\n",
      "Epoch: 10, Loss (standarized): 0.20102972376050524\n",
      "Epoch: 11, Loss (standarized): 0.19762709530551423\n",
      "Epoch: 12, Loss (standarized): 0.1946666341856145\n",
      "Epoch: 13, Loss (standarized): 0.192286678271143\n",
      "Epoch: 14, Loss (standarized): 0.19059976358707995\n",
      "Epoch: 15, Loss (standarized): 0.18948841193679236\n",
      "Epoch: 16, Loss (standarized): 0.1888664269848917\n",
      "Epoch: 17, Loss (standarized): 0.18860392058377465\n",
      "Epoch: 18, Loss (standarized): 0.18854804240919304\n",
      "Epoch: 19, Loss (standarized): 0.1885584862681197\n",
      "Epoch: 20, Loss (standarized): 0.18852787574058452\n",
      "Final epoch: 20, Final loss (standarized): 0.18852787574058452\n",
      "Epoch: 1, Loss (standarized): 1.404295740933466\n",
      "Epoch: 2, Loss (standarized): 0.9280752749925415\n",
      "Epoch: 3, Loss (standarized): 0.5935863770078592\n",
      "Epoch: 4, Loss (standarized): 0.3946000798609779\n",
      "Epoch: 5, Loss (standarized): 0.2889658036842062\n",
      "Epoch: 6, Loss (standarized): 0.23744487127630579\n",
      "Epoch: 7, Loss (standarized): 0.21442863535880005\n",
      "Epoch: 8, Loss (standarized): 0.20594900685484013\n",
      "Epoch: 9, Loss (standarized): 0.2044621760605033\n",
      "Epoch: 10, Loss (standarized): 0.20617912755241266\n",
      "Epoch: 11, Loss (standarized): 0.20915359834336894\n",
      "Epoch: 12, Loss (standarized): 0.21230521716004827\n",
      "Epoch: 13, Loss (standarized): 0.21507724497006164\n",
      "Epoch: 14, Loss (standarized): 0.2172274479365983\n",
      "Epoch: 15, Loss (standarized): 0.21862584888728712\n",
      "Epoch: 16, Loss (standarized): 0.2192162633194777\n",
      "Epoch: 17, Loss (standarized): 0.21900530572766425\n",
      "Epoch: 18, Loss (standarized): 0.21808905555783953\n",
      "Epoch: 19, Loss (standarized): 0.21654458080197161\n",
      "Epoch: 20, Loss (standarized): 0.21446977886944638\n",
      "Final epoch: 20, Final loss (standarized): 0.21446977886944638\n",
      "Epoch: 1, Loss (standarized): 5.0660266366645095\n",
      "Epoch: 2, Loss (standarized): 4.071518682967012\n",
      "Epoch: 3, Loss (standarized): 3.1699859991632295\n",
      "Epoch: 4, Loss (standarized): 2.364416017094191\n",
      "Epoch: 5, Loss (standarized): 1.6736941139750106\n",
      "Epoch: 6, Loss (standarized): 1.1110338467814835\n",
      "Epoch: 7, Loss (standarized): 0.6907534637782042\n",
      "Epoch: 8, Loss (standarized): 0.41244352441937526\n",
      "Epoch: 9, Loss (standarized): 0.27419747503250197\n",
      "Epoch: 10, Loss (standarized): 0.22226789258339888\n",
      "Epoch: 11, Loss (standarized): 0.2067779015019899\n",
      "Epoch: 12, Loss (standarized): 0.20533808730755984\n",
      "Epoch: 13, Loss (standarized): 0.20931440197316814\n",
      "Epoch: 14, Loss (standarized): 0.2153095615027336\n",
      "Epoch: 15, Loss (standarized): 0.22143872645332077\n",
      "Epoch: 16, Loss (standarized): 0.22703304244708053\n",
      "Epoch: 17, Loss (standarized): 0.2316467401195544\n",
      "Epoch: 18, Loss (standarized): 0.23535923207533627\n",
      "Epoch: 19, Loss (standarized): 0.23808937444766604\n",
      "Epoch: 20, Loss (standarized): 0.23985872356363425\n",
      "Final epoch: 20, Final loss (standarized): 0.23985872356363425\n",
      "Epoch: 1, Loss (standarized): 1.2860914350575334\n",
      "Epoch: 2, Loss (standarized): 0.8873073276947395\n",
      "Epoch: 3, Loss (standarized): 0.6220298379554255\n",
      "Epoch: 4, Loss (standarized): 0.4590547605890582\n",
      "Epoch: 5, Loss (standarized): 0.3613929022762574\n",
      "Epoch: 6, Loss (standarized): 0.30253621826720645\n",
      "Epoch: 7, Loss (standarized): 0.26604976416993975\n",
      "Epoch: 8, Loss (standarized): 0.24327054698030132\n",
      "Epoch: 9, Loss (standarized): 0.2291127121224911\n",
      "Epoch: 10, Loss (standarized): 0.22056973839947935\n",
      "Epoch: 11, Loss (standarized): 0.21567931654850472\n",
      "Epoch: 12, Loss (standarized): 0.2131484331522233\n",
      "Epoch: 13, Loss (standarized): 0.2121235217822817\n",
      "Epoch: 14, Loss (standarized): 0.2120552995270221\n",
      "Epoch: 15, Loss (standarized): 0.2126082225381941\n",
      "Epoch: 16, Loss (standarized): 0.21345188113656813\n",
      "Epoch: 17, Loss (standarized): 0.214309914113059\n",
      "Epoch: 18, Loss (standarized): 0.21501890248973116\n",
      "Epoch: 19, Loss (standarized): 0.21554399903579585\n",
      "Epoch: 20, Loss (standarized): 0.21584471247271078\n",
      "Final epoch: 20, Final loss (standarized): 0.21584471247271078\n",
      "Epoch: 1, Loss (standarized): 0.7020242343306897\n",
      "Epoch: 2, Loss (standarized): 0.5856363372350496\n",
      "Epoch: 3, Loss (standarized): 0.4888096074403876\n",
      "Epoch: 4, Loss (standarized): 0.40938889943570506\n",
      "Epoch: 5, Loss (standarized): 0.3464079044872556\n",
      "Epoch: 6, Loss (standarized): 0.2981843914164734\n",
      "Epoch: 7, Loss (standarized): 0.26314539603524245\n",
      "Epoch: 8, Loss (standarized): 0.23900543462864487\n",
      "Epoch: 9, Loss (standarized): 0.22329391224146625\n",
      "Epoch: 10, Loss (standarized): 0.21385839923976868\n",
      "Epoch: 11, Loss (standarized): 0.20851253895137598\n",
      "Epoch: 12, Loss (standarized): 0.20581599582913793\n",
      "Epoch: 13, Loss (standarized): 0.20460559582288845\n",
      "Epoch: 14, Loss (standarized): 0.204089942595375\n",
      "Epoch: 15, Loss (standarized): 0.20374352923627298\n",
      "Epoch: 16, Loss (standarized): 0.20323968938324774\n",
      "Epoch: 17, Loss (standarized): 0.2024382783677747\n",
      "Epoch: 18, Loss (standarized): 0.2012431206077545\n",
      "Epoch: 19, Loss (standarized): 0.1996892589315408\n",
      "Epoch: 20, Loss (standarized): 0.19785693333621895\n",
      "Final epoch: 20, Final loss (standarized): 0.19785693333621895\n",
      "Epoch: 1, Loss (standarized): 0.49451080126315056\n",
      "Epoch: 2, Loss (standarized): 0.3216551582637597\n",
      "Epoch: 3, Loss (standarized): 0.2510338523859033\n",
      "Epoch: 4, Loss (standarized): 0.22957446145961782\n",
      "Epoch: 5, Loss (standarized): 0.2271447287691906\n",
      "Epoch: 6, Loss (standarized): 0.23046431515343507\n",
      "Epoch: 7, Loss (standarized): 0.23404557214121313\n",
      "Epoch: 8, Loss (standarized): 0.23608842848672074\n",
      "Epoch: 9, Loss (standarized): 0.2361771107195381\n",
      "Epoch: 10, Loss (standarized): 0.23445892886240002\n",
      "Epoch: 11, Loss (standarized): 0.23125069368386433\n",
      "Epoch: 12, Loss (standarized): 0.22692604778383085\n",
      "Epoch: 13, Loss (standarized): 0.2220585551382026\n",
      "Epoch: 14, Loss (standarized): 0.21719364283264525\n",
      "Epoch: 15, Loss (standarized): 0.2128251705689324\n",
      "Epoch: 16, Loss (standarized): 0.20932130954638528\n",
      "Epoch: 17, Loss (standarized): 0.20687678642872148\n",
      "Epoch: 18, Loss (standarized): 0.20536227521833406\n",
      "Epoch: 19, Loss (standarized): 0.20435163943695903\n",
      "Epoch: 20, Loss (standarized): 0.2033308898358462\n",
      "Final epoch: 20, Final loss (standarized): 0.2033308898358462\n",
      "Epoch: 1, Loss (standarized): 2.7768562790889373\n",
      "Epoch: 2, Loss (standarized): 2.241457460061462\n",
      "Epoch: 3, Loss (standarized): 1.7566082421956384\n",
      "Epoch: 4, Loss (standarized): 1.3323697450262466\n",
      "Epoch: 5, Loss (standarized): 0.985775318581334\n",
      "Epoch: 6, Loss (standarized): 0.7274458378758938\n",
      "Epoch: 7, Loss (standarized): 0.5529149212885309\n",
      "Epoch: 8, Loss (standarized): 0.43887817967264786\n",
      "Epoch: 9, Loss (standarized): 0.36165915999178294\n",
      "Epoch: 10, Loss (standarized): 0.3077937004746111\n",
      "Epoch: 11, Loss (standarized): 0.2704100510475064\n",
      "Epoch: 12, Loss (standarized): 0.24562942714688207\n",
      "Epoch: 13, Loss (standarized): 0.22998895993894036\n",
      "Epoch: 14, Loss (standarized): 0.2205686980974122\n",
      "Epoch: 15, Loss (standarized): 0.21548347634034284\n",
      "Epoch: 16, Loss (standarized): 0.21337500851057808\n",
      "Epoch: 17, Loss (standarized): 0.21309668103822588\n",
      "Epoch: 18, Loss (standarized): 0.21391721920112056\n",
      "Epoch: 19, Loss (standarized): 0.21525885391523933\n",
      "Epoch: 20, Loss (standarized): 0.21673342152499825\n",
      "Final epoch: 20, Final loss (standarized): 0.21673342152499825\n",
      "Epoch: 1, Loss (standarized): 0.6382748937309068\n",
      "Epoch: 2, Loss (standarized): 0.4348498028336536\n",
      "Epoch: 3, Loss (standarized): 0.3266563507297315\n",
      "Epoch: 4, Loss (standarized): 0.27250598190608183\n",
      "Epoch: 5, Loss (standarized): 0.2472132659977382\n",
      "Epoch: 6, Loss (standarized): 0.23560595498808962\n",
      "Epoch: 7, Loss (standarized): 0.22996412631911145\n",
      "Epoch: 8, Loss (standarized): 0.2273355440920551\n",
      "Epoch: 9, Loss (standarized): 0.22576504338074718\n",
      "Epoch: 10, Loss (standarized): 0.2243059772649288\n",
      "Epoch: 11, Loss (standarized): 0.2224581663722961\n",
      "Epoch: 12, Loss (standarized): 0.21994047640732897\n",
      "Epoch: 13, Loss (standarized): 0.21676723015724367\n",
      "Epoch: 14, Loss (standarized): 0.21302444737913154\n",
      "Epoch: 15, Loss (standarized): 0.2089110827517137\n",
      "Epoch: 16, Loss (standarized): 0.20471291342656345\n",
      "Epoch: 17, Loss (standarized): 0.20077315230495207\n",
      "Epoch: 18, Loss (standarized): 0.19732622658026805\n",
      "Epoch: 19, Loss (standarized): 0.1945900899489796\n",
      "Epoch: 20, Loss (standarized): 0.19266189613014245\n",
      "Final epoch: 20, Final loss (standarized): 0.19266189613014245\n",
      "Epoch: 1, Loss (standarized): 0.27097299493707655\n",
      "Epoch: 2, Loss (standarized): 0.24244338296819015\n",
      "Epoch: 3, Loss (standarized): 0.22721544572280572\n",
      "Epoch: 4, Loss (standarized): 0.21777718977669105\n",
      "Epoch: 5, Loss (standarized): 0.2102352115675687\n",
      "Epoch: 6, Loss (standarized): 0.20367267135860814\n",
      "Epoch: 7, Loss (standarized): 0.1987869076392831\n",
      "Epoch: 8, Loss (standarized): 0.19540184010524866\n",
      "Epoch: 9, Loss (standarized): 0.19269384178706522\n",
      "Epoch: 10, Loss (standarized): 0.19059387884510562\n",
      "Epoch: 11, Loss (standarized): 0.18872351273056184\n",
      "Epoch: 12, Loss (standarized): 0.1867645318624881\n",
      "Epoch: 13, Loss (standarized): 0.18468510542920602\n",
      "Epoch: 14, Loss (standarized): 0.18246986390131803\n",
      "Epoch: 15, Loss (standarized): 0.1803565976283254\n",
      "Epoch: 16, Loss (standarized): 0.17846631570559252\n",
      "Epoch: 17, Loss (standarized): 0.17680612450880998\n",
      "Epoch: 18, Loss (standarized): 0.17535095817717056\n",
      "Epoch: 19, Loss (standarized): 0.17413328661952987\n",
      "Epoch: 20, Loss (standarized): 0.17310467495406465\n",
      "Final epoch: 20, Final loss (standarized): 0.17310467495406465\n",
      "Epoch: 1, Loss (standarized): 1.239534672405684\n",
      "Epoch: 2, Loss (standarized): 0.7737005398368423\n",
      "Epoch: 3, Loss (standarized): 0.4726314553522287\n",
      "Epoch: 4, Loss (standarized): 0.3158933479880228\n",
      "Epoch: 5, Loss (standarized): 0.24715536519945036\n",
      "Epoch: 6, Loss (standarized): 0.2232912206413098\n",
      "Epoch: 7, Loss (standarized): 0.21913832256258664\n",
      "Epoch: 8, Loss (standarized): 0.2231792708611817\n",
      "Epoch: 9, Loss (standarized): 0.23029194961987642\n",
      "Epoch: 10, Loss (standarized): 0.2381844441528689\n",
      "Epoch: 11, Loss (standarized): 0.24568870766694598\n",
      "Epoch: 12, Loss (standarized): 0.252125028297581\n",
      "Epoch: 13, Loss (standarized): 0.25721563430986744\n",
      "Epoch: 14, Loss (standarized): 0.26087810274938156\n",
      "Epoch: 15, Loss (standarized): 0.2631032294685236\n",
      "Epoch: 16, Loss (standarized): 0.263914002248498\n",
      "Epoch: 17, Loss (standarized): 0.2635206287377172\n",
      "Epoch: 18, Loss (standarized): 0.2620168865687023\n",
      "Epoch: 19, Loss (standarized): 0.25951932834755875\n",
      "Epoch: 20, Loss (standarized): 0.2561694260113236\n",
      "Final epoch: 20, Final loss (standarized): 0.2561694260113236\n",
      "Epoch: 1, Loss (standarized): 0.8635001237422375\n",
      "Epoch: 2, Loss (standarized): 0.6350755286311711\n",
      "Epoch: 3, Loss (standarized): 0.4631449176225429\n",
      "Epoch: 4, Loss (standarized): 0.3445032852573808\n",
      "Epoch: 5, Loss (standarized): 0.2710181483892914\n",
      "Epoch: 6, Loss (standarized): 0.23066499690442405\n",
      "Epoch: 7, Loss (standarized): 0.2106477005310209\n",
      "Epoch: 8, Loss (standarized): 0.2024604181263501\n",
      "Epoch: 9, Loss (standarized): 0.20082394506698692\n",
      "Epoch: 10, Loss (standarized): 0.20262050873930348\n",
      "Epoch: 11, Loss (standarized): 0.20596730624136905\n",
      "Epoch: 12, Loss (standarized): 0.209611553781634\n",
      "Epoch: 13, Loss (standarized): 0.21282136781256022\n",
      "Epoch: 14, Loss (standarized): 0.21524407339914803\n",
      "Epoch: 15, Loss (standarized): 0.21667231703668477\n",
      "Epoch: 16, Loss (standarized): 0.217017673783257\n",
      "Epoch: 17, Loss (standarized): 0.2163160235539139\n",
      "Epoch: 18, Loss (standarized): 0.21470779530777867\n",
      "Epoch: 19, Loss (standarized): 0.21237167796509515\n",
      "Epoch: 20, Loss (standarized): 0.20941892563211312\n",
      "Final epoch: 20, Final loss (standarized): 0.20941892563211312\n",
      "Epoch: 1, Loss (standarized): 0.23726839957548923\n",
      "          Validation Loss (standardized): 1.4976871262210938\n",
      "Epoch: 2, Loss (standarized): 0.21475700678183585\n",
      "          Validation Loss (standardized): 1.674761613272735\n",
      "Epoch: 3, Loss (standarized): 0.21635901024632734\n",
      "          Validation Loss (standardized): 1.7287209885716102\n",
      "Epoch: 4, Loss (standarized): 0.21656013559949738\n",
      "          Validation Loss (standardized): 1.694531555093982\n",
      "Epoch: 5, Loss (standarized): 0.21272971900435428\n",
      "          Validation Loss (standardized): 1.6067825655587422\n",
      "Epoch: 6, Loss (standarized): 0.2062536399236866\n",
      "          Validation Loss (standardized): 1.4919184366754756\n",
      "Epoch: 7, Loss (standarized): 0.1994814645705502\n",
      "          Validation Loss (standardized): 1.3717057009470364\n",
      "Epoch: 8, Loss (standarized): 0.19433659284329952\n",
      "          Validation Loss (standardized): 1.2664607645864219\n",
      "Epoch: 9, Loss (standarized): 0.19169928902296296\n",
      "          Validation Loss (standardized): 1.19222378000348\n",
      "Epoch: 10, Loss (standarized): 0.19055482843623953\n",
      "          Validation Loss (standardized): 1.1570663517107167\n",
      "Epoch: 11, Loss (standarized): 0.18857462207035677\n",
      "          Validation Loss (standardized): 1.1596555484706883\n",
      "Epoch: 12, Loss (standarized): 0.18474159552219308\n",
      "          Validation Loss (standardized): 1.190174824581228\n",
      "Epoch: 13, Loss (standarized): 0.18048445611839675\n",
      "          Validation Loss (standardized): 1.2349243966913495\n",
      "Epoch: 14, Loss (standarized): 0.17718956723117368\n",
      "          Validation Loss (standardized): 1.2790124651834764\n",
      "Epoch: 15, Loss (standarized): 0.17506153831862137\n",
      "          Validation Loss (standardized): 1.3094576955604622\n",
      "Epoch: 16, Loss (standarized): 0.17345657823903668\n",
      "          Validation Loss (standardized): 1.3180381364355436\n",
      "Epoch: 17, Loss (standarized): 0.17155227669822606\n",
      "          Validation Loss (standardized): 1.302700934456429\n",
      "Epoch: 18, Loss (standarized): 0.16901206769773372\n",
      "          Validation Loss (standardized): 1.2658369935160125\n",
      "Epoch: 19, Loss (standarized): 0.16596071591033462\n",
      "          Validation Loss (standardized): 1.2152611461636287\n",
      "Epoch: 20, Loss (standarized): 0.16296657232302403\n",
      "          Validation Loss (standardized): 1.1611477010174411\n",
      "Final epoch: 20, Final loss (standarized): 0.16296657232302403\n",
      "Epoch: 1, Loss (standarized): 1.2288767314550604\n",
      "          Validation Loss (standardized): 0.8660980640260295\n",
      "Epoch: 2, Loss (standarized): 0.9077383847971885\n",
      "          Validation Loss (standardized): 0.8187404832796568\n",
      "Epoch: 3, Loss (standarized): 0.6388512437086448\n",
      "          Validation Loss (standardized): 0.8439738330750639\n",
      "Epoch: 4, Loss (standarized): 0.43406375372602335\n",
      "          Validation Loss (standardized): 0.9467717859038103\n",
      "Epoch: 5, Loss (standarized): 0.2994471085258115\n",
      "          Validation Loss (standardized): 1.1113410595458073\n",
      "Epoch: 6, Loss (standarized): 0.22720683432449265\n",
      "          Validation Loss (standardized): 1.3076742117110307\n",
      "Epoch: 7, Loss (standarized): 0.19901388671476797\n",
      "          Validation Loss (standardized): 1.5066102069707674\n",
      "Epoch: 8, Loss (standarized): 0.19448486738347104\n",
      "          Validation Loss (standardized): 1.6897199425830332\n",
      "Epoch: 9, Loss (standarized): 0.19957123529925827\n",
      "          Validation Loss (standardized): 1.846640676031564\n",
      "Epoch: 10, Loss (standarized): 0.20773592166612054\n",
      "          Validation Loss (standardized): 1.9740501251131832\n",
      "Epoch: 11, Loss (standarized): 0.21605287030716241\n",
      "          Validation Loss (standardized): 2.070330413969579\n",
      "Epoch: 12, Loss (standarized): 0.2231095872023825\n",
      "          Validation Loss (standardized): 2.1369063809621207\n",
      "Epoch: 13, Loss (standarized): 0.22828463925960327\n",
      "          Validation Loss (standardized): 2.1769068989007057\n",
      "Epoch: 14, Loss (standarized): 0.23153970601980187\n",
      "          Validation Loss (standardized): 2.194103346678481\n",
      "Epoch: 15, Loss (standarized): 0.23313994205580663\n",
      "          Validation Loss (standardized): 2.1923639374513813\n",
      "Epoch: 16, Loss (standarized): 0.23331901149732612\n",
      "          Validation Loss (standardized): 2.1746886371902394\n",
      "Epoch: 17, Loss (standarized): 0.23227707370749628\n",
      "          Validation Loss (standardized): 2.1437563310672427\n",
      "Epoch: 18, Loss (standarized): 0.23024580133218406\n",
      "          Validation Loss (standardized): 2.102221162775584\n",
      "Epoch: 19, Loss (standarized): 0.22746965734951324\n",
      "          Validation Loss (standardized): 2.0532774285634985\n",
      "Epoch: 20, Loss (standarized): 0.22420954170369156\n",
      "          Validation Loss (standardized): 1.9994342999513304\n",
      "Final epoch: 20, Final loss (standarized): 0.22420954170369156\n",
      "Epoch: 1, Loss (standarized): 1.524645598956128\n",
      "          Validation Loss (standardized): 0.7945788428334004\n",
      "Epoch: 2, Loss (standarized): 1.0175214284287468\n",
      "          Validation Loss (standardized): 0.7092667479955704\n",
      "Epoch: 3, Loss (standarized): 0.6595574313251477\n",
      "          Validation Loss (standardized): 0.7518189332392932\n",
      "Epoch: 4, Loss (standarized): 0.453003780349614\n",
      "          Validation Loss (standardized): 0.8712296066159044\n",
      "Epoch: 5, Loss (standarized): 0.3435684057908574\n",
      "          Validation Loss (standardized): 1.0247547207243557\n",
      "Epoch: 6, Loss (standarized): 0.2879792350202573\n",
      "          Validation Loss (standardized): 1.1905132263514182\n",
      "Epoch: 7, Loss (standarized): 0.26116976065193576\n",
      "          Validation Loss (standardized): 1.355934607553831\n",
      "Epoch: 8, Loss (standarized): 0.24940235831613666\n",
      "          Validation Loss (standardized): 1.5118821978370018\n",
      "Epoch: 9, Loss (standarized): 0.24542880254826221\n",
      "          Validation Loss (standardized): 1.654084734174466\n",
      "Epoch: 10, Loss (standarized): 0.24541483693731694\n",
      "          Validation Loss (standardized): 1.781798054911394\n",
      "Epoch: 11, Loss (standarized): 0.2474781244616614\n",
      "          Validation Loss (standardized): 1.8942781894697214\n",
      "Epoch: 12, Loss (standarized): 0.2504641928846236\n",
      "          Validation Loss (standardized): 1.9912653826250437\n",
      "Epoch: 13, Loss (standarized): 0.25360781193708176\n",
      "          Validation Loss (standardized): 2.072234129629291\n",
      "Epoch: 14, Loss (standarized): 0.25650776630198824\n",
      "          Validation Loss (standardized): 2.13725505478863\n",
      "Epoch: 15, Loss (standarized): 0.25887411793902365\n",
      "          Validation Loss (standardized): 2.1862562879494543\n",
      "Epoch: 16, Loss (standarized): 0.2604802408074349\n",
      "          Validation Loss (standardized): 2.2201896215884585\n",
      "Epoch: 17, Loss (standarized): 0.26119360512307266\n",
      "          Validation Loss (standardized): 2.2398793044803678\n",
      "Epoch: 18, Loss (standarized): 0.2609609877548149\n",
      "          Validation Loss (standardized): 2.2468428239382647\n",
      "Epoch: 19, Loss (standarized): 0.25982116307173697\n",
      "          Validation Loss (standardized): 2.2424624523368277\n",
      "Epoch: 20, Loss (standarized): 0.2579233679917616\n",
      "          Validation Loss (standardized): 2.2282779645155957\n",
      "Final epoch: 20, Final loss (standarized): 0.2579233679917616\n",
      "Epoch: 1, Loss (standarized): 0.8470326325942238\n",
      "          Validation Loss (standardized): 0.7269689158369989\n",
      "Epoch: 2, Loss (standarized): 0.616221485156907\n",
      "          Validation Loss (standardized): 0.74182461249244\n",
      "Epoch: 3, Loss (standarized): 0.4553910353526723\n",
      "          Validation Loss (standardized): 0.8020448621240683\n",
      "Epoch: 4, Loss (standarized): 0.3500501921031503\n",
      "          Validation Loss (standardized): 0.8945450526712742\n",
      "Epoch: 5, Loss (standarized): 0.28220220168599225\n",
      "          Validation Loss (standardized): 1.0093905879875433\n",
      "Epoch: 6, Loss (standarized): 0.23941406526024836\n",
      "          Validation Loss (standardized): 1.139389809539879\n",
      "Epoch: 7, Loss (standarized): 0.2139821148571171\n",
      "          Validation Loss (standardized): 1.278780271888164\n",
      "Epoch: 8, Loss (standarized): 0.201386271275778\n",
      "          Validation Loss (standardized): 1.420238656045032\n",
      "Epoch: 9, Loss (standarized): 0.19752679786660743\n",
      "          Validation Loss (standardized): 1.557487529580061\n",
      "Epoch: 10, Loss (standarized): 0.1990125518128802\n",
      "          Validation Loss (standardized): 1.6843428412381232\n",
      "Epoch: 11, Loss (standarized): 0.20326253566228503\n",
      "          Validation Loss (standardized): 1.7956973742018523\n",
      "Epoch: 12, Loss (standarized): 0.20851083661756642\n",
      "          Validation Loss (standardized): 1.888025912407722\n",
      "Epoch: 13, Loss (standarized): 0.21364325548864957\n",
      "          Validation Loss (standardized): 1.9595717761557734\n",
      "Epoch: 14, Loss (standarized): 0.21794174056892518\n",
      "          Validation Loss (standardized): 2.0102243995012157\n",
      "Epoch: 15, Loss (standarized): 0.22102461461240702\n",
      "          Validation Loss (standardized): 2.040694936027837\n",
      "Epoch: 16, Loss (standarized): 0.22278500868891682\n",
      "          Validation Loss (standardized): 2.0527858626782893\n",
      "Epoch: 17, Loss (standarized): 0.22323346068754482\n",
      "          Validation Loss (standardized): 2.0485340675834927\n",
      "Epoch: 18, Loss (standarized): 0.22247261739922722\n",
      "          Validation Loss (standardized): 2.0303053657857664\n",
      "Epoch: 19, Loss (standarized): 0.22070049625931565\n",
      "          Validation Loss (standardized): 2.00050362023386\n",
      "Epoch: 20, Loss (standarized): 0.21816132617045086\n",
      "          Validation Loss (standardized): 1.9615357317838902\n",
      "Final epoch: 20, Final loss (standarized): 0.21816132617045086\n",
      "Epoch: 1, Loss (standarized): 2.449696710350587\n",
      "          Validation Loss (standardized): 1.180804214226548\n",
      "Epoch: 2, Loss (standarized): 1.7956421546138899\n",
      "          Validation Loss (standardized): 0.931833700171725\n",
      "Epoch: 3, Loss (standarized): 1.239343933720019\n",
      "          Validation Loss (standardized): 0.7812785038112493\n",
      "Epoch: 4, Loss (standarized): 0.784859350557161\n",
      "          Validation Loss (standardized): 0.7551728933650435\n",
      "Epoch: 5, Loss (standarized): 0.4556195172817684\n",
      "          Validation Loss (standardized): 0.8622864391998881\n",
      "Epoch: 6, Loss (standarized): 0.28556186325046257\n",
      "          Validation Loss (standardized): 1.0403584549667226\n",
      "Epoch: 7, Loss (standarized): 0.22807365703560034\n",
      "          Validation Loss (standardized): 1.2284062811277494\n",
      "Epoch: 8, Loss (standarized): 0.21094570500815893\n",
      "          Validation Loss (standardized): 1.4037764728691655\n",
      "Epoch: 9, Loss (standarized): 0.20734189842669573\n",
      "          Validation Loss (standardized): 1.5581160430510732\n",
      "Epoch: 10, Loss (standarized): 0.2084636860119074\n",
      "          Validation Loss (standardized): 1.691003528792229\n",
      "Epoch: 11, Loss (standarized): 0.21169083978974218\n",
      "          Validation Loss (standardized): 1.8062652876646847\n",
      "Epoch: 12, Loss (standarized): 0.21585447269776983\n",
      "          Validation Loss (standardized): 1.9046990447189267\n",
      "Epoch: 13, Loss (standarized): 0.22015968050698526\n",
      "          Validation Loss (standardized): 1.9872416933974353\n",
      "Epoch: 14, Loss (standarized): 0.22405168213185156\n",
      "          Validation Loss (standardized): 2.054238976138903\n",
      "Epoch: 15, Loss (standarized): 0.22731218359864938\n",
      "          Validation Loss (standardized): 2.107405522693557\n",
      "Epoch: 16, Loss (standarized): 0.22992218927423427\n",
      "          Validation Loss (standardized): 2.148109115921088\n",
      "Epoch: 17, Loss (standarized): 0.23190376535222984\n",
      "          Validation Loss (standardized): 2.177263495716104\n",
      "Epoch: 18, Loss (standarized): 0.23329782839647767\n",
      "          Validation Loss (standardized): 2.1961825369661945\n",
      "Epoch: 19, Loss (standarized): 0.23412480313257858\n",
      "          Validation Loss (standardized): 2.2060318948001436\n",
      "Epoch: 20, Loss (standarized): 0.234405944970636\n",
      "          Validation Loss (standardized): 2.207751124741621\n",
      "Final epoch: 20, Final loss (standarized): 0.234405944970636\n",
      "Epoch: 1, Loss (standarized): 1.1692267983687124\n",
      "          Validation Loss (standardized): 0.7880694760456554\n",
      "Epoch: 2, Loss (standarized): 0.8964590723831022\n",
      "          Validation Loss (standardized): 0.7394704091577495\n",
      "Epoch: 3, Loss (standarized): 0.6796645813334468\n",
      "          Validation Loss (standardized): 0.7339273478080903\n",
      "Epoch: 4, Loss (standarized): 0.5229850726815637\n",
      "          Validation Loss (standardized): 0.7587718504016763\n",
      "Epoch: 5, Loss (standarized): 0.41197647628367207\n",
      "          Validation Loss (standardized): 0.8082110759768321\n",
      "Epoch: 6, Loss (standarized): 0.33589224829975084\n",
      "          Validation Loss (standardized): 0.8748826573249562\n",
      "Epoch: 7, Loss (standarized): 0.28764664405856877\n",
      "          Validation Loss (standardized): 0.9506920177002677\n",
      "Epoch: 8, Loss (standarized): 0.2602392654910825\n",
      "          Validation Loss (standardized): 1.0249751138548127\n",
      "Epoch: 9, Loss (standarized): 0.24178469615685566\n",
      "          Validation Loss (standardized): 1.0968082697027495\n",
      "Epoch: 10, Loss (standarized): 0.22833943675650034\n",
      "          Validation Loss (standardized): 1.1658126904062105\n",
      "Epoch: 11, Loss (standarized): 0.2187278172166309\n",
      "          Validation Loss (standardized): 1.23079917863491\n",
      "Epoch: 12, Loss (standarized): 0.2119459888954312\n",
      "          Validation Loss (standardized): 1.2906023130841293\n",
      "Epoch: 13, Loss (standarized): 0.20716574305120253\n",
      "          Validation Loss (standardized): 1.3440552270330566\n",
      "Epoch: 14, Loss (standarized): 0.20379105003580597\n",
      "          Validation Loss (standardized): 1.390470122929039\n",
      "Epoch: 15, Loss (standarized): 0.20136191467575898\n",
      "          Validation Loss (standardized): 1.429934765052093\n",
      "Epoch: 16, Loss (standarized): 0.19963813159993676\n",
      "          Validation Loss (standardized): 1.4625640447939177\n",
      "Epoch: 17, Loss (standarized): 0.19839092091302118\n",
      "          Validation Loss (standardized): 1.4871738034657909\n",
      "Epoch: 18, Loss (standarized): 0.19741001233629255\n",
      "          Validation Loss (standardized): 1.5040347436934434\n",
      "Epoch: 19, Loss (standarized): 0.19654934182357833\n",
      "          Validation Loss (standardized): 1.5135603983089996\n",
      "Epoch: 20, Loss (standarized): 0.1957402972775875\n",
      "          Validation Loss (standardized): 1.5165004480956206\n",
      "Final epoch: 20, Final loss (standarized): 0.1957402972775875\n",
      "Epoch: 1, Loss (standarized): 0.6994034313466942\n",
      "          Validation Loss (standardized): 0.7001411268550163\n",
      "Epoch: 2, Loss (standarized): 0.5393347598141063\n",
      "          Validation Loss (standardized): 0.727857957921881\n",
      "Epoch: 3, Loss (standarized): 0.4234086755475013\n",
      "          Validation Loss (standardized): 0.7823131650751298\n",
      "Epoch: 4, Loss (standarized): 0.34039692762382595\n",
      "          Validation Loss (standardized): 0.8573841845054099\n",
      "Epoch: 5, Loss (standarized): 0.2829598708393411\n",
      "          Validation Loss (standardized): 0.9471290882169633\n",
      "Epoch: 6, Loss (standarized): 0.24492918040642844\n",
      "          Validation Loss (standardized): 1.0445759005850004\n",
      "Epoch: 7, Loss (standarized): 0.22117546095786259\n",
      "          Validation Loss (standardized): 1.1441730666677337\n",
      "Epoch: 8, Loss (standarized): 0.2071048018119786\n",
      "          Validation Loss (standardized): 1.2408437623403585\n",
      "Epoch: 9, Loss (standarized): 0.19916081810132066\n",
      "          Validation Loss (standardized): 1.3311186497943897\n",
      "Epoch: 10, Loss (standarized): 0.19535601878794814\n",
      "          Validation Loss (standardized): 1.4126633734938228\n",
      "Epoch: 11, Loss (standarized): 0.19414071636973565\n",
      "          Validation Loss (standardized): 1.4840520099033654\n",
      "Epoch: 12, Loss (standarized): 0.19442547450481487\n",
      "          Validation Loss (standardized): 1.5443120479658325\n",
      "Epoch: 13, Loss (standarized): 0.19539728488476424\n",
      "          Validation Loss (standardized): 1.5919526056857576\n",
      "Epoch: 14, Loss (standarized): 0.19647108820115108\n",
      "          Validation Loss (standardized): 1.6271055835707962\n",
      "Epoch: 15, Loss (standarized): 0.19734959717927347\n",
      "          Validation Loss (standardized): 1.6505764993363499\n",
      "Epoch: 16, Loss (standarized): 0.19789371163026237\n",
      "          Validation Loss (standardized): 1.663147958882584\n",
      "Epoch: 17, Loss (standarized): 0.19803876266492884\n",
      "          Validation Loss (standardized): 1.6652018102784825\n",
      "Epoch: 18, Loss (standarized): 0.19774603241993202\n",
      "          Validation Loss (standardized): 1.6584885453896647\n",
      "Epoch: 19, Loss (standarized): 0.19708887198242284\n",
      "          Validation Loss (standardized): 1.6441979522438337\n",
      "Epoch: 20, Loss (standarized): 0.19611236359983977\n",
      "          Validation Loss (standardized): 1.6236032948853945\n",
      "Final epoch: 20, Final loss (standarized): 0.19611236359983977\n",
      "Epoch: 1, Loss (standarized): 1.8455099774806931\n",
      "          Validation Loss (standardized): 0.9892801535111007\n",
      "Epoch: 2, Loss (standarized): 1.33117876876637\n",
      "          Validation Loss (standardized): 0.8341879988908707\n",
      "Epoch: 3, Loss (standarized): 0.9219016010111998\n",
      "          Validation Loss (standardized): 0.76937245769763\n",
      "Epoch: 4, Loss (standarized): 0.6285129492329993\n",
      "          Validation Loss (standardized): 0.7850802204274114\n",
      "Epoch: 5, Loss (standarized): 0.43614519501155247\n",
      "          Validation Loss (standardized): 0.8606195516819031\n",
      "Epoch: 6, Loss (standarized): 0.3224418254378313\n",
      "          Validation Loss (standardized): 0.9717814990450906\n",
      "Epoch: 7, Loss (standarized): 0.26499144408738823\n",
      "          Validation Loss (standardized): 1.1000619136070167\n",
      "Epoch: 8, Loss (standarized): 0.23887950092393928\n",
      "          Validation Loss (standardized): 1.23140009785269\n",
      "Epoch: 9, Loss (standarized): 0.22760238268974614\n",
      "          Validation Loss (standardized): 1.3570718774758483\n",
      "Epoch: 10, Loss (standarized): 0.22296325418434754\n",
      "          Validation Loss (standardized): 1.4732203918974682\n",
      "Epoch: 11, Loss (standarized): 0.22218541983043608\n",
      "          Validation Loss (standardized): 1.577572766161204\n",
      "Epoch: 12, Loss (standarized): 0.2235722109553911\n",
      "          Validation Loss (standardized): 1.669011114183473\n",
      "Epoch: 13, Loss (standarized): 0.22596808535158422\n",
      "          Validation Loss (standardized): 1.7472352100722417\n",
      "Epoch: 14, Loss (standarized): 0.2286265405295973\n",
      "          Validation Loss (standardized): 1.8117392347005348\n",
      "Epoch: 15, Loss (standarized): 0.2310776018358511\n",
      "          Validation Loss (standardized): 1.8622384994885026\n",
      "Epoch: 16, Loss (standarized): 0.23297537054784015\n",
      "          Validation Loss (standardized): 1.899250630939905\n",
      "Epoch: 17, Loss (standarized): 0.23429950407741043\n",
      "          Validation Loss (standardized): 1.9235264032133437\n",
      "Epoch: 18, Loss (standarized): 0.2349864663171058\n",
      "          Validation Loss (standardized): 1.9358286609064173\n",
      "Epoch: 19, Loss (standarized): 0.23498492504407414\n",
      "          Validation Loss (standardized): 1.9376242845641043\n",
      "Epoch: 20, Loss (standarized): 0.2343307240676883\n",
      "          Validation Loss (standardized): 1.9299814200621943\n",
      "Final epoch: 20, Final loss (standarized): 0.2343307240676883\n",
      "Epoch: 1, Loss (standarized): 0.6637114968334319\n",
      "          Validation Loss (standardized): 0.8187717981179128\n",
      "Epoch: 2, Loss (standarized): 0.44754866533077714\n",
      "          Validation Loss (standardized): 0.9588969562430532\n",
      "Epoch: 3, Loss (standarized): 0.32589615220560125\n",
      "          Validation Loss (standardized): 1.1314666937230813\n",
      "Epoch: 4, Loss (standarized): 0.26416263779191246\n",
      "          Validation Loss (standardized): 1.307006727622825\n",
      "Epoch: 5, Loss (standarized): 0.2350819507273553\n",
      "          Validation Loss (standardized): 1.4686517652205962\n",
      "Epoch: 6, Loss (standarized): 0.22295006605358844\n",
      "          Validation Loss (standardized): 1.607778880269709\n",
      "Epoch: 7, Loss (standarized): 0.2188065189007556\n",
      "          Validation Loss (standardized): 1.7208395619133656\n",
      "Epoch: 8, Loss (standarized): 0.2180837996236779\n",
      "          Validation Loss (standardized): 1.8075121843022413\n",
      "Epoch: 9, Loss (standarized): 0.21836660264836558\n",
      "          Validation Loss (standardized): 1.869228040019126\n",
      "Epoch: 10, Loss (standarized): 0.21849431396912095\n",
      "          Validation Loss (standardized): 1.9079675277214385\n",
      "Epoch: 11, Loss (standarized): 0.2180211963655211\n",
      "          Validation Loss (standardized): 1.9261109014313524\n",
      "Epoch: 12, Loss (standarized): 0.21676168289095935\n",
      "          Validation Loss (standardized): 1.9260402902653146\n",
      "Epoch: 13, Loss (standarized): 0.21469449624543543\n",
      "          Validation Loss (standardized): 1.9103747741215336\n",
      "Epoch: 14, Loss (standarized): 0.2120209423157768\n",
      "          Validation Loss (standardized): 1.8818101708977562\n",
      "Epoch: 15, Loss (standarized): 0.20883515626719543\n",
      "          Validation Loss (standardized): 1.8430762749527339\n",
      "Epoch: 16, Loss (standarized): 0.20539336619494367\n",
      "          Validation Loss (standardized): 1.7969905207222927\n",
      "Epoch: 17, Loss (standarized): 0.20207103244623098\n",
      "          Validation Loss (standardized): 1.7471523843468646\n",
      "Epoch: 18, Loss (standarized): 0.19924261508543373\n",
      "          Validation Loss (standardized): 1.6962189744957417\n",
      "Epoch: 19, Loss (standarized): 0.19708786465761388\n",
      "          Validation Loss (standardized): 1.6466245279080263\n",
      "Epoch: 20, Loss (standarized): 0.1956377062192154\n",
      "          Validation Loss (standardized): 1.5999669969723092\n",
      "Final epoch: 20, Final loss (standarized): 0.1956377062192154\n",
      "Epoch: 1, Loss (standarized): 0.6533268543684905\n",
      "          Validation Loss (standardized): 0.8873731038078319\n",
      "Epoch: 2, Loss (standarized): 0.46671317456658645\n",
      "          Validation Loss (standardized): 1.0117639261267701\n",
      "Epoch: 3, Loss (standarized): 0.35505212320976054\n",
      "          Validation Loss (standardized): 1.146604292535685\n",
      "Epoch: 4, Loss (standarized): 0.28804017612458055\n",
      "          Validation Loss (standardized): 1.2792704022889836\n",
      "Epoch: 5, Loss (standarized): 0.24979362108902656\n",
      "          Validation Loss (standardized): 1.4028132246968759\n",
      "Epoch: 6, Loss (standarized): 0.22974628898850388\n",
      "          Validation Loss (standardized): 1.5086758653253514\n",
      "Epoch: 7, Loss (standarized): 0.21990009957101073\n",
      "          Validation Loss (standardized): 1.5927831652095972\n",
      "Epoch: 8, Loss (standarized): 0.21520209609442265\n",
      "          Validation Loss (standardized): 1.6541758042968622\n",
      "Epoch: 9, Loss (standarized): 0.21265186509909978\n",
      "          Validation Loss (standardized): 1.6925871834127826\n",
      "Epoch: 10, Loss (standarized): 0.21054381669413524\n",
      "          Validation Loss (standardized): 1.7097236399036837\n",
      "Epoch: 11, Loss (standarized): 0.20822578521656207\n",
      "          Validation Loss (standardized): 1.7081431537880474\n",
      "Epoch: 12, Loss (standarized): 0.2054405905127168\n",
      "          Validation Loss (standardized): 1.6908734943777717\n",
      "Epoch: 13, Loss (standarized): 0.20231522516014486\n",
      "          Validation Loss (standardized): 1.6610718198680765\n",
      "Epoch: 14, Loss (standarized): 0.19919679045380728\n",
      "          Validation Loss (standardized): 1.622579321725278\n",
      "Epoch: 15, Loss (standarized): 0.19658418426425972\n",
      "          Validation Loss (standardized): 1.579282438233757\n",
      "Epoch: 16, Loss (standarized): 0.19486876879536016\n",
      "          Validation Loss (standardized): 1.5351254576770454\n",
      "Epoch: 17, Loss (standarized): 0.19442552211956426\n",
      "          Validation Loss (standardized): 1.4946655361404115\n",
      "Epoch: 18, Loss (standarized): 0.19522371865224594\n",
      "          Validation Loss (standardized): 1.4613567688573716\n",
      "Epoch: 19, Loss (standarized): 0.19646453785269702\n",
      "          Validation Loss (standardized): 1.4366581366882594\n",
      "Epoch: 20, Loss (standarized): 0.19694688512176786\n",
      "          Validation Loss (standardized): 1.4204069325481032\n",
      "Final epoch: 20, Final loss (standarized): 0.19694688512176786\n",
      "Epoch: 1, Loss (standarized): 0.3713514862357896\n",
      "          Validation Loss (standardized): 0.9665454426296796\n",
      "Epoch: 2, Loss (standarized): 0.2854693862546118\n",
      "          Validation Loss (standardized): 1.1102842467370382\n",
      "Epoch: 3, Loss (standarized): 0.24251256603537355\n",
      "          Validation Loss (standardized): 1.2352291695701352\n",
      "Epoch: 4, Loss (standarized): 0.22120672676888575\n",
      "          Validation Loss (standardized): 1.335206073026297\n",
      "Epoch: 5, Loss (standarized): 0.21015349953530427\n",
      "          Validation Loss (standardized): 1.410673911490017\n",
      "Epoch: 6, Loss (standarized): 0.20396238897927843\n",
      "          Validation Loss (standardized): 1.4634005855825023\n",
      "Epoch: 7, Loss (standarized): 0.19982946538024937\n",
      "          Validation Loss (standardized): 1.4963122597309706\n",
      "Epoch: 8, Loss (standarized): 0.19672996268581416\n",
      "          Validation Loss (standardized): 1.5134823788679375\n",
      "Epoch: 9, Loss (standarized): 0.19410783528215797\n",
      "          Validation Loss (standardized): 1.5172750528460208\n",
      "Epoch: 10, Loss (standarized): 0.19193880105687547\n",
      "          Validation Loss (standardized): 1.510978976730664\n",
      "Epoch: 11, Loss (standarized): 0.19030209274124726\n",
      "          Validation Loss (standardized): 1.4979643158019236\n",
      "Epoch: 12, Loss (standarized): 0.18939317264483116\n",
      "          Validation Loss (standardized): 1.4819590789919905\n",
      "Epoch: 13, Loss (standarized): 0.1890706980097507\n",
      "          Validation Loss (standardized): 1.4658973708287135\n",
      "Epoch: 14, Loss (standarized): 0.18895837790856246\n",
      "          Validation Loss (standardized): 1.4518851330273252\n",
      "Epoch: 15, Loss (standarized): 0.18859997203860204\n",
      "          Validation Loss (standardized): 1.4408615256954045\n",
      "Epoch: 16, Loss (standarized): 0.18774810804264186\n",
      "          Validation Loss (standardized): 1.4333418714211734\n",
      "Epoch: 17, Loss (standarized): 0.18647145520266448\n",
      "          Validation Loss (standardized): 1.4276035274024503\n",
      "Epoch: 18, Loss (standarized): 0.18493914557177635\n",
      "          Validation Loss (standardized): 1.4224522334218066\n",
      "Epoch: 19, Loss (standarized): 0.1832319300316876\n",
      "          Validation Loss (standardized): 1.4168625070915761\n",
      "Epoch: 20, Loss (standarized): 0.18154240010249498\n",
      "          Validation Loss (standardized): 1.4098768024453556\n",
      "Final epoch: 20, Final loss (standarized): 0.18154240010249498\n",
      "Epoch: 1, Loss (standarized): 1.4621258062993256\n",
      "          Validation Loss (standardized): 0.8674538564323213\n",
      "Epoch: 2, Loss (standarized): 1.0114037977905619\n",
      "          Validation Loss (standardized): 0.7960541598876952\n",
      "Epoch: 3, Loss (standarized): 0.671525966186577\n",
      "          Validation Loss (standardized): 0.8227046990344844\n",
      "Epoch: 4, Loss (standarized): 0.4344062560317962\n",
      "          Validation Loss (standardized): 0.9325073100292457\n",
      "Epoch: 5, Loss (standarized): 0.2945637664199875\n",
      "          Validation Loss (standardized): 1.0977354247258833\n",
      "Epoch: 6, Loss (standarized): 0.2319934972802056\n",
      "          Validation Loss (standardized): 1.2839177812460314\n",
      "Epoch: 7, Loss (standarized): 0.20957299231455345\n",
      "          Validation Loss (standardized): 1.4704317552901118\n",
      "Epoch: 8, Loss (standarized): 0.2046153839423792\n",
      "          Validation Loss (standardized): 1.6459329954650457\n",
      "Epoch: 9, Loss (standarized): 0.20726764967660471\n",
      "          Validation Loss (standardized): 1.80475792150865\n",
      "Epoch: 10, Loss (standarized): 0.21302795635667174\n",
      "          Validation Loss (standardized): 1.943517113241262\n",
      "Epoch: 11, Loss (standarized): 0.21986578907041435\n",
      "          Validation Loss (standardized): 2.0605918659312636\n",
      "Epoch: 12, Loss (standarized): 0.2264861685276097\n",
      "          Validation Loss (standardized): 2.155384931914187\n",
      "Epoch: 13, Loss (standarized): 0.23225594551895948\n",
      "          Validation Loss (standardized): 2.228468652868533\n",
      "Epoch: 14, Loss (standarized): 0.23685678641980076\n",
      "          Validation Loss (standardized): 2.2809277860194963\n",
      "Epoch: 15, Loss (standarized): 0.24011414845681683\n",
      "          Validation Loss (standardized): 2.314654030542443\n",
      "Epoch: 16, Loss (standarized): 0.24202987395402176\n",
      "          Validation Loss (standardized): 2.3314008758498077\n",
      "Epoch: 17, Loss (standarized): 0.24270084486051638\n",
      "          Validation Loss (standardized): 2.3331083112828317\n",
      "Epoch: 18, Loss (standarized): 0.24229719811695016\n",
      "          Validation Loss (standardized): 2.3218026333267257\n",
      "Epoch: 19, Loss (standarized): 0.24105298817938337\n",
      "          Validation Loss (standardized): 2.3000013447347007\n",
      "Epoch: 20, Loss (standarized): 0.23916670811755297\n",
      "          Validation Loss (standardized): 2.269584550232238\n",
      "Final epoch: 20, Final loss (standarized): 0.23916670811755297\n",
      "Epoch: 1, Loss (standarized): 1.7165095852333796\n",
      "          Validation Loss (standardized): 1.1721107279631573\n",
      "Epoch: 2, Loss (standarized): 1.4085452066570814\n",
      "          Validation Loss (standardized): 1.1221269772851892\n",
      "Epoch: 3, Loss (standarized): 1.1613928457346185\n",
      "          Validation Loss (standardized): 1.1027009027749375\n",
      "Epoch: 4, Loss (standarized): 0.9627173638853372\n",
      "          Validation Loss (standardized): 1.1051599492919135\n",
      "Epoch: 5, Loss (standarized): 0.8007166047357981\n",
      "          Validation Loss (standardized): 1.1168185621390352\n",
      "Epoch: 6, Loss (standarized): 0.6637482621223336\n",
      "          Validation Loss (standardized): 1.1431064348151307\n",
      "Epoch: 7, Loss (standarized): 0.5472204559211025\n",
      "          Validation Loss (standardized): 1.1836058874188702\n",
      "Epoch: 8, Loss (standarized): 0.45021512223271315\n",
      "          Validation Loss (standardized): 1.2367442390083718\n",
      "Epoch: 9, Loss (standarized): 0.3726992971417494\n",
      "          Validation Loss (standardized): 1.3009294247834786\n",
      "Epoch: 10, Loss (standarized): 0.3141287122792991\n",
      "          Validation Loss (standardized): 1.3739214758671423\n",
      "Epoch: 11, Loss (standarized): 0.2728689424389307\n",
      "          Validation Loss (standardized): 1.4527607995962728\n",
      "Epoch: 12, Loss (standarized): 0.24619779022655502\n",
      "          Validation Loss (standardized): 1.5323791564074472\n",
      "Epoch: 13, Loss (standarized): 0.23038715348127956\n",
      "          Validation Loss (standardized): 1.6083426540417105\n",
      "Epoch: 14, Loss (standarized): 0.22188729115106523\n",
      "          Validation Loss (standardized): 1.6772871337306317\n",
      "Epoch: 15, Loss (standarized): 0.21801144578907836\n",
      "          Validation Loss (standardized): 1.7389726683994744\n",
      "Epoch: 16, Loss (standarized): 0.2170069659176378\n",
      "          Validation Loss (standardized): 1.7915020587587822\n",
      "Epoch: 17, Loss (standarized): 0.2174616775169308\n",
      "          Validation Loss (standardized): 1.8338051200485455\n",
      "Epoch: 18, Loss (standarized): 0.21842056868378248\n",
      "          Validation Loss (standardized): 1.8655578769756413\n",
      "Epoch: 19, Loss (standarized): 0.21932275854307176\n",
      "          Validation Loss (standardized): 1.886652061482115\n",
      "Epoch: 20, Loss (standarized): 0.21986756139156557\n",
      "          Validation Loss (standardized): 1.8973985162426705\n",
      "Final epoch: 20, Final loss (standarized): 0.21986756139156557\n",
      "Epoch: 1, Loss (standarized): 1.2317948143404793\n",
      "          Validation Loss (standardized): 0.7614288659903445\n",
      "Epoch: 2, Loss (standarized): 0.8654363741700145\n",
      "          Validation Loss (standardized): 0.7230811401895815\n",
      "Epoch: 3, Loss (standarized): 0.595383013994436\n",
      "          Validation Loss (standardized): 0.7588804322536069\n",
      "Epoch: 4, Loss (standarized): 0.41574638191555974\n",
      "          Validation Loss (standardized): 0.8506844152439456\n",
      "Epoch: 5, Loss (standarized): 0.3080782025637037\n",
      "          Validation Loss (standardized): 0.9779566355076283\n",
      "Epoch: 6, Loss (standarized): 0.24917598884926578\n",
      "          Validation Loss (standardized): 1.1203616173324773\n",
      "Epoch: 7, Loss (standarized): 0.21921505746215578\n",
      "          Validation Loss (standardized): 1.264838434417581\n",
      "Epoch: 8, Loss (standarized): 0.2053934231189448\n",
      "          Validation Loss (standardized): 1.403830247260002\n",
      "Epoch: 9, Loss (standarized): 0.2002030677204771\n",
      "          Validation Loss (standardized): 1.5325262394143087\n",
      "Epoch: 10, Loss (standarized): 0.19956647246851786\n",
      "          Validation Loss (standardized): 1.648169468126282\n",
      "Epoch: 11, Loss (standarized): 0.201298156078052\n",
      "          Validation Loss (standardized): 1.7493467790738402\n",
      "Epoch: 12, Loss (standarized): 0.2041021659852375\n",
      "          Validation Loss (standardized): 1.83542335727536\n",
      "Epoch: 13, Loss (standarized): 0.20723022996785392\n",
      "          Validation Loss (standardized): 1.9062647145370493\n",
      "Epoch: 14, Loss (standarized): 0.21018824327686267\n",
      "          Validation Loss (standardized): 1.9620320013010297\n",
      "Epoch: 15, Loss (standarized): 0.2127238414921976\n",
      "          Validation Loss (standardized): 2.0032993663221568\n",
      "Epoch: 16, Loss (standarized): 0.21465419220445497\n",
      "          Validation Loss (standardized): 2.0308884140308567\n",
      "Epoch: 17, Loss (standarized): 0.21593827886778222\n",
      "          Validation Loss (standardized): 2.0458538041940137\n",
      "Epoch: 18, Loss (standarized): 0.2165326942081155\n",
      "          Validation Loss (standardized): 2.0492535423772154\n",
      "Epoch: 19, Loss (standarized): 0.2164692180368944\n",
      "          Validation Loss (standardized): 2.042327465738394\n",
      "Epoch: 20, Loss (standarized): 0.21580752723999977\n",
      "          Validation Loss (standardized): 2.026347498094468\n",
      "Final epoch: 20, Final loss (standarized): 0.21580752723999977\n",
      "Epoch: 1, Loss (standarized): 0.8645380088676847\n",
      "          Validation Loss (standardized): 0.7888151009262472\n",
      "Epoch: 2, Loss (standarized): 0.543252658165224\n",
      "          Validation Loss (standardized): 0.8719186173845935\n",
      "Epoch: 3, Loss (standarized): 0.35708122302734563\n",
      "          Validation Loss (standardized): 1.0288688751039061\n",
      "Epoch: 4, Loss (standarized): 0.2698055353795569\n",
      "          Validation Loss (standardized): 1.2138040811601756\n",
      "Epoch: 5, Loss (standarized): 0.2348036213293999\n",
      "          Validation Loss (standardized): 1.3998684809153001\n",
      "Epoch: 6, Loss (standarized): 0.22403299783411085\n",
      "          Validation Loss (standardized): 1.57283058489189\n",
      "Epoch: 7, Loss (standarized): 0.22385052101414793\n",
      "          Validation Loss (standardized): 1.7254101991469468\n",
      "Epoch: 8, Loss (standarized): 0.22791399495294673\n",
      "          Validation Loss (standardized): 1.8538602691497197\n",
      "Epoch: 9, Loss (standarized): 0.23313894063674553\n",
      "          Validation Loss (standardized): 1.9568990699438575\n",
      "Epoch: 10, Loss (standarized): 0.23801055031749652\n",
      "          Validation Loss (standardized): 2.0348068106242683\n",
      "Epoch: 11, Loss (standarized): 0.24176181527085885\n",
      "          Validation Loss (standardized): 2.088776083002282\n",
      "Epoch: 12, Loss (standarized): 0.2440633221559821\n",
      "          Validation Loss (standardized): 2.120770644292646\n",
      "Epoch: 13, Loss (standarized): 0.24487140303705485\n",
      "          Validation Loss (standardized): 2.1329988365717596\n",
      "Epoch: 14, Loss (standarized): 0.24425625656342936\n",
      "          Validation Loss (standardized): 2.127920414950529\n",
      "Epoch: 15, Loss (standarized): 0.24235542390789294\n",
      "          Validation Loss (standardized): 2.1081687850516446\n",
      "Epoch: 16, Loss (standarized): 0.23938972256417557\n",
      "          Validation Loss (standardized): 2.076073239234449\n",
      "Epoch: 17, Loss (standarized): 0.2355665892317596\n",
      "          Validation Loss (standardized): 2.0336548934924368\n",
      "Epoch: 18, Loss (standarized): 0.2311857029405138\n",
      "          Validation Loss (standardized): 1.9831944399486576\n",
      "Epoch: 19, Loss (standarized): 0.22643260292128778\n",
      "          Validation Loss (standardized): 1.926662965094314\n",
      "Epoch: 20, Loss (standarized): 0.22142929207714382\n",
      "          Validation Loss (standardized): 1.865836082760528\n",
      "Final epoch: 20, Final loss (standarized): 0.22142929207714382\n",
      "Epoch: 1, Loss (standarized): 0.4370332794450799\n",
      "          Validation Loss (standardized): 1.0458102901112187\n",
      "Epoch: 2, Loss (standarized): 0.36197682083092625\n",
      "          Validation Loss (standardized): 1.1986755179403379\n",
      "Epoch: 3, Loss (standarized): 0.30218970753153007\n",
      "          Validation Loss (standardized): 1.375326318538164\n",
      "Epoch: 4, Loss (standarized): 0.26154245683501987\n",
      "          Validation Loss (standardized): 1.5591867128286203\n",
      "Epoch: 5, Loss (standarized): 0.23792104619254442\n",
      "          Validation Loss (standardized): 1.737616783199452\n",
      "Epoch: 6, Loss (standarized): 0.22738734319556794\n",
      "          Validation Loss (standardized): 1.892727634143466\n",
      "Epoch: 7, Loss (standarized): 0.22484233104231532\n",
      "          Validation Loss (standardized): 2.0117564410089988\n",
      "Epoch: 8, Loss (standarized): 0.22590891535763438\n",
      "          Validation Loss (standardized): 2.0914866605048803\n",
      "Epoch: 9, Loss (standarized): 0.22766336483273672\n",
      "          Validation Loss (standardized): 2.131017184791421\n",
      "Epoch: 10, Loss (standarized): 0.22861349513331167\n",
      "          Validation Loss (standardized): 2.1276274598906975\n",
      "Epoch: 11, Loss (standarized): 0.2271232487592269\n",
      "          Validation Loss (standardized): 2.090016429272126\n",
      "Epoch: 12, Loss (standarized): 0.22352210111116588\n",
      "          Validation Loss (standardized): 2.0270487342182846\n",
      "Epoch: 13, Loss (standarized): 0.21848780207015306\n",
      "          Validation Loss (standardized): 1.947010077807127\n",
      "Epoch: 14, Loss (standarized): 0.21269630131959755\n",
      "          Validation Loss (standardized): 1.8559665425384921\n",
      "Epoch: 15, Loss (standarized): 0.20667722753147527\n",
      "          Validation Loss (standardized): 1.7590615394495563\n",
      "Epoch: 16, Loss (standarized): 0.2009366634135699\n",
      "          Validation Loss (standardized): 1.6611815659390659\n",
      "Epoch: 17, Loss (standarized): 0.1957148780642341\n",
      "          Validation Loss (standardized): 1.5661503005624582\n",
      "Epoch: 18, Loss (standarized): 0.1913008771616588\n",
      "          Validation Loss (standardized): 1.476710560604423\n",
      "Epoch: 19, Loss (standarized): 0.1878541615687029\n",
      "          Validation Loss (standardized): 1.3954009790491846\n",
      "Epoch: 20, Loss (standarized): 0.18556636671684393\n",
      "          Validation Loss (standardized): 1.324334157872408\n",
      "Final epoch: 20, Final loss (standarized): 0.18556636671684393\n",
      "Epoch: 1, Loss (standarized): 0.6638267017190721\n",
      "          Validation Loss (standardized): 1.0631534901996433\n",
      "Epoch: 2, Loss (standarized): 0.41852416389980396\n",
      "          Validation Loss (standardized): 1.2168525024925676\n",
      "Epoch: 3, Loss (standarized): 0.30111596554888553\n",
      "          Validation Loss (standardized): 1.3800017740092867\n",
      "Epoch: 4, Loss (standarized): 0.25098457498391613\n",
      "          Validation Loss (standardized): 1.5219337231052714\n",
      "Epoch: 5, Loss (standarized): 0.23017813357449632\n",
      "          Validation Loss (standardized): 1.627794354508148\n",
      "Epoch: 6, Loss (standarized): 0.22127188099359085\n",
      "          Validation Loss (standardized): 1.6945479900073661\n",
      "Epoch: 7, Loss (standarized): 0.2168971515129638\n",
      "          Validation Loss (standardized): 1.7293835507521265\n",
      "Epoch: 8, Loss (standarized): 0.2142426343615469\n",
      "          Validation Loss (standardized): 1.7415567334959579\n",
      "Epoch: 9, Loss (standarized): 0.2125741458696374\n",
      "          Validation Loss (standardized): 1.7417144650912144\n",
      "Epoch: 10, Loss (standarized): 0.21218958693694726\n",
      "          Validation Loss (standardized): 1.7384737545123403\n",
      "Epoch: 11, Loss (standarized): 0.21309018262863322\n",
      "          Validation Loss (standardized): 1.7428188757858083\n",
      "Epoch: 12, Loss (standarized): 0.21438270576944016\n",
      "          Validation Loss (standardized): 1.7624912886733188\n",
      "Epoch: 13, Loss (standarized): 0.21481056458513043\n",
      "          Validation Loss (standardized): 1.7932378890769092\n",
      "Epoch: 14, Loss (standarized): 0.21379791452001443\n",
      "          Validation Loss (standardized): 1.828943210255995\n",
      "Epoch: 15, Loss (standarized): 0.2121817609505674\n",
      "          Validation Loss (standardized): 1.8637770312543211\n",
      "Epoch: 16, Loss (standarized): 0.2108693461427882\n",
      "          Validation Loss (standardized): 1.8917553464852757\n",
      "Epoch: 17, Loss (standarized): 0.20998912143164436\n",
      "          Validation Loss (standardized): 1.9083578622596449\n",
      "Epoch: 18, Loss (standarized): 0.2091713139661376\n",
      "          Validation Loss (standardized): 1.9116503330686756\n",
      "Epoch: 19, Loss (standarized): 0.20805404733343796\n",
      "          Validation Loss (standardized): 1.9006813961171936\n",
      "Epoch: 20, Loss (standarized): 0.20653650334332257\n",
      "          Validation Loss (standardized): 1.8758836250740774\n",
      "Final epoch: 20, Final loss (standarized): 0.20653650334332257\n",
      "Epoch: 1, Loss (standarized): 1.2010321090090024\n",
      "          Validation Loss (standardized): 0.7893835254581782\n",
      "Epoch: 2, Loss (standarized): 0.9725099490597943\n",
      "          Validation Loss (standardized): 0.7366105378152613\n",
      "Epoch: 3, Loss (standarized): 0.7809591880391378\n",
      "          Validation Loss (standardized): 0.7145763960723402\n",
      "Epoch: 4, Loss (standarized): 0.6279516555429405\n",
      "          Validation Loss (standardized): 0.7195371800621301\n",
      "Epoch: 5, Loss (standarized): 0.5033237427260568\n",
      "          Validation Loss (standardized): 0.7511023290783218\n",
      "Epoch: 6, Loss (standarized): 0.4055324426304825\n",
      "          Validation Loss (standardized): 0.8072778737833652\n",
      "Epoch: 7, Loss (standarized): 0.3316002078561457\n",
      "          Validation Loss (standardized): 0.8852009097702088\n",
      "Epoch: 8, Loss (standarized): 0.2781807497342283\n",
      "          Validation Loss (standardized): 0.9812885282995066\n",
      "Epoch: 9, Loss (standarized): 0.2418295768762121\n",
      "          Validation Loss (standardized): 1.0913612455244337\n",
      "Epoch: 10, Loss (standarized): 0.2193799670630326\n",
      "          Validation Loss (standardized): 1.209822990223001\n",
      "Epoch: 11, Loss (standarized): 0.20722942024354557\n",
      "          Validation Loss (standardized): 1.3305201368079738\n",
      "Epoch: 12, Loss (standarized): 0.20206262491415944\n",
      "          Validation Loss (standardized): 1.4479684275302005\n",
      "Epoch: 13, Loss (standarized): 0.2013291789979393\n",
      "          Validation Loss (standardized): 1.5578118047926508\n",
      "Epoch: 14, Loss (standarized): 0.20321386499999713\n",
      "          Validation Loss (standardized): 1.6567581817755466\n",
      "Epoch: 15, Loss (standarized): 0.20642834042750563\n",
      "          Validation Loss (standardized): 1.7416596053911155\n",
      "Epoch: 16, Loss (standarized): 0.21001847960104414\n",
      "          Validation Loss (standardized): 1.8108366769258764\n",
      "Epoch: 17, Loss (standarized): 0.21337041332832976\n",
      "          Validation Loss (standardized): 1.8634203852181497\n",
      "Epoch: 18, Loss (standarized): 0.215985580840518\n",
      "          Validation Loss (standardized): 1.8992650948143064\n",
      "Epoch: 19, Loss (standarized): 0.21766525208469142\n",
      "          Validation Loss (standardized): 1.9191112214583013\n",
      "Epoch: 20, Loss (standarized): 0.2183289630077736\n",
      "          Validation Loss (standardized): 1.9244016585015147\n",
      "Final epoch: 20, Final loss (standarized): 0.2183289630077736\n",
      "Epoch: 1, Loss (standarized): 0.9941799141398951\n",
      "          Validation Loss (standardized): 0.6880442747924831\n",
      "Epoch: 2, Loss (standarized): 0.6934417563632033\n",
      "          Validation Loss (standardized): 0.6684685625833492\n",
      "Epoch: 3, Loss (standarized): 0.4828179209699236\n",
      "          Validation Loss (standardized): 0.7168035567858886\n",
      "Epoch: 4, Loss (standarized): 0.3481456408396598\n",
      "          Validation Loss (standardized): 0.8151025910810629\n",
      "Epoch: 5, Loss (standarized): 0.2680138123719638\n",
      "          Validation Loss (standardized): 0.9492101890908902\n",
      "Epoch: 6, Loss (standarized): 0.22526523987746339\n",
      "          Validation Loss (standardized): 1.1021415395576826\n",
      "Epoch: 7, Loss (standarized): 0.20529885716107127\n",
      "          Validation Loss (standardized): 1.2628939364132599\n",
      "Epoch: 8, Loss (standarized): 0.19862299967319158\n",
      "          Validation Loss (standardized): 1.4207922348022453\n",
      "Epoch: 9, Loss (standarized): 0.19900158133455934\n",
      "          Validation Loss (standardized): 1.5682199511496915\n",
      "Epoch: 10, Loss (standarized): 0.20293180811666198\n",
      "          Validation Loss (standardized): 1.698684739555011\n",
      "Epoch: 11, Loss (standarized): 0.20818855470839184\n",
      "          Validation Loss (standardized): 1.808307412669208\n",
      "Epoch: 12, Loss (standarized): 0.21346440484020918\n",
      "          Validation Loss (standardized): 1.8953899057727346\n",
      "Epoch: 13, Loss (standarized): 0.21807551908269748\n",
      "          Validation Loss (standardized): 1.9602298282966677\n",
      "Epoch: 14, Loss (standarized): 0.22161945427590407\n",
      "          Validation Loss (standardized): 2.0039518998330785\n",
      "Epoch: 15, Loss (standarized): 0.22399644608606847\n",
      "          Validation Loss (standardized): 2.028543590071107\n",
      "Epoch: 16, Loss (standarized): 0.22522056508446245\n",
      "          Validation Loss (standardized): 2.036478980610706\n",
      "Epoch: 17, Loss (standarized): 0.22544155137109878\n",
      "          Validation Loss (standardized): 2.0302008623798242\n",
      "Epoch: 18, Loss (standarized): 0.2247353202774452\n",
      "          Validation Loss (standardized): 2.0121413930482497\n",
      "Epoch: 19, Loss (standarized): 0.22325545087861803\n",
      "          Validation Loss (standardized): 1.9846294103998117\n",
      "Epoch: 20, Loss (standarized): 0.22117482900800803\n",
      "          Validation Loss (standardized): 1.949649159178111\n",
      "Final epoch: 20, Final loss (standarized): 0.22117482900800803\n",
      "Epoch: 1, Loss (standarized): 0.8762161627917053\n",
      "          Validation Loss (standardized): 1.085869810385629\n",
      "Epoch: 2, Loss (standarized): 0.6342199426599442\n",
      "          Validation Loss (standardized): 1.2008072608216636\n",
      "Epoch: 3, Loss (standarized): 0.45860278059333387\n",
      "          Validation Loss (standardized): 1.3356449913044741\n",
      "Epoch: 4, Loss (standarized): 0.34034786966180414\n",
      "          Validation Loss (standardized): 1.4775466667542896\n",
      "Epoch: 5, Loss (standarized): 0.2693416466736937\n",
      "          Validation Loss (standardized): 1.6165766925162512\n",
      "Epoch: 6, Loss (standarized): 0.23354436308306672\n",
      "          Validation Loss (standardized): 1.7406500545215198\n",
      "Epoch: 7, Loss (standarized): 0.21894371102407137\n",
      "          Validation Loss (standardized): 1.8399845508913897\n",
      "Epoch: 8, Loss (standarized): 0.21477254723740336\n",
      "          Validation Loss (standardized): 1.909816460144217\n",
      "Epoch: 9, Loss (standarized): 0.21471861277603305\n",
      "          Validation Loss (standardized): 1.9486889410387906\n",
      "Epoch: 10, Loss (standarized): 0.21567027724917814\n",
      "          Validation Loss (standardized): 1.9585695723691554\n",
      "Epoch: 11, Loss (standarized): 0.2162909106726594\n",
      "          Validation Loss (standardized): 1.9423265841653774\n",
      "Epoch: 12, Loss (standarized): 0.21600796274088954\n",
      "          Validation Loss (standardized): 1.9032124142402005\n",
      "Epoch: 13, Loss (standarized): 0.21463637685578743\n",
      "          Validation Loss (standardized): 1.8446463760462257\n",
      "Epoch: 14, Loss (standarized): 0.21234100264562183\n",
      "          Validation Loss (standardized): 1.7702993466250245\n",
      "Epoch: 15, Loss (standarized): 0.20951778350866979\n",
      "          Validation Loss (standardized): 1.684580927584409\n",
      "Epoch: 16, Loss (standarized): 0.20687836404460255\n",
      "          Validation Loss (standardized): 1.593518401804742\n",
      "Epoch: 17, Loss (standarized): 0.20526224137185667\n",
      "          Validation Loss (standardized): 1.5068181085812027\n",
      "Epoch: 18, Loss (standarized): 0.2059800045706332\n",
      "          Validation Loss (standardized): 1.440413313265803\n",
      "Epoch: 19, Loss (standarized): 0.20903437423108753\n",
      "          Validation Loss (standardized): 1.4074643258365194\n",
      "Epoch: 20, Loss (standarized): 0.21082329134854874\n",
      "          Validation Loss (standardized): 1.4051813339575119\n",
      "Final epoch: 20, Final loss (standarized): 0.21082329134854874\n",
      "Epoch: 1, Loss (standarized): 0.8602425109033763\n",
      "          Validation Loss (standardized): 0.7857520787674798\n",
      "Epoch: 2, Loss (standarized): 0.5882200559486687\n",
      "          Validation Loss (standardized): 0.8462352945993655\n",
      "Epoch: 3, Loss (standarized): 0.41582256638038945\n",
      "          Validation Loss (standardized): 0.9556588925997198\n",
      "Epoch: 4, Loss (standarized): 0.31551405922103304\n",
      "          Validation Loss (standardized): 1.0868890921364078\n",
      "Epoch: 5, Loss (standarized): 0.2600801022168297\n",
      "          Validation Loss (standardized): 1.2200974408667435\n",
      "Epoch: 6, Loss (standarized): 0.23086898611398937\n",
      "          Validation Loss (standardized): 1.3459303989767377\n",
      "Epoch: 7, Loss (standarized): 0.21684815553220255\n",
      "          Validation Loss (standardized): 1.4574783699825233\n",
      "Epoch: 8, Loss (standarized): 0.21112566677620798\n",
      "          Validation Loss (standardized): 1.5511303480466077\n",
      "Epoch: 9, Loss (standarized): 0.20956342069637934\n",
      "          Validation Loss (standardized): 1.6262220959172242\n",
      "Epoch: 10, Loss (standarized): 0.20968102115674983\n",
      "          Validation Loss (standardized): 1.6829348263769146\n",
      "Epoch: 11, Loss (standarized): 0.21006266977746477\n",
      "          Validation Loss (standardized): 1.7221862788864823\n",
      "Epoch: 12, Loss (standarized): 0.2101691748543192\n",
      "          Validation Loss (standardized): 1.745181642115455\n",
      "Epoch: 13, Loss (standarized): 0.20977427087401923\n",
      "          Validation Loss (standardized): 1.7536032346495098\n",
      "Epoch: 14, Loss (standarized): 0.2087741043452026\n",
      "          Validation Loss (standardized): 1.7494733716969852\n",
      "Epoch: 15, Loss (standarized): 0.20721255939290065\n",
      "          Validation Loss (standardized): 1.7345745462370643\n",
      "Epoch: 16, Loss (standarized): 0.20517611530669105\n",
      "          Validation Loss (standardized): 1.7108397216955031\n",
      "Epoch: 17, Loss (standarized): 0.20278325893903884\n",
      "          Validation Loss (standardized): 1.6802342156003705\n",
      "Epoch: 18, Loss (standarized): 0.20019912866092804\n",
      "          Validation Loss (standardized): 1.64456197702096\n",
      "Epoch: 19, Loss (standarized): 0.19755448029446443\n",
      "          Validation Loss (standardized): 1.6052374099155395\n",
      "Epoch: 20, Loss (standarized): 0.19499572135936288\n",
      "          Validation Loss (standardized): 1.5639230102892043\n",
      "Final epoch: 20, Final loss (standarized): 0.19499572135936288\n",
      "Epoch: 1, Loss (standarized): 0.6599689324533368\n",
      "          Validation Loss (standardized): 0.7126756588652632\n",
      "Epoch: 2, Loss (standarized): 0.4933194111231396\n",
      "          Validation Loss (standardized): 0.7530960626949073\n",
      "Epoch: 3, Loss (standarized): 0.38306290236491036\n",
      "          Validation Loss (standardized): 0.8181199079162904\n",
      "Epoch: 4, Loss (standarized): 0.3102849264917401\n",
      "          Validation Loss (standardized): 0.8982009323515322\n",
      "Epoch: 5, Loss (standarized): 0.26399798698767085\n",
      "          Validation Loss (standardized): 0.9846860595144216\n",
      "Epoch: 6, Loss (standarized): 0.23559200843995617\n",
      "          Validation Loss (standardized): 1.0707782921466071\n",
      "Epoch: 7, Loss (standarized): 0.2185175593337515\n",
      "          Validation Loss (standardized): 1.1523348751230278\n",
      "Epoch: 8, Loss (standarized): 0.20808389547910322\n",
      "          Validation Loss (standardized): 1.227787924927438\n",
      "Epoch: 9, Loss (standarized): 0.20181976442930658\n",
      "          Validation Loss (standardized): 1.2957578562922243\n",
      "Epoch: 10, Loss (standarized): 0.19813316247154333\n",
      "          Validation Loss (standardized): 1.3553229644758236\n",
      "Epoch: 11, Loss (standarized): 0.19606607738334797\n",
      "          Validation Loss (standardized): 1.4058364572785007\n",
      "Epoch: 12, Loss (standarized): 0.19496435910676918\n",
      "          Validation Loss (standardized): 1.4473330043834585\n",
      "Epoch: 13, Loss (standarized): 0.19438130439720452\n",
      "          Validation Loss (standardized): 1.4799198988332014\n",
      "Epoch: 14, Loss (standarized): 0.19399212982001857\n",
      "          Validation Loss (standardized): 1.5035030562175404\n",
      "Epoch: 15, Loss (standarized): 0.1936617242448564\n",
      "          Validation Loss (standardized): 1.5187713340907234\n",
      "Epoch: 16, Loss (standarized): 0.19324542488647328\n",
      "          Validation Loss (standardized): 1.526249538580056\n",
      "Epoch: 17, Loss (standarized): 0.19269128907309968\n",
      "          Validation Loss (standardized): 1.5270131663655178\n",
      "Epoch: 18, Loss (standarized): 0.19198112129570086\n",
      "          Validation Loss (standardized): 1.521715246573811\n",
      "Epoch: 19, Loss (standarized): 0.19110991844380973\n",
      "          Validation Loss (standardized): 1.5111893054921035\n",
      "Epoch: 20, Loss (standarized): 0.19013240811413057\n",
      "          Validation Loss (standardized): 1.495933156027319\n",
      "Final epoch: 20, Final loss (standarized): 0.19013240811413057\n",
      "Epoch: 1, Loss (standarized): 0.3208405270490695\n",
      "          Validation Loss (standardized): 0.9538549020792436\n",
      "Epoch: 2, Loss (standarized): 0.2570473449382147\n",
      "          Validation Loss (standardized): 1.0928213463427208\n",
      "Epoch: 3, Loss (standarized): 0.2258021035457873\n",
      "          Validation Loss (standardized): 1.2251377208212286\n",
      "Epoch: 4, Loss (standarized): 0.21212200656219354\n",
      "          Validation Loss (standardized): 1.3385885845770276\n",
      "Epoch: 5, Loss (standarized): 0.20666109362329085\n",
      "          Validation Loss (standardized): 1.429510673980609\n",
      "Epoch: 6, Loss (standarized): 0.20485366602377988\n",
      "          Validation Loss (standardized): 1.4973017096084749\n",
      "Epoch: 7, Loss (standarized): 0.204465723415585\n",
      "          Validation Loss (standardized): 1.5438945178012669\n",
      "Epoch: 8, Loss (standarized): 0.20445779463061567\n",
      "          Validation Loss (standardized): 1.5718829226803894\n",
      "Epoch: 9, Loss (standarized): 0.20426832953913493\n",
      "          Validation Loss (standardized): 1.5839478127281925\n",
      "Epoch: 10, Loss (standarized): 0.20371042395989353\n",
      "          Validation Loss (standardized): 1.5831637875852778\n",
      "Epoch: 11, Loss (standarized): 0.202783482377253\n",
      "          Validation Loss (standardized): 1.57182260724427\n",
      "Epoch: 12, Loss (standarized): 0.201563424285861\n",
      "          Validation Loss (standardized): 1.5522623510668245\n",
      "Epoch: 13, Loss (standarized): 0.2001316096253909\n",
      "          Validation Loss (standardized): 1.5266065206971025\n",
      "Epoch: 14, Loss (standarized): 0.19862027453640854\n",
      "          Validation Loss (standardized): 1.4969008620664201\n",
      "Epoch: 15, Loss (standarized): 0.19715868029273942\n",
      "          Validation Loss (standardized): 1.4653507094799931\n",
      "Epoch: 16, Loss (standarized): 0.19582030714297005\n",
      "          Validation Loss (standardized): 1.4331582070753555\n",
      "Epoch: 17, Loss (standarized): 0.19466734254891757\n",
      "          Validation Loss (standardized): 1.401236861381326\n",
      "Epoch: 18, Loss (standarized): 0.1937179750512902\n",
      "          Validation Loss (standardized): 1.3709153567399985\n",
      "Epoch: 19, Loss (standarized): 0.19300587336250158\n",
      "          Validation Loss (standardized): 1.343066872543469\n",
      "Epoch: 20, Loss (standarized): 0.1925169101954927\n",
      "          Validation Loss (standardized): 1.3180203953068306\n",
      "Final epoch: 20, Final loss (standarized): 0.1925169101954927\n",
      "Epoch: 1, Loss (standarized): 0.34812403184790675\n",
      "          Validation Loss (standardized): 0.9479620244779937\n",
      "Epoch: 2, Loss (standarized): 0.2892612370890003\n",
      "          Validation Loss (standardized): 1.0479953625863205\n",
      "Epoch: 3, Loss (standarized): 0.2514414184226719\n",
      "          Validation Loss (standardized): 1.1482558827120979\n",
      "Epoch: 4, Loss (standarized): 0.2284278521818658\n",
      "          Validation Loss (standardized): 1.2413674193902777\n",
      "Epoch: 5, Loss (standarized): 0.21487922014993954\n",
      "          Validation Loss (standardized): 1.3214258943041346\n",
      "Epoch: 6, Loss (standarized): 0.20697687390421993\n",
      "          Validation Loss (standardized): 1.3863416794037782\n",
      "Epoch: 7, Loss (standarized): 0.20229398281001895\n",
      "          Validation Loss (standardized): 1.435720176220397\n",
      "Epoch: 8, Loss (standarized): 0.19943438414025408\n",
      "          Validation Loss (standardized): 1.4705315661433287\n",
      "Epoch: 9, Loss (standarized): 0.19757457302298934\n",
      "          Validation Loss (standardized): 1.492017213005243\n",
      "Epoch: 10, Loss (standarized): 0.1961628337332079\n",
      "          Validation Loss (standardized): 1.5001099551557386\n",
      "Epoch: 11, Loss (standarized): 0.1948501845366894\n",
      "          Validation Loss (standardized): 1.4959459496378502\n",
      "Epoch: 12, Loss (standarized): 0.1935424804369387\n",
      "          Validation Loss (standardized): 1.482116255827605\n",
      "Epoch: 13, Loss (standarized): 0.19221362657502605\n",
      "          Validation Loss (standardized): 1.4603241917194607\n",
      "Epoch: 14, Loss (standarized): 0.1908853956548432\n",
      "          Validation Loss (standardized): 1.4329189995318012\n",
      "Epoch: 15, Loss (standarized): 0.1896483925841544\n",
      "          Validation Loss (standardized): 1.4018826593591682\n",
      "Epoch: 16, Loss (standarized): 0.18858898780676542\n",
      "          Validation Loss (standardized): 1.3695484249380434\n",
      "Epoch: 17, Loss (standarized): 0.18780820067413762\n",
      "          Validation Loss (standardized): 1.3380645337774302\n",
      "Epoch: 18, Loss (standarized): 0.1873603434648229\n",
      "          Validation Loss (standardized): 1.3091597806723398\n",
      "Epoch: 19, Loss (standarized): 0.1871850842232046\n",
      "          Validation Loss (standardized): 1.283302301048203\n",
      "Epoch: 20, Loss (standarized): 0.1872064498153991\n",
      "          Validation Loss (standardized): 1.2618529088004538\n",
      "Final epoch: 20, Final loss (standarized): 0.1872064498153991\n",
      "Epoch: 1, Loss (standarized): 0.6415286173248054\n",
      "          Validation Loss (standardized): 0.7463623325645109\n",
      "Epoch: 2, Loss (standarized): 0.4729417082244589\n",
      "          Validation Loss (standardized): 0.8162926453839583\n",
      "Epoch: 3, Loss (standarized): 0.3740546766149849\n",
      "          Validation Loss (standardized): 0.9140890811414958\n",
      "Epoch: 4, Loss (standarized): 0.3172742990979632\n",
      "          Validation Loss (standardized): 1.023882298920259\n",
      "Epoch: 5, Loss (standarized): 0.28435034476652804\n",
      "          Validation Loss (standardized): 1.1344004511083232\n",
      "Epoch: 6, Loss (standarized): 0.2643331973889286\n",
      "          Validation Loss (standardized): 1.2392354278439057\n",
      "Epoch: 7, Loss (standarized): 0.2517177770374587\n",
      "          Validation Loss (standardized): 1.3345743688809848\n",
      "Epoch: 8, Loss (standarized): 0.24333215617624077\n",
      "          Validation Loss (standardized): 1.41864954595151\n",
      "Epoch: 9, Loss (standarized): 0.2374450543931596\n",
      "          Validation Loss (standardized): 1.490357206469241\n",
      "Epoch: 10, Loss (standarized): 0.2330413677868882\n",
      "          Validation Loss (standardized): 1.549230973077008\n",
      "Epoch: 11, Loss (standarized): 0.22938694850562574\n",
      "          Validation Loss (standardized): 1.5953076849802161\n",
      "Epoch: 12, Loss (standarized): 0.2260024610288067\n",
      "          Validation Loss (standardized): 1.6288546414698775\n",
      "Epoch: 13, Loss (standarized): 0.2226226779637071\n",
      "          Validation Loss (standardized): 1.6508692671430323\n",
      "Epoch: 14, Loss (standarized): 0.21929029766664476\n",
      "          Validation Loss (standardized): 1.662767637100863\n",
      "Epoch: 15, Loss (standarized): 0.21600119964612807\n",
      "          Validation Loss (standardized): 1.666079950981607\n",
      "Epoch: 16, Loss (standarized): 0.2126296879204632\n",
      "          Validation Loss (standardized): 1.6622356402169454\n",
      "Epoch: 17, Loss (standarized): 0.2093200608866509\n",
      "          Validation Loss (standardized): 1.652166305818783\n",
      "Epoch: 18, Loss (standarized): 0.2060017476957092\n",
      "          Validation Loss (standardized): 1.6370981506753453\n",
      "Epoch: 19, Loss (standarized): 0.2027809898147943\n",
      "          Validation Loss (standardized): 1.6183604015289341\n",
      "Epoch: 20, Loss (standarized): 0.1997690017591006\n",
      "          Validation Loss (standardized): 1.596916908940083\n",
      "Final epoch: 20, Final loss (standarized): 0.1997690017591006\n",
      "Epoch: 1, Loss (standarized): 2.534073912847327\n",
      "          Validation Loss (standardized): 1.1584611974840922\n",
      "Epoch: 2, Loss (standarized): 1.8369904864565298\n",
      "          Validation Loss (standardized): 0.8832371454941146\n",
      "Epoch: 3, Loss (standarized): 1.245296109026608\n",
      "          Validation Loss (standardized): 0.7269158708205191\n",
      "Epoch: 4, Loss (standarized): 0.7957580399823497\n",
      "          Validation Loss (standardized): 0.7037133017885749\n",
      "Epoch: 5, Loss (standarized): 0.5194546662302005\n",
      "          Validation Loss (standardized): 0.7712360231818307\n",
      "Epoch: 6, Loss (standarized): 0.3626315564989171\n",
      "          Validation Loss (standardized): 0.891836396235634\n",
      "Epoch: 7, Loss (standarized): 0.2810205805080085\n",
      "          Validation Loss (standardized): 1.0373299862129701\n",
      "Epoch: 8, Loss (standarized): 0.2408377827814263\n",
      "          Validation Loss (standardized): 1.1910305485519175\n",
      "Epoch: 9, Loss (standarized): 0.22275086098639194\n",
      "          Validation Loss (standardized): 1.344346403122542\n",
      "Epoch: 10, Loss (standarized): 0.2166971268609411\n",
      "          Validation Loss (standardized): 1.4895800809981323\n",
      "Epoch: 11, Loss (standarized): 0.21706680501253345\n",
      "          Validation Loss (standardized): 1.622622566774405\n",
      "Epoch: 12, Loss (standarized): 0.22060256943858575\n",
      "          Validation Loss (standardized): 1.7411984431585472\n",
      "Epoch: 13, Loss (standarized): 0.22549674630573996\n",
      "          Validation Loss (standardized): 1.8443935727392817\n",
      "Epoch: 14, Loss (standarized): 0.23068690954376106\n",
      "          Validation Loss (standardized): 1.9318645560454177\n",
      "Epoch: 15, Loss (standarized): 0.23558624038951875\n",
      "          Validation Loss (standardized): 2.00381454907815\n",
      "Epoch: 16, Loss (standarized): 0.23983410536450508\n",
      "          Validation Loss (standardized): 2.0607344655953463\n",
      "Epoch: 17, Loss (standarized): 0.24325479948313264\n",
      "          Validation Loss (standardized): 2.103436385709317\n",
      "Epoch: 18, Loss (standarized): 0.2457580010018159\n",
      "          Validation Loss (standardized): 2.132639743507228\n",
      "Epoch: 19, Loss (standarized): 0.24734509602012894\n",
      "          Validation Loss (standardized): 2.1494073843212447\n",
      "Epoch: 20, Loss (standarized): 0.2480160074407145\n",
      "          Validation Loss (standardized): 2.154870951528358\n",
      "Final epoch: 20, Final loss (standarized): 0.2480160074407145\n",
      "Epoch: 1, Loss (standarized): 1.0382694167574504\n",
      "          Validation Loss (standardized): 1.0338379826457345\n",
      "Epoch: 2, Loss (standarized): 0.7533573835560206\n",
      "          Validation Loss (standardized): 1.1066374503133483\n",
      "Epoch: 3, Loss (standarized): 0.5500509096647951\n",
      "          Validation Loss (standardized): 1.2222437987445631\n",
      "Epoch: 4, Loss (standarized): 0.4066571561712182\n",
      "          Validation Loss (standardized): 1.36736208711642\n",
      "Epoch: 5, Loss (standarized): 0.3157961114693069\n",
      "          Validation Loss (standardized): 1.5238737173103096\n",
      "Epoch: 6, Loss (standarized): 0.26289073975796856\n",
      "          Validation Loss (standardized): 1.6780042624022622\n",
      "Epoch: 7, Loss (standarized): 0.23616045045889458\n",
      "          Validation Loss (standardized): 1.8171087636552112\n",
      "Epoch: 8, Loss (standarized): 0.22521207226955642\n",
      "          Validation Loss (standardized): 1.9328268861592681\n",
      "Epoch: 9, Loss (standarized): 0.22223726362738824\n",
      "          Validation Loss (standardized): 2.022033468549856\n",
      "Epoch: 10, Loss (standarized): 0.2227469555089887\n",
      "          Validation Loss (standardized): 2.0841753933781924\n",
      "Epoch: 11, Loss (standarized): 0.22439777597779548\n",
      "          Validation Loss (standardized): 2.1204296157094764\n",
      "Epoch: 12, Loss (standarized): 0.22596779823033325\n",
      "          Validation Loss (standardized): 2.1334947309720076\n",
      "Epoch: 13, Loss (standarized): 0.22694953837684062\n",
      "          Validation Loss (standardized): 2.1263876144969713\n",
      "Epoch: 14, Loss (standarized): 0.2271217340115303\n",
      "          Validation Loss (standardized): 2.101301327732526\n",
      "Epoch: 15, Loss (standarized): 0.22647167416988426\n",
      "          Validation Loss (standardized): 2.060123756602162\n",
      "Epoch: 16, Loss (standarized): 0.22499928109085707\n",
      "          Validation Loss (standardized): 2.0069899607460884\n",
      "Epoch: 17, Loss (standarized): 0.22288402152010836\n",
      "          Validation Loss (standardized): 1.9451445234926168\n",
      "Epoch: 18, Loss (standarized): 0.2202712896484935\n",
      "          Validation Loss (standardized): 1.8767861568570117\n",
      "Epoch: 19, Loss (standarized): 0.21732222380303626\n",
      "          Validation Loss (standardized): 1.8050625393143949\n",
      "Epoch: 20, Loss (standarized): 0.2142212663326554\n",
      "          Validation Loss (standardized): 1.7323789997423733\n",
      "Final epoch: 20, Final loss (standarized): 0.2142212663326554\n",
      "Epoch: 1, Loss (standarized): 0.4560957246119621\n",
      "          Validation Loss (standardized): 1.3391478928900755\n",
      "Epoch: 2, Loss (standarized): 0.3360573992536722\n",
      "          Validation Loss (standardized): 1.3292533196153289\n",
      "Epoch: 3, Loss (standarized): 0.26292539151521294\n",
      "          Validation Loss (standardized): 1.3370033302863282\n",
      "Epoch: 4, Loss (standarized): 0.22383205174923165\n",
      "          Validation Loss (standardized): 1.3509261793958354\n",
      "Epoch: 5, Loss (standarized): 0.20491982454864957\n",
      "          Validation Loss (standardized): 1.3752750539615837\n",
      "Epoch: 6, Loss (standarized): 0.2006824326667259\n",
      "          Validation Loss (standardized): 1.424551322048581\n",
      "Epoch: 7, Loss (standarized): 0.20380156153606768\n",
      "          Validation Loss (standardized): 1.4964762279341084\n",
      "Epoch: 8, Loss (standarized): 0.2043760391638464\n",
      "          Validation Loss (standardized): 1.57362167283608\n",
      "Epoch: 9, Loss (standarized): 0.2017211190253165\n",
      "          Validation Loss (standardized): 1.6453236568775103\n",
      "Epoch: 10, Loss (standarized): 0.19879213698005954\n",
      "          Validation Loss (standardized): 1.7047450412102751\n",
      "Epoch: 11, Loss (standarized): 0.1972766031775204\n",
      "          Validation Loss (standardized): 1.7467455557991758\n",
      "Epoch: 12, Loss (standarized): 0.19665959325051802\n",
      "          Validation Loss (standardized): 1.7688188884018485\n",
      "Epoch: 13, Loss (standarized): 0.19613810880081897\n",
      "          Validation Loss (standardized): 1.7697925228311384\n",
      "Epoch: 14, Loss (standarized): 0.1950704889475837\n",
      "          Validation Loss (standardized): 1.7526917493204888\n",
      "Epoch: 15, Loss (standarized): 0.19325322250844898\n",
      "          Validation Loss (standardized): 1.720628152132619\n",
      "Epoch: 16, Loss (standarized): 0.19075433581326814\n",
      "          Validation Loss (standardized): 1.6771399429695064\n",
      "Epoch: 17, Loss (standarized): 0.18785210393275353\n",
      "          Validation Loss (standardized): 1.6258721323588008\n",
      "Epoch: 18, Loss (standarized): 0.18480696738027816\n",
      "          Validation Loss (standardized): 1.5709150075626126\n",
      "Epoch: 19, Loss (standarized): 0.1819833522764537\n",
      "          Validation Loss (standardized): 1.5160758133096193\n",
      "Epoch: 20, Loss (standarized): 0.17953143978913927\n",
      "          Validation Loss (standardized): 1.4644973094275906\n",
      "Final epoch: 20, Final loss (standarized): 0.17953143978913927\n",
      "Epoch: 1, Loss (standarized): 0.4124447587018008\n",
      "          Validation Loss (standardized): 0.905038499575594\n",
      "Epoch: 2, Loss (standarized): 0.32333473002806773\n",
      "          Validation Loss (standardized): 1.032591992025241\n",
      "Epoch: 3, Loss (standarized): 0.26751690812504214\n",
      "          Validation Loss (standardized): 1.1825911843835326\n",
      "Epoch: 4, Loss (standarized): 0.2354482765963166\n",
      "          Validation Loss (standardized): 1.341983311975457\n",
      "Epoch: 5, Loss (standarized): 0.21954423916503527\n",
      "          Validation Loss (standardized): 1.495564892967048\n",
      "Epoch: 6, Loss (standarized): 0.21339111447838277\n",
      "          Validation Loss (standardized): 1.638535305525229\n",
      "Epoch: 7, Loss (standarized): 0.2127600062139411\n",
      "          Validation Loss (standardized): 1.7617931659369857\n",
      "Epoch: 8, Loss (standarized): 0.21491320023349877\n",
      "          Validation Loss (standardized): 1.8551103241625508\n",
      "Epoch: 9, Loss (standarized): 0.2174886509121527\n",
      "          Validation Loss (standardized): 1.916478072107858\n",
      "Epoch: 10, Loss (standarized): 0.21911009607352067\n",
      "          Validation Loss (standardized): 1.9479288298489537\n",
      "Epoch: 11, Loss (standarized): 0.2192669478762028\n",
      "          Validation Loss (standardized): 1.9530722310392132\n",
      "Epoch: 12, Loss (standarized): 0.2180261912805178\n",
      "          Validation Loss (standardized): 1.9361174252461228\n",
      "Epoch: 13, Loss (standarized): 0.2155594032329963\n",
      "          Validation Loss (standardized): 1.9010019133351252\n",
      "Epoch: 14, Loss (standarized): 0.2122456902362452\n",
      "          Validation Loss (standardized): 1.8522503462277786\n",
      "Epoch: 15, Loss (standarized): 0.20856181925300066\n",
      "          Validation Loss (standardized): 1.7956104976935792\n",
      "Epoch: 16, Loss (standarized): 0.20494925853025228\n",
      "          Validation Loss (standardized): 1.7364878309996334\n",
      "Epoch: 17, Loss (standarized): 0.20185388761626416\n",
      "          Validation Loss (standardized): 1.6756815920825676\n",
      "Epoch: 18, Loss (standarized): 0.19930002007841202\n",
      "          Validation Loss (standardized): 1.6150224563739577\n",
      "Epoch: 19, Loss (standarized): 0.19713991573295386\n",
      "          Validation Loss (standardized): 1.556780306373839\n",
      "Epoch: 20, Loss (standarized): 0.1952120214329377\n",
      "          Validation Loss (standardized): 1.5047605292104311\n",
      "Final epoch: 20, Final loss (standarized): 0.1952120214329377\n",
      "Epoch: 1, Loss (standarized): 1.6199336855417723\n",
      "          Validation Loss (standardized): 0.8993017180014284\n",
      "Epoch: 2, Loss (standarized): 1.1716208520889375\n",
      "          Validation Loss (standardized): 0.8094243891607309\n",
      "Epoch: 3, Loss (standarized): 0.8058307907039539\n",
      "          Validation Loss (standardized): 0.8000347104254835\n",
      "Epoch: 4, Loss (standarized): 0.5349256541672806\n",
      "          Validation Loss (standardized): 0.8727270493045978\n",
      "Epoch: 5, Loss (standarized): 0.37026260712353587\n",
      "          Validation Loss (standardized): 1.0039799756747048\n",
      "Epoch: 6, Loss (standarized): 0.28773767608440504\n",
      "          Validation Loss (standardized): 1.1609070161160364\n",
      "Epoch: 7, Loss (standarized): 0.2502791154940147\n",
      "          Validation Loss (standardized): 1.3228076200288599\n",
      "Epoch: 8, Loss (standarized): 0.23598916151776433\n",
      "          Validation Loss (standardized): 1.4753636331026132\n",
      "Epoch: 9, Loss (standarized): 0.23243976976079894\n",
      "          Validation Loss (standardized): 1.6119204992018328\n",
      "Epoch: 10, Loss (standarized): 0.23372236002865487\n",
      "          Validation Loss (standardized): 1.7290503593807793\n",
      "Epoch: 11, Loss (standarized): 0.2368731361497421\n",
      "          Validation Loss (standardized): 1.8252294660657884\n",
      "Epoch: 12, Loss (standarized): 0.24021687904184663\n",
      "          Validation Loss (standardized): 1.9008045807206206\n",
      "Epoch: 13, Loss (standarized): 0.2429326455869252\n",
      "          Validation Loss (standardized): 1.9565927483680254\n",
      "Epoch: 14, Loss (standarized): 0.24462123009341868\n",
      "          Validation Loss (standardized): 1.9942418323083604\n",
      "Epoch: 15, Loss (standarized): 0.24526126050082525\n",
      "          Validation Loss (standardized): 2.015395432973157\n",
      "Epoch: 16, Loss (standarized): 0.2448666041561235\n",
      "          Validation Loss (standardized): 2.021656591287915\n",
      "Epoch: 17, Loss (standarized): 0.2434691368432793\n",
      "          Validation Loss (standardized): 2.0147675882110905\n",
      "Epoch: 18, Loss (standarized): 0.24113658864849136\n",
      "          Validation Loss (standardized): 1.9964601216809599\n",
      "Epoch: 19, Loss (standarized): 0.23800217583121874\n",
      "          Validation Loss (standardized): 1.9685101801514795\n",
      "Epoch: 20, Loss (standarized): 0.2342067437617095\n",
      "          Validation Loss (standardized): 1.932854300309512\n",
      "Final epoch: 20, Final loss (standarized): 0.2342067437617095\n",
      "Epoch: 1, Loss (standarized): 1.106157323647373\n",
      "          Validation Loss (standardized): 0.7308760259253174\n",
      "Epoch: 2, Loss (standarized): 0.7000743533119166\n",
      "          Validation Loss (standardized): 0.7437974928957054\n",
      "Epoch: 3, Loss (standarized): 0.4451373999266301\n",
      "          Validation Loss (standardized): 0.8522821872913107\n",
      "Epoch: 4, Loss (standarized): 0.3088456141976771\n",
      "          Validation Loss (standardized): 1.012440448903977\n",
      "Epoch: 5, Loss (standarized): 0.2433282140358507\n",
      "          Validation Loss (standardized): 1.1920964249110246\n",
      "Epoch: 6, Loss (standarized): 0.21557908697085074\n",
      "          Validation Loss (standardized): 1.3722218610616224\n",
      "Epoch: 7, Loss (standarized): 0.20729377183766126\n",
      "          Validation Loss (standardized): 1.5424010805539898\n",
      "Epoch: 8, Loss (standarized): 0.2083091770510218\n",
      "          Validation Loss (standardized): 1.6962679562455876\n",
      "Epoch: 9, Loss (standarized): 0.21327214843337722\n",
      "          Validation Loss (standardized): 1.830156991669635\n",
      "Epoch: 10, Loss (standarized): 0.2195159240303948\n",
      "          Validation Loss (standardized): 1.9430102087534138\n",
      "Epoch: 11, Loss (standarized): 0.22577510856281066\n",
      "          Validation Loss (standardized): 2.035158731382065\n",
      "Epoch: 12, Loss (standarized): 0.2313895960564337\n",
      "          Validation Loss (standardized): 2.1074400068936567\n",
      "Epoch: 13, Loss (standarized): 0.2360089410718481\n",
      "          Validation Loss (standardized): 2.160637577506104\n",
      "Epoch: 14, Loss (standarized): 0.23943433862224045\n",
      "          Validation Loss (standardized): 2.196024963929354\n",
      "Epoch: 15, Loss (standarized): 0.24162243965993913\n",
      "          Validation Loss (standardized): 2.215266625096945\n",
      "Epoch: 16, Loss (standarized): 0.242640972270255\n",
      "          Validation Loss (standardized): 2.2200510136214198\n",
      "Epoch: 17, Loss (standarized): 0.2425804426968885\n",
      "          Validation Loss (standardized): 2.2119508967780632\n",
      "Epoch: 18, Loss (standarized): 0.24155709197853384\n",
      "          Validation Loss (standardized): 2.1927512364231103\n",
      "Epoch: 19, Loss (standarized): 0.2397035974104676\n",
      "          Validation Loss (standardized): 2.163963501905749\n",
      "Epoch: 20, Loss (standarized): 0.23717987319967473\n",
      "          Validation Loss (standardized): 2.127332489365054\n",
      "Final epoch: 20, Final loss (standarized): 0.23717987319967473\n",
      "Epoch: 1, Loss (standarized): 0.822673899089369\n",
      "          Validation Loss (standardized): 1.414424610232914\n",
      "Epoch: 2, Loss (standarized): 0.6041559625251414\n",
      "          Validation Loss (standardized): 1.5651673016499257\n",
      "Epoch: 3, Loss (standarized): 0.4629419847027065\n",
      "          Validation Loss (standardized): 1.6987598967693927\n",
      "Epoch: 4, Loss (standarized): 0.36904731090752074\n",
      "          Validation Loss (standardized): 1.816326342226165\n",
      "Epoch: 5, Loss (standarized): 0.30757406282054\n",
      "          Validation Loss (standardized): 1.9151374697639838\n",
      "Epoch: 6, Loss (standarized): 0.27020483297540954\n",
      "          Validation Loss (standardized): 1.9913901194967556\n",
      "Epoch: 7, Loss (standarized): 0.24960483407138656\n",
      "          Validation Loss (standardized): 2.0418104934290002\n",
      "Epoch: 8, Loss (standarized): 0.2393981630649999\n",
      "          Validation Loss (standardized): 2.0659032517080766\n",
      "Epoch: 9, Loss (standarized): 0.23475861852715757\n",
      "          Validation Loss (standardized): 2.0640522626475275\n",
      "Epoch: 10, Loss (standarized): 0.23268564063866623\n",
      "          Validation Loss (standardized): 2.0391693271806144\n",
      "Epoch: 11, Loss (standarized): 0.23153231791179166\n",
      "          Validation Loss (standardized): 1.9954221761466746\n",
      "Epoch: 12, Loss (standarized): 0.23047317522791494\n",
      "          Validation Loss (standardized): 1.9374439644554775\n",
      "Epoch: 13, Loss (standarized): 0.2294654965772442\n",
      "          Validation Loss (standardized): 1.8713879686526682\n",
      "Epoch: 14, Loss (standarized): 0.22885068995033955\n",
      "          Validation Loss (standardized): 1.8038117786547203\n",
      "Epoch: 15, Loss (standarized): 0.22904468920888518\n",
      "          Validation Loss (standardized): 1.7443474794873821\n",
      "Epoch: 16, Loss (standarized): 0.22976434409968396\n",
      "          Validation Loss (standardized): 1.700438537445781\n",
      "Epoch: 17, Loss (standarized): 0.22962639077683\n",
      "          Validation Loss (standardized): 1.671426025156606\n",
      "Epoch: 18, Loss (standarized): 0.2275317304437213\n",
      "          Validation Loss (standardized): 1.653801559366002\n",
      "Epoch: 19, Loss (standarized): 0.22366057368252823\n",
      "          Validation Loss (standardized): 1.6438038493318528\n",
      "Epoch: 20, Loss (standarized): 0.21883798637995674\n",
      "          Validation Loss (standardized): 1.636917917999272\n",
      "Final epoch: 20, Final loss (standarized): 0.21883798637995674\n",
      "Epoch: 1, Loss (standarized): 1.4694215739409595\n",
      "          Validation Loss (standardized): 0.8380581077875894\n",
      "Epoch: 2, Loss (standarized): 1.05977691927536\n",
      "          Validation Loss (standardized): 0.7258525252628217\n",
      "Epoch: 3, Loss (standarized): 0.7294042741173399\n",
      "          Validation Loss (standardized): 0.6959960578014569\n",
      "Epoch: 4, Loss (standarized): 0.49549218471507966\n",
      "          Validation Loss (standardized): 0.7462872751981559\n",
      "Epoch: 5, Loss (standarized): 0.3563126694599242\n",
      "          Validation Loss (standardized): 0.8495408527679189\n",
      "Epoch: 6, Loss (standarized): 0.28132422302740745\n",
      "          Validation Loss (standardized): 0.9788294170067003\n",
      "Epoch: 7, Loss (standarized): 0.24032880494448672\n",
      "          Validation Loss (standardized): 1.1173503615789455\n",
      "Epoch: 8, Loss (standarized): 0.2183711966891548\n",
      "          Validation Loss (standardized): 1.2560558767447554\n",
      "Epoch: 9, Loss (standarized): 0.20705426405557248\n",
      "          Validation Loss (standardized): 1.390275236890468\n",
      "Epoch: 10, Loss (standarized): 0.20218346553871355\n",
      "          Validation Loss (standardized): 1.5179066956678888\n",
      "Epoch: 11, Loss (standarized): 0.20140562898496184\n",
      "          Validation Loss (standardized): 1.6364537880366827\n",
      "Epoch: 12, Loss (standarized): 0.20321071623037965\n",
      "          Validation Loss (standardized): 1.743754234433729\n",
      "Epoch: 13, Loss (standarized): 0.20637082193658343\n",
      "          Validation Loss (standardized): 1.838215568362578\n",
      "Epoch: 14, Loss (standarized): 0.21009226126778122\n",
      "          Validation Loss (standardized): 1.9183154880334896\n",
      "Epoch: 15, Loss (standarized): 0.21375322990050255\n",
      "          Validation Loss (standardized): 1.9840285366503625\n",
      "Epoch: 16, Loss (standarized): 0.2169084133187705\n",
      "          Validation Loss (standardized): 2.0356407917631922\n",
      "Epoch: 17, Loss (standarized): 0.2193762969505746\n",
      "          Validation Loss (standardized): 2.0739365234134386\n",
      "Epoch: 18, Loss (standarized): 0.221110074764698\n",
      "          Validation Loss (standardized): 2.0998803064469604\n",
      "Epoch: 19, Loss (standarized): 0.22210357284937163\n",
      "          Validation Loss (standardized): 2.114437346409582\n",
      "Epoch: 20, Loss (standarized): 0.2223784356717169\n",
      "          Validation Loss (standardized): 2.1188994324456827\n",
      "Final epoch: 20, Final loss (standarized): 0.2223784356717169\n",
      "Epoch: 1, Loss (standarized): 0.4204715239335419\n",
      "          Validation Loss (standardized): 0.8149336104176448\n",
      "Epoch: 2, Loss (standarized): 0.28833895971694434\n",
      "          Validation Loss (standardized): 1.00529807653436\n",
      "Epoch: 3, Loss (standarized): 0.2295996152033331\n",
      "          Validation Loss (standardized): 1.2015960559014587\n",
      "Epoch: 4, Loss (standarized): 0.20715413349302128\n",
      "          Validation Loss (standardized): 1.3805494118030563\n",
      "Epoch: 5, Loss (standarized): 0.20137591505382602\n",
      "          Validation Loss (standardized): 1.5304007500337589\n",
      "Epoch: 6, Loss (standarized): 0.20232140125097672\n",
      "          Validation Loss (standardized): 1.6484192496556616\n",
      "Epoch: 7, Loss (standarized): 0.20552936694023144\n",
      "          Validation Loss (standardized): 1.7338209936053837\n",
      "Epoch: 8, Loss (standarized): 0.2086048626924582\n",
      "          Validation Loss (standardized): 1.7880809955866743\n",
      "Epoch: 9, Loss (standarized): 0.21053088699582892\n",
      "          Validation Loss (standardized): 1.813983388563859\n",
      "Epoch: 10, Loss (standarized): 0.21091576391722627\n",
      "          Validation Loss (standardized): 1.814872736974213\n",
      "Epoch: 11, Loss (standarized): 0.2097313419392047\n",
      "          Validation Loss (standardized): 1.7947008775004907\n",
      "Epoch: 12, Loss (standarized): 0.20723177808493712\n",
      "          Validation Loss (standardized): 1.7571652347120676\n",
      "Epoch: 13, Loss (standarized): 0.2037832743115543\n",
      "          Validation Loss (standardized): 1.7060991271827464\n",
      "Epoch: 14, Loss (standarized): 0.19972412869307082\n",
      "          Validation Loss (standardized): 1.6454004857713613\n",
      "Epoch: 15, Loss (standarized): 0.19557181670313814\n",
      "          Validation Loss (standardized): 1.5779771508245406\n",
      "Epoch: 16, Loss (standarized): 0.1915060967528307\n",
      "          Validation Loss (standardized): 1.506285149211256\n",
      "Epoch: 17, Loss (standarized): 0.1878054583978472\n",
      "          Validation Loss (standardized): 1.433752817068487\n",
      "Epoch: 18, Loss (standarized): 0.18467253346068785\n",
      "          Validation Loss (standardized): 1.3624020102421763\n",
      "Epoch: 19, Loss (standarized): 0.18224434974559375\n",
      "          Validation Loss (standardized): 1.294393845172482\n",
      "Epoch: 20, Loss (standarized): 0.18080112817714897\n",
      "          Validation Loss (standardized): 1.2328915224652144\n",
      "Final epoch: 20, Final loss (standarized): 0.18080112817714897\n",
      "Epoch: 1, Loss (standarized): 0.3236652619195583\n",
      "          Validation Loss (standardized): 1.1601372831892243\n",
      "Epoch: 2, Loss (standarized): 0.2441954572445449\n",
      "          Validation Loss (standardized): 1.4060889360212272\n",
      "Epoch: 3, Loss (standarized): 0.22035770768772578\n",
      "          Validation Loss (standardized): 1.6305864633485678\n",
      "Epoch: 4, Loss (standarized): 0.2182329704986772\n",
      "          Validation Loss (standardized): 1.8048843375311305\n",
      "Epoch: 5, Loss (standarized): 0.22242222796576064\n",
      "          Validation Loss (standardized): 1.9235554601963478\n",
      "Epoch: 6, Loss (standarized): 0.22678760928559988\n",
      "          Validation Loss (standardized): 1.990195940246764\n",
      "Epoch: 7, Loss (standarized): 0.22919938347047983\n",
      "          Validation Loss (standardized): 2.011518261936224\n",
      "Epoch: 8, Loss (standarized): 0.2291761816777541\n",
      "          Validation Loss (standardized): 1.9950863400509593\n",
      "Epoch: 9, Loss (standarized): 0.22693505695852212\n",
      "          Validation Loss (standardized): 1.9485391219291903\n",
      "Epoch: 10, Loss (standarized): 0.22298765636630424\n",
      "          Validation Loss (standardized): 1.8789061313714341\n",
      "Epoch: 11, Loss (standarized): 0.2179470910080562\n",
      "          Validation Loss (standardized): 1.7930893124042344\n",
      "Epoch: 12, Loss (standarized): 0.21249078127569332\n",
      "          Validation Loss (standardized): 1.6972706536522815\n",
      "Epoch: 13, Loss (standarized): 0.20722576314504923\n",
      "          Validation Loss (standardized): 1.5971237262547273\n",
      "Epoch: 14, Loss (standarized): 0.20265155232252072\n",
      "          Validation Loss (standardized): 1.4983160084338425\n",
      "Epoch: 15, Loss (standarized): 0.19922052257191503\n",
      "          Validation Loss (standardized): 1.4060931677442594\n",
      "Epoch: 16, Loss (standarized): 0.19714413366467648\n",
      "          Validation Loss (standardized): 1.3257436783446785\n",
      "Epoch: 17, Loss (standarized): 0.19618227846486427\n",
      "          Validation Loss (standardized): 1.2615394547617955\n",
      "Epoch: 18, Loss (standarized): 0.19578140362680987\n",
      "          Validation Loss (standardized): 1.2160231002665307\n",
      "Epoch: 19, Loss (standarized): 0.19516706473096634\n",
      "          Validation Loss (standardized): 1.1893713695580994\n",
      "Epoch: 20, Loss (standarized): 0.19374628050800122\n",
      "          Validation Loss (standardized): 1.1801414231075809\n",
      "Final epoch: 20, Final loss (standarized): 0.19374628050800122\n",
      "Epoch: 1, Loss (standarized): 1.3031949434031243\n",
      "          Validation Loss (standardized): 0.7911853128072909\n",
      "Epoch: 2, Loss (standarized): 0.8234299333121579\n",
      "          Validation Loss (standardized): 0.7505234823077416\n",
      "Epoch: 3, Loss (standarized): 0.4909859322338885\n",
      "          Validation Loss (standardized): 0.8332651205204833\n",
      "Epoch: 4, Loss (standarized): 0.3126866248399245\n",
      "          Validation Loss (standardized): 0.9975445351779735\n",
      "Epoch: 5, Loss (standarized): 0.24090540776707403\n",
      "          Validation Loss (standardized): 1.187063805000444\n",
      "Epoch: 6, Loss (standarized): 0.21880969811745887\n",
      "          Validation Loss (standardized): 1.3748082405040385\n",
      "Epoch: 7, Loss (standarized): 0.21655184004286818\n",
      "          Validation Loss (standardized): 1.54742683429456\n",
      "Epoch: 8, Loss (standarized): 0.22170435505127076\n",
      "          Validation Loss (standardized): 1.7000439450581581\n",
      "Epoch: 9, Loss (standarized): 0.2293541883838449\n",
      "          Validation Loss (standardized): 1.8313971597950078\n",
      "Epoch: 10, Loss (standarized): 0.2372367515993527\n",
      "          Validation Loss (standardized): 1.940876788850957\n",
      "Epoch: 11, Loss (standarized): 0.24422620587743343\n",
      "          Validation Loss (standardized): 2.0288949138755386\n",
      "Epoch: 12, Loss (standarized): 0.24988399619599477\n",
      "          Validation Loss (standardized): 2.096985930879993\n",
      "Epoch: 13, Loss (standarized): 0.25409152237213684\n",
      "          Validation Loss (standardized): 2.146737691581242\n",
      "Epoch: 14, Loss (standarized): 0.2568476806032141\n",
      "          Validation Loss (standardized): 2.1799116306302766\n",
      "Epoch: 15, Loss (standarized): 0.2582108343298517\n",
      "          Validation Loss (standardized): 2.198067157539906\n",
      "Epoch: 16, Loss (standarized): 0.25830327351093835\n",
      "          Validation Loss (standardized): 2.2030149405083077\n",
      "Epoch: 17, Loss (standarized): 0.2572621247355361\n",
      "          Validation Loss (standardized): 2.196449100707826\n",
      "Epoch: 18, Loss (standarized): 0.2552737264932976\n",
      "          Validation Loss (standardized): 2.1801597074207226\n",
      "Epoch: 19, Loss (standarized): 0.25249708013043276\n",
      "          Validation Loss (standardized): 2.155739681136323\n",
      "Epoch: 20, Loss (standarized): 0.2490878355377421\n",
      "          Validation Loss (standardized): 2.124955016975455\n",
      "Final epoch: 20, Final loss (standarized): 0.2490878355377421\n",
      "Epoch: 1, Loss (standarized): 0.7130004387963761\n",
      "          Validation Loss (standardized): 0.8675550032134197\n",
      "Epoch: 2, Loss (standarized): 0.5512955883052113\n",
      "          Validation Loss (standardized): 0.9160774864362051\n",
      "Epoch: 3, Loss (standarized): 0.42709074441915446\n",
      "          Validation Loss (standardized): 0.9865415736142726\n",
      "Epoch: 4, Loss (standarized): 0.33535916841384095\n",
      "          Validation Loss (standardized): 1.0747663398726608\n",
      "Epoch: 5, Loss (standarized): 0.2734869972263845\n",
      "          Validation Loss (standardized): 1.172027208310284\n",
      "Epoch: 6, Loss (standarized): 0.23490149309685374\n",
      "          Validation Loss (standardized): 1.2710527820156157\n",
      "Epoch: 7, Loss (standarized): 0.21240787596837934\n",
      "          Validation Loss (standardized): 1.3664976263329995\n",
      "Epoch: 8, Loss (standarized): 0.20106952465428413\n",
      "          Validation Loss (standardized): 1.4540125711380358\n",
      "Epoch: 9, Loss (standarized): 0.1962438836101832\n",
      "          Validation Loss (standardized): 1.528507984521406\n",
      "Epoch: 10, Loss (standarized): 0.19504699802881686\n",
      "          Validation Loss (standardized): 1.586540363348147\n",
      "Epoch: 11, Loss (standarized): 0.19538931488503614\n",
      "          Validation Loss (standardized): 1.628897377252848\n",
      "Epoch: 12, Loss (standarized): 0.19626344013687322\n",
      "          Validation Loss (standardized): 1.6568337260100174\n",
      "Epoch: 13, Loss (standarized): 0.197087557030727\n",
      "          Validation Loss (standardized): 1.6715278508363398\n",
      "Epoch: 14, Loss (standarized): 0.19760294721049468\n",
      "          Validation Loss (standardized): 1.6747360860202611\n",
      "Epoch: 15, Loss (standarized): 0.1977233654842522\n",
      "          Validation Loss (standardized): 1.668168662188662\n",
      "Epoch: 16, Loss (standarized): 0.19745938858634712\n",
      "          Validation Loss (standardized): 1.6534966146658427\n",
      "Epoch: 17, Loss (standarized): 0.19686233039780804\n",
      "          Validation Loss (standardized): 1.632344125040261\n",
      "Epoch: 18, Loss (standarized): 0.19599300049109297\n",
      "          Validation Loss (standardized): 1.606119066677968\n",
      "Epoch: 19, Loss (standarized): 0.19492088848274805\n",
      "          Validation Loss (standardized): 1.576363322313792\n",
      "Epoch: 20, Loss (standarized): 0.19377094054018357\n",
      "          Validation Loss (standardized): 1.5443966730246745\n",
      "Final epoch: 20, Final loss (standarized): 0.19377094054018357\n",
      "Epoch: 1, Loss (standarized): 0.8513399834950593\n",
      "          Validation Loss (standardized): 0.8640276837217445\n",
      "Epoch: 2, Loss (standarized): 0.509838040916608\n",
      "          Validation Loss (standardized): 0.9852329381901674\n",
      "Epoch: 3, Loss (standarized): 0.31829918300822746\n",
      "          Validation Loss (standardized): 1.1683115059063105\n",
      "Epoch: 4, Loss (standarized): 0.2383220646854855\n",
      "          Validation Loss (standardized): 1.3581384741546925\n",
      "Epoch: 5, Loss (standarized): 0.21403863840667786\n",
      "          Validation Loss (standardized): 1.5271122902136627\n",
      "Epoch: 6, Loss (standarized): 0.21080410903140243\n",
      "          Validation Loss (standardized): 1.6663978954913654\n",
      "Epoch: 7, Loss (standarized): 0.21447947356611563\n",
      "          Validation Loss (standardized): 1.7745963843665935\n",
      "Epoch: 8, Loss (standarized): 0.21972955709827818\n",
      "          Validation Loss (standardized): 1.853484393601982\n",
      "Epoch: 9, Loss (standarized): 0.2245307234077085\n",
      "          Validation Loss (standardized): 1.9064184618524485\n",
      "Epoch: 10, Loss (standarized): 0.22809797043963298\n",
      "          Validation Loss (standardized): 1.9366884423300734\n",
      "Epoch: 11, Loss (standarized): 0.23026325340220485\n",
      "          Validation Loss (standardized): 1.9476153347301295\n",
      "Epoch: 12, Loss (standarized): 0.23104920917111307\n",
      "          Validation Loss (standardized): 1.9420399377883046\n",
      "Epoch: 13, Loss (standarized): 0.2305921812819858\n",
      "          Validation Loss (standardized): 1.9225449068729012\n",
      "Epoch: 14, Loss (standarized): 0.22906948566241814\n",
      "          Validation Loss (standardized): 1.8912229283422262\n",
      "Epoch: 15, Loss (standarized): 0.22665328355637013\n",
      "          Validation Loss (standardized): 1.850627651940747\n",
      "Epoch: 16, Loss (standarized): 0.22359639752771104\n",
      "          Validation Loss (standardized): 1.8028543178517455\n",
      "Epoch: 17, Loss (standarized): 0.22010514942484183\n",
      "          Validation Loss (standardized): 1.7499990115640924\n",
      "Epoch: 18, Loss (standarized): 0.21638348334689456\n",
      "          Validation Loss (standardized): 1.6936428479938417\n",
      "Epoch: 19, Loss (standarized): 0.2126140177404544\n",
      "          Validation Loss (standardized): 1.6354167280553755\n",
      "Epoch: 20, Loss (standarized): 0.20903286958894274\n",
      "          Validation Loss (standardized): 1.5766435217136054\n",
      "Final epoch: 20, Final loss (standarized): 0.20903286958894274\n",
      "Epoch: 1, Loss (standarized): 0.2562877278768924\n",
      "          Validation Loss (standardized): 1.028822805030269\n",
      "Epoch: 2, Loss (standarized): 0.22553872623039356\n",
      "          Validation Loss (standardized): 1.1571889322707154\n",
      "Epoch: 3, Loss (standarized): 0.21132231861004366\n",
      "          Validation Loss (standardized): 1.2613747123947434\n",
      "Epoch: 4, Loss (standarized): 0.20505444668507736\n",
      "          Validation Loss (standardized): 1.3346553616558572\n",
      "Epoch: 5, Loss (standarized): 0.20207399061502407\n",
      "          Validation Loss (standardized): 1.380228609962566\n",
      "Epoch: 6, Loss (standarized): 0.20005287335817454\n",
      "          Validation Loss (standardized): 1.4029153703911965\n",
      "Epoch: 7, Loss (standarized): 0.19817591483975996\n",
      "          Validation Loss (standardized): 1.4088970836436547\n",
      "Epoch: 8, Loss (standarized): 0.19631774940946697\n",
      "          Validation Loss (standardized): 1.402503828619827\n",
      "Epoch: 9, Loss (standarized): 0.19445198168230415\n",
      "          Validation Loss (standardized): 1.3874885675666038\n",
      "Epoch: 10, Loss (standarized): 0.19253114446993394\n",
      "          Validation Loss (standardized): 1.3672093489974992\n",
      "Epoch: 11, Loss (standarized): 0.19061632747791263\n",
      "          Validation Loss (standardized): 1.3436148978162243\n",
      "Epoch: 12, Loss (standarized): 0.18874797819089373\n",
      "          Validation Loss (standardized): 1.3190057817486478\n",
      "Epoch: 13, Loss (standarized): 0.18704456007984505\n",
      "          Validation Loss (standardized): 1.2946474102274295\n",
      "Epoch: 14, Loss (standarized): 0.18555739323652243\n",
      "          Validation Loss (standardized): 1.2715200254451304\n",
      "Epoch: 15, Loss (standarized): 0.18428805710486215\n",
      "          Validation Loss (standardized): 1.2513099660012734\n",
      "Epoch: 16, Loss (standarized): 0.1832272526388733\n",
      "          Validation Loss (standardized): 1.2353659882152097\n",
      "Epoch: 17, Loss (standarized): 0.18245290134867007\n",
      "          Validation Loss (standardized): 1.2235738342109068\n",
      "Epoch: 18, Loss (standarized): 0.1819271838495768\n",
      "          Validation Loss (standardized): 1.2152965171822134\n",
      "Epoch: 19, Loss (standarized): 0.18144412336015192\n",
      "          Validation Loss (standardized): 1.2103395490482687\n",
      "Epoch: 20, Loss (standarized): 0.18095674110245033\n",
      "          Validation Loss (standardized): 1.208649927066755\n",
      "Final epoch: 20, Final loss (standarized): 0.18095674110245033\n",
      "Epoch: 1, Loss (standarized): 2.1703136733304436\n",
      "          Validation Loss (standardized): 1.372600874313488\n",
      "Epoch: 2, Loss (standarized): 1.637410105164815\n",
      "          Validation Loss (standardized): 1.2382091832493045\n",
      "Epoch: 3, Loss (standarized): 1.1642008088021885\n",
      "          Validation Loss (standardized): 1.1541059021368154\n",
      "Epoch: 4, Loss (standarized): 0.7623309344240781\n",
      "          Validation Loss (standardized): 1.1480620962407568\n",
      "Epoch: 5, Loss (standarized): 0.46900761327299406\n",
      "          Validation Loss (standardized): 1.2377485269898076\n",
      "Epoch: 6, Loss (standarized): 0.30947162369346043\n",
      "          Validation Loss (standardized): 1.3898957473672886\n",
      "Epoch: 7, Loss (standarized): 0.24686247461506516\n",
      "          Validation Loss (standardized): 1.553773188519761\n",
      "Epoch: 8, Loss (standarized): 0.2276678582376498\n",
      "          Validation Loss (standardized): 1.7037275901602238\n",
      "Epoch: 9, Loss (standarized): 0.22360046964066882\n",
      "          Validation Loss (standardized): 1.8309823650484456\n",
      "Epoch: 10, Loss (standarized): 0.2242823122234999\n",
      "          Validation Loss (standardized): 1.9346176381436049\n",
      "Epoch: 11, Loss (standarized): 0.22615358613921227\n",
      "          Validation Loss (standardized): 2.0158332929416405\n",
      "Epoch: 12, Loss (standarized): 0.2278402909714342\n",
      "          Validation Loss (standardized): 2.076215557255984\n",
      "Epoch: 13, Loss (standarized): 0.2288070986788477\n",
      "          Validation Loss (standardized): 2.1180518346887016\n",
      "Epoch: 14, Loss (standarized): 0.22893054681643918\n",
      "          Validation Loss (standardized): 2.143550310348646\n",
      "Epoch: 15, Loss (standarized): 0.22832492679392385\n",
      "          Validation Loss (standardized): 2.1551252318608505\n",
      "Epoch: 16, Loss (standarized): 0.22727337915907941\n",
      "          Validation Loss (standardized): 2.15515540634617\n",
      "Epoch: 17, Loss (standarized): 0.2259272211979531\n",
      "          Validation Loss (standardized): 2.1458178455325667\n",
      "Epoch: 18, Loss (standarized): 0.22454255990441227\n",
      "          Validation Loss (standardized): 2.1290228801075246\n",
      "Epoch: 19, Loss (standarized): 0.2233298635343795\n",
      "          Validation Loss (standardized): 2.1070839139761177\n",
      "Epoch: 20, Loss (standarized): 0.22251170670837275\n",
      "          Validation Loss (standardized): 2.081846256118185\n",
      "Final epoch: 20, Final loss (standarized): 0.22251170670837275\n",
      "Epoch: 1, Loss (standarized): 1.5780307676274272\n",
      "          Validation Loss (standardized): 0.8657714233565733\n",
      "Epoch: 2, Loss (standarized): 1.2028843760895185\n",
      "          Validation Loss (standardized): 0.7532272554632787\n",
      "Epoch: 3, Loss (standarized): 0.9021426608028201\n",
      "          Validation Loss (standardized): 0.6987429939093976\n",
      "Epoch: 4, Loss (standarized): 0.6798631645711201\n",
      "          Validation Loss (standardized): 0.6962253452803773\n",
      "Epoch: 5, Loss (standarized): 0.5254761668937916\n",
      "          Validation Loss (standardized): 0.7319982648041367\n",
      "Epoch: 6, Loss (standarized): 0.4216875926099712\n",
      "          Validation Loss (standardized): 0.7892124295096596\n",
      "Epoch: 7, Loss (standarized): 0.35069031388020877\n",
      "          Validation Loss (standardized): 0.8616452928518321\n",
      "Epoch: 8, Loss (standarized): 0.3017753627884076\n",
      "          Validation Loss (standardized): 0.9442389709605559\n",
      "Epoch: 9, Loss (standarized): 0.26813404547248326\n",
      "          Validation Loss (standardized): 1.033184441363603\n",
      "Epoch: 10, Loss (standarized): 0.24547863686862736\n",
      "          Validation Loss (standardized): 1.125687625051553\n",
      "Epoch: 11, Loss (standarized): 0.23062022704731286\n",
      "          Validation Loss (standardized): 1.2217043329834965\n",
      "Epoch: 12, Loss (standarized): 0.22140479703093\n",
      "          Validation Loss (standardized): 1.3172137104901986\n",
      "Epoch: 13, Loss (standarized): 0.21626368416308153\n",
      "          Validation Loss (standardized): 1.4080347612629829\n",
      "Epoch: 14, Loss (standarized): 0.2139614698131219\n",
      "          Validation Loss (standardized): 1.492762325157222\n",
      "Epoch: 15, Loss (standarized): 0.2135120004336377\n",
      "          Validation Loss (standardized): 1.5695547074429976\n",
      "Epoch: 16, Loss (standarized): 0.21406734311067338\n",
      "          Validation Loss (standardized): 1.6368140406948868\n",
      "Epoch: 17, Loss (standarized): 0.21513789027258767\n",
      "          Validation Loss (standardized): 1.6930122140692783\n",
      "Epoch: 18, Loss (standarized): 0.21623122084239865\n",
      "          Validation Loss (standardized): 1.7374750092810474\n",
      "Epoch: 19, Loss (standarized): 0.2170211968788635\n",
      "          Validation Loss (standardized): 1.7708072222646274\n",
      "Epoch: 20, Loss (standarized): 0.21740055306517825\n",
      "          Validation Loss (standardized): 1.7942649294627497\n",
      "Final epoch: 20, Final loss (standarized): 0.21740055306517825\n",
      "Epoch: 1, Loss (standarized): 0.9554948444586435\n",
      "          Validation Loss (standardized): 0.7432679374696317\n",
      "Epoch: 2, Loss (standarized): 0.6278622487752272\n",
      "          Validation Loss (standardized): 0.7961393535810476\n",
      "Epoch: 3, Loss (standarized): 0.4253740105271858\n",
      "          Validation Loss (standardized): 0.9173887210790223\n",
      "Epoch: 4, Loss (standarized): 0.30754345828822677\n",
      "          Validation Loss (standardized): 1.0733800349100922\n",
      "Epoch: 5, Loss (standarized): 0.2460250564156237\n",
      "          Validation Loss (standardized): 1.2420253655696487\n",
      "Epoch: 6, Loss (standarized): 0.21952887333579615\n",
      "          Validation Loss (standardized): 1.4043260071375772\n",
      "Epoch: 7, Loss (standarized): 0.21128860554244694\n",
      "          Validation Loss (standardized): 1.547267588110821\n",
      "Epoch: 8, Loss (standarized): 0.21078771299698226\n",
      "          Validation Loss (standardized): 1.6634604181564527\n",
      "Epoch: 9, Loss (standarized): 0.21296823576842322\n",
      "          Validation Loss (standardized): 1.7556269860645546\n",
      "Epoch: 10, Loss (standarized): 0.21593330026555183\n",
      "          Validation Loss (standardized): 1.8261323011131723\n",
      "Epoch: 11, Loss (standarized): 0.21855360481276415\n",
      "          Validation Loss (standardized): 1.8767141627500967\n",
      "Epoch: 12, Loss (standarized): 0.22036571547723996\n",
      "          Validation Loss (standardized): 1.9092330267557605\n",
      "Epoch: 13, Loss (standarized): 0.22121330095611288\n",
      "          Validation Loss (standardized): 1.9253671048143743\n",
      "Epoch: 14, Loss (standarized): 0.22108809948700275\n",
      "          Validation Loss (standardized): 1.927013482168403\n",
      "Epoch: 15, Loss (standarized): 0.22010054341737667\n",
      "          Validation Loss (standardized): 1.9163657941727446\n",
      "Epoch: 16, Loss (standarized): 0.21838729608053573\n",
      "          Validation Loss (standardized): 1.895331959313758\n",
      "Epoch: 17, Loss (standarized): 0.21607916138931327\n",
      "          Validation Loss (standardized): 1.865696041394031\n",
      "Epoch: 18, Loss (standarized): 0.21331897707598066\n",
      "          Validation Loss (standardized): 1.829164291272295\n",
      "Epoch: 19, Loss (standarized): 0.2102596117551687\n",
      "          Validation Loss (standardized): 1.7874048477069389\n",
      "Epoch: 20, Loss (standarized): 0.20706981648873682\n",
      "          Validation Loss (standardized): 1.7419513514578517\n",
      "Final epoch: 20, Final loss (standarized): 0.20706981648873682\n",
      "Epoch: 1, Loss (standarized): 0.6229097183682243\n",
      "          Validation Loss (standardized): 0.9122075486031989\n",
      "Epoch: 2, Loss (standarized): 0.4593755708191115\n",
      "          Validation Loss (standardized): 0.9898488994978285\n",
      "Epoch: 3, Loss (standarized): 0.3515103134388803\n",
      "          Validation Loss (standardized): 1.1026312158718024\n",
      "Epoch: 4, Loss (standarized): 0.28580298661993786\n",
      "          Validation Loss (standardized): 1.2326909929216991\n",
      "Epoch: 5, Loss (standarized): 0.24823238880081974\n",
      "          Validation Loss (standardized): 1.3673827796281333\n",
      "Epoch: 6, Loss (standarized): 0.22808332167194773\n",
      "          Validation Loss (standardized): 1.4996290756382116\n",
      "Epoch: 7, Loss (standarized): 0.2186049525457026\n",
      "          Validation Loss (standardized): 1.6207442417445088\n",
      "Epoch: 8, Loss (standarized): 0.21552879634822494\n",
      "          Validation Loss (standardized): 1.7254011824623336\n",
      "Epoch: 9, Loss (standarized): 0.21581207059864227\n",
      "          Validation Loss (standardized): 1.8101313226696174\n",
      "Epoch: 10, Loss (standarized): 0.21747065206161156\n",
      "          Validation Loss (standardized): 1.8736694708199713\n",
      "Epoch: 11, Loss (standarized): 0.21933312242478434\n",
      "          Validation Loss (standardized): 1.9156036424058436\n",
      "Epoch: 12, Loss (standarized): 0.22064204260122175\n",
      "          Validation Loss (standardized): 1.9367553933851422\n",
      "Epoch: 13, Loss (standarized): 0.2210131013384088\n",
      "          Validation Loss (standardized): 1.938950693330416\n",
      "Epoch: 14, Loss (standarized): 0.22037175326013936\n",
      "          Validation Loss (standardized): 1.9246646909961311\n",
      "Epoch: 15, Loss (standarized): 0.21876742562013218\n",
      "          Validation Loss (standardized): 1.8965762798186148\n",
      "Epoch: 16, Loss (standarized): 0.2164200675352225\n",
      "          Validation Loss (standardized): 1.8576076726824078\n",
      "Epoch: 17, Loss (standarized): 0.21349390000715715\n",
      "          Validation Loss (standardized): 1.810545203083639\n",
      "Epoch: 18, Loss (standarized): 0.21023795657832497\n",
      "          Validation Loss (standardized): 1.757705673209027\n",
      "Epoch: 19, Loss (standarized): 0.20683427226415546\n",
      "          Validation Loss (standardized): 1.7014984670705797\n",
      "Epoch: 20, Loss (standarized): 0.20342753662594587\n",
      "          Validation Loss (standardized): 1.6437236332245861\n",
      "Final epoch: 20, Final loss (standarized): 0.20342753662594587\n",
      "Epoch: 1, Loss (standarized): 1.2614514973365907\n",
      "          Validation Loss (standardized): 0.8211288788837208\n",
      "Epoch: 2, Loss (standarized): 0.8303997961405648\n",
      "          Validation Loss (standardized): 0.7860825246164552\n",
      "Epoch: 3, Loss (standarized): 0.5399065802758646\n",
      "          Validation Loss (standardized): 0.8307532517975664\n",
      "Epoch: 4, Loss (standarized): 0.36912771509366277\n",
      "          Validation Loss (standardized): 0.9290553714374468\n",
      "Epoch: 5, Loss (standarized): 0.2768172492225506\n",
      "          Validation Loss (standardized): 1.055749896124902\n",
      "Epoch: 6, Loss (standarized): 0.2300429218616747\n",
      "          Validation Loss (standardized): 1.1931427053729668\n",
      "Epoch: 7, Loss (standarized): 0.20820410608274592\n",
      "          Validation Loss (standardized): 1.3314805282636804\n",
      "Epoch: 8, Loss (standarized): 0.19958558417841785\n",
      "          Validation Loss (standardized): 1.46414979700367\n",
      "Epoch: 9, Loss (standarized): 0.19780267511450103\n",
      "          Validation Loss (standardized): 1.58712730206438\n",
      "Epoch: 10, Loss (standarized): 0.19968207206109556\n",
      "          Validation Loss (standardized): 1.697147055232266\n",
      "Epoch: 11, Loss (standarized): 0.2033474114187841\n",
      "          Validation Loss (standardized): 1.7940671150653555\n",
      "Epoch: 12, Loss (standarized): 0.20774421625093367\n",
      "          Validation Loss (standardized): 1.8772832537920818\n",
      "Epoch: 13, Loss (standarized): 0.2121423837605579\n",
      "          Validation Loss (standardized): 1.9469598545768236\n",
      "Epoch: 14, Loss (standarized): 0.2161256256201586\n",
      "          Validation Loss (standardized): 2.0028530924404695\n",
      "Epoch: 15, Loss (standarized): 0.21943063793405224\n",
      "          Validation Loss (standardized): 2.044905681656397\n",
      "Epoch: 16, Loss (standarized): 0.22186145034669585\n",
      "          Validation Loss (standardized): 2.0734693602992653\n",
      "Epoch: 17, Loss (standarized): 0.2233605188962447\n",
      "          Validation Loss (standardized): 2.089546785824023\n",
      "Epoch: 18, Loss (standarized): 0.2239710344225614\n",
      "          Validation Loss (standardized): 2.094240219066833\n",
      "Epoch: 19, Loss (standarized): 0.22378616595427325\n",
      "          Validation Loss (standardized): 2.088955755533771\n",
      "Epoch: 20, Loss (standarized): 0.22289007105247033\n",
      "          Validation Loss (standardized): 2.0749025545694493\n",
      "Final epoch: 20, Final loss (standarized): 0.22289007105247033\n",
      "Epoch: 1, Loss (standarized): 2.8707879211823326\n",
      "          Validation Loss (standardized): 1.4730490831439398\n",
      "Epoch: 2, Loss (standarized): 2.3471039574989367\n",
      "          Validation Loss (standardized): 1.2566717846227877\n",
      "Epoch: 3, Loss (standarized): 1.8713113306399287\n",
      "          Validation Loss (standardized): 1.093424685547062\n",
      "Epoch: 4, Loss (standarized): 1.4544680575375803\n",
      "          Validation Loss (standardized): 0.9855663974964978\n",
      "Epoch: 5, Loss (standarized): 1.0985270121865574\n",
      "          Validation Loss (standardized): 0.9324600630617668\n",
      "Epoch: 6, Loss (standarized): 0.8054348078289292\n",
      "          Validation Loss (standardized): 0.940716695308969\n",
      "Epoch: 7, Loss (standarized): 0.580443875768461\n",
      "          Validation Loss (standardized): 1.0113819019969252\n",
      "Epoch: 8, Loss (standarized): 0.422378555381843\n",
      "          Validation Loss (standardized): 1.133118850789366\n",
      "Epoch: 9, Loss (standarized): 0.3210459733179563\n",
      "          Validation Loss (standardized): 1.2874850811888239\n",
      "Epoch: 10, Loss (standarized): 0.2621744197071728\n",
      "          Validation Loss (standardized): 1.4540577665274328\n",
      "Epoch: 11, Loss (standarized): 0.23290608976590943\n",
      "          Validation Loss (standardized): 1.6187399770589586\n",
      "Epoch: 12, Loss (standarized): 0.22189752014755473\n",
      "          Validation Loss (standardized): 1.7736662871100208\n",
      "Epoch: 13, Loss (standarized): 0.22078474356719588\n",
      "          Validation Loss (standardized): 1.913182161660441\n",
      "Epoch: 14, Loss (standarized): 0.22453806588391245\n",
      "          Validation Loss (standardized): 2.034214460126453\n",
      "Epoch: 15, Loss (standarized): 0.2301757074684074\n",
      "          Validation Loss (standardized): 2.135834504430186\n",
      "Epoch: 16, Loss (standarized): 0.2360700883634373\n",
      "          Validation Loss (standardized): 2.21831594179189\n",
      "Epoch: 17, Loss (standarized): 0.2413078725988633\n",
      "          Validation Loss (standardized): 2.2829292838691266\n",
      "Epoch: 18, Loss (standarized): 0.24550166810809163\n",
      "          Validation Loss (standardized): 2.330902080036116\n",
      "Epoch: 19, Loss (standarized): 0.24864495430963318\n",
      "          Validation Loss (standardized): 2.3643956188948105\n",
      "Epoch: 20, Loss (standarized): 0.25069992319701434\n",
      "          Validation Loss (standardized): 2.3841983617797875\n",
      "Final epoch: 20, Final loss (standarized): 0.25069992319701434\n",
      "Epoch: 1, Loss (standarized): 0.4543379298454031\n",
      "          Validation Loss (standardized): 1.6417664901471927\n",
      "Epoch: 2, Loss (standarized): 0.3746675096008879\n",
      "          Validation Loss (standardized): 1.7381964831621093\n",
      "Epoch: 3, Loss (standarized): 0.3280660096340785\n",
      "          Validation Loss (standardized): 1.8047865295700103\n",
      "Epoch: 4, Loss (standarized): 0.29755891676137214\n",
      "          Validation Loss (standardized): 1.8434275883324023\n",
      "Epoch: 5, Loss (standarized): 0.2760655580252265\n",
      "          Validation Loss (standardized): 1.8539121547658801\n",
      "Epoch: 6, Loss (standarized): 0.2594854615523127\n",
      "          Validation Loss (standardized): 1.8386079353581326\n",
      "Epoch: 7, Loss (standarized): 0.2460314862765632\n",
      "          Validation Loss (standardized): 1.8002700040588737\n",
      "Epoch: 8, Loss (standarized): 0.23439426297845645\n",
      "          Validation Loss (standardized): 1.7431204696679095\n",
      "Epoch: 9, Loss (standarized): 0.22384843527297754\n",
      "          Validation Loss (standardized): 1.6710502441245523\n",
      "Epoch: 10, Loss (standarized): 0.21406375092097446\n",
      "          Validation Loss (standardized): 1.588469809269136\n",
      "Epoch: 11, Loss (standarized): 0.2052631649574767\n",
      "          Validation Loss (standardized): 1.4994550906232569\n",
      "Epoch: 12, Loss (standarized): 0.19765037014922884\n",
      "          Validation Loss (standardized): 1.4087251113462589\n",
      "Epoch: 13, Loss (standarized): 0.19158093393172307\n",
      "          Validation Loss (standardized): 1.321987053084382\n",
      "Epoch: 14, Loss (standarized): 0.1875310710013087\n",
      "          Validation Loss (standardized): 1.2474332490565094\n",
      "Epoch: 15, Loss (standarized): 0.18594060555638509\n",
      "          Validation Loss (standardized): 1.1968720690405712\n",
      "Epoch: 16, Loss (standarized): 0.18620498970974503\n",
      "          Validation Loss (standardized): 1.1772014451164463\n",
      "Epoch: 17, Loss (standarized): 0.18615571530609584\n",
      "          Validation Loss (standardized): 1.1848642701643757\n",
      "Epoch: 18, Loss (standarized): 0.18437338076332413\n",
      "          Validation Loss (standardized): 1.212235172535863\n",
      "Epoch: 19, Loss (standarized): 0.18175073346674617\n",
      "          Validation Loss (standardized): 1.2511088496762317\n",
      "Epoch: 20, Loss (standarized): 0.17952807486330763\n",
      "          Validation Loss (standardized): 1.2930776149426557\n",
      "Final epoch: 20, Final loss (standarized): 0.17952807486330763\n",
      "Epoch: 1, Loss (standarized): 1.3285442675616768\n",
      "          Validation Loss (standardized): 0.8433954136643201\n",
      "Epoch: 2, Loss (standarized): 0.8881696303020895\n",
      "          Validation Loss (standardized): 0.8177782885049794\n",
      "Epoch: 3, Loss (standarized): 0.5595491213181192\n",
      "          Validation Loss (standardized): 0.9018575039264738\n",
      "Epoch: 4, Loss (standarized): 0.3561385255936892\n",
      "          Validation Loss (standardized): 1.0708645601005289\n",
      "Epoch: 5, Loss (standarized): 0.2619707783749654\n",
      "          Validation Loss (standardized): 1.2744519385570379\n",
      "Epoch: 6, Loss (standarized): 0.22886246558809054\n",
      "          Validation Loss (standardized): 1.474772193114141\n",
      "Epoch: 7, Loss (standarized): 0.22113012710805352\n",
      "          Validation Loss (standardized): 1.6555735108652028\n",
      "Epoch: 8, Loss (standarized): 0.2228896534395623\n",
      "          Validation Loss (standardized): 1.8113178084674673\n",
      "Epoch: 9, Loss (standarized): 0.22785652397183034\n",
      "          Validation Loss (standardized): 1.9408854196084067\n",
      "Epoch: 10, Loss (standarized): 0.233248165282607\n",
      "          Validation Loss (standardized): 2.044852692621239\n",
      "Epoch: 11, Loss (standarized): 0.23795819387756323\n",
      "          Validation Loss (standardized): 2.124798546665163\n",
      "Epoch: 12, Loss (standarized): 0.24143567554911569\n",
      "          Validation Loss (standardized): 2.182700671294388\n",
      "Epoch: 13, Loss (standarized): 0.24362501809128642\n",
      "          Validation Loss (standardized): 2.220831028282329\n",
      "Epoch: 14, Loss (standarized): 0.24452105932174195\n",
      "          Validation Loss (standardized): 2.24158132751264\n",
      "Epoch: 15, Loss (standarized): 0.2442381391095985\n",
      "          Validation Loss (standardized): 2.2471536114941117\n",
      "Epoch: 16, Loss (standarized): 0.24290833338615953\n",
      "          Validation Loss (standardized): 2.2393602490315763\n",
      "Epoch: 17, Loss (standarized): 0.24067585741503936\n",
      "          Validation Loss (standardized): 2.2202673002095814\n",
      "Epoch: 18, Loss (standarized): 0.2377352009111402\n",
      "          Validation Loss (standardized): 2.1917377953175823\n",
      "Epoch: 19, Loss (standarized): 0.2342341986936582\n",
      "          Validation Loss (standardized): 2.1556611173236986\n",
      "Epoch: 20, Loss (standarized): 0.23035345175371366\n",
      "          Validation Loss (standardized): 2.113398441708183\n",
      "Final epoch: 20, Final loss (standarized): 0.23035345175371366\n",
      "Epoch: 1, Loss (standarized): 1.0460327805151155\n",
      "          Validation Loss (standardized): 0.755482298205724\n",
      "Epoch: 2, Loss (standarized): 0.7221838642148337\n",
      "          Validation Loss (standardized): 0.7852777020428161\n",
      "Epoch: 3, Loss (standarized): 0.5017320868348748\n",
      "          Validation Loss (standardized): 0.8807140907149278\n",
      "Epoch: 4, Loss (standarized): 0.3639074572211402\n",
      "          Validation Loss (standardized): 1.0190927053701997\n",
      "Epoch: 5, Loss (standarized): 0.28379849225376064\n",
      "          Validation Loss (standardized): 1.1768561613511261\n",
      "Epoch: 6, Loss (standarized): 0.23969990087231655\n",
      "          Validation Loss (standardized): 1.3377255359352243\n",
      "Epoch: 7, Loss (standarized): 0.21737925157827356\n",
      "          Validation Loss (standardized): 1.4923468408241691\n",
      "Epoch: 8, Loss (standarized): 0.20820228222645445\n",
      "          Validation Loss (standardized): 1.6368939947988508\n",
      "Epoch: 9, Loss (standarized): 0.20687690320411034\n",
      "          Validation Loss (standardized): 1.7678878095529702\n",
      "Epoch: 10, Loss (standarized): 0.2094581206616108\n",
      "          Validation Loss (standardized): 1.8828267114199073\n",
      "Epoch: 11, Loss (standarized): 0.2141354268359759\n",
      "          Validation Loss (standardized): 1.9783385809479717\n",
      "Epoch: 12, Loss (standarized): 0.21943871060876513\n",
      "          Validation Loss (standardized): 2.0535154563385034\n",
      "Epoch: 13, Loss (standarized): 0.2244559457631211\n",
      "          Validation Loss (standardized): 2.10853312695655\n",
      "Epoch: 14, Loss (standarized): 0.2285011653431677\n",
      "          Validation Loss (standardized): 2.145133410086983\n",
      "Epoch: 15, Loss (standarized): 0.23131170692860195\n",
      "          Validation Loss (standardized): 2.1652512413419633\n",
      "Epoch: 16, Loss (standarized): 0.23300141570124175\n",
      "          Validation Loss (standardized): 2.171388786307617\n",
      "Epoch: 17, Loss (standarized): 0.2335844851927862\n",
      "          Validation Loss (standardized): 2.166012112153751\n",
      "Epoch: 18, Loss (standarized): 0.23318694944743687\n",
      "          Validation Loss (standardized): 2.1506091463540185\n",
      "Epoch: 19, Loss (standarized): 0.23204155583142347\n",
      "          Validation Loss (standardized): 2.1271258156919064\n",
      "Epoch: 20, Loss (standarized): 0.23036288156220844\n",
      "          Validation Loss (standardized): 2.0974905909141155\n",
      "Final epoch: 20, Final loss (standarized): 0.23036288156220844\n",
      "Epoch: 1, Loss (standarized): 1.026615586651819\n",
      "          Validation Loss (standardized): 0.7125699232605142\n",
      "Epoch: 2, Loss (standarized): 0.709740296355196\n",
      "          Validation Loss (standardized): 0.7163727073903587\n",
      "Epoch: 3, Loss (standarized): 0.5020958362236172\n",
      "          Validation Loss (standardized): 0.7900813918082874\n",
      "Epoch: 4, Loss (standarized): 0.37282516160911444\n",
      "          Validation Loss (standardized): 0.9063800845820253\n",
      "Epoch: 5, Loss (standarized): 0.29525688317384885\n",
      "          Validation Loss (standardized): 1.046772875410607\n",
      "Epoch: 6, Loss (standarized): 0.24892049990675938\n",
      "          Validation Loss (standardized): 1.2008184837523985\n",
      "Epoch: 7, Loss (standarized): 0.22293146163924032\n",
      "          Validation Loss (standardized): 1.3609309522010016\n",
      "Epoch: 8, Loss (standarized): 0.21054798366675137\n",
      "          Validation Loss (standardized): 1.5208162721686131\n",
      "Epoch: 9, Loss (standarized): 0.2070022936980248\n",
      "          Validation Loss (standardized): 1.6715678342861013\n",
      "Epoch: 10, Loss (standarized): 0.20861601853892772\n",
      "          Validation Loss (standardized): 1.8078172610466328\n",
      "Epoch: 11, Loss (standarized): 0.21288643300881852\n",
      "          Validation Loss (standardized): 1.9266837533771826\n",
      "Epoch: 12, Loss (standarized): 0.218130341641315\n",
      "          Validation Loss (standardized): 2.0261746017950566\n",
      "Epoch: 13, Loss (standarized): 0.22335084531484978\n",
      "          Validation Loss (standardized): 2.105752087285947\n",
      "Epoch: 14, Loss (standarized): 0.22796288228935474\n",
      "          Validation Loss (standardized): 2.165729828641796\n",
      "Epoch: 15, Loss (standarized): 0.23161997941611612\n",
      "          Validation Loss (standardized): 2.206891285301861\n",
      "Epoch: 16, Loss (standarized): 0.2341487189363968\n",
      "          Validation Loss (standardized): 2.2302978030276215\n",
      "Epoch: 17, Loss (standarized): 0.23547390250757833\n",
      "          Validation Loss (standardized): 2.2376991024037802\n",
      "Epoch: 18, Loss (standarized): 0.23566509979747863\n",
      "          Validation Loss (standardized): 2.231102040138233\n",
      "Epoch: 19, Loss (standarized): 0.23483115883232797\n",
      "          Validation Loss (standardized): 2.2123986399310156\n",
      "Epoch: 20, Loss (standarized): 0.2331243726470988\n",
      "          Validation Loss (standardized): 2.183274634477385\n",
      "Final epoch: 20, Final loss (standarized): 0.2331243726470988\n",
      "Epoch: 1, Loss (standarized): 1.348849639511764\n",
      "          Validation Loss (standardized): 0.9561957357143885\n",
      "Epoch: 2, Loss (standarized): 0.913289102998696\n",
      "          Validation Loss (standardized): 1.0182816100264653\n",
      "Epoch: 3, Loss (standarized): 0.6546729099181257\n",
      "          Validation Loss (standardized): 1.132069369670487\n",
      "Epoch: 4, Loss (standarized): 0.4816509229332616\n",
      "          Validation Loss (standardized): 1.2735294393801564\n",
      "Epoch: 5, Loss (standarized): 0.3663849545480197\n",
      "          Validation Loss (standardized): 1.4313957681472589\n",
      "Epoch: 6, Loss (standarized): 0.2977218601168323\n",
      "          Validation Loss (standardized): 1.5929897107234274\n",
      "Epoch: 7, Loss (standarized): 0.2617475740342202\n",
      "          Validation Loss (standardized): 1.745755926096131\n",
      "Epoch: 8, Loss (standarized): 0.24484539357987659\n",
      "          Validation Loss (standardized): 1.8824436663135835\n",
      "Epoch: 9, Loss (standarized): 0.2380184537957959\n",
      "          Validation Loss (standardized): 1.999590648502957\n",
      "Epoch: 10, Loss (standarized): 0.2364366389386975\n",
      "          Validation Loss (standardized): 2.096065800958678\n",
      "Epoch: 11, Loss (standarized): 0.23736127584844652\n",
      "          Validation Loss (standardized): 2.1709576166518034\n",
      "Epoch: 12, Loss (standarized): 0.2389549140741466\n",
      "          Validation Loss (standardized): 2.223998833511296\n",
      "Epoch: 13, Loss (standarized): 0.24021706509747895\n",
      "          Validation Loss (standardized): 2.2558664047049994\n",
      "Epoch: 14, Loss (standarized): 0.24066456502259923\n",
      "          Validation Loss (standardized): 2.2681197249954885\n",
      "Epoch: 15, Loss (standarized): 0.24009141573005877\n",
      "          Validation Loss (standardized): 2.2627630916222214\n",
      "Epoch: 16, Loss (standarized): 0.23848042524846075\n",
      "          Validation Loss (standardized): 2.241966595081519\n",
      "Epoch: 17, Loss (standarized): 0.23588335728045157\n",
      "          Validation Loss (standardized): 2.2078450582016216\n",
      "Epoch: 18, Loss (standarized): 0.23244834085707847\n",
      "          Validation Loss (standardized): 2.1626430755870514\n",
      "Epoch: 19, Loss (standarized): 0.22836549601651884\n",
      "          Validation Loss (standardized): 2.1085918048772005\n",
      "Epoch: 20, Loss (standarized): 0.22380587422999282\n",
      "          Validation Loss (standardized): 2.0477968149641543\n",
      "Final epoch: 20, Final loss (standarized): 0.22380587422999282\n",
      "Epoch: 1, Loss (standarized): 0.40049285964705467\n",
      "          Validation Loss (standardized): 0.7817063170293668\n",
      "Epoch: 2, Loss (standarized): 0.30388846178016027\n",
      "          Validation Loss (standardized): 0.9071231356331808\n",
      "Epoch: 3, Loss (standarized): 0.2520151670972658\n",
      "          Validation Loss (standardized): 1.0515893412342188\n",
      "Epoch: 4, Loss (standarized): 0.22712346922109042\n",
      "          Validation Loss (standardized): 1.1923487062709022\n",
      "Epoch: 5, Loss (standarized): 0.21616449805817084\n",
      "          Validation Loss (standardized): 1.3151044486009165\n",
      "Epoch: 6, Loss (standarized): 0.21154638574148457\n",
      "          Validation Loss (standardized): 1.4129360609639627\n",
      "Epoch: 7, Loss (standarized): 0.20928041994452537\n",
      "          Validation Loss (standardized): 1.4840610272118189\n",
      "Epoch: 8, Loss (standarized): 0.2073717008133647\n",
      "          Validation Loss (standardized): 1.5301339683966682\n",
      "Epoch: 9, Loss (standarized): 0.20492539419551786\n",
      "          Validation Loss (standardized): 1.5544246648653441\n",
      "Epoch: 10, Loss (standarized): 0.20180992299751088\n",
      "          Validation Loss (standardized): 1.5615399141102273\n",
      "Epoch: 11, Loss (standarized): 0.19833372540504457\n",
      "          Validation Loss (standardized): 1.5562504403883184\n",
      "Epoch: 12, Loss (standarized): 0.19508296074564063\n",
      "          Validation Loss (standardized): 1.5426983360728002\n",
      "Epoch: 13, Loss (standarized): 0.19216291170109126\n",
      "          Validation Loss (standardized): 1.523291576110268\n",
      "Epoch: 14, Loss (standarized): 0.1895814660143263\n",
      "          Validation Loss (standardized): 1.5002094983922267\n",
      "Epoch: 15, Loss (standarized): 0.18741086899055046\n",
      "          Validation Loss (standardized): 1.4766123119288381\n",
      "Epoch: 16, Loss (standarized): 0.18579411474076707\n",
      "          Validation Loss (standardized): 1.4538871045414092\n",
      "Epoch: 17, Loss (standarized): 0.1846735978172558\n",
      "          Validation Loss (standardized): 1.4326930594192953\n",
      "Epoch: 18, Loss (standarized): 0.18378309082405372\n",
      "          Validation Loss (standardized): 1.4136029995866732\n",
      "Epoch: 19, Loss (standarized): 0.1829457429587102\n",
      "          Validation Loss (standardized): 1.3966268792054506\n",
      "Epoch: 20, Loss (standarized): 0.18206340957758033\n",
      "          Validation Loss (standardized): 1.381929169195847\n",
      "Final epoch: 20, Final loss (standarized): 0.18206340957758033\n",
      "Epoch: 1, Loss (standarized): 1.9009999959537909\n",
      "          Validation Loss (standardized): 1.0241238875332885\n",
      "Epoch: 2, Loss (standarized): 1.3845375745030746\n",
      "          Validation Loss (standardized): 0.8836706205320329\n",
      "Epoch: 3, Loss (standarized): 0.9582826836116006\n",
      "          Validation Loss (standardized): 0.8316798296319032\n",
      "Epoch: 4, Loss (standarized): 0.6336046635022342\n",
      "          Validation Loss (standardized): 0.869550256890598\n",
      "Epoch: 5, Loss (standarized): 0.41702711247244995\n",
      "          Validation Loss (standardized): 0.9775993850474518\n",
      "Epoch: 6, Loss (standarized): 0.2948612892449319\n",
      "          Validation Loss (standardized): 1.1242981376008607\n",
      "Epoch: 7, Loss (standarized): 0.23714009694746446\n",
      "          Validation Loss (standardized): 1.2844609779354383\n",
      "Epoch: 8, Loss (standarized): 0.21400426084336782\n",
      "          Validation Loss (standardized): 1.4428466016864758\n",
      "Epoch: 9, Loss (standarized): 0.20778626337576395\n",
      "          Validation Loss (standardized): 1.5913420650654035\n",
      "Epoch: 10, Loss (standarized): 0.20961781971769916\n",
      "          Validation Loss (standardized): 1.7260222508618073\n",
      "Epoch: 11, Loss (standarized): 0.21487239641277808\n",
      "          Validation Loss (standardized): 1.8448878533108137\n",
      "Epoch: 12, Loss (standarized): 0.22135575421260145\n",
      "          Validation Loss (standardized): 1.9471419012183508\n",
      "Epoch: 13, Loss (standarized): 0.22790714820963384\n",
      "          Validation Loss (standardized): 2.0328909602517955\n",
      "Epoch: 14, Loss (standarized): 0.23383534645280593\n",
      "          Validation Loss (standardized): 2.1024060406592335\n",
      "Epoch: 15, Loss (standarized): 0.2389134457473741\n",
      "          Validation Loss (standardized): 2.156439218691251\n",
      "Epoch: 16, Loss (standarized): 0.24295378151734104\n",
      "          Validation Loss (standardized): 2.1958875609082025\n",
      "Epoch: 17, Loss (standarized): 0.24592365759775583\n",
      "          Validation Loss (standardized): 2.2219763786473594\n",
      "Epoch: 18, Loss (standarized): 0.24783338620469791\n",
      "          Validation Loss (standardized): 2.235841198372102\n",
      "Epoch: 19, Loss (standarized): 0.24871683411536916\n",
      "          Validation Loss (standardized): 2.238572156713177\n",
      "Epoch: 20, Loss (standarized): 0.24868357686679307\n",
      "          Validation Loss (standardized): 2.2312100706375935\n",
      "Final epoch: 20, Final loss (standarized): 0.24868357686679307\n",
      "Epoch: 1, Loss (standarized): 0.6509243705968782\n",
      "          Validation Loss (standardized): 0.7397743603599817\n",
      "Epoch: 2, Loss (standarized): 0.5429000160268651\n",
      "          Validation Loss (standardized): 0.7701726212849911\n",
      "Epoch: 3, Loss (standarized): 0.4604560961994413\n",
      "          Validation Loss (standardized): 0.8153121075163753\n",
      "Epoch: 4, Loss (standarized): 0.39651771702673255\n",
      "          Validation Loss (standardized): 0.8701474719098485\n",
      "Epoch: 5, Loss (standarized): 0.34678306218573934\n",
      "          Validation Loss (standardized): 0.9321170084339562\n",
      "Epoch: 6, Loss (standarized): 0.3081320549621109\n",
      "          Validation Loss (standardized): 0.9995751298874705\n",
      "Epoch: 7, Loss (standarized): 0.27863283791063764\n",
      "          Validation Loss (standardized): 1.0702165407542858\n",
      "Epoch: 8, Loss (standarized): 0.2565679145070821\n",
      "          Validation Loss (standardized): 1.1424529286214304\n",
      "Epoch: 9, Loss (standarized): 0.23947890586356288\n",
      "          Validation Loss (standardized): 1.2142264951187405\n",
      "Epoch: 10, Loss (standarized): 0.22609720507437633\n",
      "          Validation Loss (standardized): 1.2837874122265072\n",
      "Epoch: 11, Loss (standarized): 0.2160211936612839\n",
      "          Validation Loss (standardized): 1.3495828419019482\n",
      "Epoch: 12, Loss (standarized): 0.208890872358248\n",
      "          Validation Loss (standardized): 1.4101446500953276\n",
      "Epoch: 13, Loss (standarized): 0.20395383107577172\n",
      "          Validation Loss (standardized): 1.4639354616367095\n",
      "Epoch: 14, Loss (standarized): 0.2005979989261779\n",
      "          Validation Loss (standardized): 1.5096731922912137\n",
      "Epoch: 15, Loss (standarized): 0.1984399050677496\n",
      "          Validation Loss (standardized): 1.5462654423105828\n",
      "Epoch: 16, Loss (standarized): 0.19701148064975607\n",
      "          Validation Loss (standardized): 1.5731107517896377\n",
      "Epoch: 17, Loss (standarized): 0.195960162679473\n",
      "          Validation Loss (standardized): 1.590178942830766\n",
      "Epoch: 18, Loss (standarized): 0.19498460247680502\n",
      "          Validation Loss (standardized): 1.5979311909921428\n",
      "Epoch: 19, Loss (standarized): 0.19393901191089769\n",
      "          Validation Loss (standardized): 1.597106949248838\n",
      "Epoch: 20, Loss (standarized): 0.19276774715014006\n",
      "          Validation Loss (standardized): 1.588806378529608\n",
      "Final epoch: 20, Final loss (standarized): 0.19276774715014006\n",
      "Epoch: 1, Loss (standarized): 0.2572177539217549\n",
      "          Validation Loss (standardized): 1.401620177467244\n",
      "Epoch: 2, Loss (standarized): 0.22623736960766422\n",
      "          Validation Loss (standardized): 1.3978600843359619\n",
      "Epoch: 3, Loss (standarized): 0.21065237791721522\n",
      "          Validation Loss (standardized): 1.3818963068834602\n",
      "Epoch: 4, Loss (standarized): 0.20150183295775423\n",
      "          Validation Loss (standardized): 1.3557547800675638\n",
      "Epoch: 5, Loss (standarized): 0.19564150702249425\n",
      "          Validation Loss (standardized): 1.3256219459583827\n",
      "Epoch: 6, Loss (standarized): 0.19198521281585548\n",
      "          Validation Loss (standardized): 1.2972261962960425\n",
      "Epoch: 7, Loss (standarized): 0.18994007485761275\n",
      "          Validation Loss (standardized): 1.2751980163337193\n",
      "Epoch: 8, Loss (standarized): 0.1888884573579316\n",
      "          Validation Loss (standardized): 1.2608815759214225\n",
      "Epoch: 9, Loss (standarized): 0.18816509077805874\n",
      "          Validation Loss (standardized): 1.2523522629065105\n",
      "Epoch: 10, Loss (standarized): 0.1874047136712469\n",
      "          Validation Loss (standardized): 1.2491714331381445\n",
      "Epoch: 11, Loss (standarized): 0.1864294529576403\n",
      "          Validation Loss (standardized): 1.2504219671138663\n",
      "Epoch: 12, Loss (standarized): 0.1852302393949584\n",
      "          Validation Loss (standardized): 1.2546963711855899\n",
      "Epoch: 13, Loss (standarized): 0.18401488778706446\n",
      "          Validation Loss (standardized): 1.2614878003730379\n",
      "Epoch: 14, Loss (standarized): 0.18294855634083318\n",
      "          Validation Loss (standardized): 1.2687155378984505\n",
      "Epoch: 15, Loss (standarized): 0.18209277735874127\n",
      "          Validation Loss (standardized): 1.2753924739372724\n",
      "Epoch: 16, Loss (standarized): 0.1814906832781295\n",
      "          Validation Loss (standardized): 1.2797690408545028\n",
      "Epoch: 17, Loss (standarized): 0.18119136478257705\n",
      "          Validation Loss (standardized): 1.2805983656594202\n",
      "Epoch: 18, Loss (standarized): 0.18112576435746977\n",
      "          Validation Loss (standardized): 1.2801110325685274\n",
      "Epoch: 19, Loss (standarized): 0.18116118248657445\n",
      "          Validation Loss (standardized): 1.2785810319950581\n",
      "Epoch: 20, Loss (standarized): 0.18124685057325382\n",
      "          Validation Loss (standardized): 1.2750034790663898\n",
      "Final epoch: 20, Final loss (standarized): 0.18124685057325382\n",
      "Epoch: 1, Loss (standarized): 0.8542713789094339\n",
      "          Validation Loss (standardized): 0.7428937265241682\n",
      "Epoch: 2, Loss (standarized): 0.5158233968925149\n",
      "          Validation Loss (standardized): 0.8331430423634134\n",
      "Epoch: 3, Loss (standarized): 0.3500545024073787\n",
      "          Validation Loss (standardized): 0.9875986910404007\n",
      "Epoch: 4, Loss (standarized): 0.28074075069162746\n",
      "          Validation Loss (standardized): 1.1456732946656303\n",
      "Epoch: 5, Loss (standarized): 0.24961177189300576\n",
      "          Validation Loss (standardized): 1.292144252125617\n",
      "Epoch: 6, Loss (standarized): 0.2347295051996159\n",
      "          Validation Loss (standardized): 1.4215565990237897\n",
      "Epoch: 7, Loss (standarized): 0.2278410489571205\n",
      "          Validation Loss (standardized): 1.5301381290509264\n",
      "Epoch: 8, Loss (standarized): 0.22467943289714093\n",
      "          Validation Loss (standardized): 1.6174025238210865\n",
      "Epoch: 9, Loss (standarized): 0.2232997644663592\n",
      "          Validation Loss (standardized): 1.6851198032325254\n",
      "Epoch: 10, Loss (standarized): 0.22255771744987446\n",
      "          Validation Loss (standardized): 1.7348211803615567\n",
      "Epoch: 11, Loss (standarized): 0.22172478725562492\n",
      "          Validation Loss (standardized): 1.7683886659197146\n",
      "Epoch: 12, Loss (standarized): 0.2205853669930912\n",
      "          Validation Loss (standardized): 1.7875914256225658\n",
      "Epoch: 13, Loss (standarized): 0.21906021183724872\n",
      "          Validation Loss (standardized): 1.7934054492840428\n",
      "Epoch: 14, Loss (standarized): 0.2171176425935317\n",
      "          Validation Loss (standardized): 1.7880744490712004\n",
      "Epoch: 15, Loss (standarized): 0.21484238902976363\n",
      "          Validation Loss (standardized): 1.7732796523474712\n",
      "Epoch: 16, Loss (standarized): 0.21228210827840097\n",
      "          Validation Loss (standardized): 1.7503518608687847\n",
      "Epoch: 17, Loss (standarized): 0.20948367508359994\n",
      "          Validation Loss (standardized): 1.7203974292330935\n",
      "Epoch: 18, Loss (standarized): 0.20659182955540684\n",
      "          Validation Loss (standardized): 1.6848030738166058\n",
      "Epoch: 19, Loss (standarized): 0.20370014232618294\n",
      "          Validation Loss (standardized): 1.6452632000488547\n",
      "Epoch: 20, Loss (standarized): 0.20095597352818095\n",
      "          Validation Loss (standardized): 1.6033711575145562\n",
      "Final epoch: 20, Final loss (standarized): 0.20095597352818095\n",
      "Epoch: 1, Loss (standarized): 3.4338021088282793\n",
      "          Validation Loss (standardized): 1.6252995846386358\n",
      "Epoch: 2, Loss (standarized): 2.693850049961617\n",
      "          Validation Loss (standardized): 1.2868785793066508\n",
      "Epoch: 3, Loss (standarized): 2.0513005849029335\n",
      "          Validation Loss (standardized): 1.0225797441051592\n",
      "Epoch: 4, Loss (standarized): 1.5106709435129346\n",
      "          Validation Loss (standardized): 0.8523279422596608\n",
      "Epoch: 5, Loss (standarized): 1.0979603700607719\n",
      "          Validation Loss (standardized): 0.7779386984255345\n",
      "Epoch: 6, Loss (standarized): 0.8087991751212684\n",
      "          Validation Loss (standardized): 0.7689940464494969\n",
      "Epoch: 7, Loss (standarized): 0.6016168524362283\n",
      "          Validation Loss (standardized): 0.8070111704382279\n",
      "Epoch: 8, Loss (standarized): 0.45734297153064857\n",
      "          Validation Loss (standardized): 0.8827456251115737\n",
      "Epoch: 9, Loss (standarized): 0.3677403053283593\n",
      "          Validation Loss (standardized): 0.9793620684721012\n",
      "Epoch: 10, Loss (standarized): 0.31245478257926856\n",
      "          Validation Loss (standardized): 1.0821282919146373\n",
      "Epoch: 11, Loss (standarized): 0.27786695916884174\n",
      "          Validation Loss (standardized): 1.1862537828741682\n",
      "Epoch: 12, Loss (standarized): 0.25734352362171725\n",
      "          Validation Loss (standardized): 1.2865181518223823\n",
      "Epoch: 13, Loss (standarized): 0.2454255738447432\n",
      "          Validation Loss (standardized): 1.379041352443922\n",
      "Epoch: 14, Loss (standarized): 0.2386902764122585\n",
      "          Validation Loss (standardized): 1.4629891664433086\n",
      "Epoch: 15, Loss (standarized): 0.2351348890622467\n",
      "          Validation Loss (standardized): 1.5384946094708811\n",
      "Epoch: 16, Loss (standarized): 0.23358466551172552\n",
      "          Validation Loss (standardized): 1.6048443539426192\n",
      "Epoch: 17, Loss (standarized): 0.23314964125519125\n",
      "          Validation Loss (standardized): 1.6618063883682612\n",
      "Epoch: 18, Loss (standarized): 0.23333439941796602\n",
      "          Validation Loss (standardized): 1.709489471898994\n",
      "Epoch: 19, Loss (standarized): 0.2337444536244433\n",
      "          Validation Loss (standardized): 1.7481647128773512\n",
      "Epoch: 20, Loss (standarized): 0.2341078605613399\n",
      "          Validation Loss (standardized): 1.7782640789701936\n",
      "Final epoch: 20, Final loss (standarized): 0.2341078605613399\n",
      "Epoch: 1, Loss (standarized): 1.0674173144950507\n",
      "          Validation Loss (standardized): 0.7752449973309768\n",
      "Epoch: 2, Loss (standarized): 0.7511075548277282\n",
      "          Validation Loss (standardized): 0.7582962940528222\n",
      "Epoch: 3, Loss (standarized): 0.5220148387729029\n",
      "          Validation Loss (standardized): 0.8059067710694058\n",
      "Epoch: 4, Loss (standarized): 0.3737713209755879\n",
      "          Validation Loss (standardized): 0.9003597592734767\n",
      "Epoch: 5, Loss (standarized): 0.2872328461911096\n",
      "          Validation Loss (standardized): 1.020506345841834\n",
      "Epoch: 6, Loss (standarized): 0.2398181691873527\n",
      "          Validation Loss (standardized): 1.1507020308727745\n",
      "Epoch: 7, Loss (standarized): 0.21598346746161476\n",
      "          Validation Loss (standardized): 1.2835624019222762\n",
      "Epoch: 8, Loss (standarized): 0.2051559437909663\n",
      "          Validation Loss (standardized): 1.4120939439538165\n",
      "Epoch: 9, Loss (standarized): 0.2015492266970075\n",
      "          Validation Loss (standardized): 1.532209193221588\n",
      "Epoch: 10, Loss (standarized): 0.2020608388809384\n",
      "          Validation Loss (standardized): 1.6421401214331588\n",
      "Epoch: 11, Loss (standarized): 0.20472645980617943\n",
      "          Validation Loss (standardized): 1.7391360198359118\n",
      "Epoch: 12, Loss (standarized): 0.20833933929954448\n",
      "          Validation Loss (standardized): 1.820719034603819\n",
      "Epoch: 13, Loss (standarized): 0.2120075593919683\n",
      "          Validation Loss (standardized): 1.8861065789311038\n",
      "Epoch: 14, Loss (standarized): 0.2151680253119757\n",
      "          Validation Loss (standardized): 1.9351855805901488\n",
      "Epoch: 15, Loss (standarized): 0.2175229574528462\n",
      "          Validation Loss (standardized): 1.9685975143264773\n",
      "Epoch: 16, Loss (standarized): 0.21896000280367964\n",
      "          Validation Loss (standardized): 1.9871308098548122\n",
      "Epoch: 17, Loss (standarized): 0.219498748786086\n",
      "          Validation Loss (standardized): 1.9921415218297467\n",
      "Epoch: 18, Loss (standarized): 0.21918272174405148\n",
      "          Validation Loss (standardized): 1.9853910956448337\n",
      "Epoch: 19, Loss (standarized): 0.2182032587462031\n",
      "          Validation Loss (standardized): 1.9684453993834004\n",
      "Epoch: 20, Loss (standarized): 0.2166582551879745\n",
      "          Validation Loss (standardized): 1.9428477962711233\n",
      "Final epoch: 20, Final loss (standarized): 0.2166582551879745\n",
      "Epoch: 1, Loss (standarized): 0.4524548777564799\n",
      "          Validation Loss (standardized): 0.8216793644107007\n",
      "Epoch: 2, Loss (standarized): 0.3055562276069024\n",
      "          Validation Loss (standardized): 0.9265517741662197\n",
      "Epoch: 3, Loss (standarized): 0.23715311917923812\n",
      "          Validation Loss (standardized): 1.0601602379540396\n",
      "Epoch: 4, Loss (standarized): 0.20941987145743096\n",
      "          Validation Loss (standardized): 1.1976663018034464\n",
      "Epoch: 5, Loss (standarized): 0.19994474488483485\n",
      "          Validation Loss (standardized): 1.3246241906870986\n",
      "Epoch: 6, Loss (standarized): 0.19898943008326536\n",
      "          Validation Loss (standardized): 1.4330416019149896\n",
      "Epoch: 7, Loss (standarized): 0.20110615300350532\n",
      "          Validation Loss (standardized): 1.5198270306100647\n",
      "Epoch: 8, Loss (standarized): 0.20381436062719507\n",
      "          Validation Loss (standardized): 1.5842597237376188\n",
      "Epoch: 9, Loss (standarized): 0.20586055081805035\n",
      "          Validation Loss (standardized): 1.62642127160789\n",
      "Epoch: 10, Loss (standarized): 0.20683015098790358\n",
      "          Validation Loss (standardized): 1.6481394653930181\n",
      "Epoch: 11, Loss (standarized): 0.20654980058509842\n",
      "          Validation Loss (standardized): 1.651886479503574\n",
      "Epoch: 12, Loss (standarized): 0.20511673002049\n",
      "          Validation Loss (standardized): 1.6409304028822482\n",
      "Epoch: 13, Loss (standarized): 0.2027156079911015\n",
      "          Validation Loss (standardized): 1.6178163421487775\n",
      "Epoch: 14, Loss (standarized): 0.1996365792538829\n",
      "          Validation Loss (standardized): 1.5851741518604652\n",
      "Epoch: 15, Loss (standarized): 0.1961548982172558\n",
      "          Validation Loss (standardized): 1.5459076373738898\n",
      "Epoch: 16, Loss (standarized): 0.19250188508225075\n",
      "          Validation Loss (standardized): 1.5026962018005394\n",
      "Epoch: 17, Loss (standarized): 0.18901456495740707\n",
      "          Validation Loss (standardized): 1.4579650211872213\n",
      "Epoch: 18, Loss (standarized): 0.18582401469814888\n",
      "          Validation Loss (standardized): 1.4132825655059134\n",
      "Epoch: 19, Loss (standarized): 0.18302805772528657\n",
      "          Validation Loss (standardized): 1.3702244375381267\n",
      "Epoch: 20, Loss (standarized): 0.18067891913500905\n",
      "          Validation Loss (standardized): 1.3301350433662316\n",
      "Final epoch: 20, Final loss (standarized): 0.18067891913500905\n",
      "Epoch: 1, Loss (standarized): 0.4737395247775828\n",
      "          Validation Loss (standardized): 0.9615082082753688\n",
      "Epoch: 2, Loss (standarized): 0.3691305621768576\n",
      "          Validation Loss (standardized): 1.0879337126130388\n",
      "Epoch: 3, Loss (standarized): 0.3049095259659247\n",
      "          Validation Loss (standardized): 1.224220067048816\n",
      "Epoch: 4, Loss (standarized): 0.26869205620390574\n",
      "          Validation Loss (standardized): 1.3529503444609885\n",
      "Epoch: 5, Loss (standarized): 0.24814648412781615\n",
      "          Validation Loss (standardized): 1.4649264464442635\n",
      "Epoch: 6, Loss (standarized): 0.23599650446523696\n",
      "          Validation Loss (standardized): 1.5555746534528838\n",
      "Epoch: 7, Loss (standarized): 0.22873394581879863\n",
      "          Validation Loss (standardized): 1.6224375455900997\n",
      "Epoch: 8, Loss (standarized): 0.22397313254995557\n",
      "          Validation Loss (standardized): 1.665495556432413\n",
      "Epoch: 9, Loss (standarized): 0.22017124786035344\n",
      "          Validation Loss (standardized): 1.686560832939125\n",
      "Epoch: 10, Loss (standarized): 0.21650853551413013\n",
      "          Validation Loss (standardized): 1.688662188833716\n",
      "Epoch: 11, Loss (standarized): 0.21276777882271025\n",
      "          Validation Loss (standardized): 1.6754529543174936\n",
      "Epoch: 12, Loss (standarized): 0.20889674826521404\n",
      "          Validation Loss (standardized): 1.6503900843987407\n",
      "Epoch: 13, Loss (standarized): 0.20518977854731565\n",
      "          Validation Loss (standardized): 1.6165890395015288\n",
      "Epoch: 14, Loss (standarized): 0.20187645916384517\n",
      "          Validation Loss (standardized): 1.5773122695985584\n",
      "Epoch: 15, Loss (standarized): 0.19912026786339482\n",
      "          Validation Loss (standardized): 1.5359786912219096\n",
      "Epoch: 16, Loss (standarized): 0.19700039187280324\n",
      "          Validation Loss (standardized): 1.495820737624375\n",
      "Epoch: 17, Loss (standarized): 0.19545535852490686\n",
      "          Validation Loss (standardized): 1.4595048011882739\n",
      "Epoch: 18, Loss (standarized): 0.1943053230945329\n",
      "          Validation Loss (standardized): 1.4289391013513495\n",
      "Epoch: 19, Loss (standarized): 0.19332989883391963\n",
      "          Validation Loss (standardized): 1.4051677592205865\n",
      "Epoch: 20, Loss (standarized): 0.19218462668765515\n",
      "          Validation Loss (standardized): 1.388385091028133\n",
      "Final epoch: 20, Final loss (standarized): 0.19218462668765515\n",
      "Epoch: 1, Loss (standarized): 1.7365353842681994\n",
      "          Validation Loss (standardized): 0.9522383596711609\n",
      "Epoch: 2, Loss (standarized): 1.2848235336663087\n",
      "          Validation Loss (standardized): 0.8077360487910322\n",
      "Epoch: 3, Loss (standarized): 0.9235334079159875\n",
      "          Validation Loss (standardized): 0.7404714070212438\n",
      "Epoch: 4, Loss (standarized): 0.6652503878105844\n",
      "          Validation Loss (standardized): 0.7487456191835784\n",
      "Epoch: 5, Loss (standarized): 0.5037828306969283\n",
      "          Validation Loss (standardized): 0.810464043783097\n",
      "Epoch: 6, Loss (standarized): 0.40376401913044396\n",
      "          Validation Loss (standardized): 0.9041095295795116\n",
      "Epoch: 7, Loss (standarized): 0.33913469181781236\n",
      "          Validation Loss (standardized): 1.0136436629043886\n",
      "Epoch: 8, Loss (standarized): 0.2967841564804101\n",
      "          Validation Loss (standardized): 1.1305472067315339\n",
      "Epoch: 9, Loss (standarized): 0.2682048135162886\n",
      "          Validation Loss (standardized): 1.2515713520841008\n",
      "Epoch: 10, Loss (standarized): 0.2508054552612193\n",
      "          Validation Loss (standardized): 1.3728337152725691\n",
      "Epoch: 11, Loss (standarized): 0.2426837293806475\n",
      "          Validation Loss (standardized): 1.4900945888709793\n",
      "Epoch: 12, Loss (standarized): 0.24002116090668335\n",
      "          Validation Loss (standardized): 1.5995730356035067\n",
      "Epoch: 13, Loss (standarized): 0.24033277608785697\n",
      "          Validation Loss (standardized): 1.6993217709156039\n",
      "Epoch: 14, Loss (standarized): 0.24230117416049804\n",
      "          Validation Loss (standardized): 1.7878025390980512\n",
      "Epoch: 15, Loss (standarized): 0.24496571421681607\n",
      "          Validation Loss (standardized): 1.8636213018983359\n",
      "Epoch: 16, Loss (standarized): 0.2477598510163767\n",
      "          Validation Loss (standardized): 1.9258468111509144\n",
      "Epoch: 17, Loss (standarized): 0.2501905172708078\n",
      "          Validation Loss (standardized): 1.973761103864116\n",
      "Epoch: 18, Loss (standarized): 0.2519673419866154\n",
      "          Validation Loss (standardized): 2.0073267272520896\n",
      "Epoch: 19, Loss (standarized): 0.2529048214871902\n",
      "          Validation Loss (standardized): 2.027208438371791\n",
      "Epoch: 20, Loss (standarized): 0.2529452749265961\n",
      "          Validation Loss (standardized): 2.034602972845301\n",
      "Final epoch: 20, Final loss (standarized): 0.2529452749265961\n",
      "Epoch: 1, Loss (standarized): 1.9473461097580398\n",
      "          Validation Loss (standardized): 1.0708143052587917\n",
      "Epoch: 2, Loss (standarized): 1.4301426649707283\n",
      "          Validation Loss (standardized): 0.9184236398656719\n",
      "Epoch: 3, Loss (standarized): 1.0238607693860502\n",
      "          Validation Loss (standardized): 0.8537356316126156\n",
      "Epoch: 4, Loss (standarized): 0.7261290165109668\n",
      "          Validation Loss (standardized): 0.8716845353971209\n",
      "Epoch: 5, Loss (standarized): 0.5303532981227517\n",
      "          Validation Loss (standardized): 0.9509342966117776\n",
      "Epoch: 6, Loss (standarized): 0.41527913905554564\n",
      "          Validation Loss (standardized): 1.0617718208501643\n",
      "Epoch: 7, Loss (standarized): 0.3489162849902923\n",
      "          Validation Loss (standardized): 1.1833590534737213\n",
      "Epoch: 8, Loss (standarized): 0.3086895888302332\n",
      "          Validation Loss (standardized): 1.3060152862921885\n",
      "Epoch: 9, Loss (standarized): 0.2837287478144661\n",
      "          Validation Loss (standardized): 1.424928536705109\n",
      "Epoch: 10, Loss (standarized): 0.2684217462850203\n",
      "          Validation Loss (standardized): 1.5368509843382543\n",
      "Epoch: 11, Loss (standarized): 0.2591947692539422\n",
      "          Validation Loss (standardized): 1.6397955114838907\n",
      "Epoch: 12, Loss (standarized): 0.2538824362838042\n",
      "          Validation Loss (standardized): 1.7323936277916743\n",
      "Epoch: 13, Loss (standarized): 0.25097916679845866\n",
      "          Validation Loss (standardized): 1.8142246599466565\n",
      "Epoch: 14, Loss (standarized): 0.2496164911527025\n",
      "          Validation Loss (standardized): 1.8849973905352726\n",
      "Epoch: 15, Loss (standarized): 0.24903330674696614\n",
      "          Validation Loss (standardized): 1.9448931292370286\n",
      "Epoch: 16, Loss (standarized): 0.24871554342085211\n",
      "          Validation Loss (standardized): 1.993915069556668\n",
      "Epoch: 17, Loss (standarized): 0.24835447037519098\n",
      "          Validation Loss (standardized): 2.0327210790251655\n",
      "Epoch: 18, Loss (standarized): 0.24778590370686704\n",
      "          Validation Loss (standardized): 2.061937276743543\n",
      "Epoch: 19, Loss (standarized): 0.24689059858544138\n",
      "          Validation Loss (standardized): 2.0821420159205655\n",
      "Epoch: 20, Loss (standarized): 0.24557019458586632\n",
      "          Validation Loss (standardized): 2.0938872996723568\n",
      "Final epoch: 20, Final loss (standarized): 0.24557019458586632\n",
      "Epoch: 1, Loss (standarized): 1.3476467918221842\n",
      "          Validation Loss (standardized): 0.8050117092536436\n",
      "Epoch: 2, Loss (standarized): 0.9471455557113492\n",
      "          Validation Loss (standardized): 0.7542883023086278\n",
      "Epoch: 3, Loss (standarized): 0.6390282099524578\n",
      "          Validation Loss (standardized): 0.7902643761670726\n",
      "Epoch: 4, Loss (standarized): 0.4282874518507614\n",
      "          Validation Loss (standardized): 0.8989556006372084\n",
      "Epoch: 5, Loss (standarized): 0.30676362938491647\n",
      "          Validation Loss (standardized): 1.0499420367088723\n",
      "Epoch: 6, Loss (standarized): 0.24616156885154325\n",
      "          Validation Loss (standardized): 1.2166067153583575\n",
      "Epoch: 7, Loss (standarized): 0.21981369307918508\n",
      "          Validation Loss (standardized): 1.382287950791565\n",
      "Epoch: 8, Loss (standarized): 0.2108930223826868\n",
      "          Validation Loss (standardized): 1.5374309861360433\n",
      "Epoch: 9, Loss (standarized): 0.2103943504203873\n",
      "          Validation Loss (standardized): 1.676169194057845\n",
      "Epoch: 10, Loss (standarized): 0.2136660391564103\n",
      "          Validation Loss (standardized): 1.7959488510096024\n",
      "Epoch: 11, Loss (standarized): 0.21827051562936417\n",
      "          Validation Loss (standardized): 1.8951624618263627\n",
      "Epoch: 12, Loss (standarized): 0.2228585192629368\n",
      "          Validation Loss (standardized): 1.973954386719621\n",
      "Epoch: 13, Loss (standarized): 0.22681709391799035\n",
      "          Validation Loss (standardized): 2.033026841643901\n",
      "Epoch: 14, Loss (standarized): 0.2298042573285325\n",
      "          Validation Loss (standardized): 2.0737566474287434\n",
      "Epoch: 15, Loss (standarized): 0.23165219547727914\n",
      "          Validation Loss (standardized): 2.0977813102106615\n",
      "Epoch: 16, Loss (standarized): 0.23237479974874706\n",
      "          Validation Loss (standardized): 2.106856405017311\n",
      "Epoch: 17, Loss (standarized): 0.23206593056429883\n",
      "          Validation Loss (standardized): 2.102794436763795\n",
      "Epoch: 18, Loss (standarized): 0.23086313182063858\n",
      "          Validation Loss (standardized): 2.087655268424305\n",
      "Epoch: 19, Loss (standarized): 0.22890701915766531\n",
      "          Validation Loss (standardized): 2.063342144244865\n",
      "Epoch: 20, Loss (standarized): 0.22636879080157374\n",
      "          Validation Loss (standardized): 2.0314780146093874\n",
      "Final epoch: 20, Final loss (standarized): 0.22636879080157374\n",
      "Epoch: 1, Loss (standarized): 1.1266669330701682\n",
      "          Validation Loss (standardized): 0.7187428426695414\n",
      "Epoch: 2, Loss (standarized): 0.776987260750404\n",
      "          Validation Loss (standardized): 0.7138297575772676\n",
      "Epoch: 3, Loss (standarized): 0.5540917870165198\n",
      "          Validation Loss (standardized): 0.7729484664042227\n",
      "Epoch: 4, Loss (standarized): 0.41866645684092857\n",
      "          Validation Loss (standardized): 0.8672215649187807\n",
      "Epoch: 5, Loss (standarized): 0.33621521029845425\n",
      "          Validation Loss (standardized): 0.9791148116516817\n",
      "Epoch: 6, Loss (standarized): 0.28711112411020473\n",
      "          Validation Loss (standardized): 1.097482223913547\n",
      "Epoch: 7, Loss (standarized): 0.25856079894289913\n",
      "          Validation Loss (standardized): 1.2146365880785615\n",
      "Epoch: 8, Loss (standarized): 0.24178854009683373\n",
      "          Validation Loss (standardized): 1.3269875747485198\n",
      "Epoch: 9, Loss (standarized): 0.2321050760510883\n",
      "          Validation Loss (standardized): 1.431960946790573\n",
      "Epoch: 10, Loss (standarized): 0.22669082982486352\n",
      "          Validation Loss (standardized): 1.5270707952427045\n",
      "Epoch: 11, Loss (standarized): 0.2238137947375083\n",
      "          Validation Loss (standardized): 1.6111634796426977\n",
      "Epoch: 12, Loss (standarized): 0.2225180480916796\n",
      "          Validation Loss (standardized): 1.6846829285865763\n",
      "Epoch: 13, Loss (standarized): 0.2221984210724259\n",
      "          Validation Loss (standardized): 1.7474676161614808\n",
      "Epoch: 14, Loss (standarized): 0.2223571206393209\n",
      "          Validation Loss (standardized): 1.7993631469000468\n",
      "Epoch: 15, Loss (standarized): 0.22258743976518955\n",
      "          Validation Loss (standardized): 1.840570819876382\n",
      "Epoch: 16, Loss (standarized): 0.22268310556854926\n",
      "          Validation Loss (standardized): 1.871499973431424\n",
      "Epoch: 17, Loss (standarized): 0.2225551536140732\n",
      "          Validation Loss (standardized): 1.8926016534313765\n",
      "Epoch: 18, Loss (standarized): 0.22213046828732846\n",
      "          Validation Loss (standardized): 1.9047359387808376\n",
      "Epoch: 19, Loss (standarized): 0.22136425488517247\n",
      "          Validation Loss (standardized): 1.9084442367319978\n",
      "Epoch: 20, Loss (standarized): 0.22021410355662857\n",
      "          Validation Loss (standardized): 1.9043662047778485\n",
      "Final epoch: 20, Final loss (standarized): 0.22021410355662857\n",
      "Epoch: 1, Loss (standarized): 0.802631057383428\n",
      "          Validation Loss (standardized): 0.7548170975090739\n",
      "Epoch: 2, Loss (standarized): 0.5593274350610166\n",
      "          Validation Loss (standardized): 0.7757475269595164\n",
      "Epoch: 3, Loss (standarized): 0.3976764891988649\n",
      "          Validation Loss (standardized): 0.8473668097234384\n",
      "Epoch: 4, Loss (standarized): 0.30545667235720386\n",
      "          Validation Loss (standardized): 0.9477179176331408\n",
      "Epoch: 5, Loss (standarized): 0.25670158239674634\n",
      "          Validation Loss (standardized): 1.056004235601265\n",
      "Epoch: 6, Loss (standarized): 0.23057910579749377\n",
      "          Validation Loss (standardized): 1.1648118141154555\n",
      "Epoch: 7, Loss (standarized): 0.21702947925464022\n",
      "          Validation Loss (standardized): 1.2702221625187569\n",
      "Epoch: 8, Loss (standarized): 0.21031582464835627\n",
      "          Validation Loss (standardized): 1.3690509976212843\n",
      "Epoch: 9, Loss (standarized): 0.20759442016608073\n",
      "          Validation Loss (standardized): 1.4598487879713113\n",
      "Epoch: 10, Loss (standarized): 0.20729773533868404\n",
      "          Validation Loss (standardized): 1.5401973874988955\n",
      "Epoch: 11, Loss (standarized): 0.20824652759682685\n",
      "          Validation Loss (standardized): 1.608644193756024\n",
      "Epoch: 12, Loss (standarized): 0.20968692985939769\n",
      "          Validation Loss (standardized): 1.6643815118457366\n",
      "Epoch: 13, Loss (standarized): 0.21114380200033797\n",
      "          Validation Loss (standardized): 1.7046044907784539\n",
      "Epoch: 14, Loss (standarized): 0.21196049619873386\n",
      "          Validation Loss (standardized): 1.7307604343603007\n",
      "Epoch: 15, Loss (standarized): 0.21209603116614312\n",
      "          Validation Loss (standardized): 1.7438677574515788\n",
      "Epoch: 16, Loss (standarized): 0.21150921433762504\n",
      "          Validation Loss (standardized): 1.7450681523784595\n",
      "Epoch: 17, Loss (standarized): 0.2102497412835344\n",
      "          Validation Loss (standardized): 1.7357099454842757\n",
      "Epoch: 18, Loss (standarized): 0.208415139315302\n",
      "          Validation Loss (standardized): 1.7169062301066846\n",
      "Epoch: 19, Loss (standarized): 0.20626163345572254\n",
      "          Validation Loss (standardized): 1.690122045013852\n",
      "Epoch: 20, Loss (standarized): 0.2038652306554565\n",
      "          Validation Loss (standardized): 1.6567605025254055\n",
      "Final epoch: 20, Final loss (standarized): 0.2038652306554565\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "archs = [[2, 20, 20, 2]]\n",
    "funs = [sigmoid, tanh, relu, leaky_relu]\n",
    "fun_derivs = [sigmoid_deriv, tanh_deriv, relu_deriv, leaky_relu_deriv]\n",
    "dropouts = [0] # Testy dropout'u usunąłem\n",
    "early_stops = [0, 50, 100, 200, 500]  # Patience = 1 jest za mały tak samo = 5 oraz 10 i 20, więc usunąłem\n",
    "l1_vals = [0, 0.01, 0.001, 0.0001]\n",
    "l2_vals = [0, 0.01, 0.001, 0.0001]\n",
    "initialization = [\"xavier\", \"xavier\", \"he\", \"he\"]\n",
    "results = { \"Arch\": [],\n",
    "            \"Fun\": [],\n",
    "            \"Fscore\": [],\n",
    "            \"Train_results\": [], \n",
    "            \"Dropout\": [],\n",
    "            \"Patience\": [],\n",
    "            \"Net\": [],\n",
    "            \"L1\": [],\n",
    "            \"L2\": [],}\n",
    "\n",
    "for arch in archs:\n",
    "    for i in range(len(funs)):\n",
    "        for dropout in dropouts:\n",
    "            for early_stop in early_stops:\n",
    "                for l1 in l1_vals:\n",
    "                    for l2 in l2_vals:\n",
    "                        net = MLP(arch, act_fun=funs[i], act_derivative=fun_derivs[i], out_fun=softmax, out_derivative=linear_deriv, init_type=initialization[i], dropout_rate=dropout)\n",
    "                        curr_result = net.train_classify(x = x_train, y = y_train, loss_fun=cross_entropy, epochs = 2000, optimizer=Adam(), batch_size=None, early_stopping_patience=early_stop, val_x=x_test, val_y=y_test, l1_lambda=l1, l2_lambda=l2)\n",
    "                        y_pred = net.predict(x_test)\n",
    "                        y_pred = from_one_hot_to_label(one_hot_from_probabilities(y_pred))\n",
    "                        fscore = f1_score(from_one_hot_to_label(y_test), y_pred)\n",
    "                        results[\"Arch\"].append(arch)\n",
    "                        results[\"Fun\"].append(funs[i])\n",
    "                        results[\"Fscore\"].append(fscore)\n",
    "                        results[\"Train_results\"].append(curr_result)\n",
    "                        results[\"Dropout\"].append(dropout)\n",
    "                        results[\"Patience\"].append(early_stop)\n",
    "                        results[\"Net\"].append(net)\n",
    "                        results[\"L1\"].append(l1)\n",
    "                        results[\"L2\"].append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f77e5afa-2d41-41df-820c-c2d150160169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Fscore</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function sigmoid at 0x0000029E017B67A0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.9990982381917314, 0.7964175200920551, 0.629...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A79850&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[1.8129334075970067, 1.2401851294230544, 0.799...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A4B30&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.5454827750633963, 0.39242598156201347, 0.30...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E06097C50&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[1.1377418463229305, 0.9144219468716726, 0.746...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A6ED0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.8179433095803389, 0.4547866995877197, 0.271...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A71D0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.42026775157087926, 0.3000891597284046, 0.24...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A6AB0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.9205653748657537, 0.6148184504559785, 0.423...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A46B0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[1.3461390802655486, 0.9196603399735378, 0.596...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A24950&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.4496733514275121, 0.2998960793678898, 0.235...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A4B60&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7462582799316065, 0.5526188638301006, 0.416...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A7770&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7522850978434035, 0.5108971160245153, 0.365...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A5E50&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.5712795341104541, 0.4092758036124388, 0.309...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E04E5C5F0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.5207957329373953, 0.35960733106839954, 0.27...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A6360&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[2.103717775683884, 1.5892659567076504, 1.1549...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A7290&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[2.3926323872281023, 1.8295787338337461, 1.350...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A54C0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[2.1493735472723277, 1.6187049307415964, 1.169...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A5100&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.8276150330784804, 0.4790277666894583, 0.312...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A6EA0&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.45456247033672503, 0.29823786266051877, 0.2...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A58B0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[1.783034336065763, 1.3562848352984513, 1.0098...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A4AD0&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function relu at 0x0000029E039CF2E0&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7846367981912522, 0.5248029020260114, 0.367...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E015A7410&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Arch                                       Fun    Fscore  \\\n",
       "0    [2, 20, 20, 2]  <function sigmoid at 0x0000029E017B67A0>  0.355878   \n",
       "217  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "216  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "215  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "214  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "213  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "212  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "211  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "218  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "210  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "208  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "207  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "206  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "205  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "204  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "203  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "202  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "209  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "201  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "219  [2, 20, 20, 2]     <function relu at 0x0000029E039CF2E0>  0.355878   \n",
       "\n",
       "                                         Train_results  Dropout  Patience  \\\n",
       "0    [0.9990982381917314, 0.7964175200920551, 0.629...        0         0   \n",
       "217  [1.8129334075970067, 1.2401851294230544, 0.799...        0       200   \n",
       "216  [0.5454827750633963, 0.39242598156201347, 0.30...        0       200   \n",
       "215  [1.1377418463229305, 0.9144219468716726, 0.746...        0       200   \n",
       "214  [0.8179433095803389, 0.4547866995877197, 0.271...        0       200   \n",
       "213  [0.42026775157087926, 0.3000891597284046, 0.24...        0       200   \n",
       "212  [0.9205653748657537, 0.6148184504559785, 0.423...        0       200   \n",
       "211  [1.3461390802655486, 0.9196603399735378, 0.596...        0       200   \n",
       "218  [0.4496733514275121, 0.2998960793678898, 0.235...        0       200   \n",
       "210  [0.7462582799316065, 0.5526188638301006, 0.416...        0       200   \n",
       "208  [0.7522850978434035, 0.5108971160245153, 0.365...        0       200   \n",
       "207  [0.5712795341104541, 0.4092758036124388, 0.309...        0       100   \n",
       "206  [0.5207957329373953, 0.35960733106839954, 0.27...        0       100   \n",
       "205  [2.103717775683884, 1.5892659567076504, 1.1549...        0       100   \n",
       "204  [2.3926323872281023, 1.8295787338337461, 1.350...        0       100   \n",
       "203  [2.1493735472723277, 1.6187049307415964, 1.169...        0       100   \n",
       "202  [0.8276150330784804, 0.4790277666894583, 0.312...        0       100   \n",
       "209  [0.45456247033672503, 0.29823786266051877, 0.2...        0       200   \n",
       "201  [1.783034336065763, 1.3562848352984513, 1.0098...        0       100   \n",
       "219  [0.7846367981912522, 0.5248029020260114, 0.367...        0       200   \n",
       "\n",
       "                                             Net      L1      L2  \n",
       "0    <__main__.MLP object at 0x0000029E03A79850>  0.0000  0.0000  \n",
       "217  <__main__.MLP object at 0x0000029E015A4B30>  0.0010  0.0100  \n",
       "216  <__main__.MLP object at 0x0000029E06097C50>  0.0010  0.0000  \n",
       "215  <__main__.MLP object at 0x0000029E015A6ED0>  0.0100  0.0001  \n",
       "214  <__main__.MLP object at 0x0000029E015A71D0>  0.0100  0.0010  \n",
       "213  <__main__.MLP object at 0x0000029E015A6AB0>  0.0100  0.0100  \n",
       "212  <__main__.MLP object at 0x0000029E015A46B0>  0.0100  0.0000  \n",
       "211  <__main__.MLP object at 0x0000029E03A24950>  0.0000  0.0001  \n",
       "218  <__main__.MLP object at 0x0000029E015A4B60>  0.0010  0.0010  \n",
       "210  <__main__.MLP object at 0x0000029E015A7770>  0.0000  0.0010  \n",
       "208  <__main__.MLP object at 0x0000029E015A5E50>  0.0000  0.0000  \n",
       "207  <__main__.MLP object at 0x0000029E04E5C5F0>  0.0001  0.0001  \n",
       "206  <__main__.MLP object at 0x0000029E015A6360>  0.0001  0.0010  \n",
       "205  <__main__.MLP object at 0x0000029E015A7290>  0.0001  0.0100  \n",
       "204  <__main__.MLP object at 0x0000029E015A54C0>  0.0001  0.0000  \n",
       "203  <__main__.MLP object at 0x0000029E015A5100>  0.0010  0.0001  \n",
       "202  <__main__.MLP object at 0x0000029E015A6EA0>  0.0010  0.0010  \n",
       "209  <__main__.MLP object at 0x0000029E015A58B0>  0.0000  0.0100  \n",
       "201  <__main__.MLP object at 0x0000029E015A4AD0>  0.0010  0.0100  \n",
       "219  <__main__.MLP object at 0x0000029E015A7410>  0.0010  0.0001  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(\"Fscore\")\n",
    "results_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "66989f02-9a6e-4038-b2e5-0acf313428d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arch</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Fscore</th>\n",
       "      <th>Train_results</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Net</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7581627236798786, 0.6572151512300274, 0.590...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01068320&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7197509524665786, 0.6450618419278153, 0.590...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0106BFE0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.6976249233994154, 0.641467034117524, 0.5937...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A49AC0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7003944788133226, 0.6460274994613167, 0.602...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0106A030&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7063152486138947, 0.6445450490556737, 0.599...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0106BD70&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7701357423049778, 0.6287279560227769, 0.549...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01783AD0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.8120209688426318, 0.6577341871262202, 0.562...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01068FE0&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.8138378764679226, 0.6771249358865179, 0.589...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0106AAB0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7445651717548015, 0.6635680101035777, 0.613...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E03A49670&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7101301942518431, 0.6420985254142356, 0.596...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01068A40&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7352593105614135, 0.6296195619844722, 0.572...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0106BA70&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7141440766640053, 0.6260182709981398, 0.569...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E019D2690&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.70624698185106, 0.6365968294497404, 0.57957...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01068080&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7813703349928443, 0.6587850125515413, 0.588...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E0106B320&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7323795256326135, 0.6446638077728594, 0.589...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E019D2480&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7785221792678743, 0.6592789482797644, 0.578...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E01068AA0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.7532828897238186, 0.6475859738900196, 0.579...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E019D02C0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function tanh at 0x0000029E039CE200&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.6967002997538676, 0.6380344932203226, 0.587...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E010698E0&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[1.1266669330701682, 0.776987260750404, 0.5540...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05F8D5E0&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>[2, 20, 20, 2]</td>\n",
       "      <td>&lt;function leaky_relu at 0x0000029E039CE980&gt;</td>\n",
       "      <td>0.355878</td>\n",
       "      <td>[0.802631057383428, 0.5593274350610166, 0.3976...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;__main__.MLP object at 0x0000029E05F8CC50&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Arch                                          Fun    Fscore  \\\n",
       "100  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "117  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "116  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "115  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "114  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "113  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "112  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "111  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "110  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "109  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "108  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "107  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "106  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "105  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "104  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "103  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "102  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "101  [2, 20, 20, 2]        <function tanh at 0x0000029E039CE200>  0.355878   \n",
       "318  [2, 20, 20, 2]  <function leaky_relu at 0x0000029E039CE980>  0.355878   \n",
       "319  [2, 20, 20, 2]  <function leaky_relu at 0x0000029E039CE980>  0.355878   \n",
       "\n",
       "                                         Train_results  Dropout  Patience  \\\n",
       "100  [0.7581627236798786, 0.6572151512300274, 0.590...        0        50   \n",
       "117  [0.7197509524665786, 0.6450618419278153, 0.590...        0       100   \n",
       "116  [0.6976249233994154, 0.641467034117524, 0.5937...        0       100   \n",
       "115  [0.7003944788133226, 0.6460274994613167, 0.602...        0       100   \n",
       "114  [0.7063152486138947, 0.6445450490556737, 0.599...        0       100   \n",
       "113  [0.7701357423049778, 0.6287279560227769, 0.549...        0       100   \n",
       "112  [0.8120209688426318, 0.6577341871262202, 0.562...        0       100   \n",
       "111  [0.8138378764679226, 0.6771249358865179, 0.589...        0        50   \n",
       "110  [0.7445651717548015, 0.6635680101035777, 0.613...        0        50   \n",
       "109  [0.7101301942518431, 0.6420985254142356, 0.596...        0        50   \n",
       "108  [0.7352593105614135, 0.6296195619844722, 0.572...        0        50   \n",
       "107  [0.7141440766640053, 0.6260182709981398, 0.569...        0        50   \n",
       "106  [0.70624698185106, 0.6365968294497404, 0.57957...        0        50   \n",
       "105  [0.7813703349928443, 0.6587850125515413, 0.588...        0        50   \n",
       "104  [0.7323795256326135, 0.6446638077728594, 0.589...        0        50   \n",
       "103  [0.7785221792678743, 0.6592789482797644, 0.578...        0        50   \n",
       "102  [0.7532828897238186, 0.6475859738900196, 0.579...        0        50   \n",
       "101  [0.6967002997538676, 0.6380344932203226, 0.587...        0        50   \n",
       "318  [1.1266669330701682, 0.776987260750404, 0.5540...        0       500   \n",
       "319  [0.802631057383428, 0.5593274350610166, 0.3976...        0       500   \n",
       "\n",
       "                                             Net      L1      L2  \n",
       "100  <__main__.MLP object at 0x0000029E01068320>  0.0100  0.0000  \n",
       "117  <__main__.MLP object at 0x0000029E0106BFE0>  0.0100  0.0100  \n",
       "116  <__main__.MLP object at 0x0000029E03A49AC0>  0.0100  0.0000  \n",
       "115  <__main__.MLP object at 0x0000029E0106A030>  0.0000  0.0001  \n",
       "114  <__main__.MLP object at 0x0000029E0106BD70>  0.0000  0.0010  \n",
       "113  <__main__.MLP object at 0x0000029E01783AD0>  0.0000  0.0100  \n",
       "112  <__main__.MLP object at 0x0000029E01068FE0>  0.0000  0.0000  \n",
       "111  <__main__.MLP object at 0x0000029E0106AAB0>  0.0001  0.0001  \n",
       "110  <__main__.MLP object at 0x0000029E03A49670>  0.0001  0.0010  \n",
       "109  <__main__.MLP object at 0x0000029E01068A40>  0.0001  0.0100  \n",
       "108  <__main__.MLP object at 0x0000029E0106BA70>  0.0001  0.0000  \n",
       "107  <__main__.MLP object at 0x0000029E019D2690>  0.0010  0.0001  \n",
       "106  <__main__.MLP object at 0x0000029E01068080>  0.0010  0.0010  \n",
       "105  <__main__.MLP object at 0x0000029E0106B320>  0.0010  0.0100  \n",
       "104  <__main__.MLP object at 0x0000029E019D2480>  0.0010  0.0000  \n",
       "103  <__main__.MLP object at 0x0000029E01068AA0>  0.0100  0.0001  \n",
       "102  <__main__.MLP object at 0x0000029E019D02C0>  0.0100  0.0010  \n",
       "101  <__main__.MLP object at 0x0000029E010698E0>  0.0100  0.0100  \n",
       "318  <__main__.MLP object at 0x0000029E05F8D5E0>  0.0001  0.0010  \n",
       "319  <__main__.MLP object at 0x0000029E05F8CC50>  0.0001  0.0001  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "05261a96-196c-446c-a4cb-3d986d5a1ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96016349, 0.03983651],\n",
       "       [0.95969293, 0.04030707],\n",
       "       [0.9622243 , 0.0377757 ],\n",
       "       ...,\n",
       "       [0.96062674, 0.03937326],\n",
       "       [0.96162107, 0.03837893],\n",
       "       [0.96078154, 0.03921846]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.iloc[200][\"Net\"].predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
